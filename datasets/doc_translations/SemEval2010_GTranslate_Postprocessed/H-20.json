{
    "id": "H-20",
    "original_text": "New Event Detection Based on Indexing-tree and Named Entity Zhang Kuo Tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn Li Juan Zi Tsinghua University Beijing, 100084, China 86-10-62781461 ljz@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn ABSTRACT New Event Detection (NED) aims at detecting from one or multiple streams of news stories that which one is reported on a new event (i.e. not reported previously). With the overwhelming volume of news available today, there is an increasing need for a NED system which is able to detect new events more efficiently and accurately. In this paper we propose a new NED model to speed up the NED task by using news indexing-tree dynamically. Moreover, based on the observation that terms of different types have different effects for NED task, two term reweighting approaches are proposed to improve NED accuracy. In the first approach, we propose to adjust term weights dynamically based on previous story clusters and in the second approach, we propose to employ statistics on training data to learn the named entity reweighting model for each class of stories. Experimental results on two Linguistic Data Consortium (LDC) datasets TDT2 and TDT3 show that the proposed model can improve both efficiency and accuracy of NED task significantly, compared to the baseline system and other existing systems. Categories and Subject Descriptors H.3.3 [Information Systems]: Information Search and Retrieval; H.4.2 [Information Systems Applications]: Types of Systemsdecision support. General Terms Algorithms, Performance, Experimentation 1. INTRODUCTION Topic Detection and Tracking (TDT) program aims to develop techniques which can effectively organize, search and structure news text materials from a variety of newswire and broadcast media [1]. New Event Detection (NED) is one of the five tasks in TDT. It is the task of online identification of the earliest report for each topic as soon as that report arrives in the sequence of documents. A Topic is defined as a seminal event or activity, along with directly related events and activities [2]. An Event is defined as something (non-trivial) happening in a certain place at a certain time [3]. For instance, when a bomb explodes in a building, the exploding is the seminal event that triggers the topic, and other stories on the same topic would be those discussing salvaging efforts, the search for perpetrators, arrests and trial and so on. Useful news information is usually buried in a mass of data generated everyday. Therefore, NED systems are very useful for people who need to detect novel information from real-time news stream. These real-life needs often occur in domains like financial markets, news analysis, and intelligence gathering. In most of state-of-the-art (currently) NED systems, each news story on hand is compared to all the previous received stories. If all the similarities between them do not exceed a threshold, then the story triggers a new event. They are usually in the form of cosine similarity or Hellinger similarity metric. The core problem of NED is to identify whether two stories are on the same topic. Obviously, these systems cannot take advantage of topic information. Further more, it is not acceptable in real applications because of the large amount of computation required in the NED process. Other systems organize previous stories into clusters (each cluster corresponds to a topic), and new story is compared to the previous clusters instead of stories. This manner can reduce comparing times significantly. Nevertheless, it has been proved that this manner is less accurate [4, 5]. This is because sometimes stories within a topic drift far away from each other, which could lead low similarity between a story and its topic. On the other hand, some proposed NED systems tried to improve accuracy by making better use of named entities [10, 11, 12, 13]. However, none of the systems have considered that terms of different types (e.g. Noun, Verb or Person name) have different effects for different classes of stories in determining whether two stories are on the same topic. For example, the names of election candidates (Person name) are very important for stories of election class; the locations (Location name) where accidents happened are important for stories of accidents class. So, in NED, there still exist following three problems to be investigated: (1) How to speed up the detection procedure while do not decrease the detection accuracy? (2) How to make good use of cluster (topic) information to improve accuracy? (3) How to obtain better news story representation by better understanding of named entities. Driven by these problems, we have proposed three approaches in this paper. (1)To make the detection procedure faster, we propose a new NED procedure based on news indexing-tree created dynamically. Story indexing-tree is created by assembling similar stories together to form news clusters in different hierarchies according to their values of similarity. Comparisons between current story and previous clusters could help find the most similar story in less comparing times. The new procedure can reduce the amount of comparing times without hurting accuracy. (2)We use the clusters of the first floor in the indexing-tree as news topics, in which term weights are adjusted dynamically according to term distribution in the clusters. In this approach, cluster (topic) information is used properly, so the problem of theme decentralization is avoided. (3)Based on observations on the statistics obtained from training data, we found that terms of different types (e.g. Noun and Verb) have different effects for different classes of stories in determining whether two stories are on the same topic. And we propose to use statistics to optimize the weights of the terms of different types in a story according to the news class that the story belongs to. On TDT3 dataset, the new NED model just uses 14.9% comparing times of the basic model, while its minimum normalized cost is 0.5012, which is 0.0797 better than the basic model, and also better than any other results previously reported for this dataset [8, 13]. The rest of the paper is organized as follows. We start off this paper by summarizing the previous work in NED in section 2. Section 3 presents the basic model for NED that most current systems use. Section 4 describes our new detection procedure based on news indexing-tree. In section 5, two term reweighting methods are proposed to improve NED accuracy. Section 6 gives our experimental data and evaluation metrics. We finally wrap up with the experimental results in Section 7, and the conclusions and future work in Section 8. 2. RELATED WORK Papka et al. proposed Single-Pass clustering on NED [6]. When a new story was encountered, it was processed immediately to extract term features and a query representation of the storys content is built up. Then it was compared with all the previous queries. If the document did not trigger any queries by exceeding a threshold, it was marked as a new event. Lam et al build up previous query representations of story clusters, each of which corresponds to a topic [7]. In this manner comparisons happen between stories and clusters. Recent years, most work focus on proposing better methods on comparison of stories and document representation. Brants et al. [8] extended a basic incremental TF-IDF model to include sourcespecific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, term reweighting based on inverse event frequencies, and segmentation of documents. Good improvements on TDT bench-marks were shown. Stokes et al. [9] utilized a combination of evidence from two distinct representations of a documents content. One of the representations was the usual free text vector, the other made use of lexical chains (created using WordNet) to build another term vector. Then the two representations are combined in a linear fashion. A marginal increase in effectiveness was achieved when the combined representation was used. Some efforts have been done on how to utilize named entities to improve NED. Yang et al. gave location named entities four times weight than other terms and named entities [10]. DOREMI research group combined semantic similarities of person names, location names and time together with textual similarity [11][12]. UMass [13] research group split document representation into two parts: named entities and non-named entities. And it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation. Both [10] and [13] used text categorization technique to classify news stories in advance. In [13] news stories are classified automatically at first, and then test sensitivities of names and non-name terms for NED for each class. In [10] frequent terms for each class are removed from document representation. For example, word election does not help identify different elections. In their work, effectiveness of different kinds of names (or terms with different POS) for NED in different news classes are not investigated. We use statistical analysis to reveal the fact and use it to improve NED performance. 3. BASIC MODEL In this section, we present the basic New Event Detection model which is similar to what most current systems apply. Then, we propose our new model by extending the basic model. New Event Detection systems use news story stream as input, in which stories are strictly time-ordered. Only previously received stories are available when dealing with current story. The output is a decision for whether the current story is on a new event or not and the confidence of the decision. Usually, a NED model consists of three parts: story representation, similarity calculation and detection procedure. 3.1 Story Representation Preprocessing is needed before generating story representation. For preprocessing, we tokenize words, recognize abbreviations, normalize abbreviations, add part-of-speech tags, remove stopwords included in the stop list used in InQuery [14], replace words with their stems using K-stem algorithm[15], and then generate word vector for each news story. We use incremental TF-IDF model for term weight calculation [4]. In a TF-IDF model, term frequency in a news document is weighted by the inverse document frequency, which is generated from training corpus. When a new term occurs in testing process, there are two solutions: simply ignore the new term or set df of the term as a small const (e.g. df = 1). The new term receives too low weight in the first solution (0) and too high weight in the second solution. In incremental TF-IDF model, document frequencies are updated dynamically in each time step t: 1( ) ( ) ( )t t D tdf w df w df w−= + (1) where Dt represents news story set received in time t, and dfDt(w) means the number of documents that term w occurs in, and dft(w) means the total number of documents that term w occurs in before time t. In this work, each time window includes 50 news stories. Thus, each story d received in t is represented as follows: 1 2{ ( , , ), ( , , ),..., ( , , )}nd weight d t w weight d t w weight d t w→ where n means the number of distinct terms in story d, and ( , , )weight d t w means the weight of term w in story d at time t: log( ( , ) 1) log(( 1) /( ( ) 0.5)) ( , , ) log( ( , ) 1) log(( 1) /( ( ) 0.5)) t t t t w d tf d w N df w weight d t w tf d w N df w ∈ + + + = + + +∑ (2) where Nt means the total number of news stories before time t, and tf(d,w) means how many times term w occurs in news story d. 3.2 Similarity Calculation We use Hellinger distance for the calculation of similarity between two stories, for two stories d and d at time t, their similarity is defined as follows: , ( , , ) ( , , ) * ( , , ) w d d sim d d t weight d t w weight d t w ∈ = ∑ (3) 3.3 Detection Procedure For each story d received in time step t, the value ( ) ( ) ( ) ( ( , , )) time d time d n d max sim d d t < = (4) is a score used to determine whether d is a story about a new topic and at the same time is an indication of the confidence in our decision [8]. time(d) means the publication time of story d. If the score exceeds the thresholdθ new, then there exists a sufficiently similar document, thus d is a old story, otherwise, there is no sufficiently similar previous document, thus d is an new story. 4. New NED Procedure Traditional NED systems can be classified into two main types on the aspect of detection procedure: (1) S-S type, in which the story on hand is compared to each story received previously, and use the highest similarity to determine whether current story is about a new event; (2) S-C type, in which the story on hand is compared to all previous clusters each of which representing a topic, and the highest similarity is used for final decision for current story. If the highest similarity exceeds thresholdθ new, then it is an old story, and put it into the most similar cluster; otherwise it is a new story and create a new cluster. Previous work show that the first manner is more accurate than the second one [4][5]. Since sometimes stories within a topic drift far away from each other, a story may have very low similarity with its topic. So using similarities between stories for determining new story is better than using similarities between story and clusters. Nevertheless, the first manner needs much more comparing times which means the first manner is low efficient. We propose a new detection procedure which uses comparisons with previous clusters to help find the most similar story in less comparing times, and the final new event decision is made according to the most similar story. Therefore, we can get both the accuracy of S-S type methods and the efficiency of S-C type methods. The new procedure creates a news indexing-tree dynamically, in which similar stories are put together to form a hierarchy of clusters. We index similar stories together by their common ancestor (a cluster node). Dissimilar stories are indexed in different clusters. When a story is coming, we use comparisons between the current story and previous hierarchical clusters to help find the most similar story which is useful for new event decision. After the new event decision is made, the current story is inserted to the indexing-tree for the following detection. The news indexing-tree is defined formally as follows: S-Tree = {r, NC , NS , E} where r is the root of S-Tree, NC is the set of all cluster nodes, NS is the set of all story nodes, and E is the set of all edges in S-Tree. We define a set of constraints for a S-Tree: ⅰ . , is an non-terminal node in the treeC i i N i∀ ∈ → ⅱ . , is a terminal node in the treeS i i N i∀ ∈ → ⅲ . , out degree of is at least 2C i i N i∀ ∈ → ⅳ . , is represented as the centroid of its desendantsC i i iN∀ ∈ → For a news story di, the comparison procedure and inserting procedure based on indexing-tree are defined as follows. An example is shown by Figure 1 and Figure 2. Figure 1. Comparison procedure Figure 2. Inserting procedure Comparison procedure: Step 1: compare di to all the direct child nodes of r and select λ nodes with highest similarities, e.g., C1 2 and C1 3 in Figure 1. Step 2: for each selected node in the last step, e.g. C1 2, compare di to all its direct child nodes, and select λ nodes with highest similarities, e.g. C2 2 and d8. Repeat step 2 for all non-terminal nodes. Step 3: record the terminal node with the highest similarty to di, e.g. s5, and the similarity value (0.20). Inserting di to the S-tree with r as root: Find the node n which is direct child of r in the path from r to the terminal node with highest similarity s, e.g. C1 2. If s is smaller than θ init+(h-1)δ , then add di to the tree as a direct child of r. Otherwise, if n is a terminal node, then create a cluster node instead of n, and add both n and di as its direct children; if n is an non-terminal node, then repeat this procedure and insert di to the sub-tree with n as root recursively. Here h is the length between n and the root of S-tree. The more the stories in a cluster similar to each other, the better the cluster represents the stories in it. Hence we add no constraints on the maximum of trees height and degree of a node. Therefore, we cannot give the complexity of this indexing-tree based procedure. But we will give the number of comparing times needed by the new procedure in our experiments in section7. 5. Term Reweighting Methods In this section, two term reweighting methods are proposed to improve NED accuracy. In the first method, a new way is explored for better using of cluster (topic) information. The second one finds a better way to make use of named entities based on news classification. 5.1 Term Reweighting Based on Distribution Distance TF-IDF is the most prevalent model used in information retrieval systems. The basic idea is that the fewer documents a term appears in, the more important the term is in discrimination of documents (relevant or not relevant to a query containing the term). Nevertheless, in TDT domain, we need to discriminate documents with regard to topics rather than queries. Intuitively, using cluster (topic) vectors to compare with subsequent news stories should outperform using story vectors. Unfortunately, the experimental results do not support this intuition [4][5]. Based on observation on data, we find the reason is that a news topic usually contains many directly or indirectly related events, while they all have their own sub-subjects which are usually different with each other. Take the topic described in section 1 as an example, events like the explosion and salvage have very low similarities with events about criminal trial, therefore stories about trial would have low similarity with the topic vector built on its previous events. This section focuses on how to effectively make use of topic information and at the same time avoid the problem of content decentralization. At first, we classify terms into 5 classes to help analysis the needs of the modified model: Term class A: terms that occur frequently in the whole corpus, e.g., year and people. Terms of this class should be given low weights because they do not help much for topic discrimination. Term class B: terms that occur frequently within a news category, e.g., election, storm. They are useful to distinguish two stories in different news categories. However, they cannot provide information to determine whether two stories are on the same or different topics. In another words, term election and term storm are not helpful in differentiate two election campaigns and two storm disasters. Therefore, terms of this class should be assigned lower weights. Term class C: terms that occur frequently in a topic, and infrequently in other topics, e.g., the name of a crash plane, the name of a specific hurricane. News stories that belong to different topics rarely have overlap terms in this class. The more frequently a term appears in a topic, the more important the term is for a story belonging to the topic, therefore the term should be set higher weight. Term class D: terms that appear in a topic exclusively, but not frequently. For example, the name of a fireman who did very well in a salvage action, which may appears in only two or three stories but never appeared in other topics. Terms of this type should receive more weights than in TF-IDF model. However, since they are not popular in the topic, it is not appropriate to give them too high weights. Term class E: terms with low document frequency, and appear in different topics. Terms of this class should receive lower weights. Now we analyze whether TF-IDF model can give proper weights to the five classes of terms. Obviously, terms of class A are lowly weighted in TF-IDF model, which is conformable with the requirement described above. In TF-IDF model, terms of class B are highly dependant with the number of stories in a news class. TF-IDF model cannot provide low weights if the story containing the term belongs to a relative small news class. For a term of class C, the more frequently it appears in a topic, the less weight TFIDF model gives to it. This strongly conflicts with the requirement of terms in class C. For terms of class D, TF-IDF model gives them high weights correctly. But for terms of class E, TF-IDF model gives high weights to them which are not conformable with the requirement of low weights. To sum up, terms of class B, C, E cannot be properly weighted in TF-IDF model. So, we propose a modified model to resolve this problem. When θ init andθ new are set closely, we assume that most of the stories in a first-level cluster (a direct child node of root node) are on the same topic. Therefore, we make use of a first-level cluster to capture term distribution (df for all the terms within the cluster) within the topic dynamically. KL divergence of term distribution in a first-level cluster and the whole story set is used to adjust term weights:  ( , , ) * (1 * ( || )) ( , , ) ( , , ) * (1 * ( || )) cw tw cw tw w d D weight d t w KL P P weight d t w weight d t w KL P P γ γ ∈ + = +∑ (5) where ( ) ( ) ( ) ( ) 1,cw cw c c c c df w df w p y p y N N = = − (6) ( ) ( ) ( ) ( ) 1,t t tw tw t t df w df w p y p y N N = = − (7) where dfc(w) is the number of documents containing term w within cluster C, and Nc is the number of documents in cluster C, and Nt is the total number of documents that arrive before time step t. γ is a const parameter, now is manually set 3. KL divergence is defined as follows [17]: ( ) ( || ) ( ) log ( )x p x KL P Q p x q x = ∑ (8) The basic idea is: for a story in a topic, the more a term occurs within the topic, and the less it occurs in other topics, it should be assigned higher weights. Obviously, modified model can meet all the requirements of the five term classes listed above. 5.2 Term Reweighting Based on Term Type and Story Class Previous work found that some classes of news stories could achieve good improvements by giving extra weight to named entities. But we find that terms of different types should be given different amount of extra weight for different classes of news stories. We use open-NLP1 to recognize named entity types and part-ofspeech tags for terms that appear in news stories. Named entity types include person name, organization name, location name, date, time, money and percentage, and five POSs are selected: none (NN), verb (VB), adjective (JJ), adverb (RB) and cardinal number (CD). Statistical analysis shows topic-level discriminative terms types for different classes of stories. For the sake of convenience, named entity type and part-of-speech tags are uniformly called term type in subsequent sections. Determining whether two stories are about the same topic is a basic component for NED task. So at first we use 2 χ statistic to compute correlations between terms and topics. For a term t and a topic T, a contingence table is derived: Table 1. A 2×2 Contingence Table Doc Number belong to topic T not belong to topic T include t A B not include t C D The 2 χ statistic for a specific term t with respect to topic T is defined to be [16]: 2 2 ( , ) ( ) * ( ) ( ) * ( ) * ( ) * ( ) w T A B C D AD CB A C B D A B C D χ = + + + − + + + + (9) News topics for the TDT task are further classified into 11 rules of interpretations (ROIs) 2 . The ROI can be seen as a higher level class of stories. The average correlation between a term type and a topic ROI is computed as: 2 avg 2 ( , )( ( , ) )k m m km kT R w P w TP R p w T R P χ χ ∈ ∈ ∑ ∑（ , ）= 1 1 k=1…K, m=1…M (10) where K is the number of term types (set 12 constantly in the paper). M is the number news classes (ROIs, set 11 in the paper). Pk represents the set of all terms of type k, and Rm represents the set of all topics of class m, p(t,T) means the probability that t occurs in topic T. Because of limitation of space, only parts of the term types (9 term types) and parts of news classes (8 classes) are listed in table 2 with the average correlation values between them. The statistics is derived from labeled data in TDT2 corpus. (Results in table 2 are already normalized for convenience in comparison.) The statistics in table 2 indicates the usefulness of different term types in topic discrimination with respect to different news classes. We can see that, location name is the most useful term type for three news classes: Natural Disasters, Violence or War, Finances. And for three other categories Elections, Legal/Criminal Cases, Science and Discovery, person name is the most discriminative term type. For Scandals/Hearings, date is the most important information for topic discrimination. In addition, Legal/Criminal Cases and Finance topics have higher correlation with money terms, while Science and Discovery have higher correlation with percentage terms. Non-name terms are more stable for different classes. 1 . http://opennlp.sourceforge.net/ 2 . http://projects.ldc.upenn.edu/TDT3/Guide/label.html From the analysis of table 2, it is reasonable to adjust term weight according to their term type and the news class the story belongs to. New term weights are reweighted as follows: ( ) ( ) ( ) ( ) ( , , ) * ( , , ) ( , , ) * class d D type w T class d D type w w d weight d t w weight d t w weight d t w α α ∈ = ∑ (11) where type(w) represents the type of term w, and class(d) represents the class of story d, c kα is reweighting parameter for news class c and term type k. In the work, we just simply use statistics in table 2 as the reweighting parameters. Even thought using the statistics directly may not the best choice, we do not discuss how to automatically obtain the best parameters. We will try to use machine learning techniques to obtain the best parameters in the future work. In the work, we use BoosTexter [20] to classify all stories into one of the 11 ROIs. BoosTexter is a boosting based machine learning program, which creates a series of simple rules for building a classifier for text or attribute-value data. We use term weight generated using TF-IDF model as feature for story classification. We trained the model on the 12000 judged English stories in TDT2, and classify the rest of the stories in TDT2 and all stories in TDT3. Classification results are used for term reweighting in formula (11). Since the class labels of topic-off stories are not given in TDT datasets, we cannot give the classification accuracy here. Thus we do not discuss the effects of classification accuracy to NED performance in the paper. 6. EXPERIMENTAL SETUP 6.1 Datasets We used two LDC [18] datasets TDT2 and TDT3 for our experiments. TDT2 contains news stories from January to June 1998. It contains around 54,000 stories from sources like ABC, Associated Press, CNN, New York Times, Public Radio International, Voice of America etc. Only English stories in the collection were considered. TDT3 contains approximately 31,000 English stories collected from October to December 1998. In addition to the sources used in TDT2, it also contains stories from NBC and MSNBC TV broadcasts. We used transcribed versions of the TV and radio broadcasts besides textual news. TDT2 dataset is labeled with about 100 topics, and approximately 12,000 English stories belong to at least one of these topics. TDT3 dataset is labeled with about 120 topics, and approximately 8000 English stories belong to at least one of these topics. All the topics are classified into 11 Rules of Interpretation: (1)Elections, (2)Scandals/Hearings, (3)Legal/Criminal Cases, (4)Natural Disasters, (5)Accidents, (6)Ongoing Violence or War, (7)Science and Discovery News, (8)Finance, (9)New Law, (10)Sports News, (11)MISC. News. 6.2 Evaluation Metric TDT uses a cost function CDet that combines the probabilities of missing a new story and a false alarm [19]: * * * *Det Miss Miss Target FA FA NontargetC C P P C P P= + (12) Table 2. Average correlation between term types and news classes where CMiss means the cost of missing a new story, PMiss means the probability of missing a new story, and PTarget means the probability of seeing a new story in the data; CFA means the cost of a false alarm, PFA means the probability of a false alarm, and PNontarget means the probability of seeing an old story. The cost CDet is normalized such that a perfect system scores 0 and a trivial system, which is the better one of mark all stories as new or old, scores 1: ( ( * , * ) ) Det Det Miss Target FA Nontarget C Norm C min C P C P = (13) New event detection system gives two outputs for each story. The first part is yes or no indicating whether the story triggers a new event or not. The second part is a score indicating confidence of the first decision. Confidence scores can be used to plot DET curve, i.e., curves that plot false alarm vs. miss probabilities. Minimum normalized cost can be determined if optimal threshold on the score were chosen. 7. EXPERIMENTAL RESULTS 7.1 Main Results To test the approaches proposed in the model, we implemented and tested five systems: System-1: this system is used as baseline. It is implemented based on the basic model described in section 3, i.e., using incremental TF-IDF model to generate term weights, and using Hellinger distance to compute document similarity. Similarity score normalization is also employed [8]. S-S detection procedure is used. System-2: this system is the same as system-1 except that S-C detection procedure is used. System-3: this system is the same as system-1 except that it uses the new detection procedure which is based on indexing-tree. System-4: implemented based on the approach presented in section 5.1, i.e., terms are reweighted according to the distance between term distributions in a cluster and all stories. The new detection procedure is used. System-5: implemented based on the approach presented in section 5.2, i.e., terms of different types are reweighted according to news class using trained parameters. The new detection procedure is used. The following are some other NED systems: System-6: [21] for each pair of stories, it computes three similarity values for named entity, non-named entity and all terms respectively. And employ Support Vector Machine to predict new or old using the similarity values as features. System-7: [8] it extended a basic incremental TF-IDF model to include source-specific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, etc. System-8: [13] it split document representation into two parts: named entities and non-named entities, and choose one effective part for each news class. Table 3 and table 4 show topic-weighted normalized costs and comparing times on TDT2 and TDT3 datasets respectively. Since no heldout data set for fine-tuning the threshold θ new was available for experiments on TDT2, we only report minimum normalized costs for our systems in table 3. System-5 outperforms all other systems including system-6, and it performs only 2.78e+8 comparing times in detection procedure which is only 13.4% of system-1. Table 3. NED results on TDT2 Systems Min Norm(CDet) Cmp times System-1 0.5749 2.08e+9 System-2① 0.6673 3.77e+8 System-3② 0.5765 2.81e+8 System-4② 0.5431 2.99e+8 System-5② 0.5089 2.78e+8 System-6 0.5300 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 When evaluating on the normalized costs on TDT3, we use the optimal thresholds obtained from TDT2 data set for all systems. System-2 reduces comparing times to 1.29e+9 which is just 18.3% of system-1, but at the same time it also gets a deteriorated minimum normalized cost which is 0.0499 higher than system-1. System-3 uses the new detection procedure based on news indexing-tree. It requires even less comparing times than system-2. This is because story-story comparisons usually yield greater similarities than story-cluster ones, so stories tend to be combined Location Person Date Organization Money Percentage NN JJ CD Elections 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 Scandals/Hearings 0.66 0.62 0.28 1 0.11 0.02 0.27 0.13 0.05 Legal/Criminal Cases 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 Natural Disasters 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 Violence or War 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 Science and Discovery 0.11 1 0.01 0.22 0.08 0.12 0.19 0.08 0.03 Finances 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 Sports 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 together in system-3. And system-3 is basically equivalent to system-1 in accuracy results. System-4 adjusts term weights based on the distance of term distributions between the whole corpus and cluster story set, yielding a good improvement by 0.0468 compared to system-1. The best system (system-5) has a minimum normalized cost 0.5012, which is 0.0797 better than system-1, and also better than any other results previously reported for this dataset [8, 13]. Further more, system-5 only needs 1.05e+8 comparing times which is 14.9% of system-1. Table 4. NED results on TDT3 Systems Norm(CDet) Min Norm(CDet) Cmp times System-1 0.6159 0.5809 7.04e+8 System-2① 0.6493 0.6308 1.29e+8 System-3② 0.6197 0.5868 1.03e+8 System-4② 0.5601 0.5341 1.03e+8 System-5② 0.5413 0.5012 1.05e+8 System-7 -- 0.5783 -System-8 -- 0.5229 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 Figure5 shows the five DET curves for our systems on data set TDT3. System-5 achieves the minimum cost at a false alarm rate of 0.0157 and a miss rate of 0.4310. We can observe that System4 and System-5 obtain lower miss probability at regions of low false alarm probabilities. The hypothesis is that, more weight value is transferred to key terms of topics from non-key terms. Similarity score between two stories belonging to different topics are lower than before, because their overlapping terms are usually not key terms of their topics. 7.2 Parameter selection for indexing-tree detection Figure 3 shows the minimum normalized costs obtained by system-3 on TDT3 using different parameters. Theθ init parameter is tested on six values spanning from 0.03 to 0.18. And the λ parameter is tested on four values 1, 2, 3 and 4. We can see that, whenθ init is set to 0.12, which is the closest one toθ new, the costs are lower than others. This is easy to explain, because when stories belonging to the same topic are put in a cluster, it is more reasonable for the cluster to represent the stories in it. When parameter λ is set to 3 or 4, the costs are better than other cases, but there is no much difference between 3 and 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ MinCost 0.6 0.65 0.7 0.75 0.8 0.85 0.9 Figure 3. Min Cost on TDT3 (δ =0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ Comparingtimes 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 Figure 4. Comparing times on TDT3 (δ =0.15) Figure 4 gives the comparing times used by system-3 on TDT3 with the same parameters as figure 3. The comparing times are strongly dependent onθ init. Because the greaterθ init is, the less stories combined together, the more comparing times are needed for new event decision. So we useθ init =0.13,λ =3,δ =0.15 for system-3, 4, and 5. In this parameter setting, we can get both low minimum normalized costs and less comparing times. 8. CONCLUSION We have proposed a news indexing-tree based detection procedure in our model. It reduces comparing times to about one seventh of traditional method without hurting NED accuracy. We also have presented two extensions to the basic TF-IDF model. The first extension is made by adjust term weights based on term distributions between the whole corpus and a cluster story set. And the second extension to basic TF-IDF model is better use of term types (named entities types and part-of-speed) according to news categories. Our experimental results on TDT2 and TDT3 datasets show that both of the two extensions contribute significantly to improvement in accuracy. We did not consider news time information as a clue for NED task, since most of the topics last for a long time and TDT data sets only span for a relative short period (no more than 6 months). For the future work, we want to collect news set which span for a longer period from internet, and integrate time information in NED task. Since topic is a relative coarse-grained news cluster, we also want to refine cluster granularity to event-level, and identify different events and their relations within a topic. Acknowledgments This work is supported by the National Natural Science Foundation of China under Grant No. 90604025. Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsor. 9. REFERENCES [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] In Topic Detection and Tracking. Event-based Information Organization. Kluwer Academic Publishers, 2002. .01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90 1 2 5 10 20 40 60 80 90 False Alarm Probability (in %) MissProbability(in%) SYSTEM1 Topic Weighted Curve SYSTEM1 Min Norm(Cost) SYSTEM2 Topic Weighted Curve SYSTEM2 Min Norm(Cost) SYSTEM3 Topic Weighted Curve SYSTEM3 Min Norm(Cost) SYSTEM4 Topic Weighted Curve SYSTEM4 Min Norm(Cost) SYSTEM5 Topic Weighted Curve SYSTEM5 Min Norm(Cost) Random Performance Figure 5. DET curves on TDT3 [3] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B.T. Archibald, and X. Liu. Learning Approaches for Detecting and Tracking News Events. In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), 1999, 32-43. [4] Y. Yang, T. Pierce, and J. Carbonell. A Study on Retrospective and On-line Event Detection. In Proceedings of SIGIR-98, Melbourne, Australia, 1998, 28-36. [5] J. Allan, V. Lavrenko, D. Malin, and R. Swan. Detections, Bounds, and Timelines: Umass and tdt-3. In Proceedings of Topic Detection and Tracking Workshop (TDT-3), Vienna, VA, 2000, 167-174. [6] R. Papka and J. Allan. On-line New Event Detection Using Single Pass Clustering TITLE2:. Technical Report UM-CS1998-021, 1998. [7] W. Lam, H. Meng, K. Wong, and J. Yen. Using Contextual Analysis for News Event Detection. International Journal on Intelligent Systems, 2001, 525-546. [8] B. Thorsten, C. Francine, and F. Ayman. A System for New Event Detection. In Proceedings of the 26th Annual International ACM SIGIR Conference, New York, NY, USA. ACM Press. 2003, 330-337. [9] S. Nicola and C. Joe. Combining Semantic and Syntactic Document Classifiers to Improve First Story Detection. In Proceedings of the 24th Annual International ACM SIGIR Conference, New York, NY, USA. ACM Press. 2001, 424425. [10] Y. Yang, J. Zhang, J. Carbonell, and C. Jin. Topicconditioned Novelty Detection. In Proceedings of the 8th ACM SIGKDD International Conference, ACM Press. 2002, 688-693. [11] M. Juha, A.M. Helena, and S. Marko. Applying Semantic Classes in Event Detection and Tracking. In Proceedings of International Conference on Natural Language Processing (ICON 2002), 2002, pages 175-183. [12] M. Juha, A.M. Helena, and S. Marko. Simple Semantics in Topic Detection and Tracking. Information Retrieval, 7(3-4): 2004, 347-368. [13] K. Giridhar and J. Allan. Text Classification and Named Entities for New Event Detection. In Proceedings of the 27th Annual International ACM SIGIR Conference, New York, NY, USA. ACM Press. 2004, 297-304. [14] J. P. Callan, W. B. Croft, and S. M. Harding. The INQUERY Retrieval System. In Proceedings of DEXA-92, 3rd International Conference on Database and Expert Systems Applications, 1992, 78-83. [15] R. Krovetz. Viewing Morphology as An Inference Process. In Proceedings of ACM SIGIR93, 1993, 61-81. [16] Y. Yang and J. Pedersen. A Comparative Study on Feature Selection in Text Categorization. In J. D. H. Fisher, editor, The Fourteenth International Conference on Machine Learning (ICML97), Morgan Kaufmann, 1997, 412-420. [17] T. M. Cover, and J.A. Thomas. Elements of Information Theory. Wiley. 1991. [18] The linguistic data consortium, http://www.ldc,upenn.edu/. [19] The 2001 TDT task definition and evaluation plan, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm. [20] R. E. Schapire and Y. Singer. Boostexter: A Boosting-based System for Text Categorization. In Machine Learning 39(2/3):1, Kluwer Academic Publishers, 2000, 35-168. [21] K. Giridhar and J. Allan. 2005. Using Names and Topics for New Event Detection. In Proceedings of Human Technology Conference and Conference on Empirical Methods in Natural Language, Vancouver, 2005, 121-128",
    "original_translation": "Nueva detección de eventos basada en el árbol de indexación y la entidad nombrada Zhang Kuo tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn li Juan zi tsinghua University Beijing, 100084, China 86-10-62781414141 LiJzzze Beijing, 100084, China 86-10-62781414141@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn Resumen New Detection (NED) para detectar de una o múltiples transmisionesde noticias que se informan sobre un nuevo evento (es decir ,. no se informó anteriormente). Con el abrumador volumen de noticias disponibles en la actualidad, existe una creciente necesidad de un sistema NED que pueda detectar nuevos eventos de manera más eficiente y precisa. En este artículo proponemos un nuevo modelo NED para acelerar la tarea NED mediante el uso de la indexación de noticias dinámicamente. Además, en base a la observación de que los términos de diferentes tipos tienen diferentes efectos para la tarea NED, se proponen enfoques de re -peso de dos términos para mejorar la precisión de NED. En el primer enfoque, proponemos ajustar los pesos de los términos basados dinámicamente en los grupos de historias anteriores y en el segundo enfoque, proponemos emplear estadísticas sobre datos de capacitación para aprender el modelo de reweapting de entidad nombrado para cada clase de historias. Los resultados experimentales en dos conjuntos de datos del consorcio de datos lingüísticos (LDC) TDT2 y TDT3 muestran que el modelo propuesto puede mejorar significativamente la eficiencia y la precisión de la tarea NED, en comparación con el sistema de referencia y otros sistemas existentes. Categorías y descriptores de sujetos H.3.3 [Sistemas de información]: Búsqueda y recuperación de información;H.4.2 [Aplicaciones de sistemas de información]: Tipos de soporte de SystemsDecision. Algoritmos de términos generales, rendimiento, experimentación 1. Introducción El programa de detección y seguimiento de temas (TDT) tiene como objetivo desarrollar técnicas que puedan organizar, buscar y estructurar materiales de texto de noticias de manera efectiva de una variedad de medios de comunicación y transmisión [1]. La nueva detección de eventos (NED) es una de las cinco tareas en TDT. Es la tarea de la identificación en línea del primer informe para cada tema tan pronto como ese informe llega en la secuencia de documentos. Un tema se define como un evento o actividad seminal, junto con eventos y actividades directamente relacionados [2]. Un evento se define como algo (no trivial) que ocurre en cierto lugar en un momento determinado [3]. Por ejemplo, cuando una bomba explota en un edificio, la explosión es el evento seminal que desencadena el tema, y otras historias sobre el mismo tema serían aquellos que discuten los esfuerzos de recuperación, la búsqueda de perpetradores, arrestos y juicio, etc. La información de noticias útil generalmente se entierra en una masa de datos generados todos los días. Por lo tanto, los sistemas NED son muy útiles para las personas que necesitan detectar información novedosa del flujo de noticias en tiempo real. Estas necesidades de la vida real a menudo ocurren en dominios como mercados financieros, análisis de noticias y recopilación de inteligencia. En la mayoría de los sistemas NED de última generación (actualmente), cada noticia disponible se compara con todas las historias recibidas anteriores. Si todas las similitudes entre ellos no exceden un umbral, entonces la historia desencadena un nuevo evento. Por lo general, están en forma de similitud cosena o métrica de similitud de Hellinger. El problema central de NED es identificar si dos historias están sobre el mismo tema. Obviamente, estos sistemas no pueden aprovechar la información del tema. Además, no es aceptable en aplicaciones reales debido a la gran cantidad de cálculo requerida en el proceso NED. Otros sistemas organizan historias anteriores en grupos (cada clúster corresponde a un tema), y se compara una nueva historia con los grupos anteriores en lugar de las historias. Esta manera puede reducir significativamente los tiempos de comparación. Sin embargo, se ha demostrado que esta manera es menos precisa [4, 5]. Esto se debe a que a veces las historias dentro de un tema se alejan del otro, lo que podría llevar una baja similitud entre una historia y su tema. Por otro lado, algunos sistemas NED propuestos intentaron mejorar la precisión al hacer un mejor uso de las entidades nombradas [10, 11, 12, 13]. Sin embargo, ninguno de los sistemas ha considerado los términos de diferentes tipos (p. Ej. Nombre de sustantivo, verbo o persona) tiene diferentes efectos para diferentes clases de historias para determinar si dos historias están sobre el mismo tema. Por ejemplo, los nombres de los candidatos electorales (nombre de la persona) son muy importantes para las historias de clase electoral;Las ubicaciones (nombre de ubicación) donde ocurrieron los accidentes son importantes para las historias de la clase de accidentes. Entonces, en NED, todavía existe después de tres problemas a investigar: (1) ¿Cómo acelerar el procedimiento de detección mientras no disminuye la precisión de la detección?(2) ¿Cómo hacer un buen uso de la información del clúster (tema) para mejorar la precisión?(3) Cómo obtener una mejor representación de noticias mediante una mejor comprensión de las entidades nombradas. Impulsados por estos problemas, hemos propuesto tres enfoques en este documento.(1) Para hacer el procedimiento de detección más rápido, proponemos un nuevo procedimiento NED basado en el árbol de indexación de noticias creado dinámicamente. El árbol de la indexación de historias se crea reuniendo historias similares para formar grupos de noticias en diferentes jerarquías de acuerdo con sus valores de similitud. Las comparaciones entre la historia actual y los clústeres anteriores podrían ayudar a encontrar la historia más similar en los tiempos menos comparantes. El nuevo procedimiento puede reducir la cantidad de tiempos de comparación sin dañar la precisión.(2) Usamos los grupos del primer piso en el árbol de indexación como temas de noticias, en los que los pesos de término se ajustan dinámicamente de acuerdo con la distribución de términos en los grupos. En este enfoque, la información del clúster (tema) se usa correctamente, por lo que se evita el problema de la descentralización del tema.(3) Basado en las observaciones sobre las estadísticas obtenidas de los datos de capacitación, encontramos que los términos de diferentes tipos (p. Ej. Sustantivo y verbo) tienen diferentes efectos para diferentes clases de historias para determinar si dos historias están sobre el mismo tema. Y proponemos usar estadísticas para optimizar los pesos de los términos de diferentes tipos en una historia de acuerdo con la clase de noticias a la que pertenece la historia. En el conjunto de datos TDT3, el nuevo modelo NED solo usa el 14.9% de comparación de tiempos del modelo básico, mientras que su costo normalizado mínimo es 0.5012, que es 0.0797 mejor que el modelo básico, y también mejor que cualquier otro resultado informado previamente para este conjunto de datos [8, 13]. El resto del documento está organizado de la siguiente manera. Comenzamos este documento resumiendo el trabajo anterior en NED en la Sección 2. La Sección 3 presenta el modelo básico para NED que usan la mayoría de los sistemas actuales. La Sección 4 describe nuestro nuevo procedimiento de detección basado en el árbol de indexación de noticias. En la Sección 5, se proponen métodos de rewesavo de dos términos para mejorar la precisión de NED. La Sección 6 proporciona nuestras métricas experimentales de datos y evaluación. Finalmente terminamos con los resultados experimentales en la Sección 7, y las conclusiones y el trabajo futuro en la Sección 8. 2. Trabajo relacionado Papka et al.Agrupación de paso único propuesto en NED [6]. Cuando se encontró una nueva historia, se procesó inmediatamente para extraer características de términos y se construye una representación de consulta del contenido de las historias. Luego se comparó con todas las consultas anteriores. Si el documento no activó ninguna consulta al exceder un umbral, se marcó como un nuevo evento. Lam et al construyen representaciones de consultas anteriores de grupos de historias, cada uno de los cuales corresponde a un tema [7]. De esta manera, las comparaciones ocurren entre historias y grupos. Los últimos años, la mayoría de los trabajos se centran en proponer mejores métodos en la comparación de historias y representación de documentos. Brants et al.[8] extendió un modelo básico de TF-IDF incremental para incluir modelos específicos de fuentes, normalización de la puntuación de similitud basada en promedios específicos de documentos, normalización de puntaje de similitud basada en promedios específicos de pares de origen, reescribencia de término basado en frecuencias de eventos inversas y segmentación de documentos. Se mostraron buenas mejoras en las marcas de banco TDT. Stokes et al.[9] utilizó una combinación de evidencia de dos representaciones distintas de un contenido de documentos. Una de las representaciones fue el vector de texto libre habitual, el otro hizo uso de cadenas léxicas (creadas usando WordNet) para construir otro vector de término. Luego, las dos representaciones se combinan de manera lineal. Se logró un aumento marginal en la efectividad cuando se usó la representación combinada. Se han realizado algunos esfuerzos sobre cómo utilizar entidades nombradas para mejorar NED. Yang et al.Dio ubicación entidades nombradas cuatro veces peso que otros términos y entidades nombradas [10]. Doremi Research Group combinó similitudes semánticas de nombres de personas, nombres de ubicación y tiempo junto con similitud textual [11] [12]. UMass [13] El grupo de investigación dividió la representación del documento en dos partes: entidades nombradas y entidades no nombradas. Y se descubrió que algunas clases de noticias podrían lograr un mejor rendimiento utilizando la representación de entidad nombrada, mientras que otras clases de noticias podrían lograr un mejor rendimiento utilizando la representación de la entidad no nombrada. Tanto [10] como [13] utilizaron la técnica de categorización de texto para clasificar las noticias de antemano. En [13], las noticias se clasifican automáticamente al principio, y luego prueban las sensibilidades de los nombres y los términos no name para NED para cada clase. En [10] los términos frecuentes para cada clase se eliminan de la representación del documento. Por ejemplo, la elección de palabras no ayuda a identificar diferentes elecciones. En su trabajo, no se investigan la efectividad de diferentes tipos de nombres (o términos con diferentes POS) para NED en diferentes clases de noticias. Utilizamos el análisis estadístico para revelar el hecho y lo usamos para mejorar el rendimiento de NED.3. Modelo básico En esta sección, presentamos el nuevo modelo básico de detección de eventos que es similar a lo que se aplican la mayoría de los sistemas actuales. Luego, proponemos nuestro nuevo modelo extendiendo el modelo básico. Los nuevos sistemas de detección de eventos utilizan la transmisión de noticias como entrada, en la que las historias están estrictamente ordenadas por el tiempo. Solo las historias recibidas anteriormente están disponibles cuando se trata de la historia actual. El resultado es una decisión de si la historia actual está en un nuevo evento o no y la confianza de la decisión. Por lo general, un modelo NED consta de tres partes: representación de la historia, cálculo de similitud y procedimiento de detección.3.1 Se necesita preprocesamiento de la representación de la historia antes de generar la representación de la historia. Para el preprocesamiento, tokenizamos las palabras, reconocemos abreviaturas, normalizamos las abreviaturas, agregamos etiquetas de parte de voz, eliminamos las palabras de parada incluidas en la lista de paradas utilizadas en la investigación [14], reemplace las palabras con sus tallos utilizando el algoritmo de K-SIM [15] yLuego genere Word Vector para cada noticia. Utilizamos el modelo TF-IDF incremental para el cálculo de peso a término [4]. En un modelo TF-IDF, la frecuencia de término en un documento de noticias se pone en peso de la frecuencia de documentos inversos, que se genera a partir del corpus de capacitación. Cuando se produce un nuevo término en el proceso de prueba, hay dos soluciones: simplemente ignore el nuevo término o establezca DF del término como un constante constante (por ejemplo, DF = 1). El nuevo término recibe un peso demasiado bajo en la primera solución (0) y un peso demasiado alto en la segunda solución. En el modelo TF-IDF incremental, las frecuencias de documentos se actualizan dinámicamente en cada paso de tiempo T: 1 () () () T T D TDF W DF W DF W- = + (1) Donde DT representa el conjunto de noticias de noticias recibidas en el tiempo T,y DFDT (W) significa que el número de documentos que el término W ocurre en, y DFT (W) significa el número total de documentos que el término W ocurre antes del tiempo t.En este trabajo, cada ventana de tiempo incluye 50 noticias. Por lo tanto, cada historia d recibida en t se representa de la siguiente manera: 1 2 {(,,), (,,), ..., (,,)} Nd peso d t w peso d t w peso d t w → donde n significa el número de distintoTérminos en la historia d, y (,,) peso d t w significa el peso del término w en la historia d en el tiempo t: log ((,) 1) log ((1) /(() 0.5)) (,,) log ((,) 1) log (((1) /(() 0.5)) t t t t t w w d tf d w n df w peso d t w tf d w n df w ∈ + + + = + + + ∑ (2) donde nt significa el número total de noticiasHistorias antes del tiempo T, y TF (D, W) significa cuántas veces ocurre el término W en la noticia d.3.2 Similarity Calculation We use Hellinger distance for the calculation of similarity between two stories, for two stories d and d at time t, their similarity is defined as follows: , ( , , ) ( , , ) * ( , , ) w d d sim d d tpeso d t w peso d t w ∈ = ∑ (3) 3.3 Procedimiento de detección para cada historia D recibida en el paso de tiempo t, el valor () () () ((,)) Tiempo D Tiempo D N D MAX SIM D D T <= (4) ISUna puntuación utilizada para determinar si D es una historia sobre un nuevo tema y al mismo tiempo es una indicación de la confianza en nuestra decisión [8].El tiempo (d) significa el tiempo de publicación de la historia d.Si el puntaje excede el umbral θ nuevo, entonces existe un documento suficientemente similar, por lo tanto, D es una historia antigua, de lo contrario, no hay un documento anterior suficientemente similar, por lo que D es una nueva historia.4. Nuevo procedimiento NED Los sistemas NED tradicionales se pueden clasificar en dos tipos principales sobre el aspecto del procedimiento de detección: (1) Tipo S-S, en el que la historia disponible se compara con cada historia recibida anteriormente, y utilice la mayor similitud para determinar si la historia actualse trata de un nuevo evento;(2) Tipo S-C, en el que la historia disponible se compara con todos los grupos anteriores, cada uno de los cuales representa un tema, y la mayor similitud se usa para la decisión final para la historia actual. Si la mayor similitud excede el umbral, entonces, entonces es una historia antigua y la pone en el clúster más similar;De lo contrario, es una nueva historia y crea un nuevo clúster. El trabajo anterior muestra que la primera manera es más precisa que la segunda [4] [5]. Dado que a veces las historias dentro de un tema se alejan del otro, una historia puede tener muy baja similitud con su tema. Por lo tanto, usar similitudes entre historias para determinar una nueva historia es mejor que usar similitudes entre la historia y los clústeres. Sin embargo, la primera manera necesita mucho más tiempos de comparación, lo que significa que la primera manera es de baja eficiente. Proponemos un nuevo procedimiento de detección que utiliza comparaciones con grupos anteriores para ayudar a encontrar la historia más similar en los tiempos de comparación menos, y la nueva decisión del evento final se toma de acuerdo con la historia más similar. Por lo tanto, podemos obtener tanto la precisión de los métodos de tipo S-S como la eficiencia de los métodos de tipo S-C. El nuevo procedimiento crea un árbol de indexación de noticias dinámicamente, en el que se elaboran historias similares para formar una jerarquía de grupos. Indexamos historias similares juntas por su antepasado común (un nodo de clúster). Las historias diferentes se indexan en diferentes grupos. Cuando se acerca una historia, utilizamos comparaciones entre la historia actual y los grupos jerárquicos anteriores para ayudar a encontrar la historia más similar que sea útil para la nueva decisión de eventos. Después de tomar la nueva decisión del evento, la historia actual se inserta en el árbol de indexación para la siguiente detección. El árbol de indexación de noticias se define formalmente de la siguiente manera: s-tree = {r, nc, ns, e} donde r es la raíz de s-tree, nc es el conjunto de todos los nodos de clúster, ns es el conjunto de toda la historiaNodos, y E es el conjunto de todos los bordes en S-Tree. Definimos un conjunto de restricciones para un árbol S: ⅰ., es un nodo no terminal en el treec i i n i∀ ∈ → ⅱ., es un nodo terminal en los árboles i i n i∀ ∈ → ⅲ., grado de IS al menos 2c i i n i∀ ∈ → ⅳ., se representa como el centroide de sus desendantsc i i in∀ ∈ → Para una noticia DI, el procedimiento de comparación y el procedimiento de inserción basado en el árbol de indexación se definen de la siguiente manera. Un ejemplo se muestra en la Figura 1 y la Figura 2. Figura 1. Procedimiento de comparación Figura 2. Procedimiento del procedimiento de inserción Procedimiento de comparación: Paso 1: Compare DI con todos los nodos infantiles directos de R y seleccione los nodos λ con las más altas similitudes, por ejemplo, C1 2 y C1 3 en la Figura 1. Paso 2: para cada nodo seleccionado en el último paso, p. C1 2, compare DI con todos sus nodos infantiles directos y seleccione los nodos λ con las más altas similitudes, p. C2 2 y D8. Repita el paso 2 para todos los nodos no terminales. Paso 3: Registre el nodo terminal con la mayor similitud para hacer, p.S5, y el valor de similitud (0.20). Insertando DI al árbol S con R como raíz: Encuentre el nodo n que es un niño directo de R en la ruta de R al nodo terminal con la mayor similitud S, p. C1 2. Si S es más pequeño que θ init+(h-1) δ, entonces agregue DI al árbol como un hijo directo de r.De lo contrario, si N es un nodo terminal, cree un nodo de clúster en lugar de N, y agregue N y DI como sus hijos directos;Si N es un nodo no terminal, repita este procedimiento e inserte DI en el sub-árbol con N como raíz de recursiva. Aquí H es la longitud entre N y la raíz del árbol S. Cuanto más sean las historias en un clúster similares entre sí, mejor será el clúster las historias en él. Por lo tanto, no agregamos restricciones sobre el máximo de altura y grado de un nodo. Por lo tanto, no podemos dar la complejidad de este procedimiento basado en el árbol de indexación. Pero daremos el número de tiempos de comparación necesarios por el nuevo procedimiento en nuestros experimentos en la Sección 7.5. Métodos de reweaptheing de término En esta sección, se proponen métodos de rewesavo de dos términos para mejorar la precisión de NED. En el primer método, se explora una nueva forma para un mejor uso de la información de clúster (tema). El segundo encuentra una mejor manera de hacer uso de entidades nombradas basadas en la clasificación de noticias.5.1 El reescalentamiento a término basado en la distancia de distribución TF-IDF es el modelo más frecuente utilizado en los sistemas de recuperación de información. La idea básica es que los menos documentos en los que aparecen un término, cuanto más importante sea el término en la discriminación de los documentos (relevantes o no relevantes para una consulta que contiene el término). Sin embargo, en el dominio TDT, necesitamos discriminar documentos con respecto a los temas en lugar de las consultas. Intuitivamente, el uso de vectores de clúster (tema) para comparar con las noticias posteriores debe superar a los vectores de la historia. Desafortunadamente, los resultados experimentales no respaldan esta intuición [4] [5]. Basado en la observación de los datos, encontramos que la razón es que un tema de noticias generalmente contiene muchos eventos relacionados directa o indirectamente, mientras que todos tienen sus propios subconjetos que generalmente son diferentes entre sí. Tome el tema descrito en la Sección 1 como un ejemplo, eventos como la explosión y el salvamento tienen similitudes muy bajas con eventos sobre el juicio penal, por lo tanto, las historias sobre el juicio tendrían poca similitud con el vector del tema construido en sus eventos anteriores. Esta sección se centra en cómo utilizar de manera efectiva la información del tema y al mismo tiempo evitar el problema de la descentralización del contenido. Al principio, clasificamos los términos en 5 clases para ayudar a análisis de las necesidades del modelo modificado: Término Clase A: Términos que ocurren con frecuencia en todo el corpus, por ejemplo, año y personas. Los términos de esta clase deben tener bajos pesos porque no ayudan mucho para la discriminación del tema. Término Clase B: Términos que ocurren con frecuencia dentro de una categoría de noticias, por ejemplo, elección, tormenta. Son útiles para distinguir dos historias en diferentes categorías de noticias. Sin embargo, no pueden proporcionar información para determinar si dos historias están en los mismos o diferentes temas. En otras palabras, las elecciones a término y la tormenta no son útiles para diferenciar dos campañas electorales y dos desastres de tormentas. Por lo tanto, los términos de esta clase se les debe asignar pesos más bajos. Término Clase C: Términos que ocurren con frecuencia en un tema, y con poca frecuencia en otros temas, por ejemplo, el nombre de un avión de choque, el nombre de un huracán específico. Las noticias que pertenecen a diferentes temas rara vez tienen términos de superposición en esta clase. Cuanto más frecuentemente aparezca un término en un tema, más importante es el término para una historia que pertenece al tema, por lo tanto, el término debe establecerse con mayor peso. Término Clase D: Términos que aparecen en un tema exclusivamente, pero no con frecuencia. Por ejemplo, el nombre de un bombero que le fue muy bien en una acción de salvamento, que puede aparecer en solo dos o tres historias pero nunca apareció en otros temas. Los términos de este tipo deben recibir más pesos que en el modelo TF-IDF. Sin embargo, dado que no son populares en el tema, no es apropiado darles pesos demasiado altos. Término Clase E: Términos con baja frecuencia de documentos y aparecen en diferentes temas. Los términos de esta clase deben recibir pesos más bajos. Ahora analizamos si el modelo TF-IDF puede dar los pesos adecuados a las cinco clases de términos. Obviamente, los términos de clase A tienen un peso de baja en el modelo TF-IDF, que es conforme con el requisito descrito anteriormente. En el modelo TF-IDF, los términos de la clase B dependen en gran medida con el número de historias en una clase de noticias. El modelo TF-IDF no puede proporcionar pesos bajos si la historia que contiene el término pertenece a una clase relativa de noticias pequeña. Para un término de clase C, cuanto más frecuentemente aparece en un tema, menos peso TFIDF le da el modelo TFIDF. Esto en conflicto fuertemente con el requisito de los términos en la clase C. para los términos de la clase D, el modelo TF-IDF les da altos pesos correctamente. Pero para los términos de clase E, el modelo TF-IDF les da altos pesos que no son conformes con el requisito de pesos bajos. Para resumir, los términos de la clase B, C, E no pueden ponderarse adecuadamente en el modelo TF-IDF. Entonces, proponemos un modelo modificado para resolver este problema. Cuando θ init y θ new se establecen de cerca, suponemos que la mayoría de las historias en un clúster de primer nivel (un nodo infantil directo del nodo raíz) están en el mismo tema. Por lo tanto, utilizamos un clúster de primer nivel para capturar la distribución de términos (DF para todos los términos dentro del clúster) dentro del tema dinámicamente. Divergencia KL de la distribución del término en un clúster de primer nivel y todo el conjunto de la historia se usa para ajustar los pesos de los términos: (,,) * (1 * (||) (,,) (,,) * (1 * (||)) cw tw cw tw w d d peso d t w w kl p p peso d t w peso d t w kl p p γ γ ∈ + = + ∑ (5) Where () () () () 1, CW CW C C C DF W DF W P Y P Y N = = = =- (6) () () () () 1, t t t tw t t t t df w df w p y p y n n = = - (7) donde dfc (w) es el número de documentos que contienen el término w dentro del clúster c, y nc es elNúmero de documentos en el clúster C, y NT es el número total de documentos que llegan antes del tiempo, paso t.γ es un parámetro const, ahora se establece manualmente 3. La divergencia de KL se define de la siguiente manera [17]: () (||) () log () x p x kl p q p x q x = ∑ (8) La idea básica es: para una historia en un tema, cuanto más ocurre un término dentro del tema, y cuanto menos ocurre en otros temas, se le debe asignar pesos más altos. Obviamente, el modelo modificado puede cumplir con todos los requisitos de las cinco clases de términos enumeradas anteriormente.5.2 Término de rewesaveo basado en el tipo de término y la clase de historia El trabajo anterior descubrió que algunas clases de noticias podrían lograr buenas mejoras al dar peso adicional a las entidades nombradas. Pero encontramos que los términos de diferentes tipos deberían tener una cantidad diferente de peso adicional para diferentes clases de noticias. Utilizamos Open-NLP1 para reconocer los tipos de entidades nombrados y las etiquetas de parte del habla para los términos que aparecen en las noticias. Los tipos de entidad nombrados incluyen el nombre de la persona, el nombre de la organización, el nombre de la ubicación, la fecha, la hora, el dinero y el porcentaje, y los cinco POSS se seleccionan: Ninguno (NN), verbo (VB), Adjetivo (JJ), Adverb (RB) y número cardinal (CD). El análisis estadístico muestra tipos de términos discriminativos a nivel de tema para diferentes clases de historias. En aras de la conveniencia, las etiquetas de tipo de entidad nombradas y las etiquetas de parte del discurso se llaman uniformemente el tipo de término en secciones posteriores. Determinar si dos historias son sobre el mismo tema es un componente básico para la tarea NED. Entonces, al principio usamos 2 χ estadísticos para calcular las correlaciones entre términos y temas. Para un término t y un tema t, se deriva una tabla de contingencia: Tabla 1. Un número de documento de la tabla de contingencia 2 × 2 pertenece al tema t no pertenece al tema t incluido t a b no incluye t c d la estadística 2 χ para un término t específico con respecto al tema t se define como [16]: 2 2 (,,) () * () () * () * () * () W T A B C D AD CB A C B D A B C D χ = + + + - + + + + (9) Los temas de noticias para la tarea TDT se clasifican aún más en 11 reglas de interpretaciones (Rois) 2. El ROI puede verse como una clase de historias de nivel superior. La correlación promedio entre un tipo de término y un ROI de tema se calcula como: 2 avg 2 (,) ((,)) k m m km kt r w p w tp r p w t r p χ χ ∈ ∈ ∑ ∑ （,） = 1 K K= 1 ... k, m = 1 ... m (10) donde k es el número de tipos de términos (establecido 12 constantemente en el documento). M es el número de clases de noticias (ROI, establecidas 11 en el periódico). PK representa el conjunto de todos los términos de tipo K, y RM representa el conjunto de todos los temas de la clase M, P (t, t) significa la probabilidad de que T ocurra en el tema T. debido a la limitación del espacio, solo partes del términoLos tipos (9 tipos de términos) y las partes de las clases de noticias (8 clases) se enumeran en la Tabla 2 con los valores de correlación promedio entre ellos. Las estadísticas se derivan de datos etiquetados en el corpus TDT2.(Los resultados en la Tabla 2 ya están normalizados por conveniencia en comparación). Las estadísticas en la Tabla 2 indican la utilidad de los diferentes tipos de términos en la discriminación de temas con respecto a diferentes clases de noticias. Podemos ver que el nombre de la ubicación es el tipo de término más útil para tres clases de noticias: desastres naturales, violencia o guerra, finanzas. Y para otras tres categorías, las elecciones, casos legales/penales, ciencia y descubrimiento, el nombre de la persona es el tipo de término más discriminativo. Para escándalos/audiencias, la fecha es la información más importante para la discriminación de temas. Además, los casos legales/penales y los temas financieros tienen una mayor correlación con los términos del dinero, mientras que la ciencia y el descubrimiento tienen una correlación más alta con términos porcentuales. Los términos no nombrados son más estables para diferentes clases.1.http://opennlp.sourceforge.net/ 2.http://projects.ldc.upenn.edu/tdt3/guide/label.html Del análisis de la Tabla 2, es razonable ajustar el peso del término de acuerdo con su tipo de término y la clase de noticias a la que pertenece la historia. El nuevo término los pesos se vuelven a ver de la siguiente manera: () () () () (,,) * (,) (,,) * Clase D D Type W T Clase D D Tipo W W W W W W W W W W PESO D T W PESO D T W α α ∈= ∑ (11) donde el tipo (W) representa el tipo de término W, y la clase (d) representa la clase de la historia D, C Kα es el parámetro de re -peso para la clase de noticias C y el tipo de término K.En el trabajo, simplemente usamos estadísticas en la Tabla 2 como parámetros de re -peso. Incluso el pensamiento utilizando las estadísticas directamente puede no ser la mejor opción, no discutimos cómo obtener automáticamente los mejores parámetros. Intentaremos usar técnicas de aprendizaje automático para obtener los mejores parámetros en el trabajo futuro. En el trabajo, utilizamos Boostexter [20] para clasificar todas las historias en uno de los 11 ROI. Boostexter es un programa de aprendizaje automático basado en el aumento, que crea una serie de reglas simples para construir un clasificador para datos de texto o valores de atributos. Utilizamos el peso a término generado utilizando el modelo TF-IDF como función para la clasificación de la historia. Entrenamos al modelo en las 12000 historias de inglés juzgadas en TDT2, y clasificamos el resto de las historias en TDT2 y todas las historias en TDT3. Los resultados de la clasificación se utilizan para el peso de término en la fórmula (11). Dado que las etiquetas de clase de las historias de temas no se dan en los conjuntos de datos TDT, no podemos dar la precisión de la clasificación aquí. Por lo tanto, no discutimos los efectos de la precisión de clasificación al rendimiento de NED en el documento.6. Configuración experimental 6.1 conjuntos de datos utilizamos dos conjuntos de datos LDC [18] TDT2 y TDT3 para nuestros experimentos. TDT2 contiene noticias de enero a junio de 1998. Contiene alrededor de 54,000 historias de fuentes como ABC, Associated Press, CNN, New York Times, Public Radio International, Voice of America, etc. Solo se consideraron historias inglesas en la colección. TDT3 contiene aproximadamente 31,000 historias de inglés recopiladas de octubre a diciembre de 1998. Además de las fuentes utilizadas en TDT2, también contiene historias de transmisiones de TV NBC y MSNBC. Utilizamos versiones transcritas de las transmisiones de televisión y radio además de noticias textuales. El conjunto de datos TDT2 está etiquetado con aproximadamente 100 temas, y aproximadamente 12,000 historias de inglés pertenecen a al menos uno de estos temas. El conjunto de datos TDT3 está etiquetado con aproximadamente 120 temas, y aproximadamente 8000 historias en inglés pertenecen a al menos uno de estos temas. Todos los temas se clasifican en 11 reglas de interpretación: (1) elecciones, (2) escándalos/audiencias, (3) casos legales/penales, (4) desastres naturales, (5) accidentes, (6) violencia o guerra en curso,(7) Noticias de ciencia y descubrimiento, (8) Finanzas, (9) Nueva ley, (10) Noticias deportivas, (11) Misc. Noticias.6.2 Metric de evaluación TDT utiliza un CDET de la función de costo que combina las probabilidades de perder una nueva historia y una falsa alarma [19]: * * * * * Det Miss Miss Target Fa fa Nontargetc C P P P P P = + (12) Tabla 2. Correlación promedio entre los tipos de términos y las clases de noticias donde CMISS significa el costo de perder una nueva historia, PMISS significa la probabilidad de perder una nueva historia y PTARGET significa la probabilidad de ver una nueva historia en los datos;CFA significa el costo de una falsa alarma, PFA significa la probabilidad de una falsa alarma y PnonTarget significa la probabilidad de ver una historia antigua. El Costo CDET se normaliza de tal manera que un sistema perfecto obtiene 0 y un sistema trivial, que es el mejor de Mark todas las historias como nuevas o antiguas, puntajes 1: (( *, *)) det Det Det Miss Target Fa NonTarget C Norm C N Norm CMin C P C P = (13) El nuevo sistema de detección de eventos ofrece dos salidas para cada historia. La primera parte es sí o no indicar si la historia desencadena un nuevo evento o no. La segunda parte es un puntaje que indica la confianza de la primera decisión. Los puntajes de confianza se pueden usar para trazar la curva Det, es decir, curvas que trazan falsas alarmas versus probabilidades de falla. Se puede determinar un costo mínimo normalizado si se eligió un umbral óptimo en la puntuación.7. Resultados experimentales 7.1 Resultados principales Para probar los enfoques propuestos en el modelo, implementamos y probamos cinco sistemas: System-1: este sistema se usa como línea de base. Se implementa en función del modelo básico descrito en la Sección 3, es decir, utilizando el modelo TF-IDF incremental para generar pesos de términos y usar la distancia de Hellinger para calcular la similitud del documento. La normalización de la puntuación de similitud también se emplea [8]. Se utiliza el procedimiento de detección S-S. Sistema-2: Este sistema es el mismo que el System-1, excepto que se utiliza el procedimiento de detección S-C. Sistema-3: Este sistema es el mismo que el System-1, excepto que utiliza el nuevo procedimiento de detección que se basa en el árbol de indexación. Sistema-4: Implementado basado en el enfoque presentado en la Sección 5.1, es decir, los términos se vuelven a ver de acuerdo con la distancia entre las distribuciones de términos en un clúster y todas las historias. Se utiliza el nuevo procedimiento de detección. Sistema-5: Implementado basado en el enfoque presentado en la Sección 5.2, es decir, los términos de diferentes tipos se vuelven a ver de acuerdo con la clase de noticias utilizando parámetros capacitados. Se utiliza el nuevo procedimiento de detección. Los siguientes son otros sistemas NED: System-6: [21] Para cada par de historias, calcula tres valores de similitud para entidad nombrada, entidad no nombrada y todos los términos respectivamente. Y emplee la máquina de vectores de soporte para predecir la nueva o antigua utilizando los valores de similitud como características. System-7: [8] Extendió un modelo básico de TF-IDF incremental para incluir modelos específicos de fuente, normalización de puntaje de similitud basada en promedios específicos de documentos, normalización de puntaje de similitud basada en promedios específicos de pares de origen, etc. Sistema-8: [13] Distiró la representación del documento en dos partes: entidades nombradas y entidades no nombradas, y elija una parte efectiva para cada clase de noticias. La Tabla 3 y la Tabla 4 muestran costos normalizados ponderados por el tema y comparación de tiempos en conjuntos de datos TDT2 y TDT3, respectivamente. Dado que no había un conjunto de datos retenidos para ajustar el umbral θ nuevo estaba disponible para experimentos en TDT2, solo informamos costos normalizados mínimos para nuestros sistemas en la Tabla 3. El sistema-5 supera a todos los demás sistemas, incluido el System-6, y realiza solo 2.78E+8 de comparación de tiempos en el procedimiento de detección que es solo el 13.4% del sistema-1. Tabla 3. Resultados de NED en los sistemas TDT2 Min Norma (CDET) CMP Times System-1 0.5749 2.08E+9 Sistema-2① 0.6673 3.77e+8 Sistema-3② 0.5765 2.81E+8 Sistema-4② 0.5431 2.99e+8 Sistema-5② 0.5089 2.78E 2.78E+8 Sistema -6 0.5300 -① θ nuevo = 0.13 ② θ init = 0.13, λ = 3, Δ = 0.15 Al evaluar los costos normalizados en TDT3, utilizamos los umbrales óptimos obtenidos del conjunto de datos TDT2 para todos los sistemas. El sistema-2 reduce los tiempos de comparación a 1.29E+9, que es solo el 18.3% del sistema-1, pero al mismo tiempo también obtiene un costo mínimo normalizado deteriorado que es 0.0499 más alto que el sistema-1. System-3 utiliza el nuevo procedimiento de detección basado en el árbol de indexación de noticias. Requiere aún menos tiempos de comparación que el sistema-2. Esto se debe a que las comparaciones de la historia de la historia generalmente producen mayores similitudes que las de la historia de la historia, por lo que las historias tienden a ser combinadas de ubicación de la persona Fecha de la organización porcentual porcentaje NN JJ CD Elecciones 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 Escandals/audiencias 0.66 0.62 0.28 1 0.111110.02 0.27 0.13 0.05 casos legales/penales 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 desastres naturales 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 Violencia o guerra 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 ciencia y descubrimiento0.08 0.03 finanzas 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 deportes 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 juntos en el sistema-3. Y System-3 es básicamente equivalente a System-1 en resultados de precisión. El sistema-4 ajusta los pesos de términos en función de la distancia de las distribuciones de términos entre todo el conjunto de historias de corpus y clúster, lo que produce una buena mejora en 0.0468 en comparación con el sistema-1. El mejor sistema (System-5) tiene un costo mínimo normalizado 0.5012, que es 0.0797 mejor que System-1, y también mejor que cualquier otro resultado informado previamente para este conjunto de datos [8, 13]. Además, el sistema-5 solo necesita 1.05E+8 tiempos de comparación que son el 14.9% del sistema-1. Tabla 4. Resultados de NED en la norma de sistemas TDT3 (CDET) Min Norm (CDET) CMP Times System-1 0.6159 0.5809 7.04e+8 Sistema-2① 0.6493 0.6308 1.29E+8 Sistema-3② 0.6197 0.5868 1.03e+8 Sistema-4② 0.5601 0.5341 1.03e+8 Sistema-5② 0.5413 0.5012 1.05e+8 Sistema-7-0.5783 -System-8-0.5229 -① θ nuevo = 0.13 ② θ init = 0.13, λ = 3, Δ = 0.15 Figura 5 muestra las cinco curvas para detects para las curvas paraNuestros sistemas en el conjunto de datos TDT3. El sistema 5 logra el costo mínimo a una tasa de alarma falsa de 0.0157 y una tasa de fallas de 0.4310. Podemos observar que System4 y System-5 obtienen una menor probabilidad de Miss en regiones de probabilidades de baja alarma falsa. La hipótesis es que, más valor de peso se transfiere a términos clave de temas de términos no clave. El puntaje de similitud entre dos historias que pertenecen a diferentes temas son más bajos que antes, porque sus términos superpuestos generalmente no son términos clave de sus temas.7.2 Selección de parámetros para la detección del árbol de indexación La Figura 3 muestra los costos mínimos normalizados obtenidos por System-3 en TDT3 utilizando diferentes parámetros. El parámetro Init θ se prueba en seis valores que abarcan de 0.03 a 0.18. Y el parámetro λ se prueba en cuatro valores 1, 2, 3 y 4. Podemos ver que, cuando dθ init se establece en 0.12, que es el más cercano a dar nuevo, los costos son más bajos que otros. Esto es fácil de explicar, porque cuando las historias que pertenecen al mismo tema se colocan en un clúster, es más razonable que el clúster represente las historias en él. Cuando el parámetro λ se establece en 3 o 4, los costos son mejores que otros casos, pero no hay mucha diferencia entre 3 y 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ Mincost 0.6 0.65 0.650.7 0.75 0.8 0.85 0.9 Figura 3. Costo mínimo en TDT3 (Δ = 0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ comparando tiempos 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 Figura 4. Comparar tiempos en TDT3 (Δ = 0.15) La Figura 4 proporciona los tiempos de comparación utilizados por System-3 en TDT3 con los mismos parámetros que la Figura 3. Los tiempos de comparación dependen fuertemente de INIT. Debido a que el Init Greaterθ es, cuanto menos historias combinadas juntas, se necesitan más tiempos de comparación para la decisión de nuevos eventos. Entonces usamos θ init = 0.13, λ = 3, δ = 0.15 para el sistema-3, 4 y 5. En esta configuración de parámetros, podemos obtener bajos costos mínimos normalizados y menos tiempos de comparación.8. Conclusión Hemos propuesto un procedimiento de detección basado en el árbol de indexación de noticias en nuestro modelo. Reduce los tiempos de comparación con aproximadamente un séptimo método tradicional sin dañar la precisión de NED. También hemos presentado dos extensiones al modelo BASIC TF-IDF. La primera extensión se realiza mediante pesos de término ajustados en función de las distribuciones de términos entre todo el corpus y un conjunto de historias de clúster. Y la segunda extensión al modelo BASIC TF-IDF es el mejor uso de los tipos de términos (tipos de entidades nombrados y parte de la velocidad) de acuerdo con las categorías de noticias. Nuestros resultados experimentales en los conjuntos de datos TDT2 y TDT3 muestran que ambas extensiones contribuyen significativamente a la mejora en la precisión. No consideramos la información del tiempo de noticias como una pista para la tarea NED, ya que la mayoría de los temas duran mucho tiempo y los conjuntos de datos TDT solo se extienden durante un período relativo (no más de 6 meses). Para el trabajo futuro, queremos recopilar un conjunto de noticias que se extiendan por un período más largo de Internet e integrar la información de tiempo en la tarea NED. Dado que el tema es un clúster de noticias relativo de grano grueso, también queremos refinar la granularidad del clúster al nivel de eventos e identificar diferentes eventos y sus relaciones dentro de un tema. Agradecimientos Este trabajo es apoyado por la Fundación Nacional de Ciencias Naturales de China bajo la subvención No. 90604025. Cualquier opinión, hallazgos y conclusiones o recomendaciones expresadas en este material son los autores y no reflejan necesariamente las del patrocinador.9. Referencias [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] En la detección y seguimiento de temas. Organización de información basada en eventos. Kluwer Academic Publishers, 2002.Curva ponderada Sistema1 Min Norma (Costo) Sistema2 Tema Curva ponderada Sistema2 Norma min Norma (Costo) Sistema de tema Curva ponderada Sistema3 Min Norma (Costo) Sistema4 Tema Curva ponderada Sistema4 Min Norma (Costo) Sistema 5 Curva ponderada Sistema 5 Min Norma (Costo) Rendimiento aleatorio) ¡Rendimiento aleatorio) AleatorioFigura 5. Det curvas en TDT3 [3] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B.T. Archibald y X. Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En IEEE Intelligent Systems, número especial sobre aplicaciones de recuperación de información inteligente, Volumen 14 (4), 1999, 32-43.[4] Y. Yang, T. Pierce y J. Carbonell. Un estudio sobre detección de eventos retrospectivos y en línea. En Actas de Sigir-98, Melbourne, Australia, 1998, 28-36.[5] J. Allan, V. Lavrenko, D. Malin y R. Swan. Detecciones, límites y plazos: UMass y TDT-3. En Actas del Taller de detección y seguimiento de temas (TDT-3), Viena, VA, 2000, 167-174.[6] R. Papka y J. Allan. Detección de eventos en línea en línea con Título de la agrupación de un solo pase2:. Informe técnico UM-CS1998-021, 1998. [7] W. Lam, H. Meng, K. Wong y J. Yen. Uso del análisis contextual para la detección de eventos de noticias. Revista Internacional sobre Sistemas Inteligentes, 2001, 525-546.[8] B. Thorsten, C. Francine y F. Ayman. Un sistema para la nueva detección de eventos. En Actas de la 26ª Conferencia Internacional ACM Sigir de ACM, Nueva York, NY, EE. UU. ACM Press.2003, 330-337.[9] S. Nicola y C. Joe. Combinando clasificadores de documentos semánticos y sintácticos para mejorar la detección de la primera historia. En Actas de la 24ª Conferencia Internacional ACM Sigir anual, Nueva York, NY, EE. UU. ACM Press.2001, 424425. [10] Y. Yang, J. Zhang, J. Carbonell y C. Jin. Detección de novedad acondicionada con temas. En Actas de la 8ª Conferencia Internacional SIGKDD ACM, ACM Press.2002, 688-693.[11] M. Juha, A.M.Helena y S. Marko. Aplicación de clases semánticas en detección y seguimiento de eventos. En Actas de la Conferencia Internacional sobre Procesamiento del Lenguaje Natural (Icon 2002), 2002, páginas 175-183.[12] M. Juha, A.M.Helena y S. Marko. Semántica simple en la detección y seguimiento de temas. Recuperación de información, 7 (3-4): 2004, 347-368.[13] K. Giridhar y J. Allan. Clasificación de texto y entidades nombradas para la nueva detección de eventos. En Actas de la 27ª Conferencia Internacional ACM Sigir, Nueva York, NY, EE. UU. ACM Press.2004, 297-304.[14] J. P. Callan, W. B. Croft y S. M. Harding. El sistema de recuperación de la investigación. En Actas de Dexa-92, tercera conferencia internacional sobre bases de datos y aplicaciones de sistemas expertos, 1992, 78-83.[15] R. Krovetz. Ver la morfología como un proceso de inferencia. En Actas de ACM Sigir93, 1993, 61-81.[16] Y. Yang y J. Pedersen. Un estudio comparativo sobre la selección de características en la categorización de texto. En J. D. H. Fisher, Editor, La Decimocuarta Conferencia Internacional sobre Aprendizaje Autor (ICML97), Morgan Kaufmann, 1997, 412-420.[17] T. M. Cover y J.A. Thomas. Elementos de la teoría de la información. Wiley.1991. [18] El consorcio de datos lingüísticos, http: //www.ldc,upenn.edu/.[19] El plan de evaluación y definición de tareas TDT 2001, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm.[20] R. E. Schapire e Y. Cantante. BoostExter: un sistema basado en el refuerzo para la categorización de texto. En el aprendizaje automático 39 (2/3): 1, Kluwer Academic Publishers, 2000, 35-168.[21] K. Giridhar y J. Allan.2005. Uso de nombres y temas para la nueva detección de eventos. En Actas de la Conferencia de Tecnología Humana y Conferencia sobre Métodos Empíricos en Lenguaje Natural, Vancouver, 2005, 121-128",
    "original_sentences": [
        "New Event Detection Based on Indexing-tree and Named Entity Zhang Kuo Tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn Li Juan Zi Tsinghua University Beijing, 100084, China 86-10-62781461 ljz@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn ABSTRACT New Event Detection (NED) aims at detecting from one or multiple streams of news stories that which one is reported on a new event (i.e.",
        "not reported previously).",
        "With the overwhelming volume of news available today, there is an increasing need for a NED system which is able to detect new events more efficiently and accurately.",
        "In this paper we propose a new NED model to speed up the NED task by using news indexing-tree dynamically.",
        "Moreover, based on the observation that terms of different types have different effects for NED task, two term reweighting approaches are proposed to improve NED accuracy.",
        "In the first approach, we propose to adjust term weights dynamically based on previous story clusters and in the second approach, we propose to employ statistics on training data to learn the named entity reweighting model for each class of stories.",
        "Experimental results on two Linguistic Data Consortium (LDC) datasets TDT2 and TDT3 show that the proposed model can improve both efficiency and accuracy of NED task significantly, compared to the baseline system and other existing systems.",
        "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Search and Retrieval; H.4.2 [Information Systems Applications]: Types of Systemsdecision support.",
        "General Terms Algorithms, Performance, Experimentation 1.",
        "INTRODUCTION Topic Detection and Tracking (TDT) program aims to develop techniques which can effectively organize, search and structure news text materials from a variety of newswire and broadcast media [1].",
        "New Event Detection (NED) is one of the five tasks in TDT.",
        "It is the task of online identification of the earliest report for each topic as soon as that report arrives in the sequence of documents.",
        "A Topic is defined as a seminal event or activity, along with directly related events and activities [2].",
        "An Event is defined as something (non-trivial) happening in a certain place at a certain time [3].",
        "For instance, when a bomb explodes in a building, the exploding is the seminal event that triggers the topic, and other stories on the same topic would be those discussing salvaging efforts, the search for perpetrators, arrests and trial and so on.",
        "Useful news information is usually buried in a mass of data generated everyday.",
        "Therefore, NED systems are very useful for people who need to detect novel information from real-time news stream.",
        "These real-life needs often occur in domains like financial markets, news analysis, and intelligence gathering.",
        "In most of state-of-the-art (currently) NED systems, each news story on hand is compared to all the previous received stories.",
        "If all the similarities between them do not exceed a threshold, then the story triggers a new event.",
        "They are usually in the form of cosine similarity or Hellinger similarity metric.",
        "The core problem of NED is to identify whether two stories are on the same topic.",
        "Obviously, these systems cannot take advantage of topic information.",
        "Further more, it is not acceptable in real applications because of the large amount of computation required in the NED process.",
        "Other systems organize previous stories into clusters (each cluster corresponds to a topic), and new story is compared to the previous clusters instead of stories.",
        "This manner can reduce comparing times significantly.",
        "Nevertheless, it has been proved that this manner is less accurate [4, 5].",
        "This is because sometimes stories within a topic drift far away from each other, which could lead low similarity between a story and its topic.",
        "On the other hand, some proposed NED systems tried to improve accuracy by making better use of named entities [10, 11, 12, 13].",
        "However, none of the systems have considered that terms of different types (e.g.",
        "Noun, Verb or Person name) have different effects for different classes of stories in determining whether two stories are on the same topic.",
        "For example, the names of election candidates (Person name) are very important for stories of election class; the locations (Location name) where accidents happened are important for stories of accidents class.",
        "So, in NED, there still exist following three problems to be investigated: (1) How to speed up the detection procedure while do not decrease the detection accuracy? (2) How to make good use of cluster (topic) information to improve accuracy? (3) How to obtain better news story representation by better understanding of named entities.",
        "Driven by these problems, we have proposed three approaches in this paper. (1)To make the detection procedure faster, we propose a new NED procedure based on news indexing-tree created dynamically.",
        "Story indexing-tree is created by assembling similar stories together to form news clusters in different hierarchies according to their values of similarity.",
        "Comparisons between current story and previous clusters could help find the most similar story in less comparing times.",
        "The new procedure can reduce the amount of comparing times without hurting accuracy. (2)We use the clusters of the first floor in the indexing-tree as news topics, in which term weights are adjusted dynamically according to term distribution in the clusters.",
        "In this approach, cluster (topic) information is used properly, so the problem of theme decentralization is avoided. (3)Based on observations on the statistics obtained from training data, we found that terms of different types (e.g.",
        "Noun and Verb) have different effects for different classes of stories in determining whether two stories are on the same topic.",
        "And we propose to use statistics to optimize the weights of the terms of different types in a story according to the news class that the story belongs to.",
        "On TDT3 dataset, the new NED model just uses 14.9% comparing times of the basic model, while its minimum normalized cost is 0.5012, which is 0.0797 better than the basic model, and also better than any other results previously reported for this dataset [8, 13].",
        "The rest of the paper is organized as follows.",
        "We start off this paper by summarizing the previous work in NED in section 2.",
        "Section 3 presents the basic model for NED that most current systems use.",
        "Section 4 describes our new detection procedure based on news indexing-tree.",
        "In section 5, two term reweighting methods are proposed to improve NED accuracy.",
        "Section 6 gives our experimental data and evaluation metrics.",
        "We finally wrap up with the experimental results in Section 7, and the conclusions and future work in Section 8. 2.",
        "RELATED WORK Papka et al. proposed Single-Pass clustering on NED [6].",
        "When a new story was encountered, it was processed immediately to extract term features and a query representation of the storys content is built up.",
        "Then it was compared with all the previous queries.",
        "If the document did not trigger any queries by exceeding a threshold, it was marked as a new event.",
        "Lam et al build up previous query representations of story clusters, each of which corresponds to a topic [7].",
        "In this manner comparisons happen between stories and clusters.",
        "Recent years, most work focus on proposing better methods on comparison of stories and document representation.",
        "Brants et al. [8] extended a basic incremental TF-IDF model to include sourcespecific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, term reweighting based on inverse event frequencies, and segmentation of documents.",
        "Good improvements on TDT bench-marks were shown.",
        "Stokes et al. [9] utilized a combination of evidence from two distinct representations of a documents content.",
        "One of the representations was the usual free text vector, the other made use of lexical chains (created using WordNet) to build another term vector.",
        "Then the two representations are combined in a linear fashion.",
        "A marginal increase in effectiveness was achieved when the combined representation was used.",
        "Some efforts have been done on how to utilize named entities to improve NED.",
        "Yang et al. gave location named entities four times weight than other terms and named entities [10].",
        "DOREMI research group combined semantic similarities of person names, location names and time together with textual similarity [11][12].",
        "UMass [13] research group split document representation into two parts: named entities and non-named entities.",
        "And it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation.",
        "Both [10] and [13] used text categorization technique to classify news stories in advance.",
        "In [13] news stories are classified automatically at first, and then test sensitivities of names and non-name terms for NED for each class.",
        "In [10] frequent terms for each class are removed from document representation.",
        "For example, word election does not help identify different elections.",
        "In their work, effectiveness of different kinds of names (or terms with different POS) for NED in different news classes are not investigated.",
        "We use statistical analysis to reveal the fact and use it to improve NED performance. 3.",
        "BASIC MODEL In this section, we present the basic New Event Detection model which is similar to what most current systems apply.",
        "Then, we propose our new model by extending the basic model.",
        "New Event Detection systems use news story stream as input, in which stories are strictly time-ordered.",
        "Only previously received stories are available when dealing with current story.",
        "The output is a decision for whether the current story is on a new event or not and the confidence of the decision.",
        "Usually, a NED model consists of three parts: story representation, similarity calculation and detection procedure. 3.1 Story Representation Preprocessing is needed before generating story representation.",
        "For preprocessing, we tokenize words, recognize abbreviations, normalize abbreviations, add part-of-speech tags, remove stopwords included in the stop list used in InQuery [14], replace words with their stems using K-stem algorithm[15], and then generate word vector for each news story.",
        "We use incremental TF-IDF model for term weight calculation [4].",
        "In a TF-IDF model, term frequency in a news document is weighted by the inverse document frequency, which is generated from training corpus.",
        "When a new term occurs in testing process, there are two solutions: simply ignore the new term or set df of the term as a small const (e.g. df = 1).",
        "The new term receives too low weight in the first solution (0) and too high weight in the second solution.",
        "In incremental TF-IDF model, document frequencies are updated dynamically in each time step t: 1( ) ( ) ( )t t D tdf w df w df w−= + (1) where Dt represents news story set received in time t, and dfDt(w) means the number of documents that term w occurs in, and dft(w) means the total number of documents that term w occurs in before time t. In this work, each time window includes 50 news stories.",
        "Thus, each story d received in t is represented as follows: 1 2{ ( , , ), ( , , ),..., ( , , )}nd weight d t w weight d t w weight d t w→ where n means the number of distinct terms in story d, and ( , , )weight d t w means the weight of term w in story d at time t: log( ( , ) 1) log(( 1) /( ( ) 0.5)) ( , , ) log( ( , ) 1) log(( 1) /( ( ) 0.5)) t t t t w d tf d w N df w weight d t w tf d w N df w ∈ + + + = + + +∑ (2) where Nt means the total number of news stories before time t, and tf(d,w) means how many times term w occurs in news story d. 3.2 Similarity Calculation We use Hellinger distance for the calculation of similarity between two stories, for two stories d and d at time t, their similarity is defined as follows: , ( , , ) ( , , ) * ( , , ) w d d sim d d t weight d t w weight d t w ∈ = ∑ (3) 3.3 Detection Procedure For each story d received in time step t, the value ( ) ( ) ( ) ( ( , , )) time d time d n d max sim d d t < = (4) is a score used to determine whether d is a story about a new topic and at the same time is an indication of the confidence in our decision [8]. time(d) means the publication time of story d. If the score exceeds the thresholdθ new, then there exists a sufficiently similar document, thus d is a old story, otherwise, there is no sufficiently similar previous document, thus d is an new story. 4.",
        "New NED Procedure Traditional NED systems can be classified into two main types on the aspect of detection procedure: (1) S-S type, in which the story on hand is compared to each story received previously, and use the highest similarity to determine whether current story is about a new event; (2) S-C type, in which the story on hand is compared to all previous clusters each of which representing a topic, and the highest similarity is used for final decision for current story.",
        "If the highest similarity exceeds thresholdθ new, then it is an old story, and put it into the most similar cluster; otherwise it is a new story and create a new cluster.",
        "Previous work show that the first manner is more accurate than the second one [4][5].",
        "Since sometimes stories within a topic drift far away from each other, a story may have very low similarity with its topic.",
        "So using similarities between stories for determining new story is better than using similarities between story and clusters.",
        "Nevertheless, the first manner needs much more comparing times which means the first manner is low efficient.",
        "We propose a new detection procedure which uses comparisons with previous clusters to help find the most similar story in less comparing times, and the final new event decision is made according to the most similar story.",
        "Therefore, we can get both the accuracy of S-S type methods and the efficiency of S-C type methods.",
        "The new procedure creates a news indexing-tree dynamically, in which similar stories are put together to form a hierarchy of clusters.",
        "We index similar stories together by their common ancestor (a cluster node).",
        "Dissimilar stories are indexed in different clusters.",
        "When a story is coming, we use comparisons between the current story and previous hierarchical clusters to help find the most similar story which is useful for new event decision.",
        "After the new event decision is made, the current story is inserted to the indexing-tree for the following detection.",
        "The news indexing-tree is defined formally as follows: S-Tree = {r, NC , NS , E} where r is the root of S-Tree, NC is the set of all cluster nodes, NS is the set of all story nodes, and E is the set of all edges in S-Tree.",
        "We define a set of constraints for a S-Tree: ⅰ . , is an non-terminal node in the treeC i i N i∀ ∈ → ⅱ . , is a terminal node in the treeS i i N i∀ ∈ → ⅲ . , out degree of is at least 2C i i N i∀ ∈ → ⅳ . , is represented as the centroid of its desendantsC i i iN∀ ∈ → For a news story di, the comparison procedure and inserting procedure based on indexing-tree are defined as follows.",
        "An example is shown by Figure 1 and Figure 2.",
        "Figure 1.",
        "Comparison procedure Figure 2.",
        "Inserting procedure Comparison procedure: Step 1: compare di to all the direct child nodes of r and select λ nodes with highest similarities, e.g., C1 2 and C1 3 in Figure 1.",
        "Step 2: for each selected node in the last step, e.g.",
        "C1 2, compare di to all its direct child nodes, and select λ nodes with highest similarities, e.g.",
        "C2 2 and d8.",
        "Repeat step 2 for all non-terminal nodes.",
        "Step 3: record the terminal node with the highest similarty to di, e.g. s5, and the similarity value (0.20).",
        "Inserting di to the S-tree with r as root: Find the node n which is direct child of r in the path from r to the terminal node with highest similarity s, e.g.",
        "C1 2.",
        "If s is smaller than θ init+(h-1)δ , then add di to the tree as a direct child of r. Otherwise, if n is a terminal node, then create a cluster node instead of n, and add both n and di as its direct children; if n is an non-terminal node, then repeat this procedure and insert di to the sub-tree with n as root recursively.",
        "Here h is the length between n and the root of S-tree.",
        "The more the stories in a cluster similar to each other, the better the cluster represents the stories in it.",
        "Hence we add no constraints on the maximum of trees height and degree of a node.",
        "Therefore, we cannot give the complexity of this indexing-tree based procedure.",
        "But we will give the number of comparing times needed by the new procedure in our experiments in section7. 5.",
        "Term Reweighting Methods In this section, two term reweighting methods are proposed to improve NED accuracy.",
        "In the first method, a new way is explored for better using of cluster (topic) information.",
        "The second one finds a better way to make use of named entities based on news classification. 5.1 Term Reweighting Based on Distribution Distance TF-IDF is the most prevalent model used in information retrieval systems.",
        "The basic idea is that the fewer documents a term appears in, the more important the term is in discrimination of documents (relevant or not relevant to a query containing the term).",
        "Nevertheless, in TDT domain, we need to discriminate documents with regard to topics rather than queries.",
        "Intuitively, using cluster (topic) vectors to compare with subsequent news stories should outperform using story vectors.",
        "Unfortunately, the experimental results do not support this intuition [4][5].",
        "Based on observation on data, we find the reason is that a news topic usually contains many directly or indirectly related events, while they all have their own sub-subjects which are usually different with each other.",
        "Take the topic described in section 1 as an example, events like the explosion and salvage have very low similarities with events about criminal trial, therefore stories about trial would have low similarity with the topic vector built on its previous events.",
        "This section focuses on how to effectively make use of topic information and at the same time avoid the problem of content decentralization.",
        "At first, we classify terms into 5 classes to help analysis the needs of the modified model: Term class A: terms that occur frequently in the whole corpus, e.g., year and people.",
        "Terms of this class should be given low weights because they do not help much for topic discrimination.",
        "Term class B: terms that occur frequently within a news category, e.g., election, storm.",
        "They are useful to distinguish two stories in different news categories.",
        "However, they cannot provide information to determine whether two stories are on the same or different topics.",
        "In another words, term election and term storm are not helpful in differentiate two election campaigns and two storm disasters.",
        "Therefore, terms of this class should be assigned lower weights.",
        "Term class C: terms that occur frequently in a topic, and infrequently in other topics, e.g., the name of a crash plane, the name of a specific hurricane.",
        "News stories that belong to different topics rarely have overlap terms in this class.",
        "The more frequently a term appears in a topic, the more important the term is for a story belonging to the topic, therefore the term should be set higher weight.",
        "Term class D: terms that appear in a topic exclusively, but not frequently.",
        "For example, the name of a fireman who did very well in a salvage action, which may appears in only two or three stories but never appeared in other topics.",
        "Terms of this type should receive more weights than in TF-IDF model.",
        "However, since they are not popular in the topic, it is not appropriate to give them too high weights.",
        "Term class E: terms with low document frequency, and appear in different topics.",
        "Terms of this class should receive lower weights.",
        "Now we analyze whether TF-IDF model can give proper weights to the five classes of terms.",
        "Obviously, terms of class A are lowly weighted in TF-IDF model, which is conformable with the requirement described above.",
        "In TF-IDF model, terms of class B are highly dependant with the number of stories in a news class.",
        "TF-IDF model cannot provide low weights if the story containing the term belongs to a relative small news class.",
        "For a term of class C, the more frequently it appears in a topic, the less weight TFIDF model gives to it.",
        "This strongly conflicts with the requirement of terms in class C. For terms of class D, TF-IDF model gives them high weights correctly.",
        "But for terms of class E, TF-IDF model gives high weights to them which are not conformable with the requirement of low weights.",
        "To sum up, terms of class B, C, E cannot be properly weighted in TF-IDF model.",
        "So, we propose a modified model to resolve this problem.",
        "When θ init andθ new are set closely, we assume that most of the stories in a first-level cluster (a direct child node of root node) are on the same topic.",
        "Therefore, we make use of a first-level cluster to capture term distribution (df for all the terms within the cluster) within the topic dynamically.",
        "KL divergence of term distribution in a first-level cluster and the whole story set is used to adjust term weights:  ( , , ) * (1 * ( || )) ( , , ) ( , , ) * (1 * ( || )) cw tw cw tw w d D weight d t w KL P P weight d t w weight d t w KL P P γ γ ∈ + = +∑ (5) where ( ) ( ) ( ) ( ) 1,cw cw c c c c df w df w p y p y N N = = − (6) ( ) ( ) ( ) ( ) 1,t t tw tw t t df w df w p y p y N N = = − (7) where dfc(w) is the number of documents containing term w within cluster C, and Nc is the number of documents in cluster C, and Nt is the total number of documents that arrive before time step t. γ is a const parameter, now is manually set 3.",
        "KL divergence is defined as follows [17]: ( ) ( || ) ( ) log ( )x p x KL P Q p x q x = ∑ (8) The basic idea is: for a story in a topic, the more a term occurs within the topic, and the less it occurs in other topics, it should be assigned higher weights.",
        "Obviously, modified model can meet all the requirements of the five term classes listed above. 5.2 Term Reweighting Based on Term Type and Story Class Previous work found that some classes of news stories could achieve good improvements by giving extra weight to named entities.",
        "But we find that terms of different types should be given different amount of extra weight for different classes of news stories.",
        "We use open-NLP1 to recognize named entity types and part-ofspeech tags for terms that appear in news stories.",
        "Named entity types include person name, organization name, location name, date, time, money and percentage, and five POSs are selected: none (NN), verb (VB), adjective (JJ), adverb (RB) and cardinal number (CD).",
        "Statistical analysis shows topic-level discriminative terms types for different classes of stories.",
        "For the sake of convenience, named entity type and part-of-speech tags are uniformly called term type in subsequent sections.",
        "Determining whether two stories are about the same topic is a basic component for NED task.",
        "So at first we use 2 χ statistic to compute correlations between terms and topics.",
        "For a term t and a topic T, a contingence table is derived: Table 1.",
        "A 2×2 Contingence Table Doc Number belong to topic T not belong to topic T include t A B not include t C D The 2 χ statistic for a specific term t with respect to topic T is defined to be [16]: 2 2 ( , ) ( ) * ( ) ( ) * ( ) * ( ) * ( ) w T A B C D AD CB A C B D A B C D χ = + + + − + + + + (9) News topics for the TDT task are further classified into 11 rules of interpretations (ROIs) 2 .",
        "The ROI can be seen as a higher level class of stories.",
        "The average correlation between a term type and a topic ROI is computed as: 2 avg 2 ( , )( ( , ) )k m m km kT R w P w TP R p w T R P χ χ ∈ ∈ ∑ ∑（ , ）= 1 1 k=1…K, m=1…M (10) where K is the number of term types (set 12 constantly in the paper).",
        "M is the number news classes (ROIs, set 11 in the paper).",
        "Pk represents the set of all terms of type k, and Rm represents the set of all topics of class m, p(t,T) means the probability that t occurs in topic T. Because of limitation of space, only parts of the term types (9 term types) and parts of news classes (8 classes) are listed in table 2 with the average correlation values between them.",
        "The statistics is derived from labeled data in TDT2 corpus. (Results in table 2 are already normalized for convenience in comparison.)",
        "The statistics in table 2 indicates the usefulness of different term types in topic discrimination with respect to different news classes.",
        "We can see that, location name is the most useful term type for three news classes: Natural Disasters, Violence or War, Finances.",
        "And for three other categories Elections, Legal/Criminal Cases, Science and Discovery, person name is the most discriminative term type.",
        "For Scandals/Hearings, date is the most important information for topic discrimination.",
        "In addition, Legal/Criminal Cases and Finance topics have higher correlation with money terms, while Science and Discovery have higher correlation with percentage terms.",
        "Non-name terms are more stable for different classes. 1 . http://opennlp.sourceforge.net/ 2 . http://projects.ldc.upenn.edu/TDT3/Guide/label.html From the analysis of table 2, it is reasonable to adjust term weight according to their term type and the news class the story belongs to.",
        "New term weights are reweighted as follows: ( ) ( ) ( ) ( ) ( , , ) * ( , , ) ( , , ) * class d D type w T class d D type w w d weight d t w weight d t w weight d t w α α ∈ = ∑ (11) where type(w) represents the type of term w, and class(d) represents the class of story d, c kα is reweighting parameter for news class c and term type k. In the work, we just simply use statistics in table 2 as the reweighting parameters.",
        "Even thought using the statistics directly may not the best choice, we do not discuss how to automatically obtain the best parameters.",
        "We will try to use machine learning techniques to obtain the best parameters in the future work.",
        "In the work, we use BoosTexter [20] to classify all stories into one of the 11 ROIs.",
        "BoosTexter is a boosting based machine learning program, which creates a series of simple rules for building a classifier for text or attribute-value data.",
        "We use term weight generated using TF-IDF model as feature for story classification.",
        "We trained the model on the 12000 judged English stories in TDT2, and classify the rest of the stories in TDT2 and all stories in TDT3.",
        "Classification results are used for term reweighting in formula (11).",
        "Since the class labels of topic-off stories are not given in TDT datasets, we cannot give the classification accuracy here.",
        "Thus we do not discuss the effects of classification accuracy to NED performance in the paper. 6.",
        "EXPERIMENTAL SETUP 6.1 Datasets We used two LDC [18] datasets TDT2 and TDT3 for our experiments.",
        "TDT2 contains news stories from January to June 1998.",
        "It contains around 54,000 stories from sources like ABC, Associated Press, CNN, New York Times, Public Radio International, Voice of America etc.",
        "Only English stories in the collection were considered.",
        "TDT3 contains approximately 31,000 English stories collected from October to December 1998.",
        "In addition to the sources used in TDT2, it also contains stories from NBC and MSNBC TV broadcasts.",
        "We used transcribed versions of the TV and radio broadcasts besides textual news.",
        "TDT2 dataset is labeled with about 100 topics, and approximately 12,000 English stories belong to at least one of these topics.",
        "TDT3 dataset is labeled with about 120 topics, and approximately 8000 English stories belong to at least one of these topics.",
        "All the topics are classified into 11 Rules of Interpretation: (1)Elections, (2)Scandals/Hearings, (3)Legal/Criminal Cases, (4)Natural Disasters, (5)Accidents, (6)Ongoing Violence or War, (7)Science and Discovery News, (8)Finance, (9)New Law, (10)Sports News, (11)MISC.",
        "News. 6.2 Evaluation Metric TDT uses a cost function CDet that combines the probabilities of missing a new story and a false alarm [19]: * * * *Det Miss Miss Target FA FA NontargetC C P P C P P= + (12) Table 2.",
        "Average correlation between term types and news classes where CMiss means the cost of missing a new story, PMiss means the probability of missing a new story, and PTarget means the probability of seeing a new story in the data; CFA means the cost of a false alarm, PFA means the probability of a false alarm, and PNontarget means the probability of seeing an old story.",
        "The cost CDet is normalized such that a perfect system scores 0 and a trivial system, which is the better one of mark all stories as new or old, scores 1: ( ( * , * ) ) Det Det Miss Target FA Nontarget C Norm C min C P C P = (13) New event detection system gives two outputs for each story.",
        "The first part is yes or no indicating whether the story triggers a new event or not.",
        "The second part is a score indicating confidence of the first decision.",
        "Confidence scores can be used to plot DET curve, i.e., curves that plot false alarm vs. miss probabilities.",
        "Minimum normalized cost can be determined if optimal threshold on the score were chosen. 7.",
        "EXPERIMENTAL RESULTS 7.1 Main Results To test the approaches proposed in the model, we implemented and tested five systems: System-1: this system is used as baseline.",
        "It is implemented based on the basic model described in section 3, i.e., using incremental TF-IDF model to generate term weights, and using Hellinger distance to compute document similarity.",
        "Similarity score normalization is also employed [8].",
        "S-S detection procedure is used.",
        "System-2: this system is the same as system-1 except that S-C detection procedure is used.",
        "System-3: this system is the same as system-1 except that it uses the new detection procedure which is based on indexing-tree.",
        "System-4: implemented based on the approach presented in section 5.1, i.e., terms are reweighted according to the distance between term distributions in a cluster and all stories.",
        "The new detection procedure is used.",
        "System-5: implemented based on the approach presented in section 5.2, i.e., terms of different types are reweighted according to news class using trained parameters.",
        "The new detection procedure is used.",
        "The following are some other NED systems: System-6: [21] for each pair of stories, it computes three similarity values for named entity, non-named entity and all terms respectively.",
        "And employ Support Vector Machine to predict new or old using the similarity values as features.",
        "System-7: [8] it extended a basic incremental TF-IDF model to include source-specific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, etc.",
        "System-8: [13] it split document representation into two parts: named entities and non-named entities, and choose one effective part for each news class.",
        "Table 3 and table 4 show topic-weighted normalized costs and comparing times on TDT2 and TDT3 datasets respectively.",
        "Since no heldout data set for fine-tuning the threshold θ new was available for experiments on TDT2, we only report minimum normalized costs for our systems in table 3.",
        "System-5 outperforms all other systems including system-6, and it performs only 2.78e+8 comparing times in detection procedure which is only 13.4% of system-1.",
        "Table 3.",
        "NED results on TDT2 Systems Min Norm(CDet) Cmp times System-1 0.5749 2.08e+9 System-2① 0.6673 3.77e+8 System-3② 0.5765 2.81e+8 System-4② 0.5431 2.99e+8 System-5② 0.5089 2.78e+8 System-6 0.5300 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 When evaluating on the normalized costs on TDT3, we use the optimal thresholds obtained from TDT2 data set for all systems.",
        "System-2 reduces comparing times to 1.29e+9 which is just 18.3% of system-1, but at the same time it also gets a deteriorated minimum normalized cost which is 0.0499 higher than system-1.",
        "System-3 uses the new detection procedure based on news indexing-tree.",
        "It requires even less comparing times than system-2.",
        "This is because story-story comparisons usually yield greater similarities than story-cluster ones, so stories tend to be combined Location Person Date Organization Money Percentage NN JJ CD Elections 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 Scandals/Hearings 0.66 0.62 0.28 1 0.11 0.02 0.27 0.13 0.05 Legal/Criminal Cases 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 Natural Disasters 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 Violence or War 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 Science and Discovery 0.11 1 0.01 0.22 0.08 0.12 0.19 0.08 0.03 Finances 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 Sports 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 together in system-3.",
        "And system-3 is basically equivalent to system-1 in accuracy results.",
        "System-4 adjusts term weights based on the distance of term distributions between the whole corpus and cluster story set, yielding a good improvement by 0.0468 compared to system-1.",
        "The best system (system-5) has a minimum normalized cost 0.5012, which is 0.0797 better than system-1, and also better than any other results previously reported for this dataset [8, 13].",
        "Further more, system-5 only needs 1.05e+8 comparing times which is 14.9% of system-1.",
        "Table 4.",
        "NED results on TDT3 Systems Norm(CDet) Min Norm(CDet) Cmp times System-1 0.6159 0.5809 7.04e+8 System-2① 0.6493 0.6308 1.29e+8 System-3② 0.6197 0.5868 1.03e+8 System-4② 0.5601 0.5341 1.03e+8 System-5② 0.5413 0.5012 1.05e+8 System-7 -- 0.5783 -System-8 -- 0.5229 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 Figure5 shows the five DET curves for our systems on data set TDT3.",
        "System-5 achieves the minimum cost at a false alarm rate of 0.0157 and a miss rate of 0.4310.",
        "We can observe that System4 and System-5 obtain lower miss probability at regions of low false alarm probabilities.",
        "The hypothesis is that, more weight value is transferred to key terms of topics from non-key terms.",
        "Similarity score between two stories belonging to different topics are lower than before, because their overlapping terms are usually not key terms of their topics. 7.2 Parameter selection for indexing-tree detection Figure 3 shows the minimum normalized costs obtained by system-3 on TDT3 using different parameters.",
        "Theθ init parameter is tested on six values spanning from 0.03 to 0.18.",
        "And the λ parameter is tested on four values 1, 2, 3 and 4.",
        "We can see that, whenθ init is set to 0.12, which is the closest one toθ new, the costs are lower than others.",
        "This is easy to explain, because when stories belonging to the same topic are put in a cluster, it is more reasonable for the cluster to represent the stories in it.",
        "When parameter λ is set to 3 or 4, the costs are better than other cases, but there is no much difference between 3 and 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ MinCost 0.6 0.65 0.7 0.75 0.8 0.85 0.9 Figure 3.",
        "Min Cost on TDT3 (δ =0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ Comparingtimes 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 Figure 4.",
        "Comparing times on TDT3 (δ =0.15) Figure 4 gives the comparing times used by system-3 on TDT3 with the same parameters as figure 3.",
        "The comparing times are strongly dependent onθ init.",
        "Because the greaterθ init is, the less stories combined together, the more comparing times are needed for new event decision.",
        "So we useθ init =0.13,λ =3,δ =0.15 for system-3, 4, and 5.",
        "In this parameter setting, we can get both low minimum normalized costs and less comparing times. 8.",
        "CONCLUSION We have proposed a news indexing-tree based detection procedure in our model.",
        "It reduces comparing times to about one seventh of traditional method without hurting NED accuracy.",
        "We also have presented two extensions to the basic TF-IDF model.",
        "The first extension is made by adjust term weights based on term distributions between the whole corpus and a cluster story set.",
        "And the second extension to basic TF-IDF model is better use of term types (named entities types and part-of-speed) according to news categories.",
        "Our experimental results on TDT2 and TDT3 datasets show that both of the two extensions contribute significantly to improvement in accuracy.",
        "We did not consider news time information as a clue for NED task, since most of the topics last for a long time and TDT data sets only span for a relative short period (no more than 6 months).",
        "For the future work, we want to collect news set which span for a longer period from internet, and integrate time information in NED task.",
        "Since topic is a relative coarse-grained news cluster, we also want to refine cluster granularity to event-level, and identify different events and their relations within a topic.",
        "Acknowledgments This work is supported by the National Natural Science Foundation of China under Grant No. 90604025.",
        "Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsor. 9.",
        "REFERENCES [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] In Topic Detection and Tracking.",
        "Event-based Information Organization.",
        "Kluwer Academic Publishers, 2002. .01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90 1 2 5 10 20 40 60 80 90 False Alarm Probability (in %) MissProbability(in%) SYSTEM1 Topic Weighted Curve SYSTEM1 Min Norm(Cost) SYSTEM2 Topic Weighted Curve SYSTEM2 Min Norm(Cost) SYSTEM3 Topic Weighted Curve SYSTEM3 Min Norm(Cost) SYSTEM4 Topic Weighted Curve SYSTEM4 Min Norm(Cost) SYSTEM5 Topic Weighted Curve SYSTEM5 Min Norm(Cost) Random Performance Figure 5.",
        "DET curves on TDT3 [3] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B.T.",
        "Archibald, and X. Liu.",
        "Learning Approaches for Detecting and Tracking News Events.",
        "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), 1999, 32-43. [4] Y. Yang, T. Pierce, and J. Carbonell.",
        "A Study on Retrospective and On-line Event Detection.",
        "In Proceedings of SIGIR-98, Melbourne, Australia, 1998, 28-36. [5] J. Allan, V. Lavrenko, D. Malin, and R. Swan.",
        "Detections, Bounds, and Timelines: Umass and tdt-3.",
        "In Proceedings of Topic Detection and Tracking Workshop (TDT-3), Vienna, VA, 2000, 167-174. [6] R. Papka and J. Allan.",
        "On-line New Event Detection Using Single Pass Clustering TITLE2:.",
        "Technical Report UM-CS1998-021, 1998. [7] W. Lam, H. Meng, K. Wong, and J.",
        "Yen.",
        "Using Contextual Analysis for News Event Detection.",
        "International Journal on Intelligent Systems, 2001, 525-546. [8] B. Thorsten, C. Francine, and F. Ayman.",
        "A System for New Event Detection.",
        "In Proceedings of the 26th Annual International ACM SIGIR Conference, New York, NY, USA.",
        "ACM Press. 2003, 330-337. [9] S. Nicola and C. Joe.",
        "Combining Semantic and Syntactic Document Classifiers to Improve First Story Detection.",
        "In Proceedings of the 24th Annual International ACM SIGIR Conference, New York, NY, USA.",
        "ACM Press. 2001, 424425. [10] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
        "Topicconditioned Novelty Detection.",
        "In Proceedings of the 8th ACM SIGKDD International Conference, ACM Press. 2002, 688-693. [11] M. Juha, A.M. Helena, and S. Marko.",
        "Applying Semantic Classes in Event Detection and Tracking.",
        "In Proceedings of International Conference on Natural Language Processing (ICON 2002), 2002, pages 175-183. [12] M. Juha, A.M. Helena, and S. Marko.",
        "Simple Semantics in Topic Detection and Tracking.",
        "Information Retrieval, 7(3-4): 2004, 347-368. [13] K. Giridhar and J. Allan.",
        "Text Classification and Named Entities for New Event Detection.",
        "In Proceedings of the 27th Annual International ACM SIGIR Conference, New York, NY, USA.",
        "ACM Press. 2004, 297-304. [14] J. P. Callan, W. B. Croft, and S. M. Harding.",
        "The INQUERY Retrieval System.",
        "In Proceedings of DEXA-92, 3rd International Conference on Database and Expert Systems Applications, 1992, 78-83. [15] R. Krovetz.",
        "Viewing Morphology as An Inference Process.",
        "In Proceedings of ACM SIGIR93, 1993, 61-81. [16] Y. Yang and J. Pedersen.",
        "A Comparative Study on Feature Selection in Text Categorization.",
        "In J. D. H. Fisher, editor, The Fourteenth International Conference on Machine Learning (ICML97), Morgan Kaufmann, 1997, 412-420. [17] T. M. Cover, and J.A.",
        "Thomas.",
        "Elements of Information Theory.",
        "Wiley. 1991. [18] The linguistic data consortium, http://www.ldc,upenn.edu/. [19] The 2001 TDT task definition and evaluation plan, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm. [20] R. E. Schapire and Y.",
        "Singer.",
        "Boostexter: A Boosting-based System for Text Categorization.",
        "In Machine Learning 39(2/3):1, Kluwer Academic Publishers, 2000, 35-168. [21] K. Giridhar and J. Allan. 2005.",
        "Using Names and Topics for New Event Detection.",
        "In Proceedings of Human Technology Conference and Conference on Empirical Methods in Natural Language, Vancouver, 2005, 121-128"
    ],
    "error_count": 0,
    "keys": {
        "new event detection": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "<br>new event detection</br> Based on Indexing-tree and Named Entity Zhang Kuo Tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn Li Juan Zi Tsinghua University Beijing, 100084, China 86-10-62781461 ljz@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn ABSTRACT <br>new event detection</br> (NED) aims at detecting from one or multiple streams of news stories that which one is reported on a new event (i.e.",
                "not reported previously).",
                "With the overwhelming volume of news available today, there is an increasing need for a NED system which is able to detect new events more efficiently and accurately.",
                "In this paper we propose a new NED model to speed up the NED task by using news indexing-tree dynamically.",
                "Moreover, based on the observation that terms of different types have different effects for NED task, two term reweighting approaches are proposed to improve NED accuracy.",
                "In the first approach, we propose to adjust term weights dynamically based on previous story clusters and in the second approach, we propose to employ statistics on training data to learn the named entity reweighting model for each class of stories.",
                "Experimental results on two Linguistic Data Consortium (LDC) datasets TDT2 and TDT3 show that the proposed model can improve both efficiency and accuracy of NED task significantly, compared to the baseline system and other existing systems.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Search and Retrieval; H.4.2 [Information Systems Applications]: Types of Systemsdecision support.",
                "General Terms Algorithms, Performance, Experimentation 1.",
                "INTRODUCTION Topic Detection and Tracking (TDT) program aims to develop techniques which can effectively organize, search and structure news text materials from a variety of newswire and broadcast media [1].",
                "<br>new event detection</br> (NED) is one of the five tasks in TDT.",
                "It is the task of online identification of the earliest report for each topic as soon as that report arrives in the sequence of documents.",
                "A Topic is defined as a seminal event or activity, along with directly related events and activities [2].",
                "An Event is defined as something (non-trivial) happening in a certain place at a certain time [3].",
                "For instance, when a bomb explodes in a building, the exploding is the seminal event that triggers the topic, and other stories on the same topic would be those discussing salvaging efforts, the search for perpetrators, arrests and trial and so on.",
                "Useful news information is usually buried in a mass of data generated everyday.",
                "Therefore, NED systems are very useful for people who need to detect novel information from real-time news stream.",
                "These real-life needs often occur in domains like financial markets, news analysis, and intelligence gathering.",
                "In most of state-of-the-art (currently) NED systems, each news story on hand is compared to all the previous received stories.",
                "If all the similarities between them do not exceed a threshold, then the story triggers a new event.",
                "They are usually in the form of cosine similarity or Hellinger similarity metric.",
                "The core problem of NED is to identify whether two stories are on the same topic.",
                "Obviously, these systems cannot take advantage of topic information.",
                "Further more, it is not acceptable in real applications because of the large amount of computation required in the NED process.",
                "Other systems organize previous stories into clusters (each cluster corresponds to a topic), and new story is compared to the previous clusters instead of stories.",
                "This manner can reduce comparing times significantly.",
                "Nevertheless, it has been proved that this manner is less accurate [4, 5].",
                "This is because sometimes stories within a topic drift far away from each other, which could lead low similarity between a story and its topic.",
                "On the other hand, some proposed NED systems tried to improve accuracy by making better use of named entities [10, 11, 12, 13].",
                "However, none of the systems have considered that terms of different types (e.g.",
                "Noun, Verb or Person name) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "For example, the names of election candidates (Person name) are very important for stories of election class; the locations (Location name) where accidents happened are important for stories of accidents class.",
                "So, in NED, there still exist following three problems to be investigated: (1) How to speed up the detection procedure while do not decrease the detection accuracy? (2) How to make good use of cluster (topic) information to improve accuracy? (3) How to obtain better news story representation by better understanding of named entities.",
                "Driven by these problems, we have proposed three approaches in this paper. (1)To make the detection procedure faster, we propose a new NED procedure based on news indexing-tree created dynamically.",
                "Story indexing-tree is created by assembling similar stories together to form news clusters in different hierarchies according to their values of similarity.",
                "Comparisons between current story and previous clusters could help find the most similar story in less comparing times.",
                "The new procedure can reduce the amount of comparing times without hurting accuracy. (2)We use the clusters of the first floor in the indexing-tree as news topics, in which term weights are adjusted dynamically according to term distribution in the clusters.",
                "In this approach, cluster (topic) information is used properly, so the problem of theme decentralization is avoided. (3)Based on observations on the statistics obtained from training data, we found that terms of different types (e.g.",
                "Noun and Verb) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "And we propose to use statistics to optimize the weights of the terms of different types in a story according to the news class that the story belongs to.",
                "On TDT3 dataset, the new NED model just uses 14.9% comparing times of the basic model, while its minimum normalized cost is 0.5012, which is 0.0797 better than the basic model, and also better than any other results previously reported for this dataset [8, 13].",
                "The rest of the paper is organized as follows.",
                "We start off this paper by summarizing the previous work in NED in section 2.",
                "Section 3 presents the basic model for NED that most current systems use.",
                "Section 4 describes our new detection procedure based on news indexing-tree.",
                "In section 5, two term reweighting methods are proposed to improve NED accuracy.",
                "Section 6 gives our experimental data and evaluation metrics.",
                "We finally wrap up with the experimental results in Section 7, and the conclusions and future work in Section 8. 2.",
                "RELATED WORK Papka et al. proposed Single-Pass clustering on NED [6].",
                "When a new story was encountered, it was processed immediately to extract term features and a query representation of the storys content is built up.",
                "Then it was compared with all the previous queries.",
                "If the document did not trigger any queries by exceeding a threshold, it was marked as a new event.",
                "Lam et al build up previous query representations of story clusters, each of which corresponds to a topic [7].",
                "In this manner comparisons happen between stories and clusters.",
                "Recent years, most work focus on proposing better methods on comparison of stories and document representation.",
                "Brants et al. [8] extended a basic incremental TF-IDF model to include sourcespecific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, term reweighting based on inverse event frequencies, and segmentation of documents.",
                "Good improvements on TDT bench-marks were shown.",
                "Stokes et al. [9] utilized a combination of evidence from two distinct representations of a documents content.",
                "One of the representations was the usual free text vector, the other made use of lexical chains (created using WordNet) to build another term vector.",
                "Then the two representations are combined in a linear fashion.",
                "A marginal increase in effectiveness was achieved when the combined representation was used.",
                "Some efforts have been done on how to utilize named entities to improve NED.",
                "Yang et al. gave location named entities four times weight than other terms and named entities [10].",
                "DOREMI research group combined semantic similarities of person names, location names and time together with textual similarity [11][12].",
                "UMass [13] research group split document representation into two parts: named entities and non-named entities.",
                "And it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation.",
                "Both [10] and [13] used text categorization technique to classify news stories in advance.",
                "In [13] news stories are classified automatically at first, and then test sensitivities of names and non-name terms for NED for each class.",
                "In [10] frequent terms for each class are removed from document representation.",
                "For example, word election does not help identify different elections.",
                "In their work, effectiveness of different kinds of names (or terms with different POS) for NED in different news classes are not investigated.",
                "We use statistical analysis to reveal the fact and use it to improve NED performance. 3.",
                "BASIC MODEL In this section, we present the basic <br>new event detection</br> model which is similar to what most current systems apply.",
                "Then, we propose our new model by extending the basic model.",
                "<br>new event detection</br> systems use news story stream as input, in which stories are strictly time-ordered.",
                "Only previously received stories are available when dealing with current story.",
                "The output is a decision for whether the current story is on a new event or not and the confidence of the decision.",
                "Usually, a NED model consists of three parts: story representation, similarity calculation and detection procedure. 3.1 Story Representation Preprocessing is needed before generating story representation.",
                "For preprocessing, we tokenize words, recognize abbreviations, normalize abbreviations, add part-of-speech tags, remove stopwords included in the stop list used in InQuery [14], replace words with their stems using K-stem algorithm[15], and then generate word vector for each news story.",
                "We use incremental TF-IDF model for term weight calculation [4].",
                "In a TF-IDF model, term frequency in a news document is weighted by the inverse document frequency, which is generated from training corpus.",
                "When a new term occurs in testing process, there are two solutions: simply ignore the new term or set df of the term as a small const (e.g. df = 1).",
                "The new term receives too low weight in the first solution (0) and too high weight in the second solution.",
                "In incremental TF-IDF model, document frequencies are updated dynamically in each time step t: 1( ) ( ) ( )t t D tdf w df w df w−= + (1) where Dt represents news story set received in time t, and dfDt(w) means the number of documents that term w occurs in, and dft(w) means the total number of documents that term w occurs in before time t. In this work, each time window includes 50 news stories.",
                "Thus, each story d received in t is represented as follows: 1 2{ ( , , ), ( , , ),..., ( , , )}nd weight d t w weight d t w weight d t w→ where n means the number of distinct terms in story d, and ( , , )weight d t w means the weight of term w in story d at time t: log( ( , ) 1) log(( 1) /( ( ) 0.5)) ( , , ) log( ( , ) 1) log(( 1) /( ( ) 0.5)) t t t t w d tf d w N df w weight d t w tf d w N df w ∈ + + + = + + +∑ (2) where Nt means the total number of news stories before time t, and tf(d,w) means how many times term w occurs in news story d. 3.2 Similarity Calculation We use Hellinger distance for the calculation of similarity between two stories, for two stories d and d at time t, their similarity is defined as follows: , ( , , ) ( , , ) * ( , , ) w d d sim d d t weight d t w weight d t w ∈ = ∑ (3) 3.3 Detection Procedure For each story d received in time step t, the value ( ) ( ) ( ) ( ( , , )) time d time d n d max sim d d t < = (4) is a score used to determine whether d is a story about a new topic and at the same time is an indication of the confidence in our decision [8]. time(d) means the publication time of story d. If the score exceeds the thresholdθ new, then there exists a sufficiently similar document, thus d is a old story, otherwise, there is no sufficiently similar previous document, thus d is an new story. 4.",
                "New NED Procedure Traditional NED systems can be classified into two main types on the aspect of detection procedure: (1) S-S type, in which the story on hand is compared to each story received previously, and use the highest similarity to determine whether current story is about a new event; (2) S-C type, in which the story on hand is compared to all previous clusters each of which representing a topic, and the highest similarity is used for final decision for current story.",
                "If the highest similarity exceeds thresholdθ new, then it is an old story, and put it into the most similar cluster; otherwise it is a new story and create a new cluster.",
                "Previous work show that the first manner is more accurate than the second one [4][5].",
                "Since sometimes stories within a topic drift far away from each other, a story may have very low similarity with its topic.",
                "So using similarities between stories for determining new story is better than using similarities between story and clusters.",
                "Nevertheless, the first manner needs much more comparing times which means the first manner is low efficient.",
                "We propose a new detection procedure which uses comparisons with previous clusters to help find the most similar story in less comparing times, and the final new event decision is made according to the most similar story.",
                "Therefore, we can get both the accuracy of S-S type methods and the efficiency of S-C type methods.",
                "The new procedure creates a news indexing-tree dynamically, in which similar stories are put together to form a hierarchy of clusters.",
                "We index similar stories together by their common ancestor (a cluster node).",
                "Dissimilar stories are indexed in different clusters.",
                "When a story is coming, we use comparisons between the current story and previous hierarchical clusters to help find the most similar story which is useful for new event decision.",
                "After the new event decision is made, the current story is inserted to the indexing-tree for the following detection.",
                "The news indexing-tree is defined formally as follows: S-Tree = {r, NC , NS , E} where r is the root of S-Tree, NC is the set of all cluster nodes, NS is the set of all story nodes, and E is the set of all edges in S-Tree.",
                "We define a set of constraints for a S-Tree: ⅰ . , is an non-terminal node in the treeC i i N i∀ ∈ → ⅱ . , is a terminal node in the treeS i i N i∀ ∈ → ⅲ . , out degree of is at least 2C i i N i∀ ∈ → ⅳ . , is represented as the centroid of its desendantsC i i iN∀ ∈ → For a news story di, the comparison procedure and inserting procedure based on indexing-tree are defined as follows.",
                "An example is shown by Figure 1 and Figure 2.",
                "Figure 1.",
                "Comparison procedure Figure 2.",
                "Inserting procedure Comparison procedure: Step 1: compare di to all the direct child nodes of r and select λ nodes with highest similarities, e.g., C1 2 and C1 3 in Figure 1.",
                "Step 2: for each selected node in the last step, e.g.",
                "C1 2, compare di to all its direct child nodes, and select λ nodes with highest similarities, e.g.",
                "C2 2 and d8.",
                "Repeat step 2 for all non-terminal nodes.",
                "Step 3: record the terminal node with the highest similarty to di, e.g. s5, and the similarity value (0.20).",
                "Inserting di to the S-tree with r as root: Find the node n which is direct child of r in the path from r to the terminal node with highest similarity s, e.g.",
                "C1 2.",
                "If s is smaller than θ init+(h-1)δ , then add di to the tree as a direct child of r. Otherwise, if n is a terminal node, then create a cluster node instead of n, and add both n and di as its direct children; if n is an non-terminal node, then repeat this procedure and insert di to the sub-tree with n as root recursively.",
                "Here h is the length between n and the root of S-tree.",
                "The more the stories in a cluster similar to each other, the better the cluster represents the stories in it.",
                "Hence we add no constraints on the maximum of trees height and degree of a node.",
                "Therefore, we cannot give the complexity of this indexing-tree based procedure.",
                "But we will give the number of comparing times needed by the new procedure in our experiments in section7. 5.",
                "Term Reweighting Methods In this section, two term reweighting methods are proposed to improve NED accuracy.",
                "In the first method, a new way is explored for better using of cluster (topic) information.",
                "The second one finds a better way to make use of named entities based on news classification. 5.1 Term Reweighting Based on Distribution Distance TF-IDF is the most prevalent model used in information retrieval systems.",
                "The basic idea is that the fewer documents a term appears in, the more important the term is in discrimination of documents (relevant or not relevant to a query containing the term).",
                "Nevertheless, in TDT domain, we need to discriminate documents with regard to topics rather than queries.",
                "Intuitively, using cluster (topic) vectors to compare with subsequent news stories should outperform using story vectors.",
                "Unfortunately, the experimental results do not support this intuition [4][5].",
                "Based on observation on data, we find the reason is that a news topic usually contains many directly or indirectly related events, while they all have their own sub-subjects which are usually different with each other.",
                "Take the topic described in section 1 as an example, events like the explosion and salvage have very low similarities with events about criminal trial, therefore stories about trial would have low similarity with the topic vector built on its previous events.",
                "This section focuses on how to effectively make use of topic information and at the same time avoid the problem of content decentralization.",
                "At first, we classify terms into 5 classes to help analysis the needs of the modified model: Term class A: terms that occur frequently in the whole corpus, e.g., year and people.",
                "Terms of this class should be given low weights because they do not help much for topic discrimination.",
                "Term class B: terms that occur frequently within a news category, e.g., election, storm.",
                "They are useful to distinguish two stories in different news categories.",
                "However, they cannot provide information to determine whether two stories are on the same or different topics.",
                "In another words, term election and term storm are not helpful in differentiate two election campaigns and two storm disasters.",
                "Therefore, terms of this class should be assigned lower weights.",
                "Term class C: terms that occur frequently in a topic, and infrequently in other topics, e.g., the name of a crash plane, the name of a specific hurricane.",
                "News stories that belong to different topics rarely have overlap terms in this class.",
                "The more frequently a term appears in a topic, the more important the term is for a story belonging to the topic, therefore the term should be set higher weight.",
                "Term class D: terms that appear in a topic exclusively, but not frequently.",
                "For example, the name of a fireman who did very well in a salvage action, which may appears in only two or three stories but never appeared in other topics.",
                "Terms of this type should receive more weights than in TF-IDF model.",
                "However, since they are not popular in the topic, it is not appropriate to give them too high weights.",
                "Term class E: terms with low document frequency, and appear in different topics.",
                "Terms of this class should receive lower weights.",
                "Now we analyze whether TF-IDF model can give proper weights to the five classes of terms.",
                "Obviously, terms of class A are lowly weighted in TF-IDF model, which is conformable with the requirement described above.",
                "In TF-IDF model, terms of class B are highly dependant with the number of stories in a news class.",
                "TF-IDF model cannot provide low weights if the story containing the term belongs to a relative small news class.",
                "For a term of class C, the more frequently it appears in a topic, the less weight TFIDF model gives to it.",
                "This strongly conflicts with the requirement of terms in class C. For terms of class D, TF-IDF model gives them high weights correctly.",
                "But for terms of class E, TF-IDF model gives high weights to them which are not conformable with the requirement of low weights.",
                "To sum up, terms of class B, C, E cannot be properly weighted in TF-IDF model.",
                "So, we propose a modified model to resolve this problem.",
                "When θ init andθ new are set closely, we assume that most of the stories in a first-level cluster (a direct child node of root node) are on the same topic.",
                "Therefore, we make use of a first-level cluster to capture term distribution (df for all the terms within the cluster) within the topic dynamically.",
                "KL divergence of term distribution in a first-level cluster and the whole story set is used to adjust term weights:  ( , , ) * (1 * ( || )) ( , , ) ( , , ) * (1 * ( || )) cw tw cw tw w d D weight d t w KL P P weight d t w weight d t w KL P P γ γ ∈ + = +∑ (5) where ( ) ( ) ( ) ( ) 1,cw cw c c c c df w df w p y p y N N = = − (6) ( ) ( ) ( ) ( ) 1,t t tw tw t t df w df w p y p y N N = = − (7) where dfc(w) is the number of documents containing term w within cluster C, and Nc is the number of documents in cluster C, and Nt is the total number of documents that arrive before time step t. γ is a const parameter, now is manually set 3.",
                "KL divergence is defined as follows [17]: ( ) ( || ) ( ) log ( )x p x KL P Q p x q x = ∑ (8) The basic idea is: for a story in a topic, the more a term occurs within the topic, and the less it occurs in other topics, it should be assigned higher weights.",
                "Obviously, modified model can meet all the requirements of the five term classes listed above. 5.2 Term Reweighting Based on Term Type and Story Class Previous work found that some classes of news stories could achieve good improvements by giving extra weight to named entities.",
                "But we find that terms of different types should be given different amount of extra weight for different classes of news stories.",
                "We use open-NLP1 to recognize named entity types and part-ofspeech tags for terms that appear in news stories.",
                "Named entity types include person name, organization name, location name, date, time, money and percentage, and five POSs are selected: none (NN), verb (VB), adjective (JJ), adverb (RB) and cardinal number (CD).",
                "Statistical analysis shows topic-level discriminative terms types for different classes of stories.",
                "For the sake of convenience, named entity type and part-of-speech tags are uniformly called term type in subsequent sections.",
                "Determining whether two stories are about the same topic is a basic component for NED task.",
                "So at first we use 2 χ statistic to compute correlations between terms and topics.",
                "For a term t and a topic T, a contingence table is derived: Table 1.",
                "A 2×2 Contingence Table Doc Number belong to topic T not belong to topic T include t A B not include t C D The 2 χ statistic for a specific term t with respect to topic T is defined to be [16]: 2 2 ( , ) ( ) * ( ) ( ) * ( ) * ( ) * ( ) w T A B C D AD CB A C B D A B C D χ = + + + − + + + + (9) News topics for the TDT task are further classified into 11 rules of interpretations (ROIs) 2 .",
                "The ROI can be seen as a higher level class of stories.",
                "The average correlation between a term type and a topic ROI is computed as: 2 avg 2 ( , )( ( , ) )k m m km kT R w P w TP R p w T R P χ χ ∈ ∈ ∑ ∑（ , ）= 1 1 k=1…K, m=1…M (10) where K is the number of term types (set 12 constantly in the paper).",
                "M is the number news classes (ROIs, set 11 in the paper).",
                "Pk represents the set of all terms of type k, and Rm represents the set of all topics of class m, p(t,T) means the probability that t occurs in topic T. Because of limitation of space, only parts of the term types (9 term types) and parts of news classes (8 classes) are listed in table 2 with the average correlation values between them.",
                "The statistics is derived from labeled data in TDT2 corpus. (Results in table 2 are already normalized for convenience in comparison.)",
                "The statistics in table 2 indicates the usefulness of different term types in topic discrimination with respect to different news classes.",
                "We can see that, location name is the most useful term type for three news classes: Natural Disasters, Violence or War, Finances.",
                "And for three other categories Elections, Legal/Criminal Cases, Science and Discovery, person name is the most discriminative term type.",
                "For Scandals/Hearings, date is the most important information for topic discrimination.",
                "In addition, Legal/Criminal Cases and Finance topics have higher correlation with money terms, while Science and Discovery have higher correlation with percentage terms.",
                "Non-name terms are more stable for different classes. 1 . http://opennlp.sourceforge.net/ 2 . http://projects.ldc.upenn.edu/TDT3/Guide/label.html From the analysis of table 2, it is reasonable to adjust term weight according to their term type and the news class the story belongs to.",
                "New term weights are reweighted as follows: ( ) ( ) ( ) ( ) ( , , ) * ( , , ) ( , , ) * class d D type w T class d D type w w d weight d t w weight d t w weight d t w α α ∈ = ∑ (11) where type(w) represents the type of term w, and class(d) represents the class of story d, c kα is reweighting parameter for news class c and term type k. In the work, we just simply use statistics in table 2 as the reweighting parameters.",
                "Even thought using the statistics directly may not the best choice, we do not discuss how to automatically obtain the best parameters.",
                "We will try to use machine learning techniques to obtain the best parameters in the future work.",
                "In the work, we use BoosTexter [20] to classify all stories into one of the 11 ROIs.",
                "BoosTexter is a boosting based machine learning program, which creates a series of simple rules for building a classifier for text or attribute-value data.",
                "We use term weight generated using TF-IDF model as feature for story classification.",
                "We trained the model on the 12000 judged English stories in TDT2, and classify the rest of the stories in TDT2 and all stories in TDT3.",
                "Classification results are used for term reweighting in formula (11).",
                "Since the class labels of topic-off stories are not given in TDT datasets, we cannot give the classification accuracy here.",
                "Thus we do not discuss the effects of classification accuracy to NED performance in the paper. 6.",
                "EXPERIMENTAL SETUP 6.1 Datasets We used two LDC [18] datasets TDT2 and TDT3 for our experiments.",
                "TDT2 contains news stories from January to June 1998.",
                "It contains around 54,000 stories from sources like ABC, Associated Press, CNN, New York Times, Public Radio International, Voice of America etc.",
                "Only English stories in the collection were considered.",
                "TDT3 contains approximately 31,000 English stories collected from October to December 1998.",
                "In addition to the sources used in TDT2, it also contains stories from NBC and MSNBC TV broadcasts.",
                "We used transcribed versions of the TV and radio broadcasts besides textual news.",
                "TDT2 dataset is labeled with about 100 topics, and approximately 12,000 English stories belong to at least one of these topics.",
                "TDT3 dataset is labeled with about 120 topics, and approximately 8000 English stories belong to at least one of these topics.",
                "All the topics are classified into 11 Rules of Interpretation: (1)Elections, (2)Scandals/Hearings, (3)Legal/Criminal Cases, (4)Natural Disasters, (5)Accidents, (6)Ongoing Violence or War, (7)Science and Discovery News, (8)Finance, (9)New Law, (10)Sports News, (11)MISC.",
                "News. 6.2 Evaluation Metric TDT uses a cost function CDet that combines the probabilities of missing a new story and a false alarm [19]: * * * *Det Miss Miss Target FA FA NontargetC C P P C P P= + (12) Table 2.",
                "Average correlation between term types and news classes where CMiss means the cost of missing a new story, PMiss means the probability of missing a new story, and PTarget means the probability of seeing a new story in the data; CFA means the cost of a false alarm, PFA means the probability of a false alarm, and PNontarget means the probability of seeing an old story.",
                "The cost CDet is normalized such that a perfect system scores 0 and a trivial system, which is the better one of mark all stories as new or old, scores 1: ( ( * , * ) ) Det Det Miss Target FA Nontarget C Norm C min C P C P = (13) <br>new event detection</br> system gives two outputs for each story.",
                "The first part is yes or no indicating whether the story triggers a new event or not.",
                "The second part is a score indicating confidence of the first decision.",
                "Confidence scores can be used to plot DET curve, i.e., curves that plot false alarm vs. miss probabilities.",
                "Minimum normalized cost can be determined if optimal threshold on the score were chosen. 7.",
                "EXPERIMENTAL RESULTS 7.1 Main Results To test the approaches proposed in the model, we implemented and tested five systems: System-1: this system is used as baseline.",
                "It is implemented based on the basic model described in section 3, i.e., using incremental TF-IDF model to generate term weights, and using Hellinger distance to compute document similarity.",
                "Similarity score normalization is also employed [8].",
                "S-S detection procedure is used.",
                "System-2: this system is the same as system-1 except that S-C detection procedure is used.",
                "System-3: this system is the same as system-1 except that it uses the new detection procedure which is based on indexing-tree.",
                "System-4: implemented based on the approach presented in section 5.1, i.e., terms are reweighted according to the distance between term distributions in a cluster and all stories.",
                "The new detection procedure is used.",
                "System-5: implemented based on the approach presented in section 5.2, i.e., terms of different types are reweighted according to news class using trained parameters.",
                "The new detection procedure is used.",
                "The following are some other NED systems: System-6: [21] for each pair of stories, it computes three similarity values for named entity, non-named entity and all terms respectively.",
                "And employ Support Vector Machine to predict new or old using the similarity values as features.",
                "System-7: [8] it extended a basic incremental TF-IDF model to include source-specific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, etc.",
                "System-8: [13] it split document representation into two parts: named entities and non-named entities, and choose one effective part for each news class.",
                "Table 3 and table 4 show topic-weighted normalized costs and comparing times on TDT2 and TDT3 datasets respectively.",
                "Since no heldout data set for fine-tuning the threshold θ new was available for experiments on TDT2, we only report minimum normalized costs for our systems in table 3.",
                "System-5 outperforms all other systems including system-6, and it performs only 2.78e+8 comparing times in detection procedure which is only 13.4% of system-1.",
                "Table 3.",
                "NED results on TDT2 Systems Min Norm(CDet) Cmp times System-1 0.5749 2.08e+9 System-2① 0.6673 3.77e+8 System-3② 0.5765 2.81e+8 System-4② 0.5431 2.99e+8 System-5② 0.5089 2.78e+8 System-6 0.5300 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 When evaluating on the normalized costs on TDT3, we use the optimal thresholds obtained from TDT2 data set for all systems.",
                "System-2 reduces comparing times to 1.29e+9 which is just 18.3% of system-1, but at the same time it also gets a deteriorated minimum normalized cost which is 0.0499 higher than system-1.",
                "System-3 uses the new detection procedure based on news indexing-tree.",
                "It requires even less comparing times than system-2.",
                "This is because story-story comparisons usually yield greater similarities than story-cluster ones, so stories tend to be combined Location Person Date Organization Money Percentage NN JJ CD Elections 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 Scandals/Hearings 0.66 0.62 0.28 1 0.11 0.02 0.27 0.13 0.05 Legal/Criminal Cases 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 Natural Disasters 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 Violence or War 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 Science and Discovery 0.11 1 0.01 0.22 0.08 0.12 0.19 0.08 0.03 Finances 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 Sports 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 together in system-3.",
                "And system-3 is basically equivalent to system-1 in accuracy results.",
                "System-4 adjusts term weights based on the distance of term distributions between the whole corpus and cluster story set, yielding a good improvement by 0.0468 compared to system-1.",
                "The best system (system-5) has a minimum normalized cost 0.5012, which is 0.0797 better than system-1, and also better than any other results previously reported for this dataset [8, 13].",
                "Further more, system-5 only needs 1.05e+8 comparing times which is 14.9% of system-1.",
                "Table 4.",
                "NED results on TDT3 Systems Norm(CDet) Min Norm(CDet) Cmp times System-1 0.6159 0.5809 7.04e+8 System-2① 0.6493 0.6308 1.29e+8 System-3② 0.6197 0.5868 1.03e+8 System-4② 0.5601 0.5341 1.03e+8 System-5② 0.5413 0.5012 1.05e+8 System-7 -- 0.5783 -System-8 -- 0.5229 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 Figure5 shows the five DET curves for our systems on data set TDT3.",
                "System-5 achieves the minimum cost at a false alarm rate of 0.0157 and a miss rate of 0.4310.",
                "We can observe that System4 and System-5 obtain lower miss probability at regions of low false alarm probabilities.",
                "The hypothesis is that, more weight value is transferred to key terms of topics from non-key terms.",
                "Similarity score between two stories belonging to different topics are lower than before, because their overlapping terms are usually not key terms of their topics. 7.2 Parameter selection for indexing-tree detection Figure 3 shows the minimum normalized costs obtained by system-3 on TDT3 using different parameters.",
                "Theθ init parameter is tested on six values spanning from 0.03 to 0.18.",
                "And the λ parameter is tested on four values 1, 2, 3 and 4.",
                "We can see that, whenθ init is set to 0.12, which is the closest one toθ new, the costs are lower than others.",
                "This is easy to explain, because when stories belonging to the same topic are put in a cluster, it is more reasonable for the cluster to represent the stories in it.",
                "When parameter λ is set to 3 or 4, the costs are better than other cases, but there is no much difference between 3 and 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ MinCost 0.6 0.65 0.7 0.75 0.8 0.85 0.9 Figure 3.",
                "Min Cost on TDT3 (δ =0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ Comparingtimes 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 Figure 4.",
                "Comparing times on TDT3 (δ =0.15) Figure 4 gives the comparing times used by system-3 on TDT3 with the same parameters as figure 3.",
                "The comparing times are strongly dependent onθ init.",
                "Because the greaterθ init is, the less stories combined together, the more comparing times are needed for new event decision.",
                "So we useθ init =0.13,λ =3,δ =0.15 for system-3, 4, and 5.",
                "In this parameter setting, we can get both low minimum normalized costs and less comparing times. 8.",
                "CONCLUSION We have proposed a news indexing-tree based detection procedure in our model.",
                "It reduces comparing times to about one seventh of traditional method without hurting NED accuracy.",
                "We also have presented two extensions to the basic TF-IDF model.",
                "The first extension is made by adjust term weights based on term distributions between the whole corpus and a cluster story set.",
                "And the second extension to basic TF-IDF model is better use of term types (named entities types and part-of-speed) according to news categories.",
                "Our experimental results on TDT2 and TDT3 datasets show that both of the two extensions contribute significantly to improvement in accuracy.",
                "We did not consider news time information as a clue for NED task, since most of the topics last for a long time and TDT data sets only span for a relative short period (no more than 6 months).",
                "For the future work, we want to collect news set which span for a longer period from internet, and integrate time information in NED task.",
                "Since topic is a relative coarse-grained news cluster, we also want to refine cluster granularity to event-level, and identify different events and their relations within a topic.",
                "Acknowledgments This work is supported by the National Natural Science Foundation of China under Grant No. 90604025.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] In Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. .01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90 1 2 5 10 20 40 60 80 90 False Alarm Probability (in %) MissProbability(in%) SYSTEM1 Topic Weighted Curve SYSTEM1 Min Norm(Cost) SYSTEM2 Topic Weighted Curve SYSTEM2 Min Norm(Cost) SYSTEM3 Topic Weighted Curve SYSTEM3 Min Norm(Cost) SYSTEM4 Topic Weighted Curve SYSTEM4 Min Norm(Cost) SYSTEM5 Topic Weighted Curve SYSTEM5 Min Norm(Cost) Random Performance Figure 5.",
                "DET curves on TDT3 [3] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B.T.",
                "Archibald, and X. Liu.",
                "Learning Approaches for Detecting and Tracking News Events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), 1999, 32-43. [4] Y. Yang, T. Pierce, and J. Carbonell.",
                "A Study on Retrospective and On-line Event Detection.",
                "In Proceedings of SIGIR-98, Melbourne, Australia, 1998, 28-36. [5] J. Allan, V. Lavrenko, D. Malin, and R. Swan.",
                "Detections, Bounds, and Timelines: Umass and tdt-3.",
                "In Proceedings of Topic Detection and Tracking Workshop (TDT-3), Vienna, VA, 2000, 167-174. [6] R. Papka and J. Allan.",
                "On-line <br>new event detection</br> Using Single Pass Clustering TITLE2:.",
                "Technical Report UM-CS1998-021, 1998. [7] W. Lam, H. Meng, K. Wong, and J.",
                "Yen.",
                "Using Contextual Analysis for News Event Detection.",
                "International Journal on Intelligent Systems, 2001, 525-546. [8] B. Thorsten, C. Francine, and F. Ayman.",
                "A System for <br>new event detection</br>.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2003, 330-337. [9] S. Nicola and C. Joe.",
                "Combining Semantic and Syntactic Document Classifiers to Improve First Story Detection.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2001, 424425. [10] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topicconditioned Novelty Detection.",
                "In Proceedings of the 8th ACM SIGKDD International Conference, ACM Press. 2002, 688-693. [11] M. Juha, A.M. Helena, and S. Marko.",
                "Applying Semantic Classes in Event Detection and Tracking.",
                "In Proceedings of International Conference on Natural Language Processing (ICON 2002), 2002, pages 175-183. [12] M. Juha, A.M. Helena, and S. Marko.",
                "Simple Semantics in Topic Detection and Tracking.",
                "Information Retrieval, 7(3-4): 2004, 347-368. [13] K. Giridhar and J. Allan.",
                "Text Classification and Named Entities for <br>new event detection</br>.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2004, 297-304. [14] J. P. Callan, W. B. Croft, and S. M. Harding.",
                "The INQUERY Retrieval System.",
                "In Proceedings of DEXA-92, 3rd International Conference on Database and Expert Systems Applications, 1992, 78-83. [15] R. Krovetz.",
                "Viewing Morphology as An Inference Process.",
                "In Proceedings of ACM SIGIR93, 1993, 61-81. [16] Y. Yang and J. Pedersen.",
                "A Comparative Study on Feature Selection in Text Categorization.",
                "In J. D. H. Fisher, editor, The Fourteenth International Conference on Machine Learning (ICML97), Morgan Kaufmann, 1997, 412-420. [17] T. M. Cover, and J.A.",
                "Thomas.",
                "Elements of Information Theory.",
                "Wiley. 1991. [18] The linguistic data consortium, http://www.ldc,upenn.edu/. [19] The 2001 TDT task definition and evaluation plan, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm. [20] R. E. Schapire and Y.",
                "Singer.",
                "Boostexter: A Boosting-based System for Text Categorization.",
                "In Machine Learning 39(2/3):1, Kluwer Academic Publishers, 2000, 35-168. [21] K. Giridhar and J. Allan. 2005.",
                "Using Names and Topics for <br>new event detection</br>.",
                "In Proceedings of Human Technology Conference and Conference on Empirical Methods in Natural Language, Vancouver, 2005, 121-128"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "\"Nueva detección de eventos\" basada en el árbol de indexación y la entidad nombrada Zhang Kuo tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn li juy zi tsinghua University beijing, 100084, China 86-10-10-10-10-10-1062781461 ljz@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn Abstract \"New Event Detection\" (NED)",
                "\"Nueva detección de eventos\" (NED) es una de las cinco tareas en TDT.",
                "Modelo básico En esta sección, presentamos el modelo básico de \"Detección de eventos\" que es similar a lo que se aplican la mayoría de los sistemas actuales.",
                "Los sistemas de \"Detección de eventos\" utilizan la transmisión de noticias de noticias como entrada, en la que las historias están estrictamente ordenadas por el tiempo.",
                "El Costo CDET se normaliza de tal manera que un sistema perfecto obtiene 0 y un sistema trivial, que es el mejor de Mark TODOS las historias como nuevas o antiguas, puntajes 1: (( *, *)) Det det Det Miss Target Fa no objetivo C Norm CMin C P C P = (13) El sistema de \"Detección de eventos\" nueva proporciona dos salidas para cada historia.",
                "\"Nuevo detección de eventos\" en línea utilizando Title2 de un solo pase:.",
                "Un sistema para \"nueva detección de eventos\".",
                "Clasificación de texto y entidades nombradas para \"nueva detección de eventos\".",
                "Uso de nombres y temas para la \"nueva detección de eventos\"."
            ],
            "translated_text": "",
            "candidates": [
                "apunta a la detección de desdeuna o múltiples transmisiones de noticias que se informan en un nuevo evento (es decir, la nueva detección de eventos",
                "Nueva detección de eventos",
                "New Event Detection",
                "Nueva detección de eventos",
                "Nueva detección de eventos",
                "Nueva detección de eventos",
                "Detección de eventos",
                "Nueva detección de eventos",
                "Detección de eventos",
                "Nueva detección de eventos",
                "Detección de eventos",
                "Nueva detección de eventos",
                "Nuevo detección de eventos",
                "Nueva detección de eventos",
                "nueva detección de eventos",
                "Nueva detección de eventos",
                "nueva detección de eventos",
                "Nueva detección de eventos",
                "nueva detección de eventos"
            ],
            "error": []
        },
        "streams of news stories": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "New Event Detection Based on Indexing-tree and Named Entity Zhang Kuo Tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn Li Juan Zi Tsinghua University Beijing, 100084, China 86-10-62781461 ljz@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn ABSTRACT New Event Detection (NED) aims at detecting from one or multiple <br>streams of news stories</br> that which one is reported on a new event (i.e.",
                "not reported previously).",
                "With the overwhelming volume of news available today, there is an increasing need for a NED system which is able to detect new events more efficiently and accurately.",
                "In this paper we propose a new NED model to speed up the NED task by using news indexing-tree dynamically.",
                "Moreover, based on the observation that terms of different types have different effects for NED task, two term reweighting approaches are proposed to improve NED accuracy.",
                "In the first approach, we propose to adjust term weights dynamically based on previous story clusters and in the second approach, we propose to employ statistics on training data to learn the named entity reweighting model for each class of stories.",
                "Experimental results on two Linguistic Data Consortium (LDC) datasets TDT2 and TDT3 show that the proposed model can improve both efficiency and accuracy of NED task significantly, compared to the baseline system and other existing systems.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Search and Retrieval; H.4.2 [Information Systems Applications]: Types of Systemsdecision support.",
                "General Terms Algorithms, Performance, Experimentation 1.",
                "INTRODUCTION Topic Detection and Tracking (TDT) program aims to develop techniques which can effectively organize, search and structure news text materials from a variety of newswire and broadcast media [1].",
                "New Event Detection (NED) is one of the five tasks in TDT.",
                "It is the task of online identification of the earliest report for each topic as soon as that report arrives in the sequence of documents.",
                "A Topic is defined as a seminal event or activity, along with directly related events and activities [2].",
                "An Event is defined as something (non-trivial) happening in a certain place at a certain time [3].",
                "For instance, when a bomb explodes in a building, the exploding is the seminal event that triggers the topic, and other stories on the same topic would be those discussing salvaging efforts, the search for perpetrators, arrests and trial and so on.",
                "Useful news information is usually buried in a mass of data generated everyday.",
                "Therefore, NED systems are very useful for people who need to detect novel information from real-time news stream.",
                "These real-life needs often occur in domains like financial markets, news analysis, and intelligence gathering.",
                "In most of state-of-the-art (currently) NED systems, each news story on hand is compared to all the previous received stories.",
                "If all the similarities between them do not exceed a threshold, then the story triggers a new event.",
                "They are usually in the form of cosine similarity or Hellinger similarity metric.",
                "The core problem of NED is to identify whether two stories are on the same topic.",
                "Obviously, these systems cannot take advantage of topic information.",
                "Further more, it is not acceptable in real applications because of the large amount of computation required in the NED process.",
                "Other systems organize previous stories into clusters (each cluster corresponds to a topic), and new story is compared to the previous clusters instead of stories.",
                "This manner can reduce comparing times significantly.",
                "Nevertheless, it has been proved that this manner is less accurate [4, 5].",
                "This is because sometimes stories within a topic drift far away from each other, which could lead low similarity between a story and its topic.",
                "On the other hand, some proposed NED systems tried to improve accuracy by making better use of named entities [10, 11, 12, 13].",
                "However, none of the systems have considered that terms of different types (e.g.",
                "Noun, Verb or Person name) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "For example, the names of election candidates (Person name) are very important for stories of election class; the locations (Location name) where accidents happened are important for stories of accidents class.",
                "So, in NED, there still exist following three problems to be investigated: (1) How to speed up the detection procedure while do not decrease the detection accuracy? (2) How to make good use of cluster (topic) information to improve accuracy? (3) How to obtain better news story representation by better understanding of named entities.",
                "Driven by these problems, we have proposed three approaches in this paper. (1)To make the detection procedure faster, we propose a new NED procedure based on news indexing-tree created dynamically.",
                "Story indexing-tree is created by assembling similar stories together to form news clusters in different hierarchies according to their values of similarity.",
                "Comparisons between current story and previous clusters could help find the most similar story in less comparing times.",
                "The new procedure can reduce the amount of comparing times without hurting accuracy. (2)We use the clusters of the first floor in the indexing-tree as news topics, in which term weights are adjusted dynamically according to term distribution in the clusters.",
                "In this approach, cluster (topic) information is used properly, so the problem of theme decentralization is avoided. (3)Based on observations on the statistics obtained from training data, we found that terms of different types (e.g.",
                "Noun and Verb) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "And we propose to use statistics to optimize the weights of the terms of different types in a story according to the news class that the story belongs to.",
                "On TDT3 dataset, the new NED model just uses 14.9% comparing times of the basic model, while its minimum normalized cost is 0.5012, which is 0.0797 better than the basic model, and also better than any other results previously reported for this dataset [8, 13].",
                "The rest of the paper is organized as follows.",
                "We start off this paper by summarizing the previous work in NED in section 2.",
                "Section 3 presents the basic model for NED that most current systems use.",
                "Section 4 describes our new detection procedure based on news indexing-tree.",
                "In section 5, two term reweighting methods are proposed to improve NED accuracy.",
                "Section 6 gives our experimental data and evaluation metrics.",
                "We finally wrap up with the experimental results in Section 7, and the conclusions and future work in Section 8. 2.",
                "RELATED WORK Papka et al. proposed Single-Pass clustering on NED [6].",
                "When a new story was encountered, it was processed immediately to extract term features and a query representation of the storys content is built up.",
                "Then it was compared with all the previous queries.",
                "If the document did not trigger any queries by exceeding a threshold, it was marked as a new event.",
                "Lam et al build up previous query representations of story clusters, each of which corresponds to a topic [7].",
                "In this manner comparisons happen between stories and clusters.",
                "Recent years, most work focus on proposing better methods on comparison of stories and document representation.",
                "Brants et al. [8] extended a basic incremental TF-IDF model to include sourcespecific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, term reweighting based on inverse event frequencies, and segmentation of documents.",
                "Good improvements on TDT bench-marks were shown.",
                "Stokes et al. [9] utilized a combination of evidence from two distinct representations of a documents content.",
                "One of the representations was the usual free text vector, the other made use of lexical chains (created using WordNet) to build another term vector.",
                "Then the two representations are combined in a linear fashion.",
                "A marginal increase in effectiveness was achieved when the combined representation was used.",
                "Some efforts have been done on how to utilize named entities to improve NED.",
                "Yang et al. gave location named entities four times weight than other terms and named entities [10].",
                "DOREMI research group combined semantic similarities of person names, location names and time together with textual similarity [11][12].",
                "UMass [13] research group split document representation into two parts: named entities and non-named entities.",
                "And it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation.",
                "Both [10] and [13] used text categorization technique to classify news stories in advance.",
                "In [13] news stories are classified automatically at first, and then test sensitivities of names and non-name terms for NED for each class.",
                "In [10] frequent terms for each class are removed from document representation.",
                "For example, word election does not help identify different elections.",
                "In their work, effectiveness of different kinds of names (or terms with different POS) for NED in different news classes are not investigated.",
                "We use statistical analysis to reveal the fact and use it to improve NED performance. 3.",
                "BASIC MODEL In this section, we present the basic New Event Detection model which is similar to what most current systems apply.",
                "Then, we propose our new model by extending the basic model.",
                "New Event Detection systems use news story stream as input, in which stories are strictly time-ordered.",
                "Only previously received stories are available when dealing with current story.",
                "The output is a decision for whether the current story is on a new event or not and the confidence of the decision.",
                "Usually, a NED model consists of three parts: story representation, similarity calculation and detection procedure. 3.1 Story Representation Preprocessing is needed before generating story representation.",
                "For preprocessing, we tokenize words, recognize abbreviations, normalize abbreviations, add part-of-speech tags, remove stopwords included in the stop list used in InQuery [14], replace words with their stems using K-stem algorithm[15], and then generate word vector for each news story.",
                "We use incremental TF-IDF model for term weight calculation [4].",
                "In a TF-IDF model, term frequency in a news document is weighted by the inverse document frequency, which is generated from training corpus.",
                "When a new term occurs in testing process, there are two solutions: simply ignore the new term or set df of the term as a small const (e.g. df = 1).",
                "The new term receives too low weight in the first solution (0) and too high weight in the second solution.",
                "In incremental TF-IDF model, document frequencies are updated dynamically in each time step t: 1( ) ( ) ( )t t D tdf w df w df w−= + (1) where Dt represents news story set received in time t, and dfDt(w) means the number of documents that term w occurs in, and dft(w) means the total number of documents that term w occurs in before time t. In this work, each time window includes 50 news stories.",
                "Thus, each story d received in t is represented as follows: 1 2{ ( , , ), ( , , ),..., ( , , )}nd weight d t w weight d t w weight d t w→ where n means the number of distinct terms in story d, and ( , , )weight d t w means the weight of term w in story d at time t: log( ( , ) 1) log(( 1) /( ( ) 0.5)) ( , , ) log( ( , ) 1) log(( 1) /( ( ) 0.5)) t t t t w d tf d w N df w weight d t w tf d w N df w ∈ + + + = + + +∑ (2) where Nt means the total number of news stories before time t, and tf(d,w) means how many times term w occurs in news story d. 3.2 Similarity Calculation We use Hellinger distance for the calculation of similarity between two stories, for two stories d and d at time t, their similarity is defined as follows: , ( , , ) ( , , ) * ( , , ) w d d sim d d t weight d t w weight d t w ∈ = ∑ (3) 3.3 Detection Procedure For each story d received in time step t, the value ( ) ( ) ( ) ( ( , , )) time d time d n d max sim d d t < = (4) is a score used to determine whether d is a story about a new topic and at the same time is an indication of the confidence in our decision [8]. time(d) means the publication time of story d. If the score exceeds the thresholdθ new, then there exists a sufficiently similar document, thus d is a old story, otherwise, there is no sufficiently similar previous document, thus d is an new story. 4.",
                "New NED Procedure Traditional NED systems can be classified into two main types on the aspect of detection procedure: (1) S-S type, in which the story on hand is compared to each story received previously, and use the highest similarity to determine whether current story is about a new event; (2) S-C type, in which the story on hand is compared to all previous clusters each of which representing a topic, and the highest similarity is used for final decision for current story.",
                "If the highest similarity exceeds thresholdθ new, then it is an old story, and put it into the most similar cluster; otherwise it is a new story and create a new cluster.",
                "Previous work show that the first manner is more accurate than the second one [4][5].",
                "Since sometimes stories within a topic drift far away from each other, a story may have very low similarity with its topic.",
                "So using similarities between stories for determining new story is better than using similarities between story and clusters.",
                "Nevertheless, the first manner needs much more comparing times which means the first manner is low efficient.",
                "We propose a new detection procedure which uses comparisons with previous clusters to help find the most similar story in less comparing times, and the final new event decision is made according to the most similar story.",
                "Therefore, we can get both the accuracy of S-S type methods and the efficiency of S-C type methods.",
                "The new procedure creates a news indexing-tree dynamically, in which similar stories are put together to form a hierarchy of clusters.",
                "We index similar stories together by their common ancestor (a cluster node).",
                "Dissimilar stories are indexed in different clusters.",
                "When a story is coming, we use comparisons between the current story and previous hierarchical clusters to help find the most similar story which is useful for new event decision.",
                "After the new event decision is made, the current story is inserted to the indexing-tree for the following detection.",
                "The news indexing-tree is defined formally as follows: S-Tree = {r, NC , NS , E} where r is the root of S-Tree, NC is the set of all cluster nodes, NS is the set of all story nodes, and E is the set of all edges in S-Tree.",
                "We define a set of constraints for a S-Tree: ⅰ . , is an non-terminal node in the treeC i i N i∀ ∈ → ⅱ . , is a terminal node in the treeS i i N i∀ ∈ → ⅲ . , out degree of is at least 2C i i N i∀ ∈ → ⅳ . , is represented as the centroid of its desendantsC i i iN∀ ∈ → For a news story di, the comparison procedure and inserting procedure based on indexing-tree are defined as follows.",
                "An example is shown by Figure 1 and Figure 2.",
                "Figure 1.",
                "Comparison procedure Figure 2.",
                "Inserting procedure Comparison procedure: Step 1: compare di to all the direct child nodes of r and select λ nodes with highest similarities, e.g., C1 2 and C1 3 in Figure 1.",
                "Step 2: for each selected node in the last step, e.g.",
                "C1 2, compare di to all its direct child nodes, and select λ nodes with highest similarities, e.g.",
                "C2 2 and d8.",
                "Repeat step 2 for all non-terminal nodes.",
                "Step 3: record the terminal node with the highest similarty to di, e.g. s5, and the similarity value (0.20).",
                "Inserting di to the S-tree with r as root: Find the node n which is direct child of r in the path from r to the terminal node with highest similarity s, e.g.",
                "C1 2.",
                "If s is smaller than θ init+(h-1)δ , then add di to the tree as a direct child of r. Otherwise, if n is a terminal node, then create a cluster node instead of n, and add both n and di as its direct children; if n is an non-terminal node, then repeat this procedure and insert di to the sub-tree with n as root recursively.",
                "Here h is the length between n and the root of S-tree.",
                "The more the stories in a cluster similar to each other, the better the cluster represents the stories in it.",
                "Hence we add no constraints on the maximum of trees height and degree of a node.",
                "Therefore, we cannot give the complexity of this indexing-tree based procedure.",
                "But we will give the number of comparing times needed by the new procedure in our experiments in section7. 5.",
                "Term Reweighting Methods In this section, two term reweighting methods are proposed to improve NED accuracy.",
                "In the first method, a new way is explored for better using of cluster (topic) information.",
                "The second one finds a better way to make use of named entities based on news classification. 5.1 Term Reweighting Based on Distribution Distance TF-IDF is the most prevalent model used in information retrieval systems.",
                "The basic idea is that the fewer documents a term appears in, the more important the term is in discrimination of documents (relevant or not relevant to a query containing the term).",
                "Nevertheless, in TDT domain, we need to discriminate documents with regard to topics rather than queries.",
                "Intuitively, using cluster (topic) vectors to compare with subsequent news stories should outperform using story vectors.",
                "Unfortunately, the experimental results do not support this intuition [4][5].",
                "Based on observation on data, we find the reason is that a news topic usually contains many directly or indirectly related events, while they all have their own sub-subjects which are usually different with each other.",
                "Take the topic described in section 1 as an example, events like the explosion and salvage have very low similarities with events about criminal trial, therefore stories about trial would have low similarity with the topic vector built on its previous events.",
                "This section focuses on how to effectively make use of topic information and at the same time avoid the problem of content decentralization.",
                "At first, we classify terms into 5 classes to help analysis the needs of the modified model: Term class A: terms that occur frequently in the whole corpus, e.g., year and people.",
                "Terms of this class should be given low weights because they do not help much for topic discrimination.",
                "Term class B: terms that occur frequently within a news category, e.g., election, storm.",
                "They are useful to distinguish two stories in different news categories.",
                "However, they cannot provide information to determine whether two stories are on the same or different topics.",
                "In another words, term election and term storm are not helpful in differentiate two election campaigns and two storm disasters.",
                "Therefore, terms of this class should be assigned lower weights.",
                "Term class C: terms that occur frequently in a topic, and infrequently in other topics, e.g., the name of a crash plane, the name of a specific hurricane.",
                "News stories that belong to different topics rarely have overlap terms in this class.",
                "The more frequently a term appears in a topic, the more important the term is for a story belonging to the topic, therefore the term should be set higher weight.",
                "Term class D: terms that appear in a topic exclusively, but not frequently.",
                "For example, the name of a fireman who did very well in a salvage action, which may appears in only two or three stories but never appeared in other topics.",
                "Terms of this type should receive more weights than in TF-IDF model.",
                "However, since they are not popular in the topic, it is not appropriate to give them too high weights.",
                "Term class E: terms with low document frequency, and appear in different topics.",
                "Terms of this class should receive lower weights.",
                "Now we analyze whether TF-IDF model can give proper weights to the five classes of terms.",
                "Obviously, terms of class A are lowly weighted in TF-IDF model, which is conformable with the requirement described above.",
                "In TF-IDF model, terms of class B are highly dependant with the number of stories in a news class.",
                "TF-IDF model cannot provide low weights if the story containing the term belongs to a relative small news class.",
                "For a term of class C, the more frequently it appears in a topic, the less weight TFIDF model gives to it.",
                "This strongly conflicts with the requirement of terms in class C. For terms of class D, TF-IDF model gives them high weights correctly.",
                "But for terms of class E, TF-IDF model gives high weights to them which are not conformable with the requirement of low weights.",
                "To sum up, terms of class B, C, E cannot be properly weighted in TF-IDF model.",
                "So, we propose a modified model to resolve this problem.",
                "When θ init andθ new are set closely, we assume that most of the stories in a first-level cluster (a direct child node of root node) are on the same topic.",
                "Therefore, we make use of a first-level cluster to capture term distribution (df for all the terms within the cluster) within the topic dynamically.",
                "KL divergence of term distribution in a first-level cluster and the whole story set is used to adjust term weights:  ( , , ) * (1 * ( || )) ( , , ) ( , , ) * (1 * ( || )) cw tw cw tw w d D weight d t w KL P P weight d t w weight d t w KL P P γ γ ∈ + = +∑ (5) where ( ) ( ) ( ) ( ) 1,cw cw c c c c df w df w p y p y N N = = − (6) ( ) ( ) ( ) ( ) 1,t t tw tw t t df w df w p y p y N N = = − (7) where dfc(w) is the number of documents containing term w within cluster C, and Nc is the number of documents in cluster C, and Nt is the total number of documents that arrive before time step t. γ is a const parameter, now is manually set 3.",
                "KL divergence is defined as follows [17]: ( ) ( || ) ( ) log ( )x p x KL P Q p x q x = ∑ (8) The basic idea is: for a story in a topic, the more a term occurs within the topic, and the less it occurs in other topics, it should be assigned higher weights.",
                "Obviously, modified model can meet all the requirements of the five term classes listed above. 5.2 Term Reweighting Based on Term Type and Story Class Previous work found that some classes of news stories could achieve good improvements by giving extra weight to named entities.",
                "But we find that terms of different types should be given different amount of extra weight for different classes of news stories.",
                "We use open-NLP1 to recognize named entity types and part-ofspeech tags for terms that appear in news stories.",
                "Named entity types include person name, organization name, location name, date, time, money and percentage, and five POSs are selected: none (NN), verb (VB), adjective (JJ), adverb (RB) and cardinal number (CD).",
                "Statistical analysis shows topic-level discriminative terms types for different classes of stories.",
                "For the sake of convenience, named entity type and part-of-speech tags are uniformly called term type in subsequent sections.",
                "Determining whether two stories are about the same topic is a basic component for NED task.",
                "So at first we use 2 χ statistic to compute correlations between terms and topics.",
                "For a term t and a topic T, a contingence table is derived: Table 1.",
                "A 2×2 Contingence Table Doc Number belong to topic T not belong to topic T include t A B not include t C D The 2 χ statistic for a specific term t with respect to topic T is defined to be [16]: 2 2 ( , ) ( ) * ( ) ( ) * ( ) * ( ) * ( ) w T A B C D AD CB A C B D A B C D χ = + + + − + + + + (9) News topics for the TDT task are further classified into 11 rules of interpretations (ROIs) 2 .",
                "The ROI can be seen as a higher level class of stories.",
                "The average correlation between a term type and a topic ROI is computed as: 2 avg 2 ( , )( ( , ) )k m m km kT R w P w TP R p w T R P χ χ ∈ ∈ ∑ ∑（ , ）= 1 1 k=1…K, m=1…M (10) where K is the number of term types (set 12 constantly in the paper).",
                "M is the number news classes (ROIs, set 11 in the paper).",
                "Pk represents the set of all terms of type k, and Rm represents the set of all topics of class m, p(t,T) means the probability that t occurs in topic T. Because of limitation of space, only parts of the term types (9 term types) and parts of news classes (8 classes) are listed in table 2 with the average correlation values between them.",
                "The statistics is derived from labeled data in TDT2 corpus. (Results in table 2 are already normalized for convenience in comparison.)",
                "The statistics in table 2 indicates the usefulness of different term types in topic discrimination with respect to different news classes.",
                "We can see that, location name is the most useful term type for three news classes: Natural Disasters, Violence or War, Finances.",
                "And for three other categories Elections, Legal/Criminal Cases, Science and Discovery, person name is the most discriminative term type.",
                "For Scandals/Hearings, date is the most important information for topic discrimination.",
                "In addition, Legal/Criminal Cases and Finance topics have higher correlation with money terms, while Science and Discovery have higher correlation with percentage terms.",
                "Non-name terms are more stable for different classes. 1 . http://opennlp.sourceforge.net/ 2 . http://projects.ldc.upenn.edu/TDT3/Guide/label.html From the analysis of table 2, it is reasonable to adjust term weight according to their term type and the news class the story belongs to.",
                "New term weights are reweighted as follows: ( ) ( ) ( ) ( ) ( , , ) * ( , , ) ( , , ) * class d D type w T class d D type w w d weight d t w weight d t w weight d t w α α ∈ = ∑ (11) where type(w) represents the type of term w, and class(d) represents the class of story d, c kα is reweighting parameter for news class c and term type k. In the work, we just simply use statistics in table 2 as the reweighting parameters.",
                "Even thought using the statistics directly may not the best choice, we do not discuss how to automatically obtain the best parameters.",
                "We will try to use machine learning techniques to obtain the best parameters in the future work.",
                "In the work, we use BoosTexter [20] to classify all stories into one of the 11 ROIs.",
                "BoosTexter is a boosting based machine learning program, which creates a series of simple rules for building a classifier for text or attribute-value data.",
                "We use term weight generated using TF-IDF model as feature for story classification.",
                "We trained the model on the 12000 judged English stories in TDT2, and classify the rest of the stories in TDT2 and all stories in TDT3.",
                "Classification results are used for term reweighting in formula (11).",
                "Since the class labels of topic-off stories are not given in TDT datasets, we cannot give the classification accuracy here.",
                "Thus we do not discuss the effects of classification accuracy to NED performance in the paper. 6.",
                "EXPERIMENTAL SETUP 6.1 Datasets We used two LDC [18] datasets TDT2 and TDT3 for our experiments.",
                "TDT2 contains news stories from January to June 1998.",
                "It contains around 54,000 stories from sources like ABC, Associated Press, CNN, New York Times, Public Radio International, Voice of America etc.",
                "Only English stories in the collection were considered.",
                "TDT3 contains approximately 31,000 English stories collected from October to December 1998.",
                "In addition to the sources used in TDT2, it also contains stories from NBC and MSNBC TV broadcasts.",
                "We used transcribed versions of the TV and radio broadcasts besides textual news.",
                "TDT2 dataset is labeled with about 100 topics, and approximately 12,000 English stories belong to at least one of these topics.",
                "TDT3 dataset is labeled with about 120 topics, and approximately 8000 English stories belong to at least one of these topics.",
                "All the topics are classified into 11 Rules of Interpretation: (1)Elections, (2)Scandals/Hearings, (3)Legal/Criminal Cases, (4)Natural Disasters, (5)Accidents, (6)Ongoing Violence or War, (7)Science and Discovery News, (8)Finance, (9)New Law, (10)Sports News, (11)MISC.",
                "News. 6.2 Evaluation Metric TDT uses a cost function CDet that combines the probabilities of missing a new story and a false alarm [19]: * * * *Det Miss Miss Target FA FA NontargetC C P P C P P= + (12) Table 2.",
                "Average correlation between term types and news classes where CMiss means the cost of missing a new story, PMiss means the probability of missing a new story, and PTarget means the probability of seeing a new story in the data; CFA means the cost of a false alarm, PFA means the probability of a false alarm, and PNontarget means the probability of seeing an old story.",
                "The cost CDet is normalized such that a perfect system scores 0 and a trivial system, which is the better one of mark all stories as new or old, scores 1: ( ( * , * ) ) Det Det Miss Target FA Nontarget C Norm C min C P C P = (13) New event detection system gives two outputs for each story.",
                "The first part is yes or no indicating whether the story triggers a new event or not.",
                "The second part is a score indicating confidence of the first decision.",
                "Confidence scores can be used to plot DET curve, i.e., curves that plot false alarm vs. miss probabilities.",
                "Minimum normalized cost can be determined if optimal threshold on the score were chosen. 7.",
                "EXPERIMENTAL RESULTS 7.1 Main Results To test the approaches proposed in the model, we implemented and tested five systems: System-1: this system is used as baseline.",
                "It is implemented based on the basic model described in section 3, i.e., using incremental TF-IDF model to generate term weights, and using Hellinger distance to compute document similarity.",
                "Similarity score normalization is also employed [8].",
                "S-S detection procedure is used.",
                "System-2: this system is the same as system-1 except that S-C detection procedure is used.",
                "System-3: this system is the same as system-1 except that it uses the new detection procedure which is based on indexing-tree.",
                "System-4: implemented based on the approach presented in section 5.1, i.e., terms are reweighted according to the distance between term distributions in a cluster and all stories.",
                "The new detection procedure is used.",
                "System-5: implemented based on the approach presented in section 5.2, i.e., terms of different types are reweighted according to news class using trained parameters.",
                "The new detection procedure is used.",
                "The following are some other NED systems: System-6: [21] for each pair of stories, it computes three similarity values for named entity, non-named entity and all terms respectively.",
                "And employ Support Vector Machine to predict new or old using the similarity values as features.",
                "System-7: [8] it extended a basic incremental TF-IDF model to include source-specific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, etc.",
                "System-8: [13] it split document representation into two parts: named entities and non-named entities, and choose one effective part for each news class.",
                "Table 3 and table 4 show topic-weighted normalized costs and comparing times on TDT2 and TDT3 datasets respectively.",
                "Since no heldout data set for fine-tuning the threshold θ new was available for experiments on TDT2, we only report minimum normalized costs for our systems in table 3.",
                "System-5 outperforms all other systems including system-6, and it performs only 2.78e+8 comparing times in detection procedure which is only 13.4% of system-1.",
                "Table 3.",
                "NED results on TDT2 Systems Min Norm(CDet) Cmp times System-1 0.5749 2.08e+9 System-2① 0.6673 3.77e+8 System-3② 0.5765 2.81e+8 System-4② 0.5431 2.99e+8 System-5② 0.5089 2.78e+8 System-6 0.5300 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 When evaluating on the normalized costs on TDT3, we use the optimal thresholds obtained from TDT2 data set for all systems.",
                "System-2 reduces comparing times to 1.29e+9 which is just 18.3% of system-1, but at the same time it also gets a deteriorated minimum normalized cost which is 0.0499 higher than system-1.",
                "System-3 uses the new detection procedure based on news indexing-tree.",
                "It requires even less comparing times than system-2.",
                "This is because story-story comparisons usually yield greater similarities than story-cluster ones, so stories tend to be combined Location Person Date Organization Money Percentage NN JJ CD Elections 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 Scandals/Hearings 0.66 0.62 0.28 1 0.11 0.02 0.27 0.13 0.05 Legal/Criminal Cases 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 Natural Disasters 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 Violence or War 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 Science and Discovery 0.11 1 0.01 0.22 0.08 0.12 0.19 0.08 0.03 Finances 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 Sports 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 together in system-3.",
                "And system-3 is basically equivalent to system-1 in accuracy results.",
                "System-4 adjusts term weights based on the distance of term distributions between the whole corpus and cluster story set, yielding a good improvement by 0.0468 compared to system-1.",
                "The best system (system-5) has a minimum normalized cost 0.5012, which is 0.0797 better than system-1, and also better than any other results previously reported for this dataset [8, 13].",
                "Further more, system-5 only needs 1.05e+8 comparing times which is 14.9% of system-1.",
                "Table 4.",
                "NED results on TDT3 Systems Norm(CDet) Min Norm(CDet) Cmp times System-1 0.6159 0.5809 7.04e+8 System-2① 0.6493 0.6308 1.29e+8 System-3② 0.6197 0.5868 1.03e+8 System-4② 0.5601 0.5341 1.03e+8 System-5② 0.5413 0.5012 1.05e+8 System-7 -- 0.5783 -System-8 -- 0.5229 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 Figure5 shows the five DET curves for our systems on data set TDT3.",
                "System-5 achieves the minimum cost at a false alarm rate of 0.0157 and a miss rate of 0.4310.",
                "We can observe that System4 and System-5 obtain lower miss probability at regions of low false alarm probabilities.",
                "The hypothesis is that, more weight value is transferred to key terms of topics from non-key terms.",
                "Similarity score between two stories belonging to different topics are lower than before, because their overlapping terms are usually not key terms of their topics. 7.2 Parameter selection for indexing-tree detection Figure 3 shows the minimum normalized costs obtained by system-3 on TDT3 using different parameters.",
                "Theθ init parameter is tested on six values spanning from 0.03 to 0.18.",
                "And the λ parameter is tested on four values 1, 2, 3 and 4.",
                "We can see that, whenθ init is set to 0.12, which is the closest one toθ new, the costs are lower than others.",
                "This is easy to explain, because when stories belonging to the same topic are put in a cluster, it is more reasonable for the cluster to represent the stories in it.",
                "When parameter λ is set to 3 or 4, the costs are better than other cases, but there is no much difference between 3 and 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ MinCost 0.6 0.65 0.7 0.75 0.8 0.85 0.9 Figure 3.",
                "Min Cost on TDT3 (δ =0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ Comparingtimes 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 Figure 4.",
                "Comparing times on TDT3 (δ =0.15) Figure 4 gives the comparing times used by system-3 on TDT3 with the same parameters as figure 3.",
                "The comparing times are strongly dependent onθ init.",
                "Because the greaterθ init is, the less stories combined together, the more comparing times are needed for new event decision.",
                "So we useθ init =0.13,λ =3,δ =0.15 for system-3, 4, and 5.",
                "In this parameter setting, we can get both low minimum normalized costs and less comparing times. 8.",
                "CONCLUSION We have proposed a news indexing-tree based detection procedure in our model.",
                "It reduces comparing times to about one seventh of traditional method without hurting NED accuracy.",
                "We also have presented two extensions to the basic TF-IDF model.",
                "The first extension is made by adjust term weights based on term distributions between the whole corpus and a cluster story set.",
                "And the second extension to basic TF-IDF model is better use of term types (named entities types and part-of-speed) according to news categories.",
                "Our experimental results on TDT2 and TDT3 datasets show that both of the two extensions contribute significantly to improvement in accuracy.",
                "We did not consider news time information as a clue for NED task, since most of the topics last for a long time and TDT data sets only span for a relative short period (no more than 6 months).",
                "For the future work, we want to collect news set which span for a longer period from internet, and integrate time information in NED task.",
                "Since topic is a relative coarse-grained news cluster, we also want to refine cluster granularity to event-level, and identify different events and their relations within a topic.",
                "Acknowledgments This work is supported by the National Natural Science Foundation of China under Grant No. 90604025.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] In Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. .01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90 1 2 5 10 20 40 60 80 90 False Alarm Probability (in %) MissProbability(in%) SYSTEM1 Topic Weighted Curve SYSTEM1 Min Norm(Cost) SYSTEM2 Topic Weighted Curve SYSTEM2 Min Norm(Cost) SYSTEM3 Topic Weighted Curve SYSTEM3 Min Norm(Cost) SYSTEM4 Topic Weighted Curve SYSTEM4 Min Norm(Cost) SYSTEM5 Topic Weighted Curve SYSTEM5 Min Norm(Cost) Random Performance Figure 5.",
                "DET curves on TDT3 [3] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B.T.",
                "Archibald, and X. Liu.",
                "Learning Approaches for Detecting and Tracking News Events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), 1999, 32-43. [4] Y. Yang, T. Pierce, and J. Carbonell.",
                "A Study on Retrospective and On-line Event Detection.",
                "In Proceedings of SIGIR-98, Melbourne, Australia, 1998, 28-36. [5] J. Allan, V. Lavrenko, D. Malin, and R. Swan.",
                "Detections, Bounds, and Timelines: Umass and tdt-3.",
                "In Proceedings of Topic Detection and Tracking Workshop (TDT-3), Vienna, VA, 2000, 167-174. [6] R. Papka and J. Allan.",
                "On-line New Event Detection Using Single Pass Clustering TITLE2:.",
                "Technical Report UM-CS1998-021, 1998. [7] W. Lam, H. Meng, K. Wong, and J.",
                "Yen.",
                "Using Contextual Analysis for News Event Detection.",
                "International Journal on Intelligent Systems, 2001, 525-546. [8] B. Thorsten, C. Francine, and F. Ayman.",
                "A System for New Event Detection.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2003, 330-337. [9] S. Nicola and C. Joe.",
                "Combining Semantic and Syntactic Document Classifiers to Improve First Story Detection.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2001, 424425. [10] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topicconditioned Novelty Detection.",
                "In Proceedings of the 8th ACM SIGKDD International Conference, ACM Press. 2002, 688-693. [11] M. Juha, A.M. Helena, and S. Marko.",
                "Applying Semantic Classes in Event Detection and Tracking.",
                "In Proceedings of International Conference on Natural Language Processing (ICON 2002), 2002, pages 175-183. [12] M. Juha, A.M. Helena, and S. Marko.",
                "Simple Semantics in Topic Detection and Tracking.",
                "Information Retrieval, 7(3-4): 2004, 347-368. [13] K. Giridhar and J. Allan.",
                "Text Classification and Named Entities for New Event Detection.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2004, 297-304. [14] J. P. Callan, W. B. Croft, and S. M. Harding.",
                "The INQUERY Retrieval System.",
                "In Proceedings of DEXA-92, 3rd International Conference on Database and Expert Systems Applications, 1992, 78-83. [15] R. Krovetz.",
                "Viewing Morphology as An Inference Process.",
                "In Proceedings of ACM SIGIR93, 1993, 61-81. [16] Y. Yang and J. Pedersen.",
                "A Comparative Study on Feature Selection in Text Categorization.",
                "In J. D. H. Fisher, editor, The Fourteenth International Conference on Machine Learning (ICML97), Morgan Kaufmann, 1997, 412-420. [17] T. M. Cover, and J.A.",
                "Thomas.",
                "Elements of Information Theory.",
                "Wiley. 1991. [18] The linguistic data consortium, http://www.ldc,upenn.edu/. [19] The 2001 TDT task definition and evaluation plan, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm. [20] R. E. Schapire and Y.",
                "Singer.",
                "Boostexter: A Boosting-based System for Text Categorization.",
                "In Machine Learning 39(2/3):1, Kluwer Academic Publishers, 2000, 35-168. [21] K. Giridhar and J. Allan. 2005.",
                "Using Names and Topics for New Event Detection.",
                "In Proceedings of Human Technology Conference and Conference on Empirical Methods in Natural Language, Vancouver, 2005, 121-128"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Nueva detección de eventos basada en el árbol de indexación y la entidad nombrada Zhang Kuo tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn li Juan zi tsinghua University Beijing, 100084, China 86-10-62781414141 LiJzzze Beijing, 100084, China 86-10-62781414141@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn Resumen de la detección de nuevos eventos (NED)"
            ],
            "translated_text": "",
            "candidates": [
                "a la detección de uno o múltiples \"transmisiones de noticias \", lo cual se informa en un nuevo evento (es decir, transmisiones de noticias",
                "transmisiones de noticias "
            ],
            "error": []
        },
        "news story stream": {
            "translated_key": "transmisión de noticias",
            "is_in_text": true,
            "original_annotated_sentences": [
                "New Event Detection Based on Indexing-tree and Named Entity Zhang Kuo Tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn Li Juan Zi Tsinghua University Beijing, 100084, China 86-10-62781461 ljz@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn ABSTRACT New Event Detection (NED) aims at detecting from one or multiple streams of news stories that which one is reported on a new event (i.e.",
                "not reported previously).",
                "With the overwhelming volume of news available today, there is an increasing need for a NED system which is able to detect new events more efficiently and accurately.",
                "In this paper we propose a new NED model to speed up the NED task by using news indexing-tree dynamically.",
                "Moreover, based on the observation that terms of different types have different effects for NED task, two term reweighting approaches are proposed to improve NED accuracy.",
                "In the first approach, we propose to adjust term weights dynamically based on previous story clusters and in the second approach, we propose to employ statistics on training data to learn the named entity reweighting model for each class of stories.",
                "Experimental results on two Linguistic Data Consortium (LDC) datasets TDT2 and TDT3 show that the proposed model can improve both efficiency and accuracy of NED task significantly, compared to the baseline system and other existing systems.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Search and Retrieval; H.4.2 [Information Systems Applications]: Types of Systemsdecision support.",
                "General Terms Algorithms, Performance, Experimentation 1.",
                "INTRODUCTION Topic Detection and Tracking (TDT) program aims to develop techniques which can effectively organize, search and structure news text materials from a variety of newswire and broadcast media [1].",
                "New Event Detection (NED) is one of the five tasks in TDT.",
                "It is the task of online identification of the earliest report for each topic as soon as that report arrives in the sequence of documents.",
                "A Topic is defined as a seminal event or activity, along with directly related events and activities [2].",
                "An Event is defined as something (non-trivial) happening in a certain place at a certain time [3].",
                "For instance, when a bomb explodes in a building, the exploding is the seminal event that triggers the topic, and other stories on the same topic would be those discussing salvaging efforts, the search for perpetrators, arrests and trial and so on.",
                "Useful news information is usually buried in a mass of data generated everyday.",
                "Therefore, NED systems are very useful for people who need to detect novel information from real-time news stream.",
                "These real-life needs often occur in domains like financial markets, news analysis, and intelligence gathering.",
                "In most of state-of-the-art (currently) NED systems, each news story on hand is compared to all the previous received stories.",
                "If all the similarities between them do not exceed a threshold, then the story triggers a new event.",
                "They are usually in the form of cosine similarity or Hellinger similarity metric.",
                "The core problem of NED is to identify whether two stories are on the same topic.",
                "Obviously, these systems cannot take advantage of topic information.",
                "Further more, it is not acceptable in real applications because of the large amount of computation required in the NED process.",
                "Other systems organize previous stories into clusters (each cluster corresponds to a topic), and new story is compared to the previous clusters instead of stories.",
                "This manner can reduce comparing times significantly.",
                "Nevertheless, it has been proved that this manner is less accurate [4, 5].",
                "This is because sometimes stories within a topic drift far away from each other, which could lead low similarity between a story and its topic.",
                "On the other hand, some proposed NED systems tried to improve accuracy by making better use of named entities [10, 11, 12, 13].",
                "However, none of the systems have considered that terms of different types (e.g.",
                "Noun, Verb or Person name) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "For example, the names of election candidates (Person name) are very important for stories of election class; the locations (Location name) where accidents happened are important for stories of accidents class.",
                "So, in NED, there still exist following three problems to be investigated: (1) How to speed up the detection procedure while do not decrease the detection accuracy? (2) How to make good use of cluster (topic) information to improve accuracy? (3) How to obtain better news story representation by better understanding of named entities.",
                "Driven by these problems, we have proposed three approaches in this paper. (1)To make the detection procedure faster, we propose a new NED procedure based on news indexing-tree created dynamically.",
                "Story indexing-tree is created by assembling similar stories together to form news clusters in different hierarchies according to their values of similarity.",
                "Comparisons between current story and previous clusters could help find the most similar story in less comparing times.",
                "The new procedure can reduce the amount of comparing times without hurting accuracy. (2)We use the clusters of the first floor in the indexing-tree as news topics, in which term weights are adjusted dynamically according to term distribution in the clusters.",
                "In this approach, cluster (topic) information is used properly, so the problem of theme decentralization is avoided. (3)Based on observations on the statistics obtained from training data, we found that terms of different types (e.g.",
                "Noun and Verb) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "And we propose to use statistics to optimize the weights of the terms of different types in a story according to the news class that the story belongs to.",
                "On TDT3 dataset, the new NED model just uses 14.9% comparing times of the basic model, while its minimum normalized cost is 0.5012, which is 0.0797 better than the basic model, and also better than any other results previously reported for this dataset [8, 13].",
                "The rest of the paper is organized as follows.",
                "We start off this paper by summarizing the previous work in NED in section 2.",
                "Section 3 presents the basic model for NED that most current systems use.",
                "Section 4 describes our new detection procedure based on news indexing-tree.",
                "In section 5, two term reweighting methods are proposed to improve NED accuracy.",
                "Section 6 gives our experimental data and evaluation metrics.",
                "We finally wrap up with the experimental results in Section 7, and the conclusions and future work in Section 8. 2.",
                "RELATED WORK Papka et al. proposed Single-Pass clustering on NED [6].",
                "When a new story was encountered, it was processed immediately to extract term features and a query representation of the storys content is built up.",
                "Then it was compared with all the previous queries.",
                "If the document did not trigger any queries by exceeding a threshold, it was marked as a new event.",
                "Lam et al build up previous query representations of story clusters, each of which corresponds to a topic [7].",
                "In this manner comparisons happen between stories and clusters.",
                "Recent years, most work focus on proposing better methods on comparison of stories and document representation.",
                "Brants et al. [8] extended a basic incremental TF-IDF model to include sourcespecific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, term reweighting based on inverse event frequencies, and segmentation of documents.",
                "Good improvements on TDT bench-marks were shown.",
                "Stokes et al. [9] utilized a combination of evidence from two distinct representations of a documents content.",
                "One of the representations was the usual free text vector, the other made use of lexical chains (created using WordNet) to build another term vector.",
                "Then the two representations are combined in a linear fashion.",
                "A marginal increase in effectiveness was achieved when the combined representation was used.",
                "Some efforts have been done on how to utilize named entities to improve NED.",
                "Yang et al. gave location named entities four times weight than other terms and named entities [10].",
                "DOREMI research group combined semantic similarities of person names, location names and time together with textual similarity [11][12].",
                "UMass [13] research group split document representation into two parts: named entities and non-named entities.",
                "And it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation.",
                "Both [10] and [13] used text categorization technique to classify news stories in advance.",
                "In [13] news stories are classified automatically at first, and then test sensitivities of names and non-name terms for NED for each class.",
                "In [10] frequent terms for each class are removed from document representation.",
                "For example, word election does not help identify different elections.",
                "In their work, effectiveness of different kinds of names (or terms with different POS) for NED in different news classes are not investigated.",
                "We use statistical analysis to reveal the fact and use it to improve NED performance. 3.",
                "BASIC MODEL In this section, we present the basic New Event Detection model which is similar to what most current systems apply.",
                "Then, we propose our new model by extending the basic model.",
                "New Event Detection systems use <br>news story stream</br> as input, in which stories are strictly time-ordered.",
                "Only previously received stories are available when dealing with current story.",
                "The output is a decision for whether the current story is on a new event or not and the confidence of the decision.",
                "Usually, a NED model consists of three parts: story representation, similarity calculation and detection procedure. 3.1 Story Representation Preprocessing is needed before generating story representation.",
                "For preprocessing, we tokenize words, recognize abbreviations, normalize abbreviations, add part-of-speech tags, remove stopwords included in the stop list used in InQuery [14], replace words with their stems using K-stem algorithm[15], and then generate word vector for each news story.",
                "We use incremental TF-IDF model for term weight calculation [4].",
                "In a TF-IDF model, term frequency in a news document is weighted by the inverse document frequency, which is generated from training corpus.",
                "When a new term occurs in testing process, there are two solutions: simply ignore the new term or set df of the term as a small const (e.g. df = 1).",
                "The new term receives too low weight in the first solution (0) and too high weight in the second solution.",
                "In incremental TF-IDF model, document frequencies are updated dynamically in each time step t: 1( ) ( ) ( )t t D tdf w df w df w−= + (1) where Dt represents news story set received in time t, and dfDt(w) means the number of documents that term w occurs in, and dft(w) means the total number of documents that term w occurs in before time t. In this work, each time window includes 50 news stories.",
                "Thus, each story d received in t is represented as follows: 1 2{ ( , , ), ( , , ),..., ( , , )}nd weight d t w weight d t w weight d t w→ where n means the number of distinct terms in story d, and ( , , )weight d t w means the weight of term w in story d at time t: log( ( , ) 1) log(( 1) /( ( ) 0.5)) ( , , ) log( ( , ) 1) log(( 1) /( ( ) 0.5)) t t t t w d tf d w N df w weight d t w tf d w N df w ∈ + + + = + + +∑ (2) where Nt means the total number of news stories before time t, and tf(d,w) means how many times term w occurs in news story d. 3.2 Similarity Calculation We use Hellinger distance for the calculation of similarity between two stories, for two stories d and d at time t, their similarity is defined as follows: , ( , , ) ( , , ) * ( , , ) w d d sim d d t weight d t w weight d t w ∈ = ∑ (3) 3.3 Detection Procedure For each story d received in time step t, the value ( ) ( ) ( ) ( ( , , )) time d time d n d max sim d d t < = (4) is a score used to determine whether d is a story about a new topic and at the same time is an indication of the confidence in our decision [8]. time(d) means the publication time of story d. If the score exceeds the thresholdθ new, then there exists a sufficiently similar document, thus d is a old story, otherwise, there is no sufficiently similar previous document, thus d is an new story. 4.",
                "New NED Procedure Traditional NED systems can be classified into two main types on the aspect of detection procedure: (1) S-S type, in which the story on hand is compared to each story received previously, and use the highest similarity to determine whether current story is about a new event; (2) S-C type, in which the story on hand is compared to all previous clusters each of which representing a topic, and the highest similarity is used for final decision for current story.",
                "If the highest similarity exceeds thresholdθ new, then it is an old story, and put it into the most similar cluster; otherwise it is a new story and create a new cluster.",
                "Previous work show that the first manner is more accurate than the second one [4][5].",
                "Since sometimes stories within a topic drift far away from each other, a story may have very low similarity with its topic.",
                "So using similarities between stories for determining new story is better than using similarities between story and clusters.",
                "Nevertheless, the first manner needs much more comparing times which means the first manner is low efficient.",
                "We propose a new detection procedure which uses comparisons with previous clusters to help find the most similar story in less comparing times, and the final new event decision is made according to the most similar story.",
                "Therefore, we can get both the accuracy of S-S type methods and the efficiency of S-C type methods.",
                "The new procedure creates a news indexing-tree dynamically, in which similar stories are put together to form a hierarchy of clusters.",
                "We index similar stories together by their common ancestor (a cluster node).",
                "Dissimilar stories are indexed in different clusters.",
                "When a story is coming, we use comparisons between the current story and previous hierarchical clusters to help find the most similar story which is useful for new event decision.",
                "After the new event decision is made, the current story is inserted to the indexing-tree for the following detection.",
                "The news indexing-tree is defined formally as follows: S-Tree = {r, NC , NS , E} where r is the root of S-Tree, NC is the set of all cluster nodes, NS is the set of all story nodes, and E is the set of all edges in S-Tree.",
                "We define a set of constraints for a S-Tree: ⅰ . , is an non-terminal node in the treeC i i N i∀ ∈ → ⅱ . , is a terminal node in the treeS i i N i∀ ∈ → ⅲ . , out degree of is at least 2C i i N i∀ ∈ → ⅳ . , is represented as the centroid of its desendantsC i i iN∀ ∈ → For a news story di, the comparison procedure and inserting procedure based on indexing-tree are defined as follows.",
                "An example is shown by Figure 1 and Figure 2.",
                "Figure 1.",
                "Comparison procedure Figure 2.",
                "Inserting procedure Comparison procedure: Step 1: compare di to all the direct child nodes of r and select λ nodes with highest similarities, e.g., C1 2 and C1 3 in Figure 1.",
                "Step 2: for each selected node in the last step, e.g.",
                "C1 2, compare di to all its direct child nodes, and select λ nodes with highest similarities, e.g.",
                "C2 2 and d8.",
                "Repeat step 2 for all non-terminal nodes.",
                "Step 3: record the terminal node with the highest similarty to di, e.g. s5, and the similarity value (0.20).",
                "Inserting di to the S-tree with r as root: Find the node n which is direct child of r in the path from r to the terminal node with highest similarity s, e.g.",
                "C1 2.",
                "If s is smaller than θ init+(h-1)δ , then add di to the tree as a direct child of r. Otherwise, if n is a terminal node, then create a cluster node instead of n, and add both n and di as its direct children; if n is an non-terminal node, then repeat this procedure and insert di to the sub-tree with n as root recursively.",
                "Here h is the length between n and the root of S-tree.",
                "The more the stories in a cluster similar to each other, the better the cluster represents the stories in it.",
                "Hence we add no constraints on the maximum of trees height and degree of a node.",
                "Therefore, we cannot give the complexity of this indexing-tree based procedure.",
                "But we will give the number of comparing times needed by the new procedure in our experiments in section7. 5.",
                "Term Reweighting Methods In this section, two term reweighting methods are proposed to improve NED accuracy.",
                "In the first method, a new way is explored for better using of cluster (topic) information.",
                "The second one finds a better way to make use of named entities based on news classification. 5.1 Term Reweighting Based on Distribution Distance TF-IDF is the most prevalent model used in information retrieval systems.",
                "The basic idea is that the fewer documents a term appears in, the more important the term is in discrimination of documents (relevant or not relevant to a query containing the term).",
                "Nevertheless, in TDT domain, we need to discriminate documents with regard to topics rather than queries.",
                "Intuitively, using cluster (topic) vectors to compare with subsequent news stories should outperform using story vectors.",
                "Unfortunately, the experimental results do not support this intuition [4][5].",
                "Based on observation on data, we find the reason is that a news topic usually contains many directly or indirectly related events, while they all have their own sub-subjects which are usually different with each other.",
                "Take the topic described in section 1 as an example, events like the explosion and salvage have very low similarities with events about criminal trial, therefore stories about trial would have low similarity with the topic vector built on its previous events.",
                "This section focuses on how to effectively make use of topic information and at the same time avoid the problem of content decentralization.",
                "At first, we classify terms into 5 classes to help analysis the needs of the modified model: Term class A: terms that occur frequently in the whole corpus, e.g., year and people.",
                "Terms of this class should be given low weights because they do not help much for topic discrimination.",
                "Term class B: terms that occur frequently within a news category, e.g., election, storm.",
                "They are useful to distinguish two stories in different news categories.",
                "However, they cannot provide information to determine whether two stories are on the same or different topics.",
                "In another words, term election and term storm are not helpful in differentiate two election campaigns and two storm disasters.",
                "Therefore, terms of this class should be assigned lower weights.",
                "Term class C: terms that occur frequently in a topic, and infrequently in other topics, e.g., the name of a crash plane, the name of a specific hurricane.",
                "News stories that belong to different topics rarely have overlap terms in this class.",
                "The more frequently a term appears in a topic, the more important the term is for a story belonging to the topic, therefore the term should be set higher weight.",
                "Term class D: terms that appear in a topic exclusively, but not frequently.",
                "For example, the name of a fireman who did very well in a salvage action, which may appears in only two or three stories but never appeared in other topics.",
                "Terms of this type should receive more weights than in TF-IDF model.",
                "However, since they are not popular in the topic, it is not appropriate to give them too high weights.",
                "Term class E: terms with low document frequency, and appear in different topics.",
                "Terms of this class should receive lower weights.",
                "Now we analyze whether TF-IDF model can give proper weights to the five classes of terms.",
                "Obviously, terms of class A are lowly weighted in TF-IDF model, which is conformable with the requirement described above.",
                "In TF-IDF model, terms of class B are highly dependant with the number of stories in a news class.",
                "TF-IDF model cannot provide low weights if the story containing the term belongs to a relative small news class.",
                "For a term of class C, the more frequently it appears in a topic, the less weight TFIDF model gives to it.",
                "This strongly conflicts with the requirement of terms in class C. For terms of class D, TF-IDF model gives them high weights correctly.",
                "But for terms of class E, TF-IDF model gives high weights to them which are not conformable with the requirement of low weights.",
                "To sum up, terms of class B, C, E cannot be properly weighted in TF-IDF model.",
                "So, we propose a modified model to resolve this problem.",
                "When θ init andθ new are set closely, we assume that most of the stories in a first-level cluster (a direct child node of root node) are on the same topic.",
                "Therefore, we make use of a first-level cluster to capture term distribution (df for all the terms within the cluster) within the topic dynamically.",
                "KL divergence of term distribution in a first-level cluster and the whole story set is used to adjust term weights:  ( , , ) * (1 * ( || )) ( , , ) ( , , ) * (1 * ( || )) cw tw cw tw w d D weight d t w KL P P weight d t w weight d t w KL P P γ γ ∈ + = +∑ (5) where ( ) ( ) ( ) ( ) 1,cw cw c c c c df w df w p y p y N N = = − (6) ( ) ( ) ( ) ( ) 1,t t tw tw t t df w df w p y p y N N = = − (7) where dfc(w) is the number of documents containing term w within cluster C, and Nc is the number of documents in cluster C, and Nt is the total number of documents that arrive before time step t. γ is a const parameter, now is manually set 3.",
                "KL divergence is defined as follows [17]: ( ) ( || ) ( ) log ( )x p x KL P Q p x q x = ∑ (8) The basic idea is: for a story in a topic, the more a term occurs within the topic, and the less it occurs in other topics, it should be assigned higher weights.",
                "Obviously, modified model can meet all the requirements of the five term classes listed above. 5.2 Term Reweighting Based on Term Type and Story Class Previous work found that some classes of news stories could achieve good improvements by giving extra weight to named entities.",
                "But we find that terms of different types should be given different amount of extra weight for different classes of news stories.",
                "We use open-NLP1 to recognize named entity types and part-ofspeech tags for terms that appear in news stories.",
                "Named entity types include person name, organization name, location name, date, time, money and percentage, and five POSs are selected: none (NN), verb (VB), adjective (JJ), adverb (RB) and cardinal number (CD).",
                "Statistical analysis shows topic-level discriminative terms types for different classes of stories.",
                "For the sake of convenience, named entity type and part-of-speech tags are uniformly called term type in subsequent sections.",
                "Determining whether two stories are about the same topic is a basic component for NED task.",
                "So at first we use 2 χ statistic to compute correlations between terms and topics.",
                "For a term t and a topic T, a contingence table is derived: Table 1.",
                "A 2×2 Contingence Table Doc Number belong to topic T not belong to topic T include t A B not include t C D The 2 χ statistic for a specific term t with respect to topic T is defined to be [16]: 2 2 ( , ) ( ) * ( ) ( ) * ( ) * ( ) * ( ) w T A B C D AD CB A C B D A B C D χ = + + + − + + + + (9) News topics for the TDT task are further classified into 11 rules of interpretations (ROIs) 2 .",
                "The ROI can be seen as a higher level class of stories.",
                "The average correlation between a term type and a topic ROI is computed as: 2 avg 2 ( , )( ( , ) )k m m km kT R w P w TP R p w T R P χ χ ∈ ∈ ∑ ∑（ , ）= 1 1 k=1…K, m=1…M (10) where K is the number of term types (set 12 constantly in the paper).",
                "M is the number news classes (ROIs, set 11 in the paper).",
                "Pk represents the set of all terms of type k, and Rm represents the set of all topics of class m, p(t,T) means the probability that t occurs in topic T. Because of limitation of space, only parts of the term types (9 term types) and parts of news classes (8 classes) are listed in table 2 with the average correlation values between them.",
                "The statistics is derived from labeled data in TDT2 corpus. (Results in table 2 are already normalized for convenience in comparison.)",
                "The statistics in table 2 indicates the usefulness of different term types in topic discrimination with respect to different news classes.",
                "We can see that, location name is the most useful term type for three news classes: Natural Disasters, Violence or War, Finances.",
                "And for three other categories Elections, Legal/Criminal Cases, Science and Discovery, person name is the most discriminative term type.",
                "For Scandals/Hearings, date is the most important information for topic discrimination.",
                "In addition, Legal/Criminal Cases and Finance topics have higher correlation with money terms, while Science and Discovery have higher correlation with percentage terms.",
                "Non-name terms are more stable for different classes. 1 . http://opennlp.sourceforge.net/ 2 . http://projects.ldc.upenn.edu/TDT3/Guide/label.html From the analysis of table 2, it is reasonable to adjust term weight according to their term type and the news class the story belongs to.",
                "New term weights are reweighted as follows: ( ) ( ) ( ) ( ) ( , , ) * ( , , ) ( , , ) * class d D type w T class d D type w w d weight d t w weight d t w weight d t w α α ∈ = ∑ (11) where type(w) represents the type of term w, and class(d) represents the class of story d, c kα is reweighting parameter for news class c and term type k. In the work, we just simply use statistics in table 2 as the reweighting parameters.",
                "Even thought using the statistics directly may not the best choice, we do not discuss how to automatically obtain the best parameters.",
                "We will try to use machine learning techniques to obtain the best parameters in the future work.",
                "In the work, we use BoosTexter [20] to classify all stories into one of the 11 ROIs.",
                "BoosTexter is a boosting based machine learning program, which creates a series of simple rules for building a classifier for text or attribute-value data.",
                "We use term weight generated using TF-IDF model as feature for story classification.",
                "We trained the model on the 12000 judged English stories in TDT2, and classify the rest of the stories in TDT2 and all stories in TDT3.",
                "Classification results are used for term reweighting in formula (11).",
                "Since the class labels of topic-off stories are not given in TDT datasets, we cannot give the classification accuracy here.",
                "Thus we do not discuss the effects of classification accuracy to NED performance in the paper. 6.",
                "EXPERIMENTAL SETUP 6.1 Datasets We used two LDC [18] datasets TDT2 and TDT3 for our experiments.",
                "TDT2 contains news stories from January to June 1998.",
                "It contains around 54,000 stories from sources like ABC, Associated Press, CNN, New York Times, Public Radio International, Voice of America etc.",
                "Only English stories in the collection were considered.",
                "TDT3 contains approximately 31,000 English stories collected from October to December 1998.",
                "In addition to the sources used in TDT2, it also contains stories from NBC and MSNBC TV broadcasts.",
                "We used transcribed versions of the TV and radio broadcasts besides textual news.",
                "TDT2 dataset is labeled with about 100 topics, and approximately 12,000 English stories belong to at least one of these topics.",
                "TDT3 dataset is labeled with about 120 topics, and approximately 8000 English stories belong to at least one of these topics.",
                "All the topics are classified into 11 Rules of Interpretation: (1)Elections, (2)Scandals/Hearings, (3)Legal/Criminal Cases, (4)Natural Disasters, (5)Accidents, (6)Ongoing Violence or War, (7)Science and Discovery News, (8)Finance, (9)New Law, (10)Sports News, (11)MISC.",
                "News. 6.2 Evaluation Metric TDT uses a cost function CDet that combines the probabilities of missing a new story and a false alarm [19]: * * * *Det Miss Miss Target FA FA NontargetC C P P C P P= + (12) Table 2.",
                "Average correlation between term types and news classes where CMiss means the cost of missing a new story, PMiss means the probability of missing a new story, and PTarget means the probability of seeing a new story in the data; CFA means the cost of a false alarm, PFA means the probability of a false alarm, and PNontarget means the probability of seeing an old story.",
                "The cost CDet is normalized such that a perfect system scores 0 and a trivial system, which is the better one of mark all stories as new or old, scores 1: ( ( * , * ) ) Det Det Miss Target FA Nontarget C Norm C min C P C P = (13) New event detection system gives two outputs for each story.",
                "The first part is yes or no indicating whether the story triggers a new event or not.",
                "The second part is a score indicating confidence of the first decision.",
                "Confidence scores can be used to plot DET curve, i.e., curves that plot false alarm vs. miss probabilities.",
                "Minimum normalized cost can be determined if optimal threshold on the score were chosen. 7.",
                "EXPERIMENTAL RESULTS 7.1 Main Results To test the approaches proposed in the model, we implemented and tested five systems: System-1: this system is used as baseline.",
                "It is implemented based on the basic model described in section 3, i.e., using incremental TF-IDF model to generate term weights, and using Hellinger distance to compute document similarity.",
                "Similarity score normalization is also employed [8].",
                "S-S detection procedure is used.",
                "System-2: this system is the same as system-1 except that S-C detection procedure is used.",
                "System-3: this system is the same as system-1 except that it uses the new detection procedure which is based on indexing-tree.",
                "System-4: implemented based on the approach presented in section 5.1, i.e., terms are reweighted according to the distance between term distributions in a cluster and all stories.",
                "The new detection procedure is used.",
                "System-5: implemented based on the approach presented in section 5.2, i.e., terms of different types are reweighted according to news class using trained parameters.",
                "The new detection procedure is used.",
                "The following are some other NED systems: System-6: [21] for each pair of stories, it computes three similarity values for named entity, non-named entity and all terms respectively.",
                "And employ Support Vector Machine to predict new or old using the similarity values as features.",
                "System-7: [8] it extended a basic incremental TF-IDF model to include source-specific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, etc.",
                "System-8: [13] it split document representation into two parts: named entities and non-named entities, and choose one effective part for each news class.",
                "Table 3 and table 4 show topic-weighted normalized costs and comparing times on TDT2 and TDT3 datasets respectively.",
                "Since no heldout data set for fine-tuning the threshold θ new was available for experiments on TDT2, we only report minimum normalized costs for our systems in table 3.",
                "System-5 outperforms all other systems including system-6, and it performs only 2.78e+8 comparing times in detection procedure which is only 13.4% of system-1.",
                "Table 3.",
                "NED results on TDT2 Systems Min Norm(CDet) Cmp times System-1 0.5749 2.08e+9 System-2① 0.6673 3.77e+8 System-3② 0.5765 2.81e+8 System-4② 0.5431 2.99e+8 System-5② 0.5089 2.78e+8 System-6 0.5300 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 When evaluating on the normalized costs on TDT3, we use the optimal thresholds obtained from TDT2 data set for all systems.",
                "System-2 reduces comparing times to 1.29e+9 which is just 18.3% of system-1, but at the same time it also gets a deteriorated minimum normalized cost which is 0.0499 higher than system-1.",
                "System-3 uses the new detection procedure based on news indexing-tree.",
                "It requires even less comparing times than system-2.",
                "This is because story-story comparisons usually yield greater similarities than story-cluster ones, so stories tend to be combined Location Person Date Organization Money Percentage NN JJ CD Elections 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 Scandals/Hearings 0.66 0.62 0.28 1 0.11 0.02 0.27 0.13 0.05 Legal/Criminal Cases 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 Natural Disasters 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 Violence or War 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 Science and Discovery 0.11 1 0.01 0.22 0.08 0.12 0.19 0.08 0.03 Finances 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 Sports 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 together in system-3.",
                "And system-3 is basically equivalent to system-1 in accuracy results.",
                "System-4 adjusts term weights based on the distance of term distributions between the whole corpus and cluster story set, yielding a good improvement by 0.0468 compared to system-1.",
                "The best system (system-5) has a minimum normalized cost 0.5012, which is 0.0797 better than system-1, and also better than any other results previously reported for this dataset [8, 13].",
                "Further more, system-5 only needs 1.05e+8 comparing times which is 14.9% of system-1.",
                "Table 4.",
                "NED results on TDT3 Systems Norm(CDet) Min Norm(CDet) Cmp times System-1 0.6159 0.5809 7.04e+8 System-2① 0.6493 0.6308 1.29e+8 System-3② 0.6197 0.5868 1.03e+8 System-4② 0.5601 0.5341 1.03e+8 System-5② 0.5413 0.5012 1.05e+8 System-7 -- 0.5783 -System-8 -- 0.5229 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 Figure5 shows the five DET curves for our systems on data set TDT3.",
                "System-5 achieves the minimum cost at a false alarm rate of 0.0157 and a miss rate of 0.4310.",
                "We can observe that System4 and System-5 obtain lower miss probability at regions of low false alarm probabilities.",
                "The hypothesis is that, more weight value is transferred to key terms of topics from non-key terms.",
                "Similarity score between two stories belonging to different topics are lower than before, because their overlapping terms are usually not key terms of their topics. 7.2 Parameter selection for indexing-tree detection Figure 3 shows the minimum normalized costs obtained by system-3 on TDT3 using different parameters.",
                "Theθ init parameter is tested on six values spanning from 0.03 to 0.18.",
                "And the λ parameter is tested on four values 1, 2, 3 and 4.",
                "We can see that, whenθ init is set to 0.12, which is the closest one toθ new, the costs are lower than others.",
                "This is easy to explain, because when stories belonging to the same topic are put in a cluster, it is more reasonable for the cluster to represent the stories in it.",
                "When parameter λ is set to 3 or 4, the costs are better than other cases, but there is no much difference between 3 and 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ MinCost 0.6 0.65 0.7 0.75 0.8 0.85 0.9 Figure 3.",
                "Min Cost on TDT3 (δ =0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ Comparingtimes 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 Figure 4.",
                "Comparing times on TDT3 (δ =0.15) Figure 4 gives the comparing times used by system-3 on TDT3 with the same parameters as figure 3.",
                "The comparing times are strongly dependent onθ init.",
                "Because the greaterθ init is, the less stories combined together, the more comparing times are needed for new event decision.",
                "So we useθ init =0.13,λ =3,δ =0.15 for system-3, 4, and 5.",
                "In this parameter setting, we can get both low minimum normalized costs and less comparing times. 8.",
                "CONCLUSION We have proposed a news indexing-tree based detection procedure in our model.",
                "It reduces comparing times to about one seventh of traditional method without hurting NED accuracy.",
                "We also have presented two extensions to the basic TF-IDF model.",
                "The first extension is made by adjust term weights based on term distributions between the whole corpus and a cluster story set.",
                "And the second extension to basic TF-IDF model is better use of term types (named entities types and part-of-speed) according to news categories.",
                "Our experimental results on TDT2 and TDT3 datasets show that both of the two extensions contribute significantly to improvement in accuracy.",
                "We did not consider news time information as a clue for NED task, since most of the topics last for a long time and TDT data sets only span for a relative short period (no more than 6 months).",
                "For the future work, we want to collect news set which span for a longer period from internet, and integrate time information in NED task.",
                "Since topic is a relative coarse-grained news cluster, we also want to refine cluster granularity to event-level, and identify different events and their relations within a topic.",
                "Acknowledgments This work is supported by the National Natural Science Foundation of China under Grant No. 90604025.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] In Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. .01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90 1 2 5 10 20 40 60 80 90 False Alarm Probability (in %) MissProbability(in%) SYSTEM1 Topic Weighted Curve SYSTEM1 Min Norm(Cost) SYSTEM2 Topic Weighted Curve SYSTEM2 Min Norm(Cost) SYSTEM3 Topic Weighted Curve SYSTEM3 Min Norm(Cost) SYSTEM4 Topic Weighted Curve SYSTEM4 Min Norm(Cost) SYSTEM5 Topic Weighted Curve SYSTEM5 Min Norm(Cost) Random Performance Figure 5.",
                "DET curves on TDT3 [3] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B.T.",
                "Archibald, and X. Liu.",
                "Learning Approaches for Detecting and Tracking News Events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), 1999, 32-43. [4] Y. Yang, T. Pierce, and J. Carbonell.",
                "A Study on Retrospective and On-line Event Detection.",
                "In Proceedings of SIGIR-98, Melbourne, Australia, 1998, 28-36. [5] J. Allan, V. Lavrenko, D. Malin, and R. Swan.",
                "Detections, Bounds, and Timelines: Umass and tdt-3.",
                "In Proceedings of Topic Detection and Tracking Workshop (TDT-3), Vienna, VA, 2000, 167-174. [6] R. Papka and J. Allan.",
                "On-line New Event Detection Using Single Pass Clustering TITLE2:.",
                "Technical Report UM-CS1998-021, 1998. [7] W. Lam, H. Meng, K. Wong, and J.",
                "Yen.",
                "Using Contextual Analysis for News Event Detection.",
                "International Journal on Intelligent Systems, 2001, 525-546. [8] B. Thorsten, C. Francine, and F. Ayman.",
                "A System for New Event Detection.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2003, 330-337. [9] S. Nicola and C. Joe.",
                "Combining Semantic and Syntactic Document Classifiers to Improve First Story Detection.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2001, 424425. [10] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topicconditioned Novelty Detection.",
                "In Proceedings of the 8th ACM SIGKDD International Conference, ACM Press. 2002, 688-693. [11] M. Juha, A.M. Helena, and S. Marko.",
                "Applying Semantic Classes in Event Detection and Tracking.",
                "In Proceedings of International Conference on Natural Language Processing (ICON 2002), 2002, pages 175-183. [12] M. Juha, A.M. Helena, and S. Marko.",
                "Simple Semantics in Topic Detection and Tracking.",
                "Information Retrieval, 7(3-4): 2004, 347-368. [13] K. Giridhar and J. Allan.",
                "Text Classification and Named Entities for New Event Detection.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2004, 297-304. [14] J. P. Callan, W. B. Croft, and S. M. Harding.",
                "The INQUERY Retrieval System.",
                "In Proceedings of DEXA-92, 3rd International Conference on Database and Expert Systems Applications, 1992, 78-83. [15] R. Krovetz.",
                "Viewing Morphology as An Inference Process.",
                "In Proceedings of ACM SIGIR93, 1993, 61-81. [16] Y. Yang and J. Pedersen.",
                "A Comparative Study on Feature Selection in Text Categorization.",
                "In J. D. H. Fisher, editor, The Fourteenth International Conference on Machine Learning (ICML97), Morgan Kaufmann, 1997, 412-420. [17] T. M. Cover, and J.A.",
                "Thomas.",
                "Elements of Information Theory.",
                "Wiley. 1991. [18] The linguistic data consortium, http://www.ldc,upenn.edu/. [19] The 2001 TDT task definition and evaluation plan, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm. [20] R. E. Schapire and Y.",
                "Singer.",
                "Boostexter: A Boosting-based System for Text Categorization.",
                "In Machine Learning 39(2/3):1, Kluwer Academic Publishers, 2000, 35-168. [21] K. Giridhar and J. Allan. 2005.",
                "Using Names and Topics for New Event Detection.",
                "In Proceedings of Human Technology Conference and Conference on Empirical Methods in Natural Language, Vancouver, 2005, 121-128"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Los nuevos sistemas de detección de eventos utilizan \"transmisión de noticias\" como entrada, en la que las historias están estrictamente ordenadas por el tiempo."
            ],
            "translated_text": "",
            "candidates": [
                "transmisión de noticias",
                "transmisión de noticias"
            ],
            "error": []
        },
        "volume of news": {
            "translated_key": "Volumen de noticias",
            "is_in_text": true,
            "original_annotated_sentences": [
                "New Event Detection Based on Indexing-tree and Named Entity Zhang Kuo Tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn Li Juan Zi Tsinghua University Beijing, 100084, China 86-10-62781461 ljz@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn ABSTRACT New Event Detection (NED) aims at detecting from one or multiple streams of news stories that which one is reported on a new event (i.e.",
                "not reported previously).",
                "With the overwhelming <br>volume of news</br> available today, there is an increasing need for a NED system which is able to detect new events more efficiently and accurately.",
                "In this paper we propose a new NED model to speed up the NED task by using news indexing-tree dynamically.",
                "Moreover, based on the observation that terms of different types have different effects for NED task, two term reweighting approaches are proposed to improve NED accuracy.",
                "In the first approach, we propose to adjust term weights dynamically based on previous story clusters and in the second approach, we propose to employ statistics on training data to learn the named entity reweighting model for each class of stories.",
                "Experimental results on two Linguistic Data Consortium (LDC) datasets TDT2 and TDT3 show that the proposed model can improve both efficiency and accuracy of NED task significantly, compared to the baseline system and other existing systems.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Search and Retrieval; H.4.2 [Information Systems Applications]: Types of Systemsdecision support.",
                "General Terms Algorithms, Performance, Experimentation 1.",
                "INTRODUCTION Topic Detection and Tracking (TDT) program aims to develop techniques which can effectively organize, search and structure news text materials from a variety of newswire and broadcast media [1].",
                "New Event Detection (NED) is one of the five tasks in TDT.",
                "It is the task of online identification of the earliest report for each topic as soon as that report arrives in the sequence of documents.",
                "A Topic is defined as a seminal event or activity, along with directly related events and activities [2].",
                "An Event is defined as something (non-trivial) happening in a certain place at a certain time [3].",
                "For instance, when a bomb explodes in a building, the exploding is the seminal event that triggers the topic, and other stories on the same topic would be those discussing salvaging efforts, the search for perpetrators, arrests and trial and so on.",
                "Useful news information is usually buried in a mass of data generated everyday.",
                "Therefore, NED systems are very useful for people who need to detect novel information from real-time news stream.",
                "These real-life needs often occur in domains like financial markets, news analysis, and intelligence gathering.",
                "In most of state-of-the-art (currently) NED systems, each news story on hand is compared to all the previous received stories.",
                "If all the similarities between them do not exceed a threshold, then the story triggers a new event.",
                "They are usually in the form of cosine similarity or Hellinger similarity metric.",
                "The core problem of NED is to identify whether two stories are on the same topic.",
                "Obviously, these systems cannot take advantage of topic information.",
                "Further more, it is not acceptable in real applications because of the large amount of computation required in the NED process.",
                "Other systems organize previous stories into clusters (each cluster corresponds to a topic), and new story is compared to the previous clusters instead of stories.",
                "This manner can reduce comparing times significantly.",
                "Nevertheless, it has been proved that this manner is less accurate [4, 5].",
                "This is because sometimes stories within a topic drift far away from each other, which could lead low similarity between a story and its topic.",
                "On the other hand, some proposed NED systems tried to improve accuracy by making better use of named entities [10, 11, 12, 13].",
                "However, none of the systems have considered that terms of different types (e.g.",
                "Noun, Verb or Person name) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "For example, the names of election candidates (Person name) are very important for stories of election class; the locations (Location name) where accidents happened are important for stories of accidents class.",
                "So, in NED, there still exist following three problems to be investigated: (1) How to speed up the detection procedure while do not decrease the detection accuracy? (2) How to make good use of cluster (topic) information to improve accuracy? (3) How to obtain better news story representation by better understanding of named entities.",
                "Driven by these problems, we have proposed three approaches in this paper. (1)To make the detection procedure faster, we propose a new NED procedure based on news indexing-tree created dynamically.",
                "Story indexing-tree is created by assembling similar stories together to form news clusters in different hierarchies according to their values of similarity.",
                "Comparisons between current story and previous clusters could help find the most similar story in less comparing times.",
                "The new procedure can reduce the amount of comparing times without hurting accuracy. (2)We use the clusters of the first floor in the indexing-tree as news topics, in which term weights are adjusted dynamically according to term distribution in the clusters.",
                "In this approach, cluster (topic) information is used properly, so the problem of theme decentralization is avoided. (3)Based on observations on the statistics obtained from training data, we found that terms of different types (e.g.",
                "Noun and Verb) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "And we propose to use statistics to optimize the weights of the terms of different types in a story according to the news class that the story belongs to.",
                "On TDT3 dataset, the new NED model just uses 14.9% comparing times of the basic model, while its minimum normalized cost is 0.5012, which is 0.0797 better than the basic model, and also better than any other results previously reported for this dataset [8, 13].",
                "The rest of the paper is organized as follows.",
                "We start off this paper by summarizing the previous work in NED in section 2.",
                "Section 3 presents the basic model for NED that most current systems use.",
                "Section 4 describes our new detection procedure based on news indexing-tree.",
                "In section 5, two term reweighting methods are proposed to improve NED accuracy.",
                "Section 6 gives our experimental data and evaluation metrics.",
                "We finally wrap up with the experimental results in Section 7, and the conclusions and future work in Section 8. 2.",
                "RELATED WORK Papka et al. proposed Single-Pass clustering on NED [6].",
                "When a new story was encountered, it was processed immediately to extract term features and a query representation of the storys content is built up.",
                "Then it was compared with all the previous queries.",
                "If the document did not trigger any queries by exceeding a threshold, it was marked as a new event.",
                "Lam et al build up previous query representations of story clusters, each of which corresponds to a topic [7].",
                "In this manner comparisons happen between stories and clusters.",
                "Recent years, most work focus on proposing better methods on comparison of stories and document representation.",
                "Brants et al. [8] extended a basic incremental TF-IDF model to include sourcespecific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, term reweighting based on inverse event frequencies, and segmentation of documents.",
                "Good improvements on TDT bench-marks were shown.",
                "Stokes et al. [9] utilized a combination of evidence from two distinct representations of a documents content.",
                "One of the representations was the usual free text vector, the other made use of lexical chains (created using WordNet) to build another term vector.",
                "Then the two representations are combined in a linear fashion.",
                "A marginal increase in effectiveness was achieved when the combined representation was used.",
                "Some efforts have been done on how to utilize named entities to improve NED.",
                "Yang et al. gave location named entities four times weight than other terms and named entities [10].",
                "DOREMI research group combined semantic similarities of person names, location names and time together with textual similarity [11][12].",
                "UMass [13] research group split document representation into two parts: named entities and non-named entities.",
                "And it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation.",
                "Both [10] and [13] used text categorization technique to classify news stories in advance.",
                "In [13] news stories are classified automatically at first, and then test sensitivities of names and non-name terms for NED for each class.",
                "In [10] frequent terms for each class are removed from document representation.",
                "For example, word election does not help identify different elections.",
                "In their work, effectiveness of different kinds of names (or terms with different POS) for NED in different news classes are not investigated.",
                "We use statistical analysis to reveal the fact and use it to improve NED performance. 3.",
                "BASIC MODEL In this section, we present the basic New Event Detection model which is similar to what most current systems apply.",
                "Then, we propose our new model by extending the basic model.",
                "New Event Detection systems use news story stream as input, in which stories are strictly time-ordered.",
                "Only previously received stories are available when dealing with current story.",
                "The output is a decision for whether the current story is on a new event or not and the confidence of the decision.",
                "Usually, a NED model consists of three parts: story representation, similarity calculation and detection procedure. 3.1 Story Representation Preprocessing is needed before generating story representation.",
                "For preprocessing, we tokenize words, recognize abbreviations, normalize abbreviations, add part-of-speech tags, remove stopwords included in the stop list used in InQuery [14], replace words with their stems using K-stem algorithm[15], and then generate word vector for each news story.",
                "We use incremental TF-IDF model for term weight calculation [4].",
                "In a TF-IDF model, term frequency in a news document is weighted by the inverse document frequency, which is generated from training corpus.",
                "When a new term occurs in testing process, there are two solutions: simply ignore the new term or set df of the term as a small const (e.g. df = 1).",
                "The new term receives too low weight in the first solution (0) and too high weight in the second solution.",
                "In incremental TF-IDF model, document frequencies are updated dynamically in each time step t: 1( ) ( ) ( )t t D tdf w df w df w−= + (1) where Dt represents news story set received in time t, and dfDt(w) means the number of documents that term w occurs in, and dft(w) means the total number of documents that term w occurs in before time t. In this work, each time window includes 50 news stories.",
                "Thus, each story d received in t is represented as follows: 1 2{ ( , , ), ( , , ),..., ( , , )}nd weight d t w weight d t w weight d t w→ where n means the number of distinct terms in story d, and ( , , )weight d t w means the weight of term w in story d at time t: log( ( , ) 1) log(( 1) /( ( ) 0.5)) ( , , ) log( ( , ) 1) log(( 1) /( ( ) 0.5)) t t t t w d tf d w N df w weight d t w tf d w N df w ∈ + + + = + + +∑ (2) where Nt means the total number of news stories before time t, and tf(d,w) means how many times term w occurs in news story d. 3.2 Similarity Calculation We use Hellinger distance for the calculation of similarity between two stories, for two stories d and d at time t, their similarity is defined as follows: , ( , , ) ( , , ) * ( , , ) w d d sim d d t weight d t w weight d t w ∈ = ∑ (3) 3.3 Detection Procedure For each story d received in time step t, the value ( ) ( ) ( ) ( ( , , )) time d time d n d max sim d d t < = (4) is a score used to determine whether d is a story about a new topic and at the same time is an indication of the confidence in our decision [8]. time(d) means the publication time of story d. If the score exceeds the thresholdθ new, then there exists a sufficiently similar document, thus d is a old story, otherwise, there is no sufficiently similar previous document, thus d is an new story. 4.",
                "New NED Procedure Traditional NED systems can be classified into two main types on the aspect of detection procedure: (1) S-S type, in which the story on hand is compared to each story received previously, and use the highest similarity to determine whether current story is about a new event; (2) S-C type, in which the story on hand is compared to all previous clusters each of which representing a topic, and the highest similarity is used for final decision for current story.",
                "If the highest similarity exceeds thresholdθ new, then it is an old story, and put it into the most similar cluster; otherwise it is a new story and create a new cluster.",
                "Previous work show that the first manner is more accurate than the second one [4][5].",
                "Since sometimes stories within a topic drift far away from each other, a story may have very low similarity with its topic.",
                "So using similarities between stories for determining new story is better than using similarities between story and clusters.",
                "Nevertheless, the first manner needs much more comparing times which means the first manner is low efficient.",
                "We propose a new detection procedure which uses comparisons with previous clusters to help find the most similar story in less comparing times, and the final new event decision is made according to the most similar story.",
                "Therefore, we can get both the accuracy of S-S type methods and the efficiency of S-C type methods.",
                "The new procedure creates a news indexing-tree dynamically, in which similar stories are put together to form a hierarchy of clusters.",
                "We index similar stories together by their common ancestor (a cluster node).",
                "Dissimilar stories are indexed in different clusters.",
                "When a story is coming, we use comparisons between the current story and previous hierarchical clusters to help find the most similar story which is useful for new event decision.",
                "After the new event decision is made, the current story is inserted to the indexing-tree for the following detection.",
                "The news indexing-tree is defined formally as follows: S-Tree = {r, NC , NS , E} where r is the root of S-Tree, NC is the set of all cluster nodes, NS is the set of all story nodes, and E is the set of all edges in S-Tree.",
                "We define a set of constraints for a S-Tree: ⅰ . , is an non-terminal node in the treeC i i N i∀ ∈ → ⅱ . , is a terminal node in the treeS i i N i∀ ∈ → ⅲ . , out degree of is at least 2C i i N i∀ ∈ → ⅳ . , is represented as the centroid of its desendantsC i i iN∀ ∈ → For a news story di, the comparison procedure and inserting procedure based on indexing-tree are defined as follows.",
                "An example is shown by Figure 1 and Figure 2.",
                "Figure 1.",
                "Comparison procedure Figure 2.",
                "Inserting procedure Comparison procedure: Step 1: compare di to all the direct child nodes of r and select λ nodes with highest similarities, e.g., C1 2 and C1 3 in Figure 1.",
                "Step 2: for each selected node in the last step, e.g.",
                "C1 2, compare di to all its direct child nodes, and select λ nodes with highest similarities, e.g.",
                "C2 2 and d8.",
                "Repeat step 2 for all non-terminal nodes.",
                "Step 3: record the terminal node with the highest similarty to di, e.g. s5, and the similarity value (0.20).",
                "Inserting di to the S-tree with r as root: Find the node n which is direct child of r in the path from r to the terminal node with highest similarity s, e.g.",
                "C1 2.",
                "If s is smaller than θ init+(h-1)δ , then add di to the tree as a direct child of r. Otherwise, if n is a terminal node, then create a cluster node instead of n, and add both n and di as its direct children; if n is an non-terminal node, then repeat this procedure and insert di to the sub-tree with n as root recursively.",
                "Here h is the length between n and the root of S-tree.",
                "The more the stories in a cluster similar to each other, the better the cluster represents the stories in it.",
                "Hence we add no constraints on the maximum of trees height and degree of a node.",
                "Therefore, we cannot give the complexity of this indexing-tree based procedure.",
                "But we will give the number of comparing times needed by the new procedure in our experiments in section7. 5.",
                "Term Reweighting Methods In this section, two term reweighting methods are proposed to improve NED accuracy.",
                "In the first method, a new way is explored for better using of cluster (topic) information.",
                "The second one finds a better way to make use of named entities based on news classification. 5.1 Term Reweighting Based on Distribution Distance TF-IDF is the most prevalent model used in information retrieval systems.",
                "The basic idea is that the fewer documents a term appears in, the more important the term is in discrimination of documents (relevant or not relevant to a query containing the term).",
                "Nevertheless, in TDT domain, we need to discriminate documents with regard to topics rather than queries.",
                "Intuitively, using cluster (topic) vectors to compare with subsequent news stories should outperform using story vectors.",
                "Unfortunately, the experimental results do not support this intuition [4][5].",
                "Based on observation on data, we find the reason is that a news topic usually contains many directly or indirectly related events, while they all have their own sub-subjects which are usually different with each other.",
                "Take the topic described in section 1 as an example, events like the explosion and salvage have very low similarities with events about criminal trial, therefore stories about trial would have low similarity with the topic vector built on its previous events.",
                "This section focuses on how to effectively make use of topic information and at the same time avoid the problem of content decentralization.",
                "At first, we classify terms into 5 classes to help analysis the needs of the modified model: Term class A: terms that occur frequently in the whole corpus, e.g., year and people.",
                "Terms of this class should be given low weights because they do not help much for topic discrimination.",
                "Term class B: terms that occur frequently within a news category, e.g., election, storm.",
                "They are useful to distinguish two stories in different news categories.",
                "However, they cannot provide information to determine whether two stories are on the same or different topics.",
                "In another words, term election and term storm are not helpful in differentiate two election campaigns and two storm disasters.",
                "Therefore, terms of this class should be assigned lower weights.",
                "Term class C: terms that occur frequently in a topic, and infrequently in other topics, e.g., the name of a crash plane, the name of a specific hurricane.",
                "News stories that belong to different topics rarely have overlap terms in this class.",
                "The more frequently a term appears in a topic, the more important the term is for a story belonging to the topic, therefore the term should be set higher weight.",
                "Term class D: terms that appear in a topic exclusively, but not frequently.",
                "For example, the name of a fireman who did very well in a salvage action, which may appears in only two or three stories but never appeared in other topics.",
                "Terms of this type should receive more weights than in TF-IDF model.",
                "However, since they are not popular in the topic, it is not appropriate to give them too high weights.",
                "Term class E: terms with low document frequency, and appear in different topics.",
                "Terms of this class should receive lower weights.",
                "Now we analyze whether TF-IDF model can give proper weights to the five classes of terms.",
                "Obviously, terms of class A are lowly weighted in TF-IDF model, which is conformable with the requirement described above.",
                "In TF-IDF model, terms of class B are highly dependant with the number of stories in a news class.",
                "TF-IDF model cannot provide low weights if the story containing the term belongs to a relative small news class.",
                "For a term of class C, the more frequently it appears in a topic, the less weight TFIDF model gives to it.",
                "This strongly conflicts with the requirement of terms in class C. For terms of class D, TF-IDF model gives them high weights correctly.",
                "But for terms of class E, TF-IDF model gives high weights to them which are not conformable with the requirement of low weights.",
                "To sum up, terms of class B, C, E cannot be properly weighted in TF-IDF model.",
                "So, we propose a modified model to resolve this problem.",
                "When θ init andθ new are set closely, we assume that most of the stories in a first-level cluster (a direct child node of root node) are on the same topic.",
                "Therefore, we make use of a first-level cluster to capture term distribution (df for all the terms within the cluster) within the topic dynamically.",
                "KL divergence of term distribution in a first-level cluster and the whole story set is used to adjust term weights:  ( , , ) * (1 * ( || )) ( , , ) ( , , ) * (1 * ( || )) cw tw cw tw w d D weight d t w KL P P weight d t w weight d t w KL P P γ γ ∈ + = +∑ (5) where ( ) ( ) ( ) ( ) 1,cw cw c c c c df w df w p y p y N N = = − (6) ( ) ( ) ( ) ( ) 1,t t tw tw t t df w df w p y p y N N = = − (7) where dfc(w) is the number of documents containing term w within cluster C, and Nc is the number of documents in cluster C, and Nt is the total number of documents that arrive before time step t. γ is a const parameter, now is manually set 3.",
                "KL divergence is defined as follows [17]: ( ) ( || ) ( ) log ( )x p x KL P Q p x q x = ∑ (8) The basic idea is: for a story in a topic, the more a term occurs within the topic, and the less it occurs in other topics, it should be assigned higher weights.",
                "Obviously, modified model can meet all the requirements of the five term classes listed above. 5.2 Term Reweighting Based on Term Type and Story Class Previous work found that some classes of news stories could achieve good improvements by giving extra weight to named entities.",
                "But we find that terms of different types should be given different amount of extra weight for different classes of news stories.",
                "We use open-NLP1 to recognize named entity types and part-ofspeech tags for terms that appear in news stories.",
                "Named entity types include person name, organization name, location name, date, time, money and percentage, and five POSs are selected: none (NN), verb (VB), adjective (JJ), adverb (RB) and cardinal number (CD).",
                "Statistical analysis shows topic-level discriminative terms types for different classes of stories.",
                "For the sake of convenience, named entity type and part-of-speech tags are uniformly called term type in subsequent sections.",
                "Determining whether two stories are about the same topic is a basic component for NED task.",
                "So at first we use 2 χ statistic to compute correlations between terms and topics.",
                "For a term t and a topic T, a contingence table is derived: Table 1.",
                "A 2×2 Contingence Table Doc Number belong to topic T not belong to topic T include t A B not include t C D The 2 χ statistic for a specific term t with respect to topic T is defined to be [16]: 2 2 ( , ) ( ) * ( ) ( ) * ( ) * ( ) * ( ) w T A B C D AD CB A C B D A B C D χ = + + + − + + + + (9) News topics for the TDT task are further classified into 11 rules of interpretations (ROIs) 2 .",
                "The ROI can be seen as a higher level class of stories.",
                "The average correlation between a term type and a topic ROI is computed as: 2 avg 2 ( , )( ( , ) )k m m km kT R w P w TP R p w T R P χ χ ∈ ∈ ∑ ∑（ , ）= 1 1 k=1…K, m=1…M (10) where K is the number of term types (set 12 constantly in the paper).",
                "M is the number news classes (ROIs, set 11 in the paper).",
                "Pk represents the set of all terms of type k, and Rm represents the set of all topics of class m, p(t,T) means the probability that t occurs in topic T. Because of limitation of space, only parts of the term types (9 term types) and parts of news classes (8 classes) are listed in table 2 with the average correlation values between them.",
                "The statistics is derived from labeled data in TDT2 corpus. (Results in table 2 are already normalized for convenience in comparison.)",
                "The statistics in table 2 indicates the usefulness of different term types in topic discrimination with respect to different news classes.",
                "We can see that, location name is the most useful term type for three news classes: Natural Disasters, Violence or War, Finances.",
                "And for three other categories Elections, Legal/Criminal Cases, Science and Discovery, person name is the most discriminative term type.",
                "For Scandals/Hearings, date is the most important information for topic discrimination.",
                "In addition, Legal/Criminal Cases and Finance topics have higher correlation with money terms, while Science and Discovery have higher correlation with percentage terms.",
                "Non-name terms are more stable for different classes. 1 . http://opennlp.sourceforge.net/ 2 . http://projects.ldc.upenn.edu/TDT3/Guide/label.html From the analysis of table 2, it is reasonable to adjust term weight according to their term type and the news class the story belongs to.",
                "New term weights are reweighted as follows: ( ) ( ) ( ) ( ) ( , , ) * ( , , ) ( , , ) * class d D type w T class d D type w w d weight d t w weight d t w weight d t w α α ∈ = ∑ (11) where type(w) represents the type of term w, and class(d) represents the class of story d, c kα is reweighting parameter for news class c and term type k. In the work, we just simply use statistics in table 2 as the reweighting parameters.",
                "Even thought using the statistics directly may not the best choice, we do not discuss how to automatically obtain the best parameters.",
                "We will try to use machine learning techniques to obtain the best parameters in the future work.",
                "In the work, we use BoosTexter [20] to classify all stories into one of the 11 ROIs.",
                "BoosTexter is a boosting based machine learning program, which creates a series of simple rules for building a classifier for text or attribute-value data.",
                "We use term weight generated using TF-IDF model as feature for story classification.",
                "We trained the model on the 12000 judged English stories in TDT2, and classify the rest of the stories in TDT2 and all stories in TDT3.",
                "Classification results are used for term reweighting in formula (11).",
                "Since the class labels of topic-off stories are not given in TDT datasets, we cannot give the classification accuracy here.",
                "Thus we do not discuss the effects of classification accuracy to NED performance in the paper. 6.",
                "EXPERIMENTAL SETUP 6.1 Datasets We used two LDC [18] datasets TDT2 and TDT3 for our experiments.",
                "TDT2 contains news stories from January to June 1998.",
                "It contains around 54,000 stories from sources like ABC, Associated Press, CNN, New York Times, Public Radio International, Voice of America etc.",
                "Only English stories in the collection were considered.",
                "TDT3 contains approximately 31,000 English stories collected from October to December 1998.",
                "In addition to the sources used in TDT2, it also contains stories from NBC and MSNBC TV broadcasts.",
                "We used transcribed versions of the TV and radio broadcasts besides textual news.",
                "TDT2 dataset is labeled with about 100 topics, and approximately 12,000 English stories belong to at least one of these topics.",
                "TDT3 dataset is labeled with about 120 topics, and approximately 8000 English stories belong to at least one of these topics.",
                "All the topics are classified into 11 Rules of Interpretation: (1)Elections, (2)Scandals/Hearings, (3)Legal/Criminal Cases, (4)Natural Disasters, (5)Accidents, (6)Ongoing Violence or War, (7)Science and Discovery News, (8)Finance, (9)New Law, (10)Sports News, (11)MISC.",
                "News. 6.2 Evaluation Metric TDT uses a cost function CDet that combines the probabilities of missing a new story and a false alarm [19]: * * * *Det Miss Miss Target FA FA NontargetC C P P C P P= + (12) Table 2.",
                "Average correlation between term types and news classes where CMiss means the cost of missing a new story, PMiss means the probability of missing a new story, and PTarget means the probability of seeing a new story in the data; CFA means the cost of a false alarm, PFA means the probability of a false alarm, and PNontarget means the probability of seeing an old story.",
                "The cost CDet is normalized such that a perfect system scores 0 and a trivial system, which is the better one of mark all stories as new or old, scores 1: ( ( * , * ) ) Det Det Miss Target FA Nontarget C Norm C min C P C P = (13) New event detection system gives two outputs for each story.",
                "The first part is yes or no indicating whether the story triggers a new event or not.",
                "The second part is a score indicating confidence of the first decision.",
                "Confidence scores can be used to plot DET curve, i.e., curves that plot false alarm vs. miss probabilities.",
                "Minimum normalized cost can be determined if optimal threshold on the score were chosen. 7.",
                "EXPERIMENTAL RESULTS 7.1 Main Results To test the approaches proposed in the model, we implemented and tested five systems: System-1: this system is used as baseline.",
                "It is implemented based on the basic model described in section 3, i.e., using incremental TF-IDF model to generate term weights, and using Hellinger distance to compute document similarity.",
                "Similarity score normalization is also employed [8].",
                "S-S detection procedure is used.",
                "System-2: this system is the same as system-1 except that S-C detection procedure is used.",
                "System-3: this system is the same as system-1 except that it uses the new detection procedure which is based on indexing-tree.",
                "System-4: implemented based on the approach presented in section 5.1, i.e., terms are reweighted according to the distance between term distributions in a cluster and all stories.",
                "The new detection procedure is used.",
                "System-5: implemented based on the approach presented in section 5.2, i.e., terms of different types are reweighted according to news class using trained parameters.",
                "The new detection procedure is used.",
                "The following are some other NED systems: System-6: [21] for each pair of stories, it computes three similarity values for named entity, non-named entity and all terms respectively.",
                "And employ Support Vector Machine to predict new or old using the similarity values as features.",
                "System-7: [8] it extended a basic incremental TF-IDF model to include source-specific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, etc.",
                "System-8: [13] it split document representation into two parts: named entities and non-named entities, and choose one effective part for each news class.",
                "Table 3 and table 4 show topic-weighted normalized costs and comparing times on TDT2 and TDT3 datasets respectively.",
                "Since no heldout data set for fine-tuning the threshold θ new was available for experiments on TDT2, we only report minimum normalized costs for our systems in table 3.",
                "System-5 outperforms all other systems including system-6, and it performs only 2.78e+8 comparing times in detection procedure which is only 13.4% of system-1.",
                "Table 3.",
                "NED results on TDT2 Systems Min Norm(CDet) Cmp times System-1 0.5749 2.08e+9 System-2① 0.6673 3.77e+8 System-3② 0.5765 2.81e+8 System-4② 0.5431 2.99e+8 System-5② 0.5089 2.78e+8 System-6 0.5300 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 When evaluating on the normalized costs on TDT3, we use the optimal thresholds obtained from TDT2 data set for all systems.",
                "System-2 reduces comparing times to 1.29e+9 which is just 18.3% of system-1, but at the same time it also gets a deteriorated minimum normalized cost which is 0.0499 higher than system-1.",
                "System-3 uses the new detection procedure based on news indexing-tree.",
                "It requires even less comparing times than system-2.",
                "This is because story-story comparisons usually yield greater similarities than story-cluster ones, so stories tend to be combined Location Person Date Organization Money Percentage NN JJ CD Elections 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 Scandals/Hearings 0.66 0.62 0.28 1 0.11 0.02 0.27 0.13 0.05 Legal/Criminal Cases 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 Natural Disasters 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 Violence or War 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 Science and Discovery 0.11 1 0.01 0.22 0.08 0.12 0.19 0.08 0.03 Finances 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 Sports 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 together in system-3.",
                "And system-3 is basically equivalent to system-1 in accuracy results.",
                "System-4 adjusts term weights based on the distance of term distributions between the whole corpus and cluster story set, yielding a good improvement by 0.0468 compared to system-1.",
                "The best system (system-5) has a minimum normalized cost 0.5012, which is 0.0797 better than system-1, and also better than any other results previously reported for this dataset [8, 13].",
                "Further more, system-5 only needs 1.05e+8 comparing times which is 14.9% of system-1.",
                "Table 4.",
                "NED results on TDT3 Systems Norm(CDet) Min Norm(CDet) Cmp times System-1 0.6159 0.5809 7.04e+8 System-2① 0.6493 0.6308 1.29e+8 System-3② 0.6197 0.5868 1.03e+8 System-4② 0.5601 0.5341 1.03e+8 System-5② 0.5413 0.5012 1.05e+8 System-7 -- 0.5783 -System-8 -- 0.5229 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 Figure5 shows the five DET curves for our systems on data set TDT3.",
                "System-5 achieves the minimum cost at a false alarm rate of 0.0157 and a miss rate of 0.4310.",
                "We can observe that System4 and System-5 obtain lower miss probability at regions of low false alarm probabilities.",
                "The hypothesis is that, more weight value is transferred to key terms of topics from non-key terms.",
                "Similarity score between two stories belonging to different topics are lower than before, because their overlapping terms are usually not key terms of their topics. 7.2 Parameter selection for indexing-tree detection Figure 3 shows the minimum normalized costs obtained by system-3 on TDT3 using different parameters.",
                "Theθ init parameter is tested on six values spanning from 0.03 to 0.18.",
                "And the λ parameter is tested on four values 1, 2, 3 and 4.",
                "We can see that, whenθ init is set to 0.12, which is the closest one toθ new, the costs are lower than others.",
                "This is easy to explain, because when stories belonging to the same topic are put in a cluster, it is more reasonable for the cluster to represent the stories in it.",
                "When parameter λ is set to 3 or 4, the costs are better than other cases, but there is no much difference between 3 and 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ MinCost 0.6 0.65 0.7 0.75 0.8 0.85 0.9 Figure 3.",
                "Min Cost on TDT3 (δ =0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ Comparingtimes 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 Figure 4.",
                "Comparing times on TDT3 (δ =0.15) Figure 4 gives the comparing times used by system-3 on TDT3 with the same parameters as figure 3.",
                "The comparing times are strongly dependent onθ init.",
                "Because the greaterθ init is, the less stories combined together, the more comparing times are needed for new event decision.",
                "So we useθ init =0.13,λ =3,δ =0.15 for system-3, 4, and 5.",
                "In this parameter setting, we can get both low minimum normalized costs and less comparing times. 8.",
                "CONCLUSION We have proposed a news indexing-tree based detection procedure in our model.",
                "It reduces comparing times to about one seventh of traditional method without hurting NED accuracy.",
                "We also have presented two extensions to the basic TF-IDF model.",
                "The first extension is made by adjust term weights based on term distributions between the whole corpus and a cluster story set.",
                "And the second extension to basic TF-IDF model is better use of term types (named entities types and part-of-speed) according to news categories.",
                "Our experimental results on TDT2 and TDT3 datasets show that both of the two extensions contribute significantly to improvement in accuracy.",
                "We did not consider news time information as a clue for NED task, since most of the topics last for a long time and TDT data sets only span for a relative short period (no more than 6 months).",
                "For the future work, we want to collect news set which span for a longer period from internet, and integrate time information in NED task.",
                "Since topic is a relative coarse-grained news cluster, we also want to refine cluster granularity to event-level, and identify different events and their relations within a topic.",
                "Acknowledgments This work is supported by the National Natural Science Foundation of China under Grant No. 90604025.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] In Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. .01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90 1 2 5 10 20 40 60 80 90 False Alarm Probability (in %) MissProbability(in%) SYSTEM1 Topic Weighted Curve SYSTEM1 Min Norm(Cost) SYSTEM2 Topic Weighted Curve SYSTEM2 Min Norm(Cost) SYSTEM3 Topic Weighted Curve SYSTEM3 Min Norm(Cost) SYSTEM4 Topic Weighted Curve SYSTEM4 Min Norm(Cost) SYSTEM5 Topic Weighted Curve SYSTEM5 Min Norm(Cost) Random Performance Figure 5.",
                "DET curves on TDT3 [3] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B.T.",
                "Archibald, and X. Liu.",
                "Learning Approaches for Detecting and Tracking News Events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), 1999, 32-43. [4] Y. Yang, T. Pierce, and J. Carbonell.",
                "A Study on Retrospective and On-line Event Detection.",
                "In Proceedings of SIGIR-98, Melbourne, Australia, 1998, 28-36. [5] J. Allan, V. Lavrenko, D. Malin, and R. Swan.",
                "Detections, Bounds, and Timelines: Umass and tdt-3.",
                "In Proceedings of Topic Detection and Tracking Workshop (TDT-3), Vienna, VA, 2000, 167-174. [6] R. Papka and J. Allan.",
                "On-line New Event Detection Using Single Pass Clustering TITLE2:.",
                "Technical Report UM-CS1998-021, 1998. [7] W. Lam, H. Meng, K. Wong, and J.",
                "Yen.",
                "Using Contextual Analysis for News Event Detection.",
                "International Journal on Intelligent Systems, 2001, 525-546. [8] B. Thorsten, C. Francine, and F. Ayman.",
                "A System for New Event Detection.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2003, 330-337. [9] S. Nicola and C. Joe.",
                "Combining Semantic and Syntactic Document Classifiers to Improve First Story Detection.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2001, 424425. [10] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topicconditioned Novelty Detection.",
                "In Proceedings of the 8th ACM SIGKDD International Conference, ACM Press. 2002, 688-693. [11] M. Juha, A.M. Helena, and S. Marko.",
                "Applying Semantic Classes in Event Detection and Tracking.",
                "In Proceedings of International Conference on Natural Language Processing (ICON 2002), 2002, pages 175-183. [12] M. Juha, A.M. Helena, and S. Marko.",
                "Simple Semantics in Topic Detection and Tracking.",
                "Information Retrieval, 7(3-4): 2004, 347-368. [13] K. Giridhar and J. Allan.",
                "Text Classification and Named Entities for New Event Detection.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2004, 297-304. [14] J. P. Callan, W. B. Croft, and S. M. Harding.",
                "The INQUERY Retrieval System.",
                "In Proceedings of DEXA-92, 3rd International Conference on Database and Expert Systems Applications, 1992, 78-83. [15] R. Krovetz.",
                "Viewing Morphology as An Inference Process.",
                "In Proceedings of ACM SIGIR93, 1993, 61-81. [16] Y. Yang and J. Pedersen.",
                "A Comparative Study on Feature Selection in Text Categorization.",
                "In J. D. H. Fisher, editor, The Fourteenth International Conference on Machine Learning (ICML97), Morgan Kaufmann, 1997, 412-420. [17] T. M. Cover, and J.A.",
                "Thomas.",
                "Elements of Information Theory.",
                "Wiley. 1991. [18] The linguistic data consortium, http://www.ldc,upenn.edu/. [19] The 2001 TDT task definition and evaluation plan, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm. [20] R. E. Schapire and Y.",
                "Singer.",
                "Boostexter: A Boosting-based System for Text Categorization.",
                "In Machine Learning 39(2/3):1, Kluwer Academic Publishers, 2000, 35-168. [21] K. Giridhar and J. Allan. 2005.",
                "Using Names and Topics for New Event Detection.",
                "In Proceedings of Human Technology Conference and Conference on Empirical Methods in Natural Language, Vancouver, 2005, 121-128"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Con el abrumador \"volumen de noticias\" disponibles hoy, existe una creciente necesidad de un sistema NED que pueda detectar nuevos eventos de manera más eficiente y precisa."
            ],
            "translated_text": "",
            "candidates": [
                "Volumen de noticias",
                "volumen de noticias"
            ],
            "error": []
        },
        "news volume": {
            "translated_key": "volumen de noticias",
            "is_in_text": false,
            "original_annotated_sentences": [
                "New Event Detection Based on Indexing-tree and Named Entity Zhang Kuo Tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn Li Juan Zi Tsinghua University Beijing, 100084, China 86-10-62781461 ljz@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn ABSTRACT New Event Detection (NED) aims at detecting from one or multiple streams of news stories that which one is reported on a new event (i.e.",
                "not reported previously).",
                "With the overwhelming volume of news available today, there is an increasing need for a NED system which is able to detect new events more efficiently and accurately.",
                "In this paper we propose a new NED model to speed up the NED task by using news indexing-tree dynamically.",
                "Moreover, based on the observation that terms of different types have different effects for NED task, two term reweighting approaches are proposed to improve NED accuracy.",
                "In the first approach, we propose to adjust term weights dynamically based on previous story clusters and in the second approach, we propose to employ statistics on training data to learn the named entity reweighting model for each class of stories.",
                "Experimental results on two Linguistic Data Consortium (LDC) datasets TDT2 and TDT3 show that the proposed model can improve both efficiency and accuracy of NED task significantly, compared to the baseline system and other existing systems.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Search and Retrieval; H.4.2 [Information Systems Applications]: Types of Systemsdecision support.",
                "General Terms Algorithms, Performance, Experimentation 1.",
                "INTRODUCTION Topic Detection and Tracking (TDT) program aims to develop techniques which can effectively organize, search and structure news text materials from a variety of newswire and broadcast media [1].",
                "New Event Detection (NED) is one of the five tasks in TDT.",
                "It is the task of online identification of the earliest report for each topic as soon as that report arrives in the sequence of documents.",
                "A Topic is defined as a seminal event or activity, along with directly related events and activities [2].",
                "An Event is defined as something (non-trivial) happening in a certain place at a certain time [3].",
                "For instance, when a bomb explodes in a building, the exploding is the seminal event that triggers the topic, and other stories on the same topic would be those discussing salvaging efforts, the search for perpetrators, arrests and trial and so on.",
                "Useful news information is usually buried in a mass of data generated everyday.",
                "Therefore, NED systems are very useful for people who need to detect novel information from real-time news stream.",
                "These real-life needs often occur in domains like financial markets, news analysis, and intelligence gathering.",
                "In most of state-of-the-art (currently) NED systems, each news story on hand is compared to all the previous received stories.",
                "If all the similarities between them do not exceed a threshold, then the story triggers a new event.",
                "They are usually in the form of cosine similarity or Hellinger similarity metric.",
                "The core problem of NED is to identify whether two stories are on the same topic.",
                "Obviously, these systems cannot take advantage of topic information.",
                "Further more, it is not acceptable in real applications because of the large amount of computation required in the NED process.",
                "Other systems organize previous stories into clusters (each cluster corresponds to a topic), and new story is compared to the previous clusters instead of stories.",
                "This manner can reduce comparing times significantly.",
                "Nevertheless, it has been proved that this manner is less accurate [4, 5].",
                "This is because sometimes stories within a topic drift far away from each other, which could lead low similarity between a story and its topic.",
                "On the other hand, some proposed NED systems tried to improve accuracy by making better use of named entities [10, 11, 12, 13].",
                "However, none of the systems have considered that terms of different types (e.g.",
                "Noun, Verb or Person name) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "For example, the names of election candidates (Person name) are very important for stories of election class; the locations (Location name) where accidents happened are important for stories of accidents class.",
                "So, in NED, there still exist following three problems to be investigated: (1) How to speed up the detection procedure while do not decrease the detection accuracy? (2) How to make good use of cluster (topic) information to improve accuracy? (3) How to obtain better news story representation by better understanding of named entities.",
                "Driven by these problems, we have proposed three approaches in this paper. (1)To make the detection procedure faster, we propose a new NED procedure based on news indexing-tree created dynamically.",
                "Story indexing-tree is created by assembling similar stories together to form news clusters in different hierarchies according to their values of similarity.",
                "Comparisons between current story and previous clusters could help find the most similar story in less comparing times.",
                "The new procedure can reduce the amount of comparing times without hurting accuracy. (2)We use the clusters of the first floor in the indexing-tree as news topics, in which term weights are adjusted dynamically according to term distribution in the clusters.",
                "In this approach, cluster (topic) information is used properly, so the problem of theme decentralization is avoided. (3)Based on observations on the statistics obtained from training data, we found that terms of different types (e.g.",
                "Noun and Verb) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "And we propose to use statistics to optimize the weights of the terms of different types in a story according to the news class that the story belongs to.",
                "On TDT3 dataset, the new NED model just uses 14.9% comparing times of the basic model, while its minimum normalized cost is 0.5012, which is 0.0797 better than the basic model, and also better than any other results previously reported for this dataset [8, 13].",
                "The rest of the paper is organized as follows.",
                "We start off this paper by summarizing the previous work in NED in section 2.",
                "Section 3 presents the basic model for NED that most current systems use.",
                "Section 4 describes our new detection procedure based on news indexing-tree.",
                "In section 5, two term reweighting methods are proposed to improve NED accuracy.",
                "Section 6 gives our experimental data and evaluation metrics.",
                "We finally wrap up with the experimental results in Section 7, and the conclusions and future work in Section 8. 2.",
                "RELATED WORK Papka et al. proposed Single-Pass clustering on NED [6].",
                "When a new story was encountered, it was processed immediately to extract term features and a query representation of the storys content is built up.",
                "Then it was compared with all the previous queries.",
                "If the document did not trigger any queries by exceeding a threshold, it was marked as a new event.",
                "Lam et al build up previous query representations of story clusters, each of which corresponds to a topic [7].",
                "In this manner comparisons happen between stories and clusters.",
                "Recent years, most work focus on proposing better methods on comparison of stories and document representation.",
                "Brants et al. [8] extended a basic incremental TF-IDF model to include sourcespecific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, term reweighting based on inverse event frequencies, and segmentation of documents.",
                "Good improvements on TDT bench-marks were shown.",
                "Stokes et al. [9] utilized a combination of evidence from two distinct representations of a documents content.",
                "One of the representations was the usual free text vector, the other made use of lexical chains (created using WordNet) to build another term vector.",
                "Then the two representations are combined in a linear fashion.",
                "A marginal increase in effectiveness was achieved when the combined representation was used.",
                "Some efforts have been done on how to utilize named entities to improve NED.",
                "Yang et al. gave location named entities four times weight than other terms and named entities [10].",
                "DOREMI research group combined semantic similarities of person names, location names and time together with textual similarity [11][12].",
                "UMass [13] research group split document representation into two parts: named entities and non-named entities.",
                "And it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation.",
                "Both [10] and [13] used text categorization technique to classify news stories in advance.",
                "In [13] news stories are classified automatically at first, and then test sensitivities of names and non-name terms for NED for each class.",
                "In [10] frequent terms for each class are removed from document representation.",
                "For example, word election does not help identify different elections.",
                "In their work, effectiveness of different kinds of names (or terms with different POS) for NED in different news classes are not investigated.",
                "We use statistical analysis to reveal the fact and use it to improve NED performance. 3.",
                "BASIC MODEL In this section, we present the basic New Event Detection model which is similar to what most current systems apply.",
                "Then, we propose our new model by extending the basic model.",
                "New Event Detection systems use news story stream as input, in which stories are strictly time-ordered.",
                "Only previously received stories are available when dealing with current story.",
                "The output is a decision for whether the current story is on a new event or not and the confidence of the decision.",
                "Usually, a NED model consists of three parts: story representation, similarity calculation and detection procedure. 3.1 Story Representation Preprocessing is needed before generating story representation.",
                "For preprocessing, we tokenize words, recognize abbreviations, normalize abbreviations, add part-of-speech tags, remove stopwords included in the stop list used in InQuery [14], replace words with their stems using K-stem algorithm[15], and then generate word vector for each news story.",
                "We use incremental TF-IDF model for term weight calculation [4].",
                "In a TF-IDF model, term frequency in a news document is weighted by the inverse document frequency, which is generated from training corpus.",
                "When a new term occurs in testing process, there are two solutions: simply ignore the new term or set df of the term as a small const (e.g. df = 1).",
                "The new term receives too low weight in the first solution (0) and too high weight in the second solution.",
                "In incremental TF-IDF model, document frequencies are updated dynamically in each time step t: 1( ) ( ) ( )t t D tdf w df w df w−= + (1) where Dt represents news story set received in time t, and dfDt(w) means the number of documents that term w occurs in, and dft(w) means the total number of documents that term w occurs in before time t. In this work, each time window includes 50 news stories.",
                "Thus, each story d received in t is represented as follows: 1 2{ ( , , ), ( , , ),..., ( , , )}nd weight d t w weight d t w weight d t w→ where n means the number of distinct terms in story d, and ( , , )weight d t w means the weight of term w in story d at time t: log( ( , ) 1) log(( 1) /( ( ) 0.5)) ( , , ) log( ( , ) 1) log(( 1) /( ( ) 0.5)) t t t t w d tf d w N df w weight d t w tf d w N df w ∈ + + + = + + +∑ (2) where Nt means the total number of news stories before time t, and tf(d,w) means how many times term w occurs in news story d. 3.2 Similarity Calculation We use Hellinger distance for the calculation of similarity between two stories, for two stories d and d at time t, their similarity is defined as follows: , ( , , ) ( , , ) * ( , , ) w d d sim d d t weight d t w weight d t w ∈ = ∑ (3) 3.3 Detection Procedure For each story d received in time step t, the value ( ) ( ) ( ) ( ( , , )) time d time d n d max sim d d t < = (4) is a score used to determine whether d is a story about a new topic and at the same time is an indication of the confidence in our decision [8]. time(d) means the publication time of story d. If the score exceeds the thresholdθ new, then there exists a sufficiently similar document, thus d is a old story, otherwise, there is no sufficiently similar previous document, thus d is an new story. 4.",
                "New NED Procedure Traditional NED systems can be classified into two main types on the aspect of detection procedure: (1) S-S type, in which the story on hand is compared to each story received previously, and use the highest similarity to determine whether current story is about a new event; (2) S-C type, in which the story on hand is compared to all previous clusters each of which representing a topic, and the highest similarity is used for final decision for current story.",
                "If the highest similarity exceeds thresholdθ new, then it is an old story, and put it into the most similar cluster; otherwise it is a new story and create a new cluster.",
                "Previous work show that the first manner is more accurate than the second one [4][5].",
                "Since sometimes stories within a topic drift far away from each other, a story may have very low similarity with its topic.",
                "So using similarities between stories for determining new story is better than using similarities between story and clusters.",
                "Nevertheless, the first manner needs much more comparing times which means the first manner is low efficient.",
                "We propose a new detection procedure which uses comparisons with previous clusters to help find the most similar story in less comparing times, and the final new event decision is made according to the most similar story.",
                "Therefore, we can get both the accuracy of S-S type methods and the efficiency of S-C type methods.",
                "The new procedure creates a news indexing-tree dynamically, in which similar stories are put together to form a hierarchy of clusters.",
                "We index similar stories together by their common ancestor (a cluster node).",
                "Dissimilar stories are indexed in different clusters.",
                "When a story is coming, we use comparisons between the current story and previous hierarchical clusters to help find the most similar story which is useful for new event decision.",
                "After the new event decision is made, the current story is inserted to the indexing-tree for the following detection.",
                "The news indexing-tree is defined formally as follows: S-Tree = {r, NC , NS , E} where r is the root of S-Tree, NC is the set of all cluster nodes, NS is the set of all story nodes, and E is the set of all edges in S-Tree.",
                "We define a set of constraints for a S-Tree: ⅰ . , is an non-terminal node in the treeC i i N i∀ ∈ → ⅱ . , is a terminal node in the treeS i i N i∀ ∈ → ⅲ . , out degree of is at least 2C i i N i∀ ∈ → ⅳ . , is represented as the centroid of its desendantsC i i iN∀ ∈ → For a news story di, the comparison procedure and inserting procedure based on indexing-tree are defined as follows.",
                "An example is shown by Figure 1 and Figure 2.",
                "Figure 1.",
                "Comparison procedure Figure 2.",
                "Inserting procedure Comparison procedure: Step 1: compare di to all the direct child nodes of r and select λ nodes with highest similarities, e.g., C1 2 and C1 3 in Figure 1.",
                "Step 2: for each selected node in the last step, e.g.",
                "C1 2, compare di to all its direct child nodes, and select λ nodes with highest similarities, e.g.",
                "C2 2 and d8.",
                "Repeat step 2 for all non-terminal nodes.",
                "Step 3: record the terminal node with the highest similarty to di, e.g. s5, and the similarity value (0.20).",
                "Inserting di to the S-tree with r as root: Find the node n which is direct child of r in the path from r to the terminal node with highest similarity s, e.g.",
                "C1 2.",
                "If s is smaller than θ init+(h-1)δ , then add di to the tree as a direct child of r. Otherwise, if n is a terminal node, then create a cluster node instead of n, and add both n and di as its direct children; if n is an non-terminal node, then repeat this procedure and insert di to the sub-tree with n as root recursively.",
                "Here h is the length between n and the root of S-tree.",
                "The more the stories in a cluster similar to each other, the better the cluster represents the stories in it.",
                "Hence we add no constraints on the maximum of trees height and degree of a node.",
                "Therefore, we cannot give the complexity of this indexing-tree based procedure.",
                "But we will give the number of comparing times needed by the new procedure in our experiments in section7. 5.",
                "Term Reweighting Methods In this section, two term reweighting methods are proposed to improve NED accuracy.",
                "In the first method, a new way is explored for better using of cluster (topic) information.",
                "The second one finds a better way to make use of named entities based on news classification. 5.1 Term Reweighting Based on Distribution Distance TF-IDF is the most prevalent model used in information retrieval systems.",
                "The basic idea is that the fewer documents a term appears in, the more important the term is in discrimination of documents (relevant or not relevant to a query containing the term).",
                "Nevertheless, in TDT domain, we need to discriminate documents with regard to topics rather than queries.",
                "Intuitively, using cluster (topic) vectors to compare with subsequent news stories should outperform using story vectors.",
                "Unfortunately, the experimental results do not support this intuition [4][5].",
                "Based on observation on data, we find the reason is that a news topic usually contains many directly or indirectly related events, while they all have their own sub-subjects which are usually different with each other.",
                "Take the topic described in section 1 as an example, events like the explosion and salvage have very low similarities with events about criminal trial, therefore stories about trial would have low similarity with the topic vector built on its previous events.",
                "This section focuses on how to effectively make use of topic information and at the same time avoid the problem of content decentralization.",
                "At first, we classify terms into 5 classes to help analysis the needs of the modified model: Term class A: terms that occur frequently in the whole corpus, e.g., year and people.",
                "Terms of this class should be given low weights because they do not help much for topic discrimination.",
                "Term class B: terms that occur frequently within a news category, e.g., election, storm.",
                "They are useful to distinguish two stories in different news categories.",
                "However, they cannot provide information to determine whether two stories are on the same or different topics.",
                "In another words, term election and term storm are not helpful in differentiate two election campaigns and two storm disasters.",
                "Therefore, terms of this class should be assigned lower weights.",
                "Term class C: terms that occur frequently in a topic, and infrequently in other topics, e.g., the name of a crash plane, the name of a specific hurricane.",
                "News stories that belong to different topics rarely have overlap terms in this class.",
                "The more frequently a term appears in a topic, the more important the term is for a story belonging to the topic, therefore the term should be set higher weight.",
                "Term class D: terms that appear in a topic exclusively, but not frequently.",
                "For example, the name of a fireman who did very well in a salvage action, which may appears in only two or three stories but never appeared in other topics.",
                "Terms of this type should receive more weights than in TF-IDF model.",
                "However, since they are not popular in the topic, it is not appropriate to give them too high weights.",
                "Term class E: terms with low document frequency, and appear in different topics.",
                "Terms of this class should receive lower weights.",
                "Now we analyze whether TF-IDF model can give proper weights to the five classes of terms.",
                "Obviously, terms of class A are lowly weighted in TF-IDF model, which is conformable with the requirement described above.",
                "In TF-IDF model, terms of class B are highly dependant with the number of stories in a news class.",
                "TF-IDF model cannot provide low weights if the story containing the term belongs to a relative small news class.",
                "For a term of class C, the more frequently it appears in a topic, the less weight TFIDF model gives to it.",
                "This strongly conflicts with the requirement of terms in class C. For terms of class D, TF-IDF model gives them high weights correctly.",
                "But for terms of class E, TF-IDF model gives high weights to them which are not conformable with the requirement of low weights.",
                "To sum up, terms of class B, C, E cannot be properly weighted in TF-IDF model.",
                "So, we propose a modified model to resolve this problem.",
                "When θ init andθ new are set closely, we assume that most of the stories in a first-level cluster (a direct child node of root node) are on the same topic.",
                "Therefore, we make use of a first-level cluster to capture term distribution (df for all the terms within the cluster) within the topic dynamically.",
                "KL divergence of term distribution in a first-level cluster and the whole story set is used to adjust term weights:  ( , , ) * (1 * ( || )) ( , , ) ( , , ) * (1 * ( || )) cw tw cw tw w d D weight d t w KL P P weight d t w weight d t w KL P P γ γ ∈ + = +∑ (5) where ( ) ( ) ( ) ( ) 1,cw cw c c c c df w df w p y p y N N = = − (6) ( ) ( ) ( ) ( ) 1,t t tw tw t t df w df w p y p y N N = = − (7) where dfc(w) is the number of documents containing term w within cluster C, and Nc is the number of documents in cluster C, and Nt is the total number of documents that arrive before time step t. γ is a const parameter, now is manually set 3.",
                "KL divergence is defined as follows [17]: ( ) ( || ) ( ) log ( )x p x KL P Q p x q x = ∑ (8) The basic idea is: for a story in a topic, the more a term occurs within the topic, and the less it occurs in other topics, it should be assigned higher weights.",
                "Obviously, modified model can meet all the requirements of the five term classes listed above. 5.2 Term Reweighting Based on Term Type and Story Class Previous work found that some classes of news stories could achieve good improvements by giving extra weight to named entities.",
                "But we find that terms of different types should be given different amount of extra weight for different classes of news stories.",
                "We use open-NLP1 to recognize named entity types and part-ofspeech tags for terms that appear in news stories.",
                "Named entity types include person name, organization name, location name, date, time, money and percentage, and five POSs are selected: none (NN), verb (VB), adjective (JJ), adverb (RB) and cardinal number (CD).",
                "Statistical analysis shows topic-level discriminative terms types for different classes of stories.",
                "For the sake of convenience, named entity type and part-of-speech tags are uniformly called term type in subsequent sections.",
                "Determining whether two stories are about the same topic is a basic component for NED task.",
                "So at first we use 2 χ statistic to compute correlations between terms and topics.",
                "For a term t and a topic T, a contingence table is derived: Table 1.",
                "A 2×2 Contingence Table Doc Number belong to topic T not belong to topic T include t A B not include t C D The 2 χ statistic for a specific term t with respect to topic T is defined to be [16]: 2 2 ( , ) ( ) * ( ) ( ) * ( ) * ( ) * ( ) w T A B C D AD CB A C B D A B C D χ = + + + − + + + + (9) News topics for the TDT task are further classified into 11 rules of interpretations (ROIs) 2 .",
                "The ROI can be seen as a higher level class of stories.",
                "The average correlation between a term type and a topic ROI is computed as: 2 avg 2 ( , )( ( , ) )k m m km kT R w P w TP R p w T R P χ χ ∈ ∈ ∑ ∑（ , ）= 1 1 k=1…K, m=1…M (10) where K is the number of term types (set 12 constantly in the paper).",
                "M is the number news classes (ROIs, set 11 in the paper).",
                "Pk represents the set of all terms of type k, and Rm represents the set of all topics of class m, p(t,T) means the probability that t occurs in topic T. Because of limitation of space, only parts of the term types (9 term types) and parts of news classes (8 classes) are listed in table 2 with the average correlation values between them.",
                "The statistics is derived from labeled data in TDT2 corpus. (Results in table 2 are already normalized for convenience in comparison.)",
                "The statistics in table 2 indicates the usefulness of different term types in topic discrimination with respect to different news classes.",
                "We can see that, location name is the most useful term type for three news classes: Natural Disasters, Violence or War, Finances.",
                "And for three other categories Elections, Legal/Criminal Cases, Science and Discovery, person name is the most discriminative term type.",
                "For Scandals/Hearings, date is the most important information for topic discrimination.",
                "In addition, Legal/Criminal Cases and Finance topics have higher correlation with money terms, while Science and Discovery have higher correlation with percentage terms.",
                "Non-name terms are more stable for different classes. 1 . http://opennlp.sourceforge.net/ 2 . http://projects.ldc.upenn.edu/TDT3/Guide/label.html From the analysis of table 2, it is reasonable to adjust term weight according to their term type and the news class the story belongs to.",
                "New term weights are reweighted as follows: ( ) ( ) ( ) ( ) ( , , ) * ( , , ) ( , , ) * class d D type w T class d D type w w d weight d t w weight d t w weight d t w α α ∈ = ∑ (11) where type(w) represents the type of term w, and class(d) represents the class of story d, c kα is reweighting parameter for news class c and term type k. In the work, we just simply use statistics in table 2 as the reweighting parameters.",
                "Even thought using the statistics directly may not the best choice, we do not discuss how to automatically obtain the best parameters.",
                "We will try to use machine learning techniques to obtain the best parameters in the future work.",
                "In the work, we use BoosTexter [20] to classify all stories into one of the 11 ROIs.",
                "BoosTexter is a boosting based machine learning program, which creates a series of simple rules for building a classifier for text or attribute-value data.",
                "We use term weight generated using TF-IDF model as feature for story classification.",
                "We trained the model on the 12000 judged English stories in TDT2, and classify the rest of the stories in TDT2 and all stories in TDT3.",
                "Classification results are used for term reweighting in formula (11).",
                "Since the class labels of topic-off stories are not given in TDT datasets, we cannot give the classification accuracy here.",
                "Thus we do not discuss the effects of classification accuracy to NED performance in the paper. 6.",
                "EXPERIMENTAL SETUP 6.1 Datasets We used two LDC [18] datasets TDT2 and TDT3 for our experiments.",
                "TDT2 contains news stories from January to June 1998.",
                "It contains around 54,000 stories from sources like ABC, Associated Press, CNN, New York Times, Public Radio International, Voice of America etc.",
                "Only English stories in the collection were considered.",
                "TDT3 contains approximately 31,000 English stories collected from October to December 1998.",
                "In addition to the sources used in TDT2, it also contains stories from NBC and MSNBC TV broadcasts.",
                "We used transcribed versions of the TV and radio broadcasts besides textual news.",
                "TDT2 dataset is labeled with about 100 topics, and approximately 12,000 English stories belong to at least one of these topics.",
                "TDT3 dataset is labeled with about 120 topics, and approximately 8000 English stories belong to at least one of these topics.",
                "All the topics are classified into 11 Rules of Interpretation: (1)Elections, (2)Scandals/Hearings, (3)Legal/Criminal Cases, (4)Natural Disasters, (5)Accidents, (6)Ongoing Violence or War, (7)Science and Discovery News, (8)Finance, (9)New Law, (10)Sports News, (11)MISC.",
                "News. 6.2 Evaluation Metric TDT uses a cost function CDet that combines the probabilities of missing a new story and a false alarm [19]: * * * *Det Miss Miss Target FA FA NontargetC C P P C P P= + (12) Table 2.",
                "Average correlation between term types and news classes where CMiss means the cost of missing a new story, PMiss means the probability of missing a new story, and PTarget means the probability of seeing a new story in the data; CFA means the cost of a false alarm, PFA means the probability of a false alarm, and PNontarget means the probability of seeing an old story.",
                "The cost CDet is normalized such that a perfect system scores 0 and a trivial system, which is the better one of mark all stories as new or old, scores 1: ( ( * , * ) ) Det Det Miss Target FA Nontarget C Norm C min C P C P = (13) New event detection system gives two outputs for each story.",
                "The first part is yes or no indicating whether the story triggers a new event or not.",
                "The second part is a score indicating confidence of the first decision.",
                "Confidence scores can be used to plot DET curve, i.e., curves that plot false alarm vs. miss probabilities.",
                "Minimum normalized cost can be determined if optimal threshold on the score were chosen. 7.",
                "EXPERIMENTAL RESULTS 7.1 Main Results To test the approaches proposed in the model, we implemented and tested five systems: System-1: this system is used as baseline.",
                "It is implemented based on the basic model described in section 3, i.e., using incremental TF-IDF model to generate term weights, and using Hellinger distance to compute document similarity.",
                "Similarity score normalization is also employed [8].",
                "S-S detection procedure is used.",
                "System-2: this system is the same as system-1 except that S-C detection procedure is used.",
                "System-3: this system is the same as system-1 except that it uses the new detection procedure which is based on indexing-tree.",
                "System-4: implemented based on the approach presented in section 5.1, i.e., terms are reweighted according to the distance between term distributions in a cluster and all stories.",
                "The new detection procedure is used.",
                "System-5: implemented based on the approach presented in section 5.2, i.e., terms of different types are reweighted according to news class using trained parameters.",
                "The new detection procedure is used.",
                "The following are some other NED systems: System-6: [21] for each pair of stories, it computes three similarity values for named entity, non-named entity and all terms respectively.",
                "And employ Support Vector Machine to predict new or old using the similarity values as features.",
                "System-7: [8] it extended a basic incremental TF-IDF model to include source-specific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, etc.",
                "System-8: [13] it split document representation into two parts: named entities and non-named entities, and choose one effective part for each news class.",
                "Table 3 and table 4 show topic-weighted normalized costs and comparing times on TDT2 and TDT3 datasets respectively.",
                "Since no heldout data set for fine-tuning the threshold θ new was available for experiments on TDT2, we only report minimum normalized costs for our systems in table 3.",
                "System-5 outperforms all other systems including system-6, and it performs only 2.78e+8 comparing times in detection procedure which is only 13.4% of system-1.",
                "Table 3.",
                "NED results on TDT2 Systems Min Norm(CDet) Cmp times System-1 0.5749 2.08e+9 System-2① 0.6673 3.77e+8 System-3② 0.5765 2.81e+8 System-4② 0.5431 2.99e+8 System-5② 0.5089 2.78e+8 System-6 0.5300 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 When evaluating on the normalized costs on TDT3, we use the optimal thresholds obtained from TDT2 data set for all systems.",
                "System-2 reduces comparing times to 1.29e+9 which is just 18.3% of system-1, but at the same time it also gets a deteriorated minimum normalized cost which is 0.0499 higher than system-1.",
                "System-3 uses the new detection procedure based on news indexing-tree.",
                "It requires even less comparing times than system-2.",
                "This is because story-story comparisons usually yield greater similarities than story-cluster ones, so stories tend to be combined Location Person Date Organization Money Percentage NN JJ CD Elections 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 Scandals/Hearings 0.66 0.62 0.28 1 0.11 0.02 0.27 0.13 0.05 Legal/Criminal Cases 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 Natural Disasters 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 Violence or War 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 Science and Discovery 0.11 1 0.01 0.22 0.08 0.12 0.19 0.08 0.03 Finances 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 Sports 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 together in system-3.",
                "And system-3 is basically equivalent to system-1 in accuracy results.",
                "System-4 adjusts term weights based on the distance of term distributions between the whole corpus and cluster story set, yielding a good improvement by 0.0468 compared to system-1.",
                "The best system (system-5) has a minimum normalized cost 0.5012, which is 0.0797 better than system-1, and also better than any other results previously reported for this dataset [8, 13].",
                "Further more, system-5 only needs 1.05e+8 comparing times which is 14.9% of system-1.",
                "Table 4.",
                "NED results on TDT3 Systems Norm(CDet) Min Norm(CDet) Cmp times System-1 0.6159 0.5809 7.04e+8 System-2① 0.6493 0.6308 1.29e+8 System-3② 0.6197 0.5868 1.03e+8 System-4② 0.5601 0.5341 1.03e+8 System-5② 0.5413 0.5012 1.05e+8 System-7 -- 0.5783 -System-8 -- 0.5229 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 Figure5 shows the five DET curves for our systems on data set TDT3.",
                "System-5 achieves the minimum cost at a false alarm rate of 0.0157 and a miss rate of 0.4310.",
                "We can observe that System4 and System-5 obtain lower miss probability at regions of low false alarm probabilities.",
                "The hypothesis is that, more weight value is transferred to key terms of topics from non-key terms.",
                "Similarity score between two stories belonging to different topics are lower than before, because their overlapping terms are usually not key terms of their topics. 7.2 Parameter selection for indexing-tree detection Figure 3 shows the minimum normalized costs obtained by system-3 on TDT3 using different parameters.",
                "Theθ init parameter is tested on six values spanning from 0.03 to 0.18.",
                "And the λ parameter is tested on four values 1, 2, 3 and 4.",
                "We can see that, whenθ init is set to 0.12, which is the closest one toθ new, the costs are lower than others.",
                "This is easy to explain, because when stories belonging to the same topic are put in a cluster, it is more reasonable for the cluster to represent the stories in it.",
                "When parameter λ is set to 3 or 4, the costs are better than other cases, but there is no much difference between 3 and 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ MinCost 0.6 0.65 0.7 0.75 0.8 0.85 0.9 Figure 3.",
                "Min Cost on TDT3 (δ =0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ Comparingtimes 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 Figure 4.",
                "Comparing times on TDT3 (δ =0.15) Figure 4 gives the comparing times used by system-3 on TDT3 with the same parameters as figure 3.",
                "The comparing times are strongly dependent onθ init.",
                "Because the greaterθ init is, the less stories combined together, the more comparing times are needed for new event decision.",
                "So we useθ init =0.13,λ =3,δ =0.15 for system-3, 4, and 5.",
                "In this parameter setting, we can get both low minimum normalized costs and less comparing times. 8.",
                "CONCLUSION We have proposed a news indexing-tree based detection procedure in our model.",
                "It reduces comparing times to about one seventh of traditional method without hurting NED accuracy.",
                "We also have presented two extensions to the basic TF-IDF model.",
                "The first extension is made by adjust term weights based on term distributions between the whole corpus and a cluster story set.",
                "And the second extension to basic TF-IDF model is better use of term types (named entities types and part-of-speed) according to news categories.",
                "Our experimental results on TDT2 and TDT3 datasets show that both of the two extensions contribute significantly to improvement in accuracy.",
                "We did not consider news time information as a clue for NED task, since most of the topics last for a long time and TDT data sets only span for a relative short period (no more than 6 months).",
                "For the future work, we want to collect news set which span for a longer period from internet, and integrate time information in NED task.",
                "Since topic is a relative coarse-grained news cluster, we also want to refine cluster granularity to event-level, and identify different events and their relations within a topic.",
                "Acknowledgments This work is supported by the National Natural Science Foundation of China under Grant No. 90604025.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] In Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. .01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90 1 2 5 10 20 40 60 80 90 False Alarm Probability (in %) MissProbability(in%) SYSTEM1 Topic Weighted Curve SYSTEM1 Min Norm(Cost) SYSTEM2 Topic Weighted Curve SYSTEM2 Min Norm(Cost) SYSTEM3 Topic Weighted Curve SYSTEM3 Min Norm(Cost) SYSTEM4 Topic Weighted Curve SYSTEM4 Min Norm(Cost) SYSTEM5 Topic Weighted Curve SYSTEM5 Min Norm(Cost) Random Performance Figure 5.",
                "DET curves on TDT3 [3] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B.T.",
                "Archibald, and X. Liu.",
                "Learning Approaches for Detecting and Tracking News Events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), 1999, 32-43. [4] Y. Yang, T. Pierce, and J. Carbonell.",
                "A Study on Retrospective and On-line Event Detection.",
                "In Proceedings of SIGIR-98, Melbourne, Australia, 1998, 28-36. [5] J. Allan, V. Lavrenko, D. Malin, and R. Swan.",
                "Detections, Bounds, and Timelines: Umass and tdt-3.",
                "In Proceedings of Topic Detection and Tracking Workshop (TDT-3), Vienna, VA, 2000, 167-174. [6] R. Papka and J. Allan.",
                "On-line New Event Detection Using Single Pass Clustering TITLE2:.",
                "Technical Report UM-CS1998-021, 1998. [7] W. Lam, H. Meng, K. Wong, and J.",
                "Yen.",
                "Using Contextual Analysis for News Event Detection.",
                "International Journal on Intelligent Systems, 2001, 525-546. [8] B. Thorsten, C. Francine, and F. Ayman.",
                "A System for New Event Detection.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2003, 330-337. [9] S. Nicola and C. Joe.",
                "Combining Semantic and Syntactic Document Classifiers to Improve First Story Detection.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2001, 424425. [10] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topicconditioned Novelty Detection.",
                "In Proceedings of the 8th ACM SIGKDD International Conference, ACM Press. 2002, 688-693. [11] M. Juha, A.M. Helena, and S. Marko.",
                "Applying Semantic Classes in Event Detection and Tracking.",
                "In Proceedings of International Conference on Natural Language Processing (ICON 2002), 2002, pages 175-183. [12] M. Juha, A.M. Helena, and S. Marko.",
                "Simple Semantics in Topic Detection and Tracking.",
                "Information Retrieval, 7(3-4): 2004, 347-368. [13] K. Giridhar and J. Allan.",
                "Text Classification and Named Entities for New Event Detection.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2004, 297-304. [14] J. P. Callan, W. B. Croft, and S. M. Harding.",
                "The INQUERY Retrieval System.",
                "In Proceedings of DEXA-92, 3rd International Conference on Database and Expert Systems Applications, 1992, 78-83. [15] R. Krovetz.",
                "Viewing Morphology as An Inference Process.",
                "In Proceedings of ACM SIGIR93, 1993, 61-81. [16] Y. Yang and J. Pedersen.",
                "A Comparative Study on Feature Selection in Text Categorization.",
                "In J. D. H. Fisher, editor, The Fourteenth International Conference on Machine Learning (ICML97), Morgan Kaufmann, 1997, 412-420. [17] T. M. Cover, and J.A.",
                "Thomas.",
                "Elements of Information Theory.",
                "Wiley. 1991. [18] The linguistic data consortium, http://www.ldc,upenn.edu/. [19] The 2001 TDT task definition and evaluation plan, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm. [20] R. E. Schapire and Y.",
                "Singer.",
                "Boostexter: A Boosting-based System for Text Categorization.",
                "In Machine Learning 39(2/3):1, Kluwer Academic Publishers, 2000, 35-168. [21] K. Giridhar and J. Allan. 2005.",
                "Using Names and Topics for New Event Detection.",
                "In Proceedings of Human Technology Conference and Conference on Empirical Methods in Natural Language, Vancouver, 2005, 121-128"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "speed up the ned task": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "New Event Detection Based on Indexing-tree and Named Entity Zhang Kuo Tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn Li Juan Zi Tsinghua University Beijing, 100084, China 86-10-62781461 ljz@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn ABSTRACT New Event Detection (NED) aims at detecting from one or multiple streams of news stories that which one is reported on a new event (i.e.",
                "not reported previously).",
                "With the overwhelming volume of news available today, there is an increasing need for a NED system which is able to detect new events more efficiently and accurately.",
                "In this paper we propose a new NED model to <br>speed up the ned task</br> by using news indexing-tree dynamically.",
                "Moreover, based on the observation that terms of different types have different effects for NED task, two term reweighting approaches are proposed to improve NED accuracy.",
                "In the first approach, we propose to adjust term weights dynamically based on previous story clusters and in the second approach, we propose to employ statistics on training data to learn the named entity reweighting model for each class of stories.",
                "Experimental results on two Linguistic Data Consortium (LDC) datasets TDT2 and TDT3 show that the proposed model can improve both efficiency and accuracy of NED task significantly, compared to the baseline system and other existing systems.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Search and Retrieval; H.4.2 [Information Systems Applications]: Types of Systemsdecision support.",
                "General Terms Algorithms, Performance, Experimentation 1.",
                "INTRODUCTION Topic Detection and Tracking (TDT) program aims to develop techniques which can effectively organize, search and structure news text materials from a variety of newswire and broadcast media [1].",
                "New Event Detection (NED) is one of the five tasks in TDT.",
                "It is the task of online identification of the earliest report for each topic as soon as that report arrives in the sequence of documents.",
                "A Topic is defined as a seminal event or activity, along with directly related events and activities [2].",
                "An Event is defined as something (non-trivial) happening in a certain place at a certain time [3].",
                "For instance, when a bomb explodes in a building, the exploding is the seminal event that triggers the topic, and other stories on the same topic would be those discussing salvaging efforts, the search for perpetrators, arrests and trial and so on.",
                "Useful news information is usually buried in a mass of data generated everyday.",
                "Therefore, NED systems are very useful for people who need to detect novel information from real-time news stream.",
                "These real-life needs often occur in domains like financial markets, news analysis, and intelligence gathering.",
                "In most of state-of-the-art (currently) NED systems, each news story on hand is compared to all the previous received stories.",
                "If all the similarities between them do not exceed a threshold, then the story triggers a new event.",
                "They are usually in the form of cosine similarity or Hellinger similarity metric.",
                "The core problem of NED is to identify whether two stories are on the same topic.",
                "Obviously, these systems cannot take advantage of topic information.",
                "Further more, it is not acceptable in real applications because of the large amount of computation required in the NED process.",
                "Other systems organize previous stories into clusters (each cluster corresponds to a topic), and new story is compared to the previous clusters instead of stories.",
                "This manner can reduce comparing times significantly.",
                "Nevertheless, it has been proved that this manner is less accurate [4, 5].",
                "This is because sometimes stories within a topic drift far away from each other, which could lead low similarity between a story and its topic.",
                "On the other hand, some proposed NED systems tried to improve accuracy by making better use of named entities [10, 11, 12, 13].",
                "However, none of the systems have considered that terms of different types (e.g.",
                "Noun, Verb or Person name) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "For example, the names of election candidates (Person name) are very important for stories of election class; the locations (Location name) where accidents happened are important for stories of accidents class.",
                "So, in NED, there still exist following three problems to be investigated: (1) How to speed up the detection procedure while do not decrease the detection accuracy? (2) How to make good use of cluster (topic) information to improve accuracy? (3) How to obtain better news story representation by better understanding of named entities.",
                "Driven by these problems, we have proposed three approaches in this paper. (1)To make the detection procedure faster, we propose a new NED procedure based on news indexing-tree created dynamically.",
                "Story indexing-tree is created by assembling similar stories together to form news clusters in different hierarchies according to their values of similarity.",
                "Comparisons between current story and previous clusters could help find the most similar story in less comparing times.",
                "The new procedure can reduce the amount of comparing times without hurting accuracy. (2)We use the clusters of the first floor in the indexing-tree as news topics, in which term weights are adjusted dynamically according to term distribution in the clusters.",
                "In this approach, cluster (topic) information is used properly, so the problem of theme decentralization is avoided. (3)Based on observations on the statistics obtained from training data, we found that terms of different types (e.g.",
                "Noun and Verb) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "And we propose to use statistics to optimize the weights of the terms of different types in a story according to the news class that the story belongs to.",
                "On TDT3 dataset, the new NED model just uses 14.9% comparing times of the basic model, while its minimum normalized cost is 0.5012, which is 0.0797 better than the basic model, and also better than any other results previously reported for this dataset [8, 13].",
                "The rest of the paper is organized as follows.",
                "We start off this paper by summarizing the previous work in NED in section 2.",
                "Section 3 presents the basic model for NED that most current systems use.",
                "Section 4 describes our new detection procedure based on news indexing-tree.",
                "In section 5, two term reweighting methods are proposed to improve NED accuracy.",
                "Section 6 gives our experimental data and evaluation metrics.",
                "We finally wrap up with the experimental results in Section 7, and the conclusions and future work in Section 8. 2.",
                "RELATED WORK Papka et al. proposed Single-Pass clustering on NED [6].",
                "When a new story was encountered, it was processed immediately to extract term features and a query representation of the storys content is built up.",
                "Then it was compared with all the previous queries.",
                "If the document did not trigger any queries by exceeding a threshold, it was marked as a new event.",
                "Lam et al build up previous query representations of story clusters, each of which corresponds to a topic [7].",
                "In this manner comparisons happen between stories and clusters.",
                "Recent years, most work focus on proposing better methods on comparison of stories and document representation.",
                "Brants et al. [8] extended a basic incremental TF-IDF model to include sourcespecific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, term reweighting based on inverse event frequencies, and segmentation of documents.",
                "Good improvements on TDT bench-marks were shown.",
                "Stokes et al. [9] utilized a combination of evidence from two distinct representations of a documents content.",
                "One of the representations was the usual free text vector, the other made use of lexical chains (created using WordNet) to build another term vector.",
                "Then the two representations are combined in a linear fashion.",
                "A marginal increase in effectiveness was achieved when the combined representation was used.",
                "Some efforts have been done on how to utilize named entities to improve NED.",
                "Yang et al. gave location named entities four times weight than other terms and named entities [10].",
                "DOREMI research group combined semantic similarities of person names, location names and time together with textual similarity [11][12].",
                "UMass [13] research group split document representation into two parts: named entities and non-named entities.",
                "And it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation.",
                "Both [10] and [13] used text categorization technique to classify news stories in advance.",
                "In [13] news stories are classified automatically at first, and then test sensitivities of names and non-name terms for NED for each class.",
                "In [10] frequent terms for each class are removed from document representation.",
                "For example, word election does not help identify different elections.",
                "In their work, effectiveness of different kinds of names (or terms with different POS) for NED in different news classes are not investigated.",
                "We use statistical analysis to reveal the fact and use it to improve NED performance. 3.",
                "BASIC MODEL In this section, we present the basic New Event Detection model which is similar to what most current systems apply.",
                "Then, we propose our new model by extending the basic model.",
                "New Event Detection systems use news story stream as input, in which stories are strictly time-ordered.",
                "Only previously received stories are available when dealing with current story.",
                "The output is a decision for whether the current story is on a new event or not and the confidence of the decision.",
                "Usually, a NED model consists of three parts: story representation, similarity calculation and detection procedure. 3.1 Story Representation Preprocessing is needed before generating story representation.",
                "For preprocessing, we tokenize words, recognize abbreviations, normalize abbreviations, add part-of-speech tags, remove stopwords included in the stop list used in InQuery [14], replace words with their stems using K-stem algorithm[15], and then generate word vector for each news story.",
                "We use incremental TF-IDF model for term weight calculation [4].",
                "In a TF-IDF model, term frequency in a news document is weighted by the inverse document frequency, which is generated from training corpus.",
                "When a new term occurs in testing process, there are two solutions: simply ignore the new term or set df of the term as a small const (e.g. df = 1).",
                "The new term receives too low weight in the first solution (0) and too high weight in the second solution.",
                "In incremental TF-IDF model, document frequencies are updated dynamically in each time step t: 1( ) ( ) ( )t t D tdf w df w df w−= + (1) where Dt represents news story set received in time t, and dfDt(w) means the number of documents that term w occurs in, and dft(w) means the total number of documents that term w occurs in before time t. In this work, each time window includes 50 news stories.",
                "Thus, each story d received in t is represented as follows: 1 2{ ( , , ), ( , , ),..., ( , , )}nd weight d t w weight d t w weight d t w→ where n means the number of distinct terms in story d, and ( , , )weight d t w means the weight of term w in story d at time t: log( ( , ) 1) log(( 1) /( ( ) 0.5)) ( , , ) log( ( , ) 1) log(( 1) /( ( ) 0.5)) t t t t w d tf d w N df w weight d t w tf d w N df w ∈ + + + = + + +∑ (2) where Nt means the total number of news stories before time t, and tf(d,w) means how many times term w occurs in news story d. 3.2 Similarity Calculation We use Hellinger distance for the calculation of similarity between two stories, for two stories d and d at time t, their similarity is defined as follows: , ( , , ) ( , , ) * ( , , ) w d d sim d d t weight d t w weight d t w ∈ = ∑ (3) 3.3 Detection Procedure For each story d received in time step t, the value ( ) ( ) ( ) ( ( , , )) time d time d n d max sim d d t < = (4) is a score used to determine whether d is a story about a new topic and at the same time is an indication of the confidence in our decision [8]. time(d) means the publication time of story d. If the score exceeds the thresholdθ new, then there exists a sufficiently similar document, thus d is a old story, otherwise, there is no sufficiently similar previous document, thus d is an new story. 4.",
                "New NED Procedure Traditional NED systems can be classified into two main types on the aspect of detection procedure: (1) S-S type, in which the story on hand is compared to each story received previously, and use the highest similarity to determine whether current story is about a new event; (2) S-C type, in which the story on hand is compared to all previous clusters each of which representing a topic, and the highest similarity is used for final decision for current story.",
                "If the highest similarity exceeds thresholdθ new, then it is an old story, and put it into the most similar cluster; otherwise it is a new story and create a new cluster.",
                "Previous work show that the first manner is more accurate than the second one [4][5].",
                "Since sometimes stories within a topic drift far away from each other, a story may have very low similarity with its topic.",
                "So using similarities between stories for determining new story is better than using similarities between story and clusters.",
                "Nevertheless, the first manner needs much more comparing times which means the first manner is low efficient.",
                "We propose a new detection procedure which uses comparisons with previous clusters to help find the most similar story in less comparing times, and the final new event decision is made according to the most similar story.",
                "Therefore, we can get both the accuracy of S-S type methods and the efficiency of S-C type methods.",
                "The new procedure creates a news indexing-tree dynamically, in which similar stories are put together to form a hierarchy of clusters.",
                "We index similar stories together by their common ancestor (a cluster node).",
                "Dissimilar stories are indexed in different clusters.",
                "When a story is coming, we use comparisons between the current story and previous hierarchical clusters to help find the most similar story which is useful for new event decision.",
                "After the new event decision is made, the current story is inserted to the indexing-tree for the following detection.",
                "The news indexing-tree is defined formally as follows: S-Tree = {r, NC , NS , E} where r is the root of S-Tree, NC is the set of all cluster nodes, NS is the set of all story nodes, and E is the set of all edges in S-Tree.",
                "We define a set of constraints for a S-Tree: ⅰ . , is an non-terminal node in the treeC i i N i∀ ∈ → ⅱ . , is a terminal node in the treeS i i N i∀ ∈ → ⅲ . , out degree of is at least 2C i i N i∀ ∈ → ⅳ . , is represented as the centroid of its desendantsC i i iN∀ ∈ → For a news story di, the comparison procedure and inserting procedure based on indexing-tree are defined as follows.",
                "An example is shown by Figure 1 and Figure 2.",
                "Figure 1.",
                "Comparison procedure Figure 2.",
                "Inserting procedure Comparison procedure: Step 1: compare di to all the direct child nodes of r and select λ nodes with highest similarities, e.g., C1 2 and C1 3 in Figure 1.",
                "Step 2: for each selected node in the last step, e.g.",
                "C1 2, compare di to all its direct child nodes, and select λ nodes with highest similarities, e.g.",
                "C2 2 and d8.",
                "Repeat step 2 for all non-terminal nodes.",
                "Step 3: record the terminal node with the highest similarty to di, e.g. s5, and the similarity value (0.20).",
                "Inserting di to the S-tree with r as root: Find the node n which is direct child of r in the path from r to the terminal node with highest similarity s, e.g.",
                "C1 2.",
                "If s is smaller than θ init+(h-1)δ , then add di to the tree as a direct child of r. Otherwise, if n is a terminal node, then create a cluster node instead of n, and add both n and di as its direct children; if n is an non-terminal node, then repeat this procedure and insert di to the sub-tree with n as root recursively.",
                "Here h is the length between n and the root of S-tree.",
                "The more the stories in a cluster similar to each other, the better the cluster represents the stories in it.",
                "Hence we add no constraints on the maximum of trees height and degree of a node.",
                "Therefore, we cannot give the complexity of this indexing-tree based procedure.",
                "But we will give the number of comparing times needed by the new procedure in our experiments in section7. 5.",
                "Term Reweighting Methods In this section, two term reweighting methods are proposed to improve NED accuracy.",
                "In the first method, a new way is explored for better using of cluster (topic) information.",
                "The second one finds a better way to make use of named entities based on news classification. 5.1 Term Reweighting Based on Distribution Distance TF-IDF is the most prevalent model used in information retrieval systems.",
                "The basic idea is that the fewer documents a term appears in, the more important the term is in discrimination of documents (relevant or not relevant to a query containing the term).",
                "Nevertheless, in TDT domain, we need to discriminate documents with regard to topics rather than queries.",
                "Intuitively, using cluster (topic) vectors to compare with subsequent news stories should outperform using story vectors.",
                "Unfortunately, the experimental results do not support this intuition [4][5].",
                "Based on observation on data, we find the reason is that a news topic usually contains many directly or indirectly related events, while they all have their own sub-subjects which are usually different with each other.",
                "Take the topic described in section 1 as an example, events like the explosion and salvage have very low similarities with events about criminal trial, therefore stories about trial would have low similarity with the topic vector built on its previous events.",
                "This section focuses on how to effectively make use of topic information and at the same time avoid the problem of content decentralization.",
                "At first, we classify terms into 5 classes to help analysis the needs of the modified model: Term class A: terms that occur frequently in the whole corpus, e.g., year and people.",
                "Terms of this class should be given low weights because they do not help much for topic discrimination.",
                "Term class B: terms that occur frequently within a news category, e.g., election, storm.",
                "They are useful to distinguish two stories in different news categories.",
                "However, they cannot provide information to determine whether two stories are on the same or different topics.",
                "In another words, term election and term storm are not helpful in differentiate two election campaigns and two storm disasters.",
                "Therefore, terms of this class should be assigned lower weights.",
                "Term class C: terms that occur frequently in a topic, and infrequently in other topics, e.g., the name of a crash plane, the name of a specific hurricane.",
                "News stories that belong to different topics rarely have overlap terms in this class.",
                "The more frequently a term appears in a topic, the more important the term is for a story belonging to the topic, therefore the term should be set higher weight.",
                "Term class D: terms that appear in a topic exclusively, but not frequently.",
                "For example, the name of a fireman who did very well in a salvage action, which may appears in only two or three stories but never appeared in other topics.",
                "Terms of this type should receive more weights than in TF-IDF model.",
                "However, since they are not popular in the topic, it is not appropriate to give them too high weights.",
                "Term class E: terms with low document frequency, and appear in different topics.",
                "Terms of this class should receive lower weights.",
                "Now we analyze whether TF-IDF model can give proper weights to the five classes of terms.",
                "Obviously, terms of class A are lowly weighted in TF-IDF model, which is conformable with the requirement described above.",
                "In TF-IDF model, terms of class B are highly dependant with the number of stories in a news class.",
                "TF-IDF model cannot provide low weights if the story containing the term belongs to a relative small news class.",
                "For a term of class C, the more frequently it appears in a topic, the less weight TFIDF model gives to it.",
                "This strongly conflicts with the requirement of terms in class C. For terms of class D, TF-IDF model gives them high weights correctly.",
                "But for terms of class E, TF-IDF model gives high weights to them which are not conformable with the requirement of low weights.",
                "To sum up, terms of class B, C, E cannot be properly weighted in TF-IDF model.",
                "So, we propose a modified model to resolve this problem.",
                "When θ init andθ new are set closely, we assume that most of the stories in a first-level cluster (a direct child node of root node) are on the same topic.",
                "Therefore, we make use of a first-level cluster to capture term distribution (df for all the terms within the cluster) within the topic dynamically.",
                "KL divergence of term distribution in a first-level cluster and the whole story set is used to adjust term weights:  ( , , ) * (1 * ( || )) ( , , ) ( , , ) * (1 * ( || )) cw tw cw tw w d D weight d t w KL P P weight d t w weight d t w KL P P γ γ ∈ + = +∑ (5) where ( ) ( ) ( ) ( ) 1,cw cw c c c c df w df w p y p y N N = = − (6) ( ) ( ) ( ) ( ) 1,t t tw tw t t df w df w p y p y N N = = − (7) where dfc(w) is the number of documents containing term w within cluster C, and Nc is the number of documents in cluster C, and Nt is the total number of documents that arrive before time step t. γ is a const parameter, now is manually set 3.",
                "KL divergence is defined as follows [17]: ( ) ( || ) ( ) log ( )x p x KL P Q p x q x = ∑ (8) The basic idea is: for a story in a topic, the more a term occurs within the topic, and the less it occurs in other topics, it should be assigned higher weights.",
                "Obviously, modified model can meet all the requirements of the five term classes listed above. 5.2 Term Reweighting Based on Term Type and Story Class Previous work found that some classes of news stories could achieve good improvements by giving extra weight to named entities.",
                "But we find that terms of different types should be given different amount of extra weight for different classes of news stories.",
                "We use open-NLP1 to recognize named entity types and part-ofspeech tags for terms that appear in news stories.",
                "Named entity types include person name, organization name, location name, date, time, money and percentage, and five POSs are selected: none (NN), verb (VB), adjective (JJ), adverb (RB) and cardinal number (CD).",
                "Statistical analysis shows topic-level discriminative terms types for different classes of stories.",
                "For the sake of convenience, named entity type and part-of-speech tags are uniformly called term type in subsequent sections.",
                "Determining whether two stories are about the same topic is a basic component for NED task.",
                "So at first we use 2 χ statistic to compute correlations between terms and topics.",
                "For a term t and a topic T, a contingence table is derived: Table 1.",
                "A 2×2 Contingence Table Doc Number belong to topic T not belong to topic T include t A B not include t C D The 2 χ statistic for a specific term t with respect to topic T is defined to be [16]: 2 2 ( , ) ( ) * ( ) ( ) * ( ) * ( ) * ( ) w T A B C D AD CB A C B D A B C D χ = + + + − + + + + (9) News topics for the TDT task are further classified into 11 rules of interpretations (ROIs) 2 .",
                "The ROI can be seen as a higher level class of stories.",
                "The average correlation between a term type and a topic ROI is computed as: 2 avg 2 ( , )( ( , ) )k m m km kT R w P w TP R p w T R P χ χ ∈ ∈ ∑ ∑（ , ）= 1 1 k=1…K, m=1…M (10) where K is the number of term types (set 12 constantly in the paper).",
                "M is the number news classes (ROIs, set 11 in the paper).",
                "Pk represents the set of all terms of type k, and Rm represents the set of all topics of class m, p(t,T) means the probability that t occurs in topic T. Because of limitation of space, only parts of the term types (9 term types) and parts of news classes (8 classes) are listed in table 2 with the average correlation values between them.",
                "The statistics is derived from labeled data in TDT2 corpus. (Results in table 2 are already normalized for convenience in comparison.)",
                "The statistics in table 2 indicates the usefulness of different term types in topic discrimination with respect to different news classes.",
                "We can see that, location name is the most useful term type for three news classes: Natural Disasters, Violence or War, Finances.",
                "And for three other categories Elections, Legal/Criminal Cases, Science and Discovery, person name is the most discriminative term type.",
                "For Scandals/Hearings, date is the most important information for topic discrimination.",
                "In addition, Legal/Criminal Cases and Finance topics have higher correlation with money terms, while Science and Discovery have higher correlation with percentage terms.",
                "Non-name terms are more stable for different classes. 1 . http://opennlp.sourceforge.net/ 2 . http://projects.ldc.upenn.edu/TDT3/Guide/label.html From the analysis of table 2, it is reasonable to adjust term weight according to their term type and the news class the story belongs to.",
                "New term weights are reweighted as follows: ( ) ( ) ( ) ( ) ( , , ) * ( , , ) ( , , ) * class d D type w T class d D type w w d weight d t w weight d t w weight d t w α α ∈ = ∑ (11) where type(w) represents the type of term w, and class(d) represents the class of story d, c kα is reweighting parameter for news class c and term type k. In the work, we just simply use statistics in table 2 as the reweighting parameters.",
                "Even thought using the statistics directly may not the best choice, we do not discuss how to automatically obtain the best parameters.",
                "We will try to use machine learning techniques to obtain the best parameters in the future work.",
                "In the work, we use BoosTexter [20] to classify all stories into one of the 11 ROIs.",
                "BoosTexter is a boosting based machine learning program, which creates a series of simple rules for building a classifier for text or attribute-value data.",
                "We use term weight generated using TF-IDF model as feature for story classification.",
                "We trained the model on the 12000 judged English stories in TDT2, and classify the rest of the stories in TDT2 and all stories in TDT3.",
                "Classification results are used for term reweighting in formula (11).",
                "Since the class labels of topic-off stories are not given in TDT datasets, we cannot give the classification accuracy here.",
                "Thus we do not discuss the effects of classification accuracy to NED performance in the paper. 6.",
                "EXPERIMENTAL SETUP 6.1 Datasets We used two LDC [18] datasets TDT2 and TDT3 for our experiments.",
                "TDT2 contains news stories from January to June 1998.",
                "It contains around 54,000 stories from sources like ABC, Associated Press, CNN, New York Times, Public Radio International, Voice of America etc.",
                "Only English stories in the collection were considered.",
                "TDT3 contains approximately 31,000 English stories collected from October to December 1998.",
                "In addition to the sources used in TDT2, it also contains stories from NBC and MSNBC TV broadcasts.",
                "We used transcribed versions of the TV and radio broadcasts besides textual news.",
                "TDT2 dataset is labeled with about 100 topics, and approximately 12,000 English stories belong to at least one of these topics.",
                "TDT3 dataset is labeled with about 120 topics, and approximately 8000 English stories belong to at least one of these topics.",
                "All the topics are classified into 11 Rules of Interpretation: (1)Elections, (2)Scandals/Hearings, (3)Legal/Criminal Cases, (4)Natural Disasters, (5)Accidents, (6)Ongoing Violence or War, (7)Science and Discovery News, (8)Finance, (9)New Law, (10)Sports News, (11)MISC.",
                "News. 6.2 Evaluation Metric TDT uses a cost function CDet that combines the probabilities of missing a new story and a false alarm [19]: * * * *Det Miss Miss Target FA FA NontargetC C P P C P P= + (12) Table 2.",
                "Average correlation between term types and news classes where CMiss means the cost of missing a new story, PMiss means the probability of missing a new story, and PTarget means the probability of seeing a new story in the data; CFA means the cost of a false alarm, PFA means the probability of a false alarm, and PNontarget means the probability of seeing an old story.",
                "The cost CDet is normalized such that a perfect system scores 0 and a trivial system, which is the better one of mark all stories as new or old, scores 1: ( ( * , * ) ) Det Det Miss Target FA Nontarget C Norm C min C P C P = (13) New event detection system gives two outputs for each story.",
                "The first part is yes or no indicating whether the story triggers a new event or not.",
                "The second part is a score indicating confidence of the first decision.",
                "Confidence scores can be used to plot DET curve, i.e., curves that plot false alarm vs. miss probabilities.",
                "Minimum normalized cost can be determined if optimal threshold on the score were chosen. 7.",
                "EXPERIMENTAL RESULTS 7.1 Main Results To test the approaches proposed in the model, we implemented and tested five systems: System-1: this system is used as baseline.",
                "It is implemented based on the basic model described in section 3, i.e., using incremental TF-IDF model to generate term weights, and using Hellinger distance to compute document similarity.",
                "Similarity score normalization is also employed [8].",
                "S-S detection procedure is used.",
                "System-2: this system is the same as system-1 except that S-C detection procedure is used.",
                "System-3: this system is the same as system-1 except that it uses the new detection procedure which is based on indexing-tree.",
                "System-4: implemented based on the approach presented in section 5.1, i.e., terms are reweighted according to the distance between term distributions in a cluster and all stories.",
                "The new detection procedure is used.",
                "System-5: implemented based on the approach presented in section 5.2, i.e., terms of different types are reweighted according to news class using trained parameters.",
                "The new detection procedure is used.",
                "The following are some other NED systems: System-6: [21] for each pair of stories, it computes three similarity values for named entity, non-named entity and all terms respectively.",
                "And employ Support Vector Machine to predict new or old using the similarity values as features.",
                "System-7: [8] it extended a basic incremental TF-IDF model to include source-specific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, etc.",
                "System-8: [13] it split document representation into two parts: named entities and non-named entities, and choose one effective part for each news class.",
                "Table 3 and table 4 show topic-weighted normalized costs and comparing times on TDT2 and TDT3 datasets respectively.",
                "Since no heldout data set for fine-tuning the threshold θ new was available for experiments on TDT2, we only report minimum normalized costs for our systems in table 3.",
                "System-5 outperforms all other systems including system-6, and it performs only 2.78e+8 comparing times in detection procedure which is only 13.4% of system-1.",
                "Table 3.",
                "NED results on TDT2 Systems Min Norm(CDet) Cmp times System-1 0.5749 2.08e+9 System-2① 0.6673 3.77e+8 System-3② 0.5765 2.81e+8 System-4② 0.5431 2.99e+8 System-5② 0.5089 2.78e+8 System-6 0.5300 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 When evaluating on the normalized costs on TDT3, we use the optimal thresholds obtained from TDT2 data set for all systems.",
                "System-2 reduces comparing times to 1.29e+9 which is just 18.3% of system-1, but at the same time it also gets a deteriorated minimum normalized cost which is 0.0499 higher than system-1.",
                "System-3 uses the new detection procedure based on news indexing-tree.",
                "It requires even less comparing times than system-2.",
                "This is because story-story comparisons usually yield greater similarities than story-cluster ones, so stories tend to be combined Location Person Date Organization Money Percentage NN JJ CD Elections 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 Scandals/Hearings 0.66 0.62 0.28 1 0.11 0.02 0.27 0.13 0.05 Legal/Criminal Cases 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 Natural Disasters 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 Violence or War 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 Science and Discovery 0.11 1 0.01 0.22 0.08 0.12 0.19 0.08 0.03 Finances 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 Sports 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 together in system-3.",
                "And system-3 is basically equivalent to system-1 in accuracy results.",
                "System-4 adjusts term weights based on the distance of term distributions between the whole corpus and cluster story set, yielding a good improvement by 0.0468 compared to system-1.",
                "The best system (system-5) has a minimum normalized cost 0.5012, which is 0.0797 better than system-1, and also better than any other results previously reported for this dataset [8, 13].",
                "Further more, system-5 only needs 1.05e+8 comparing times which is 14.9% of system-1.",
                "Table 4.",
                "NED results on TDT3 Systems Norm(CDet) Min Norm(CDet) Cmp times System-1 0.6159 0.5809 7.04e+8 System-2① 0.6493 0.6308 1.29e+8 System-3② 0.6197 0.5868 1.03e+8 System-4② 0.5601 0.5341 1.03e+8 System-5② 0.5413 0.5012 1.05e+8 System-7 -- 0.5783 -System-8 -- 0.5229 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 Figure5 shows the five DET curves for our systems on data set TDT3.",
                "System-5 achieves the minimum cost at a false alarm rate of 0.0157 and a miss rate of 0.4310.",
                "We can observe that System4 and System-5 obtain lower miss probability at regions of low false alarm probabilities.",
                "The hypothesis is that, more weight value is transferred to key terms of topics from non-key terms.",
                "Similarity score between two stories belonging to different topics are lower than before, because their overlapping terms are usually not key terms of their topics. 7.2 Parameter selection for indexing-tree detection Figure 3 shows the minimum normalized costs obtained by system-3 on TDT3 using different parameters.",
                "Theθ init parameter is tested on six values spanning from 0.03 to 0.18.",
                "And the λ parameter is tested on four values 1, 2, 3 and 4.",
                "We can see that, whenθ init is set to 0.12, which is the closest one toθ new, the costs are lower than others.",
                "This is easy to explain, because when stories belonging to the same topic are put in a cluster, it is more reasonable for the cluster to represent the stories in it.",
                "When parameter λ is set to 3 or 4, the costs are better than other cases, but there is no much difference between 3 and 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ MinCost 0.6 0.65 0.7 0.75 0.8 0.85 0.9 Figure 3.",
                "Min Cost on TDT3 (δ =0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ Comparingtimes 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 Figure 4.",
                "Comparing times on TDT3 (δ =0.15) Figure 4 gives the comparing times used by system-3 on TDT3 with the same parameters as figure 3.",
                "The comparing times are strongly dependent onθ init.",
                "Because the greaterθ init is, the less stories combined together, the more comparing times are needed for new event decision.",
                "So we useθ init =0.13,λ =3,δ =0.15 for system-3, 4, and 5.",
                "In this parameter setting, we can get both low minimum normalized costs and less comparing times. 8.",
                "CONCLUSION We have proposed a news indexing-tree based detection procedure in our model.",
                "It reduces comparing times to about one seventh of traditional method without hurting NED accuracy.",
                "We also have presented two extensions to the basic TF-IDF model.",
                "The first extension is made by adjust term weights based on term distributions between the whole corpus and a cluster story set.",
                "And the second extension to basic TF-IDF model is better use of term types (named entities types and part-of-speed) according to news categories.",
                "Our experimental results on TDT2 and TDT3 datasets show that both of the two extensions contribute significantly to improvement in accuracy.",
                "We did not consider news time information as a clue for NED task, since most of the topics last for a long time and TDT data sets only span for a relative short period (no more than 6 months).",
                "For the future work, we want to collect news set which span for a longer period from internet, and integrate time information in NED task.",
                "Since topic is a relative coarse-grained news cluster, we also want to refine cluster granularity to event-level, and identify different events and their relations within a topic.",
                "Acknowledgments This work is supported by the National Natural Science Foundation of China under Grant No. 90604025.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] In Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. .01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90 1 2 5 10 20 40 60 80 90 False Alarm Probability (in %) MissProbability(in%) SYSTEM1 Topic Weighted Curve SYSTEM1 Min Norm(Cost) SYSTEM2 Topic Weighted Curve SYSTEM2 Min Norm(Cost) SYSTEM3 Topic Weighted Curve SYSTEM3 Min Norm(Cost) SYSTEM4 Topic Weighted Curve SYSTEM4 Min Norm(Cost) SYSTEM5 Topic Weighted Curve SYSTEM5 Min Norm(Cost) Random Performance Figure 5.",
                "DET curves on TDT3 [3] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B.T.",
                "Archibald, and X. Liu.",
                "Learning Approaches for Detecting and Tracking News Events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), 1999, 32-43. [4] Y. Yang, T. Pierce, and J. Carbonell.",
                "A Study on Retrospective and On-line Event Detection.",
                "In Proceedings of SIGIR-98, Melbourne, Australia, 1998, 28-36. [5] J. Allan, V. Lavrenko, D. Malin, and R. Swan.",
                "Detections, Bounds, and Timelines: Umass and tdt-3.",
                "In Proceedings of Topic Detection and Tracking Workshop (TDT-3), Vienna, VA, 2000, 167-174. [6] R. Papka and J. Allan.",
                "On-line New Event Detection Using Single Pass Clustering TITLE2:.",
                "Technical Report UM-CS1998-021, 1998. [7] W. Lam, H. Meng, K. Wong, and J.",
                "Yen.",
                "Using Contextual Analysis for News Event Detection.",
                "International Journal on Intelligent Systems, 2001, 525-546. [8] B. Thorsten, C. Francine, and F. Ayman.",
                "A System for New Event Detection.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2003, 330-337. [9] S. Nicola and C. Joe.",
                "Combining Semantic and Syntactic Document Classifiers to Improve First Story Detection.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2001, 424425. [10] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topicconditioned Novelty Detection.",
                "In Proceedings of the 8th ACM SIGKDD International Conference, ACM Press. 2002, 688-693. [11] M. Juha, A.M. Helena, and S. Marko.",
                "Applying Semantic Classes in Event Detection and Tracking.",
                "In Proceedings of International Conference on Natural Language Processing (ICON 2002), 2002, pages 175-183. [12] M. Juha, A.M. Helena, and S. Marko.",
                "Simple Semantics in Topic Detection and Tracking.",
                "Information Retrieval, 7(3-4): 2004, 347-368. [13] K. Giridhar and J. Allan.",
                "Text Classification and Named Entities for New Event Detection.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2004, 297-304. [14] J. P. Callan, W. B. Croft, and S. M. Harding.",
                "The INQUERY Retrieval System.",
                "In Proceedings of DEXA-92, 3rd International Conference on Database and Expert Systems Applications, 1992, 78-83. [15] R. Krovetz.",
                "Viewing Morphology as An Inference Process.",
                "In Proceedings of ACM SIGIR93, 1993, 61-81. [16] Y. Yang and J. Pedersen.",
                "A Comparative Study on Feature Selection in Text Categorization.",
                "In J. D. H. Fisher, editor, The Fourteenth International Conference on Machine Learning (ICML97), Morgan Kaufmann, 1997, 412-420. [17] T. M. Cover, and J.A.",
                "Thomas.",
                "Elements of Information Theory.",
                "Wiley. 1991. [18] The linguistic data consortium, http://www.ldc,upenn.edu/. [19] The 2001 TDT task definition and evaluation plan, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm. [20] R. E. Schapire and Y.",
                "Singer.",
                "Boostexter: A Boosting-based System for Text Categorization.",
                "In Machine Learning 39(2/3):1, Kluwer Academic Publishers, 2000, 35-168. [21] K. Giridhar and J. Allan. 2005.",
                "Using Names and Topics for New Event Detection.",
                "In Proceedings of Human Technology Conference and Conference on Empirical Methods in Natural Language, Vancouver, 2005, 121-128"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "En este artículo proponemos un nuevo modelo NED para \"acelerar la tarea NED\" utilizando dinámicamente el árbol de indexación de noticias."
            ],
            "translated_text": "",
            "candidates": [
                "Acelera la tarea de NED",
                "acelerar la tarea NED"
            ],
            "error": []
        },
        "news indexing-tree": {
            "translated_key": "árbol de indexación de noticias",
            "is_in_text": true,
            "original_annotated_sentences": [
                "New Event Detection Based on Indexing-tree and Named Entity Zhang Kuo Tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn Li Juan Zi Tsinghua University Beijing, 100084, China 86-10-62781461 ljz@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn ABSTRACT New Event Detection (NED) aims at detecting from one or multiple streams of news stories that which one is reported on a new event (i.e.",
                "not reported previously).",
                "With the overwhelming volume of news available today, there is an increasing need for a NED system which is able to detect new events more efficiently and accurately.",
                "In this paper we propose a new NED model to speed up the NED task by using <br>news indexing-tree</br> dynamically.",
                "Moreover, based on the observation that terms of different types have different effects for NED task, two term reweighting approaches are proposed to improve NED accuracy.",
                "In the first approach, we propose to adjust term weights dynamically based on previous story clusters and in the second approach, we propose to employ statistics on training data to learn the named entity reweighting model for each class of stories.",
                "Experimental results on two Linguistic Data Consortium (LDC) datasets TDT2 and TDT3 show that the proposed model can improve both efficiency and accuracy of NED task significantly, compared to the baseline system and other existing systems.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Search and Retrieval; H.4.2 [Information Systems Applications]: Types of Systemsdecision support.",
                "General Terms Algorithms, Performance, Experimentation 1.",
                "INTRODUCTION Topic Detection and Tracking (TDT) program aims to develop techniques which can effectively organize, search and structure news text materials from a variety of newswire and broadcast media [1].",
                "New Event Detection (NED) is one of the five tasks in TDT.",
                "It is the task of online identification of the earliest report for each topic as soon as that report arrives in the sequence of documents.",
                "A Topic is defined as a seminal event or activity, along with directly related events and activities [2].",
                "An Event is defined as something (non-trivial) happening in a certain place at a certain time [3].",
                "For instance, when a bomb explodes in a building, the exploding is the seminal event that triggers the topic, and other stories on the same topic would be those discussing salvaging efforts, the search for perpetrators, arrests and trial and so on.",
                "Useful news information is usually buried in a mass of data generated everyday.",
                "Therefore, NED systems are very useful for people who need to detect novel information from real-time news stream.",
                "These real-life needs often occur in domains like financial markets, news analysis, and intelligence gathering.",
                "In most of state-of-the-art (currently) NED systems, each news story on hand is compared to all the previous received stories.",
                "If all the similarities between them do not exceed a threshold, then the story triggers a new event.",
                "They are usually in the form of cosine similarity or Hellinger similarity metric.",
                "The core problem of NED is to identify whether two stories are on the same topic.",
                "Obviously, these systems cannot take advantage of topic information.",
                "Further more, it is not acceptable in real applications because of the large amount of computation required in the NED process.",
                "Other systems organize previous stories into clusters (each cluster corresponds to a topic), and new story is compared to the previous clusters instead of stories.",
                "This manner can reduce comparing times significantly.",
                "Nevertheless, it has been proved that this manner is less accurate [4, 5].",
                "This is because sometimes stories within a topic drift far away from each other, which could lead low similarity between a story and its topic.",
                "On the other hand, some proposed NED systems tried to improve accuracy by making better use of named entities [10, 11, 12, 13].",
                "However, none of the systems have considered that terms of different types (e.g.",
                "Noun, Verb or Person name) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "For example, the names of election candidates (Person name) are very important for stories of election class; the locations (Location name) where accidents happened are important for stories of accidents class.",
                "So, in NED, there still exist following three problems to be investigated: (1) How to speed up the detection procedure while do not decrease the detection accuracy? (2) How to make good use of cluster (topic) information to improve accuracy? (3) How to obtain better news story representation by better understanding of named entities.",
                "Driven by these problems, we have proposed three approaches in this paper. (1)To make the detection procedure faster, we propose a new NED procedure based on <br>news indexing-tree</br> created dynamically.",
                "Story indexing-tree is created by assembling similar stories together to form news clusters in different hierarchies according to their values of similarity.",
                "Comparisons between current story and previous clusters could help find the most similar story in less comparing times.",
                "The new procedure can reduce the amount of comparing times without hurting accuracy. (2)We use the clusters of the first floor in the indexing-tree as news topics, in which term weights are adjusted dynamically according to term distribution in the clusters.",
                "In this approach, cluster (topic) information is used properly, so the problem of theme decentralization is avoided. (3)Based on observations on the statistics obtained from training data, we found that terms of different types (e.g.",
                "Noun and Verb) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "And we propose to use statistics to optimize the weights of the terms of different types in a story according to the news class that the story belongs to.",
                "On TDT3 dataset, the new NED model just uses 14.9% comparing times of the basic model, while its minimum normalized cost is 0.5012, which is 0.0797 better than the basic model, and also better than any other results previously reported for this dataset [8, 13].",
                "The rest of the paper is organized as follows.",
                "We start off this paper by summarizing the previous work in NED in section 2.",
                "Section 3 presents the basic model for NED that most current systems use.",
                "Section 4 describes our new detection procedure based on <br>news indexing-tree</br>.",
                "In section 5, two term reweighting methods are proposed to improve NED accuracy.",
                "Section 6 gives our experimental data and evaluation metrics.",
                "We finally wrap up with the experimental results in Section 7, and the conclusions and future work in Section 8. 2.",
                "RELATED WORK Papka et al. proposed Single-Pass clustering on NED [6].",
                "When a new story was encountered, it was processed immediately to extract term features and a query representation of the storys content is built up.",
                "Then it was compared with all the previous queries.",
                "If the document did not trigger any queries by exceeding a threshold, it was marked as a new event.",
                "Lam et al build up previous query representations of story clusters, each of which corresponds to a topic [7].",
                "In this manner comparisons happen between stories and clusters.",
                "Recent years, most work focus on proposing better methods on comparison of stories and document representation.",
                "Brants et al. [8] extended a basic incremental TF-IDF model to include sourcespecific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, term reweighting based on inverse event frequencies, and segmentation of documents.",
                "Good improvements on TDT bench-marks were shown.",
                "Stokes et al. [9] utilized a combination of evidence from two distinct representations of a documents content.",
                "One of the representations was the usual free text vector, the other made use of lexical chains (created using WordNet) to build another term vector.",
                "Then the two representations are combined in a linear fashion.",
                "A marginal increase in effectiveness was achieved when the combined representation was used.",
                "Some efforts have been done on how to utilize named entities to improve NED.",
                "Yang et al. gave location named entities four times weight than other terms and named entities [10].",
                "DOREMI research group combined semantic similarities of person names, location names and time together with textual similarity [11][12].",
                "UMass [13] research group split document representation into two parts: named entities and non-named entities.",
                "And it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation.",
                "Both [10] and [13] used text categorization technique to classify news stories in advance.",
                "In [13] news stories are classified automatically at first, and then test sensitivities of names and non-name terms for NED for each class.",
                "In [10] frequent terms for each class are removed from document representation.",
                "For example, word election does not help identify different elections.",
                "In their work, effectiveness of different kinds of names (or terms with different POS) for NED in different news classes are not investigated.",
                "We use statistical analysis to reveal the fact and use it to improve NED performance. 3.",
                "BASIC MODEL In this section, we present the basic New Event Detection model which is similar to what most current systems apply.",
                "Then, we propose our new model by extending the basic model.",
                "New Event Detection systems use news story stream as input, in which stories are strictly time-ordered.",
                "Only previously received stories are available when dealing with current story.",
                "The output is a decision for whether the current story is on a new event or not and the confidence of the decision.",
                "Usually, a NED model consists of three parts: story representation, similarity calculation and detection procedure. 3.1 Story Representation Preprocessing is needed before generating story representation.",
                "For preprocessing, we tokenize words, recognize abbreviations, normalize abbreviations, add part-of-speech tags, remove stopwords included in the stop list used in InQuery [14], replace words with their stems using K-stem algorithm[15], and then generate word vector for each news story.",
                "We use incremental TF-IDF model for term weight calculation [4].",
                "In a TF-IDF model, term frequency in a news document is weighted by the inverse document frequency, which is generated from training corpus.",
                "When a new term occurs in testing process, there are two solutions: simply ignore the new term or set df of the term as a small const (e.g. df = 1).",
                "The new term receives too low weight in the first solution (0) and too high weight in the second solution.",
                "In incremental TF-IDF model, document frequencies are updated dynamically in each time step t: 1( ) ( ) ( )t t D tdf w df w df w−= + (1) where Dt represents news story set received in time t, and dfDt(w) means the number of documents that term w occurs in, and dft(w) means the total number of documents that term w occurs in before time t. In this work, each time window includes 50 news stories.",
                "Thus, each story d received in t is represented as follows: 1 2{ ( , , ), ( , , ),..., ( , , )}nd weight d t w weight d t w weight d t w→ where n means the number of distinct terms in story d, and ( , , )weight d t w means the weight of term w in story d at time t: log( ( , ) 1) log(( 1) /( ( ) 0.5)) ( , , ) log( ( , ) 1) log(( 1) /( ( ) 0.5)) t t t t w d tf d w N df w weight d t w tf d w N df w ∈ + + + = + + +∑ (2) where Nt means the total number of news stories before time t, and tf(d,w) means how many times term w occurs in news story d. 3.2 Similarity Calculation We use Hellinger distance for the calculation of similarity between two stories, for two stories d and d at time t, their similarity is defined as follows: , ( , , ) ( , , ) * ( , , ) w d d sim d d t weight d t w weight d t w ∈ = ∑ (3) 3.3 Detection Procedure For each story d received in time step t, the value ( ) ( ) ( ) ( ( , , )) time d time d n d max sim d d t < = (4) is a score used to determine whether d is a story about a new topic and at the same time is an indication of the confidence in our decision [8]. time(d) means the publication time of story d. If the score exceeds the thresholdθ new, then there exists a sufficiently similar document, thus d is a old story, otherwise, there is no sufficiently similar previous document, thus d is an new story. 4.",
                "New NED Procedure Traditional NED systems can be classified into two main types on the aspect of detection procedure: (1) S-S type, in which the story on hand is compared to each story received previously, and use the highest similarity to determine whether current story is about a new event; (2) S-C type, in which the story on hand is compared to all previous clusters each of which representing a topic, and the highest similarity is used for final decision for current story.",
                "If the highest similarity exceeds thresholdθ new, then it is an old story, and put it into the most similar cluster; otherwise it is a new story and create a new cluster.",
                "Previous work show that the first manner is more accurate than the second one [4][5].",
                "Since sometimes stories within a topic drift far away from each other, a story may have very low similarity with its topic.",
                "So using similarities between stories for determining new story is better than using similarities between story and clusters.",
                "Nevertheless, the first manner needs much more comparing times which means the first manner is low efficient.",
                "We propose a new detection procedure which uses comparisons with previous clusters to help find the most similar story in less comparing times, and the final new event decision is made according to the most similar story.",
                "Therefore, we can get both the accuracy of S-S type methods and the efficiency of S-C type methods.",
                "The new procedure creates a <br>news indexing-tree</br> dynamically, in which similar stories are put together to form a hierarchy of clusters.",
                "We index similar stories together by their common ancestor (a cluster node).",
                "Dissimilar stories are indexed in different clusters.",
                "When a story is coming, we use comparisons between the current story and previous hierarchical clusters to help find the most similar story which is useful for new event decision.",
                "After the new event decision is made, the current story is inserted to the indexing-tree for the following detection.",
                "The <br>news indexing-tree</br> is defined formally as follows: S-Tree = {r, NC , NS , E} where r is the root of S-Tree, NC is the set of all cluster nodes, NS is the set of all story nodes, and E is the set of all edges in S-Tree.",
                "We define a set of constraints for a S-Tree: ⅰ . , is an non-terminal node in the treeC i i N i∀ ∈ → ⅱ . , is a terminal node in the treeS i i N i∀ ∈ → ⅲ . , out degree of is at least 2C i i N i∀ ∈ → ⅳ . , is represented as the centroid of its desendantsC i i iN∀ ∈ → For a news story di, the comparison procedure and inserting procedure based on indexing-tree are defined as follows.",
                "An example is shown by Figure 1 and Figure 2.",
                "Figure 1.",
                "Comparison procedure Figure 2.",
                "Inserting procedure Comparison procedure: Step 1: compare di to all the direct child nodes of r and select λ nodes with highest similarities, e.g., C1 2 and C1 3 in Figure 1.",
                "Step 2: for each selected node in the last step, e.g.",
                "C1 2, compare di to all its direct child nodes, and select λ nodes with highest similarities, e.g.",
                "C2 2 and d8.",
                "Repeat step 2 for all non-terminal nodes.",
                "Step 3: record the terminal node with the highest similarty to di, e.g. s5, and the similarity value (0.20).",
                "Inserting di to the S-tree with r as root: Find the node n which is direct child of r in the path from r to the terminal node with highest similarity s, e.g.",
                "C1 2.",
                "If s is smaller than θ init+(h-1)δ , then add di to the tree as a direct child of r. Otherwise, if n is a terminal node, then create a cluster node instead of n, and add both n and di as its direct children; if n is an non-terminal node, then repeat this procedure and insert di to the sub-tree with n as root recursively.",
                "Here h is the length between n and the root of S-tree.",
                "The more the stories in a cluster similar to each other, the better the cluster represents the stories in it.",
                "Hence we add no constraints on the maximum of trees height and degree of a node.",
                "Therefore, we cannot give the complexity of this indexing-tree based procedure.",
                "But we will give the number of comparing times needed by the new procedure in our experiments in section7. 5.",
                "Term Reweighting Methods In this section, two term reweighting methods are proposed to improve NED accuracy.",
                "In the first method, a new way is explored for better using of cluster (topic) information.",
                "The second one finds a better way to make use of named entities based on news classification. 5.1 Term Reweighting Based on Distribution Distance TF-IDF is the most prevalent model used in information retrieval systems.",
                "The basic idea is that the fewer documents a term appears in, the more important the term is in discrimination of documents (relevant or not relevant to a query containing the term).",
                "Nevertheless, in TDT domain, we need to discriminate documents with regard to topics rather than queries.",
                "Intuitively, using cluster (topic) vectors to compare with subsequent news stories should outperform using story vectors.",
                "Unfortunately, the experimental results do not support this intuition [4][5].",
                "Based on observation on data, we find the reason is that a news topic usually contains many directly or indirectly related events, while they all have their own sub-subjects which are usually different with each other.",
                "Take the topic described in section 1 as an example, events like the explosion and salvage have very low similarities with events about criminal trial, therefore stories about trial would have low similarity with the topic vector built on its previous events.",
                "This section focuses on how to effectively make use of topic information and at the same time avoid the problem of content decentralization.",
                "At first, we classify terms into 5 classes to help analysis the needs of the modified model: Term class A: terms that occur frequently in the whole corpus, e.g., year and people.",
                "Terms of this class should be given low weights because they do not help much for topic discrimination.",
                "Term class B: terms that occur frequently within a news category, e.g., election, storm.",
                "They are useful to distinguish two stories in different news categories.",
                "However, they cannot provide information to determine whether two stories are on the same or different topics.",
                "In another words, term election and term storm are not helpful in differentiate two election campaigns and two storm disasters.",
                "Therefore, terms of this class should be assigned lower weights.",
                "Term class C: terms that occur frequently in a topic, and infrequently in other topics, e.g., the name of a crash plane, the name of a specific hurricane.",
                "News stories that belong to different topics rarely have overlap terms in this class.",
                "The more frequently a term appears in a topic, the more important the term is for a story belonging to the topic, therefore the term should be set higher weight.",
                "Term class D: terms that appear in a topic exclusively, but not frequently.",
                "For example, the name of a fireman who did very well in a salvage action, which may appears in only two or three stories but never appeared in other topics.",
                "Terms of this type should receive more weights than in TF-IDF model.",
                "However, since they are not popular in the topic, it is not appropriate to give them too high weights.",
                "Term class E: terms with low document frequency, and appear in different topics.",
                "Terms of this class should receive lower weights.",
                "Now we analyze whether TF-IDF model can give proper weights to the five classes of terms.",
                "Obviously, terms of class A are lowly weighted in TF-IDF model, which is conformable with the requirement described above.",
                "In TF-IDF model, terms of class B are highly dependant with the number of stories in a news class.",
                "TF-IDF model cannot provide low weights if the story containing the term belongs to a relative small news class.",
                "For a term of class C, the more frequently it appears in a topic, the less weight TFIDF model gives to it.",
                "This strongly conflicts with the requirement of terms in class C. For terms of class D, TF-IDF model gives them high weights correctly.",
                "But for terms of class E, TF-IDF model gives high weights to them which are not conformable with the requirement of low weights.",
                "To sum up, terms of class B, C, E cannot be properly weighted in TF-IDF model.",
                "So, we propose a modified model to resolve this problem.",
                "When θ init andθ new are set closely, we assume that most of the stories in a first-level cluster (a direct child node of root node) are on the same topic.",
                "Therefore, we make use of a first-level cluster to capture term distribution (df for all the terms within the cluster) within the topic dynamically.",
                "KL divergence of term distribution in a first-level cluster and the whole story set is used to adjust term weights:  ( , , ) * (1 * ( || )) ( , , ) ( , , ) * (1 * ( || )) cw tw cw tw w d D weight d t w KL P P weight d t w weight d t w KL P P γ γ ∈ + = +∑ (5) where ( ) ( ) ( ) ( ) 1,cw cw c c c c df w df w p y p y N N = = − (6) ( ) ( ) ( ) ( ) 1,t t tw tw t t df w df w p y p y N N = = − (7) where dfc(w) is the number of documents containing term w within cluster C, and Nc is the number of documents in cluster C, and Nt is the total number of documents that arrive before time step t. γ is a const parameter, now is manually set 3.",
                "KL divergence is defined as follows [17]: ( ) ( || ) ( ) log ( )x p x KL P Q p x q x = ∑ (8) The basic idea is: for a story in a topic, the more a term occurs within the topic, and the less it occurs in other topics, it should be assigned higher weights.",
                "Obviously, modified model can meet all the requirements of the five term classes listed above. 5.2 Term Reweighting Based on Term Type and Story Class Previous work found that some classes of news stories could achieve good improvements by giving extra weight to named entities.",
                "But we find that terms of different types should be given different amount of extra weight for different classes of news stories.",
                "We use open-NLP1 to recognize named entity types and part-ofspeech tags for terms that appear in news stories.",
                "Named entity types include person name, organization name, location name, date, time, money and percentage, and five POSs are selected: none (NN), verb (VB), adjective (JJ), adverb (RB) and cardinal number (CD).",
                "Statistical analysis shows topic-level discriminative terms types for different classes of stories.",
                "For the sake of convenience, named entity type and part-of-speech tags are uniformly called term type in subsequent sections.",
                "Determining whether two stories are about the same topic is a basic component for NED task.",
                "So at first we use 2 χ statistic to compute correlations between terms and topics.",
                "For a term t and a topic T, a contingence table is derived: Table 1.",
                "A 2×2 Contingence Table Doc Number belong to topic T not belong to topic T include t A B not include t C D The 2 χ statistic for a specific term t with respect to topic T is defined to be [16]: 2 2 ( , ) ( ) * ( ) ( ) * ( ) * ( ) * ( ) w T A B C D AD CB A C B D A B C D χ = + + + − + + + + (9) News topics for the TDT task are further classified into 11 rules of interpretations (ROIs) 2 .",
                "The ROI can be seen as a higher level class of stories.",
                "The average correlation between a term type and a topic ROI is computed as: 2 avg 2 ( , )( ( , ) )k m m km kT R w P w TP R p w T R P χ χ ∈ ∈ ∑ ∑（ , ）= 1 1 k=1…K, m=1…M (10) where K is the number of term types (set 12 constantly in the paper).",
                "M is the number news classes (ROIs, set 11 in the paper).",
                "Pk represents the set of all terms of type k, and Rm represents the set of all topics of class m, p(t,T) means the probability that t occurs in topic T. Because of limitation of space, only parts of the term types (9 term types) and parts of news classes (8 classes) are listed in table 2 with the average correlation values between them.",
                "The statistics is derived from labeled data in TDT2 corpus. (Results in table 2 are already normalized for convenience in comparison.)",
                "The statistics in table 2 indicates the usefulness of different term types in topic discrimination with respect to different news classes.",
                "We can see that, location name is the most useful term type for three news classes: Natural Disasters, Violence or War, Finances.",
                "And for three other categories Elections, Legal/Criminal Cases, Science and Discovery, person name is the most discriminative term type.",
                "For Scandals/Hearings, date is the most important information for topic discrimination.",
                "In addition, Legal/Criminal Cases and Finance topics have higher correlation with money terms, while Science and Discovery have higher correlation with percentage terms.",
                "Non-name terms are more stable for different classes. 1 . http://opennlp.sourceforge.net/ 2 . http://projects.ldc.upenn.edu/TDT3/Guide/label.html From the analysis of table 2, it is reasonable to adjust term weight according to their term type and the news class the story belongs to.",
                "New term weights are reweighted as follows: ( ) ( ) ( ) ( ) ( , , ) * ( , , ) ( , , ) * class d D type w T class d D type w w d weight d t w weight d t w weight d t w α α ∈ = ∑ (11) where type(w) represents the type of term w, and class(d) represents the class of story d, c kα is reweighting parameter for news class c and term type k. In the work, we just simply use statistics in table 2 as the reweighting parameters.",
                "Even thought using the statistics directly may not the best choice, we do not discuss how to automatically obtain the best parameters.",
                "We will try to use machine learning techniques to obtain the best parameters in the future work.",
                "In the work, we use BoosTexter [20] to classify all stories into one of the 11 ROIs.",
                "BoosTexter is a boosting based machine learning program, which creates a series of simple rules for building a classifier for text or attribute-value data.",
                "We use term weight generated using TF-IDF model as feature for story classification.",
                "We trained the model on the 12000 judged English stories in TDT2, and classify the rest of the stories in TDT2 and all stories in TDT3.",
                "Classification results are used for term reweighting in formula (11).",
                "Since the class labels of topic-off stories are not given in TDT datasets, we cannot give the classification accuracy here.",
                "Thus we do not discuss the effects of classification accuracy to NED performance in the paper. 6.",
                "EXPERIMENTAL SETUP 6.1 Datasets We used two LDC [18] datasets TDT2 and TDT3 for our experiments.",
                "TDT2 contains news stories from January to June 1998.",
                "It contains around 54,000 stories from sources like ABC, Associated Press, CNN, New York Times, Public Radio International, Voice of America etc.",
                "Only English stories in the collection were considered.",
                "TDT3 contains approximately 31,000 English stories collected from October to December 1998.",
                "In addition to the sources used in TDT2, it also contains stories from NBC and MSNBC TV broadcasts.",
                "We used transcribed versions of the TV and radio broadcasts besides textual news.",
                "TDT2 dataset is labeled with about 100 topics, and approximately 12,000 English stories belong to at least one of these topics.",
                "TDT3 dataset is labeled with about 120 topics, and approximately 8000 English stories belong to at least one of these topics.",
                "All the topics are classified into 11 Rules of Interpretation: (1)Elections, (2)Scandals/Hearings, (3)Legal/Criminal Cases, (4)Natural Disasters, (5)Accidents, (6)Ongoing Violence or War, (7)Science and Discovery News, (8)Finance, (9)New Law, (10)Sports News, (11)MISC.",
                "News. 6.2 Evaluation Metric TDT uses a cost function CDet that combines the probabilities of missing a new story and a false alarm [19]: * * * *Det Miss Miss Target FA FA NontargetC C P P C P P= + (12) Table 2.",
                "Average correlation between term types and news classes where CMiss means the cost of missing a new story, PMiss means the probability of missing a new story, and PTarget means the probability of seeing a new story in the data; CFA means the cost of a false alarm, PFA means the probability of a false alarm, and PNontarget means the probability of seeing an old story.",
                "The cost CDet is normalized such that a perfect system scores 0 and a trivial system, which is the better one of mark all stories as new or old, scores 1: ( ( * , * ) ) Det Det Miss Target FA Nontarget C Norm C min C P C P = (13) New event detection system gives two outputs for each story.",
                "The first part is yes or no indicating whether the story triggers a new event or not.",
                "The second part is a score indicating confidence of the first decision.",
                "Confidence scores can be used to plot DET curve, i.e., curves that plot false alarm vs. miss probabilities.",
                "Minimum normalized cost can be determined if optimal threshold on the score were chosen. 7.",
                "EXPERIMENTAL RESULTS 7.1 Main Results To test the approaches proposed in the model, we implemented and tested five systems: System-1: this system is used as baseline.",
                "It is implemented based on the basic model described in section 3, i.e., using incremental TF-IDF model to generate term weights, and using Hellinger distance to compute document similarity.",
                "Similarity score normalization is also employed [8].",
                "S-S detection procedure is used.",
                "System-2: this system is the same as system-1 except that S-C detection procedure is used.",
                "System-3: this system is the same as system-1 except that it uses the new detection procedure which is based on indexing-tree.",
                "System-4: implemented based on the approach presented in section 5.1, i.e., terms are reweighted according to the distance between term distributions in a cluster and all stories.",
                "The new detection procedure is used.",
                "System-5: implemented based on the approach presented in section 5.2, i.e., terms of different types are reweighted according to news class using trained parameters.",
                "The new detection procedure is used.",
                "The following are some other NED systems: System-6: [21] for each pair of stories, it computes three similarity values for named entity, non-named entity and all terms respectively.",
                "And employ Support Vector Machine to predict new or old using the similarity values as features.",
                "System-7: [8] it extended a basic incremental TF-IDF model to include source-specific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, etc.",
                "System-8: [13] it split document representation into two parts: named entities and non-named entities, and choose one effective part for each news class.",
                "Table 3 and table 4 show topic-weighted normalized costs and comparing times on TDT2 and TDT3 datasets respectively.",
                "Since no heldout data set for fine-tuning the threshold θ new was available for experiments on TDT2, we only report minimum normalized costs for our systems in table 3.",
                "System-5 outperforms all other systems including system-6, and it performs only 2.78e+8 comparing times in detection procedure which is only 13.4% of system-1.",
                "Table 3.",
                "NED results on TDT2 Systems Min Norm(CDet) Cmp times System-1 0.5749 2.08e+9 System-2① 0.6673 3.77e+8 System-3② 0.5765 2.81e+8 System-4② 0.5431 2.99e+8 System-5② 0.5089 2.78e+8 System-6 0.5300 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 When evaluating on the normalized costs on TDT3, we use the optimal thresholds obtained from TDT2 data set for all systems.",
                "System-2 reduces comparing times to 1.29e+9 which is just 18.3% of system-1, but at the same time it also gets a deteriorated minimum normalized cost which is 0.0499 higher than system-1.",
                "System-3 uses the new detection procedure based on <br>news indexing-tree</br>.",
                "It requires even less comparing times than system-2.",
                "This is because story-story comparisons usually yield greater similarities than story-cluster ones, so stories tend to be combined Location Person Date Organization Money Percentage NN JJ CD Elections 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 Scandals/Hearings 0.66 0.62 0.28 1 0.11 0.02 0.27 0.13 0.05 Legal/Criminal Cases 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 Natural Disasters 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 Violence or War 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 Science and Discovery 0.11 1 0.01 0.22 0.08 0.12 0.19 0.08 0.03 Finances 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 Sports 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 together in system-3.",
                "And system-3 is basically equivalent to system-1 in accuracy results.",
                "System-4 adjusts term weights based on the distance of term distributions between the whole corpus and cluster story set, yielding a good improvement by 0.0468 compared to system-1.",
                "The best system (system-5) has a minimum normalized cost 0.5012, which is 0.0797 better than system-1, and also better than any other results previously reported for this dataset [8, 13].",
                "Further more, system-5 only needs 1.05e+8 comparing times which is 14.9% of system-1.",
                "Table 4.",
                "NED results on TDT3 Systems Norm(CDet) Min Norm(CDet) Cmp times System-1 0.6159 0.5809 7.04e+8 System-2① 0.6493 0.6308 1.29e+8 System-3② 0.6197 0.5868 1.03e+8 System-4② 0.5601 0.5341 1.03e+8 System-5② 0.5413 0.5012 1.05e+8 System-7 -- 0.5783 -System-8 -- 0.5229 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 Figure5 shows the five DET curves for our systems on data set TDT3.",
                "System-5 achieves the minimum cost at a false alarm rate of 0.0157 and a miss rate of 0.4310.",
                "We can observe that System4 and System-5 obtain lower miss probability at regions of low false alarm probabilities.",
                "The hypothesis is that, more weight value is transferred to key terms of topics from non-key terms.",
                "Similarity score between two stories belonging to different topics are lower than before, because their overlapping terms are usually not key terms of their topics. 7.2 Parameter selection for indexing-tree detection Figure 3 shows the minimum normalized costs obtained by system-3 on TDT3 using different parameters.",
                "Theθ init parameter is tested on six values spanning from 0.03 to 0.18.",
                "And the λ parameter is tested on four values 1, 2, 3 and 4.",
                "We can see that, whenθ init is set to 0.12, which is the closest one toθ new, the costs are lower than others.",
                "This is easy to explain, because when stories belonging to the same topic are put in a cluster, it is more reasonable for the cluster to represent the stories in it.",
                "When parameter λ is set to 3 or 4, the costs are better than other cases, but there is no much difference between 3 and 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ MinCost 0.6 0.65 0.7 0.75 0.8 0.85 0.9 Figure 3.",
                "Min Cost on TDT3 (δ =0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ Comparingtimes 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 Figure 4.",
                "Comparing times on TDT3 (δ =0.15) Figure 4 gives the comparing times used by system-3 on TDT3 with the same parameters as figure 3.",
                "The comparing times are strongly dependent onθ init.",
                "Because the greaterθ init is, the less stories combined together, the more comparing times are needed for new event decision.",
                "So we useθ init =0.13,λ =3,δ =0.15 for system-3, 4, and 5.",
                "In this parameter setting, we can get both low minimum normalized costs and less comparing times. 8.",
                "CONCLUSION We have proposed a <br>news indexing-tree</br> based detection procedure in our model.",
                "It reduces comparing times to about one seventh of traditional method without hurting NED accuracy.",
                "We also have presented two extensions to the basic TF-IDF model.",
                "The first extension is made by adjust term weights based on term distributions between the whole corpus and a cluster story set.",
                "And the second extension to basic TF-IDF model is better use of term types (named entities types and part-of-speed) according to news categories.",
                "Our experimental results on TDT2 and TDT3 datasets show that both of the two extensions contribute significantly to improvement in accuracy.",
                "We did not consider news time information as a clue for NED task, since most of the topics last for a long time and TDT data sets only span for a relative short period (no more than 6 months).",
                "For the future work, we want to collect news set which span for a longer period from internet, and integrate time information in NED task.",
                "Since topic is a relative coarse-grained news cluster, we also want to refine cluster granularity to event-level, and identify different events and their relations within a topic.",
                "Acknowledgments This work is supported by the National Natural Science Foundation of China under Grant No. 90604025.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] In Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. .01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90 1 2 5 10 20 40 60 80 90 False Alarm Probability (in %) MissProbability(in%) SYSTEM1 Topic Weighted Curve SYSTEM1 Min Norm(Cost) SYSTEM2 Topic Weighted Curve SYSTEM2 Min Norm(Cost) SYSTEM3 Topic Weighted Curve SYSTEM3 Min Norm(Cost) SYSTEM4 Topic Weighted Curve SYSTEM4 Min Norm(Cost) SYSTEM5 Topic Weighted Curve SYSTEM5 Min Norm(Cost) Random Performance Figure 5.",
                "DET curves on TDT3 [3] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B.T.",
                "Archibald, and X. Liu.",
                "Learning Approaches for Detecting and Tracking News Events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), 1999, 32-43. [4] Y. Yang, T. Pierce, and J. Carbonell.",
                "A Study on Retrospective and On-line Event Detection.",
                "In Proceedings of SIGIR-98, Melbourne, Australia, 1998, 28-36. [5] J. Allan, V. Lavrenko, D. Malin, and R. Swan.",
                "Detections, Bounds, and Timelines: Umass and tdt-3.",
                "In Proceedings of Topic Detection and Tracking Workshop (TDT-3), Vienna, VA, 2000, 167-174. [6] R. Papka and J. Allan.",
                "On-line New Event Detection Using Single Pass Clustering TITLE2:.",
                "Technical Report UM-CS1998-021, 1998. [7] W. Lam, H. Meng, K. Wong, and J.",
                "Yen.",
                "Using Contextual Analysis for News Event Detection.",
                "International Journal on Intelligent Systems, 2001, 525-546. [8] B. Thorsten, C. Francine, and F. Ayman.",
                "A System for New Event Detection.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2003, 330-337. [9] S. Nicola and C. Joe.",
                "Combining Semantic and Syntactic Document Classifiers to Improve First Story Detection.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2001, 424425. [10] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topicconditioned Novelty Detection.",
                "In Proceedings of the 8th ACM SIGKDD International Conference, ACM Press. 2002, 688-693. [11] M. Juha, A.M. Helena, and S. Marko.",
                "Applying Semantic Classes in Event Detection and Tracking.",
                "In Proceedings of International Conference on Natural Language Processing (ICON 2002), 2002, pages 175-183. [12] M. Juha, A.M. Helena, and S. Marko.",
                "Simple Semantics in Topic Detection and Tracking.",
                "Information Retrieval, 7(3-4): 2004, 347-368. [13] K. Giridhar and J. Allan.",
                "Text Classification and Named Entities for New Event Detection.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2004, 297-304. [14] J. P. Callan, W. B. Croft, and S. M. Harding.",
                "The INQUERY Retrieval System.",
                "In Proceedings of DEXA-92, 3rd International Conference on Database and Expert Systems Applications, 1992, 78-83. [15] R. Krovetz.",
                "Viewing Morphology as An Inference Process.",
                "In Proceedings of ACM SIGIR93, 1993, 61-81. [16] Y. Yang and J. Pedersen.",
                "A Comparative Study on Feature Selection in Text Categorization.",
                "In J. D. H. Fisher, editor, The Fourteenth International Conference on Machine Learning (ICML97), Morgan Kaufmann, 1997, 412-420. [17] T. M. Cover, and J.A.",
                "Thomas.",
                "Elements of Information Theory.",
                "Wiley. 1991. [18] The linguistic data consortium, http://www.ldc,upenn.edu/. [19] The 2001 TDT task definition and evaluation plan, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm. [20] R. E. Schapire and Y.",
                "Singer.",
                "Boostexter: A Boosting-based System for Text Categorization.",
                "In Machine Learning 39(2/3):1, Kluwer Academic Publishers, 2000, 35-168. [21] K. Giridhar and J. Allan. 2005.",
                "Using Names and Topics for New Event Detection.",
                "In Proceedings of Human Technology Conference and Conference on Empirical Methods in Natural Language, Vancouver, 2005, 121-128"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "En este artículo proponemos un nuevo modelo NED para acelerar la tarea NED utilizando dinámicamente el \"árbol de indexación de noticias\".",
                "Impulsados por estos problemas, hemos propuesto tres enfoques en este documento.(1) Para hacer el procedimiento de detección más rápido, proponemos un nuevo procedimiento NED basado en el \"árbol de indexación de noticias\" creado dinámicamente.",
                "La Sección 4 describe nuestro nuevo procedimiento de detección basado en el \"árbol de indexación de noticias\".",
                "El nuevo procedimiento crea un \"árbol de indexación de noticias\" dinámicamente, en el que se juntan historias similares para formar una jerarquía de grupos.",
                "El \"árbol de indexación de noticias\" se define formalmente de la siguiente manera: s-tree = {r, nc, ns, e} donde r es la raíz de s-tree, nc es el conjunto de todos los nodos de clúster, ns es el conjunto deTodos los nodos de la historia, y E es el conjunto de todos los bordes en S-Tree.",
                "System-3 utiliza el nuevo procedimiento de detección basado en el \"árbol de indexación de noticias\".",
                "Conclusión Hemos propuesto un procedimiento de detección basado en el \"árbol de indexación de noticias\" en nuestro modelo."
            ],
            "translated_text": "",
            "candidates": [
                "árbol de indexación de noticias",
                "árbol de indexación de noticias",
                "árbol de indexación de noticias",
                "árbol de indexación de noticias",
                "árbol de indexación de noticias",
                "árbol de indexación de noticias",
                "árbol de indexación de noticias",
                "árbol de indexación de noticias",
                "árbol de indexación de noticias",
                "árbol de indexación de noticias",
                "árbol de indexación de noticias",
                "árbol de indexación de noticias",
                "árbol de indexación de noticias",
                "árbol de indexación de noticias"
            ],
            "error": []
        },
        "term reweighting approach": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "New Event Detection Based on Indexing-tree and Named Entity Zhang Kuo Tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn Li Juan Zi Tsinghua University Beijing, 100084, China 86-10-62781461 ljz@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn ABSTRACT New Event Detection (NED) aims at detecting from one or multiple streams of news stories that which one is reported on a new event (i.e.",
                "not reported previously).",
                "With the overwhelming volume of news available today, there is an increasing need for a NED system which is able to detect new events more efficiently and accurately.",
                "In this paper we propose a new NED model to speed up the NED task by using news indexing-tree dynamically.",
                "Moreover, based on the observation that terms of different types have different effects for NED task, two <br>term reweighting approach</br>es are proposed to improve NED accuracy.",
                "In the first approach, we propose to adjust term weights dynamically based on previous story clusters and in the second approach, we propose to employ statistics on training data to learn the named entity reweighting model for each class of stories.",
                "Experimental results on two Linguistic Data Consortium (LDC) datasets TDT2 and TDT3 show that the proposed model can improve both efficiency and accuracy of NED task significantly, compared to the baseline system and other existing systems.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Search and Retrieval; H.4.2 [Information Systems Applications]: Types of Systemsdecision support.",
                "General Terms Algorithms, Performance, Experimentation 1.",
                "INTRODUCTION Topic Detection and Tracking (TDT) program aims to develop techniques which can effectively organize, search and structure news text materials from a variety of newswire and broadcast media [1].",
                "New Event Detection (NED) is one of the five tasks in TDT.",
                "It is the task of online identification of the earliest report for each topic as soon as that report arrives in the sequence of documents.",
                "A Topic is defined as a seminal event or activity, along with directly related events and activities [2].",
                "An Event is defined as something (non-trivial) happening in a certain place at a certain time [3].",
                "For instance, when a bomb explodes in a building, the exploding is the seminal event that triggers the topic, and other stories on the same topic would be those discussing salvaging efforts, the search for perpetrators, arrests and trial and so on.",
                "Useful news information is usually buried in a mass of data generated everyday.",
                "Therefore, NED systems are very useful for people who need to detect novel information from real-time news stream.",
                "These real-life needs often occur in domains like financial markets, news analysis, and intelligence gathering.",
                "In most of state-of-the-art (currently) NED systems, each news story on hand is compared to all the previous received stories.",
                "If all the similarities between them do not exceed a threshold, then the story triggers a new event.",
                "They are usually in the form of cosine similarity or Hellinger similarity metric.",
                "The core problem of NED is to identify whether two stories are on the same topic.",
                "Obviously, these systems cannot take advantage of topic information.",
                "Further more, it is not acceptable in real applications because of the large amount of computation required in the NED process.",
                "Other systems organize previous stories into clusters (each cluster corresponds to a topic), and new story is compared to the previous clusters instead of stories.",
                "This manner can reduce comparing times significantly.",
                "Nevertheless, it has been proved that this manner is less accurate [4, 5].",
                "This is because sometimes stories within a topic drift far away from each other, which could lead low similarity between a story and its topic.",
                "On the other hand, some proposed NED systems tried to improve accuracy by making better use of named entities [10, 11, 12, 13].",
                "However, none of the systems have considered that terms of different types (e.g.",
                "Noun, Verb or Person name) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "For example, the names of election candidates (Person name) are very important for stories of election class; the locations (Location name) where accidents happened are important for stories of accidents class.",
                "So, in NED, there still exist following three problems to be investigated: (1) How to speed up the detection procedure while do not decrease the detection accuracy? (2) How to make good use of cluster (topic) information to improve accuracy? (3) How to obtain better news story representation by better understanding of named entities.",
                "Driven by these problems, we have proposed three approaches in this paper. (1)To make the detection procedure faster, we propose a new NED procedure based on news indexing-tree created dynamically.",
                "Story indexing-tree is created by assembling similar stories together to form news clusters in different hierarchies according to their values of similarity.",
                "Comparisons between current story and previous clusters could help find the most similar story in less comparing times.",
                "The new procedure can reduce the amount of comparing times without hurting accuracy. (2)We use the clusters of the first floor in the indexing-tree as news topics, in which term weights are adjusted dynamically according to term distribution in the clusters.",
                "In this approach, cluster (topic) information is used properly, so the problem of theme decentralization is avoided. (3)Based on observations on the statistics obtained from training data, we found that terms of different types (e.g.",
                "Noun and Verb) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "And we propose to use statistics to optimize the weights of the terms of different types in a story according to the news class that the story belongs to.",
                "On TDT3 dataset, the new NED model just uses 14.9% comparing times of the basic model, while its minimum normalized cost is 0.5012, which is 0.0797 better than the basic model, and also better than any other results previously reported for this dataset [8, 13].",
                "The rest of the paper is organized as follows.",
                "We start off this paper by summarizing the previous work in NED in section 2.",
                "Section 3 presents the basic model for NED that most current systems use.",
                "Section 4 describes our new detection procedure based on news indexing-tree.",
                "In section 5, two term reweighting methods are proposed to improve NED accuracy.",
                "Section 6 gives our experimental data and evaluation metrics.",
                "We finally wrap up with the experimental results in Section 7, and the conclusions and future work in Section 8. 2.",
                "RELATED WORK Papka et al. proposed Single-Pass clustering on NED [6].",
                "When a new story was encountered, it was processed immediately to extract term features and a query representation of the storys content is built up.",
                "Then it was compared with all the previous queries.",
                "If the document did not trigger any queries by exceeding a threshold, it was marked as a new event.",
                "Lam et al build up previous query representations of story clusters, each of which corresponds to a topic [7].",
                "In this manner comparisons happen between stories and clusters.",
                "Recent years, most work focus on proposing better methods on comparison of stories and document representation.",
                "Brants et al. [8] extended a basic incremental TF-IDF model to include sourcespecific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, term reweighting based on inverse event frequencies, and segmentation of documents.",
                "Good improvements on TDT bench-marks were shown.",
                "Stokes et al. [9] utilized a combination of evidence from two distinct representations of a documents content.",
                "One of the representations was the usual free text vector, the other made use of lexical chains (created using WordNet) to build another term vector.",
                "Then the two representations are combined in a linear fashion.",
                "A marginal increase in effectiveness was achieved when the combined representation was used.",
                "Some efforts have been done on how to utilize named entities to improve NED.",
                "Yang et al. gave location named entities four times weight than other terms and named entities [10].",
                "DOREMI research group combined semantic similarities of person names, location names and time together with textual similarity [11][12].",
                "UMass [13] research group split document representation into two parts: named entities and non-named entities.",
                "And it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation.",
                "Both [10] and [13] used text categorization technique to classify news stories in advance.",
                "In [13] news stories are classified automatically at first, and then test sensitivities of names and non-name terms for NED for each class.",
                "In [10] frequent terms for each class are removed from document representation.",
                "For example, word election does not help identify different elections.",
                "In their work, effectiveness of different kinds of names (or terms with different POS) for NED in different news classes are not investigated.",
                "We use statistical analysis to reveal the fact and use it to improve NED performance. 3.",
                "BASIC MODEL In this section, we present the basic New Event Detection model which is similar to what most current systems apply.",
                "Then, we propose our new model by extending the basic model.",
                "New Event Detection systems use news story stream as input, in which stories are strictly time-ordered.",
                "Only previously received stories are available when dealing with current story.",
                "The output is a decision for whether the current story is on a new event or not and the confidence of the decision.",
                "Usually, a NED model consists of three parts: story representation, similarity calculation and detection procedure. 3.1 Story Representation Preprocessing is needed before generating story representation.",
                "For preprocessing, we tokenize words, recognize abbreviations, normalize abbreviations, add part-of-speech tags, remove stopwords included in the stop list used in InQuery [14], replace words with their stems using K-stem algorithm[15], and then generate word vector for each news story.",
                "We use incremental TF-IDF model for term weight calculation [4].",
                "In a TF-IDF model, term frequency in a news document is weighted by the inverse document frequency, which is generated from training corpus.",
                "When a new term occurs in testing process, there are two solutions: simply ignore the new term or set df of the term as a small const (e.g. df = 1).",
                "The new term receives too low weight in the first solution (0) and too high weight in the second solution.",
                "In incremental TF-IDF model, document frequencies are updated dynamically in each time step t: 1( ) ( ) ( )t t D tdf w df w df w−= + (1) where Dt represents news story set received in time t, and dfDt(w) means the number of documents that term w occurs in, and dft(w) means the total number of documents that term w occurs in before time t. In this work, each time window includes 50 news stories.",
                "Thus, each story d received in t is represented as follows: 1 2{ ( , , ), ( , , ),..., ( , , )}nd weight d t w weight d t w weight d t w→ where n means the number of distinct terms in story d, and ( , , )weight d t w means the weight of term w in story d at time t: log( ( , ) 1) log(( 1) /( ( ) 0.5)) ( , , ) log( ( , ) 1) log(( 1) /( ( ) 0.5)) t t t t w d tf d w N df w weight d t w tf d w N df w ∈ + + + = + + +∑ (2) where Nt means the total number of news stories before time t, and tf(d,w) means how many times term w occurs in news story d. 3.2 Similarity Calculation We use Hellinger distance for the calculation of similarity between two stories, for two stories d and d at time t, their similarity is defined as follows: , ( , , ) ( , , ) * ( , , ) w d d sim d d t weight d t w weight d t w ∈ = ∑ (3) 3.3 Detection Procedure For each story d received in time step t, the value ( ) ( ) ( ) ( ( , , )) time d time d n d max sim d d t < = (4) is a score used to determine whether d is a story about a new topic and at the same time is an indication of the confidence in our decision [8]. time(d) means the publication time of story d. If the score exceeds the thresholdθ new, then there exists a sufficiently similar document, thus d is a old story, otherwise, there is no sufficiently similar previous document, thus d is an new story. 4.",
                "New NED Procedure Traditional NED systems can be classified into two main types on the aspect of detection procedure: (1) S-S type, in which the story on hand is compared to each story received previously, and use the highest similarity to determine whether current story is about a new event; (2) S-C type, in which the story on hand is compared to all previous clusters each of which representing a topic, and the highest similarity is used for final decision for current story.",
                "If the highest similarity exceeds thresholdθ new, then it is an old story, and put it into the most similar cluster; otherwise it is a new story and create a new cluster.",
                "Previous work show that the first manner is more accurate than the second one [4][5].",
                "Since sometimes stories within a topic drift far away from each other, a story may have very low similarity with its topic.",
                "So using similarities between stories for determining new story is better than using similarities between story and clusters.",
                "Nevertheless, the first manner needs much more comparing times which means the first manner is low efficient.",
                "We propose a new detection procedure which uses comparisons with previous clusters to help find the most similar story in less comparing times, and the final new event decision is made according to the most similar story.",
                "Therefore, we can get both the accuracy of S-S type methods and the efficiency of S-C type methods.",
                "The new procedure creates a news indexing-tree dynamically, in which similar stories are put together to form a hierarchy of clusters.",
                "We index similar stories together by their common ancestor (a cluster node).",
                "Dissimilar stories are indexed in different clusters.",
                "When a story is coming, we use comparisons between the current story and previous hierarchical clusters to help find the most similar story which is useful for new event decision.",
                "After the new event decision is made, the current story is inserted to the indexing-tree for the following detection.",
                "The news indexing-tree is defined formally as follows: S-Tree = {r, NC , NS , E} where r is the root of S-Tree, NC is the set of all cluster nodes, NS is the set of all story nodes, and E is the set of all edges in S-Tree.",
                "We define a set of constraints for a S-Tree: ⅰ . , is an non-terminal node in the treeC i i N i∀ ∈ → ⅱ . , is a terminal node in the treeS i i N i∀ ∈ → ⅲ . , out degree of is at least 2C i i N i∀ ∈ → ⅳ . , is represented as the centroid of its desendantsC i i iN∀ ∈ → For a news story di, the comparison procedure and inserting procedure based on indexing-tree are defined as follows.",
                "An example is shown by Figure 1 and Figure 2.",
                "Figure 1.",
                "Comparison procedure Figure 2.",
                "Inserting procedure Comparison procedure: Step 1: compare di to all the direct child nodes of r and select λ nodes with highest similarities, e.g., C1 2 and C1 3 in Figure 1.",
                "Step 2: for each selected node in the last step, e.g.",
                "C1 2, compare di to all its direct child nodes, and select λ nodes with highest similarities, e.g.",
                "C2 2 and d8.",
                "Repeat step 2 for all non-terminal nodes.",
                "Step 3: record the terminal node with the highest similarty to di, e.g. s5, and the similarity value (0.20).",
                "Inserting di to the S-tree with r as root: Find the node n which is direct child of r in the path from r to the terminal node with highest similarity s, e.g.",
                "C1 2.",
                "If s is smaller than θ init+(h-1)δ , then add di to the tree as a direct child of r. Otherwise, if n is a terminal node, then create a cluster node instead of n, and add both n and di as its direct children; if n is an non-terminal node, then repeat this procedure and insert di to the sub-tree with n as root recursively.",
                "Here h is the length between n and the root of S-tree.",
                "The more the stories in a cluster similar to each other, the better the cluster represents the stories in it.",
                "Hence we add no constraints on the maximum of trees height and degree of a node.",
                "Therefore, we cannot give the complexity of this indexing-tree based procedure.",
                "But we will give the number of comparing times needed by the new procedure in our experiments in section7. 5.",
                "Term Reweighting Methods In this section, two term reweighting methods are proposed to improve NED accuracy.",
                "In the first method, a new way is explored for better using of cluster (topic) information.",
                "The second one finds a better way to make use of named entities based on news classification. 5.1 Term Reweighting Based on Distribution Distance TF-IDF is the most prevalent model used in information retrieval systems.",
                "The basic idea is that the fewer documents a term appears in, the more important the term is in discrimination of documents (relevant or not relevant to a query containing the term).",
                "Nevertheless, in TDT domain, we need to discriminate documents with regard to topics rather than queries.",
                "Intuitively, using cluster (topic) vectors to compare with subsequent news stories should outperform using story vectors.",
                "Unfortunately, the experimental results do not support this intuition [4][5].",
                "Based on observation on data, we find the reason is that a news topic usually contains many directly or indirectly related events, while they all have their own sub-subjects which are usually different with each other.",
                "Take the topic described in section 1 as an example, events like the explosion and salvage have very low similarities with events about criminal trial, therefore stories about trial would have low similarity with the topic vector built on its previous events.",
                "This section focuses on how to effectively make use of topic information and at the same time avoid the problem of content decentralization.",
                "At first, we classify terms into 5 classes to help analysis the needs of the modified model: Term class A: terms that occur frequently in the whole corpus, e.g., year and people.",
                "Terms of this class should be given low weights because they do not help much for topic discrimination.",
                "Term class B: terms that occur frequently within a news category, e.g., election, storm.",
                "They are useful to distinguish two stories in different news categories.",
                "However, they cannot provide information to determine whether two stories are on the same or different topics.",
                "In another words, term election and term storm are not helpful in differentiate two election campaigns and two storm disasters.",
                "Therefore, terms of this class should be assigned lower weights.",
                "Term class C: terms that occur frequently in a topic, and infrequently in other topics, e.g., the name of a crash plane, the name of a specific hurricane.",
                "News stories that belong to different topics rarely have overlap terms in this class.",
                "The more frequently a term appears in a topic, the more important the term is for a story belonging to the topic, therefore the term should be set higher weight.",
                "Term class D: terms that appear in a topic exclusively, but not frequently.",
                "For example, the name of a fireman who did very well in a salvage action, which may appears in only two or three stories but never appeared in other topics.",
                "Terms of this type should receive more weights than in TF-IDF model.",
                "However, since they are not popular in the topic, it is not appropriate to give them too high weights.",
                "Term class E: terms with low document frequency, and appear in different topics.",
                "Terms of this class should receive lower weights.",
                "Now we analyze whether TF-IDF model can give proper weights to the five classes of terms.",
                "Obviously, terms of class A are lowly weighted in TF-IDF model, which is conformable with the requirement described above.",
                "In TF-IDF model, terms of class B are highly dependant with the number of stories in a news class.",
                "TF-IDF model cannot provide low weights if the story containing the term belongs to a relative small news class.",
                "For a term of class C, the more frequently it appears in a topic, the less weight TFIDF model gives to it.",
                "This strongly conflicts with the requirement of terms in class C. For terms of class D, TF-IDF model gives them high weights correctly.",
                "But for terms of class E, TF-IDF model gives high weights to them which are not conformable with the requirement of low weights.",
                "To sum up, terms of class B, C, E cannot be properly weighted in TF-IDF model.",
                "So, we propose a modified model to resolve this problem.",
                "When θ init andθ new are set closely, we assume that most of the stories in a first-level cluster (a direct child node of root node) are on the same topic.",
                "Therefore, we make use of a first-level cluster to capture term distribution (df for all the terms within the cluster) within the topic dynamically.",
                "KL divergence of term distribution in a first-level cluster and the whole story set is used to adjust term weights:  ( , , ) * (1 * ( || )) ( , , ) ( , , ) * (1 * ( || )) cw tw cw tw w d D weight d t w KL P P weight d t w weight d t w KL P P γ γ ∈ + = +∑ (5) where ( ) ( ) ( ) ( ) 1,cw cw c c c c df w df w p y p y N N = = − (6) ( ) ( ) ( ) ( ) 1,t t tw tw t t df w df w p y p y N N = = − (7) where dfc(w) is the number of documents containing term w within cluster C, and Nc is the number of documents in cluster C, and Nt is the total number of documents that arrive before time step t. γ is a const parameter, now is manually set 3.",
                "KL divergence is defined as follows [17]: ( ) ( || ) ( ) log ( )x p x KL P Q p x q x = ∑ (8) The basic idea is: for a story in a topic, the more a term occurs within the topic, and the less it occurs in other topics, it should be assigned higher weights.",
                "Obviously, modified model can meet all the requirements of the five term classes listed above. 5.2 Term Reweighting Based on Term Type and Story Class Previous work found that some classes of news stories could achieve good improvements by giving extra weight to named entities.",
                "But we find that terms of different types should be given different amount of extra weight for different classes of news stories.",
                "We use open-NLP1 to recognize named entity types and part-ofspeech tags for terms that appear in news stories.",
                "Named entity types include person name, organization name, location name, date, time, money and percentage, and five POSs are selected: none (NN), verb (VB), adjective (JJ), adverb (RB) and cardinal number (CD).",
                "Statistical analysis shows topic-level discriminative terms types for different classes of stories.",
                "For the sake of convenience, named entity type and part-of-speech tags are uniformly called term type in subsequent sections.",
                "Determining whether two stories are about the same topic is a basic component for NED task.",
                "So at first we use 2 χ statistic to compute correlations between terms and topics.",
                "For a term t and a topic T, a contingence table is derived: Table 1.",
                "A 2×2 Contingence Table Doc Number belong to topic T not belong to topic T include t A B not include t C D The 2 χ statistic for a specific term t with respect to topic T is defined to be [16]: 2 2 ( , ) ( ) * ( ) ( ) * ( ) * ( ) * ( ) w T A B C D AD CB A C B D A B C D χ = + + + − + + + + (9) News topics for the TDT task are further classified into 11 rules of interpretations (ROIs) 2 .",
                "The ROI can be seen as a higher level class of stories.",
                "The average correlation between a term type and a topic ROI is computed as: 2 avg 2 ( , )( ( , ) )k m m km kT R w P w TP R p w T R P χ χ ∈ ∈ ∑ ∑（ , ）= 1 1 k=1…K, m=1…M (10) where K is the number of term types (set 12 constantly in the paper).",
                "M is the number news classes (ROIs, set 11 in the paper).",
                "Pk represents the set of all terms of type k, and Rm represents the set of all topics of class m, p(t,T) means the probability that t occurs in topic T. Because of limitation of space, only parts of the term types (9 term types) and parts of news classes (8 classes) are listed in table 2 with the average correlation values between them.",
                "The statistics is derived from labeled data in TDT2 corpus. (Results in table 2 are already normalized for convenience in comparison.)",
                "The statistics in table 2 indicates the usefulness of different term types in topic discrimination with respect to different news classes.",
                "We can see that, location name is the most useful term type for three news classes: Natural Disasters, Violence or War, Finances.",
                "And for three other categories Elections, Legal/Criminal Cases, Science and Discovery, person name is the most discriminative term type.",
                "For Scandals/Hearings, date is the most important information for topic discrimination.",
                "In addition, Legal/Criminal Cases and Finance topics have higher correlation with money terms, while Science and Discovery have higher correlation with percentage terms.",
                "Non-name terms are more stable for different classes. 1 . http://opennlp.sourceforge.net/ 2 . http://projects.ldc.upenn.edu/TDT3/Guide/label.html From the analysis of table 2, it is reasonable to adjust term weight according to their term type and the news class the story belongs to.",
                "New term weights are reweighted as follows: ( ) ( ) ( ) ( ) ( , , ) * ( , , ) ( , , ) * class d D type w T class d D type w w d weight d t w weight d t w weight d t w α α ∈ = ∑ (11) where type(w) represents the type of term w, and class(d) represents the class of story d, c kα is reweighting parameter for news class c and term type k. In the work, we just simply use statistics in table 2 as the reweighting parameters.",
                "Even thought using the statistics directly may not the best choice, we do not discuss how to automatically obtain the best parameters.",
                "We will try to use machine learning techniques to obtain the best parameters in the future work.",
                "In the work, we use BoosTexter [20] to classify all stories into one of the 11 ROIs.",
                "BoosTexter is a boosting based machine learning program, which creates a series of simple rules for building a classifier for text or attribute-value data.",
                "We use term weight generated using TF-IDF model as feature for story classification.",
                "We trained the model on the 12000 judged English stories in TDT2, and classify the rest of the stories in TDT2 and all stories in TDT3.",
                "Classification results are used for term reweighting in formula (11).",
                "Since the class labels of topic-off stories are not given in TDT datasets, we cannot give the classification accuracy here.",
                "Thus we do not discuss the effects of classification accuracy to NED performance in the paper. 6.",
                "EXPERIMENTAL SETUP 6.1 Datasets We used two LDC [18] datasets TDT2 and TDT3 for our experiments.",
                "TDT2 contains news stories from January to June 1998.",
                "It contains around 54,000 stories from sources like ABC, Associated Press, CNN, New York Times, Public Radio International, Voice of America etc.",
                "Only English stories in the collection were considered.",
                "TDT3 contains approximately 31,000 English stories collected from October to December 1998.",
                "In addition to the sources used in TDT2, it also contains stories from NBC and MSNBC TV broadcasts.",
                "We used transcribed versions of the TV and radio broadcasts besides textual news.",
                "TDT2 dataset is labeled with about 100 topics, and approximately 12,000 English stories belong to at least one of these topics.",
                "TDT3 dataset is labeled with about 120 topics, and approximately 8000 English stories belong to at least one of these topics.",
                "All the topics are classified into 11 Rules of Interpretation: (1)Elections, (2)Scandals/Hearings, (3)Legal/Criminal Cases, (4)Natural Disasters, (5)Accidents, (6)Ongoing Violence or War, (7)Science and Discovery News, (8)Finance, (9)New Law, (10)Sports News, (11)MISC.",
                "News. 6.2 Evaluation Metric TDT uses a cost function CDet that combines the probabilities of missing a new story and a false alarm [19]: * * * *Det Miss Miss Target FA FA NontargetC C P P C P P= + (12) Table 2.",
                "Average correlation between term types and news classes where CMiss means the cost of missing a new story, PMiss means the probability of missing a new story, and PTarget means the probability of seeing a new story in the data; CFA means the cost of a false alarm, PFA means the probability of a false alarm, and PNontarget means the probability of seeing an old story.",
                "The cost CDet is normalized such that a perfect system scores 0 and a trivial system, which is the better one of mark all stories as new or old, scores 1: ( ( * , * ) ) Det Det Miss Target FA Nontarget C Norm C min C P C P = (13) New event detection system gives two outputs for each story.",
                "The first part is yes or no indicating whether the story triggers a new event or not.",
                "The second part is a score indicating confidence of the first decision.",
                "Confidence scores can be used to plot DET curve, i.e., curves that plot false alarm vs. miss probabilities.",
                "Minimum normalized cost can be determined if optimal threshold on the score were chosen. 7.",
                "EXPERIMENTAL RESULTS 7.1 Main Results To test the approaches proposed in the model, we implemented and tested five systems: System-1: this system is used as baseline.",
                "It is implemented based on the basic model described in section 3, i.e., using incremental TF-IDF model to generate term weights, and using Hellinger distance to compute document similarity.",
                "Similarity score normalization is also employed [8].",
                "S-S detection procedure is used.",
                "System-2: this system is the same as system-1 except that S-C detection procedure is used.",
                "System-3: this system is the same as system-1 except that it uses the new detection procedure which is based on indexing-tree.",
                "System-4: implemented based on the approach presented in section 5.1, i.e., terms are reweighted according to the distance between term distributions in a cluster and all stories.",
                "The new detection procedure is used.",
                "System-5: implemented based on the approach presented in section 5.2, i.e., terms of different types are reweighted according to news class using trained parameters.",
                "The new detection procedure is used.",
                "The following are some other NED systems: System-6: [21] for each pair of stories, it computes three similarity values for named entity, non-named entity and all terms respectively.",
                "And employ Support Vector Machine to predict new or old using the similarity values as features.",
                "System-7: [8] it extended a basic incremental TF-IDF model to include source-specific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, etc.",
                "System-8: [13] it split document representation into two parts: named entities and non-named entities, and choose one effective part for each news class.",
                "Table 3 and table 4 show topic-weighted normalized costs and comparing times on TDT2 and TDT3 datasets respectively.",
                "Since no heldout data set for fine-tuning the threshold θ new was available for experiments on TDT2, we only report minimum normalized costs for our systems in table 3.",
                "System-5 outperforms all other systems including system-6, and it performs only 2.78e+8 comparing times in detection procedure which is only 13.4% of system-1.",
                "Table 3.",
                "NED results on TDT2 Systems Min Norm(CDet) Cmp times System-1 0.5749 2.08e+9 System-2① 0.6673 3.77e+8 System-3② 0.5765 2.81e+8 System-4② 0.5431 2.99e+8 System-5② 0.5089 2.78e+8 System-6 0.5300 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 When evaluating on the normalized costs on TDT3, we use the optimal thresholds obtained from TDT2 data set for all systems.",
                "System-2 reduces comparing times to 1.29e+9 which is just 18.3% of system-1, but at the same time it also gets a deteriorated minimum normalized cost which is 0.0499 higher than system-1.",
                "System-3 uses the new detection procedure based on news indexing-tree.",
                "It requires even less comparing times than system-2.",
                "This is because story-story comparisons usually yield greater similarities than story-cluster ones, so stories tend to be combined Location Person Date Organization Money Percentage NN JJ CD Elections 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 Scandals/Hearings 0.66 0.62 0.28 1 0.11 0.02 0.27 0.13 0.05 Legal/Criminal Cases 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 Natural Disasters 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 Violence or War 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 Science and Discovery 0.11 1 0.01 0.22 0.08 0.12 0.19 0.08 0.03 Finances 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 Sports 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 together in system-3.",
                "And system-3 is basically equivalent to system-1 in accuracy results.",
                "System-4 adjusts term weights based on the distance of term distributions between the whole corpus and cluster story set, yielding a good improvement by 0.0468 compared to system-1.",
                "The best system (system-5) has a minimum normalized cost 0.5012, which is 0.0797 better than system-1, and also better than any other results previously reported for this dataset [8, 13].",
                "Further more, system-5 only needs 1.05e+8 comparing times which is 14.9% of system-1.",
                "Table 4.",
                "NED results on TDT3 Systems Norm(CDet) Min Norm(CDet) Cmp times System-1 0.6159 0.5809 7.04e+8 System-2① 0.6493 0.6308 1.29e+8 System-3② 0.6197 0.5868 1.03e+8 System-4② 0.5601 0.5341 1.03e+8 System-5② 0.5413 0.5012 1.05e+8 System-7 -- 0.5783 -System-8 -- 0.5229 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 Figure5 shows the five DET curves for our systems on data set TDT3.",
                "System-5 achieves the minimum cost at a false alarm rate of 0.0157 and a miss rate of 0.4310.",
                "We can observe that System4 and System-5 obtain lower miss probability at regions of low false alarm probabilities.",
                "The hypothesis is that, more weight value is transferred to key terms of topics from non-key terms.",
                "Similarity score between two stories belonging to different topics are lower than before, because their overlapping terms are usually not key terms of their topics. 7.2 Parameter selection for indexing-tree detection Figure 3 shows the minimum normalized costs obtained by system-3 on TDT3 using different parameters.",
                "Theθ init parameter is tested on six values spanning from 0.03 to 0.18.",
                "And the λ parameter is tested on four values 1, 2, 3 and 4.",
                "We can see that, whenθ init is set to 0.12, which is the closest one toθ new, the costs are lower than others.",
                "This is easy to explain, because when stories belonging to the same topic are put in a cluster, it is more reasonable for the cluster to represent the stories in it.",
                "When parameter λ is set to 3 or 4, the costs are better than other cases, but there is no much difference between 3 and 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ MinCost 0.6 0.65 0.7 0.75 0.8 0.85 0.9 Figure 3.",
                "Min Cost on TDT3 (δ =0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ Comparingtimes 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 Figure 4.",
                "Comparing times on TDT3 (δ =0.15) Figure 4 gives the comparing times used by system-3 on TDT3 with the same parameters as figure 3.",
                "The comparing times are strongly dependent onθ init.",
                "Because the greaterθ init is, the less stories combined together, the more comparing times are needed for new event decision.",
                "So we useθ init =0.13,λ =3,δ =0.15 for system-3, 4, and 5.",
                "In this parameter setting, we can get both low minimum normalized costs and less comparing times. 8.",
                "CONCLUSION We have proposed a news indexing-tree based detection procedure in our model.",
                "It reduces comparing times to about one seventh of traditional method without hurting NED accuracy.",
                "We also have presented two extensions to the basic TF-IDF model.",
                "The first extension is made by adjust term weights based on term distributions between the whole corpus and a cluster story set.",
                "And the second extension to basic TF-IDF model is better use of term types (named entities types and part-of-speed) according to news categories.",
                "Our experimental results on TDT2 and TDT3 datasets show that both of the two extensions contribute significantly to improvement in accuracy.",
                "We did not consider news time information as a clue for NED task, since most of the topics last for a long time and TDT data sets only span for a relative short period (no more than 6 months).",
                "For the future work, we want to collect news set which span for a longer period from internet, and integrate time information in NED task.",
                "Since topic is a relative coarse-grained news cluster, we also want to refine cluster granularity to event-level, and identify different events and their relations within a topic.",
                "Acknowledgments This work is supported by the National Natural Science Foundation of China under Grant No. 90604025.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] In Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. .01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90 1 2 5 10 20 40 60 80 90 False Alarm Probability (in %) MissProbability(in%) SYSTEM1 Topic Weighted Curve SYSTEM1 Min Norm(Cost) SYSTEM2 Topic Weighted Curve SYSTEM2 Min Norm(Cost) SYSTEM3 Topic Weighted Curve SYSTEM3 Min Norm(Cost) SYSTEM4 Topic Weighted Curve SYSTEM4 Min Norm(Cost) SYSTEM5 Topic Weighted Curve SYSTEM5 Min Norm(Cost) Random Performance Figure 5.",
                "DET curves on TDT3 [3] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B.T.",
                "Archibald, and X. Liu.",
                "Learning Approaches for Detecting and Tracking News Events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), 1999, 32-43. [4] Y. Yang, T. Pierce, and J. Carbonell.",
                "A Study on Retrospective and On-line Event Detection.",
                "In Proceedings of SIGIR-98, Melbourne, Australia, 1998, 28-36. [5] J. Allan, V. Lavrenko, D. Malin, and R. Swan.",
                "Detections, Bounds, and Timelines: Umass and tdt-3.",
                "In Proceedings of Topic Detection and Tracking Workshop (TDT-3), Vienna, VA, 2000, 167-174. [6] R. Papka and J. Allan.",
                "On-line New Event Detection Using Single Pass Clustering TITLE2:.",
                "Technical Report UM-CS1998-021, 1998. [7] W. Lam, H. Meng, K. Wong, and J.",
                "Yen.",
                "Using Contextual Analysis for News Event Detection.",
                "International Journal on Intelligent Systems, 2001, 525-546. [8] B. Thorsten, C. Francine, and F. Ayman.",
                "A System for New Event Detection.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2003, 330-337. [9] S. Nicola and C. Joe.",
                "Combining Semantic and Syntactic Document Classifiers to Improve First Story Detection.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2001, 424425. [10] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topicconditioned Novelty Detection.",
                "In Proceedings of the 8th ACM SIGKDD International Conference, ACM Press. 2002, 688-693. [11] M. Juha, A.M. Helena, and S. Marko.",
                "Applying Semantic Classes in Event Detection and Tracking.",
                "In Proceedings of International Conference on Natural Language Processing (ICON 2002), 2002, pages 175-183. [12] M. Juha, A.M. Helena, and S. Marko.",
                "Simple Semantics in Topic Detection and Tracking.",
                "Information Retrieval, 7(3-4): 2004, 347-368. [13] K. Giridhar and J. Allan.",
                "Text Classification and Named Entities for New Event Detection.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2004, 297-304. [14] J. P. Callan, W. B. Croft, and S. M. Harding.",
                "The INQUERY Retrieval System.",
                "In Proceedings of DEXA-92, 3rd International Conference on Database and Expert Systems Applications, 1992, 78-83. [15] R. Krovetz.",
                "Viewing Morphology as An Inference Process.",
                "In Proceedings of ACM SIGIR93, 1993, 61-81. [16] Y. Yang and J. Pedersen.",
                "A Comparative Study on Feature Selection in Text Categorization.",
                "In J. D. H. Fisher, editor, The Fourteenth International Conference on Machine Learning (ICML97), Morgan Kaufmann, 1997, 412-420. [17] T. M. Cover, and J.A.",
                "Thomas.",
                "Elements of Information Theory.",
                "Wiley. 1991. [18] The linguistic data consortium, http://www.ldc,upenn.edu/. [19] The 2001 TDT task definition and evaluation plan, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm. [20] R. E. Schapire and Y.",
                "Singer.",
                "Boostexter: A Boosting-based System for Text Categorization.",
                "In Machine Learning 39(2/3):1, Kluwer Academic Publishers, 2000, 35-168. [21] K. Giridhar and J. Allan. 2005.",
                "Using Names and Topics for New Event Detection.",
                "In Proceedings of Human Technology Conference and Conference on Empirical Methods in Natural Language, Vancouver, 2005, 121-128"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Además, en base a la observación de que los términos de diferentes tipos tienen diferentes efectos para la tarea NED, se proponen dos \"enfoque de re -peso de términos\" para mejorar la precisión de NED."
            ],
            "translated_text": "",
            "candidates": [
                "enfoque de rewe -weighting de término",
                "enfoque de re -peso de términos"
            ],
            "error": []
        },
        "ned accuracy": {
            "translated_key": "precisión de NED",
            "is_in_text": true,
            "original_annotated_sentences": [
                "New Event Detection Based on Indexing-tree and Named Entity Zhang Kuo Tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn Li Juan Zi Tsinghua University Beijing, 100084, China 86-10-62781461 ljz@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn ABSTRACT New Event Detection (NED) aims at detecting from one or multiple streams of news stories that which one is reported on a new event (i.e.",
                "not reported previously).",
                "With the overwhelming volume of news available today, there is an increasing need for a NED system which is able to detect new events more efficiently and accurately.",
                "In this paper we propose a new NED model to speed up the NED task by using news indexing-tree dynamically.",
                "Moreover, based on the observation that terms of different types have different effects for NED task, two term reweighting approaches are proposed to improve <br>ned accuracy</br>.",
                "In the first approach, we propose to adjust term weights dynamically based on previous story clusters and in the second approach, we propose to employ statistics on training data to learn the named entity reweighting model for each class of stories.",
                "Experimental results on two Linguistic Data Consortium (LDC) datasets TDT2 and TDT3 show that the proposed model can improve both efficiency and accuracy of NED task significantly, compared to the baseline system and other existing systems.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Search and Retrieval; H.4.2 [Information Systems Applications]: Types of Systemsdecision support.",
                "General Terms Algorithms, Performance, Experimentation 1.",
                "INTRODUCTION Topic Detection and Tracking (TDT) program aims to develop techniques which can effectively organize, search and structure news text materials from a variety of newswire and broadcast media [1].",
                "New Event Detection (NED) is one of the five tasks in TDT.",
                "It is the task of online identification of the earliest report for each topic as soon as that report arrives in the sequence of documents.",
                "A Topic is defined as a seminal event or activity, along with directly related events and activities [2].",
                "An Event is defined as something (non-trivial) happening in a certain place at a certain time [3].",
                "For instance, when a bomb explodes in a building, the exploding is the seminal event that triggers the topic, and other stories on the same topic would be those discussing salvaging efforts, the search for perpetrators, arrests and trial and so on.",
                "Useful news information is usually buried in a mass of data generated everyday.",
                "Therefore, NED systems are very useful for people who need to detect novel information from real-time news stream.",
                "These real-life needs often occur in domains like financial markets, news analysis, and intelligence gathering.",
                "In most of state-of-the-art (currently) NED systems, each news story on hand is compared to all the previous received stories.",
                "If all the similarities between them do not exceed a threshold, then the story triggers a new event.",
                "They are usually in the form of cosine similarity or Hellinger similarity metric.",
                "The core problem of NED is to identify whether two stories are on the same topic.",
                "Obviously, these systems cannot take advantage of topic information.",
                "Further more, it is not acceptable in real applications because of the large amount of computation required in the NED process.",
                "Other systems organize previous stories into clusters (each cluster corresponds to a topic), and new story is compared to the previous clusters instead of stories.",
                "This manner can reduce comparing times significantly.",
                "Nevertheless, it has been proved that this manner is less accurate [4, 5].",
                "This is because sometimes stories within a topic drift far away from each other, which could lead low similarity between a story and its topic.",
                "On the other hand, some proposed NED systems tried to improve accuracy by making better use of named entities [10, 11, 12, 13].",
                "However, none of the systems have considered that terms of different types (e.g.",
                "Noun, Verb or Person name) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "For example, the names of election candidates (Person name) are very important for stories of election class; the locations (Location name) where accidents happened are important for stories of accidents class.",
                "So, in NED, there still exist following three problems to be investigated: (1) How to speed up the detection procedure while do not decrease the detection accuracy? (2) How to make good use of cluster (topic) information to improve accuracy? (3) How to obtain better news story representation by better understanding of named entities.",
                "Driven by these problems, we have proposed three approaches in this paper. (1)To make the detection procedure faster, we propose a new NED procedure based on news indexing-tree created dynamically.",
                "Story indexing-tree is created by assembling similar stories together to form news clusters in different hierarchies according to their values of similarity.",
                "Comparisons between current story and previous clusters could help find the most similar story in less comparing times.",
                "The new procedure can reduce the amount of comparing times without hurting accuracy. (2)We use the clusters of the first floor in the indexing-tree as news topics, in which term weights are adjusted dynamically according to term distribution in the clusters.",
                "In this approach, cluster (topic) information is used properly, so the problem of theme decentralization is avoided. (3)Based on observations on the statistics obtained from training data, we found that terms of different types (e.g.",
                "Noun and Verb) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "And we propose to use statistics to optimize the weights of the terms of different types in a story according to the news class that the story belongs to.",
                "On TDT3 dataset, the new NED model just uses 14.9% comparing times of the basic model, while its minimum normalized cost is 0.5012, which is 0.0797 better than the basic model, and also better than any other results previously reported for this dataset [8, 13].",
                "The rest of the paper is organized as follows.",
                "We start off this paper by summarizing the previous work in NED in section 2.",
                "Section 3 presents the basic model for NED that most current systems use.",
                "Section 4 describes our new detection procedure based on news indexing-tree.",
                "In section 5, two term reweighting methods are proposed to improve <br>ned accuracy</br>.",
                "Section 6 gives our experimental data and evaluation metrics.",
                "We finally wrap up with the experimental results in Section 7, and the conclusions and future work in Section 8. 2.",
                "RELATED WORK Papka et al. proposed Single-Pass clustering on NED [6].",
                "When a new story was encountered, it was processed immediately to extract term features and a query representation of the storys content is built up.",
                "Then it was compared with all the previous queries.",
                "If the document did not trigger any queries by exceeding a threshold, it was marked as a new event.",
                "Lam et al build up previous query representations of story clusters, each of which corresponds to a topic [7].",
                "In this manner comparisons happen between stories and clusters.",
                "Recent years, most work focus on proposing better methods on comparison of stories and document representation.",
                "Brants et al. [8] extended a basic incremental TF-IDF model to include sourcespecific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, term reweighting based on inverse event frequencies, and segmentation of documents.",
                "Good improvements on TDT bench-marks were shown.",
                "Stokes et al. [9] utilized a combination of evidence from two distinct representations of a documents content.",
                "One of the representations was the usual free text vector, the other made use of lexical chains (created using WordNet) to build another term vector.",
                "Then the two representations are combined in a linear fashion.",
                "A marginal increase in effectiveness was achieved when the combined representation was used.",
                "Some efforts have been done on how to utilize named entities to improve NED.",
                "Yang et al. gave location named entities four times weight than other terms and named entities [10].",
                "DOREMI research group combined semantic similarities of person names, location names and time together with textual similarity [11][12].",
                "UMass [13] research group split document representation into two parts: named entities and non-named entities.",
                "And it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation.",
                "Both [10] and [13] used text categorization technique to classify news stories in advance.",
                "In [13] news stories are classified automatically at first, and then test sensitivities of names and non-name terms for NED for each class.",
                "In [10] frequent terms for each class are removed from document representation.",
                "For example, word election does not help identify different elections.",
                "In their work, effectiveness of different kinds of names (or terms with different POS) for NED in different news classes are not investigated.",
                "We use statistical analysis to reveal the fact and use it to improve NED performance. 3.",
                "BASIC MODEL In this section, we present the basic New Event Detection model which is similar to what most current systems apply.",
                "Then, we propose our new model by extending the basic model.",
                "New Event Detection systems use news story stream as input, in which stories are strictly time-ordered.",
                "Only previously received stories are available when dealing with current story.",
                "The output is a decision for whether the current story is on a new event or not and the confidence of the decision.",
                "Usually, a NED model consists of three parts: story representation, similarity calculation and detection procedure. 3.1 Story Representation Preprocessing is needed before generating story representation.",
                "For preprocessing, we tokenize words, recognize abbreviations, normalize abbreviations, add part-of-speech tags, remove stopwords included in the stop list used in InQuery [14], replace words with their stems using K-stem algorithm[15], and then generate word vector for each news story.",
                "We use incremental TF-IDF model for term weight calculation [4].",
                "In a TF-IDF model, term frequency in a news document is weighted by the inverse document frequency, which is generated from training corpus.",
                "When a new term occurs in testing process, there are two solutions: simply ignore the new term or set df of the term as a small const (e.g. df = 1).",
                "The new term receives too low weight in the first solution (0) and too high weight in the second solution.",
                "In incremental TF-IDF model, document frequencies are updated dynamically in each time step t: 1( ) ( ) ( )t t D tdf w df w df w−= + (1) where Dt represents news story set received in time t, and dfDt(w) means the number of documents that term w occurs in, and dft(w) means the total number of documents that term w occurs in before time t. In this work, each time window includes 50 news stories.",
                "Thus, each story d received in t is represented as follows: 1 2{ ( , , ), ( , , ),..., ( , , )}nd weight d t w weight d t w weight d t w→ where n means the number of distinct terms in story d, and ( , , )weight d t w means the weight of term w in story d at time t: log( ( , ) 1) log(( 1) /( ( ) 0.5)) ( , , ) log( ( , ) 1) log(( 1) /( ( ) 0.5)) t t t t w d tf d w N df w weight d t w tf d w N df w ∈ + + + = + + +∑ (2) where Nt means the total number of news stories before time t, and tf(d,w) means how many times term w occurs in news story d. 3.2 Similarity Calculation We use Hellinger distance for the calculation of similarity between two stories, for two stories d and d at time t, their similarity is defined as follows: , ( , , ) ( , , ) * ( , , ) w d d sim d d t weight d t w weight d t w ∈ = ∑ (3) 3.3 Detection Procedure For each story d received in time step t, the value ( ) ( ) ( ) ( ( , , )) time d time d n d max sim d d t < = (4) is a score used to determine whether d is a story about a new topic and at the same time is an indication of the confidence in our decision [8]. time(d) means the publication time of story d. If the score exceeds the thresholdθ new, then there exists a sufficiently similar document, thus d is a old story, otherwise, there is no sufficiently similar previous document, thus d is an new story. 4.",
                "New NED Procedure Traditional NED systems can be classified into two main types on the aspect of detection procedure: (1) S-S type, in which the story on hand is compared to each story received previously, and use the highest similarity to determine whether current story is about a new event; (2) S-C type, in which the story on hand is compared to all previous clusters each of which representing a topic, and the highest similarity is used for final decision for current story.",
                "If the highest similarity exceeds thresholdθ new, then it is an old story, and put it into the most similar cluster; otherwise it is a new story and create a new cluster.",
                "Previous work show that the first manner is more accurate than the second one [4][5].",
                "Since sometimes stories within a topic drift far away from each other, a story may have very low similarity with its topic.",
                "So using similarities between stories for determining new story is better than using similarities between story and clusters.",
                "Nevertheless, the first manner needs much more comparing times which means the first manner is low efficient.",
                "We propose a new detection procedure which uses comparisons with previous clusters to help find the most similar story in less comparing times, and the final new event decision is made according to the most similar story.",
                "Therefore, we can get both the accuracy of S-S type methods and the efficiency of S-C type methods.",
                "The new procedure creates a news indexing-tree dynamically, in which similar stories are put together to form a hierarchy of clusters.",
                "We index similar stories together by their common ancestor (a cluster node).",
                "Dissimilar stories are indexed in different clusters.",
                "When a story is coming, we use comparisons between the current story and previous hierarchical clusters to help find the most similar story which is useful for new event decision.",
                "After the new event decision is made, the current story is inserted to the indexing-tree for the following detection.",
                "The news indexing-tree is defined formally as follows: S-Tree = {r, NC , NS , E} where r is the root of S-Tree, NC is the set of all cluster nodes, NS is the set of all story nodes, and E is the set of all edges in S-Tree.",
                "We define a set of constraints for a S-Tree: ⅰ . , is an non-terminal node in the treeC i i N i∀ ∈ → ⅱ . , is a terminal node in the treeS i i N i∀ ∈ → ⅲ . , out degree of is at least 2C i i N i∀ ∈ → ⅳ . , is represented as the centroid of its desendantsC i i iN∀ ∈ → For a news story di, the comparison procedure and inserting procedure based on indexing-tree are defined as follows.",
                "An example is shown by Figure 1 and Figure 2.",
                "Figure 1.",
                "Comparison procedure Figure 2.",
                "Inserting procedure Comparison procedure: Step 1: compare di to all the direct child nodes of r and select λ nodes with highest similarities, e.g., C1 2 and C1 3 in Figure 1.",
                "Step 2: for each selected node in the last step, e.g.",
                "C1 2, compare di to all its direct child nodes, and select λ nodes with highest similarities, e.g.",
                "C2 2 and d8.",
                "Repeat step 2 for all non-terminal nodes.",
                "Step 3: record the terminal node with the highest similarty to di, e.g. s5, and the similarity value (0.20).",
                "Inserting di to the S-tree with r as root: Find the node n which is direct child of r in the path from r to the terminal node with highest similarity s, e.g.",
                "C1 2.",
                "If s is smaller than θ init+(h-1)δ , then add di to the tree as a direct child of r. Otherwise, if n is a terminal node, then create a cluster node instead of n, and add both n and di as its direct children; if n is an non-terminal node, then repeat this procedure and insert di to the sub-tree with n as root recursively.",
                "Here h is the length between n and the root of S-tree.",
                "The more the stories in a cluster similar to each other, the better the cluster represents the stories in it.",
                "Hence we add no constraints on the maximum of trees height and degree of a node.",
                "Therefore, we cannot give the complexity of this indexing-tree based procedure.",
                "But we will give the number of comparing times needed by the new procedure in our experiments in section7. 5.",
                "Term Reweighting Methods In this section, two term reweighting methods are proposed to improve <br>ned accuracy</br>.",
                "In the first method, a new way is explored for better using of cluster (topic) information.",
                "The second one finds a better way to make use of named entities based on news classification. 5.1 Term Reweighting Based on Distribution Distance TF-IDF is the most prevalent model used in information retrieval systems.",
                "The basic idea is that the fewer documents a term appears in, the more important the term is in discrimination of documents (relevant or not relevant to a query containing the term).",
                "Nevertheless, in TDT domain, we need to discriminate documents with regard to topics rather than queries.",
                "Intuitively, using cluster (topic) vectors to compare with subsequent news stories should outperform using story vectors.",
                "Unfortunately, the experimental results do not support this intuition [4][5].",
                "Based on observation on data, we find the reason is that a news topic usually contains many directly or indirectly related events, while they all have their own sub-subjects which are usually different with each other.",
                "Take the topic described in section 1 as an example, events like the explosion and salvage have very low similarities with events about criminal trial, therefore stories about trial would have low similarity with the topic vector built on its previous events.",
                "This section focuses on how to effectively make use of topic information and at the same time avoid the problem of content decentralization.",
                "At first, we classify terms into 5 classes to help analysis the needs of the modified model: Term class A: terms that occur frequently in the whole corpus, e.g., year and people.",
                "Terms of this class should be given low weights because they do not help much for topic discrimination.",
                "Term class B: terms that occur frequently within a news category, e.g., election, storm.",
                "They are useful to distinguish two stories in different news categories.",
                "However, they cannot provide information to determine whether two stories are on the same or different topics.",
                "In another words, term election and term storm are not helpful in differentiate two election campaigns and two storm disasters.",
                "Therefore, terms of this class should be assigned lower weights.",
                "Term class C: terms that occur frequently in a topic, and infrequently in other topics, e.g., the name of a crash plane, the name of a specific hurricane.",
                "News stories that belong to different topics rarely have overlap terms in this class.",
                "The more frequently a term appears in a topic, the more important the term is for a story belonging to the topic, therefore the term should be set higher weight.",
                "Term class D: terms that appear in a topic exclusively, but not frequently.",
                "For example, the name of a fireman who did very well in a salvage action, which may appears in only two or three stories but never appeared in other topics.",
                "Terms of this type should receive more weights than in TF-IDF model.",
                "However, since they are not popular in the topic, it is not appropriate to give them too high weights.",
                "Term class E: terms with low document frequency, and appear in different topics.",
                "Terms of this class should receive lower weights.",
                "Now we analyze whether TF-IDF model can give proper weights to the five classes of terms.",
                "Obviously, terms of class A are lowly weighted in TF-IDF model, which is conformable with the requirement described above.",
                "In TF-IDF model, terms of class B are highly dependant with the number of stories in a news class.",
                "TF-IDF model cannot provide low weights if the story containing the term belongs to a relative small news class.",
                "For a term of class C, the more frequently it appears in a topic, the less weight TFIDF model gives to it.",
                "This strongly conflicts with the requirement of terms in class C. For terms of class D, TF-IDF model gives them high weights correctly.",
                "But for terms of class E, TF-IDF model gives high weights to them which are not conformable with the requirement of low weights.",
                "To sum up, terms of class B, C, E cannot be properly weighted in TF-IDF model.",
                "So, we propose a modified model to resolve this problem.",
                "When θ init andθ new are set closely, we assume that most of the stories in a first-level cluster (a direct child node of root node) are on the same topic.",
                "Therefore, we make use of a first-level cluster to capture term distribution (df for all the terms within the cluster) within the topic dynamically.",
                "KL divergence of term distribution in a first-level cluster and the whole story set is used to adjust term weights:  ( , , ) * (1 * ( || )) ( , , ) ( , , ) * (1 * ( || )) cw tw cw tw w d D weight d t w KL P P weight d t w weight d t w KL P P γ γ ∈ + = +∑ (5) where ( ) ( ) ( ) ( ) 1,cw cw c c c c df w df w p y p y N N = = − (6) ( ) ( ) ( ) ( ) 1,t t tw tw t t df w df w p y p y N N = = − (7) where dfc(w) is the number of documents containing term w within cluster C, and Nc is the number of documents in cluster C, and Nt is the total number of documents that arrive before time step t. γ is a const parameter, now is manually set 3.",
                "KL divergence is defined as follows [17]: ( ) ( || ) ( ) log ( )x p x KL P Q p x q x = ∑ (8) The basic idea is: for a story in a topic, the more a term occurs within the topic, and the less it occurs in other topics, it should be assigned higher weights.",
                "Obviously, modified model can meet all the requirements of the five term classes listed above. 5.2 Term Reweighting Based on Term Type and Story Class Previous work found that some classes of news stories could achieve good improvements by giving extra weight to named entities.",
                "But we find that terms of different types should be given different amount of extra weight for different classes of news stories.",
                "We use open-NLP1 to recognize named entity types and part-ofspeech tags for terms that appear in news stories.",
                "Named entity types include person name, organization name, location name, date, time, money and percentage, and five POSs are selected: none (NN), verb (VB), adjective (JJ), adverb (RB) and cardinal number (CD).",
                "Statistical analysis shows topic-level discriminative terms types for different classes of stories.",
                "For the sake of convenience, named entity type and part-of-speech tags are uniformly called term type in subsequent sections.",
                "Determining whether two stories are about the same topic is a basic component for NED task.",
                "So at first we use 2 χ statistic to compute correlations between terms and topics.",
                "For a term t and a topic T, a contingence table is derived: Table 1.",
                "A 2×2 Contingence Table Doc Number belong to topic T not belong to topic T include t A B not include t C D The 2 χ statistic for a specific term t with respect to topic T is defined to be [16]: 2 2 ( , ) ( ) * ( ) ( ) * ( ) * ( ) * ( ) w T A B C D AD CB A C B D A B C D χ = + + + − + + + + (9) News topics for the TDT task are further classified into 11 rules of interpretations (ROIs) 2 .",
                "The ROI can be seen as a higher level class of stories.",
                "The average correlation between a term type and a topic ROI is computed as: 2 avg 2 ( , )( ( , ) )k m m km kT R w P w TP R p w T R P χ χ ∈ ∈ ∑ ∑（ , ）= 1 1 k=1…K, m=1…M (10) where K is the number of term types (set 12 constantly in the paper).",
                "M is the number news classes (ROIs, set 11 in the paper).",
                "Pk represents the set of all terms of type k, and Rm represents the set of all topics of class m, p(t,T) means the probability that t occurs in topic T. Because of limitation of space, only parts of the term types (9 term types) and parts of news classes (8 classes) are listed in table 2 with the average correlation values between them.",
                "The statistics is derived from labeled data in TDT2 corpus. (Results in table 2 are already normalized for convenience in comparison.)",
                "The statistics in table 2 indicates the usefulness of different term types in topic discrimination with respect to different news classes.",
                "We can see that, location name is the most useful term type for three news classes: Natural Disasters, Violence or War, Finances.",
                "And for three other categories Elections, Legal/Criminal Cases, Science and Discovery, person name is the most discriminative term type.",
                "For Scandals/Hearings, date is the most important information for topic discrimination.",
                "In addition, Legal/Criminal Cases and Finance topics have higher correlation with money terms, while Science and Discovery have higher correlation with percentage terms.",
                "Non-name terms are more stable for different classes. 1 . http://opennlp.sourceforge.net/ 2 . http://projects.ldc.upenn.edu/TDT3/Guide/label.html From the analysis of table 2, it is reasonable to adjust term weight according to their term type and the news class the story belongs to.",
                "New term weights are reweighted as follows: ( ) ( ) ( ) ( ) ( , , ) * ( , , ) ( , , ) * class d D type w T class d D type w w d weight d t w weight d t w weight d t w α α ∈ = ∑ (11) where type(w) represents the type of term w, and class(d) represents the class of story d, c kα is reweighting parameter for news class c and term type k. In the work, we just simply use statistics in table 2 as the reweighting parameters.",
                "Even thought using the statistics directly may not the best choice, we do not discuss how to automatically obtain the best parameters.",
                "We will try to use machine learning techniques to obtain the best parameters in the future work.",
                "In the work, we use BoosTexter [20] to classify all stories into one of the 11 ROIs.",
                "BoosTexter is a boosting based machine learning program, which creates a series of simple rules for building a classifier for text or attribute-value data.",
                "We use term weight generated using TF-IDF model as feature for story classification.",
                "We trained the model on the 12000 judged English stories in TDT2, and classify the rest of the stories in TDT2 and all stories in TDT3.",
                "Classification results are used for term reweighting in formula (11).",
                "Since the class labels of topic-off stories are not given in TDT datasets, we cannot give the classification accuracy here.",
                "Thus we do not discuss the effects of classification accuracy to NED performance in the paper. 6.",
                "EXPERIMENTAL SETUP 6.1 Datasets We used two LDC [18] datasets TDT2 and TDT3 for our experiments.",
                "TDT2 contains news stories from January to June 1998.",
                "It contains around 54,000 stories from sources like ABC, Associated Press, CNN, New York Times, Public Radio International, Voice of America etc.",
                "Only English stories in the collection were considered.",
                "TDT3 contains approximately 31,000 English stories collected from October to December 1998.",
                "In addition to the sources used in TDT2, it also contains stories from NBC and MSNBC TV broadcasts.",
                "We used transcribed versions of the TV and radio broadcasts besides textual news.",
                "TDT2 dataset is labeled with about 100 topics, and approximately 12,000 English stories belong to at least one of these topics.",
                "TDT3 dataset is labeled with about 120 topics, and approximately 8000 English stories belong to at least one of these topics.",
                "All the topics are classified into 11 Rules of Interpretation: (1)Elections, (2)Scandals/Hearings, (3)Legal/Criminal Cases, (4)Natural Disasters, (5)Accidents, (6)Ongoing Violence or War, (7)Science and Discovery News, (8)Finance, (9)New Law, (10)Sports News, (11)MISC.",
                "News. 6.2 Evaluation Metric TDT uses a cost function CDet that combines the probabilities of missing a new story and a false alarm [19]: * * * *Det Miss Miss Target FA FA NontargetC C P P C P P= + (12) Table 2.",
                "Average correlation between term types and news classes where CMiss means the cost of missing a new story, PMiss means the probability of missing a new story, and PTarget means the probability of seeing a new story in the data; CFA means the cost of a false alarm, PFA means the probability of a false alarm, and PNontarget means the probability of seeing an old story.",
                "The cost CDet is normalized such that a perfect system scores 0 and a trivial system, which is the better one of mark all stories as new or old, scores 1: ( ( * , * ) ) Det Det Miss Target FA Nontarget C Norm C min C P C P = (13) New event detection system gives two outputs for each story.",
                "The first part is yes or no indicating whether the story triggers a new event or not.",
                "The second part is a score indicating confidence of the first decision.",
                "Confidence scores can be used to plot DET curve, i.e., curves that plot false alarm vs. miss probabilities.",
                "Minimum normalized cost can be determined if optimal threshold on the score were chosen. 7.",
                "EXPERIMENTAL RESULTS 7.1 Main Results To test the approaches proposed in the model, we implemented and tested five systems: System-1: this system is used as baseline.",
                "It is implemented based on the basic model described in section 3, i.e., using incremental TF-IDF model to generate term weights, and using Hellinger distance to compute document similarity.",
                "Similarity score normalization is also employed [8].",
                "S-S detection procedure is used.",
                "System-2: this system is the same as system-1 except that S-C detection procedure is used.",
                "System-3: this system is the same as system-1 except that it uses the new detection procedure which is based on indexing-tree.",
                "System-4: implemented based on the approach presented in section 5.1, i.e., terms are reweighted according to the distance between term distributions in a cluster and all stories.",
                "The new detection procedure is used.",
                "System-5: implemented based on the approach presented in section 5.2, i.e., terms of different types are reweighted according to news class using trained parameters.",
                "The new detection procedure is used.",
                "The following are some other NED systems: System-6: [21] for each pair of stories, it computes three similarity values for named entity, non-named entity and all terms respectively.",
                "And employ Support Vector Machine to predict new or old using the similarity values as features.",
                "System-7: [8] it extended a basic incremental TF-IDF model to include source-specific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, etc.",
                "System-8: [13] it split document representation into two parts: named entities and non-named entities, and choose one effective part for each news class.",
                "Table 3 and table 4 show topic-weighted normalized costs and comparing times on TDT2 and TDT3 datasets respectively.",
                "Since no heldout data set for fine-tuning the threshold θ new was available for experiments on TDT2, we only report minimum normalized costs for our systems in table 3.",
                "System-5 outperforms all other systems including system-6, and it performs only 2.78e+8 comparing times in detection procedure which is only 13.4% of system-1.",
                "Table 3.",
                "NED results on TDT2 Systems Min Norm(CDet) Cmp times System-1 0.5749 2.08e+9 System-2① 0.6673 3.77e+8 System-3② 0.5765 2.81e+8 System-4② 0.5431 2.99e+8 System-5② 0.5089 2.78e+8 System-6 0.5300 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 When evaluating on the normalized costs on TDT3, we use the optimal thresholds obtained from TDT2 data set for all systems.",
                "System-2 reduces comparing times to 1.29e+9 which is just 18.3% of system-1, but at the same time it also gets a deteriorated minimum normalized cost which is 0.0499 higher than system-1.",
                "System-3 uses the new detection procedure based on news indexing-tree.",
                "It requires even less comparing times than system-2.",
                "This is because story-story comparisons usually yield greater similarities than story-cluster ones, so stories tend to be combined Location Person Date Organization Money Percentage NN JJ CD Elections 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 Scandals/Hearings 0.66 0.62 0.28 1 0.11 0.02 0.27 0.13 0.05 Legal/Criminal Cases 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 Natural Disasters 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 Violence or War 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 Science and Discovery 0.11 1 0.01 0.22 0.08 0.12 0.19 0.08 0.03 Finances 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 Sports 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 together in system-3.",
                "And system-3 is basically equivalent to system-1 in accuracy results.",
                "System-4 adjusts term weights based on the distance of term distributions between the whole corpus and cluster story set, yielding a good improvement by 0.0468 compared to system-1.",
                "The best system (system-5) has a minimum normalized cost 0.5012, which is 0.0797 better than system-1, and also better than any other results previously reported for this dataset [8, 13].",
                "Further more, system-5 only needs 1.05e+8 comparing times which is 14.9% of system-1.",
                "Table 4.",
                "NED results on TDT3 Systems Norm(CDet) Min Norm(CDet) Cmp times System-1 0.6159 0.5809 7.04e+8 System-2① 0.6493 0.6308 1.29e+8 System-3② 0.6197 0.5868 1.03e+8 System-4② 0.5601 0.5341 1.03e+8 System-5② 0.5413 0.5012 1.05e+8 System-7 -- 0.5783 -System-8 -- 0.5229 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 Figure5 shows the five DET curves for our systems on data set TDT3.",
                "System-5 achieves the minimum cost at a false alarm rate of 0.0157 and a miss rate of 0.4310.",
                "We can observe that System4 and System-5 obtain lower miss probability at regions of low false alarm probabilities.",
                "The hypothesis is that, more weight value is transferred to key terms of topics from non-key terms.",
                "Similarity score between two stories belonging to different topics are lower than before, because their overlapping terms are usually not key terms of their topics. 7.2 Parameter selection for indexing-tree detection Figure 3 shows the minimum normalized costs obtained by system-3 on TDT3 using different parameters.",
                "Theθ init parameter is tested on six values spanning from 0.03 to 0.18.",
                "And the λ parameter is tested on four values 1, 2, 3 and 4.",
                "We can see that, whenθ init is set to 0.12, which is the closest one toθ new, the costs are lower than others.",
                "This is easy to explain, because when stories belonging to the same topic are put in a cluster, it is more reasonable for the cluster to represent the stories in it.",
                "When parameter λ is set to 3 or 4, the costs are better than other cases, but there is no much difference between 3 and 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ MinCost 0.6 0.65 0.7 0.75 0.8 0.85 0.9 Figure 3.",
                "Min Cost on TDT3 (δ =0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ Comparingtimes 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 Figure 4.",
                "Comparing times on TDT3 (δ =0.15) Figure 4 gives the comparing times used by system-3 on TDT3 with the same parameters as figure 3.",
                "The comparing times are strongly dependent onθ init.",
                "Because the greaterθ init is, the less stories combined together, the more comparing times are needed for new event decision.",
                "So we useθ init =0.13,λ =3,δ =0.15 for system-3, 4, and 5.",
                "In this parameter setting, we can get both low minimum normalized costs and less comparing times. 8.",
                "CONCLUSION We have proposed a news indexing-tree based detection procedure in our model.",
                "It reduces comparing times to about one seventh of traditional method without hurting <br>ned accuracy</br>.",
                "We also have presented two extensions to the basic TF-IDF model.",
                "The first extension is made by adjust term weights based on term distributions between the whole corpus and a cluster story set.",
                "And the second extension to basic TF-IDF model is better use of term types (named entities types and part-of-speed) according to news categories.",
                "Our experimental results on TDT2 and TDT3 datasets show that both of the two extensions contribute significantly to improvement in accuracy.",
                "We did not consider news time information as a clue for NED task, since most of the topics last for a long time and TDT data sets only span for a relative short period (no more than 6 months).",
                "For the future work, we want to collect news set which span for a longer period from internet, and integrate time information in NED task.",
                "Since topic is a relative coarse-grained news cluster, we also want to refine cluster granularity to event-level, and identify different events and their relations within a topic.",
                "Acknowledgments This work is supported by the National Natural Science Foundation of China under Grant No. 90604025.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] In Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. .01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90 1 2 5 10 20 40 60 80 90 False Alarm Probability (in %) MissProbability(in%) SYSTEM1 Topic Weighted Curve SYSTEM1 Min Norm(Cost) SYSTEM2 Topic Weighted Curve SYSTEM2 Min Norm(Cost) SYSTEM3 Topic Weighted Curve SYSTEM3 Min Norm(Cost) SYSTEM4 Topic Weighted Curve SYSTEM4 Min Norm(Cost) SYSTEM5 Topic Weighted Curve SYSTEM5 Min Norm(Cost) Random Performance Figure 5.",
                "DET curves on TDT3 [3] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B.T.",
                "Archibald, and X. Liu.",
                "Learning Approaches for Detecting and Tracking News Events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), 1999, 32-43. [4] Y. Yang, T. Pierce, and J. Carbonell.",
                "A Study on Retrospective and On-line Event Detection.",
                "In Proceedings of SIGIR-98, Melbourne, Australia, 1998, 28-36. [5] J. Allan, V. Lavrenko, D. Malin, and R. Swan.",
                "Detections, Bounds, and Timelines: Umass and tdt-3.",
                "In Proceedings of Topic Detection and Tracking Workshop (TDT-3), Vienna, VA, 2000, 167-174. [6] R. Papka and J. Allan.",
                "On-line New Event Detection Using Single Pass Clustering TITLE2:.",
                "Technical Report UM-CS1998-021, 1998. [7] W. Lam, H. Meng, K. Wong, and J.",
                "Yen.",
                "Using Contextual Analysis for News Event Detection.",
                "International Journal on Intelligent Systems, 2001, 525-546. [8] B. Thorsten, C. Francine, and F. Ayman.",
                "A System for New Event Detection.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2003, 330-337. [9] S. Nicola and C. Joe.",
                "Combining Semantic and Syntactic Document Classifiers to Improve First Story Detection.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2001, 424425. [10] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topicconditioned Novelty Detection.",
                "In Proceedings of the 8th ACM SIGKDD International Conference, ACM Press. 2002, 688-693. [11] M. Juha, A.M. Helena, and S. Marko.",
                "Applying Semantic Classes in Event Detection and Tracking.",
                "In Proceedings of International Conference on Natural Language Processing (ICON 2002), 2002, pages 175-183. [12] M. Juha, A.M. Helena, and S. Marko.",
                "Simple Semantics in Topic Detection and Tracking.",
                "Information Retrieval, 7(3-4): 2004, 347-368. [13] K. Giridhar and J. Allan.",
                "Text Classification and Named Entities for New Event Detection.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2004, 297-304. [14] J. P. Callan, W. B. Croft, and S. M. Harding.",
                "The INQUERY Retrieval System.",
                "In Proceedings of DEXA-92, 3rd International Conference on Database and Expert Systems Applications, 1992, 78-83. [15] R. Krovetz.",
                "Viewing Morphology as An Inference Process.",
                "In Proceedings of ACM SIGIR93, 1993, 61-81. [16] Y. Yang and J. Pedersen.",
                "A Comparative Study on Feature Selection in Text Categorization.",
                "In J. D. H. Fisher, editor, The Fourteenth International Conference on Machine Learning (ICML97), Morgan Kaufmann, 1997, 412-420. [17] T. M. Cover, and J.A.",
                "Thomas.",
                "Elements of Information Theory.",
                "Wiley. 1991. [18] The linguistic data consortium, http://www.ldc,upenn.edu/. [19] The 2001 TDT task definition and evaluation plan, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm. [20] R. E. Schapire and Y.",
                "Singer.",
                "Boostexter: A Boosting-based System for Text Categorization.",
                "In Machine Learning 39(2/3):1, Kluwer Academic Publishers, 2000, 35-168. [21] K. Giridhar and J. Allan. 2005.",
                "Using Names and Topics for New Event Detection.",
                "In Proceedings of Human Technology Conference and Conference on Empirical Methods in Natural Language, Vancouver, 2005, 121-128"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Además, en base a la observación de que los términos de diferentes tipos tienen diferentes efectos para la tarea NED, se proponen enfoques de re -peso de dos términos para mejorar la \"precisión de NED\".",
                "En la Sección 5, se proponen métodos de rewesavo de dos términos para mejorar la \"precisión de NED\".",
                "Métodos de reweaptheing de término En esta sección, se proponen métodos de rewesavo de dos términos para mejorar la \"precisión de NED\".",
                "Reduce los tiempos de comparación con aproximadamente un séptimo método tradicional sin dañar la \"precisión de NED\"."
            ],
            "translated_text": "",
            "candidates": [
                "precisión de NED",
                "precisión de NED",
                "precisión de NED",
                "precisión de NED",
                "precisión de NED",
                "precisión de NED",
                "precisión de NED",
                "precisión de NED"
            ],
            "error": []
        },
        "term weight": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "New Event Detection Based on Indexing-tree and Named Entity Zhang Kuo Tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn Li Juan Zi Tsinghua University Beijing, 100084, China 86-10-62781461 ljz@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn ABSTRACT New Event Detection (NED) aims at detecting from one or multiple streams of news stories that which one is reported on a new event (i.e.",
                "not reported previously).",
                "With the overwhelming volume of news available today, there is an increasing need for a NED system which is able to detect new events more efficiently and accurately.",
                "In this paper we propose a new NED model to speed up the NED task by using news indexing-tree dynamically.",
                "Moreover, based on the observation that terms of different types have different effects for NED task, two term reweighting approaches are proposed to improve NED accuracy.",
                "In the first approach, we propose to adjust term weights dynamically based on previous story clusters and in the second approach, we propose to employ statistics on training data to learn the named entity reweighting model for each class of stories.",
                "Experimental results on two Linguistic Data Consortium (LDC) datasets TDT2 and TDT3 show that the proposed model can improve both efficiency and accuracy of NED task significantly, compared to the baseline system and other existing systems.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Search and Retrieval; H.4.2 [Information Systems Applications]: Types of Systemsdecision support.",
                "General Terms Algorithms, Performance, Experimentation 1.",
                "INTRODUCTION Topic Detection and Tracking (TDT) program aims to develop techniques which can effectively organize, search and structure news text materials from a variety of newswire and broadcast media [1].",
                "New Event Detection (NED) is one of the five tasks in TDT.",
                "It is the task of online identification of the earliest report for each topic as soon as that report arrives in the sequence of documents.",
                "A Topic is defined as a seminal event or activity, along with directly related events and activities [2].",
                "An Event is defined as something (non-trivial) happening in a certain place at a certain time [3].",
                "For instance, when a bomb explodes in a building, the exploding is the seminal event that triggers the topic, and other stories on the same topic would be those discussing salvaging efforts, the search for perpetrators, arrests and trial and so on.",
                "Useful news information is usually buried in a mass of data generated everyday.",
                "Therefore, NED systems are very useful for people who need to detect novel information from real-time news stream.",
                "These real-life needs often occur in domains like financial markets, news analysis, and intelligence gathering.",
                "In most of state-of-the-art (currently) NED systems, each news story on hand is compared to all the previous received stories.",
                "If all the similarities between them do not exceed a threshold, then the story triggers a new event.",
                "They are usually in the form of cosine similarity or Hellinger similarity metric.",
                "The core problem of NED is to identify whether two stories are on the same topic.",
                "Obviously, these systems cannot take advantage of topic information.",
                "Further more, it is not acceptable in real applications because of the large amount of computation required in the NED process.",
                "Other systems organize previous stories into clusters (each cluster corresponds to a topic), and new story is compared to the previous clusters instead of stories.",
                "This manner can reduce comparing times significantly.",
                "Nevertheless, it has been proved that this manner is less accurate [4, 5].",
                "This is because sometimes stories within a topic drift far away from each other, which could lead low similarity between a story and its topic.",
                "On the other hand, some proposed NED systems tried to improve accuracy by making better use of named entities [10, 11, 12, 13].",
                "However, none of the systems have considered that terms of different types (e.g.",
                "Noun, Verb or Person name) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "For example, the names of election candidates (Person name) are very important for stories of election class; the locations (Location name) where accidents happened are important for stories of accidents class.",
                "So, in NED, there still exist following three problems to be investigated: (1) How to speed up the detection procedure while do not decrease the detection accuracy? (2) How to make good use of cluster (topic) information to improve accuracy? (3) How to obtain better news story representation by better understanding of named entities.",
                "Driven by these problems, we have proposed three approaches in this paper. (1)To make the detection procedure faster, we propose a new NED procedure based on news indexing-tree created dynamically.",
                "Story indexing-tree is created by assembling similar stories together to form news clusters in different hierarchies according to their values of similarity.",
                "Comparisons between current story and previous clusters could help find the most similar story in less comparing times.",
                "The new procedure can reduce the amount of comparing times without hurting accuracy. (2)We use the clusters of the first floor in the indexing-tree as news topics, in which term weights are adjusted dynamically according to term distribution in the clusters.",
                "In this approach, cluster (topic) information is used properly, so the problem of theme decentralization is avoided. (3)Based on observations on the statistics obtained from training data, we found that terms of different types (e.g.",
                "Noun and Verb) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "And we propose to use statistics to optimize the weights of the terms of different types in a story according to the news class that the story belongs to.",
                "On TDT3 dataset, the new NED model just uses 14.9% comparing times of the basic model, while its minimum normalized cost is 0.5012, which is 0.0797 better than the basic model, and also better than any other results previously reported for this dataset [8, 13].",
                "The rest of the paper is organized as follows.",
                "We start off this paper by summarizing the previous work in NED in section 2.",
                "Section 3 presents the basic model for NED that most current systems use.",
                "Section 4 describes our new detection procedure based on news indexing-tree.",
                "In section 5, two term reweighting methods are proposed to improve NED accuracy.",
                "Section 6 gives our experimental data and evaluation metrics.",
                "We finally wrap up with the experimental results in Section 7, and the conclusions and future work in Section 8. 2.",
                "RELATED WORK Papka et al. proposed Single-Pass clustering on NED [6].",
                "When a new story was encountered, it was processed immediately to extract term features and a query representation of the storys content is built up.",
                "Then it was compared with all the previous queries.",
                "If the document did not trigger any queries by exceeding a threshold, it was marked as a new event.",
                "Lam et al build up previous query representations of story clusters, each of which corresponds to a topic [7].",
                "In this manner comparisons happen between stories and clusters.",
                "Recent years, most work focus on proposing better methods on comparison of stories and document representation.",
                "Brants et al. [8] extended a basic incremental TF-IDF model to include sourcespecific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, term reweighting based on inverse event frequencies, and segmentation of documents.",
                "Good improvements on TDT bench-marks were shown.",
                "Stokes et al. [9] utilized a combination of evidence from two distinct representations of a documents content.",
                "One of the representations was the usual free text vector, the other made use of lexical chains (created using WordNet) to build another term vector.",
                "Then the two representations are combined in a linear fashion.",
                "A marginal increase in effectiveness was achieved when the combined representation was used.",
                "Some efforts have been done on how to utilize named entities to improve NED.",
                "Yang et al. gave location named entities four times weight than other terms and named entities [10].",
                "DOREMI research group combined semantic similarities of person names, location names and time together with textual similarity [11][12].",
                "UMass [13] research group split document representation into two parts: named entities and non-named entities.",
                "And it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation.",
                "Both [10] and [13] used text categorization technique to classify news stories in advance.",
                "In [13] news stories are classified automatically at first, and then test sensitivities of names and non-name terms for NED for each class.",
                "In [10] frequent terms for each class are removed from document representation.",
                "For example, word election does not help identify different elections.",
                "In their work, effectiveness of different kinds of names (or terms with different POS) for NED in different news classes are not investigated.",
                "We use statistical analysis to reveal the fact and use it to improve NED performance. 3.",
                "BASIC MODEL In this section, we present the basic New Event Detection model which is similar to what most current systems apply.",
                "Then, we propose our new model by extending the basic model.",
                "New Event Detection systems use news story stream as input, in which stories are strictly time-ordered.",
                "Only previously received stories are available when dealing with current story.",
                "The output is a decision for whether the current story is on a new event or not and the confidence of the decision.",
                "Usually, a NED model consists of three parts: story representation, similarity calculation and detection procedure. 3.1 Story Representation Preprocessing is needed before generating story representation.",
                "For preprocessing, we tokenize words, recognize abbreviations, normalize abbreviations, add part-of-speech tags, remove stopwords included in the stop list used in InQuery [14], replace words with their stems using K-stem algorithm[15], and then generate word vector for each news story.",
                "We use incremental TF-IDF model for <br>term weight</br> calculation [4].",
                "In a TF-IDF model, term frequency in a news document is weighted by the inverse document frequency, which is generated from training corpus.",
                "When a new term occurs in testing process, there are two solutions: simply ignore the new term or set df of the term as a small const (e.g. df = 1).",
                "The new term receives too low weight in the first solution (0) and too high weight in the second solution.",
                "In incremental TF-IDF model, document frequencies are updated dynamically in each time step t: 1( ) ( ) ( )t t D tdf w df w df w−= + (1) where Dt represents news story set received in time t, and dfDt(w) means the number of documents that term w occurs in, and dft(w) means the total number of documents that term w occurs in before time t. In this work, each time window includes 50 news stories.",
                "Thus, each story d received in t is represented as follows: 1 2{ ( , , ), ( , , ),..., ( , , )}nd weight d t w weight d t w weight d t w→ where n means the number of distinct terms in story d, and ( , , )weight d t w means the weight of term w in story d at time t: log( ( , ) 1) log(( 1) /( ( ) 0.5)) ( , , ) log( ( , ) 1) log(( 1) /( ( ) 0.5)) t t t t w d tf d w N df w weight d t w tf d w N df w ∈ + + + = + + +∑ (2) where Nt means the total number of news stories before time t, and tf(d,w) means how many times term w occurs in news story d. 3.2 Similarity Calculation We use Hellinger distance for the calculation of similarity between two stories, for two stories d and d at time t, their similarity is defined as follows: , ( , , ) ( , , ) * ( , , ) w d d sim d d t weight d t w weight d t w ∈ = ∑ (3) 3.3 Detection Procedure For each story d received in time step t, the value ( ) ( ) ( ) ( ( , , )) time d time d n d max sim d d t < = (4) is a score used to determine whether d is a story about a new topic and at the same time is an indication of the confidence in our decision [8]. time(d) means the publication time of story d. If the score exceeds the thresholdθ new, then there exists a sufficiently similar document, thus d is a old story, otherwise, there is no sufficiently similar previous document, thus d is an new story. 4.",
                "New NED Procedure Traditional NED systems can be classified into two main types on the aspect of detection procedure: (1) S-S type, in which the story on hand is compared to each story received previously, and use the highest similarity to determine whether current story is about a new event; (2) S-C type, in which the story on hand is compared to all previous clusters each of which representing a topic, and the highest similarity is used for final decision for current story.",
                "If the highest similarity exceeds thresholdθ new, then it is an old story, and put it into the most similar cluster; otherwise it is a new story and create a new cluster.",
                "Previous work show that the first manner is more accurate than the second one [4][5].",
                "Since sometimes stories within a topic drift far away from each other, a story may have very low similarity with its topic.",
                "So using similarities between stories for determining new story is better than using similarities between story and clusters.",
                "Nevertheless, the first manner needs much more comparing times which means the first manner is low efficient.",
                "We propose a new detection procedure which uses comparisons with previous clusters to help find the most similar story in less comparing times, and the final new event decision is made according to the most similar story.",
                "Therefore, we can get both the accuracy of S-S type methods and the efficiency of S-C type methods.",
                "The new procedure creates a news indexing-tree dynamically, in which similar stories are put together to form a hierarchy of clusters.",
                "We index similar stories together by their common ancestor (a cluster node).",
                "Dissimilar stories are indexed in different clusters.",
                "When a story is coming, we use comparisons between the current story and previous hierarchical clusters to help find the most similar story which is useful for new event decision.",
                "After the new event decision is made, the current story is inserted to the indexing-tree for the following detection.",
                "The news indexing-tree is defined formally as follows: S-Tree = {r, NC , NS , E} where r is the root of S-Tree, NC is the set of all cluster nodes, NS is the set of all story nodes, and E is the set of all edges in S-Tree.",
                "We define a set of constraints for a S-Tree: ⅰ . , is an non-terminal node in the treeC i i N i∀ ∈ → ⅱ . , is a terminal node in the treeS i i N i∀ ∈ → ⅲ . , out degree of is at least 2C i i N i∀ ∈ → ⅳ . , is represented as the centroid of its desendantsC i i iN∀ ∈ → For a news story di, the comparison procedure and inserting procedure based on indexing-tree are defined as follows.",
                "An example is shown by Figure 1 and Figure 2.",
                "Figure 1.",
                "Comparison procedure Figure 2.",
                "Inserting procedure Comparison procedure: Step 1: compare di to all the direct child nodes of r and select λ nodes with highest similarities, e.g., C1 2 and C1 3 in Figure 1.",
                "Step 2: for each selected node in the last step, e.g.",
                "C1 2, compare di to all its direct child nodes, and select λ nodes with highest similarities, e.g.",
                "C2 2 and d8.",
                "Repeat step 2 for all non-terminal nodes.",
                "Step 3: record the terminal node with the highest similarty to di, e.g. s5, and the similarity value (0.20).",
                "Inserting di to the S-tree with r as root: Find the node n which is direct child of r in the path from r to the terminal node with highest similarity s, e.g.",
                "C1 2.",
                "If s is smaller than θ init+(h-1)δ , then add di to the tree as a direct child of r. Otherwise, if n is a terminal node, then create a cluster node instead of n, and add both n and di as its direct children; if n is an non-terminal node, then repeat this procedure and insert di to the sub-tree with n as root recursively.",
                "Here h is the length between n and the root of S-tree.",
                "The more the stories in a cluster similar to each other, the better the cluster represents the stories in it.",
                "Hence we add no constraints on the maximum of trees height and degree of a node.",
                "Therefore, we cannot give the complexity of this indexing-tree based procedure.",
                "But we will give the number of comparing times needed by the new procedure in our experiments in section7. 5.",
                "Term Reweighting Methods In this section, two term reweighting methods are proposed to improve NED accuracy.",
                "In the first method, a new way is explored for better using of cluster (topic) information.",
                "The second one finds a better way to make use of named entities based on news classification. 5.1 Term Reweighting Based on Distribution Distance TF-IDF is the most prevalent model used in information retrieval systems.",
                "The basic idea is that the fewer documents a term appears in, the more important the term is in discrimination of documents (relevant or not relevant to a query containing the term).",
                "Nevertheless, in TDT domain, we need to discriminate documents with regard to topics rather than queries.",
                "Intuitively, using cluster (topic) vectors to compare with subsequent news stories should outperform using story vectors.",
                "Unfortunately, the experimental results do not support this intuition [4][5].",
                "Based on observation on data, we find the reason is that a news topic usually contains many directly or indirectly related events, while they all have their own sub-subjects which are usually different with each other.",
                "Take the topic described in section 1 as an example, events like the explosion and salvage have very low similarities with events about criminal trial, therefore stories about trial would have low similarity with the topic vector built on its previous events.",
                "This section focuses on how to effectively make use of topic information and at the same time avoid the problem of content decentralization.",
                "At first, we classify terms into 5 classes to help analysis the needs of the modified model: Term class A: terms that occur frequently in the whole corpus, e.g., year and people.",
                "Terms of this class should be given low weights because they do not help much for topic discrimination.",
                "Term class B: terms that occur frequently within a news category, e.g., election, storm.",
                "They are useful to distinguish two stories in different news categories.",
                "However, they cannot provide information to determine whether two stories are on the same or different topics.",
                "In another words, term election and term storm are not helpful in differentiate two election campaigns and two storm disasters.",
                "Therefore, terms of this class should be assigned lower weights.",
                "Term class C: terms that occur frequently in a topic, and infrequently in other topics, e.g., the name of a crash plane, the name of a specific hurricane.",
                "News stories that belong to different topics rarely have overlap terms in this class.",
                "The more frequently a term appears in a topic, the more important the term is for a story belonging to the topic, therefore the term should be set higher weight.",
                "Term class D: terms that appear in a topic exclusively, but not frequently.",
                "For example, the name of a fireman who did very well in a salvage action, which may appears in only two or three stories but never appeared in other topics.",
                "Terms of this type should receive more weights than in TF-IDF model.",
                "However, since they are not popular in the topic, it is not appropriate to give them too high weights.",
                "Term class E: terms with low document frequency, and appear in different topics.",
                "Terms of this class should receive lower weights.",
                "Now we analyze whether TF-IDF model can give proper weights to the five classes of terms.",
                "Obviously, terms of class A are lowly weighted in TF-IDF model, which is conformable with the requirement described above.",
                "In TF-IDF model, terms of class B are highly dependant with the number of stories in a news class.",
                "TF-IDF model cannot provide low weights if the story containing the term belongs to a relative small news class.",
                "For a term of class C, the more frequently it appears in a topic, the less weight TFIDF model gives to it.",
                "This strongly conflicts with the requirement of terms in class C. For terms of class D, TF-IDF model gives them high weights correctly.",
                "But for terms of class E, TF-IDF model gives high weights to them which are not conformable with the requirement of low weights.",
                "To sum up, terms of class B, C, E cannot be properly weighted in TF-IDF model.",
                "So, we propose a modified model to resolve this problem.",
                "When θ init andθ new are set closely, we assume that most of the stories in a first-level cluster (a direct child node of root node) are on the same topic.",
                "Therefore, we make use of a first-level cluster to capture term distribution (df for all the terms within the cluster) within the topic dynamically.",
                "KL divergence of term distribution in a first-level cluster and the whole story set is used to adjust term weights:  ( , , ) * (1 * ( || )) ( , , ) ( , , ) * (1 * ( || )) cw tw cw tw w d D weight d t w KL P P weight d t w weight d t w KL P P γ γ ∈ + = +∑ (5) where ( ) ( ) ( ) ( ) 1,cw cw c c c c df w df w p y p y N N = = − (6) ( ) ( ) ( ) ( ) 1,t t tw tw t t df w df w p y p y N N = = − (7) where dfc(w) is the number of documents containing term w within cluster C, and Nc is the number of documents in cluster C, and Nt is the total number of documents that arrive before time step t. γ is a const parameter, now is manually set 3.",
                "KL divergence is defined as follows [17]: ( ) ( || ) ( ) log ( )x p x KL P Q p x q x = ∑ (8) The basic idea is: for a story in a topic, the more a term occurs within the topic, and the less it occurs in other topics, it should be assigned higher weights.",
                "Obviously, modified model can meet all the requirements of the five term classes listed above. 5.2 Term Reweighting Based on Term Type and Story Class Previous work found that some classes of news stories could achieve good improvements by giving extra weight to named entities.",
                "But we find that terms of different types should be given different amount of extra weight for different classes of news stories.",
                "We use open-NLP1 to recognize named entity types and part-ofspeech tags for terms that appear in news stories.",
                "Named entity types include person name, organization name, location name, date, time, money and percentage, and five POSs are selected: none (NN), verb (VB), adjective (JJ), adverb (RB) and cardinal number (CD).",
                "Statistical analysis shows topic-level discriminative terms types for different classes of stories.",
                "For the sake of convenience, named entity type and part-of-speech tags are uniformly called term type in subsequent sections.",
                "Determining whether two stories are about the same topic is a basic component for NED task.",
                "So at first we use 2 χ statistic to compute correlations between terms and topics.",
                "For a term t and a topic T, a contingence table is derived: Table 1.",
                "A 2×2 Contingence Table Doc Number belong to topic T not belong to topic T include t A B not include t C D The 2 χ statistic for a specific term t with respect to topic T is defined to be [16]: 2 2 ( , ) ( ) * ( ) ( ) * ( ) * ( ) * ( ) w T A B C D AD CB A C B D A B C D χ = + + + − + + + + (9) News topics for the TDT task are further classified into 11 rules of interpretations (ROIs) 2 .",
                "The ROI can be seen as a higher level class of stories.",
                "The average correlation between a term type and a topic ROI is computed as: 2 avg 2 ( , )( ( , ) )k m m km kT R w P w TP R p w T R P χ χ ∈ ∈ ∑ ∑（ , ）= 1 1 k=1…K, m=1…M (10) where K is the number of term types (set 12 constantly in the paper).",
                "M is the number news classes (ROIs, set 11 in the paper).",
                "Pk represents the set of all terms of type k, and Rm represents the set of all topics of class m, p(t,T) means the probability that t occurs in topic T. Because of limitation of space, only parts of the term types (9 term types) and parts of news classes (8 classes) are listed in table 2 with the average correlation values between them.",
                "The statistics is derived from labeled data in TDT2 corpus. (Results in table 2 are already normalized for convenience in comparison.)",
                "The statistics in table 2 indicates the usefulness of different term types in topic discrimination with respect to different news classes.",
                "We can see that, location name is the most useful term type for three news classes: Natural Disasters, Violence or War, Finances.",
                "And for three other categories Elections, Legal/Criminal Cases, Science and Discovery, person name is the most discriminative term type.",
                "For Scandals/Hearings, date is the most important information for topic discrimination.",
                "In addition, Legal/Criminal Cases and Finance topics have higher correlation with money terms, while Science and Discovery have higher correlation with percentage terms.",
                "Non-name terms are more stable for different classes. 1 . http://opennlp.sourceforge.net/ 2 . http://projects.ldc.upenn.edu/TDT3/Guide/label.html From the analysis of table 2, it is reasonable to adjust <br>term weight</br> according to their term type and the news class the story belongs to.",
                "New term weights are reweighted as follows: ( ) ( ) ( ) ( ) ( , , ) * ( , , ) ( , , ) * class d D type w T class d D type w w d weight d t w weight d t w weight d t w α α ∈ = ∑ (11) where type(w) represents the type of term w, and class(d) represents the class of story d, c kα is reweighting parameter for news class c and term type k. In the work, we just simply use statistics in table 2 as the reweighting parameters.",
                "Even thought using the statistics directly may not the best choice, we do not discuss how to automatically obtain the best parameters.",
                "We will try to use machine learning techniques to obtain the best parameters in the future work.",
                "In the work, we use BoosTexter [20] to classify all stories into one of the 11 ROIs.",
                "BoosTexter is a boosting based machine learning program, which creates a series of simple rules for building a classifier for text or attribute-value data.",
                "We use <br>term weight</br> generated using TF-IDF model as feature for story classification.",
                "We trained the model on the 12000 judged English stories in TDT2, and classify the rest of the stories in TDT2 and all stories in TDT3.",
                "Classification results are used for term reweighting in formula (11).",
                "Since the class labels of topic-off stories are not given in TDT datasets, we cannot give the classification accuracy here.",
                "Thus we do not discuss the effects of classification accuracy to NED performance in the paper. 6.",
                "EXPERIMENTAL SETUP 6.1 Datasets We used two LDC [18] datasets TDT2 and TDT3 for our experiments.",
                "TDT2 contains news stories from January to June 1998.",
                "It contains around 54,000 stories from sources like ABC, Associated Press, CNN, New York Times, Public Radio International, Voice of America etc.",
                "Only English stories in the collection were considered.",
                "TDT3 contains approximately 31,000 English stories collected from October to December 1998.",
                "In addition to the sources used in TDT2, it also contains stories from NBC and MSNBC TV broadcasts.",
                "We used transcribed versions of the TV and radio broadcasts besides textual news.",
                "TDT2 dataset is labeled with about 100 topics, and approximately 12,000 English stories belong to at least one of these topics.",
                "TDT3 dataset is labeled with about 120 topics, and approximately 8000 English stories belong to at least one of these topics.",
                "All the topics are classified into 11 Rules of Interpretation: (1)Elections, (2)Scandals/Hearings, (3)Legal/Criminal Cases, (4)Natural Disasters, (5)Accidents, (6)Ongoing Violence or War, (7)Science and Discovery News, (8)Finance, (9)New Law, (10)Sports News, (11)MISC.",
                "News. 6.2 Evaluation Metric TDT uses a cost function CDet that combines the probabilities of missing a new story and a false alarm [19]: * * * *Det Miss Miss Target FA FA NontargetC C P P C P P= + (12) Table 2.",
                "Average correlation between term types and news classes where CMiss means the cost of missing a new story, PMiss means the probability of missing a new story, and PTarget means the probability of seeing a new story in the data; CFA means the cost of a false alarm, PFA means the probability of a false alarm, and PNontarget means the probability of seeing an old story.",
                "The cost CDet is normalized such that a perfect system scores 0 and a trivial system, which is the better one of mark all stories as new or old, scores 1: ( ( * , * ) ) Det Det Miss Target FA Nontarget C Norm C min C P C P = (13) New event detection system gives two outputs for each story.",
                "The first part is yes or no indicating whether the story triggers a new event or not.",
                "The second part is a score indicating confidence of the first decision.",
                "Confidence scores can be used to plot DET curve, i.e., curves that plot false alarm vs. miss probabilities.",
                "Minimum normalized cost can be determined if optimal threshold on the score were chosen. 7.",
                "EXPERIMENTAL RESULTS 7.1 Main Results To test the approaches proposed in the model, we implemented and tested five systems: System-1: this system is used as baseline.",
                "It is implemented based on the basic model described in section 3, i.e., using incremental TF-IDF model to generate term weights, and using Hellinger distance to compute document similarity.",
                "Similarity score normalization is also employed [8].",
                "S-S detection procedure is used.",
                "System-2: this system is the same as system-1 except that S-C detection procedure is used.",
                "System-3: this system is the same as system-1 except that it uses the new detection procedure which is based on indexing-tree.",
                "System-4: implemented based on the approach presented in section 5.1, i.e., terms are reweighted according to the distance between term distributions in a cluster and all stories.",
                "The new detection procedure is used.",
                "System-5: implemented based on the approach presented in section 5.2, i.e., terms of different types are reweighted according to news class using trained parameters.",
                "The new detection procedure is used.",
                "The following are some other NED systems: System-6: [21] for each pair of stories, it computes three similarity values for named entity, non-named entity and all terms respectively.",
                "And employ Support Vector Machine to predict new or old using the similarity values as features.",
                "System-7: [8] it extended a basic incremental TF-IDF model to include source-specific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, etc.",
                "System-8: [13] it split document representation into two parts: named entities and non-named entities, and choose one effective part for each news class.",
                "Table 3 and table 4 show topic-weighted normalized costs and comparing times on TDT2 and TDT3 datasets respectively.",
                "Since no heldout data set for fine-tuning the threshold θ new was available for experiments on TDT2, we only report minimum normalized costs for our systems in table 3.",
                "System-5 outperforms all other systems including system-6, and it performs only 2.78e+8 comparing times in detection procedure which is only 13.4% of system-1.",
                "Table 3.",
                "NED results on TDT2 Systems Min Norm(CDet) Cmp times System-1 0.5749 2.08e+9 System-2① 0.6673 3.77e+8 System-3② 0.5765 2.81e+8 System-4② 0.5431 2.99e+8 System-5② 0.5089 2.78e+8 System-6 0.5300 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 When evaluating on the normalized costs on TDT3, we use the optimal thresholds obtained from TDT2 data set for all systems.",
                "System-2 reduces comparing times to 1.29e+9 which is just 18.3% of system-1, but at the same time it also gets a deteriorated minimum normalized cost which is 0.0499 higher than system-1.",
                "System-3 uses the new detection procedure based on news indexing-tree.",
                "It requires even less comparing times than system-2.",
                "This is because story-story comparisons usually yield greater similarities than story-cluster ones, so stories tend to be combined Location Person Date Organization Money Percentage NN JJ CD Elections 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 Scandals/Hearings 0.66 0.62 0.28 1 0.11 0.02 0.27 0.13 0.05 Legal/Criminal Cases 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 Natural Disasters 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 Violence or War 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 Science and Discovery 0.11 1 0.01 0.22 0.08 0.12 0.19 0.08 0.03 Finances 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 Sports 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 together in system-3.",
                "And system-3 is basically equivalent to system-1 in accuracy results.",
                "System-4 adjusts term weights based on the distance of term distributions between the whole corpus and cluster story set, yielding a good improvement by 0.0468 compared to system-1.",
                "The best system (system-5) has a minimum normalized cost 0.5012, which is 0.0797 better than system-1, and also better than any other results previously reported for this dataset [8, 13].",
                "Further more, system-5 only needs 1.05e+8 comparing times which is 14.9% of system-1.",
                "Table 4.",
                "NED results on TDT3 Systems Norm(CDet) Min Norm(CDet) Cmp times System-1 0.6159 0.5809 7.04e+8 System-2① 0.6493 0.6308 1.29e+8 System-3② 0.6197 0.5868 1.03e+8 System-4② 0.5601 0.5341 1.03e+8 System-5② 0.5413 0.5012 1.05e+8 System-7 -- 0.5783 -System-8 -- 0.5229 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 Figure5 shows the five DET curves for our systems on data set TDT3.",
                "System-5 achieves the minimum cost at a false alarm rate of 0.0157 and a miss rate of 0.4310.",
                "We can observe that System4 and System-5 obtain lower miss probability at regions of low false alarm probabilities.",
                "The hypothesis is that, more weight value is transferred to key terms of topics from non-key terms.",
                "Similarity score between two stories belonging to different topics are lower than before, because their overlapping terms are usually not key terms of their topics. 7.2 Parameter selection for indexing-tree detection Figure 3 shows the minimum normalized costs obtained by system-3 on TDT3 using different parameters.",
                "Theθ init parameter is tested on six values spanning from 0.03 to 0.18.",
                "And the λ parameter is tested on four values 1, 2, 3 and 4.",
                "We can see that, whenθ init is set to 0.12, which is the closest one toθ new, the costs are lower than others.",
                "This is easy to explain, because when stories belonging to the same topic are put in a cluster, it is more reasonable for the cluster to represent the stories in it.",
                "When parameter λ is set to 3 or 4, the costs are better than other cases, but there is no much difference between 3 and 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ MinCost 0.6 0.65 0.7 0.75 0.8 0.85 0.9 Figure 3.",
                "Min Cost on TDT3 (δ =0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ Comparingtimes 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 Figure 4.",
                "Comparing times on TDT3 (δ =0.15) Figure 4 gives the comparing times used by system-3 on TDT3 with the same parameters as figure 3.",
                "The comparing times are strongly dependent onθ init.",
                "Because the greaterθ init is, the less stories combined together, the more comparing times are needed for new event decision.",
                "So we useθ init =0.13,λ =3,δ =0.15 for system-3, 4, and 5.",
                "In this parameter setting, we can get both low minimum normalized costs and less comparing times. 8.",
                "CONCLUSION We have proposed a news indexing-tree based detection procedure in our model.",
                "It reduces comparing times to about one seventh of traditional method without hurting NED accuracy.",
                "We also have presented two extensions to the basic TF-IDF model.",
                "The first extension is made by adjust term weights based on term distributions between the whole corpus and a cluster story set.",
                "And the second extension to basic TF-IDF model is better use of term types (named entities types and part-of-speed) according to news categories.",
                "Our experimental results on TDT2 and TDT3 datasets show that both of the two extensions contribute significantly to improvement in accuracy.",
                "We did not consider news time information as a clue for NED task, since most of the topics last for a long time and TDT data sets only span for a relative short period (no more than 6 months).",
                "For the future work, we want to collect news set which span for a longer period from internet, and integrate time information in NED task.",
                "Since topic is a relative coarse-grained news cluster, we also want to refine cluster granularity to event-level, and identify different events and their relations within a topic.",
                "Acknowledgments This work is supported by the National Natural Science Foundation of China under Grant No. 90604025.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] In Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. .01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90 1 2 5 10 20 40 60 80 90 False Alarm Probability (in %) MissProbability(in%) SYSTEM1 Topic Weighted Curve SYSTEM1 Min Norm(Cost) SYSTEM2 Topic Weighted Curve SYSTEM2 Min Norm(Cost) SYSTEM3 Topic Weighted Curve SYSTEM3 Min Norm(Cost) SYSTEM4 Topic Weighted Curve SYSTEM4 Min Norm(Cost) SYSTEM5 Topic Weighted Curve SYSTEM5 Min Norm(Cost) Random Performance Figure 5.",
                "DET curves on TDT3 [3] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B.T.",
                "Archibald, and X. Liu.",
                "Learning Approaches for Detecting and Tracking News Events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), 1999, 32-43. [4] Y. Yang, T. Pierce, and J. Carbonell.",
                "A Study on Retrospective and On-line Event Detection.",
                "In Proceedings of SIGIR-98, Melbourne, Australia, 1998, 28-36. [5] J. Allan, V. Lavrenko, D. Malin, and R. Swan.",
                "Detections, Bounds, and Timelines: Umass and tdt-3.",
                "In Proceedings of Topic Detection and Tracking Workshop (TDT-3), Vienna, VA, 2000, 167-174. [6] R. Papka and J. Allan.",
                "On-line New Event Detection Using Single Pass Clustering TITLE2:.",
                "Technical Report UM-CS1998-021, 1998. [7] W. Lam, H. Meng, K. Wong, and J.",
                "Yen.",
                "Using Contextual Analysis for News Event Detection.",
                "International Journal on Intelligent Systems, 2001, 525-546. [8] B. Thorsten, C. Francine, and F. Ayman.",
                "A System for New Event Detection.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2003, 330-337. [9] S. Nicola and C. Joe.",
                "Combining Semantic and Syntactic Document Classifiers to Improve First Story Detection.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2001, 424425. [10] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topicconditioned Novelty Detection.",
                "In Proceedings of the 8th ACM SIGKDD International Conference, ACM Press. 2002, 688-693. [11] M. Juha, A.M. Helena, and S. Marko.",
                "Applying Semantic Classes in Event Detection and Tracking.",
                "In Proceedings of International Conference on Natural Language Processing (ICON 2002), 2002, pages 175-183. [12] M. Juha, A.M. Helena, and S. Marko.",
                "Simple Semantics in Topic Detection and Tracking.",
                "Information Retrieval, 7(3-4): 2004, 347-368. [13] K. Giridhar and J. Allan.",
                "Text Classification and Named Entities for New Event Detection.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2004, 297-304. [14] J. P. Callan, W. B. Croft, and S. M. Harding.",
                "The INQUERY Retrieval System.",
                "In Proceedings of DEXA-92, 3rd International Conference on Database and Expert Systems Applications, 1992, 78-83. [15] R. Krovetz.",
                "Viewing Morphology as An Inference Process.",
                "In Proceedings of ACM SIGIR93, 1993, 61-81. [16] Y. Yang and J. Pedersen.",
                "A Comparative Study on Feature Selection in Text Categorization.",
                "In J. D. H. Fisher, editor, The Fourteenth International Conference on Machine Learning (ICML97), Morgan Kaufmann, 1997, 412-420. [17] T. M. Cover, and J.A.",
                "Thomas.",
                "Elements of Information Theory.",
                "Wiley. 1991. [18] The linguistic data consortium, http://www.ldc,upenn.edu/. [19] The 2001 TDT task definition and evaluation plan, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm. [20] R. E. Schapire and Y.",
                "Singer.",
                "Boostexter: A Boosting-based System for Text Categorization.",
                "In Machine Learning 39(2/3):1, Kluwer Academic Publishers, 2000, 35-168. [21] K. Giridhar and J. Allan. 2005.",
                "Using Names and Topics for New Event Detection.",
                "In Proceedings of Human Technology Conference and Conference on Empirical Methods in Natural Language, Vancouver, 2005, 121-128"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Utilizamos el modelo TF-IDF incremental para el cálculo de \"peso a término\" [4].",
                "Los términos no nombrados son más estables para diferentes clases.1.http://opennlp.sourceforge.net/ 2.http://projects.ldc.upenn.edu/tdt3/guide/label.html Del análisis de la Tabla 2, es razonable ajustar el \"peso de término\" de acuerdo con su tipo de término y la clase de noticias a la que pertenece la historia.",
                "Utilizamos el \"peso de término\" generado utilizando el modelo TF-IDF como característica para la clasificación de la historia."
            ],
            "translated_text": "",
            "candidates": [
                "peso de peso",
                "peso a término",
                "peso de peso",
                "peso de término",
                "peso de peso",
                "peso de término"
            ],
            "error": []
        },
        "statistics": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "New Event Detection Based on Indexing-tree and Named Entity Zhang Kuo Tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn Li Juan Zi Tsinghua University Beijing, 100084, China 86-10-62781461 ljz@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn ABSTRACT New Event Detection (NED) aims at detecting from one or multiple streams of news stories that which one is reported on a new event (i.e.",
                "not reported previously).",
                "With the overwhelming volume of news available today, there is an increasing need for a NED system which is able to detect new events more efficiently and accurately.",
                "In this paper we propose a new NED model to speed up the NED task by using news indexing-tree dynamically.",
                "Moreover, based on the observation that terms of different types have different effects for NED task, two term reweighting approaches are proposed to improve NED accuracy.",
                "In the first approach, we propose to adjust term weights dynamically based on previous story clusters and in the second approach, we propose to employ <br>statistics</br> on training data to learn the named entity reweighting model for each class of stories.",
                "Experimental results on two Linguistic Data Consortium (LDC) datasets TDT2 and TDT3 show that the proposed model can improve both efficiency and accuracy of NED task significantly, compared to the baseline system and other existing systems.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Search and Retrieval; H.4.2 [Information Systems Applications]: Types of Systemsdecision support.",
                "General Terms Algorithms, Performance, Experimentation 1.",
                "INTRODUCTION Topic Detection and Tracking (TDT) program aims to develop techniques which can effectively organize, search and structure news text materials from a variety of newswire and broadcast media [1].",
                "New Event Detection (NED) is one of the five tasks in TDT.",
                "It is the task of online identification of the earliest report for each topic as soon as that report arrives in the sequence of documents.",
                "A Topic is defined as a seminal event or activity, along with directly related events and activities [2].",
                "An Event is defined as something (non-trivial) happening in a certain place at a certain time [3].",
                "For instance, when a bomb explodes in a building, the exploding is the seminal event that triggers the topic, and other stories on the same topic would be those discussing salvaging efforts, the search for perpetrators, arrests and trial and so on.",
                "Useful news information is usually buried in a mass of data generated everyday.",
                "Therefore, NED systems are very useful for people who need to detect novel information from real-time news stream.",
                "These real-life needs often occur in domains like financial markets, news analysis, and intelligence gathering.",
                "In most of state-of-the-art (currently) NED systems, each news story on hand is compared to all the previous received stories.",
                "If all the similarities between them do not exceed a threshold, then the story triggers a new event.",
                "They are usually in the form of cosine similarity or Hellinger similarity metric.",
                "The core problem of NED is to identify whether two stories are on the same topic.",
                "Obviously, these systems cannot take advantage of topic information.",
                "Further more, it is not acceptable in real applications because of the large amount of computation required in the NED process.",
                "Other systems organize previous stories into clusters (each cluster corresponds to a topic), and new story is compared to the previous clusters instead of stories.",
                "This manner can reduce comparing times significantly.",
                "Nevertheless, it has been proved that this manner is less accurate [4, 5].",
                "This is because sometimes stories within a topic drift far away from each other, which could lead low similarity between a story and its topic.",
                "On the other hand, some proposed NED systems tried to improve accuracy by making better use of named entities [10, 11, 12, 13].",
                "However, none of the systems have considered that terms of different types (e.g.",
                "Noun, Verb or Person name) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "For example, the names of election candidates (Person name) are very important for stories of election class; the locations (Location name) where accidents happened are important for stories of accidents class.",
                "So, in NED, there still exist following three problems to be investigated: (1) How to speed up the detection procedure while do not decrease the detection accuracy? (2) How to make good use of cluster (topic) information to improve accuracy? (3) How to obtain better news story representation by better understanding of named entities.",
                "Driven by these problems, we have proposed three approaches in this paper. (1)To make the detection procedure faster, we propose a new NED procedure based on news indexing-tree created dynamically.",
                "Story indexing-tree is created by assembling similar stories together to form news clusters in different hierarchies according to their values of similarity.",
                "Comparisons between current story and previous clusters could help find the most similar story in less comparing times.",
                "The new procedure can reduce the amount of comparing times without hurting accuracy. (2)We use the clusters of the first floor in the indexing-tree as news topics, in which term weights are adjusted dynamically according to term distribution in the clusters.",
                "In this approach, cluster (topic) information is used properly, so the problem of theme decentralization is avoided. (3)Based on observations on the <br>statistics</br> obtained from training data, we found that terms of different types (e.g.",
                "Noun and Verb) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "And we propose to use <br>statistics</br> to optimize the weights of the terms of different types in a story according to the news class that the story belongs to.",
                "On TDT3 dataset, the new NED model just uses 14.9% comparing times of the basic model, while its minimum normalized cost is 0.5012, which is 0.0797 better than the basic model, and also better than any other results previously reported for this dataset [8, 13].",
                "The rest of the paper is organized as follows.",
                "We start off this paper by summarizing the previous work in NED in section 2.",
                "Section 3 presents the basic model for NED that most current systems use.",
                "Section 4 describes our new detection procedure based on news indexing-tree.",
                "In section 5, two term reweighting methods are proposed to improve NED accuracy.",
                "Section 6 gives our experimental data and evaluation metrics.",
                "We finally wrap up with the experimental results in Section 7, and the conclusions and future work in Section 8. 2.",
                "RELATED WORK Papka et al. proposed Single-Pass clustering on NED [6].",
                "When a new story was encountered, it was processed immediately to extract term features and a query representation of the storys content is built up.",
                "Then it was compared with all the previous queries.",
                "If the document did not trigger any queries by exceeding a threshold, it was marked as a new event.",
                "Lam et al build up previous query representations of story clusters, each of which corresponds to a topic [7].",
                "In this manner comparisons happen between stories and clusters.",
                "Recent years, most work focus on proposing better methods on comparison of stories and document representation.",
                "Brants et al. [8] extended a basic incremental TF-IDF model to include sourcespecific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, term reweighting based on inverse event frequencies, and segmentation of documents.",
                "Good improvements on TDT bench-marks were shown.",
                "Stokes et al. [9] utilized a combination of evidence from two distinct representations of a documents content.",
                "One of the representations was the usual free text vector, the other made use of lexical chains (created using WordNet) to build another term vector.",
                "Then the two representations are combined in a linear fashion.",
                "A marginal increase in effectiveness was achieved when the combined representation was used.",
                "Some efforts have been done on how to utilize named entities to improve NED.",
                "Yang et al. gave location named entities four times weight than other terms and named entities [10].",
                "DOREMI research group combined semantic similarities of person names, location names and time together with textual similarity [11][12].",
                "UMass [13] research group split document representation into two parts: named entities and non-named entities.",
                "And it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation.",
                "Both [10] and [13] used text categorization technique to classify news stories in advance.",
                "In [13] news stories are classified automatically at first, and then test sensitivities of names and non-name terms for NED for each class.",
                "In [10] frequent terms for each class are removed from document representation.",
                "For example, word election does not help identify different elections.",
                "In their work, effectiveness of different kinds of names (or terms with different POS) for NED in different news classes are not investigated.",
                "We use statistical analysis to reveal the fact and use it to improve NED performance. 3.",
                "BASIC MODEL In this section, we present the basic New Event Detection model which is similar to what most current systems apply.",
                "Then, we propose our new model by extending the basic model.",
                "New Event Detection systems use news story stream as input, in which stories are strictly time-ordered.",
                "Only previously received stories are available when dealing with current story.",
                "The output is a decision for whether the current story is on a new event or not and the confidence of the decision.",
                "Usually, a NED model consists of three parts: story representation, similarity calculation and detection procedure. 3.1 Story Representation Preprocessing is needed before generating story representation.",
                "For preprocessing, we tokenize words, recognize abbreviations, normalize abbreviations, add part-of-speech tags, remove stopwords included in the stop list used in InQuery [14], replace words with their stems using K-stem algorithm[15], and then generate word vector for each news story.",
                "We use incremental TF-IDF model for term weight calculation [4].",
                "In a TF-IDF model, term frequency in a news document is weighted by the inverse document frequency, which is generated from training corpus.",
                "When a new term occurs in testing process, there are two solutions: simply ignore the new term or set df of the term as a small const (e.g. df = 1).",
                "The new term receives too low weight in the first solution (0) and too high weight in the second solution.",
                "In incremental TF-IDF model, document frequencies are updated dynamically in each time step t: 1( ) ( ) ( )t t D tdf w df w df w−= + (1) where Dt represents news story set received in time t, and dfDt(w) means the number of documents that term w occurs in, and dft(w) means the total number of documents that term w occurs in before time t. In this work, each time window includes 50 news stories.",
                "Thus, each story d received in t is represented as follows: 1 2{ ( , , ), ( , , ),..., ( , , )}nd weight d t w weight d t w weight d t w→ where n means the number of distinct terms in story d, and ( , , )weight d t w means the weight of term w in story d at time t: log( ( , ) 1) log(( 1) /( ( ) 0.5)) ( , , ) log( ( , ) 1) log(( 1) /( ( ) 0.5)) t t t t w d tf d w N df w weight d t w tf d w N df w ∈ + + + = + + +∑ (2) where Nt means the total number of news stories before time t, and tf(d,w) means how many times term w occurs in news story d. 3.2 Similarity Calculation We use Hellinger distance for the calculation of similarity between two stories, for two stories d and d at time t, their similarity is defined as follows: , ( , , ) ( , , ) * ( , , ) w d d sim d d t weight d t w weight d t w ∈ = ∑ (3) 3.3 Detection Procedure For each story d received in time step t, the value ( ) ( ) ( ) ( ( , , )) time d time d n d max sim d d t < = (4) is a score used to determine whether d is a story about a new topic and at the same time is an indication of the confidence in our decision [8]. time(d) means the publication time of story d. If the score exceeds the thresholdθ new, then there exists a sufficiently similar document, thus d is a old story, otherwise, there is no sufficiently similar previous document, thus d is an new story. 4.",
                "New NED Procedure Traditional NED systems can be classified into two main types on the aspect of detection procedure: (1) S-S type, in which the story on hand is compared to each story received previously, and use the highest similarity to determine whether current story is about a new event; (2) S-C type, in which the story on hand is compared to all previous clusters each of which representing a topic, and the highest similarity is used for final decision for current story.",
                "If the highest similarity exceeds thresholdθ new, then it is an old story, and put it into the most similar cluster; otherwise it is a new story and create a new cluster.",
                "Previous work show that the first manner is more accurate than the second one [4][5].",
                "Since sometimes stories within a topic drift far away from each other, a story may have very low similarity with its topic.",
                "So using similarities between stories for determining new story is better than using similarities between story and clusters.",
                "Nevertheless, the first manner needs much more comparing times which means the first manner is low efficient.",
                "We propose a new detection procedure which uses comparisons with previous clusters to help find the most similar story in less comparing times, and the final new event decision is made according to the most similar story.",
                "Therefore, we can get both the accuracy of S-S type methods and the efficiency of S-C type methods.",
                "The new procedure creates a news indexing-tree dynamically, in which similar stories are put together to form a hierarchy of clusters.",
                "We index similar stories together by their common ancestor (a cluster node).",
                "Dissimilar stories are indexed in different clusters.",
                "When a story is coming, we use comparisons between the current story and previous hierarchical clusters to help find the most similar story which is useful for new event decision.",
                "After the new event decision is made, the current story is inserted to the indexing-tree for the following detection.",
                "The news indexing-tree is defined formally as follows: S-Tree = {r, NC , NS , E} where r is the root of S-Tree, NC is the set of all cluster nodes, NS is the set of all story nodes, and E is the set of all edges in S-Tree.",
                "We define a set of constraints for a S-Tree: ⅰ . , is an non-terminal node in the treeC i i N i∀ ∈ → ⅱ . , is a terminal node in the treeS i i N i∀ ∈ → ⅲ . , out degree of is at least 2C i i N i∀ ∈ → ⅳ . , is represented as the centroid of its desendantsC i i iN∀ ∈ → For a news story di, the comparison procedure and inserting procedure based on indexing-tree are defined as follows.",
                "An example is shown by Figure 1 and Figure 2.",
                "Figure 1.",
                "Comparison procedure Figure 2.",
                "Inserting procedure Comparison procedure: Step 1: compare di to all the direct child nodes of r and select λ nodes with highest similarities, e.g., C1 2 and C1 3 in Figure 1.",
                "Step 2: for each selected node in the last step, e.g.",
                "C1 2, compare di to all its direct child nodes, and select λ nodes with highest similarities, e.g.",
                "C2 2 and d8.",
                "Repeat step 2 for all non-terminal nodes.",
                "Step 3: record the terminal node with the highest similarty to di, e.g. s5, and the similarity value (0.20).",
                "Inserting di to the S-tree with r as root: Find the node n which is direct child of r in the path from r to the terminal node with highest similarity s, e.g.",
                "C1 2.",
                "If s is smaller than θ init+(h-1)δ , then add di to the tree as a direct child of r. Otherwise, if n is a terminal node, then create a cluster node instead of n, and add both n and di as its direct children; if n is an non-terminal node, then repeat this procedure and insert di to the sub-tree with n as root recursively.",
                "Here h is the length between n and the root of S-tree.",
                "The more the stories in a cluster similar to each other, the better the cluster represents the stories in it.",
                "Hence we add no constraints on the maximum of trees height and degree of a node.",
                "Therefore, we cannot give the complexity of this indexing-tree based procedure.",
                "But we will give the number of comparing times needed by the new procedure in our experiments in section7. 5.",
                "Term Reweighting Methods In this section, two term reweighting methods are proposed to improve NED accuracy.",
                "In the first method, a new way is explored for better using of cluster (topic) information.",
                "The second one finds a better way to make use of named entities based on news classification. 5.1 Term Reweighting Based on Distribution Distance TF-IDF is the most prevalent model used in information retrieval systems.",
                "The basic idea is that the fewer documents a term appears in, the more important the term is in discrimination of documents (relevant or not relevant to a query containing the term).",
                "Nevertheless, in TDT domain, we need to discriminate documents with regard to topics rather than queries.",
                "Intuitively, using cluster (topic) vectors to compare with subsequent news stories should outperform using story vectors.",
                "Unfortunately, the experimental results do not support this intuition [4][5].",
                "Based on observation on data, we find the reason is that a news topic usually contains many directly or indirectly related events, while they all have their own sub-subjects which are usually different with each other.",
                "Take the topic described in section 1 as an example, events like the explosion and salvage have very low similarities with events about criminal trial, therefore stories about trial would have low similarity with the topic vector built on its previous events.",
                "This section focuses on how to effectively make use of topic information and at the same time avoid the problem of content decentralization.",
                "At first, we classify terms into 5 classes to help analysis the needs of the modified model: Term class A: terms that occur frequently in the whole corpus, e.g., year and people.",
                "Terms of this class should be given low weights because they do not help much for topic discrimination.",
                "Term class B: terms that occur frequently within a news category, e.g., election, storm.",
                "They are useful to distinguish two stories in different news categories.",
                "However, they cannot provide information to determine whether two stories are on the same or different topics.",
                "In another words, term election and term storm are not helpful in differentiate two election campaigns and two storm disasters.",
                "Therefore, terms of this class should be assigned lower weights.",
                "Term class C: terms that occur frequently in a topic, and infrequently in other topics, e.g., the name of a crash plane, the name of a specific hurricane.",
                "News stories that belong to different topics rarely have overlap terms in this class.",
                "The more frequently a term appears in a topic, the more important the term is for a story belonging to the topic, therefore the term should be set higher weight.",
                "Term class D: terms that appear in a topic exclusively, but not frequently.",
                "For example, the name of a fireman who did very well in a salvage action, which may appears in only two or three stories but never appeared in other topics.",
                "Terms of this type should receive more weights than in TF-IDF model.",
                "However, since they are not popular in the topic, it is not appropriate to give them too high weights.",
                "Term class E: terms with low document frequency, and appear in different topics.",
                "Terms of this class should receive lower weights.",
                "Now we analyze whether TF-IDF model can give proper weights to the five classes of terms.",
                "Obviously, terms of class A are lowly weighted in TF-IDF model, which is conformable with the requirement described above.",
                "In TF-IDF model, terms of class B are highly dependant with the number of stories in a news class.",
                "TF-IDF model cannot provide low weights if the story containing the term belongs to a relative small news class.",
                "For a term of class C, the more frequently it appears in a topic, the less weight TFIDF model gives to it.",
                "This strongly conflicts with the requirement of terms in class C. For terms of class D, TF-IDF model gives them high weights correctly.",
                "But for terms of class E, TF-IDF model gives high weights to them which are not conformable with the requirement of low weights.",
                "To sum up, terms of class B, C, E cannot be properly weighted in TF-IDF model.",
                "So, we propose a modified model to resolve this problem.",
                "When θ init andθ new are set closely, we assume that most of the stories in a first-level cluster (a direct child node of root node) are on the same topic.",
                "Therefore, we make use of a first-level cluster to capture term distribution (df for all the terms within the cluster) within the topic dynamically.",
                "KL divergence of term distribution in a first-level cluster and the whole story set is used to adjust term weights:  ( , , ) * (1 * ( || )) ( , , ) ( , , ) * (1 * ( || )) cw tw cw tw w d D weight d t w KL P P weight d t w weight d t w KL P P γ γ ∈ + = +∑ (5) where ( ) ( ) ( ) ( ) 1,cw cw c c c c df w df w p y p y N N = = − (6) ( ) ( ) ( ) ( ) 1,t t tw tw t t df w df w p y p y N N = = − (7) where dfc(w) is the number of documents containing term w within cluster C, and Nc is the number of documents in cluster C, and Nt is the total number of documents that arrive before time step t. γ is a const parameter, now is manually set 3.",
                "KL divergence is defined as follows [17]: ( ) ( || ) ( ) log ( )x p x KL P Q p x q x = ∑ (8) The basic idea is: for a story in a topic, the more a term occurs within the topic, and the less it occurs in other topics, it should be assigned higher weights.",
                "Obviously, modified model can meet all the requirements of the five term classes listed above. 5.2 Term Reweighting Based on Term Type and Story Class Previous work found that some classes of news stories could achieve good improvements by giving extra weight to named entities.",
                "But we find that terms of different types should be given different amount of extra weight for different classes of news stories.",
                "We use open-NLP1 to recognize named entity types and part-ofspeech tags for terms that appear in news stories.",
                "Named entity types include person name, organization name, location name, date, time, money and percentage, and five POSs are selected: none (NN), verb (VB), adjective (JJ), adverb (RB) and cardinal number (CD).",
                "Statistical analysis shows topic-level discriminative terms types for different classes of stories.",
                "For the sake of convenience, named entity type and part-of-speech tags are uniformly called term type in subsequent sections.",
                "Determining whether two stories are about the same topic is a basic component for NED task.",
                "So at first we use 2 χ statistic to compute correlations between terms and topics.",
                "For a term t and a topic T, a contingence table is derived: Table 1.",
                "A 2×2 Contingence Table Doc Number belong to topic T not belong to topic T include t A B not include t C D The 2 χ statistic for a specific term t with respect to topic T is defined to be [16]: 2 2 ( , ) ( ) * ( ) ( ) * ( ) * ( ) * ( ) w T A B C D AD CB A C B D A B C D χ = + + + − + + + + (9) News topics for the TDT task are further classified into 11 rules of interpretations (ROIs) 2 .",
                "The ROI can be seen as a higher level class of stories.",
                "The average correlation between a term type and a topic ROI is computed as: 2 avg 2 ( , )( ( , ) )k m m km kT R w P w TP R p w T R P χ χ ∈ ∈ ∑ ∑（ , ）= 1 1 k=1…K, m=1…M (10) where K is the number of term types (set 12 constantly in the paper).",
                "M is the number news classes (ROIs, set 11 in the paper).",
                "Pk represents the set of all terms of type k, and Rm represents the set of all topics of class m, p(t,T) means the probability that t occurs in topic T. Because of limitation of space, only parts of the term types (9 term types) and parts of news classes (8 classes) are listed in table 2 with the average correlation values between them.",
                "The <br>statistics</br> is derived from labeled data in TDT2 corpus. (Results in table 2 are already normalized for convenience in comparison.)",
                "The <br>statistics</br> in table 2 indicates the usefulness of different term types in topic discrimination with respect to different news classes.",
                "We can see that, location name is the most useful term type for three news classes: Natural Disasters, Violence or War, Finances.",
                "And for three other categories Elections, Legal/Criminal Cases, Science and Discovery, person name is the most discriminative term type.",
                "For Scandals/Hearings, date is the most important information for topic discrimination.",
                "In addition, Legal/Criminal Cases and Finance topics have higher correlation with money terms, while Science and Discovery have higher correlation with percentage terms.",
                "Non-name terms are more stable for different classes. 1 . http://opennlp.sourceforge.net/ 2 . http://projects.ldc.upenn.edu/TDT3/Guide/label.html From the analysis of table 2, it is reasonable to adjust term weight according to their term type and the news class the story belongs to.",
                "New term weights are reweighted as follows: ( ) ( ) ( ) ( ) ( , , ) * ( , , ) ( , , ) * class d D type w T class d D type w w d weight d t w weight d t w weight d t w α α ∈ = ∑ (11) where type(w) represents the type of term w, and class(d) represents the class of story d, c kα is reweighting parameter for news class c and term type k. In the work, we just simply use <br>statistics</br> in table 2 as the reweighting parameters.",
                "Even thought using the <br>statistics</br> directly may not the best choice, we do not discuss how to automatically obtain the best parameters.",
                "We will try to use machine learning techniques to obtain the best parameters in the future work.",
                "In the work, we use BoosTexter [20] to classify all stories into one of the 11 ROIs.",
                "BoosTexter is a boosting based machine learning program, which creates a series of simple rules for building a classifier for text or attribute-value data.",
                "We use term weight generated using TF-IDF model as feature for story classification.",
                "We trained the model on the 12000 judged English stories in TDT2, and classify the rest of the stories in TDT2 and all stories in TDT3.",
                "Classification results are used for term reweighting in formula (11).",
                "Since the class labels of topic-off stories are not given in TDT datasets, we cannot give the classification accuracy here.",
                "Thus we do not discuss the effects of classification accuracy to NED performance in the paper. 6.",
                "EXPERIMENTAL SETUP 6.1 Datasets We used two LDC [18] datasets TDT2 and TDT3 for our experiments.",
                "TDT2 contains news stories from January to June 1998.",
                "It contains around 54,000 stories from sources like ABC, Associated Press, CNN, New York Times, Public Radio International, Voice of America etc.",
                "Only English stories in the collection were considered.",
                "TDT3 contains approximately 31,000 English stories collected from October to December 1998.",
                "In addition to the sources used in TDT2, it also contains stories from NBC and MSNBC TV broadcasts.",
                "We used transcribed versions of the TV and radio broadcasts besides textual news.",
                "TDT2 dataset is labeled with about 100 topics, and approximately 12,000 English stories belong to at least one of these topics.",
                "TDT3 dataset is labeled with about 120 topics, and approximately 8000 English stories belong to at least one of these topics.",
                "All the topics are classified into 11 Rules of Interpretation: (1)Elections, (2)Scandals/Hearings, (3)Legal/Criminal Cases, (4)Natural Disasters, (5)Accidents, (6)Ongoing Violence or War, (7)Science and Discovery News, (8)Finance, (9)New Law, (10)Sports News, (11)MISC.",
                "News. 6.2 Evaluation Metric TDT uses a cost function CDet that combines the probabilities of missing a new story and a false alarm [19]: * * * *Det Miss Miss Target FA FA NontargetC C P P C P P= + (12) Table 2.",
                "Average correlation between term types and news classes where CMiss means the cost of missing a new story, PMiss means the probability of missing a new story, and PTarget means the probability of seeing a new story in the data; CFA means the cost of a false alarm, PFA means the probability of a false alarm, and PNontarget means the probability of seeing an old story.",
                "The cost CDet is normalized such that a perfect system scores 0 and a trivial system, which is the better one of mark all stories as new or old, scores 1: ( ( * , * ) ) Det Det Miss Target FA Nontarget C Norm C min C P C P = (13) New event detection system gives two outputs for each story.",
                "The first part is yes or no indicating whether the story triggers a new event or not.",
                "The second part is a score indicating confidence of the first decision.",
                "Confidence scores can be used to plot DET curve, i.e., curves that plot false alarm vs. miss probabilities.",
                "Minimum normalized cost can be determined if optimal threshold on the score were chosen. 7.",
                "EXPERIMENTAL RESULTS 7.1 Main Results To test the approaches proposed in the model, we implemented and tested five systems: System-1: this system is used as baseline.",
                "It is implemented based on the basic model described in section 3, i.e., using incremental TF-IDF model to generate term weights, and using Hellinger distance to compute document similarity.",
                "Similarity score normalization is also employed [8].",
                "S-S detection procedure is used.",
                "System-2: this system is the same as system-1 except that S-C detection procedure is used.",
                "System-3: this system is the same as system-1 except that it uses the new detection procedure which is based on indexing-tree.",
                "System-4: implemented based on the approach presented in section 5.1, i.e., terms are reweighted according to the distance between term distributions in a cluster and all stories.",
                "The new detection procedure is used.",
                "System-5: implemented based on the approach presented in section 5.2, i.e., terms of different types are reweighted according to news class using trained parameters.",
                "The new detection procedure is used.",
                "The following are some other NED systems: System-6: [21] for each pair of stories, it computes three similarity values for named entity, non-named entity and all terms respectively.",
                "And employ Support Vector Machine to predict new or old using the similarity values as features.",
                "System-7: [8] it extended a basic incremental TF-IDF model to include source-specific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, etc.",
                "System-8: [13] it split document representation into two parts: named entities and non-named entities, and choose one effective part for each news class.",
                "Table 3 and table 4 show topic-weighted normalized costs and comparing times on TDT2 and TDT3 datasets respectively.",
                "Since no heldout data set for fine-tuning the threshold θ new was available for experiments on TDT2, we only report minimum normalized costs for our systems in table 3.",
                "System-5 outperforms all other systems including system-6, and it performs only 2.78e+8 comparing times in detection procedure which is only 13.4% of system-1.",
                "Table 3.",
                "NED results on TDT2 Systems Min Norm(CDet) Cmp times System-1 0.5749 2.08e+9 System-2① 0.6673 3.77e+8 System-3② 0.5765 2.81e+8 System-4② 0.5431 2.99e+8 System-5② 0.5089 2.78e+8 System-6 0.5300 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 When evaluating on the normalized costs on TDT3, we use the optimal thresholds obtained from TDT2 data set for all systems.",
                "System-2 reduces comparing times to 1.29e+9 which is just 18.3% of system-1, but at the same time it also gets a deteriorated minimum normalized cost which is 0.0499 higher than system-1.",
                "System-3 uses the new detection procedure based on news indexing-tree.",
                "It requires even less comparing times than system-2.",
                "This is because story-story comparisons usually yield greater similarities than story-cluster ones, so stories tend to be combined Location Person Date Organization Money Percentage NN JJ CD Elections 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 Scandals/Hearings 0.66 0.62 0.28 1 0.11 0.02 0.27 0.13 0.05 Legal/Criminal Cases 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 Natural Disasters 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 Violence or War 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 Science and Discovery 0.11 1 0.01 0.22 0.08 0.12 0.19 0.08 0.03 Finances 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 Sports 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 together in system-3.",
                "And system-3 is basically equivalent to system-1 in accuracy results.",
                "System-4 adjusts term weights based on the distance of term distributions between the whole corpus and cluster story set, yielding a good improvement by 0.0468 compared to system-1.",
                "The best system (system-5) has a minimum normalized cost 0.5012, which is 0.0797 better than system-1, and also better than any other results previously reported for this dataset [8, 13].",
                "Further more, system-5 only needs 1.05e+8 comparing times which is 14.9% of system-1.",
                "Table 4.",
                "NED results on TDT3 Systems Norm(CDet) Min Norm(CDet) Cmp times System-1 0.6159 0.5809 7.04e+8 System-2① 0.6493 0.6308 1.29e+8 System-3② 0.6197 0.5868 1.03e+8 System-4② 0.5601 0.5341 1.03e+8 System-5② 0.5413 0.5012 1.05e+8 System-7 -- 0.5783 -System-8 -- 0.5229 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 Figure5 shows the five DET curves for our systems on data set TDT3.",
                "System-5 achieves the minimum cost at a false alarm rate of 0.0157 and a miss rate of 0.4310.",
                "We can observe that System4 and System-5 obtain lower miss probability at regions of low false alarm probabilities.",
                "The hypothesis is that, more weight value is transferred to key terms of topics from non-key terms.",
                "Similarity score between two stories belonging to different topics are lower than before, because their overlapping terms are usually not key terms of their topics. 7.2 Parameter selection for indexing-tree detection Figure 3 shows the minimum normalized costs obtained by system-3 on TDT3 using different parameters.",
                "Theθ init parameter is tested on six values spanning from 0.03 to 0.18.",
                "And the λ parameter is tested on four values 1, 2, 3 and 4.",
                "We can see that, whenθ init is set to 0.12, which is the closest one toθ new, the costs are lower than others.",
                "This is easy to explain, because when stories belonging to the same topic are put in a cluster, it is more reasonable for the cluster to represent the stories in it.",
                "When parameter λ is set to 3 or 4, the costs are better than other cases, but there is no much difference between 3 and 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ MinCost 0.6 0.65 0.7 0.75 0.8 0.85 0.9 Figure 3.",
                "Min Cost on TDT3 (δ =0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ Comparingtimes 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 Figure 4.",
                "Comparing times on TDT3 (δ =0.15) Figure 4 gives the comparing times used by system-3 on TDT3 with the same parameters as figure 3.",
                "The comparing times are strongly dependent onθ init.",
                "Because the greaterθ init is, the less stories combined together, the more comparing times are needed for new event decision.",
                "So we useθ init =0.13,λ =3,δ =0.15 for system-3, 4, and 5.",
                "In this parameter setting, we can get both low minimum normalized costs and less comparing times. 8.",
                "CONCLUSION We have proposed a news indexing-tree based detection procedure in our model.",
                "It reduces comparing times to about one seventh of traditional method without hurting NED accuracy.",
                "We also have presented two extensions to the basic TF-IDF model.",
                "The first extension is made by adjust term weights based on term distributions between the whole corpus and a cluster story set.",
                "And the second extension to basic TF-IDF model is better use of term types (named entities types and part-of-speed) according to news categories.",
                "Our experimental results on TDT2 and TDT3 datasets show that both of the two extensions contribute significantly to improvement in accuracy.",
                "We did not consider news time information as a clue for NED task, since most of the topics last for a long time and TDT data sets only span for a relative short period (no more than 6 months).",
                "For the future work, we want to collect news set which span for a longer period from internet, and integrate time information in NED task.",
                "Since topic is a relative coarse-grained news cluster, we also want to refine cluster granularity to event-level, and identify different events and their relations within a topic.",
                "Acknowledgments This work is supported by the National Natural Science Foundation of China under Grant No. 90604025.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] In Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. .01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90 1 2 5 10 20 40 60 80 90 False Alarm Probability (in %) MissProbability(in%) SYSTEM1 Topic Weighted Curve SYSTEM1 Min Norm(Cost) SYSTEM2 Topic Weighted Curve SYSTEM2 Min Norm(Cost) SYSTEM3 Topic Weighted Curve SYSTEM3 Min Norm(Cost) SYSTEM4 Topic Weighted Curve SYSTEM4 Min Norm(Cost) SYSTEM5 Topic Weighted Curve SYSTEM5 Min Norm(Cost) Random Performance Figure 5.",
                "DET curves on TDT3 [3] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B.T.",
                "Archibald, and X. Liu.",
                "Learning Approaches for Detecting and Tracking News Events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), 1999, 32-43. [4] Y. Yang, T. Pierce, and J. Carbonell.",
                "A Study on Retrospective and On-line Event Detection.",
                "In Proceedings of SIGIR-98, Melbourne, Australia, 1998, 28-36. [5] J. Allan, V. Lavrenko, D. Malin, and R. Swan.",
                "Detections, Bounds, and Timelines: Umass and tdt-3.",
                "In Proceedings of Topic Detection and Tracking Workshop (TDT-3), Vienna, VA, 2000, 167-174. [6] R. Papka and J. Allan.",
                "On-line New Event Detection Using Single Pass Clustering TITLE2:.",
                "Technical Report UM-CS1998-021, 1998. [7] W. Lam, H. Meng, K. Wong, and J.",
                "Yen.",
                "Using Contextual Analysis for News Event Detection.",
                "International Journal on Intelligent Systems, 2001, 525-546. [8] B. Thorsten, C. Francine, and F. Ayman.",
                "A System for New Event Detection.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2003, 330-337. [9] S. Nicola and C. Joe.",
                "Combining Semantic and Syntactic Document Classifiers to Improve First Story Detection.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2001, 424425. [10] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topicconditioned Novelty Detection.",
                "In Proceedings of the 8th ACM SIGKDD International Conference, ACM Press. 2002, 688-693. [11] M. Juha, A.M. Helena, and S. Marko.",
                "Applying Semantic Classes in Event Detection and Tracking.",
                "In Proceedings of International Conference on Natural Language Processing (ICON 2002), 2002, pages 175-183. [12] M. Juha, A.M. Helena, and S. Marko.",
                "Simple Semantics in Topic Detection and Tracking.",
                "Information Retrieval, 7(3-4): 2004, 347-368. [13] K. Giridhar and J. Allan.",
                "Text Classification and Named Entities for New Event Detection.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2004, 297-304. [14] J. P. Callan, W. B. Croft, and S. M. Harding.",
                "The INQUERY Retrieval System.",
                "In Proceedings of DEXA-92, 3rd International Conference on Database and Expert Systems Applications, 1992, 78-83. [15] R. Krovetz.",
                "Viewing Morphology as An Inference Process.",
                "In Proceedings of ACM SIGIR93, 1993, 61-81. [16] Y. Yang and J. Pedersen.",
                "A Comparative Study on Feature Selection in Text Categorization.",
                "In J. D. H. Fisher, editor, The Fourteenth International Conference on Machine Learning (ICML97), Morgan Kaufmann, 1997, 412-420. [17] T. M. Cover, and J.A.",
                "Thomas.",
                "Elements of Information Theory.",
                "Wiley. 1991. [18] The linguistic data consortium, http://www.ldc,upenn.edu/. [19] The 2001 TDT task definition and evaluation plan, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm. [20] R. E. Schapire and Y.",
                "Singer.",
                "Boostexter: A Boosting-based System for Text Categorization.",
                "In Machine Learning 39(2/3):1, Kluwer Academic Publishers, 2000, 35-168. [21] K. Giridhar and J. Allan. 2005.",
                "Using Names and Topics for New Event Detection.",
                "In Proceedings of Human Technology Conference and Conference on Empirical Methods in Natural Language, Vancouver, 2005, 121-128"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "En el primer enfoque, proponemos ajustar los pesos de los términos basados dinámicamente en los grupos de historias anteriores y en el segundo enfoque, proponemos emplear \"estadísticas\" en los datos de capacitación para aprender el modelo de peso de la entidad nombrado para cada clase de historias.",
                "En este enfoque, la información del clúster (tema) se usa correctamente, por lo que se evita el problema de la descentralización del tema.(3)",
                "Y proponemos usar \"estadísticas\" para optimizar los pesos de los términos de diferentes tipos en una historia de acuerdo con la clase de noticias a la que pertenece la historia.",
                "Las \"estadísticas\" se derivan de datos etiquetados en TDT2 Corpus.(Los resultados en la Tabla 2 ya están normalizados por conveniencia en comparación).",
                "Las \"estadísticas\" en la Tabla 2 indican la utilidad de los diferentes tipos de términos en la discriminación de temas con respecto a diferentes clases de noticias.",
                "El nuevo término los pesos se vuelven a ver de la siguiente manera: () () () () (,,) * (,) (,,) * Clase D D Type W T Clase D D Tipo W W W W W W W W W W PESO D T W PESO D T W α α ∈= ∑ (11) donde el tipo (W) representa el tipo de término W, y la clase (d) representa la clase de la historia D, C Kα es el parámetro de re -peso para la clase de noticias C y el tipo de término K.En el trabajo, simplemente usamos \"estadísticas\" en la Tabla 2 como parámetros de re -peso.",
                "Incluso el pensamiento con las \"estadísticas\" directamente puede no ser la mejor opción, no discutimos cómo obtener automáticamente los mejores parámetros."
            ],
            "translated_text": "",
            "candidates": [
                "Estadísticas",
                "estadísticas",
                "Según las observaciones sobre las \"estadísticas\" obtenidas de los datos de capacitación, encontramos que los términos de diferentes tipos (por ejemplo, estadísticas",
                "estadísticas",
                "Estadísticas",
                "estadísticas",
                "Estadísticas",
                "estadísticas",
                "Estadísticas",
                "estadísticas",
                "Estadísticas",
                "estadísticas",
                "Estadísticas",
                "estadísticas"
            ],
            "error": []
        },
        "training data": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "New Event Detection Based on Indexing-tree and Named Entity Zhang Kuo Tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn Li Juan Zi Tsinghua University Beijing, 100084, China 86-10-62781461 ljz@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn ABSTRACT New Event Detection (NED) aims at detecting from one or multiple streams of news stories that which one is reported on a new event (i.e.",
                "not reported previously).",
                "With the overwhelming volume of news available today, there is an increasing need for a NED system which is able to detect new events more efficiently and accurately.",
                "In this paper we propose a new NED model to speed up the NED task by using news indexing-tree dynamically.",
                "Moreover, based on the observation that terms of different types have different effects for NED task, two term reweighting approaches are proposed to improve NED accuracy.",
                "In the first approach, we propose to adjust term weights dynamically based on previous story clusters and in the second approach, we propose to employ statistics on <br>training data</br> to learn the named entity reweighting model for each class of stories.",
                "Experimental results on two Linguistic Data Consortium (LDC) datasets TDT2 and TDT3 show that the proposed model can improve both efficiency and accuracy of NED task significantly, compared to the baseline system and other existing systems.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Search and Retrieval; H.4.2 [Information Systems Applications]: Types of Systemsdecision support.",
                "General Terms Algorithms, Performance, Experimentation 1.",
                "INTRODUCTION Topic Detection and Tracking (TDT) program aims to develop techniques which can effectively organize, search and structure news text materials from a variety of newswire and broadcast media [1].",
                "New Event Detection (NED) is one of the five tasks in TDT.",
                "It is the task of online identification of the earliest report for each topic as soon as that report arrives in the sequence of documents.",
                "A Topic is defined as a seminal event or activity, along with directly related events and activities [2].",
                "An Event is defined as something (non-trivial) happening in a certain place at a certain time [3].",
                "For instance, when a bomb explodes in a building, the exploding is the seminal event that triggers the topic, and other stories on the same topic would be those discussing salvaging efforts, the search for perpetrators, arrests and trial and so on.",
                "Useful news information is usually buried in a mass of data generated everyday.",
                "Therefore, NED systems are very useful for people who need to detect novel information from real-time news stream.",
                "These real-life needs often occur in domains like financial markets, news analysis, and intelligence gathering.",
                "In most of state-of-the-art (currently) NED systems, each news story on hand is compared to all the previous received stories.",
                "If all the similarities between them do not exceed a threshold, then the story triggers a new event.",
                "They are usually in the form of cosine similarity or Hellinger similarity metric.",
                "The core problem of NED is to identify whether two stories are on the same topic.",
                "Obviously, these systems cannot take advantage of topic information.",
                "Further more, it is not acceptable in real applications because of the large amount of computation required in the NED process.",
                "Other systems organize previous stories into clusters (each cluster corresponds to a topic), and new story is compared to the previous clusters instead of stories.",
                "This manner can reduce comparing times significantly.",
                "Nevertheless, it has been proved that this manner is less accurate [4, 5].",
                "This is because sometimes stories within a topic drift far away from each other, which could lead low similarity between a story and its topic.",
                "On the other hand, some proposed NED systems tried to improve accuracy by making better use of named entities [10, 11, 12, 13].",
                "However, none of the systems have considered that terms of different types (e.g.",
                "Noun, Verb or Person name) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "For example, the names of election candidates (Person name) are very important for stories of election class; the locations (Location name) where accidents happened are important for stories of accidents class.",
                "So, in NED, there still exist following three problems to be investigated: (1) How to speed up the detection procedure while do not decrease the detection accuracy? (2) How to make good use of cluster (topic) information to improve accuracy? (3) How to obtain better news story representation by better understanding of named entities.",
                "Driven by these problems, we have proposed three approaches in this paper. (1)To make the detection procedure faster, we propose a new NED procedure based on news indexing-tree created dynamically.",
                "Story indexing-tree is created by assembling similar stories together to form news clusters in different hierarchies according to their values of similarity.",
                "Comparisons between current story and previous clusters could help find the most similar story in less comparing times.",
                "The new procedure can reduce the amount of comparing times without hurting accuracy. (2)We use the clusters of the first floor in the indexing-tree as news topics, in which term weights are adjusted dynamically according to term distribution in the clusters.",
                "In this approach, cluster (topic) information is used properly, so the problem of theme decentralization is avoided. (3)Based on observations on the statistics obtained from <br>training data</br>, we found that terms of different types (e.g.",
                "Noun and Verb) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "And we propose to use statistics to optimize the weights of the terms of different types in a story according to the news class that the story belongs to.",
                "On TDT3 dataset, the new NED model just uses 14.9% comparing times of the basic model, while its minimum normalized cost is 0.5012, which is 0.0797 better than the basic model, and also better than any other results previously reported for this dataset [8, 13].",
                "The rest of the paper is organized as follows.",
                "We start off this paper by summarizing the previous work in NED in section 2.",
                "Section 3 presents the basic model for NED that most current systems use.",
                "Section 4 describes our new detection procedure based on news indexing-tree.",
                "In section 5, two term reweighting methods are proposed to improve NED accuracy.",
                "Section 6 gives our experimental data and evaluation metrics.",
                "We finally wrap up with the experimental results in Section 7, and the conclusions and future work in Section 8. 2.",
                "RELATED WORK Papka et al. proposed Single-Pass clustering on NED [6].",
                "When a new story was encountered, it was processed immediately to extract term features and a query representation of the storys content is built up.",
                "Then it was compared with all the previous queries.",
                "If the document did not trigger any queries by exceeding a threshold, it was marked as a new event.",
                "Lam et al build up previous query representations of story clusters, each of which corresponds to a topic [7].",
                "In this manner comparisons happen between stories and clusters.",
                "Recent years, most work focus on proposing better methods on comparison of stories and document representation.",
                "Brants et al. [8] extended a basic incremental TF-IDF model to include sourcespecific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, term reweighting based on inverse event frequencies, and segmentation of documents.",
                "Good improvements on TDT bench-marks were shown.",
                "Stokes et al. [9] utilized a combination of evidence from two distinct representations of a documents content.",
                "One of the representations was the usual free text vector, the other made use of lexical chains (created using WordNet) to build another term vector.",
                "Then the two representations are combined in a linear fashion.",
                "A marginal increase in effectiveness was achieved when the combined representation was used.",
                "Some efforts have been done on how to utilize named entities to improve NED.",
                "Yang et al. gave location named entities four times weight than other terms and named entities [10].",
                "DOREMI research group combined semantic similarities of person names, location names and time together with textual similarity [11][12].",
                "UMass [13] research group split document representation into two parts: named entities and non-named entities.",
                "And it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation.",
                "Both [10] and [13] used text categorization technique to classify news stories in advance.",
                "In [13] news stories are classified automatically at first, and then test sensitivities of names and non-name terms for NED for each class.",
                "In [10] frequent terms for each class are removed from document representation.",
                "For example, word election does not help identify different elections.",
                "In their work, effectiveness of different kinds of names (or terms with different POS) for NED in different news classes are not investigated.",
                "We use statistical analysis to reveal the fact and use it to improve NED performance. 3.",
                "BASIC MODEL In this section, we present the basic New Event Detection model which is similar to what most current systems apply.",
                "Then, we propose our new model by extending the basic model.",
                "New Event Detection systems use news story stream as input, in which stories are strictly time-ordered.",
                "Only previously received stories are available when dealing with current story.",
                "The output is a decision for whether the current story is on a new event or not and the confidence of the decision.",
                "Usually, a NED model consists of three parts: story representation, similarity calculation and detection procedure. 3.1 Story Representation Preprocessing is needed before generating story representation.",
                "For preprocessing, we tokenize words, recognize abbreviations, normalize abbreviations, add part-of-speech tags, remove stopwords included in the stop list used in InQuery [14], replace words with their stems using K-stem algorithm[15], and then generate word vector for each news story.",
                "We use incremental TF-IDF model for term weight calculation [4].",
                "In a TF-IDF model, term frequency in a news document is weighted by the inverse document frequency, which is generated from training corpus.",
                "When a new term occurs in testing process, there are two solutions: simply ignore the new term or set df of the term as a small const (e.g. df = 1).",
                "The new term receives too low weight in the first solution (0) and too high weight in the second solution.",
                "In incremental TF-IDF model, document frequencies are updated dynamically in each time step t: 1( ) ( ) ( )t t D tdf w df w df w−= + (1) where Dt represents news story set received in time t, and dfDt(w) means the number of documents that term w occurs in, and dft(w) means the total number of documents that term w occurs in before time t. In this work, each time window includes 50 news stories.",
                "Thus, each story d received in t is represented as follows: 1 2{ ( , , ), ( , , ),..., ( , , )}nd weight d t w weight d t w weight d t w→ where n means the number of distinct terms in story d, and ( , , )weight d t w means the weight of term w in story d at time t: log( ( , ) 1) log(( 1) /( ( ) 0.5)) ( , , ) log( ( , ) 1) log(( 1) /( ( ) 0.5)) t t t t w d tf d w N df w weight d t w tf d w N df w ∈ + + + = + + +∑ (2) where Nt means the total number of news stories before time t, and tf(d,w) means how many times term w occurs in news story d. 3.2 Similarity Calculation We use Hellinger distance for the calculation of similarity between two stories, for two stories d and d at time t, their similarity is defined as follows: , ( , , ) ( , , ) * ( , , ) w d d sim d d t weight d t w weight d t w ∈ = ∑ (3) 3.3 Detection Procedure For each story d received in time step t, the value ( ) ( ) ( ) ( ( , , )) time d time d n d max sim d d t < = (4) is a score used to determine whether d is a story about a new topic and at the same time is an indication of the confidence in our decision [8]. time(d) means the publication time of story d. If the score exceeds the thresholdθ new, then there exists a sufficiently similar document, thus d is a old story, otherwise, there is no sufficiently similar previous document, thus d is an new story. 4.",
                "New NED Procedure Traditional NED systems can be classified into two main types on the aspect of detection procedure: (1) S-S type, in which the story on hand is compared to each story received previously, and use the highest similarity to determine whether current story is about a new event; (2) S-C type, in which the story on hand is compared to all previous clusters each of which representing a topic, and the highest similarity is used for final decision for current story.",
                "If the highest similarity exceeds thresholdθ new, then it is an old story, and put it into the most similar cluster; otherwise it is a new story and create a new cluster.",
                "Previous work show that the first manner is more accurate than the second one [4][5].",
                "Since sometimes stories within a topic drift far away from each other, a story may have very low similarity with its topic.",
                "So using similarities between stories for determining new story is better than using similarities between story and clusters.",
                "Nevertheless, the first manner needs much more comparing times which means the first manner is low efficient.",
                "We propose a new detection procedure which uses comparisons with previous clusters to help find the most similar story in less comparing times, and the final new event decision is made according to the most similar story.",
                "Therefore, we can get both the accuracy of S-S type methods and the efficiency of S-C type methods.",
                "The new procedure creates a news indexing-tree dynamically, in which similar stories are put together to form a hierarchy of clusters.",
                "We index similar stories together by their common ancestor (a cluster node).",
                "Dissimilar stories are indexed in different clusters.",
                "When a story is coming, we use comparisons between the current story and previous hierarchical clusters to help find the most similar story which is useful for new event decision.",
                "After the new event decision is made, the current story is inserted to the indexing-tree for the following detection.",
                "The news indexing-tree is defined formally as follows: S-Tree = {r, NC , NS , E} where r is the root of S-Tree, NC is the set of all cluster nodes, NS is the set of all story nodes, and E is the set of all edges in S-Tree.",
                "We define a set of constraints for a S-Tree: ⅰ . , is an non-terminal node in the treeC i i N i∀ ∈ → ⅱ . , is a terminal node in the treeS i i N i∀ ∈ → ⅲ . , out degree of is at least 2C i i N i∀ ∈ → ⅳ . , is represented as the centroid of its desendantsC i i iN∀ ∈ → For a news story di, the comparison procedure and inserting procedure based on indexing-tree are defined as follows.",
                "An example is shown by Figure 1 and Figure 2.",
                "Figure 1.",
                "Comparison procedure Figure 2.",
                "Inserting procedure Comparison procedure: Step 1: compare di to all the direct child nodes of r and select λ nodes with highest similarities, e.g., C1 2 and C1 3 in Figure 1.",
                "Step 2: for each selected node in the last step, e.g.",
                "C1 2, compare di to all its direct child nodes, and select λ nodes with highest similarities, e.g.",
                "C2 2 and d8.",
                "Repeat step 2 for all non-terminal nodes.",
                "Step 3: record the terminal node with the highest similarty to di, e.g. s5, and the similarity value (0.20).",
                "Inserting di to the S-tree with r as root: Find the node n which is direct child of r in the path from r to the terminal node with highest similarity s, e.g.",
                "C1 2.",
                "If s is smaller than θ init+(h-1)δ , then add di to the tree as a direct child of r. Otherwise, if n is a terminal node, then create a cluster node instead of n, and add both n and di as its direct children; if n is an non-terminal node, then repeat this procedure and insert di to the sub-tree with n as root recursively.",
                "Here h is the length between n and the root of S-tree.",
                "The more the stories in a cluster similar to each other, the better the cluster represents the stories in it.",
                "Hence we add no constraints on the maximum of trees height and degree of a node.",
                "Therefore, we cannot give the complexity of this indexing-tree based procedure.",
                "But we will give the number of comparing times needed by the new procedure in our experiments in section7. 5.",
                "Term Reweighting Methods In this section, two term reweighting methods are proposed to improve NED accuracy.",
                "In the first method, a new way is explored for better using of cluster (topic) information.",
                "The second one finds a better way to make use of named entities based on news classification. 5.1 Term Reweighting Based on Distribution Distance TF-IDF is the most prevalent model used in information retrieval systems.",
                "The basic idea is that the fewer documents a term appears in, the more important the term is in discrimination of documents (relevant or not relevant to a query containing the term).",
                "Nevertheless, in TDT domain, we need to discriminate documents with regard to topics rather than queries.",
                "Intuitively, using cluster (topic) vectors to compare with subsequent news stories should outperform using story vectors.",
                "Unfortunately, the experimental results do not support this intuition [4][5].",
                "Based on observation on data, we find the reason is that a news topic usually contains many directly or indirectly related events, while they all have their own sub-subjects which are usually different with each other.",
                "Take the topic described in section 1 as an example, events like the explosion and salvage have very low similarities with events about criminal trial, therefore stories about trial would have low similarity with the topic vector built on its previous events.",
                "This section focuses on how to effectively make use of topic information and at the same time avoid the problem of content decentralization.",
                "At first, we classify terms into 5 classes to help analysis the needs of the modified model: Term class A: terms that occur frequently in the whole corpus, e.g., year and people.",
                "Terms of this class should be given low weights because they do not help much for topic discrimination.",
                "Term class B: terms that occur frequently within a news category, e.g., election, storm.",
                "They are useful to distinguish two stories in different news categories.",
                "However, they cannot provide information to determine whether two stories are on the same or different topics.",
                "In another words, term election and term storm are not helpful in differentiate two election campaigns and two storm disasters.",
                "Therefore, terms of this class should be assigned lower weights.",
                "Term class C: terms that occur frequently in a topic, and infrequently in other topics, e.g., the name of a crash plane, the name of a specific hurricane.",
                "News stories that belong to different topics rarely have overlap terms in this class.",
                "The more frequently a term appears in a topic, the more important the term is for a story belonging to the topic, therefore the term should be set higher weight.",
                "Term class D: terms that appear in a topic exclusively, but not frequently.",
                "For example, the name of a fireman who did very well in a salvage action, which may appears in only two or three stories but never appeared in other topics.",
                "Terms of this type should receive more weights than in TF-IDF model.",
                "However, since they are not popular in the topic, it is not appropriate to give them too high weights.",
                "Term class E: terms with low document frequency, and appear in different topics.",
                "Terms of this class should receive lower weights.",
                "Now we analyze whether TF-IDF model can give proper weights to the five classes of terms.",
                "Obviously, terms of class A are lowly weighted in TF-IDF model, which is conformable with the requirement described above.",
                "In TF-IDF model, terms of class B are highly dependant with the number of stories in a news class.",
                "TF-IDF model cannot provide low weights if the story containing the term belongs to a relative small news class.",
                "For a term of class C, the more frequently it appears in a topic, the less weight TFIDF model gives to it.",
                "This strongly conflicts with the requirement of terms in class C. For terms of class D, TF-IDF model gives them high weights correctly.",
                "But for terms of class E, TF-IDF model gives high weights to them which are not conformable with the requirement of low weights.",
                "To sum up, terms of class B, C, E cannot be properly weighted in TF-IDF model.",
                "So, we propose a modified model to resolve this problem.",
                "When θ init andθ new are set closely, we assume that most of the stories in a first-level cluster (a direct child node of root node) are on the same topic.",
                "Therefore, we make use of a first-level cluster to capture term distribution (df for all the terms within the cluster) within the topic dynamically.",
                "KL divergence of term distribution in a first-level cluster and the whole story set is used to adjust term weights:  ( , , ) * (1 * ( || )) ( , , ) ( , , ) * (1 * ( || )) cw tw cw tw w d D weight d t w KL P P weight d t w weight d t w KL P P γ γ ∈ + = +∑ (5) where ( ) ( ) ( ) ( ) 1,cw cw c c c c df w df w p y p y N N = = − (6) ( ) ( ) ( ) ( ) 1,t t tw tw t t df w df w p y p y N N = = − (7) where dfc(w) is the number of documents containing term w within cluster C, and Nc is the number of documents in cluster C, and Nt is the total number of documents that arrive before time step t. γ is a const parameter, now is manually set 3.",
                "KL divergence is defined as follows [17]: ( ) ( || ) ( ) log ( )x p x KL P Q p x q x = ∑ (8) The basic idea is: for a story in a topic, the more a term occurs within the topic, and the less it occurs in other topics, it should be assigned higher weights.",
                "Obviously, modified model can meet all the requirements of the five term classes listed above. 5.2 Term Reweighting Based on Term Type and Story Class Previous work found that some classes of news stories could achieve good improvements by giving extra weight to named entities.",
                "But we find that terms of different types should be given different amount of extra weight for different classes of news stories.",
                "We use open-NLP1 to recognize named entity types and part-ofspeech tags for terms that appear in news stories.",
                "Named entity types include person name, organization name, location name, date, time, money and percentage, and five POSs are selected: none (NN), verb (VB), adjective (JJ), adverb (RB) and cardinal number (CD).",
                "Statistical analysis shows topic-level discriminative terms types for different classes of stories.",
                "For the sake of convenience, named entity type and part-of-speech tags are uniformly called term type in subsequent sections.",
                "Determining whether two stories are about the same topic is a basic component for NED task.",
                "So at first we use 2 χ statistic to compute correlations between terms and topics.",
                "For a term t and a topic T, a contingence table is derived: Table 1.",
                "A 2×2 Contingence Table Doc Number belong to topic T not belong to topic T include t A B not include t C D The 2 χ statistic for a specific term t with respect to topic T is defined to be [16]: 2 2 ( , ) ( ) * ( ) ( ) * ( ) * ( ) * ( ) w T A B C D AD CB A C B D A B C D χ = + + + − + + + + (9) News topics for the TDT task are further classified into 11 rules of interpretations (ROIs) 2 .",
                "The ROI can be seen as a higher level class of stories.",
                "The average correlation between a term type and a topic ROI is computed as: 2 avg 2 ( , )( ( , ) )k m m km kT R w P w TP R p w T R P χ χ ∈ ∈ ∑ ∑（ , ）= 1 1 k=1…K, m=1…M (10) where K is the number of term types (set 12 constantly in the paper).",
                "M is the number news classes (ROIs, set 11 in the paper).",
                "Pk represents the set of all terms of type k, and Rm represents the set of all topics of class m, p(t,T) means the probability that t occurs in topic T. Because of limitation of space, only parts of the term types (9 term types) and parts of news classes (8 classes) are listed in table 2 with the average correlation values between them.",
                "The statistics is derived from labeled data in TDT2 corpus. (Results in table 2 are already normalized for convenience in comparison.)",
                "The statistics in table 2 indicates the usefulness of different term types in topic discrimination with respect to different news classes.",
                "We can see that, location name is the most useful term type for three news classes: Natural Disasters, Violence or War, Finances.",
                "And for three other categories Elections, Legal/Criminal Cases, Science and Discovery, person name is the most discriminative term type.",
                "For Scandals/Hearings, date is the most important information for topic discrimination.",
                "In addition, Legal/Criminal Cases and Finance topics have higher correlation with money terms, while Science and Discovery have higher correlation with percentage terms.",
                "Non-name terms are more stable for different classes. 1 . http://opennlp.sourceforge.net/ 2 . http://projects.ldc.upenn.edu/TDT3/Guide/label.html From the analysis of table 2, it is reasonable to adjust term weight according to their term type and the news class the story belongs to.",
                "New term weights are reweighted as follows: ( ) ( ) ( ) ( ) ( , , ) * ( , , ) ( , , ) * class d D type w T class d D type w w d weight d t w weight d t w weight d t w α α ∈ = ∑ (11) where type(w) represents the type of term w, and class(d) represents the class of story d, c kα is reweighting parameter for news class c and term type k. In the work, we just simply use statistics in table 2 as the reweighting parameters.",
                "Even thought using the statistics directly may not the best choice, we do not discuss how to automatically obtain the best parameters.",
                "We will try to use machine learning techniques to obtain the best parameters in the future work.",
                "In the work, we use BoosTexter [20] to classify all stories into one of the 11 ROIs.",
                "BoosTexter is a boosting based machine learning program, which creates a series of simple rules for building a classifier for text or attribute-value data.",
                "We use term weight generated using TF-IDF model as feature for story classification.",
                "We trained the model on the 12000 judged English stories in TDT2, and classify the rest of the stories in TDT2 and all stories in TDT3.",
                "Classification results are used for term reweighting in formula (11).",
                "Since the class labels of topic-off stories are not given in TDT datasets, we cannot give the classification accuracy here.",
                "Thus we do not discuss the effects of classification accuracy to NED performance in the paper. 6.",
                "EXPERIMENTAL SETUP 6.1 Datasets We used two LDC [18] datasets TDT2 and TDT3 for our experiments.",
                "TDT2 contains news stories from January to June 1998.",
                "It contains around 54,000 stories from sources like ABC, Associated Press, CNN, New York Times, Public Radio International, Voice of America etc.",
                "Only English stories in the collection were considered.",
                "TDT3 contains approximately 31,000 English stories collected from October to December 1998.",
                "In addition to the sources used in TDT2, it also contains stories from NBC and MSNBC TV broadcasts.",
                "We used transcribed versions of the TV and radio broadcasts besides textual news.",
                "TDT2 dataset is labeled with about 100 topics, and approximately 12,000 English stories belong to at least one of these topics.",
                "TDT3 dataset is labeled with about 120 topics, and approximately 8000 English stories belong to at least one of these topics.",
                "All the topics are classified into 11 Rules of Interpretation: (1)Elections, (2)Scandals/Hearings, (3)Legal/Criminal Cases, (4)Natural Disasters, (5)Accidents, (6)Ongoing Violence or War, (7)Science and Discovery News, (8)Finance, (9)New Law, (10)Sports News, (11)MISC.",
                "News. 6.2 Evaluation Metric TDT uses a cost function CDet that combines the probabilities of missing a new story and a false alarm [19]: * * * *Det Miss Miss Target FA FA NontargetC C P P C P P= + (12) Table 2.",
                "Average correlation between term types and news classes where CMiss means the cost of missing a new story, PMiss means the probability of missing a new story, and PTarget means the probability of seeing a new story in the data; CFA means the cost of a false alarm, PFA means the probability of a false alarm, and PNontarget means the probability of seeing an old story.",
                "The cost CDet is normalized such that a perfect system scores 0 and a trivial system, which is the better one of mark all stories as new or old, scores 1: ( ( * , * ) ) Det Det Miss Target FA Nontarget C Norm C min C P C P = (13) New event detection system gives two outputs for each story.",
                "The first part is yes or no indicating whether the story triggers a new event or not.",
                "The second part is a score indicating confidence of the first decision.",
                "Confidence scores can be used to plot DET curve, i.e., curves that plot false alarm vs. miss probabilities.",
                "Minimum normalized cost can be determined if optimal threshold on the score were chosen. 7.",
                "EXPERIMENTAL RESULTS 7.1 Main Results To test the approaches proposed in the model, we implemented and tested five systems: System-1: this system is used as baseline.",
                "It is implemented based on the basic model described in section 3, i.e., using incremental TF-IDF model to generate term weights, and using Hellinger distance to compute document similarity.",
                "Similarity score normalization is also employed [8].",
                "S-S detection procedure is used.",
                "System-2: this system is the same as system-1 except that S-C detection procedure is used.",
                "System-3: this system is the same as system-1 except that it uses the new detection procedure which is based on indexing-tree.",
                "System-4: implemented based on the approach presented in section 5.1, i.e., terms are reweighted according to the distance between term distributions in a cluster and all stories.",
                "The new detection procedure is used.",
                "System-5: implemented based on the approach presented in section 5.2, i.e., terms of different types are reweighted according to news class using trained parameters.",
                "The new detection procedure is used.",
                "The following are some other NED systems: System-6: [21] for each pair of stories, it computes three similarity values for named entity, non-named entity and all terms respectively.",
                "And employ Support Vector Machine to predict new or old using the similarity values as features.",
                "System-7: [8] it extended a basic incremental TF-IDF model to include source-specific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, etc.",
                "System-8: [13] it split document representation into two parts: named entities and non-named entities, and choose one effective part for each news class.",
                "Table 3 and table 4 show topic-weighted normalized costs and comparing times on TDT2 and TDT3 datasets respectively.",
                "Since no heldout data set for fine-tuning the threshold θ new was available for experiments on TDT2, we only report minimum normalized costs for our systems in table 3.",
                "System-5 outperforms all other systems including system-6, and it performs only 2.78e+8 comparing times in detection procedure which is only 13.4% of system-1.",
                "Table 3.",
                "NED results on TDT2 Systems Min Norm(CDet) Cmp times System-1 0.5749 2.08e+9 System-2① 0.6673 3.77e+8 System-3② 0.5765 2.81e+8 System-4② 0.5431 2.99e+8 System-5② 0.5089 2.78e+8 System-6 0.5300 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 When evaluating on the normalized costs on TDT3, we use the optimal thresholds obtained from TDT2 data set for all systems.",
                "System-2 reduces comparing times to 1.29e+9 which is just 18.3% of system-1, but at the same time it also gets a deteriorated minimum normalized cost which is 0.0499 higher than system-1.",
                "System-3 uses the new detection procedure based on news indexing-tree.",
                "It requires even less comparing times than system-2.",
                "This is because story-story comparisons usually yield greater similarities than story-cluster ones, so stories tend to be combined Location Person Date Organization Money Percentage NN JJ CD Elections 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 Scandals/Hearings 0.66 0.62 0.28 1 0.11 0.02 0.27 0.13 0.05 Legal/Criminal Cases 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 Natural Disasters 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 Violence or War 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 Science and Discovery 0.11 1 0.01 0.22 0.08 0.12 0.19 0.08 0.03 Finances 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 Sports 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 together in system-3.",
                "And system-3 is basically equivalent to system-1 in accuracy results.",
                "System-4 adjusts term weights based on the distance of term distributions between the whole corpus and cluster story set, yielding a good improvement by 0.0468 compared to system-1.",
                "The best system (system-5) has a minimum normalized cost 0.5012, which is 0.0797 better than system-1, and also better than any other results previously reported for this dataset [8, 13].",
                "Further more, system-5 only needs 1.05e+8 comparing times which is 14.9% of system-1.",
                "Table 4.",
                "NED results on TDT3 Systems Norm(CDet) Min Norm(CDet) Cmp times System-1 0.6159 0.5809 7.04e+8 System-2① 0.6493 0.6308 1.29e+8 System-3② 0.6197 0.5868 1.03e+8 System-4② 0.5601 0.5341 1.03e+8 System-5② 0.5413 0.5012 1.05e+8 System-7 -- 0.5783 -System-8 -- 0.5229 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 Figure5 shows the five DET curves for our systems on data set TDT3.",
                "System-5 achieves the minimum cost at a false alarm rate of 0.0157 and a miss rate of 0.4310.",
                "We can observe that System4 and System-5 obtain lower miss probability at regions of low false alarm probabilities.",
                "The hypothesis is that, more weight value is transferred to key terms of topics from non-key terms.",
                "Similarity score between two stories belonging to different topics are lower than before, because their overlapping terms are usually not key terms of their topics. 7.2 Parameter selection for indexing-tree detection Figure 3 shows the minimum normalized costs obtained by system-3 on TDT3 using different parameters.",
                "Theθ init parameter is tested on six values spanning from 0.03 to 0.18.",
                "And the λ parameter is tested on four values 1, 2, 3 and 4.",
                "We can see that, whenθ init is set to 0.12, which is the closest one toθ new, the costs are lower than others.",
                "This is easy to explain, because when stories belonging to the same topic are put in a cluster, it is more reasonable for the cluster to represent the stories in it.",
                "When parameter λ is set to 3 or 4, the costs are better than other cases, but there is no much difference between 3 and 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ MinCost 0.6 0.65 0.7 0.75 0.8 0.85 0.9 Figure 3.",
                "Min Cost on TDT3 (δ =0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ Comparingtimes 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 Figure 4.",
                "Comparing times on TDT3 (δ =0.15) Figure 4 gives the comparing times used by system-3 on TDT3 with the same parameters as figure 3.",
                "The comparing times are strongly dependent onθ init.",
                "Because the greaterθ init is, the less stories combined together, the more comparing times are needed for new event decision.",
                "So we useθ init =0.13,λ =3,δ =0.15 for system-3, 4, and 5.",
                "In this parameter setting, we can get both low minimum normalized costs and less comparing times. 8.",
                "CONCLUSION We have proposed a news indexing-tree based detection procedure in our model.",
                "It reduces comparing times to about one seventh of traditional method without hurting NED accuracy.",
                "We also have presented two extensions to the basic TF-IDF model.",
                "The first extension is made by adjust term weights based on term distributions between the whole corpus and a cluster story set.",
                "And the second extension to basic TF-IDF model is better use of term types (named entities types and part-of-speed) according to news categories.",
                "Our experimental results on TDT2 and TDT3 datasets show that both of the two extensions contribute significantly to improvement in accuracy.",
                "We did not consider news time information as a clue for NED task, since most of the topics last for a long time and TDT data sets only span for a relative short period (no more than 6 months).",
                "For the future work, we want to collect news set which span for a longer period from internet, and integrate time information in NED task.",
                "Since topic is a relative coarse-grained news cluster, we also want to refine cluster granularity to event-level, and identify different events and their relations within a topic.",
                "Acknowledgments This work is supported by the National Natural Science Foundation of China under Grant No. 90604025.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] In Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. .01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90 1 2 5 10 20 40 60 80 90 False Alarm Probability (in %) MissProbability(in%) SYSTEM1 Topic Weighted Curve SYSTEM1 Min Norm(Cost) SYSTEM2 Topic Weighted Curve SYSTEM2 Min Norm(Cost) SYSTEM3 Topic Weighted Curve SYSTEM3 Min Norm(Cost) SYSTEM4 Topic Weighted Curve SYSTEM4 Min Norm(Cost) SYSTEM5 Topic Weighted Curve SYSTEM5 Min Norm(Cost) Random Performance Figure 5.",
                "DET curves on TDT3 [3] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B.T.",
                "Archibald, and X. Liu.",
                "Learning Approaches for Detecting and Tracking News Events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), 1999, 32-43. [4] Y. Yang, T. Pierce, and J. Carbonell.",
                "A Study on Retrospective and On-line Event Detection.",
                "In Proceedings of SIGIR-98, Melbourne, Australia, 1998, 28-36. [5] J. Allan, V. Lavrenko, D. Malin, and R. Swan.",
                "Detections, Bounds, and Timelines: Umass and tdt-3.",
                "In Proceedings of Topic Detection and Tracking Workshop (TDT-3), Vienna, VA, 2000, 167-174. [6] R. Papka and J. Allan.",
                "On-line New Event Detection Using Single Pass Clustering TITLE2:.",
                "Technical Report UM-CS1998-021, 1998. [7] W. Lam, H. Meng, K. Wong, and J.",
                "Yen.",
                "Using Contextual Analysis for News Event Detection.",
                "International Journal on Intelligent Systems, 2001, 525-546. [8] B. Thorsten, C. Francine, and F. Ayman.",
                "A System for New Event Detection.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2003, 330-337. [9] S. Nicola and C. Joe.",
                "Combining Semantic and Syntactic Document Classifiers to Improve First Story Detection.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2001, 424425. [10] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topicconditioned Novelty Detection.",
                "In Proceedings of the 8th ACM SIGKDD International Conference, ACM Press. 2002, 688-693. [11] M. Juha, A.M. Helena, and S. Marko.",
                "Applying Semantic Classes in Event Detection and Tracking.",
                "In Proceedings of International Conference on Natural Language Processing (ICON 2002), 2002, pages 175-183. [12] M. Juha, A.M. Helena, and S. Marko.",
                "Simple Semantics in Topic Detection and Tracking.",
                "Information Retrieval, 7(3-4): 2004, 347-368. [13] K. Giridhar and J. Allan.",
                "Text Classification and Named Entities for New Event Detection.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2004, 297-304. [14] J. P. Callan, W. B. Croft, and S. M. Harding.",
                "The INQUERY Retrieval System.",
                "In Proceedings of DEXA-92, 3rd International Conference on Database and Expert Systems Applications, 1992, 78-83. [15] R. Krovetz.",
                "Viewing Morphology as An Inference Process.",
                "In Proceedings of ACM SIGIR93, 1993, 61-81. [16] Y. Yang and J. Pedersen.",
                "A Comparative Study on Feature Selection in Text Categorization.",
                "In J. D. H. Fisher, editor, The Fourteenth International Conference on Machine Learning (ICML97), Morgan Kaufmann, 1997, 412-420. [17] T. M. Cover, and J.A.",
                "Thomas.",
                "Elements of Information Theory.",
                "Wiley. 1991. [18] The linguistic data consortium, http://www.ldc,upenn.edu/. [19] The 2001 TDT task definition and evaluation plan, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm. [20] R. E. Schapire and Y.",
                "Singer.",
                "Boostexter: A Boosting-based System for Text Categorization.",
                "In Machine Learning 39(2/3):1, Kluwer Academic Publishers, 2000, 35-168. [21] K. Giridhar and J. Allan. 2005.",
                "Using Names and Topics for New Event Detection.",
                "In Proceedings of Human Technology Conference and Conference on Empirical Methods in Natural Language, Vancouver, 2005, 121-128"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "En el primer enfoque, proponemos ajustar los pesos de los términos basados dinámicamente en los grupos de historias anteriores y en el segundo enfoque, proponemos emplear estadísticas sobre \"datos de capacitación\" para aprender el modelo de peso de la entidad nombrado para cada clase de historias.",
                "En este enfoque, la información del clúster (tema) se usa correctamente, por lo que se evita el problema de la descentralización del tema.(3)"
            ],
            "translated_text": "",
            "candidates": [
                "datos de entrenamiento",
                "datos de capacitación",
                "Basado en las observaciones sobre las estadísticas obtenidas de los \"datos de capacitación\", encontramos que los términos de diferentes tipos (por ejemplo, datos de capacitación",
                "datos de capacitación"
            ],
            "error": []
        },
        "named entity reweighting mode": {
            "translated_key": "Modo de rewes -weighting de la entidad nombrada",
            "is_in_text": true,
            "original_annotated_sentences": [
                "New Event Detection Based on Indexing-tree and Named Entity Zhang Kuo Tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn Li Juan Zi Tsinghua University Beijing, 100084, China 86-10-62781461 ljz@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn ABSTRACT New Event Detection (NED) aims at detecting from one or multiple streams of news stories that which one is reported on a new event (i.e.",
                "not reported previously).",
                "With the overwhelming volume of news available today, there is an increasing need for a NED system which is able to detect new events more efficiently and accurately.",
                "In this paper we propose a new NED model to speed up the NED task by using news indexing-tree dynamically.",
                "Moreover, based on the observation that terms of different types have different effects for NED task, two term reweighting approaches are proposed to improve NED accuracy.",
                "In the first approach, we propose to adjust term weights dynamically based on previous story clusters and in the second approach, we propose to employ statistics on training data to learn the <br>named entity reweighting mode</br>l for each class of stories.",
                "Experimental results on two Linguistic Data Consortium (LDC) datasets TDT2 and TDT3 show that the proposed model can improve both efficiency and accuracy of NED task significantly, compared to the baseline system and other existing systems.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Search and Retrieval; H.4.2 [Information Systems Applications]: Types of Systemsdecision support.",
                "General Terms Algorithms, Performance, Experimentation 1.",
                "INTRODUCTION Topic Detection and Tracking (TDT) program aims to develop techniques which can effectively organize, search and structure news text materials from a variety of newswire and broadcast media [1].",
                "New Event Detection (NED) is one of the five tasks in TDT.",
                "It is the task of online identification of the earliest report for each topic as soon as that report arrives in the sequence of documents.",
                "A Topic is defined as a seminal event or activity, along with directly related events and activities [2].",
                "An Event is defined as something (non-trivial) happening in a certain place at a certain time [3].",
                "For instance, when a bomb explodes in a building, the exploding is the seminal event that triggers the topic, and other stories on the same topic would be those discussing salvaging efforts, the search for perpetrators, arrests and trial and so on.",
                "Useful news information is usually buried in a mass of data generated everyday.",
                "Therefore, NED systems are very useful for people who need to detect novel information from real-time news stream.",
                "These real-life needs often occur in domains like financial markets, news analysis, and intelligence gathering.",
                "In most of state-of-the-art (currently) NED systems, each news story on hand is compared to all the previous received stories.",
                "If all the similarities between them do not exceed a threshold, then the story triggers a new event.",
                "They are usually in the form of cosine similarity or Hellinger similarity metric.",
                "The core problem of NED is to identify whether two stories are on the same topic.",
                "Obviously, these systems cannot take advantage of topic information.",
                "Further more, it is not acceptable in real applications because of the large amount of computation required in the NED process.",
                "Other systems organize previous stories into clusters (each cluster corresponds to a topic), and new story is compared to the previous clusters instead of stories.",
                "This manner can reduce comparing times significantly.",
                "Nevertheless, it has been proved that this manner is less accurate [4, 5].",
                "This is because sometimes stories within a topic drift far away from each other, which could lead low similarity between a story and its topic.",
                "On the other hand, some proposed NED systems tried to improve accuracy by making better use of named entities [10, 11, 12, 13].",
                "However, none of the systems have considered that terms of different types (e.g.",
                "Noun, Verb or Person name) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "For example, the names of election candidates (Person name) are very important for stories of election class; the locations (Location name) where accidents happened are important for stories of accidents class.",
                "So, in NED, there still exist following three problems to be investigated: (1) How to speed up the detection procedure while do not decrease the detection accuracy? (2) How to make good use of cluster (topic) information to improve accuracy? (3) How to obtain better news story representation by better understanding of named entities.",
                "Driven by these problems, we have proposed three approaches in this paper. (1)To make the detection procedure faster, we propose a new NED procedure based on news indexing-tree created dynamically.",
                "Story indexing-tree is created by assembling similar stories together to form news clusters in different hierarchies according to their values of similarity.",
                "Comparisons between current story and previous clusters could help find the most similar story in less comparing times.",
                "The new procedure can reduce the amount of comparing times without hurting accuracy. (2)We use the clusters of the first floor in the indexing-tree as news topics, in which term weights are adjusted dynamically according to term distribution in the clusters.",
                "In this approach, cluster (topic) information is used properly, so the problem of theme decentralization is avoided. (3)Based on observations on the statistics obtained from training data, we found that terms of different types (e.g.",
                "Noun and Verb) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "And we propose to use statistics to optimize the weights of the terms of different types in a story according to the news class that the story belongs to.",
                "On TDT3 dataset, the new NED model just uses 14.9% comparing times of the basic model, while its minimum normalized cost is 0.5012, which is 0.0797 better than the basic model, and also better than any other results previously reported for this dataset [8, 13].",
                "The rest of the paper is organized as follows.",
                "We start off this paper by summarizing the previous work in NED in section 2.",
                "Section 3 presents the basic model for NED that most current systems use.",
                "Section 4 describes our new detection procedure based on news indexing-tree.",
                "In section 5, two term reweighting methods are proposed to improve NED accuracy.",
                "Section 6 gives our experimental data and evaluation metrics.",
                "We finally wrap up with the experimental results in Section 7, and the conclusions and future work in Section 8. 2.",
                "RELATED WORK Papka et al. proposed Single-Pass clustering on NED [6].",
                "When a new story was encountered, it was processed immediately to extract term features and a query representation of the storys content is built up.",
                "Then it was compared with all the previous queries.",
                "If the document did not trigger any queries by exceeding a threshold, it was marked as a new event.",
                "Lam et al build up previous query representations of story clusters, each of which corresponds to a topic [7].",
                "In this manner comparisons happen between stories and clusters.",
                "Recent years, most work focus on proposing better methods on comparison of stories and document representation.",
                "Brants et al. [8] extended a basic incremental TF-IDF model to include sourcespecific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, term reweighting based on inverse event frequencies, and segmentation of documents.",
                "Good improvements on TDT bench-marks were shown.",
                "Stokes et al. [9] utilized a combination of evidence from two distinct representations of a documents content.",
                "One of the representations was the usual free text vector, the other made use of lexical chains (created using WordNet) to build another term vector.",
                "Then the two representations are combined in a linear fashion.",
                "A marginal increase in effectiveness was achieved when the combined representation was used.",
                "Some efforts have been done on how to utilize named entities to improve NED.",
                "Yang et al. gave location named entities four times weight than other terms and named entities [10].",
                "DOREMI research group combined semantic similarities of person names, location names and time together with textual similarity [11][12].",
                "UMass [13] research group split document representation into two parts: named entities and non-named entities.",
                "And it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation.",
                "Both [10] and [13] used text categorization technique to classify news stories in advance.",
                "In [13] news stories are classified automatically at first, and then test sensitivities of names and non-name terms for NED for each class.",
                "In [10] frequent terms for each class are removed from document representation.",
                "For example, word election does not help identify different elections.",
                "In their work, effectiveness of different kinds of names (or terms with different POS) for NED in different news classes are not investigated.",
                "We use statistical analysis to reveal the fact and use it to improve NED performance. 3.",
                "BASIC MODEL In this section, we present the basic New Event Detection model which is similar to what most current systems apply.",
                "Then, we propose our new model by extending the basic model.",
                "New Event Detection systems use news story stream as input, in which stories are strictly time-ordered.",
                "Only previously received stories are available when dealing with current story.",
                "The output is a decision for whether the current story is on a new event or not and the confidence of the decision.",
                "Usually, a NED model consists of three parts: story representation, similarity calculation and detection procedure. 3.1 Story Representation Preprocessing is needed before generating story representation.",
                "For preprocessing, we tokenize words, recognize abbreviations, normalize abbreviations, add part-of-speech tags, remove stopwords included in the stop list used in InQuery [14], replace words with their stems using K-stem algorithm[15], and then generate word vector for each news story.",
                "We use incremental TF-IDF model for term weight calculation [4].",
                "In a TF-IDF model, term frequency in a news document is weighted by the inverse document frequency, which is generated from training corpus.",
                "When a new term occurs in testing process, there are two solutions: simply ignore the new term or set df of the term as a small const (e.g. df = 1).",
                "The new term receives too low weight in the first solution (0) and too high weight in the second solution.",
                "In incremental TF-IDF model, document frequencies are updated dynamically in each time step t: 1( ) ( ) ( )t t D tdf w df w df w−= + (1) where Dt represents news story set received in time t, and dfDt(w) means the number of documents that term w occurs in, and dft(w) means the total number of documents that term w occurs in before time t. In this work, each time window includes 50 news stories.",
                "Thus, each story d received in t is represented as follows: 1 2{ ( , , ), ( , , ),..., ( , , )}nd weight d t w weight d t w weight d t w→ where n means the number of distinct terms in story d, and ( , , )weight d t w means the weight of term w in story d at time t: log( ( , ) 1) log(( 1) /( ( ) 0.5)) ( , , ) log( ( , ) 1) log(( 1) /( ( ) 0.5)) t t t t w d tf d w N df w weight d t w tf d w N df w ∈ + + + = + + +∑ (2) where Nt means the total number of news stories before time t, and tf(d,w) means how many times term w occurs in news story d. 3.2 Similarity Calculation We use Hellinger distance for the calculation of similarity between two stories, for two stories d and d at time t, their similarity is defined as follows: , ( , , ) ( , , ) * ( , , ) w d d sim d d t weight d t w weight d t w ∈ = ∑ (3) 3.3 Detection Procedure For each story d received in time step t, the value ( ) ( ) ( ) ( ( , , )) time d time d n d max sim d d t < = (4) is a score used to determine whether d is a story about a new topic and at the same time is an indication of the confidence in our decision [8]. time(d) means the publication time of story d. If the score exceeds the thresholdθ new, then there exists a sufficiently similar document, thus d is a old story, otherwise, there is no sufficiently similar previous document, thus d is an new story. 4.",
                "New NED Procedure Traditional NED systems can be classified into two main types on the aspect of detection procedure: (1) S-S type, in which the story on hand is compared to each story received previously, and use the highest similarity to determine whether current story is about a new event; (2) S-C type, in which the story on hand is compared to all previous clusters each of which representing a topic, and the highest similarity is used for final decision for current story.",
                "If the highest similarity exceeds thresholdθ new, then it is an old story, and put it into the most similar cluster; otherwise it is a new story and create a new cluster.",
                "Previous work show that the first manner is more accurate than the second one [4][5].",
                "Since sometimes stories within a topic drift far away from each other, a story may have very low similarity with its topic.",
                "So using similarities between stories for determining new story is better than using similarities between story and clusters.",
                "Nevertheless, the first manner needs much more comparing times which means the first manner is low efficient.",
                "We propose a new detection procedure which uses comparisons with previous clusters to help find the most similar story in less comparing times, and the final new event decision is made according to the most similar story.",
                "Therefore, we can get both the accuracy of S-S type methods and the efficiency of S-C type methods.",
                "The new procedure creates a news indexing-tree dynamically, in which similar stories are put together to form a hierarchy of clusters.",
                "We index similar stories together by their common ancestor (a cluster node).",
                "Dissimilar stories are indexed in different clusters.",
                "When a story is coming, we use comparisons between the current story and previous hierarchical clusters to help find the most similar story which is useful for new event decision.",
                "After the new event decision is made, the current story is inserted to the indexing-tree for the following detection.",
                "The news indexing-tree is defined formally as follows: S-Tree = {r, NC , NS , E} where r is the root of S-Tree, NC is the set of all cluster nodes, NS is the set of all story nodes, and E is the set of all edges in S-Tree.",
                "We define a set of constraints for a S-Tree: ⅰ . , is an non-terminal node in the treeC i i N i∀ ∈ → ⅱ . , is a terminal node in the treeS i i N i∀ ∈ → ⅲ . , out degree of is at least 2C i i N i∀ ∈ → ⅳ . , is represented as the centroid of its desendantsC i i iN∀ ∈ → For a news story di, the comparison procedure and inserting procedure based on indexing-tree are defined as follows.",
                "An example is shown by Figure 1 and Figure 2.",
                "Figure 1.",
                "Comparison procedure Figure 2.",
                "Inserting procedure Comparison procedure: Step 1: compare di to all the direct child nodes of r and select λ nodes with highest similarities, e.g., C1 2 and C1 3 in Figure 1.",
                "Step 2: for each selected node in the last step, e.g.",
                "C1 2, compare di to all its direct child nodes, and select λ nodes with highest similarities, e.g.",
                "C2 2 and d8.",
                "Repeat step 2 for all non-terminal nodes.",
                "Step 3: record the terminal node with the highest similarty to di, e.g. s5, and the similarity value (0.20).",
                "Inserting di to the S-tree with r as root: Find the node n which is direct child of r in the path from r to the terminal node with highest similarity s, e.g.",
                "C1 2.",
                "If s is smaller than θ init+(h-1)δ , then add di to the tree as a direct child of r. Otherwise, if n is a terminal node, then create a cluster node instead of n, and add both n and di as its direct children; if n is an non-terminal node, then repeat this procedure and insert di to the sub-tree with n as root recursively.",
                "Here h is the length between n and the root of S-tree.",
                "The more the stories in a cluster similar to each other, the better the cluster represents the stories in it.",
                "Hence we add no constraints on the maximum of trees height and degree of a node.",
                "Therefore, we cannot give the complexity of this indexing-tree based procedure.",
                "But we will give the number of comparing times needed by the new procedure in our experiments in section7. 5.",
                "Term Reweighting Methods In this section, two term reweighting methods are proposed to improve NED accuracy.",
                "In the first method, a new way is explored for better using of cluster (topic) information.",
                "The second one finds a better way to make use of named entities based on news classification. 5.1 Term Reweighting Based on Distribution Distance TF-IDF is the most prevalent model used in information retrieval systems.",
                "The basic idea is that the fewer documents a term appears in, the more important the term is in discrimination of documents (relevant or not relevant to a query containing the term).",
                "Nevertheless, in TDT domain, we need to discriminate documents with regard to topics rather than queries.",
                "Intuitively, using cluster (topic) vectors to compare with subsequent news stories should outperform using story vectors.",
                "Unfortunately, the experimental results do not support this intuition [4][5].",
                "Based on observation on data, we find the reason is that a news topic usually contains many directly or indirectly related events, while they all have their own sub-subjects which are usually different with each other.",
                "Take the topic described in section 1 as an example, events like the explosion and salvage have very low similarities with events about criminal trial, therefore stories about trial would have low similarity with the topic vector built on its previous events.",
                "This section focuses on how to effectively make use of topic information and at the same time avoid the problem of content decentralization.",
                "At first, we classify terms into 5 classes to help analysis the needs of the modified model: Term class A: terms that occur frequently in the whole corpus, e.g., year and people.",
                "Terms of this class should be given low weights because they do not help much for topic discrimination.",
                "Term class B: terms that occur frequently within a news category, e.g., election, storm.",
                "They are useful to distinguish two stories in different news categories.",
                "However, they cannot provide information to determine whether two stories are on the same or different topics.",
                "In another words, term election and term storm are not helpful in differentiate two election campaigns and two storm disasters.",
                "Therefore, terms of this class should be assigned lower weights.",
                "Term class C: terms that occur frequently in a topic, and infrequently in other topics, e.g., the name of a crash plane, the name of a specific hurricane.",
                "News stories that belong to different topics rarely have overlap terms in this class.",
                "The more frequently a term appears in a topic, the more important the term is for a story belonging to the topic, therefore the term should be set higher weight.",
                "Term class D: terms that appear in a topic exclusively, but not frequently.",
                "For example, the name of a fireman who did very well in a salvage action, which may appears in only two or three stories but never appeared in other topics.",
                "Terms of this type should receive more weights than in TF-IDF model.",
                "However, since they are not popular in the topic, it is not appropriate to give them too high weights.",
                "Term class E: terms with low document frequency, and appear in different topics.",
                "Terms of this class should receive lower weights.",
                "Now we analyze whether TF-IDF model can give proper weights to the five classes of terms.",
                "Obviously, terms of class A are lowly weighted in TF-IDF model, which is conformable with the requirement described above.",
                "In TF-IDF model, terms of class B are highly dependant with the number of stories in a news class.",
                "TF-IDF model cannot provide low weights if the story containing the term belongs to a relative small news class.",
                "For a term of class C, the more frequently it appears in a topic, the less weight TFIDF model gives to it.",
                "This strongly conflicts with the requirement of terms in class C. For terms of class D, TF-IDF model gives them high weights correctly.",
                "But for terms of class E, TF-IDF model gives high weights to them which are not conformable with the requirement of low weights.",
                "To sum up, terms of class B, C, E cannot be properly weighted in TF-IDF model.",
                "So, we propose a modified model to resolve this problem.",
                "When θ init andθ new are set closely, we assume that most of the stories in a first-level cluster (a direct child node of root node) are on the same topic.",
                "Therefore, we make use of a first-level cluster to capture term distribution (df for all the terms within the cluster) within the topic dynamically.",
                "KL divergence of term distribution in a first-level cluster and the whole story set is used to adjust term weights:  ( , , ) * (1 * ( || )) ( , , ) ( , , ) * (1 * ( || )) cw tw cw tw w d D weight d t w KL P P weight d t w weight d t w KL P P γ γ ∈ + = +∑ (5) where ( ) ( ) ( ) ( ) 1,cw cw c c c c df w df w p y p y N N = = − (6) ( ) ( ) ( ) ( ) 1,t t tw tw t t df w df w p y p y N N = = − (7) where dfc(w) is the number of documents containing term w within cluster C, and Nc is the number of documents in cluster C, and Nt is the total number of documents that arrive before time step t. γ is a const parameter, now is manually set 3.",
                "KL divergence is defined as follows [17]: ( ) ( || ) ( ) log ( )x p x KL P Q p x q x = ∑ (8) The basic idea is: for a story in a topic, the more a term occurs within the topic, and the less it occurs in other topics, it should be assigned higher weights.",
                "Obviously, modified model can meet all the requirements of the five term classes listed above. 5.2 Term Reweighting Based on Term Type and Story Class Previous work found that some classes of news stories could achieve good improvements by giving extra weight to named entities.",
                "But we find that terms of different types should be given different amount of extra weight for different classes of news stories.",
                "We use open-NLP1 to recognize named entity types and part-ofspeech tags for terms that appear in news stories.",
                "Named entity types include person name, organization name, location name, date, time, money and percentage, and five POSs are selected: none (NN), verb (VB), adjective (JJ), adverb (RB) and cardinal number (CD).",
                "Statistical analysis shows topic-level discriminative terms types for different classes of stories.",
                "For the sake of convenience, named entity type and part-of-speech tags are uniformly called term type in subsequent sections.",
                "Determining whether two stories are about the same topic is a basic component for NED task.",
                "So at first we use 2 χ statistic to compute correlations between terms and topics.",
                "For a term t and a topic T, a contingence table is derived: Table 1.",
                "A 2×2 Contingence Table Doc Number belong to topic T not belong to topic T include t A B not include t C D The 2 χ statistic for a specific term t with respect to topic T is defined to be [16]: 2 2 ( , ) ( ) * ( ) ( ) * ( ) * ( ) * ( ) w T A B C D AD CB A C B D A B C D χ = + + + − + + + + (9) News topics for the TDT task are further classified into 11 rules of interpretations (ROIs) 2 .",
                "The ROI can be seen as a higher level class of stories.",
                "The average correlation between a term type and a topic ROI is computed as: 2 avg 2 ( , )( ( , ) )k m m km kT R w P w TP R p w T R P χ χ ∈ ∈ ∑ ∑（ , ）= 1 1 k=1…K, m=1…M (10) where K is the number of term types (set 12 constantly in the paper).",
                "M is the number news classes (ROIs, set 11 in the paper).",
                "Pk represents the set of all terms of type k, and Rm represents the set of all topics of class m, p(t,T) means the probability that t occurs in topic T. Because of limitation of space, only parts of the term types (9 term types) and parts of news classes (8 classes) are listed in table 2 with the average correlation values between them.",
                "The statistics is derived from labeled data in TDT2 corpus. (Results in table 2 are already normalized for convenience in comparison.)",
                "The statistics in table 2 indicates the usefulness of different term types in topic discrimination with respect to different news classes.",
                "We can see that, location name is the most useful term type for three news classes: Natural Disasters, Violence or War, Finances.",
                "And for three other categories Elections, Legal/Criminal Cases, Science and Discovery, person name is the most discriminative term type.",
                "For Scandals/Hearings, date is the most important information for topic discrimination.",
                "In addition, Legal/Criminal Cases and Finance topics have higher correlation with money terms, while Science and Discovery have higher correlation with percentage terms.",
                "Non-name terms are more stable for different classes. 1 . http://opennlp.sourceforge.net/ 2 . http://projects.ldc.upenn.edu/TDT3/Guide/label.html From the analysis of table 2, it is reasonable to adjust term weight according to their term type and the news class the story belongs to.",
                "New term weights are reweighted as follows: ( ) ( ) ( ) ( ) ( , , ) * ( , , ) ( , , ) * class d D type w T class d D type w w d weight d t w weight d t w weight d t w α α ∈ = ∑ (11) where type(w) represents the type of term w, and class(d) represents the class of story d, c kα is reweighting parameter for news class c and term type k. In the work, we just simply use statistics in table 2 as the reweighting parameters.",
                "Even thought using the statistics directly may not the best choice, we do not discuss how to automatically obtain the best parameters.",
                "We will try to use machine learning techniques to obtain the best parameters in the future work.",
                "In the work, we use BoosTexter [20] to classify all stories into one of the 11 ROIs.",
                "BoosTexter is a boosting based machine learning program, which creates a series of simple rules for building a classifier for text or attribute-value data.",
                "We use term weight generated using TF-IDF model as feature for story classification.",
                "We trained the model on the 12000 judged English stories in TDT2, and classify the rest of the stories in TDT2 and all stories in TDT3.",
                "Classification results are used for term reweighting in formula (11).",
                "Since the class labels of topic-off stories are not given in TDT datasets, we cannot give the classification accuracy here.",
                "Thus we do not discuss the effects of classification accuracy to NED performance in the paper. 6.",
                "EXPERIMENTAL SETUP 6.1 Datasets We used two LDC [18] datasets TDT2 and TDT3 for our experiments.",
                "TDT2 contains news stories from January to June 1998.",
                "It contains around 54,000 stories from sources like ABC, Associated Press, CNN, New York Times, Public Radio International, Voice of America etc.",
                "Only English stories in the collection were considered.",
                "TDT3 contains approximately 31,000 English stories collected from October to December 1998.",
                "In addition to the sources used in TDT2, it also contains stories from NBC and MSNBC TV broadcasts.",
                "We used transcribed versions of the TV and radio broadcasts besides textual news.",
                "TDT2 dataset is labeled with about 100 topics, and approximately 12,000 English stories belong to at least one of these topics.",
                "TDT3 dataset is labeled with about 120 topics, and approximately 8000 English stories belong to at least one of these topics.",
                "All the topics are classified into 11 Rules of Interpretation: (1)Elections, (2)Scandals/Hearings, (3)Legal/Criminal Cases, (4)Natural Disasters, (5)Accidents, (6)Ongoing Violence or War, (7)Science and Discovery News, (8)Finance, (9)New Law, (10)Sports News, (11)MISC.",
                "News. 6.2 Evaluation Metric TDT uses a cost function CDet that combines the probabilities of missing a new story and a false alarm [19]: * * * *Det Miss Miss Target FA FA NontargetC C P P C P P= + (12) Table 2.",
                "Average correlation between term types and news classes where CMiss means the cost of missing a new story, PMiss means the probability of missing a new story, and PTarget means the probability of seeing a new story in the data; CFA means the cost of a false alarm, PFA means the probability of a false alarm, and PNontarget means the probability of seeing an old story.",
                "The cost CDet is normalized such that a perfect system scores 0 and a trivial system, which is the better one of mark all stories as new or old, scores 1: ( ( * , * ) ) Det Det Miss Target FA Nontarget C Norm C min C P C P = (13) New event detection system gives two outputs for each story.",
                "The first part is yes or no indicating whether the story triggers a new event or not.",
                "The second part is a score indicating confidence of the first decision.",
                "Confidence scores can be used to plot DET curve, i.e., curves that plot false alarm vs. miss probabilities.",
                "Minimum normalized cost can be determined if optimal threshold on the score were chosen. 7.",
                "EXPERIMENTAL RESULTS 7.1 Main Results To test the approaches proposed in the model, we implemented and tested five systems: System-1: this system is used as baseline.",
                "It is implemented based on the basic model described in section 3, i.e., using incremental TF-IDF model to generate term weights, and using Hellinger distance to compute document similarity.",
                "Similarity score normalization is also employed [8].",
                "S-S detection procedure is used.",
                "System-2: this system is the same as system-1 except that S-C detection procedure is used.",
                "System-3: this system is the same as system-1 except that it uses the new detection procedure which is based on indexing-tree.",
                "System-4: implemented based on the approach presented in section 5.1, i.e., terms are reweighted according to the distance between term distributions in a cluster and all stories.",
                "The new detection procedure is used.",
                "System-5: implemented based on the approach presented in section 5.2, i.e., terms of different types are reweighted according to news class using trained parameters.",
                "The new detection procedure is used.",
                "The following are some other NED systems: System-6: [21] for each pair of stories, it computes three similarity values for named entity, non-named entity and all terms respectively.",
                "And employ Support Vector Machine to predict new or old using the similarity values as features.",
                "System-7: [8] it extended a basic incremental TF-IDF model to include source-specific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, etc.",
                "System-8: [13] it split document representation into two parts: named entities and non-named entities, and choose one effective part for each news class.",
                "Table 3 and table 4 show topic-weighted normalized costs and comparing times on TDT2 and TDT3 datasets respectively.",
                "Since no heldout data set for fine-tuning the threshold θ new was available for experiments on TDT2, we only report minimum normalized costs for our systems in table 3.",
                "System-5 outperforms all other systems including system-6, and it performs only 2.78e+8 comparing times in detection procedure which is only 13.4% of system-1.",
                "Table 3.",
                "NED results on TDT2 Systems Min Norm(CDet) Cmp times System-1 0.5749 2.08e+9 System-2① 0.6673 3.77e+8 System-3② 0.5765 2.81e+8 System-4② 0.5431 2.99e+8 System-5② 0.5089 2.78e+8 System-6 0.5300 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 When evaluating on the normalized costs on TDT3, we use the optimal thresholds obtained from TDT2 data set for all systems.",
                "System-2 reduces comparing times to 1.29e+9 which is just 18.3% of system-1, but at the same time it also gets a deteriorated minimum normalized cost which is 0.0499 higher than system-1.",
                "System-3 uses the new detection procedure based on news indexing-tree.",
                "It requires even less comparing times than system-2.",
                "This is because story-story comparisons usually yield greater similarities than story-cluster ones, so stories tend to be combined Location Person Date Organization Money Percentage NN JJ CD Elections 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 Scandals/Hearings 0.66 0.62 0.28 1 0.11 0.02 0.27 0.13 0.05 Legal/Criminal Cases 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 Natural Disasters 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 Violence or War 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 Science and Discovery 0.11 1 0.01 0.22 0.08 0.12 0.19 0.08 0.03 Finances 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 Sports 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 together in system-3.",
                "And system-3 is basically equivalent to system-1 in accuracy results.",
                "System-4 adjusts term weights based on the distance of term distributions between the whole corpus and cluster story set, yielding a good improvement by 0.0468 compared to system-1.",
                "The best system (system-5) has a minimum normalized cost 0.5012, which is 0.0797 better than system-1, and also better than any other results previously reported for this dataset [8, 13].",
                "Further more, system-5 only needs 1.05e+8 comparing times which is 14.9% of system-1.",
                "Table 4.",
                "NED results on TDT3 Systems Norm(CDet) Min Norm(CDet) Cmp times System-1 0.6159 0.5809 7.04e+8 System-2① 0.6493 0.6308 1.29e+8 System-3② 0.6197 0.5868 1.03e+8 System-4② 0.5601 0.5341 1.03e+8 System-5② 0.5413 0.5012 1.05e+8 System-7 -- 0.5783 -System-8 -- 0.5229 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 Figure5 shows the five DET curves for our systems on data set TDT3.",
                "System-5 achieves the minimum cost at a false alarm rate of 0.0157 and a miss rate of 0.4310.",
                "We can observe that System4 and System-5 obtain lower miss probability at regions of low false alarm probabilities.",
                "The hypothesis is that, more weight value is transferred to key terms of topics from non-key terms.",
                "Similarity score between two stories belonging to different topics are lower than before, because their overlapping terms are usually not key terms of their topics. 7.2 Parameter selection for indexing-tree detection Figure 3 shows the minimum normalized costs obtained by system-3 on TDT3 using different parameters.",
                "Theθ init parameter is tested on six values spanning from 0.03 to 0.18.",
                "And the λ parameter is tested on four values 1, 2, 3 and 4.",
                "We can see that, whenθ init is set to 0.12, which is the closest one toθ new, the costs are lower than others.",
                "This is easy to explain, because when stories belonging to the same topic are put in a cluster, it is more reasonable for the cluster to represent the stories in it.",
                "When parameter λ is set to 3 or 4, the costs are better than other cases, but there is no much difference between 3 and 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ MinCost 0.6 0.65 0.7 0.75 0.8 0.85 0.9 Figure 3.",
                "Min Cost on TDT3 (δ =0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ Comparingtimes 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 Figure 4.",
                "Comparing times on TDT3 (δ =0.15) Figure 4 gives the comparing times used by system-3 on TDT3 with the same parameters as figure 3.",
                "The comparing times are strongly dependent onθ init.",
                "Because the greaterθ init is, the less stories combined together, the more comparing times are needed for new event decision.",
                "So we useθ init =0.13,λ =3,δ =0.15 for system-3, 4, and 5.",
                "In this parameter setting, we can get both low minimum normalized costs and less comparing times. 8.",
                "CONCLUSION We have proposed a news indexing-tree based detection procedure in our model.",
                "It reduces comparing times to about one seventh of traditional method without hurting NED accuracy.",
                "We also have presented two extensions to the basic TF-IDF model.",
                "The first extension is made by adjust term weights based on term distributions between the whole corpus and a cluster story set.",
                "And the second extension to basic TF-IDF model is better use of term types (named entities types and part-of-speed) according to news categories.",
                "Our experimental results on TDT2 and TDT3 datasets show that both of the two extensions contribute significantly to improvement in accuracy.",
                "We did not consider news time information as a clue for NED task, since most of the topics last for a long time and TDT data sets only span for a relative short period (no more than 6 months).",
                "For the future work, we want to collect news set which span for a longer period from internet, and integrate time information in NED task.",
                "Since topic is a relative coarse-grained news cluster, we also want to refine cluster granularity to event-level, and identify different events and their relations within a topic.",
                "Acknowledgments This work is supported by the National Natural Science Foundation of China under Grant No. 90604025.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] In Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. .01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90 1 2 5 10 20 40 60 80 90 False Alarm Probability (in %) MissProbability(in%) SYSTEM1 Topic Weighted Curve SYSTEM1 Min Norm(Cost) SYSTEM2 Topic Weighted Curve SYSTEM2 Min Norm(Cost) SYSTEM3 Topic Weighted Curve SYSTEM3 Min Norm(Cost) SYSTEM4 Topic Weighted Curve SYSTEM4 Min Norm(Cost) SYSTEM5 Topic Weighted Curve SYSTEM5 Min Norm(Cost) Random Performance Figure 5.",
                "DET curves on TDT3 [3] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B.T.",
                "Archibald, and X. Liu.",
                "Learning Approaches for Detecting and Tracking News Events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), 1999, 32-43. [4] Y. Yang, T. Pierce, and J. Carbonell.",
                "A Study on Retrospective and On-line Event Detection.",
                "In Proceedings of SIGIR-98, Melbourne, Australia, 1998, 28-36. [5] J. Allan, V. Lavrenko, D. Malin, and R. Swan.",
                "Detections, Bounds, and Timelines: Umass and tdt-3.",
                "In Proceedings of Topic Detection and Tracking Workshop (TDT-3), Vienna, VA, 2000, 167-174. [6] R. Papka and J. Allan.",
                "On-line New Event Detection Using Single Pass Clustering TITLE2:.",
                "Technical Report UM-CS1998-021, 1998. [7] W. Lam, H. Meng, K. Wong, and J.",
                "Yen.",
                "Using Contextual Analysis for News Event Detection.",
                "International Journal on Intelligent Systems, 2001, 525-546. [8] B. Thorsten, C. Francine, and F. Ayman.",
                "A System for New Event Detection.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2003, 330-337. [9] S. Nicola and C. Joe.",
                "Combining Semantic and Syntactic Document Classifiers to Improve First Story Detection.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2001, 424425. [10] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topicconditioned Novelty Detection.",
                "In Proceedings of the 8th ACM SIGKDD International Conference, ACM Press. 2002, 688-693. [11] M. Juha, A.M. Helena, and S. Marko.",
                "Applying Semantic Classes in Event Detection and Tracking.",
                "In Proceedings of International Conference on Natural Language Processing (ICON 2002), 2002, pages 175-183. [12] M. Juha, A.M. Helena, and S. Marko.",
                "Simple Semantics in Topic Detection and Tracking.",
                "Information Retrieval, 7(3-4): 2004, 347-368. [13] K. Giridhar and J. Allan.",
                "Text Classification and Named Entities for New Event Detection.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2004, 297-304. [14] J. P. Callan, W. B. Croft, and S. M. Harding.",
                "The INQUERY Retrieval System.",
                "In Proceedings of DEXA-92, 3rd International Conference on Database and Expert Systems Applications, 1992, 78-83. [15] R. Krovetz.",
                "Viewing Morphology as An Inference Process.",
                "In Proceedings of ACM SIGIR93, 1993, 61-81. [16] Y. Yang and J. Pedersen.",
                "A Comparative Study on Feature Selection in Text Categorization.",
                "In J. D. H. Fisher, editor, The Fourteenth International Conference on Machine Learning (ICML97), Morgan Kaufmann, 1997, 412-420. [17] T. M. Cover, and J.A.",
                "Thomas.",
                "Elements of Information Theory.",
                "Wiley. 1991. [18] The linguistic data consortium, http://www.ldc,upenn.edu/. [19] The 2001 TDT task definition and evaluation plan, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm. [20] R. E. Schapire and Y.",
                "Singer.",
                "Boostexter: A Boosting-based System for Text Categorization.",
                "In Machine Learning 39(2/3):1, Kluwer Academic Publishers, 2000, 35-168. [21] K. Giridhar and J. Allan. 2005.",
                "Using Names and Topics for New Event Detection.",
                "In Proceedings of Human Technology Conference and Conference on Empirical Methods in Natural Language, Vancouver, 2005, 121-128"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "En el primer enfoque, proponemos ajustar los pesos de los términos basados dinámicamente en los grupos de historias anteriores y en el segundo enfoque, proponemos emplear estadísticas sobre datos de capacitación para aprender el \"modo de rewe -weighting de la entidad nombrado para cada clase de historias."
            ],
            "translated_text": "",
            "candidates": [
                "Modo de rewes -weighting de la entidad nombrada"
            ],
            "error": []
        },
        "class of story": {
            "translated_key": "clase de historia",
            "is_in_text": true,
            "original_annotated_sentences": [
                "New Event Detection Based on Indexing-tree and Named Entity Zhang Kuo Tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn Li Juan Zi Tsinghua University Beijing, 100084, China 86-10-62781461 ljz@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn ABSTRACT New Event Detection (NED) aims at detecting from one or multiple streams of news stories that which one is reported on a new event (i.e.",
                "not reported previously).",
                "With the overwhelming volume of news available today, there is an increasing need for a NED system which is able to detect new events more efficiently and accurately.",
                "In this paper we propose a new NED model to speed up the NED task by using news indexing-tree dynamically.",
                "Moreover, based on the observation that terms of different types have different effects for NED task, two term reweighting approaches are proposed to improve NED accuracy.",
                "In the first approach, we propose to adjust term weights dynamically based on previous story clusters and in the second approach, we propose to employ statistics on training data to learn the named entity reweighting model for each class of stories.",
                "Experimental results on two Linguistic Data Consortium (LDC) datasets TDT2 and TDT3 show that the proposed model can improve both efficiency and accuracy of NED task significantly, compared to the baseline system and other existing systems.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Search and Retrieval; H.4.2 [Information Systems Applications]: Types of Systemsdecision support.",
                "General Terms Algorithms, Performance, Experimentation 1.",
                "INTRODUCTION Topic Detection and Tracking (TDT) program aims to develop techniques which can effectively organize, search and structure news text materials from a variety of newswire and broadcast media [1].",
                "New Event Detection (NED) is one of the five tasks in TDT.",
                "It is the task of online identification of the earliest report for each topic as soon as that report arrives in the sequence of documents.",
                "A Topic is defined as a seminal event or activity, along with directly related events and activities [2].",
                "An Event is defined as something (non-trivial) happening in a certain place at a certain time [3].",
                "For instance, when a bomb explodes in a building, the exploding is the seminal event that triggers the topic, and other stories on the same topic would be those discussing salvaging efforts, the search for perpetrators, arrests and trial and so on.",
                "Useful news information is usually buried in a mass of data generated everyday.",
                "Therefore, NED systems are very useful for people who need to detect novel information from real-time news stream.",
                "These real-life needs often occur in domains like financial markets, news analysis, and intelligence gathering.",
                "In most of state-of-the-art (currently) NED systems, each news story on hand is compared to all the previous received stories.",
                "If all the similarities between them do not exceed a threshold, then the story triggers a new event.",
                "They are usually in the form of cosine similarity or Hellinger similarity metric.",
                "The core problem of NED is to identify whether two stories are on the same topic.",
                "Obviously, these systems cannot take advantage of topic information.",
                "Further more, it is not acceptable in real applications because of the large amount of computation required in the NED process.",
                "Other systems organize previous stories into clusters (each cluster corresponds to a topic), and new story is compared to the previous clusters instead of stories.",
                "This manner can reduce comparing times significantly.",
                "Nevertheless, it has been proved that this manner is less accurate [4, 5].",
                "This is because sometimes stories within a topic drift far away from each other, which could lead low similarity between a story and its topic.",
                "On the other hand, some proposed NED systems tried to improve accuracy by making better use of named entities [10, 11, 12, 13].",
                "However, none of the systems have considered that terms of different types (e.g.",
                "Noun, Verb or Person name) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "For example, the names of election candidates (Person name) are very important for stories of election class; the locations (Location name) where accidents happened are important for stories of accidents class.",
                "So, in NED, there still exist following three problems to be investigated: (1) How to speed up the detection procedure while do not decrease the detection accuracy? (2) How to make good use of cluster (topic) information to improve accuracy? (3) How to obtain better news story representation by better understanding of named entities.",
                "Driven by these problems, we have proposed three approaches in this paper. (1)To make the detection procedure faster, we propose a new NED procedure based on news indexing-tree created dynamically.",
                "Story indexing-tree is created by assembling similar stories together to form news clusters in different hierarchies according to their values of similarity.",
                "Comparisons between current story and previous clusters could help find the most similar story in less comparing times.",
                "The new procedure can reduce the amount of comparing times without hurting accuracy. (2)We use the clusters of the first floor in the indexing-tree as news topics, in which term weights are adjusted dynamically according to term distribution in the clusters.",
                "In this approach, cluster (topic) information is used properly, so the problem of theme decentralization is avoided. (3)Based on observations on the statistics obtained from training data, we found that terms of different types (e.g.",
                "Noun and Verb) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "And we propose to use statistics to optimize the weights of the terms of different types in a story according to the news class that the story belongs to.",
                "On TDT3 dataset, the new NED model just uses 14.9% comparing times of the basic model, while its minimum normalized cost is 0.5012, which is 0.0797 better than the basic model, and also better than any other results previously reported for this dataset [8, 13].",
                "The rest of the paper is organized as follows.",
                "We start off this paper by summarizing the previous work in NED in section 2.",
                "Section 3 presents the basic model for NED that most current systems use.",
                "Section 4 describes our new detection procedure based on news indexing-tree.",
                "In section 5, two term reweighting methods are proposed to improve NED accuracy.",
                "Section 6 gives our experimental data and evaluation metrics.",
                "We finally wrap up with the experimental results in Section 7, and the conclusions and future work in Section 8. 2.",
                "RELATED WORK Papka et al. proposed Single-Pass clustering on NED [6].",
                "When a new story was encountered, it was processed immediately to extract term features and a query representation of the storys content is built up.",
                "Then it was compared with all the previous queries.",
                "If the document did not trigger any queries by exceeding a threshold, it was marked as a new event.",
                "Lam et al build up previous query representations of story clusters, each of which corresponds to a topic [7].",
                "In this manner comparisons happen between stories and clusters.",
                "Recent years, most work focus on proposing better methods on comparison of stories and document representation.",
                "Brants et al. [8] extended a basic incremental TF-IDF model to include sourcespecific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, term reweighting based on inverse event frequencies, and segmentation of documents.",
                "Good improvements on TDT bench-marks were shown.",
                "Stokes et al. [9] utilized a combination of evidence from two distinct representations of a documents content.",
                "One of the representations was the usual free text vector, the other made use of lexical chains (created using WordNet) to build another term vector.",
                "Then the two representations are combined in a linear fashion.",
                "A marginal increase in effectiveness was achieved when the combined representation was used.",
                "Some efforts have been done on how to utilize named entities to improve NED.",
                "Yang et al. gave location named entities four times weight than other terms and named entities [10].",
                "DOREMI research group combined semantic similarities of person names, location names and time together with textual similarity [11][12].",
                "UMass [13] research group split document representation into two parts: named entities and non-named entities.",
                "And it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation.",
                "Both [10] and [13] used text categorization technique to classify news stories in advance.",
                "In [13] news stories are classified automatically at first, and then test sensitivities of names and non-name terms for NED for each class.",
                "In [10] frequent terms for each class are removed from document representation.",
                "For example, word election does not help identify different elections.",
                "In their work, effectiveness of different kinds of names (or terms with different POS) for NED in different news classes are not investigated.",
                "We use statistical analysis to reveal the fact and use it to improve NED performance. 3.",
                "BASIC MODEL In this section, we present the basic New Event Detection model which is similar to what most current systems apply.",
                "Then, we propose our new model by extending the basic model.",
                "New Event Detection systems use news story stream as input, in which stories are strictly time-ordered.",
                "Only previously received stories are available when dealing with current story.",
                "The output is a decision for whether the current story is on a new event or not and the confidence of the decision.",
                "Usually, a NED model consists of three parts: story representation, similarity calculation and detection procedure. 3.1 Story Representation Preprocessing is needed before generating story representation.",
                "For preprocessing, we tokenize words, recognize abbreviations, normalize abbreviations, add part-of-speech tags, remove stopwords included in the stop list used in InQuery [14], replace words with their stems using K-stem algorithm[15], and then generate word vector for each news story.",
                "We use incremental TF-IDF model for term weight calculation [4].",
                "In a TF-IDF model, term frequency in a news document is weighted by the inverse document frequency, which is generated from training corpus.",
                "When a new term occurs in testing process, there are two solutions: simply ignore the new term or set df of the term as a small const (e.g. df = 1).",
                "The new term receives too low weight in the first solution (0) and too high weight in the second solution.",
                "In incremental TF-IDF model, document frequencies are updated dynamically in each time step t: 1( ) ( ) ( )t t D tdf w df w df w−= + (1) where Dt represents news story set received in time t, and dfDt(w) means the number of documents that term w occurs in, and dft(w) means the total number of documents that term w occurs in before time t. In this work, each time window includes 50 news stories.",
                "Thus, each story d received in t is represented as follows: 1 2{ ( , , ), ( , , ),..., ( , , )}nd weight d t w weight d t w weight d t w→ where n means the number of distinct terms in story d, and ( , , )weight d t w means the weight of term w in story d at time t: log( ( , ) 1) log(( 1) /( ( ) 0.5)) ( , , ) log( ( , ) 1) log(( 1) /( ( ) 0.5)) t t t t w d tf d w N df w weight d t w tf d w N df w ∈ + + + = + + +∑ (2) where Nt means the total number of news stories before time t, and tf(d,w) means how many times term w occurs in news story d. 3.2 Similarity Calculation We use Hellinger distance for the calculation of similarity between two stories, for two stories d and d at time t, their similarity is defined as follows: , ( , , ) ( , , ) * ( , , ) w d d sim d d t weight d t w weight d t w ∈ = ∑ (3) 3.3 Detection Procedure For each story d received in time step t, the value ( ) ( ) ( ) ( ( , , )) time d time d n d max sim d d t < = (4) is a score used to determine whether d is a story about a new topic and at the same time is an indication of the confidence in our decision [8]. time(d) means the publication time of story d. If the score exceeds the thresholdθ new, then there exists a sufficiently similar document, thus d is a old story, otherwise, there is no sufficiently similar previous document, thus d is an new story. 4.",
                "New NED Procedure Traditional NED systems can be classified into two main types on the aspect of detection procedure: (1) S-S type, in which the story on hand is compared to each story received previously, and use the highest similarity to determine whether current story is about a new event; (2) S-C type, in which the story on hand is compared to all previous clusters each of which representing a topic, and the highest similarity is used for final decision for current story.",
                "If the highest similarity exceeds thresholdθ new, then it is an old story, and put it into the most similar cluster; otherwise it is a new story and create a new cluster.",
                "Previous work show that the first manner is more accurate than the second one [4][5].",
                "Since sometimes stories within a topic drift far away from each other, a story may have very low similarity with its topic.",
                "So using similarities between stories for determining new story is better than using similarities between story and clusters.",
                "Nevertheless, the first manner needs much more comparing times which means the first manner is low efficient.",
                "We propose a new detection procedure which uses comparisons with previous clusters to help find the most similar story in less comparing times, and the final new event decision is made according to the most similar story.",
                "Therefore, we can get both the accuracy of S-S type methods and the efficiency of S-C type methods.",
                "The new procedure creates a news indexing-tree dynamically, in which similar stories are put together to form a hierarchy of clusters.",
                "We index similar stories together by their common ancestor (a cluster node).",
                "Dissimilar stories are indexed in different clusters.",
                "When a story is coming, we use comparisons between the current story and previous hierarchical clusters to help find the most similar story which is useful for new event decision.",
                "After the new event decision is made, the current story is inserted to the indexing-tree for the following detection.",
                "The news indexing-tree is defined formally as follows: S-Tree = {r, NC , NS , E} where r is the root of S-Tree, NC is the set of all cluster nodes, NS is the set of all story nodes, and E is the set of all edges in S-Tree.",
                "We define a set of constraints for a S-Tree: ⅰ . , is an non-terminal node in the treeC i i N i∀ ∈ → ⅱ . , is a terminal node in the treeS i i N i∀ ∈ → ⅲ . , out degree of is at least 2C i i N i∀ ∈ → ⅳ . , is represented as the centroid of its desendantsC i i iN∀ ∈ → For a news story di, the comparison procedure and inserting procedure based on indexing-tree are defined as follows.",
                "An example is shown by Figure 1 and Figure 2.",
                "Figure 1.",
                "Comparison procedure Figure 2.",
                "Inserting procedure Comparison procedure: Step 1: compare di to all the direct child nodes of r and select λ nodes with highest similarities, e.g., C1 2 and C1 3 in Figure 1.",
                "Step 2: for each selected node in the last step, e.g.",
                "C1 2, compare di to all its direct child nodes, and select λ nodes with highest similarities, e.g.",
                "C2 2 and d8.",
                "Repeat step 2 for all non-terminal nodes.",
                "Step 3: record the terminal node with the highest similarty to di, e.g. s5, and the similarity value (0.20).",
                "Inserting di to the S-tree with r as root: Find the node n which is direct child of r in the path from r to the terminal node with highest similarity s, e.g.",
                "C1 2.",
                "If s is smaller than θ init+(h-1)δ , then add di to the tree as a direct child of r. Otherwise, if n is a terminal node, then create a cluster node instead of n, and add both n and di as its direct children; if n is an non-terminal node, then repeat this procedure and insert di to the sub-tree with n as root recursively.",
                "Here h is the length between n and the root of S-tree.",
                "The more the stories in a cluster similar to each other, the better the cluster represents the stories in it.",
                "Hence we add no constraints on the maximum of trees height and degree of a node.",
                "Therefore, we cannot give the complexity of this indexing-tree based procedure.",
                "But we will give the number of comparing times needed by the new procedure in our experiments in section7. 5.",
                "Term Reweighting Methods In this section, two term reweighting methods are proposed to improve NED accuracy.",
                "In the first method, a new way is explored for better using of cluster (topic) information.",
                "The second one finds a better way to make use of named entities based on news classification. 5.1 Term Reweighting Based on Distribution Distance TF-IDF is the most prevalent model used in information retrieval systems.",
                "The basic idea is that the fewer documents a term appears in, the more important the term is in discrimination of documents (relevant or not relevant to a query containing the term).",
                "Nevertheless, in TDT domain, we need to discriminate documents with regard to topics rather than queries.",
                "Intuitively, using cluster (topic) vectors to compare with subsequent news stories should outperform using story vectors.",
                "Unfortunately, the experimental results do not support this intuition [4][5].",
                "Based on observation on data, we find the reason is that a news topic usually contains many directly or indirectly related events, while they all have their own sub-subjects which are usually different with each other.",
                "Take the topic described in section 1 as an example, events like the explosion and salvage have very low similarities with events about criminal trial, therefore stories about trial would have low similarity with the topic vector built on its previous events.",
                "This section focuses on how to effectively make use of topic information and at the same time avoid the problem of content decentralization.",
                "At first, we classify terms into 5 classes to help analysis the needs of the modified model: Term class A: terms that occur frequently in the whole corpus, e.g., year and people.",
                "Terms of this class should be given low weights because they do not help much for topic discrimination.",
                "Term class B: terms that occur frequently within a news category, e.g., election, storm.",
                "They are useful to distinguish two stories in different news categories.",
                "However, they cannot provide information to determine whether two stories are on the same or different topics.",
                "In another words, term election and term storm are not helpful in differentiate two election campaigns and two storm disasters.",
                "Therefore, terms of this class should be assigned lower weights.",
                "Term class C: terms that occur frequently in a topic, and infrequently in other topics, e.g., the name of a crash plane, the name of a specific hurricane.",
                "News stories that belong to different topics rarely have overlap terms in this class.",
                "The more frequently a term appears in a topic, the more important the term is for a story belonging to the topic, therefore the term should be set higher weight.",
                "Term class D: terms that appear in a topic exclusively, but not frequently.",
                "For example, the name of a fireman who did very well in a salvage action, which may appears in only two or three stories but never appeared in other topics.",
                "Terms of this type should receive more weights than in TF-IDF model.",
                "However, since they are not popular in the topic, it is not appropriate to give them too high weights.",
                "Term class E: terms with low document frequency, and appear in different topics.",
                "Terms of this class should receive lower weights.",
                "Now we analyze whether TF-IDF model can give proper weights to the five classes of terms.",
                "Obviously, terms of class A are lowly weighted in TF-IDF model, which is conformable with the requirement described above.",
                "In TF-IDF model, terms of class B are highly dependant with the number of stories in a news class.",
                "TF-IDF model cannot provide low weights if the story containing the term belongs to a relative small news class.",
                "For a term of class C, the more frequently it appears in a topic, the less weight TFIDF model gives to it.",
                "This strongly conflicts with the requirement of terms in class C. For terms of class D, TF-IDF model gives them high weights correctly.",
                "But for terms of class E, TF-IDF model gives high weights to them which are not conformable with the requirement of low weights.",
                "To sum up, terms of class B, C, E cannot be properly weighted in TF-IDF model.",
                "So, we propose a modified model to resolve this problem.",
                "When θ init andθ new are set closely, we assume that most of the stories in a first-level cluster (a direct child node of root node) are on the same topic.",
                "Therefore, we make use of a first-level cluster to capture term distribution (df for all the terms within the cluster) within the topic dynamically.",
                "KL divergence of term distribution in a first-level cluster and the whole story set is used to adjust term weights:  ( , , ) * (1 * ( || )) ( , , ) ( , , ) * (1 * ( || )) cw tw cw tw w d D weight d t w KL P P weight d t w weight d t w KL P P γ γ ∈ + = +∑ (5) where ( ) ( ) ( ) ( ) 1,cw cw c c c c df w df w p y p y N N = = − (6) ( ) ( ) ( ) ( ) 1,t t tw tw t t df w df w p y p y N N = = − (7) where dfc(w) is the number of documents containing term w within cluster C, and Nc is the number of documents in cluster C, and Nt is the total number of documents that arrive before time step t. γ is a const parameter, now is manually set 3.",
                "KL divergence is defined as follows [17]: ( ) ( || ) ( ) log ( )x p x KL P Q p x q x = ∑ (8) The basic idea is: for a story in a topic, the more a term occurs within the topic, and the less it occurs in other topics, it should be assigned higher weights.",
                "Obviously, modified model can meet all the requirements of the five term classes listed above. 5.2 Term Reweighting Based on Term Type and Story Class Previous work found that some classes of news stories could achieve good improvements by giving extra weight to named entities.",
                "But we find that terms of different types should be given different amount of extra weight for different classes of news stories.",
                "We use open-NLP1 to recognize named entity types and part-ofspeech tags for terms that appear in news stories.",
                "Named entity types include person name, organization name, location name, date, time, money and percentage, and five POSs are selected: none (NN), verb (VB), adjective (JJ), adverb (RB) and cardinal number (CD).",
                "Statistical analysis shows topic-level discriminative terms types for different classes of stories.",
                "For the sake of convenience, named entity type and part-of-speech tags are uniformly called term type in subsequent sections.",
                "Determining whether two stories are about the same topic is a basic component for NED task.",
                "So at first we use 2 χ statistic to compute correlations between terms and topics.",
                "For a term t and a topic T, a contingence table is derived: Table 1.",
                "A 2×2 Contingence Table Doc Number belong to topic T not belong to topic T include t A B not include t C D The 2 χ statistic for a specific term t with respect to topic T is defined to be [16]: 2 2 ( , ) ( ) * ( ) ( ) * ( ) * ( ) * ( ) w T A B C D AD CB A C B D A B C D χ = + + + − + + + + (9) News topics for the TDT task are further classified into 11 rules of interpretations (ROIs) 2 .",
                "The ROI can be seen as a higher level class of stories.",
                "The average correlation between a term type and a topic ROI is computed as: 2 avg 2 ( , )( ( , ) )k m m km kT R w P w TP R p w T R P χ χ ∈ ∈ ∑ ∑（ , ）= 1 1 k=1…K, m=1…M (10) where K is the number of term types (set 12 constantly in the paper).",
                "M is the number news classes (ROIs, set 11 in the paper).",
                "Pk represents the set of all terms of type k, and Rm represents the set of all topics of class m, p(t,T) means the probability that t occurs in topic T. Because of limitation of space, only parts of the term types (9 term types) and parts of news classes (8 classes) are listed in table 2 with the average correlation values between them.",
                "The statistics is derived from labeled data in TDT2 corpus. (Results in table 2 are already normalized for convenience in comparison.)",
                "The statistics in table 2 indicates the usefulness of different term types in topic discrimination with respect to different news classes.",
                "We can see that, location name is the most useful term type for three news classes: Natural Disasters, Violence or War, Finances.",
                "And for three other categories Elections, Legal/Criminal Cases, Science and Discovery, person name is the most discriminative term type.",
                "For Scandals/Hearings, date is the most important information for topic discrimination.",
                "In addition, Legal/Criminal Cases and Finance topics have higher correlation with money terms, while Science and Discovery have higher correlation with percentage terms.",
                "Non-name terms are more stable for different classes. 1 . http://opennlp.sourceforge.net/ 2 . http://projects.ldc.upenn.edu/TDT3/Guide/label.html From the analysis of table 2, it is reasonable to adjust term weight according to their term type and the news class the story belongs to.",
                "New term weights are reweighted as follows: ( ) ( ) ( ) ( ) ( , , ) * ( , , ) ( , , ) * class d D type w T class d D type w w d weight d t w weight d t w weight d t w α α ∈ = ∑ (11) where type(w) represents the type of term w, and class(d) represents the <br>class of story</br> d, c kα is reweighting parameter for news class c and term type k. In the work, we just simply use statistics in table 2 as the reweighting parameters.",
                "Even thought using the statistics directly may not the best choice, we do not discuss how to automatically obtain the best parameters.",
                "We will try to use machine learning techniques to obtain the best parameters in the future work.",
                "In the work, we use BoosTexter [20] to classify all stories into one of the 11 ROIs.",
                "BoosTexter is a boosting based machine learning program, which creates a series of simple rules for building a classifier for text or attribute-value data.",
                "We use term weight generated using TF-IDF model as feature for story classification.",
                "We trained the model on the 12000 judged English stories in TDT2, and classify the rest of the stories in TDT2 and all stories in TDT3.",
                "Classification results are used for term reweighting in formula (11).",
                "Since the class labels of topic-off stories are not given in TDT datasets, we cannot give the classification accuracy here.",
                "Thus we do not discuss the effects of classification accuracy to NED performance in the paper. 6.",
                "EXPERIMENTAL SETUP 6.1 Datasets We used two LDC [18] datasets TDT2 and TDT3 for our experiments.",
                "TDT2 contains news stories from January to June 1998.",
                "It contains around 54,000 stories from sources like ABC, Associated Press, CNN, New York Times, Public Radio International, Voice of America etc.",
                "Only English stories in the collection were considered.",
                "TDT3 contains approximately 31,000 English stories collected from October to December 1998.",
                "In addition to the sources used in TDT2, it also contains stories from NBC and MSNBC TV broadcasts.",
                "We used transcribed versions of the TV and radio broadcasts besides textual news.",
                "TDT2 dataset is labeled with about 100 topics, and approximately 12,000 English stories belong to at least one of these topics.",
                "TDT3 dataset is labeled with about 120 topics, and approximately 8000 English stories belong to at least one of these topics.",
                "All the topics are classified into 11 Rules of Interpretation: (1)Elections, (2)Scandals/Hearings, (3)Legal/Criminal Cases, (4)Natural Disasters, (5)Accidents, (6)Ongoing Violence or War, (7)Science and Discovery News, (8)Finance, (9)New Law, (10)Sports News, (11)MISC.",
                "News. 6.2 Evaluation Metric TDT uses a cost function CDet that combines the probabilities of missing a new story and a false alarm [19]: * * * *Det Miss Miss Target FA FA NontargetC C P P C P P= + (12) Table 2.",
                "Average correlation between term types and news classes where CMiss means the cost of missing a new story, PMiss means the probability of missing a new story, and PTarget means the probability of seeing a new story in the data; CFA means the cost of a false alarm, PFA means the probability of a false alarm, and PNontarget means the probability of seeing an old story.",
                "The cost CDet is normalized such that a perfect system scores 0 and a trivial system, which is the better one of mark all stories as new or old, scores 1: ( ( * , * ) ) Det Det Miss Target FA Nontarget C Norm C min C P C P = (13) New event detection system gives two outputs for each story.",
                "The first part is yes or no indicating whether the story triggers a new event or not.",
                "The second part is a score indicating confidence of the first decision.",
                "Confidence scores can be used to plot DET curve, i.e., curves that plot false alarm vs. miss probabilities.",
                "Minimum normalized cost can be determined if optimal threshold on the score were chosen. 7.",
                "EXPERIMENTAL RESULTS 7.1 Main Results To test the approaches proposed in the model, we implemented and tested five systems: System-1: this system is used as baseline.",
                "It is implemented based on the basic model described in section 3, i.e., using incremental TF-IDF model to generate term weights, and using Hellinger distance to compute document similarity.",
                "Similarity score normalization is also employed [8].",
                "S-S detection procedure is used.",
                "System-2: this system is the same as system-1 except that S-C detection procedure is used.",
                "System-3: this system is the same as system-1 except that it uses the new detection procedure which is based on indexing-tree.",
                "System-4: implemented based on the approach presented in section 5.1, i.e., terms are reweighted according to the distance between term distributions in a cluster and all stories.",
                "The new detection procedure is used.",
                "System-5: implemented based on the approach presented in section 5.2, i.e., terms of different types are reweighted according to news class using trained parameters.",
                "The new detection procedure is used.",
                "The following are some other NED systems: System-6: [21] for each pair of stories, it computes three similarity values for named entity, non-named entity and all terms respectively.",
                "And employ Support Vector Machine to predict new or old using the similarity values as features.",
                "System-7: [8] it extended a basic incremental TF-IDF model to include source-specific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, etc.",
                "System-8: [13] it split document representation into two parts: named entities and non-named entities, and choose one effective part for each news class.",
                "Table 3 and table 4 show topic-weighted normalized costs and comparing times on TDT2 and TDT3 datasets respectively.",
                "Since no heldout data set for fine-tuning the threshold θ new was available for experiments on TDT2, we only report minimum normalized costs for our systems in table 3.",
                "System-5 outperforms all other systems including system-6, and it performs only 2.78e+8 comparing times in detection procedure which is only 13.4% of system-1.",
                "Table 3.",
                "NED results on TDT2 Systems Min Norm(CDet) Cmp times System-1 0.5749 2.08e+9 System-2① 0.6673 3.77e+8 System-3② 0.5765 2.81e+8 System-4② 0.5431 2.99e+8 System-5② 0.5089 2.78e+8 System-6 0.5300 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 When evaluating on the normalized costs on TDT3, we use the optimal thresholds obtained from TDT2 data set for all systems.",
                "System-2 reduces comparing times to 1.29e+9 which is just 18.3% of system-1, but at the same time it also gets a deteriorated minimum normalized cost which is 0.0499 higher than system-1.",
                "System-3 uses the new detection procedure based on news indexing-tree.",
                "It requires even less comparing times than system-2.",
                "This is because story-story comparisons usually yield greater similarities than story-cluster ones, so stories tend to be combined Location Person Date Organization Money Percentage NN JJ CD Elections 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 Scandals/Hearings 0.66 0.62 0.28 1 0.11 0.02 0.27 0.13 0.05 Legal/Criminal Cases 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 Natural Disasters 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 Violence or War 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 Science and Discovery 0.11 1 0.01 0.22 0.08 0.12 0.19 0.08 0.03 Finances 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 Sports 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 together in system-3.",
                "And system-3 is basically equivalent to system-1 in accuracy results.",
                "System-4 adjusts term weights based on the distance of term distributions between the whole corpus and cluster story set, yielding a good improvement by 0.0468 compared to system-1.",
                "The best system (system-5) has a minimum normalized cost 0.5012, which is 0.0797 better than system-1, and also better than any other results previously reported for this dataset [8, 13].",
                "Further more, system-5 only needs 1.05e+8 comparing times which is 14.9% of system-1.",
                "Table 4.",
                "NED results on TDT3 Systems Norm(CDet) Min Norm(CDet) Cmp times System-1 0.6159 0.5809 7.04e+8 System-2① 0.6493 0.6308 1.29e+8 System-3② 0.6197 0.5868 1.03e+8 System-4② 0.5601 0.5341 1.03e+8 System-5② 0.5413 0.5012 1.05e+8 System-7 -- 0.5783 -System-8 -- 0.5229 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 Figure5 shows the five DET curves for our systems on data set TDT3.",
                "System-5 achieves the minimum cost at a false alarm rate of 0.0157 and a miss rate of 0.4310.",
                "We can observe that System4 and System-5 obtain lower miss probability at regions of low false alarm probabilities.",
                "The hypothesis is that, more weight value is transferred to key terms of topics from non-key terms.",
                "Similarity score between two stories belonging to different topics are lower than before, because their overlapping terms are usually not key terms of their topics. 7.2 Parameter selection for indexing-tree detection Figure 3 shows the minimum normalized costs obtained by system-3 on TDT3 using different parameters.",
                "Theθ init parameter is tested on six values spanning from 0.03 to 0.18.",
                "And the λ parameter is tested on four values 1, 2, 3 and 4.",
                "We can see that, whenθ init is set to 0.12, which is the closest one toθ new, the costs are lower than others.",
                "This is easy to explain, because when stories belonging to the same topic are put in a cluster, it is more reasonable for the cluster to represent the stories in it.",
                "When parameter λ is set to 3 or 4, the costs are better than other cases, but there is no much difference between 3 and 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ MinCost 0.6 0.65 0.7 0.75 0.8 0.85 0.9 Figure 3.",
                "Min Cost on TDT3 (δ =0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ Comparingtimes 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 Figure 4.",
                "Comparing times on TDT3 (δ =0.15) Figure 4 gives the comparing times used by system-3 on TDT3 with the same parameters as figure 3.",
                "The comparing times are strongly dependent onθ init.",
                "Because the greaterθ init is, the less stories combined together, the more comparing times are needed for new event decision.",
                "So we useθ init =0.13,λ =3,δ =0.15 for system-3, 4, and 5.",
                "In this parameter setting, we can get both low minimum normalized costs and less comparing times. 8.",
                "CONCLUSION We have proposed a news indexing-tree based detection procedure in our model.",
                "It reduces comparing times to about one seventh of traditional method without hurting NED accuracy.",
                "We also have presented two extensions to the basic TF-IDF model.",
                "The first extension is made by adjust term weights based on term distributions between the whole corpus and a cluster story set.",
                "And the second extension to basic TF-IDF model is better use of term types (named entities types and part-of-speed) according to news categories.",
                "Our experimental results on TDT2 and TDT3 datasets show that both of the two extensions contribute significantly to improvement in accuracy.",
                "We did not consider news time information as a clue for NED task, since most of the topics last for a long time and TDT data sets only span for a relative short period (no more than 6 months).",
                "For the future work, we want to collect news set which span for a longer period from internet, and integrate time information in NED task.",
                "Since topic is a relative coarse-grained news cluster, we also want to refine cluster granularity to event-level, and identify different events and their relations within a topic.",
                "Acknowledgments This work is supported by the National Natural Science Foundation of China under Grant No. 90604025.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] In Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. .01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90 1 2 5 10 20 40 60 80 90 False Alarm Probability (in %) MissProbability(in%) SYSTEM1 Topic Weighted Curve SYSTEM1 Min Norm(Cost) SYSTEM2 Topic Weighted Curve SYSTEM2 Min Norm(Cost) SYSTEM3 Topic Weighted Curve SYSTEM3 Min Norm(Cost) SYSTEM4 Topic Weighted Curve SYSTEM4 Min Norm(Cost) SYSTEM5 Topic Weighted Curve SYSTEM5 Min Norm(Cost) Random Performance Figure 5.",
                "DET curves on TDT3 [3] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B.T.",
                "Archibald, and X. Liu.",
                "Learning Approaches for Detecting and Tracking News Events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), 1999, 32-43. [4] Y. Yang, T. Pierce, and J. Carbonell.",
                "A Study on Retrospective and On-line Event Detection.",
                "In Proceedings of SIGIR-98, Melbourne, Australia, 1998, 28-36. [5] J. Allan, V. Lavrenko, D. Malin, and R. Swan.",
                "Detections, Bounds, and Timelines: Umass and tdt-3.",
                "In Proceedings of Topic Detection and Tracking Workshop (TDT-3), Vienna, VA, 2000, 167-174. [6] R. Papka and J. Allan.",
                "On-line New Event Detection Using Single Pass Clustering TITLE2:.",
                "Technical Report UM-CS1998-021, 1998. [7] W. Lam, H. Meng, K. Wong, and J.",
                "Yen.",
                "Using Contextual Analysis for News Event Detection.",
                "International Journal on Intelligent Systems, 2001, 525-546. [8] B. Thorsten, C. Francine, and F. Ayman.",
                "A System for New Event Detection.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2003, 330-337. [9] S. Nicola and C. Joe.",
                "Combining Semantic and Syntactic Document Classifiers to Improve First Story Detection.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2001, 424425. [10] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topicconditioned Novelty Detection.",
                "In Proceedings of the 8th ACM SIGKDD International Conference, ACM Press. 2002, 688-693. [11] M. Juha, A.M. Helena, and S. Marko.",
                "Applying Semantic Classes in Event Detection and Tracking.",
                "In Proceedings of International Conference on Natural Language Processing (ICON 2002), 2002, pages 175-183. [12] M. Juha, A.M. Helena, and S. Marko.",
                "Simple Semantics in Topic Detection and Tracking.",
                "Information Retrieval, 7(3-4): 2004, 347-368. [13] K. Giridhar and J. Allan.",
                "Text Classification and Named Entities for New Event Detection.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2004, 297-304. [14] J. P. Callan, W. B. Croft, and S. M. Harding.",
                "The INQUERY Retrieval System.",
                "In Proceedings of DEXA-92, 3rd International Conference on Database and Expert Systems Applications, 1992, 78-83. [15] R. Krovetz.",
                "Viewing Morphology as An Inference Process.",
                "In Proceedings of ACM SIGIR93, 1993, 61-81. [16] Y. Yang and J. Pedersen.",
                "A Comparative Study on Feature Selection in Text Categorization.",
                "In J. D. H. Fisher, editor, The Fourteenth International Conference on Machine Learning (ICML97), Morgan Kaufmann, 1997, 412-420. [17] T. M. Cover, and J.A.",
                "Thomas.",
                "Elements of Information Theory.",
                "Wiley. 1991. [18] The linguistic data consortium, http://www.ldc,upenn.edu/. [19] The 2001 TDT task definition and evaluation plan, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm. [20] R. E. Schapire and Y.",
                "Singer.",
                "Boostexter: A Boosting-based System for Text Categorization.",
                "In Machine Learning 39(2/3):1, Kluwer Academic Publishers, 2000, 35-168. [21] K. Giridhar and J. Allan. 2005.",
                "Using Names and Topics for New Event Detection.",
                "In Proceedings of Human Technology Conference and Conference on Empirical Methods in Natural Language, Vancouver, 2005, 121-128"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "El nuevo término los pesos se vuelven a ver de la siguiente manera: () () () () (,,) * (,) (,,) * Clase D D Type W T Clase D D Tipo W W W W W W W W W W PESO D T W PESO D T W α α ∈= ∑ (11) donde el tipo (W) representa el tipo de término W, y la clase (d) representa la \"clase de historia\" D, C Kα es el parámetro de re -peso para la clase de noticias C y el tipo de término K.En el trabajo, simplemente usamos estadísticas en la Tabla 2 como parámetros de re -peso."
            ],
            "translated_text": "",
            "candidates": [
                "clase de historia",
                "clase de historia"
            ],
            "error": []
        },
        "story class": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "New Event Detection Based on Indexing-tree and Named Entity Zhang Kuo Tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn Li Juan Zi Tsinghua University Beijing, 100084, China 86-10-62781461 ljz@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn ABSTRACT New Event Detection (NED) aims at detecting from one or multiple streams of news stories that which one is reported on a new event (i.e.",
                "not reported previously).",
                "With the overwhelming volume of news available today, there is an increasing need for a NED system which is able to detect new events more efficiently and accurately.",
                "In this paper we propose a new NED model to speed up the NED task by using news indexing-tree dynamically.",
                "Moreover, based on the observation that terms of different types have different effects for NED task, two term reweighting approaches are proposed to improve NED accuracy.",
                "In the first approach, we propose to adjust term weights dynamically based on previous story clusters and in the second approach, we propose to employ statistics on training data to learn the named entity reweighting model for each class of stories.",
                "Experimental results on two Linguistic Data Consortium (LDC) datasets TDT2 and TDT3 show that the proposed model can improve both efficiency and accuracy of NED task significantly, compared to the baseline system and other existing systems.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Search and Retrieval; H.4.2 [Information Systems Applications]: Types of Systemsdecision support.",
                "General Terms Algorithms, Performance, Experimentation 1.",
                "INTRODUCTION Topic Detection and Tracking (TDT) program aims to develop techniques which can effectively organize, search and structure news text materials from a variety of newswire and broadcast media [1].",
                "New Event Detection (NED) is one of the five tasks in TDT.",
                "It is the task of online identification of the earliest report for each topic as soon as that report arrives in the sequence of documents.",
                "A Topic is defined as a seminal event or activity, along with directly related events and activities [2].",
                "An Event is defined as something (non-trivial) happening in a certain place at a certain time [3].",
                "For instance, when a bomb explodes in a building, the exploding is the seminal event that triggers the topic, and other stories on the same topic would be those discussing salvaging efforts, the search for perpetrators, arrests and trial and so on.",
                "Useful news information is usually buried in a mass of data generated everyday.",
                "Therefore, NED systems are very useful for people who need to detect novel information from real-time news stream.",
                "These real-life needs often occur in domains like financial markets, news analysis, and intelligence gathering.",
                "In most of state-of-the-art (currently) NED systems, each news story on hand is compared to all the previous received stories.",
                "If all the similarities between them do not exceed a threshold, then the story triggers a new event.",
                "They are usually in the form of cosine similarity or Hellinger similarity metric.",
                "The core problem of NED is to identify whether two stories are on the same topic.",
                "Obviously, these systems cannot take advantage of topic information.",
                "Further more, it is not acceptable in real applications because of the large amount of computation required in the NED process.",
                "Other systems organize previous stories into clusters (each cluster corresponds to a topic), and new story is compared to the previous clusters instead of stories.",
                "This manner can reduce comparing times significantly.",
                "Nevertheless, it has been proved that this manner is less accurate [4, 5].",
                "This is because sometimes stories within a topic drift far away from each other, which could lead low similarity between a story and its topic.",
                "On the other hand, some proposed NED systems tried to improve accuracy by making better use of named entities [10, 11, 12, 13].",
                "However, none of the systems have considered that terms of different types (e.g.",
                "Noun, Verb or Person name) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "For example, the names of election candidates (Person name) are very important for stories of election class; the locations (Location name) where accidents happened are important for stories of accidents class.",
                "So, in NED, there still exist following three problems to be investigated: (1) How to speed up the detection procedure while do not decrease the detection accuracy? (2) How to make good use of cluster (topic) information to improve accuracy? (3) How to obtain better news story representation by better understanding of named entities.",
                "Driven by these problems, we have proposed three approaches in this paper. (1)To make the detection procedure faster, we propose a new NED procedure based on news indexing-tree created dynamically.",
                "Story indexing-tree is created by assembling similar stories together to form news clusters in different hierarchies according to their values of similarity.",
                "Comparisons between current story and previous clusters could help find the most similar story in less comparing times.",
                "The new procedure can reduce the amount of comparing times without hurting accuracy. (2)We use the clusters of the first floor in the indexing-tree as news topics, in which term weights are adjusted dynamically according to term distribution in the clusters.",
                "In this approach, cluster (topic) information is used properly, so the problem of theme decentralization is avoided. (3)Based on observations on the statistics obtained from training data, we found that terms of different types (e.g.",
                "Noun and Verb) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "And we propose to use statistics to optimize the weights of the terms of different types in a story according to the news class that the story belongs to.",
                "On TDT3 dataset, the new NED model just uses 14.9% comparing times of the basic model, while its minimum normalized cost is 0.5012, which is 0.0797 better than the basic model, and also better than any other results previously reported for this dataset [8, 13].",
                "The rest of the paper is organized as follows.",
                "We start off this paper by summarizing the previous work in NED in section 2.",
                "Section 3 presents the basic model for NED that most current systems use.",
                "Section 4 describes our new detection procedure based on news indexing-tree.",
                "In section 5, two term reweighting methods are proposed to improve NED accuracy.",
                "Section 6 gives our experimental data and evaluation metrics.",
                "We finally wrap up with the experimental results in Section 7, and the conclusions and future work in Section 8. 2.",
                "RELATED WORK Papka et al. proposed Single-Pass clustering on NED [6].",
                "When a new story was encountered, it was processed immediately to extract term features and a query representation of the storys content is built up.",
                "Then it was compared with all the previous queries.",
                "If the document did not trigger any queries by exceeding a threshold, it was marked as a new event.",
                "Lam et al build up previous query representations of story clusters, each of which corresponds to a topic [7].",
                "In this manner comparisons happen between stories and clusters.",
                "Recent years, most work focus on proposing better methods on comparison of stories and document representation.",
                "Brants et al. [8] extended a basic incremental TF-IDF model to include sourcespecific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, term reweighting based on inverse event frequencies, and segmentation of documents.",
                "Good improvements on TDT bench-marks were shown.",
                "Stokes et al. [9] utilized a combination of evidence from two distinct representations of a documents content.",
                "One of the representations was the usual free text vector, the other made use of lexical chains (created using WordNet) to build another term vector.",
                "Then the two representations are combined in a linear fashion.",
                "A marginal increase in effectiveness was achieved when the combined representation was used.",
                "Some efforts have been done on how to utilize named entities to improve NED.",
                "Yang et al. gave location named entities four times weight than other terms and named entities [10].",
                "DOREMI research group combined semantic similarities of person names, location names and time together with textual similarity [11][12].",
                "UMass [13] research group split document representation into two parts: named entities and non-named entities.",
                "And it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation.",
                "Both [10] and [13] used text categorization technique to classify news stories in advance.",
                "In [13] news stories are classified automatically at first, and then test sensitivities of names and non-name terms for NED for each class.",
                "In [10] frequent terms for each class are removed from document representation.",
                "For example, word election does not help identify different elections.",
                "In their work, effectiveness of different kinds of names (or terms with different POS) for NED in different news classes are not investigated.",
                "We use statistical analysis to reveal the fact and use it to improve NED performance. 3.",
                "BASIC MODEL In this section, we present the basic New Event Detection model which is similar to what most current systems apply.",
                "Then, we propose our new model by extending the basic model.",
                "New Event Detection systems use news story stream as input, in which stories are strictly time-ordered.",
                "Only previously received stories are available when dealing with current story.",
                "The output is a decision for whether the current story is on a new event or not and the confidence of the decision.",
                "Usually, a NED model consists of three parts: story representation, similarity calculation and detection procedure. 3.1 Story Representation Preprocessing is needed before generating story representation.",
                "For preprocessing, we tokenize words, recognize abbreviations, normalize abbreviations, add part-of-speech tags, remove stopwords included in the stop list used in InQuery [14], replace words with their stems using K-stem algorithm[15], and then generate word vector for each news story.",
                "We use incremental TF-IDF model for term weight calculation [4].",
                "In a TF-IDF model, term frequency in a news document is weighted by the inverse document frequency, which is generated from training corpus.",
                "When a new term occurs in testing process, there are two solutions: simply ignore the new term or set df of the term as a small const (e.g. df = 1).",
                "The new term receives too low weight in the first solution (0) and too high weight in the second solution.",
                "In incremental TF-IDF model, document frequencies are updated dynamically in each time step t: 1( ) ( ) ( )t t D tdf w df w df w−= + (1) where Dt represents news story set received in time t, and dfDt(w) means the number of documents that term w occurs in, and dft(w) means the total number of documents that term w occurs in before time t. In this work, each time window includes 50 news stories.",
                "Thus, each story d received in t is represented as follows: 1 2{ ( , , ), ( , , ),..., ( , , )}nd weight d t w weight d t w weight d t w→ where n means the number of distinct terms in story d, and ( , , )weight d t w means the weight of term w in story d at time t: log( ( , ) 1) log(( 1) /( ( ) 0.5)) ( , , ) log( ( , ) 1) log(( 1) /( ( ) 0.5)) t t t t w d tf d w N df w weight d t w tf d w N df w ∈ + + + = + + +∑ (2) where Nt means the total number of news stories before time t, and tf(d,w) means how many times term w occurs in news story d. 3.2 Similarity Calculation We use Hellinger distance for the calculation of similarity between two stories, for two stories d and d at time t, their similarity is defined as follows: , ( , , ) ( , , ) * ( , , ) w d d sim d d t weight d t w weight d t w ∈ = ∑ (3) 3.3 Detection Procedure For each story d received in time step t, the value ( ) ( ) ( ) ( ( , , )) time d time d n d max sim d d t < = (4) is a score used to determine whether d is a story about a new topic and at the same time is an indication of the confidence in our decision [8]. time(d) means the publication time of story d. If the score exceeds the thresholdθ new, then there exists a sufficiently similar document, thus d is a old story, otherwise, there is no sufficiently similar previous document, thus d is an new story. 4.",
                "New NED Procedure Traditional NED systems can be classified into two main types on the aspect of detection procedure: (1) S-S type, in which the story on hand is compared to each story received previously, and use the highest similarity to determine whether current story is about a new event; (2) S-C type, in which the story on hand is compared to all previous clusters each of which representing a topic, and the highest similarity is used for final decision for current story.",
                "If the highest similarity exceeds thresholdθ new, then it is an old story, and put it into the most similar cluster; otherwise it is a new story and create a new cluster.",
                "Previous work show that the first manner is more accurate than the second one [4][5].",
                "Since sometimes stories within a topic drift far away from each other, a story may have very low similarity with its topic.",
                "So using similarities between stories for determining new story is better than using similarities between story and clusters.",
                "Nevertheless, the first manner needs much more comparing times which means the first manner is low efficient.",
                "We propose a new detection procedure which uses comparisons with previous clusters to help find the most similar story in less comparing times, and the final new event decision is made according to the most similar story.",
                "Therefore, we can get both the accuracy of S-S type methods and the efficiency of S-C type methods.",
                "The new procedure creates a news indexing-tree dynamically, in which similar stories are put together to form a hierarchy of clusters.",
                "We index similar stories together by their common ancestor (a cluster node).",
                "Dissimilar stories are indexed in different clusters.",
                "When a story is coming, we use comparisons between the current story and previous hierarchical clusters to help find the most similar story which is useful for new event decision.",
                "After the new event decision is made, the current story is inserted to the indexing-tree for the following detection.",
                "The news indexing-tree is defined formally as follows: S-Tree = {r, NC , NS , E} where r is the root of S-Tree, NC is the set of all cluster nodes, NS is the set of all story nodes, and E is the set of all edges in S-Tree.",
                "We define a set of constraints for a S-Tree: ⅰ . , is an non-terminal node in the treeC i i N i∀ ∈ → ⅱ . , is a terminal node in the treeS i i N i∀ ∈ → ⅲ . , out degree of is at least 2C i i N i∀ ∈ → ⅳ . , is represented as the centroid of its desendantsC i i iN∀ ∈ → For a news story di, the comparison procedure and inserting procedure based on indexing-tree are defined as follows.",
                "An example is shown by Figure 1 and Figure 2.",
                "Figure 1.",
                "Comparison procedure Figure 2.",
                "Inserting procedure Comparison procedure: Step 1: compare di to all the direct child nodes of r and select λ nodes with highest similarities, e.g., C1 2 and C1 3 in Figure 1.",
                "Step 2: for each selected node in the last step, e.g.",
                "C1 2, compare di to all its direct child nodes, and select λ nodes with highest similarities, e.g.",
                "C2 2 and d8.",
                "Repeat step 2 for all non-terminal nodes.",
                "Step 3: record the terminal node with the highest similarty to di, e.g. s5, and the similarity value (0.20).",
                "Inserting di to the S-tree with r as root: Find the node n which is direct child of r in the path from r to the terminal node with highest similarity s, e.g.",
                "C1 2.",
                "If s is smaller than θ init+(h-1)δ , then add di to the tree as a direct child of r. Otherwise, if n is a terminal node, then create a cluster node instead of n, and add both n and di as its direct children; if n is an non-terminal node, then repeat this procedure and insert di to the sub-tree with n as root recursively.",
                "Here h is the length between n and the root of S-tree.",
                "The more the stories in a cluster similar to each other, the better the cluster represents the stories in it.",
                "Hence we add no constraints on the maximum of trees height and degree of a node.",
                "Therefore, we cannot give the complexity of this indexing-tree based procedure.",
                "But we will give the number of comparing times needed by the new procedure in our experiments in section7. 5.",
                "Term Reweighting Methods In this section, two term reweighting methods are proposed to improve NED accuracy.",
                "In the first method, a new way is explored for better using of cluster (topic) information.",
                "The second one finds a better way to make use of named entities based on news classification. 5.1 Term Reweighting Based on Distribution Distance TF-IDF is the most prevalent model used in information retrieval systems.",
                "The basic idea is that the fewer documents a term appears in, the more important the term is in discrimination of documents (relevant or not relevant to a query containing the term).",
                "Nevertheless, in TDT domain, we need to discriminate documents with regard to topics rather than queries.",
                "Intuitively, using cluster (topic) vectors to compare with subsequent news stories should outperform using story vectors.",
                "Unfortunately, the experimental results do not support this intuition [4][5].",
                "Based on observation on data, we find the reason is that a news topic usually contains many directly or indirectly related events, while they all have their own sub-subjects which are usually different with each other.",
                "Take the topic described in section 1 as an example, events like the explosion and salvage have very low similarities with events about criminal trial, therefore stories about trial would have low similarity with the topic vector built on its previous events.",
                "This section focuses on how to effectively make use of topic information and at the same time avoid the problem of content decentralization.",
                "At first, we classify terms into 5 classes to help analysis the needs of the modified model: Term class A: terms that occur frequently in the whole corpus, e.g., year and people.",
                "Terms of this class should be given low weights because they do not help much for topic discrimination.",
                "Term class B: terms that occur frequently within a news category, e.g., election, storm.",
                "They are useful to distinguish two stories in different news categories.",
                "However, they cannot provide information to determine whether two stories are on the same or different topics.",
                "In another words, term election and term storm are not helpful in differentiate two election campaigns and two storm disasters.",
                "Therefore, terms of this class should be assigned lower weights.",
                "Term class C: terms that occur frequently in a topic, and infrequently in other topics, e.g., the name of a crash plane, the name of a specific hurricane.",
                "News stories that belong to different topics rarely have overlap terms in this class.",
                "The more frequently a term appears in a topic, the more important the term is for a story belonging to the topic, therefore the term should be set higher weight.",
                "Term class D: terms that appear in a topic exclusively, but not frequently.",
                "For example, the name of a fireman who did very well in a salvage action, which may appears in only two or three stories but never appeared in other topics.",
                "Terms of this type should receive more weights than in TF-IDF model.",
                "However, since they are not popular in the topic, it is not appropriate to give them too high weights.",
                "Term class E: terms with low document frequency, and appear in different topics.",
                "Terms of this class should receive lower weights.",
                "Now we analyze whether TF-IDF model can give proper weights to the five classes of terms.",
                "Obviously, terms of class A are lowly weighted in TF-IDF model, which is conformable with the requirement described above.",
                "In TF-IDF model, terms of class B are highly dependant with the number of stories in a news class.",
                "TF-IDF model cannot provide low weights if the story containing the term belongs to a relative small news class.",
                "For a term of class C, the more frequently it appears in a topic, the less weight TFIDF model gives to it.",
                "This strongly conflicts with the requirement of terms in class C. For terms of class D, TF-IDF model gives them high weights correctly.",
                "But for terms of class E, TF-IDF model gives high weights to them which are not conformable with the requirement of low weights.",
                "To sum up, terms of class B, C, E cannot be properly weighted in TF-IDF model.",
                "So, we propose a modified model to resolve this problem.",
                "When θ init andθ new are set closely, we assume that most of the stories in a first-level cluster (a direct child node of root node) are on the same topic.",
                "Therefore, we make use of a first-level cluster to capture term distribution (df for all the terms within the cluster) within the topic dynamically.",
                "KL divergence of term distribution in a first-level cluster and the whole story set is used to adjust term weights:  ( , , ) * (1 * ( || )) ( , , ) ( , , ) * (1 * ( || )) cw tw cw tw w d D weight d t w KL P P weight d t w weight d t w KL P P γ γ ∈ + = +∑ (5) where ( ) ( ) ( ) ( ) 1,cw cw c c c c df w df w p y p y N N = = − (6) ( ) ( ) ( ) ( ) 1,t t tw tw t t df w df w p y p y N N = = − (7) where dfc(w) is the number of documents containing term w within cluster C, and Nc is the number of documents in cluster C, and Nt is the total number of documents that arrive before time step t. γ is a const parameter, now is manually set 3.",
                "KL divergence is defined as follows [17]: ( ) ( || ) ( ) log ( )x p x KL P Q p x q x = ∑ (8) The basic idea is: for a story in a topic, the more a term occurs within the topic, and the less it occurs in other topics, it should be assigned higher weights.",
                "Obviously, modified model can meet all the requirements of the five term classes listed above. 5.2 Term Reweighting Based on Term Type and <br>story class</br> Previous work found that some classes of news stories could achieve good improvements by giving extra weight to named entities.",
                "But we find that terms of different types should be given different amount of extra weight for different classes of news stories.",
                "We use open-NLP1 to recognize named entity types and part-ofspeech tags for terms that appear in news stories.",
                "Named entity types include person name, organization name, location name, date, time, money and percentage, and five POSs are selected: none (NN), verb (VB), adjective (JJ), adverb (RB) and cardinal number (CD).",
                "Statistical analysis shows topic-level discriminative terms types for different classes of stories.",
                "For the sake of convenience, named entity type and part-of-speech tags are uniformly called term type in subsequent sections.",
                "Determining whether two stories are about the same topic is a basic component for NED task.",
                "So at first we use 2 χ statistic to compute correlations between terms and topics.",
                "For a term t and a topic T, a contingence table is derived: Table 1.",
                "A 2×2 Contingence Table Doc Number belong to topic T not belong to topic T include t A B not include t C D The 2 χ statistic for a specific term t with respect to topic T is defined to be [16]: 2 2 ( , ) ( ) * ( ) ( ) * ( ) * ( ) * ( ) w T A B C D AD CB A C B D A B C D χ = + + + − + + + + (9) News topics for the TDT task are further classified into 11 rules of interpretations (ROIs) 2 .",
                "The ROI can be seen as a higher level class of stories.",
                "The average correlation between a term type and a topic ROI is computed as: 2 avg 2 ( , )( ( , ) )k m m km kT R w P w TP R p w T R P χ χ ∈ ∈ ∑ ∑（ , ）= 1 1 k=1…K, m=1…M (10) where K is the number of term types (set 12 constantly in the paper).",
                "M is the number news classes (ROIs, set 11 in the paper).",
                "Pk represents the set of all terms of type k, and Rm represents the set of all topics of class m, p(t,T) means the probability that t occurs in topic T. Because of limitation of space, only parts of the term types (9 term types) and parts of news classes (8 classes) are listed in table 2 with the average correlation values between them.",
                "The statistics is derived from labeled data in TDT2 corpus. (Results in table 2 are already normalized for convenience in comparison.)",
                "The statistics in table 2 indicates the usefulness of different term types in topic discrimination with respect to different news classes.",
                "We can see that, location name is the most useful term type for three news classes: Natural Disasters, Violence or War, Finances.",
                "And for three other categories Elections, Legal/Criminal Cases, Science and Discovery, person name is the most discriminative term type.",
                "For Scandals/Hearings, date is the most important information for topic discrimination.",
                "In addition, Legal/Criminal Cases and Finance topics have higher correlation with money terms, while Science and Discovery have higher correlation with percentage terms.",
                "Non-name terms are more stable for different classes. 1 . http://opennlp.sourceforge.net/ 2 . http://projects.ldc.upenn.edu/TDT3/Guide/label.html From the analysis of table 2, it is reasonable to adjust term weight according to their term type and the news class the story belongs to.",
                "New term weights are reweighted as follows: ( ) ( ) ( ) ( ) ( , , ) * ( , , ) ( , , ) * class d D type w T class d D type w w d weight d t w weight d t w weight d t w α α ∈ = ∑ (11) where type(w) represents the type of term w, and class(d) represents the class of story d, c kα is reweighting parameter for news class c and term type k. In the work, we just simply use statistics in table 2 as the reweighting parameters.",
                "Even thought using the statistics directly may not the best choice, we do not discuss how to automatically obtain the best parameters.",
                "We will try to use machine learning techniques to obtain the best parameters in the future work.",
                "In the work, we use BoosTexter [20] to classify all stories into one of the 11 ROIs.",
                "BoosTexter is a boosting based machine learning program, which creates a series of simple rules for building a classifier for text or attribute-value data.",
                "We use term weight generated using TF-IDF model as feature for story classification.",
                "We trained the model on the 12000 judged English stories in TDT2, and classify the rest of the stories in TDT2 and all stories in TDT3.",
                "Classification results are used for term reweighting in formula (11).",
                "Since the class labels of topic-off stories are not given in TDT datasets, we cannot give the classification accuracy here.",
                "Thus we do not discuss the effects of classification accuracy to NED performance in the paper. 6.",
                "EXPERIMENTAL SETUP 6.1 Datasets We used two LDC [18] datasets TDT2 and TDT3 for our experiments.",
                "TDT2 contains news stories from January to June 1998.",
                "It contains around 54,000 stories from sources like ABC, Associated Press, CNN, New York Times, Public Radio International, Voice of America etc.",
                "Only English stories in the collection were considered.",
                "TDT3 contains approximately 31,000 English stories collected from October to December 1998.",
                "In addition to the sources used in TDT2, it also contains stories from NBC and MSNBC TV broadcasts.",
                "We used transcribed versions of the TV and radio broadcasts besides textual news.",
                "TDT2 dataset is labeled with about 100 topics, and approximately 12,000 English stories belong to at least one of these topics.",
                "TDT3 dataset is labeled with about 120 topics, and approximately 8000 English stories belong to at least one of these topics.",
                "All the topics are classified into 11 Rules of Interpretation: (1)Elections, (2)Scandals/Hearings, (3)Legal/Criminal Cases, (4)Natural Disasters, (5)Accidents, (6)Ongoing Violence or War, (7)Science and Discovery News, (8)Finance, (9)New Law, (10)Sports News, (11)MISC.",
                "News. 6.2 Evaluation Metric TDT uses a cost function CDet that combines the probabilities of missing a new story and a false alarm [19]: * * * *Det Miss Miss Target FA FA NontargetC C P P C P P= + (12) Table 2.",
                "Average correlation between term types and news classes where CMiss means the cost of missing a new story, PMiss means the probability of missing a new story, and PTarget means the probability of seeing a new story in the data; CFA means the cost of a false alarm, PFA means the probability of a false alarm, and PNontarget means the probability of seeing an old story.",
                "The cost CDet is normalized such that a perfect system scores 0 and a trivial system, which is the better one of mark all stories as new or old, scores 1: ( ( * , * ) ) Det Det Miss Target FA Nontarget C Norm C min C P C P = (13) New event detection system gives two outputs for each story.",
                "The first part is yes or no indicating whether the story triggers a new event or not.",
                "The second part is a score indicating confidence of the first decision.",
                "Confidence scores can be used to plot DET curve, i.e., curves that plot false alarm vs. miss probabilities.",
                "Minimum normalized cost can be determined if optimal threshold on the score were chosen. 7.",
                "EXPERIMENTAL RESULTS 7.1 Main Results To test the approaches proposed in the model, we implemented and tested five systems: System-1: this system is used as baseline.",
                "It is implemented based on the basic model described in section 3, i.e., using incremental TF-IDF model to generate term weights, and using Hellinger distance to compute document similarity.",
                "Similarity score normalization is also employed [8].",
                "S-S detection procedure is used.",
                "System-2: this system is the same as system-1 except that S-C detection procedure is used.",
                "System-3: this system is the same as system-1 except that it uses the new detection procedure which is based on indexing-tree.",
                "System-4: implemented based on the approach presented in section 5.1, i.e., terms are reweighted according to the distance between term distributions in a cluster and all stories.",
                "The new detection procedure is used.",
                "System-5: implemented based on the approach presented in section 5.2, i.e., terms of different types are reweighted according to news class using trained parameters.",
                "The new detection procedure is used.",
                "The following are some other NED systems: System-6: [21] for each pair of stories, it computes three similarity values for named entity, non-named entity and all terms respectively.",
                "And employ Support Vector Machine to predict new or old using the similarity values as features.",
                "System-7: [8] it extended a basic incremental TF-IDF model to include source-specific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, etc.",
                "System-8: [13] it split document representation into two parts: named entities and non-named entities, and choose one effective part for each news class.",
                "Table 3 and table 4 show topic-weighted normalized costs and comparing times on TDT2 and TDT3 datasets respectively.",
                "Since no heldout data set for fine-tuning the threshold θ new was available for experiments on TDT2, we only report minimum normalized costs for our systems in table 3.",
                "System-5 outperforms all other systems including system-6, and it performs only 2.78e+8 comparing times in detection procedure which is only 13.4% of system-1.",
                "Table 3.",
                "NED results on TDT2 Systems Min Norm(CDet) Cmp times System-1 0.5749 2.08e+9 System-2① 0.6673 3.77e+8 System-3② 0.5765 2.81e+8 System-4② 0.5431 2.99e+8 System-5② 0.5089 2.78e+8 System-6 0.5300 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 When evaluating on the normalized costs on TDT3, we use the optimal thresholds obtained from TDT2 data set for all systems.",
                "System-2 reduces comparing times to 1.29e+9 which is just 18.3% of system-1, but at the same time it also gets a deteriorated minimum normalized cost which is 0.0499 higher than system-1.",
                "System-3 uses the new detection procedure based on news indexing-tree.",
                "It requires even less comparing times than system-2.",
                "This is because story-story comparisons usually yield greater similarities than story-cluster ones, so stories tend to be combined Location Person Date Organization Money Percentage NN JJ CD Elections 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 Scandals/Hearings 0.66 0.62 0.28 1 0.11 0.02 0.27 0.13 0.05 Legal/Criminal Cases 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 Natural Disasters 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 Violence or War 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 Science and Discovery 0.11 1 0.01 0.22 0.08 0.12 0.19 0.08 0.03 Finances 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 Sports 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 together in system-3.",
                "And system-3 is basically equivalent to system-1 in accuracy results.",
                "System-4 adjusts term weights based on the distance of term distributions between the whole corpus and cluster story set, yielding a good improvement by 0.0468 compared to system-1.",
                "The best system (system-5) has a minimum normalized cost 0.5012, which is 0.0797 better than system-1, and also better than any other results previously reported for this dataset [8, 13].",
                "Further more, system-5 only needs 1.05e+8 comparing times which is 14.9% of system-1.",
                "Table 4.",
                "NED results on TDT3 Systems Norm(CDet) Min Norm(CDet) Cmp times System-1 0.6159 0.5809 7.04e+8 System-2① 0.6493 0.6308 1.29e+8 System-3② 0.6197 0.5868 1.03e+8 System-4② 0.5601 0.5341 1.03e+8 System-5② 0.5413 0.5012 1.05e+8 System-7 -- 0.5783 -System-8 -- 0.5229 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 Figure5 shows the five DET curves for our systems on data set TDT3.",
                "System-5 achieves the minimum cost at a false alarm rate of 0.0157 and a miss rate of 0.4310.",
                "We can observe that System4 and System-5 obtain lower miss probability at regions of low false alarm probabilities.",
                "The hypothesis is that, more weight value is transferred to key terms of topics from non-key terms.",
                "Similarity score between two stories belonging to different topics are lower than before, because their overlapping terms are usually not key terms of their topics. 7.2 Parameter selection for indexing-tree detection Figure 3 shows the minimum normalized costs obtained by system-3 on TDT3 using different parameters.",
                "Theθ init parameter is tested on six values spanning from 0.03 to 0.18.",
                "And the λ parameter is tested on four values 1, 2, 3 and 4.",
                "We can see that, whenθ init is set to 0.12, which is the closest one toθ new, the costs are lower than others.",
                "This is easy to explain, because when stories belonging to the same topic are put in a cluster, it is more reasonable for the cluster to represent the stories in it.",
                "When parameter λ is set to 3 or 4, the costs are better than other cases, but there is no much difference between 3 and 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ MinCost 0.6 0.65 0.7 0.75 0.8 0.85 0.9 Figure 3.",
                "Min Cost on TDT3 (δ =0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ Comparingtimes 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 Figure 4.",
                "Comparing times on TDT3 (δ =0.15) Figure 4 gives the comparing times used by system-3 on TDT3 with the same parameters as figure 3.",
                "The comparing times are strongly dependent onθ init.",
                "Because the greaterθ init is, the less stories combined together, the more comparing times are needed for new event decision.",
                "So we useθ init =0.13,λ =3,δ =0.15 for system-3, 4, and 5.",
                "In this parameter setting, we can get both low minimum normalized costs and less comparing times. 8.",
                "CONCLUSION We have proposed a news indexing-tree based detection procedure in our model.",
                "It reduces comparing times to about one seventh of traditional method without hurting NED accuracy.",
                "We also have presented two extensions to the basic TF-IDF model.",
                "The first extension is made by adjust term weights based on term distributions between the whole corpus and a cluster story set.",
                "And the second extension to basic TF-IDF model is better use of term types (named entities types and part-of-speed) according to news categories.",
                "Our experimental results on TDT2 and TDT3 datasets show that both of the two extensions contribute significantly to improvement in accuracy.",
                "We did not consider news time information as a clue for NED task, since most of the topics last for a long time and TDT data sets only span for a relative short period (no more than 6 months).",
                "For the future work, we want to collect news set which span for a longer period from internet, and integrate time information in NED task.",
                "Since topic is a relative coarse-grained news cluster, we also want to refine cluster granularity to event-level, and identify different events and their relations within a topic.",
                "Acknowledgments This work is supported by the National Natural Science Foundation of China under Grant No. 90604025.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] In Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. .01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90 1 2 5 10 20 40 60 80 90 False Alarm Probability (in %) MissProbability(in%) SYSTEM1 Topic Weighted Curve SYSTEM1 Min Norm(Cost) SYSTEM2 Topic Weighted Curve SYSTEM2 Min Norm(Cost) SYSTEM3 Topic Weighted Curve SYSTEM3 Min Norm(Cost) SYSTEM4 Topic Weighted Curve SYSTEM4 Min Norm(Cost) SYSTEM5 Topic Weighted Curve SYSTEM5 Min Norm(Cost) Random Performance Figure 5.",
                "DET curves on TDT3 [3] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B.T.",
                "Archibald, and X. Liu.",
                "Learning Approaches for Detecting and Tracking News Events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), 1999, 32-43. [4] Y. Yang, T. Pierce, and J. Carbonell.",
                "A Study on Retrospective and On-line Event Detection.",
                "In Proceedings of SIGIR-98, Melbourne, Australia, 1998, 28-36. [5] J. Allan, V. Lavrenko, D. Malin, and R. Swan.",
                "Detections, Bounds, and Timelines: Umass and tdt-3.",
                "In Proceedings of Topic Detection and Tracking Workshop (TDT-3), Vienna, VA, 2000, 167-174. [6] R. Papka and J. Allan.",
                "On-line New Event Detection Using Single Pass Clustering TITLE2:.",
                "Technical Report UM-CS1998-021, 1998. [7] W. Lam, H. Meng, K. Wong, and J.",
                "Yen.",
                "Using Contextual Analysis for News Event Detection.",
                "International Journal on Intelligent Systems, 2001, 525-546. [8] B. Thorsten, C. Francine, and F. Ayman.",
                "A System for New Event Detection.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2003, 330-337. [9] S. Nicola and C. Joe.",
                "Combining Semantic and Syntactic Document Classifiers to Improve First Story Detection.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2001, 424425. [10] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topicconditioned Novelty Detection.",
                "In Proceedings of the 8th ACM SIGKDD International Conference, ACM Press. 2002, 688-693. [11] M. Juha, A.M. Helena, and S. Marko.",
                "Applying Semantic Classes in Event Detection and Tracking.",
                "In Proceedings of International Conference on Natural Language Processing (ICON 2002), 2002, pages 175-183. [12] M. Juha, A.M. Helena, and S. Marko.",
                "Simple Semantics in Topic Detection and Tracking.",
                "Information Retrieval, 7(3-4): 2004, 347-368. [13] K. Giridhar and J. Allan.",
                "Text Classification and Named Entities for New Event Detection.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2004, 297-304. [14] J. P. Callan, W. B. Croft, and S. M. Harding.",
                "The INQUERY Retrieval System.",
                "In Proceedings of DEXA-92, 3rd International Conference on Database and Expert Systems Applications, 1992, 78-83. [15] R. Krovetz.",
                "Viewing Morphology as An Inference Process.",
                "In Proceedings of ACM SIGIR93, 1993, 61-81. [16] Y. Yang and J. Pedersen.",
                "A Comparative Study on Feature Selection in Text Categorization.",
                "In J. D. H. Fisher, editor, The Fourteenth International Conference on Machine Learning (ICML97), Morgan Kaufmann, 1997, 412-420. [17] T. M. Cover, and J.A.",
                "Thomas.",
                "Elements of Information Theory.",
                "Wiley. 1991. [18] The linguistic data consortium, http://www.ldc,upenn.edu/. [19] The 2001 TDT task definition and evaluation plan, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm. [20] R. E. Schapire and Y.",
                "Singer.",
                "Boostexter: A Boosting-based System for Text Categorization.",
                "In Machine Learning 39(2/3):1, Kluwer Academic Publishers, 2000, 35-168. [21] K. Giridhar and J. Allan. 2005.",
                "Using Names and Topics for New Event Detection.",
                "In Proceedings of Human Technology Conference and Conference on Empirical Methods in Natural Language, Vancouver, 2005, 121-128"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Obviamente, el modelo modificado puede cumplir con todos los requisitos de las cinco clases de términos enumeradas anteriormente.5.2 Término de rewesaveo basado en el tipo de término y la \"clase de la historia\" El trabajo anterior descubrió que algunas clases de noticias podrían lograr buenas mejoras al dar peso adicional a las entidades nombradas."
            ],
            "translated_text": "",
            "candidates": [
                "clase de cuentos",
                "clase de la historia"
            ],
            "error": []
        },
        "linguistic data consortium": {
            "translated_key": "Consorcio de datos lingüísticos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "New Event Detection Based on Indexing-tree and Named Entity Zhang Kuo Tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn Li Juan Zi Tsinghua University Beijing, 100084, China 86-10-62781461 ljz@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn ABSTRACT New Event Detection (NED) aims at detecting from one or multiple streams of news stories that which one is reported on a new event (i.e.",
                "not reported previously).",
                "With the overwhelming volume of news available today, there is an increasing need for a NED system which is able to detect new events more efficiently and accurately.",
                "In this paper we propose a new NED model to speed up the NED task by using news indexing-tree dynamically.",
                "Moreover, based on the observation that terms of different types have different effects for NED task, two term reweighting approaches are proposed to improve NED accuracy.",
                "In the first approach, we propose to adjust term weights dynamically based on previous story clusters and in the second approach, we propose to employ statistics on training data to learn the named entity reweighting model for each class of stories.",
                "Experimental results on two <br>linguistic data consortium</br> (LDC) datasets TDT2 and TDT3 show that the proposed model can improve both efficiency and accuracy of NED task significantly, compared to the baseline system and other existing systems.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Search and Retrieval; H.4.2 [Information Systems Applications]: Types of Systemsdecision support.",
                "General Terms Algorithms, Performance, Experimentation 1.",
                "INTRODUCTION Topic Detection and Tracking (TDT) program aims to develop techniques which can effectively organize, search and structure news text materials from a variety of newswire and broadcast media [1].",
                "New Event Detection (NED) is one of the five tasks in TDT.",
                "It is the task of online identification of the earliest report for each topic as soon as that report arrives in the sequence of documents.",
                "A Topic is defined as a seminal event or activity, along with directly related events and activities [2].",
                "An Event is defined as something (non-trivial) happening in a certain place at a certain time [3].",
                "For instance, when a bomb explodes in a building, the exploding is the seminal event that triggers the topic, and other stories on the same topic would be those discussing salvaging efforts, the search for perpetrators, arrests and trial and so on.",
                "Useful news information is usually buried in a mass of data generated everyday.",
                "Therefore, NED systems are very useful for people who need to detect novel information from real-time news stream.",
                "These real-life needs often occur in domains like financial markets, news analysis, and intelligence gathering.",
                "In most of state-of-the-art (currently) NED systems, each news story on hand is compared to all the previous received stories.",
                "If all the similarities between them do not exceed a threshold, then the story triggers a new event.",
                "They are usually in the form of cosine similarity or Hellinger similarity metric.",
                "The core problem of NED is to identify whether two stories are on the same topic.",
                "Obviously, these systems cannot take advantage of topic information.",
                "Further more, it is not acceptable in real applications because of the large amount of computation required in the NED process.",
                "Other systems organize previous stories into clusters (each cluster corresponds to a topic), and new story is compared to the previous clusters instead of stories.",
                "This manner can reduce comparing times significantly.",
                "Nevertheless, it has been proved that this manner is less accurate [4, 5].",
                "This is because sometimes stories within a topic drift far away from each other, which could lead low similarity between a story and its topic.",
                "On the other hand, some proposed NED systems tried to improve accuracy by making better use of named entities [10, 11, 12, 13].",
                "However, none of the systems have considered that terms of different types (e.g.",
                "Noun, Verb or Person name) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "For example, the names of election candidates (Person name) are very important for stories of election class; the locations (Location name) where accidents happened are important for stories of accidents class.",
                "So, in NED, there still exist following three problems to be investigated: (1) How to speed up the detection procedure while do not decrease the detection accuracy? (2) How to make good use of cluster (topic) information to improve accuracy? (3) How to obtain better news story representation by better understanding of named entities.",
                "Driven by these problems, we have proposed three approaches in this paper. (1)To make the detection procedure faster, we propose a new NED procedure based on news indexing-tree created dynamically.",
                "Story indexing-tree is created by assembling similar stories together to form news clusters in different hierarchies according to their values of similarity.",
                "Comparisons between current story and previous clusters could help find the most similar story in less comparing times.",
                "The new procedure can reduce the amount of comparing times without hurting accuracy. (2)We use the clusters of the first floor in the indexing-tree as news topics, in which term weights are adjusted dynamically according to term distribution in the clusters.",
                "In this approach, cluster (topic) information is used properly, so the problem of theme decentralization is avoided. (3)Based on observations on the statistics obtained from training data, we found that terms of different types (e.g.",
                "Noun and Verb) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "And we propose to use statistics to optimize the weights of the terms of different types in a story according to the news class that the story belongs to.",
                "On TDT3 dataset, the new NED model just uses 14.9% comparing times of the basic model, while its minimum normalized cost is 0.5012, which is 0.0797 better than the basic model, and also better than any other results previously reported for this dataset [8, 13].",
                "The rest of the paper is organized as follows.",
                "We start off this paper by summarizing the previous work in NED in section 2.",
                "Section 3 presents the basic model for NED that most current systems use.",
                "Section 4 describes our new detection procedure based on news indexing-tree.",
                "In section 5, two term reweighting methods are proposed to improve NED accuracy.",
                "Section 6 gives our experimental data and evaluation metrics.",
                "We finally wrap up with the experimental results in Section 7, and the conclusions and future work in Section 8. 2.",
                "RELATED WORK Papka et al. proposed Single-Pass clustering on NED [6].",
                "When a new story was encountered, it was processed immediately to extract term features and a query representation of the storys content is built up.",
                "Then it was compared with all the previous queries.",
                "If the document did not trigger any queries by exceeding a threshold, it was marked as a new event.",
                "Lam et al build up previous query representations of story clusters, each of which corresponds to a topic [7].",
                "In this manner comparisons happen between stories and clusters.",
                "Recent years, most work focus on proposing better methods on comparison of stories and document representation.",
                "Brants et al. [8] extended a basic incremental TF-IDF model to include sourcespecific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, term reweighting based on inverse event frequencies, and segmentation of documents.",
                "Good improvements on TDT bench-marks were shown.",
                "Stokes et al. [9] utilized a combination of evidence from two distinct representations of a documents content.",
                "One of the representations was the usual free text vector, the other made use of lexical chains (created using WordNet) to build another term vector.",
                "Then the two representations are combined in a linear fashion.",
                "A marginal increase in effectiveness was achieved when the combined representation was used.",
                "Some efforts have been done on how to utilize named entities to improve NED.",
                "Yang et al. gave location named entities four times weight than other terms and named entities [10].",
                "DOREMI research group combined semantic similarities of person names, location names and time together with textual similarity [11][12].",
                "UMass [13] research group split document representation into two parts: named entities and non-named entities.",
                "And it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation.",
                "Both [10] and [13] used text categorization technique to classify news stories in advance.",
                "In [13] news stories are classified automatically at first, and then test sensitivities of names and non-name terms for NED for each class.",
                "In [10] frequent terms for each class are removed from document representation.",
                "For example, word election does not help identify different elections.",
                "In their work, effectiveness of different kinds of names (or terms with different POS) for NED in different news classes are not investigated.",
                "We use statistical analysis to reveal the fact and use it to improve NED performance. 3.",
                "BASIC MODEL In this section, we present the basic New Event Detection model which is similar to what most current systems apply.",
                "Then, we propose our new model by extending the basic model.",
                "New Event Detection systems use news story stream as input, in which stories are strictly time-ordered.",
                "Only previously received stories are available when dealing with current story.",
                "The output is a decision for whether the current story is on a new event or not and the confidence of the decision.",
                "Usually, a NED model consists of three parts: story representation, similarity calculation and detection procedure. 3.1 Story Representation Preprocessing is needed before generating story representation.",
                "For preprocessing, we tokenize words, recognize abbreviations, normalize abbreviations, add part-of-speech tags, remove stopwords included in the stop list used in InQuery [14], replace words with their stems using K-stem algorithm[15], and then generate word vector for each news story.",
                "We use incremental TF-IDF model for term weight calculation [4].",
                "In a TF-IDF model, term frequency in a news document is weighted by the inverse document frequency, which is generated from training corpus.",
                "When a new term occurs in testing process, there are two solutions: simply ignore the new term or set df of the term as a small const (e.g. df = 1).",
                "The new term receives too low weight in the first solution (0) and too high weight in the second solution.",
                "In incremental TF-IDF model, document frequencies are updated dynamically in each time step t: 1( ) ( ) ( )t t D tdf w df w df w−= + (1) where Dt represents news story set received in time t, and dfDt(w) means the number of documents that term w occurs in, and dft(w) means the total number of documents that term w occurs in before time t. In this work, each time window includes 50 news stories.",
                "Thus, each story d received in t is represented as follows: 1 2{ ( , , ), ( , , ),..., ( , , )}nd weight d t w weight d t w weight d t w→ where n means the number of distinct terms in story d, and ( , , )weight d t w means the weight of term w in story d at time t: log( ( , ) 1) log(( 1) /( ( ) 0.5)) ( , , ) log( ( , ) 1) log(( 1) /( ( ) 0.5)) t t t t w d tf d w N df w weight d t w tf d w N df w ∈ + + + = + + +∑ (2) where Nt means the total number of news stories before time t, and tf(d,w) means how many times term w occurs in news story d. 3.2 Similarity Calculation We use Hellinger distance for the calculation of similarity between two stories, for two stories d and d at time t, their similarity is defined as follows: , ( , , ) ( , , ) * ( , , ) w d d sim d d t weight d t w weight d t w ∈ = ∑ (3) 3.3 Detection Procedure For each story d received in time step t, the value ( ) ( ) ( ) ( ( , , )) time d time d n d max sim d d t < = (4) is a score used to determine whether d is a story about a new topic and at the same time is an indication of the confidence in our decision [8]. time(d) means the publication time of story d. If the score exceeds the thresholdθ new, then there exists a sufficiently similar document, thus d is a old story, otherwise, there is no sufficiently similar previous document, thus d is an new story. 4.",
                "New NED Procedure Traditional NED systems can be classified into two main types on the aspect of detection procedure: (1) S-S type, in which the story on hand is compared to each story received previously, and use the highest similarity to determine whether current story is about a new event; (2) S-C type, in which the story on hand is compared to all previous clusters each of which representing a topic, and the highest similarity is used for final decision for current story.",
                "If the highest similarity exceeds thresholdθ new, then it is an old story, and put it into the most similar cluster; otherwise it is a new story and create a new cluster.",
                "Previous work show that the first manner is more accurate than the second one [4][5].",
                "Since sometimes stories within a topic drift far away from each other, a story may have very low similarity with its topic.",
                "So using similarities between stories for determining new story is better than using similarities between story and clusters.",
                "Nevertheless, the first manner needs much more comparing times which means the first manner is low efficient.",
                "We propose a new detection procedure which uses comparisons with previous clusters to help find the most similar story in less comparing times, and the final new event decision is made according to the most similar story.",
                "Therefore, we can get both the accuracy of S-S type methods and the efficiency of S-C type methods.",
                "The new procedure creates a news indexing-tree dynamically, in which similar stories are put together to form a hierarchy of clusters.",
                "We index similar stories together by their common ancestor (a cluster node).",
                "Dissimilar stories are indexed in different clusters.",
                "When a story is coming, we use comparisons between the current story and previous hierarchical clusters to help find the most similar story which is useful for new event decision.",
                "After the new event decision is made, the current story is inserted to the indexing-tree for the following detection.",
                "The news indexing-tree is defined formally as follows: S-Tree = {r, NC , NS , E} where r is the root of S-Tree, NC is the set of all cluster nodes, NS is the set of all story nodes, and E is the set of all edges in S-Tree.",
                "We define a set of constraints for a S-Tree: ⅰ . , is an non-terminal node in the treeC i i N i∀ ∈ → ⅱ . , is a terminal node in the treeS i i N i∀ ∈ → ⅲ . , out degree of is at least 2C i i N i∀ ∈ → ⅳ . , is represented as the centroid of its desendantsC i i iN∀ ∈ → For a news story di, the comparison procedure and inserting procedure based on indexing-tree are defined as follows.",
                "An example is shown by Figure 1 and Figure 2.",
                "Figure 1.",
                "Comparison procedure Figure 2.",
                "Inserting procedure Comparison procedure: Step 1: compare di to all the direct child nodes of r and select λ nodes with highest similarities, e.g., C1 2 and C1 3 in Figure 1.",
                "Step 2: for each selected node in the last step, e.g.",
                "C1 2, compare di to all its direct child nodes, and select λ nodes with highest similarities, e.g.",
                "C2 2 and d8.",
                "Repeat step 2 for all non-terminal nodes.",
                "Step 3: record the terminal node with the highest similarty to di, e.g. s5, and the similarity value (0.20).",
                "Inserting di to the S-tree with r as root: Find the node n which is direct child of r in the path from r to the terminal node with highest similarity s, e.g.",
                "C1 2.",
                "If s is smaller than θ init+(h-1)δ , then add di to the tree as a direct child of r. Otherwise, if n is a terminal node, then create a cluster node instead of n, and add both n and di as its direct children; if n is an non-terminal node, then repeat this procedure and insert di to the sub-tree with n as root recursively.",
                "Here h is the length between n and the root of S-tree.",
                "The more the stories in a cluster similar to each other, the better the cluster represents the stories in it.",
                "Hence we add no constraints on the maximum of trees height and degree of a node.",
                "Therefore, we cannot give the complexity of this indexing-tree based procedure.",
                "But we will give the number of comparing times needed by the new procedure in our experiments in section7. 5.",
                "Term Reweighting Methods In this section, two term reweighting methods are proposed to improve NED accuracy.",
                "In the first method, a new way is explored for better using of cluster (topic) information.",
                "The second one finds a better way to make use of named entities based on news classification. 5.1 Term Reweighting Based on Distribution Distance TF-IDF is the most prevalent model used in information retrieval systems.",
                "The basic idea is that the fewer documents a term appears in, the more important the term is in discrimination of documents (relevant or not relevant to a query containing the term).",
                "Nevertheless, in TDT domain, we need to discriminate documents with regard to topics rather than queries.",
                "Intuitively, using cluster (topic) vectors to compare with subsequent news stories should outperform using story vectors.",
                "Unfortunately, the experimental results do not support this intuition [4][5].",
                "Based on observation on data, we find the reason is that a news topic usually contains many directly or indirectly related events, while they all have their own sub-subjects which are usually different with each other.",
                "Take the topic described in section 1 as an example, events like the explosion and salvage have very low similarities with events about criminal trial, therefore stories about trial would have low similarity with the topic vector built on its previous events.",
                "This section focuses on how to effectively make use of topic information and at the same time avoid the problem of content decentralization.",
                "At first, we classify terms into 5 classes to help analysis the needs of the modified model: Term class A: terms that occur frequently in the whole corpus, e.g., year and people.",
                "Terms of this class should be given low weights because they do not help much for topic discrimination.",
                "Term class B: terms that occur frequently within a news category, e.g., election, storm.",
                "They are useful to distinguish two stories in different news categories.",
                "However, they cannot provide information to determine whether two stories are on the same or different topics.",
                "In another words, term election and term storm are not helpful in differentiate two election campaigns and two storm disasters.",
                "Therefore, terms of this class should be assigned lower weights.",
                "Term class C: terms that occur frequently in a topic, and infrequently in other topics, e.g., the name of a crash plane, the name of a specific hurricane.",
                "News stories that belong to different topics rarely have overlap terms in this class.",
                "The more frequently a term appears in a topic, the more important the term is for a story belonging to the topic, therefore the term should be set higher weight.",
                "Term class D: terms that appear in a topic exclusively, but not frequently.",
                "For example, the name of a fireman who did very well in a salvage action, which may appears in only two or three stories but never appeared in other topics.",
                "Terms of this type should receive more weights than in TF-IDF model.",
                "However, since they are not popular in the topic, it is not appropriate to give them too high weights.",
                "Term class E: terms with low document frequency, and appear in different topics.",
                "Terms of this class should receive lower weights.",
                "Now we analyze whether TF-IDF model can give proper weights to the five classes of terms.",
                "Obviously, terms of class A are lowly weighted in TF-IDF model, which is conformable with the requirement described above.",
                "In TF-IDF model, terms of class B are highly dependant with the number of stories in a news class.",
                "TF-IDF model cannot provide low weights if the story containing the term belongs to a relative small news class.",
                "For a term of class C, the more frequently it appears in a topic, the less weight TFIDF model gives to it.",
                "This strongly conflicts with the requirement of terms in class C. For terms of class D, TF-IDF model gives them high weights correctly.",
                "But for terms of class E, TF-IDF model gives high weights to them which are not conformable with the requirement of low weights.",
                "To sum up, terms of class B, C, E cannot be properly weighted in TF-IDF model.",
                "So, we propose a modified model to resolve this problem.",
                "When θ init andθ new are set closely, we assume that most of the stories in a first-level cluster (a direct child node of root node) are on the same topic.",
                "Therefore, we make use of a first-level cluster to capture term distribution (df for all the terms within the cluster) within the topic dynamically.",
                "KL divergence of term distribution in a first-level cluster and the whole story set is used to adjust term weights:  ( , , ) * (1 * ( || )) ( , , ) ( , , ) * (1 * ( || )) cw tw cw tw w d D weight d t w KL P P weight d t w weight d t w KL P P γ γ ∈ + = +∑ (5) where ( ) ( ) ( ) ( ) 1,cw cw c c c c df w df w p y p y N N = = − (6) ( ) ( ) ( ) ( ) 1,t t tw tw t t df w df w p y p y N N = = − (7) where dfc(w) is the number of documents containing term w within cluster C, and Nc is the number of documents in cluster C, and Nt is the total number of documents that arrive before time step t. γ is a const parameter, now is manually set 3.",
                "KL divergence is defined as follows [17]: ( ) ( || ) ( ) log ( )x p x KL P Q p x q x = ∑ (8) The basic idea is: for a story in a topic, the more a term occurs within the topic, and the less it occurs in other topics, it should be assigned higher weights.",
                "Obviously, modified model can meet all the requirements of the five term classes listed above. 5.2 Term Reweighting Based on Term Type and Story Class Previous work found that some classes of news stories could achieve good improvements by giving extra weight to named entities.",
                "But we find that terms of different types should be given different amount of extra weight for different classes of news stories.",
                "We use open-NLP1 to recognize named entity types and part-ofspeech tags for terms that appear in news stories.",
                "Named entity types include person name, organization name, location name, date, time, money and percentage, and five POSs are selected: none (NN), verb (VB), adjective (JJ), adverb (RB) and cardinal number (CD).",
                "Statistical analysis shows topic-level discriminative terms types for different classes of stories.",
                "For the sake of convenience, named entity type and part-of-speech tags are uniformly called term type in subsequent sections.",
                "Determining whether two stories are about the same topic is a basic component for NED task.",
                "So at first we use 2 χ statistic to compute correlations between terms and topics.",
                "For a term t and a topic T, a contingence table is derived: Table 1.",
                "A 2×2 Contingence Table Doc Number belong to topic T not belong to topic T include t A B not include t C D The 2 χ statistic for a specific term t with respect to topic T is defined to be [16]: 2 2 ( , ) ( ) * ( ) ( ) * ( ) * ( ) * ( ) w T A B C D AD CB A C B D A B C D χ = + + + − + + + + (9) News topics for the TDT task are further classified into 11 rules of interpretations (ROIs) 2 .",
                "The ROI can be seen as a higher level class of stories.",
                "The average correlation between a term type and a topic ROI is computed as: 2 avg 2 ( , )( ( , ) )k m m km kT R w P w TP R p w T R P χ χ ∈ ∈ ∑ ∑（ , ）= 1 1 k=1…K, m=1…M (10) where K is the number of term types (set 12 constantly in the paper).",
                "M is the number news classes (ROIs, set 11 in the paper).",
                "Pk represents the set of all terms of type k, and Rm represents the set of all topics of class m, p(t,T) means the probability that t occurs in topic T. Because of limitation of space, only parts of the term types (9 term types) and parts of news classes (8 classes) are listed in table 2 with the average correlation values between them.",
                "The statistics is derived from labeled data in TDT2 corpus. (Results in table 2 are already normalized for convenience in comparison.)",
                "The statistics in table 2 indicates the usefulness of different term types in topic discrimination with respect to different news classes.",
                "We can see that, location name is the most useful term type for three news classes: Natural Disasters, Violence or War, Finances.",
                "And for three other categories Elections, Legal/Criminal Cases, Science and Discovery, person name is the most discriminative term type.",
                "For Scandals/Hearings, date is the most important information for topic discrimination.",
                "In addition, Legal/Criminal Cases and Finance topics have higher correlation with money terms, while Science and Discovery have higher correlation with percentage terms.",
                "Non-name terms are more stable for different classes. 1 . http://opennlp.sourceforge.net/ 2 . http://projects.ldc.upenn.edu/TDT3/Guide/label.html From the analysis of table 2, it is reasonable to adjust term weight according to their term type and the news class the story belongs to.",
                "New term weights are reweighted as follows: ( ) ( ) ( ) ( ) ( , , ) * ( , , ) ( , , ) * class d D type w T class d D type w w d weight d t w weight d t w weight d t w α α ∈ = ∑ (11) where type(w) represents the type of term w, and class(d) represents the class of story d, c kα is reweighting parameter for news class c and term type k. In the work, we just simply use statistics in table 2 as the reweighting parameters.",
                "Even thought using the statistics directly may not the best choice, we do not discuss how to automatically obtain the best parameters.",
                "We will try to use machine learning techniques to obtain the best parameters in the future work.",
                "In the work, we use BoosTexter [20] to classify all stories into one of the 11 ROIs.",
                "BoosTexter is a boosting based machine learning program, which creates a series of simple rules for building a classifier for text or attribute-value data.",
                "We use term weight generated using TF-IDF model as feature for story classification.",
                "We trained the model on the 12000 judged English stories in TDT2, and classify the rest of the stories in TDT2 and all stories in TDT3.",
                "Classification results are used for term reweighting in formula (11).",
                "Since the class labels of topic-off stories are not given in TDT datasets, we cannot give the classification accuracy here.",
                "Thus we do not discuss the effects of classification accuracy to NED performance in the paper. 6.",
                "EXPERIMENTAL SETUP 6.1 Datasets We used two LDC [18] datasets TDT2 and TDT3 for our experiments.",
                "TDT2 contains news stories from January to June 1998.",
                "It contains around 54,000 stories from sources like ABC, Associated Press, CNN, New York Times, Public Radio International, Voice of America etc.",
                "Only English stories in the collection were considered.",
                "TDT3 contains approximately 31,000 English stories collected from October to December 1998.",
                "In addition to the sources used in TDT2, it also contains stories from NBC and MSNBC TV broadcasts.",
                "We used transcribed versions of the TV and radio broadcasts besides textual news.",
                "TDT2 dataset is labeled with about 100 topics, and approximately 12,000 English stories belong to at least one of these topics.",
                "TDT3 dataset is labeled with about 120 topics, and approximately 8000 English stories belong to at least one of these topics.",
                "All the topics are classified into 11 Rules of Interpretation: (1)Elections, (2)Scandals/Hearings, (3)Legal/Criminal Cases, (4)Natural Disasters, (5)Accidents, (6)Ongoing Violence or War, (7)Science and Discovery News, (8)Finance, (9)New Law, (10)Sports News, (11)MISC.",
                "News. 6.2 Evaluation Metric TDT uses a cost function CDet that combines the probabilities of missing a new story and a false alarm [19]: * * * *Det Miss Miss Target FA FA NontargetC C P P C P P= + (12) Table 2.",
                "Average correlation between term types and news classes where CMiss means the cost of missing a new story, PMiss means the probability of missing a new story, and PTarget means the probability of seeing a new story in the data; CFA means the cost of a false alarm, PFA means the probability of a false alarm, and PNontarget means the probability of seeing an old story.",
                "The cost CDet is normalized such that a perfect system scores 0 and a trivial system, which is the better one of mark all stories as new or old, scores 1: ( ( * , * ) ) Det Det Miss Target FA Nontarget C Norm C min C P C P = (13) New event detection system gives two outputs for each story.",
                "The first part is yes or no indicating whether the story triggers a new event or not.",
                "The second part is a score indicating confidence of the first decision.",
                "Confidence scores can be used to plot DET curve, i.e., curves that plot false alarm vs. miss probabilities.",
                "Minimum normalized cost can be determined if optimal threshold on the score were chosen. 7.",
                "EXPERIMENTAL RESULTS 7.1 Main Results To test the approaches proposed in the model, we implemented and tested five systems: System-1: this system is used as baseline.",
                "It is implemented based on the basic model described in section 3, i.e., using incremental TF-IDF model to generate term weights, and using Hellinger distance to compute document similarity.",
                "Similarity score normalization is also employed [8].",
                "S-S detection procedure is used.",
                "System-2: this system is the same as system-1 except that S-C detection procedure is used.",
                "System-3: this system is the same as system-1 except that it uses the new detection procedure which is based on indexing-tree.",
                "System-4: implemented based on the approach presented in section 5.1, i.e., terms are reweighted according to the distance between term distributions in a cluster and all stories.",
                "The new detection procedure is used.",
                "System-5: implemented based on the approach presented in section 5.2, i.e., terms of different types are reweighted according to news class using trained parameters.",
                "The new detection procedure is used.",
                "The following are some other NED systems: System-6: [21] for each pair of stories, it computes three similarity values for named entity, non-named entity and all terms respectively.",
                "And employ Support Vector Machine to predict new or old using the similarity values as features.",
                "System-7: [8] it extended a basic incremental TF-IDF model to include source-specific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, etc.",
                "System-8: [13] it split document representation into two parts: named entities and non-named entities, and choose one effective part for each news class.",
                "Table 3 and table 4 show topic-weighted normalized costs and comparing times on TDT2 and TDT3 datasets respectively.",
                "Since no heldout data set for fine-tuning the threshold θ new was available for experiments on TDT2, we only report minimum normalized costs for our systems in table 3.",
                "System-5 outperforms all other systems including system-6, and it performs only 2.78e+8 comparing times in detection procedure which is only 13.4% of system-1.",
                "Table 3.",
                "NED results on TDT2 Systems Min Norm(CDet) Cmp times System-1 0.5749 2.08e+9 System-2① 0.6673 3.77e+8 System-3② 0.5765 2.81e+8 System-4② 0.5431 2.99e+8 System-5② 0.5089 2.78e+8 System-6 0.5300 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 When evaluating on the normalized costs on TDT3, we use the optimal thresholds obtained from TDT2 data set for all systems.",
                "System-2 reduces comparing times to 1.29e+9 which is just 18.3% of system-1, but at the same time it also gets a deteriorated minimum normalized cost which is 0.0499 higher than system-1.",
                "System-3 uses the new detection procedure based on news indexing-tree.",
                "It requires even less comparing times than system-2.",
                "This is because story-story comparisons usually yield greater similarities than story-cluster ones, so stories tend to be combined Location Person Date Organization Money Percentage NN JJ CD Elections 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 Scandals/Hearings 0.66 0.62 0.28 1 0.11 0.02 0.27 0.13 0.05 Legal/Criminal Cases 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 Natural Disasters 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 Violence or War 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 Science and Discovery 0.11 1 0.01 0.22 0.08 0.12 0.19 0.08 0.03 Finances 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 Sports 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 together in system-3.",
                "And system-3 is basically equivalent to system-1 in accuracy results.",
                "System-4 adjusts term weights based on the distance of term distributions between the whole corpus and cluster story set, yielding a good improvement by 0.0468 compared to system-1.",
                "The best system (system-5) has a minimum normalized cost 0.5012, which is 0.0797 better than system-1, and also better than any other results previously reported for this dataset [8, 13].",
                "Further more, system-5 only needs 1.05e+8 comparing times which is 14.9% of system-1.",
                "Table 4.",
                "NED results on TDT3 Systems Norm(CDet) Min Norm(CDet) Cmp times System-1 0.6159 0.5809 7.04e+8 System-2① 0.6493 0.6308 1.29e+8 System-3② 0.6197 0.5868 1.03e+8 System-4② 0.5601 0.5341 1.03e+8 System-5② 0.5413 0.5012 1.05e+8 System-7 -- 0.5783 -System-8 -- 0.5229 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 Figure5 shows the five DET curves for our systems on data set TDT3.",
                "System-5 achieves the minimum cost at a false alarm rate of 0.0157 and a miss rate of 0.4310.",
                "We can observe that System4 and System-5 obtain lower miss probability at regions of low false alarm probabilities.",
                "The hypothesis is that, more weight value is transferred to key terms of topics from non-key terms.",
                "Similarity score between two stories belonging to different topics are lower than before, because their overlapping terms are usually not key terms of their topics. 7.2 Parameter selection for indexing-tree detection Figure 3 shows the minimum normalized costs obtained by system-3 on TDT3 using different parameters.",
                "Theθ init parameter is tested on six values spanning from 0.03 to 0.18.",
                "And the λ parameter is tested on four values 1, 2, 3 and 4.",
                "We can see that, whenθ init is set to 0.12, which is the closest one toθ new, the costs are lower than others.",
                "This is easy to explain, because when stories belonging to the same topic are put in a cluster, it is more reasonable for the cluster to represent the stories in it.",
                "When parameter λ is set to 3 or 4, the costs are better than other cases, but there is no much difference between 3 and 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ MinCost 0.6 0.65 0.7 0.75 0.8 0.85 0.9 Figure 3.",
                "Min Cost on TDT3 (δ =0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ Comparingtimes 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 Figure 4.",
                "Comparing times on TDT3 (δ =0.15) Figure 4 gives the comparing times used by system-3 on TDT3 with the same parameters as figure 3.",
                "The comparing times are strongly dependent onθ init.",
                "Because the greaterθ init is, the less stories combined together, the more comparing times are needed for new event decision.",
                "So we useθ init =0.13,λ =3,δ =0.15 for system-3, 4, and 5.",
                "In this parameter setting, we can get both low minimum normalized costs and less comparing times. 8.",
                "CONCLUSION We have proposed a news indexing-tree based detection procedure in our model.",
                "It reduces comparing times to about one seventh of traditional method without hurting NED accuracy.",
                "We also have presented two extensions to the basic TF-IDF model.",
                "The first extension is made by adjust term weights based on term distributions between the whole corpus and a cluster story set.",
                "And the second extension to basic TF-IDF model is better use of term types (named entities types and part-of-speed) according to news categories.",
                "Our experimental results on TDT2 and TDT3 datasets show that both of the two extensions contribute significantly to improvement in accuracy.",
                "We did not consider news time information as a clue for NED task, since most of the topics last for a long time and TDT data sets only span for a relative short period (no more than 6 months).",
                "For the future work, we want to collect news set which span for a longer period from internet, and integrate time information in NED task.",
                "Since topic is a relative coarse-grained news cluster, we also want to refine cluster granularity to event-level, and identify different events and their relations within a topic.",
                "Acknowledgments This work is supported by the National Natural Science Foundation of China under Grant No. 90604025.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] In Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. .01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90 1 2 5 10 20 40 60 80 90 False Alarm Probability (in %) MissProbability(in%) SYSTEM1 Topic Weighted Curve SYSTEM1 Min Norm(Cost) SYSTEM2 Topic Weighted Curve SYSTEM2 Min Norm(Cost) SYSTEM3 Topic Weighted Curve SYSTEM3 Min Norm(Cost) SYSTEM4 Topic Weighted Curve SYSTEM4 Min Norm(Cost) SYSTEM5 Topic Weighted Curve SYSTEM5 Min Norm(Cost) Random Performance Figure 5.",
                "DET curves on TDT3 [3] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B.T.",
                "Archibald, and X. Liu.",
                "Learning Approaches for Detecting and Tracking News Events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), 1999, 32-43. [4] Y. Yang, T. Pierce, and J. Carbonell.",
                "A Study on Retrospective and On-line Event Detection.",
                "In Proceedings of SIGIR-98, Melbourne, Australia, 1998, 28-36. [5] J. Allan, V. Lavrenko, D. Malin, and R. Swan.",
                "Detections, Bounds, and Timelines: Umass and tdt-3.",
                "In Proceedings of Topic Detection and Tracking Workshop (TDT-3), Vienna, VA, 2000, 167-174. [6] R. Papka and J. Allan.",
                "On-line New Event Detection Using Single Pass Clustering TITLE2:.",
                "Technical Report UM-CS1998-021, 1998. [7] W. Lam, H. Meng, K. Wong, and J.",
                "Yen.",
                "Using Contextual Analysis for News Event Detection.",
                "International Journal on Intelligent Systems, 2001, 525-546. [8] B. Thorsten, C. Francine, and F. Ayman.",
                "A System for New Event Detection.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2003, 330-337. [9] S. Nicola and C. Joe.",
                "Combining Semantic and Syntactic Document Classifiers to Improve First Story Detection.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2001, 424425. [10] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topicconditioned Novelty Detection.",
                "In Proceedings of the 8th ACM SIGKDD International Conference, ACM Press. 2002, 688-693. [11] M. Juha, A.M. Helena, and S. Marko.",
                "Applying Semantic Classes in Event Detection and Tracking.",
                "In Proceedings of International Conference on Natural Language Processing (ICON 2002), 2002, pages 175-183. [12] M. Juha, A.M. Helena, and S. Marko.",
                "Simple Semantics in Topic Detection and Tracking.",
                "Information Retrieval, 7(3-4): 2004, 347-368. [13] K. Giridhar and J. Allan.",
                "Text Classification and Named Entities for New Event Detection.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2004, 297-304. [14] J. P. Callan, W. B. Croft, and S. M. Harding.",
                "The INQUERY Retrieval System.",
                "In Proceedings of DEXA-92, 3rd International Conference on Database and Expert Systems Applications, 1992, 78-83. [15] R. Krovetz.",
                "Viewing Morphology as An Inference Process.",
                "In Proceedings of ACM SIGIR93, 1993, 61-81. [16] Y. Yang and J. Pedersen.",
                "A Comparative Study on Feature Selection in Text Categorization.",
                "In J. D. H. Fisher, editor, The Fourteenth International Conference on Machine Learning (ICML97), Morgan Kaufmann, 1997, 412-420. [17] T. M. Cover, and J.A.",
                "Thomas.",
                "Elements of Information Theory.",
                "Wiley. 1991. [18] The <br>linguistic data consortium</br>, http://www.ldc,upenn.edu/. [19] The 2001 TDT task definition and evaluation plan, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm. [20] R. E. Schapire and Y.",
                "Singer.",
                "Boostexter: A Boosting-based System for Text Categorization.",
                "In Machine Learning 39(2/3):1, Kluwer Academic Publishers, 2000, 35-168. [21] K. Giridhar and J. Allan. 2005.",
                "Using Names and Topics for New Event Detection.",
                "In Proceedings of Human Technology Conference and Conference on Empirical Methods in Natural Language, Vancouver, 2005, 121-128"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Los resultados experimentales en dos conjuntos de datos de \"Consorcio de datos lingüísticos\" (LDC) TDT2 y TDT3 muestran que el modelo propuesto puede mejorar significativamente la eficiencia y la precisión de la tarea NED, en comparación con el sistema de referencia y otros sistemas existentes.",
                "Wiley.1991. [18] El \"Consorcio de datos lingüísticos\", http: //www.ldc,upenn.edu/.[19] El plan de evaluación y definición de tareas TDT 2001, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm.[20] R. E. Schapire e Y."
            ],
            "translated_text": "",
            "candidates": [
                "Consorcio de datos lingüísticos",
                "Consorcio de datos lingüísticos",
                "Consorcio de datos lingüísticos",
                "Consorcio de datos lingüísticos"
            ],
            "error": []
        },
        "baseline system": {
            "translated_key": "sistema de referencia",
            "is_in_text": true,
            "original_annotated_sentences": [
                "New Event Detection Based on Indexing-tree and Named Entity Zhang Kuo Tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn Li Juan Zi Tsinghua University Beijing, 100084, China 86-10-62781461 ljz@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn ABSTRACT New Event Detection (NED) aims at detecting from one or multiple streams of news stories that which one is reported on a new event (i.e.",
                "not reported previously).",
                "With the overwhelming volume of news available today, there is an increasing need for a NED system which is able to detect new events more efficiently and accurately.",
                "In this paper we propose a new NED model to speed up the NED task by using news indexing-tree dynamically.",
                "Moreover, based on the observation that terms of different types have different effects for NED task, two term reweighting approaches are proposed to improve NED accuracy.",
                "In the first approach, we propose to adjust term weights dynamically based on previous story clusters and in the second approach, we propose to employ statistics on training data to learn the named entity reweighting model for each class of stories.",
                "Experimental results on two Linguistic Data Consortium (LDC) datasets TDT2 and TDT3 show that the proposed model can improve both efficiency and accuracy of NED task significantly, compared to the <br>baseline system</br> and other existing systems.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Search and Retrieval; H.4.2 [Information Systems Applications]: Types of Systemsdecision support.",
                "General Terms Algorithms, Performance, Experimentation 1.",
                "INTRODUCTION Topic Detection and Tracking (TDT) program aims to develop techniques which can effectively organize, search and structure news text materials from a variety of newswire and broadcast media [1].",
                "New Event Detection (NED) is one of the five tasks in TDT.",
                "It is the task of online identification of the earliest report for each topic as soon as that report arrives in the sequence of documents.",
                "A Topic is defined as a seminal event or activity, along with directly related events and activities [2].",
                "An Event is defined as something (non-trivial) happening in a certain place at a certain time [3].",
                "For instance, when a bomb explodes in a building, the exploding is the seminal event that triggers the topic, and other stories on the same topic would be those discussing salvaging efforts, the search for perpetrators, arrests and trial and so on.",
                "Useful news information is usually buried in a mass of data generated everyday.",
                "Therefore, NED systems are very useful for people who need to detect novel information from real-time news stream.",
                "These real-life needs often occur in domains like financial markets, news analysis, and intelligence gathering.",
                "In most of state-of-the-art (currently) NED systems, each news story on hand is compared to all the previous received stories.",
                "If all the similarities between them do not exceed a threshold, then the story triggers a new event.",
                "They are usually in the form of cosine similarity or Hellinger similarity metric.",
                "The core problem of NED is to identify whether two stories are on the same topic.",
                "Obviously, these systems cannot take advantage of topic information.",
                "Further more, it is not acceptable in real applications because of the large amount of computation required in the NED process.",
                "Other systems organize previous stories into clusters (each cluster corresponds to a topic), and new story is compared to the previous clusters instead of stories.",
                "This manner can reduce comparing times significantly.",
                "Nevertheless, it has been proved that this manner is less accurate [4, 5].",
                "This is because sometimes stories within a topic drift far away from each other, which could lead low similarity between a story and its topic.",
                "On the other hand, some proposed NED systems tried to improve accuracy by making better use of named entities [10, 11, 12, 13].",
                "However, none of the systems have considered that terms of different types (e.g.",
                "Noun, Verb or Person name) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "For example, the names of election candidates (Person name) are very important for stories of election class; the locations (Location name) where accidents happened are important for stories of accidents class.",
                "So, in NED, there still exist following three problems to be investigated: (1) How to speed up the detection procedure while do not decrease the detection accuracy? (2) How to make good use of cluster (topic) information to improve accuracy? (3) How to obtain better news story representation by better understanding of named entities.",
                "Driven by these problems, we have proposed three approaches in this paper. (1)To make the detection procedure faster, we propose a new NED procedure based on news indexing-tree created dynamically.",
                "Story indexing-tree is created by assembling similar stories together to form news clusters in different hierarchies according to their values of similarity.",
                "Comparisons between current story and previous clusters could help find the most similar story in less comparing times.",
                "The new procedure can reduce the amount of comparing times without hurting accuracy. (2)We use the clusters of the first floor in the indexing-tree as news topics, in which term weights are adjusted dynamically according to term distribution in the clusters.",
                "In this approach, cluster (topic) information is used properly, so the problem of theme decentralization is avoided. (3)Based on observations on the statistics obtained from training data, we found that terms of different types (e.g.",
                "Noun and Verb) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "And we propose to use statistics to optimize the weights of the terms of different types in a story according to the news class that the story belongs to.",
                "On TDT3 dataset, the new NED model just uses 14.9% comparing times of the basic model, while its minimum normalized cost is 0.5012, which is 0.0797 better than the basic model, and also better than any other results previously reported for this dataset [8, 13].",
                "The rest of the paper is organized as follows.",
                "We start off this paper by summarizing the previous work in NED in section 2.",
                "Section 3 presents the basic model for NED that most current systems use.",
                "Section 4 describes our new detection procedure based on news indexing-tree.",
                "In section 5, two term reweighting methods are proposed to improve NED accuracy.",
                "Section 6 gives our experimental data and evaluation metrics.",
                "We finally wrap up with the experimental results in Section 7, and the conclusions and future work in Section 8. 2.",
                "RELATED WORK Papka et al. proposed Single-Pass clustering on NED [6].",
                "When a new story was encountered, it was processed immediately to extract term features and a query representation of the storys content is built up.",
                "Then it was compared with all the previous queries.",
                "If the document did not trigger any queries by exceeding a threshold, it was marked as a new event.",
                "Lam et al build up previous query representations of story clusters, each of which corresponds to a topic [7].",
                "In this manner comparisons happen between stories and clusters.",
                "Recent years, most work focus on proposing better methods on comparison of stories and document representation.",
                "Brants et al. [8] extended a basic incremental TF-IDF model to include sourcespecific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, term reweighting based on inverse event frequencies, and segmentation of documents.",
                "Good improvements on TDT bench-marks were shown.",
                "Stokes et al. [9] utilized a combination of evidence from two distinct representations of a documents content.",
                "One of the representations was the usual free text vector, the other made use of lexical chains (created using WordNet) to build another term vector.",
                "Then the two representations are combined in a linear fashion.",
                "A marginal increase in effectiveness was achieved when the combined representation was used.",
                "Some efforts have been done on how to utilize named entities to improve NED.",
                "Yang et al. gave location named entities four times weight than other terms and named entities [10].",
                "DOREMI research group combined semantic similarities of person names, location names and time together with textual similarity [11][12].",
                "UMass [13] research group split document representation into two parts: named entities and non-named entities.",
                "And it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation.",
                "Both [10] and [13] used text categorization technique to classify news stories in advance.",
                "In [13] news stories are classified automatically at first, and then test sensitivities of names and non-name terms for NED for each class.",
                "In [10] frequent terms for each class are removed from document representation.",
                "For example, word election does not help identify different elections.",
                "In their work, effectiveness of different kinds of names (or terms with different POS) for NED in different news classes are not investigated.",
                "We use statistical analysis to reveal the fact and use it to improve NED performance. 3.",
                "BASIC MODEL In this section, we present the basic New Event Detection model which is similar to what most current systems apply.",
                "Then, we propose our new model by extending the basic model.",
                "New Event Detection systems use news story stream as input, in which stories are strictly time-ordered.",
                "Only previously received stories are available when dealing with current story.",
                "The output is a decision for whether the current story is on a new event or not and the confidence of the decision.",
                "Usually, a NED model consists of three parts: story representation, similarity calculation and detection procedure. 3.1 Story Representation Preprocessing is needed before generating story representation.",
                "For preprocessing, we tokenize words, recognize abbreviations, normalize abbreviations, add part-of-speech tags, remove stopwords included in the stop list used in InQuery [14], replace words with their stems using K-stem algorithm[15], and then generate word vector for each news story.",
                "We use incremental TF-IDF model for term weight calculation [4].",
                "In a TF-IDF model, term frequency in a news document is weighted by the inverse document frequency, which is generated from training corpus.",
                "When a new term occurs in testing process, there are two solutions: simply ignore the new term or set df of the term as a small const (e.g. df = 1).",
                "The new term receives too low weight in the first solution (0) and too high weight in the second solution.",
                "In incremental TF-IDF model, document frequencies are updated dynamically in each time step t: 1( ) ( ) ( )t t D tdf w df w df w−= + (1) where Dt represents news story set received in time t, and dfDt(w) means the number of documents that term w occurs in, and dft(w) means the total number of documents that term w occurs in before time t. In this work, each time window includes 50 news stories.",
                "Thus, each story d received in t is represented as follows: 1 2{ ( , , ), ( , , ),..., ( , , )}nd weight d t w weight d t w weight d t w→ where n means the number of distinct terms in story d, and ( , , )weight d t w means the weight of term w in story d at time t: log( ( , ) 1) log(( 1) /( ( ) 0.5)) ( , , ) log( ( , ) 1) log(( 1) /( ( ) 0.5)) t t t t w d tf d w N df w weight d t w tf d w N df w ∈ + + + = + + +∑ (2) where Nt means the total number of news stories before time t, and tf(d,w) means how many times term w occurs in news story d. 3.2 Similarity Calculation We use Hellinger distance for the calculation of similarity between two stories, for two stories d and d at time t, their similarity is defined as follows: , ( , , ) ( , , ) * ( , , ) w d d sim d d t weight d t w weight d t w ∈ = ∑ (3) 3.3 Detection Procedure For each story d received in time step t, the value ( ) ( ) ( ) ( ( , , )) time d time d n d max sim d d t < = (4) is a score used to determine whether d is a story about a new topic and at the same time is an indication of the confidence in our decision [8]. time(d) means the publication time of story d. If the score exceeds the thresholdθ new, then there exists a sufficiently similar document, thus d is a old story, otherwise, there is no sufficiently similar previous document, thus d is an new story. 4.",
                "New NED Procedure Traditional NED systems can be classified into two main types on the aspect of detection procedure: (1) S-S type, in which the story on hand is compared to each story received previously, and use the highest similarity to determine whether current story is about a new event; (2) S-C type, in which the story on hand is compared to all previous clusters each of which representing a topic, and the highest similarity is used for final decision for current story.",
                "If the highest similarity exceeds thresholdθ new, then it is an old story, and put it into the most similar cluster; otherwise it is a new story and create a new cluster.",
                "Previous work show that the first manner is more accurate than the second one [4][5].",
                "Since sometimes stories within a topic drift far away from each other, a story may have very low similarity with its topic.",
                "So using similarities between stories for determining new story is better than using similarities between story and clusters.",
                "Nevertheless, the first manner needs much more comparing times which means the first manner is low efficient.",
                "We propose a new detection procedure which uses comparisons with previous clusters to help find the most similar story in less comparing times, and the final new event decision is made according to the most similar story.",
                "Therefore, we can get both the accuracy of S-S type methods and the efficiency of S-C type methods.",
                "The new procedure creates a news indexing-tree dynamically, in which similar stories are put together to form a hierarchy of clusters.",
                "We index similar stories together by their common ancestor (a cluster node).",
                "Dissimilar stories are indexed in different clusters.",
                "When a story is coming, we use comparisons between the current story and previous hierarchical clusters to help find the most similar story which is useful for new event decision.",
                "After the new event decision is made, the current story is inserted to the indexing-tree for the following detection.",
                "The news indexing-tree is defined formally as follows: S-Tree = {r, NC , NS , E} where r is the root of S-Tree, NC is the set of all cluster nodes, NS is the set of all story nodes, and E is the set of all edges in S-Tree.",
                "We define a set of constraints for a S-Tree: ⅰ . , is an non-terminal node in the treeC i i N i∀ ∈ → ⅱ . , is a terminal node in the treeS i i N i∀ ∈ → ⅲ . , out degree of is at least 2C i i N i∀ ∈ → ⅳ . , is represented as the centroid of its desendantsC i i iN∀ ∈ → For a news story di, the comparison procedure and inserting procedure based on indexing-tree are defined as follows.",
                "An example is shown by Figure 1 and Figure 2.",
                "Figure 1.",
                "Comparison procedure Figure 2.",
                "Inserting procedure Comparison procedure: Step 1: compare di to all the direct child nodes of r and select λ nodes with highest similarities, e.g., C1 2 and C1 3 in Figure 1.",
                "Step 2: for each selected node in the last step, e.g.",
                "C1 2, compare di to all its direct child nodes, and select λ nodes with highest similarities, e.g.",
                "C2 2 and d8.",
                "Repeat step 2 for all non-terminal nodes.",
                "Step 3: record the terminal node with the highest similarty to di, e.g. s5, and the similarity value (0.20).",
                "Inserting di to the S-tree with r as root: Find the node n which is direct child of r in the path from r to the terminal node with highest similarity s, e.g.",
                "C1 2.",
                "If s is smaller than θ init+(h-1)δ , then add di to the tree as a direct child of r. Otherwise, if n is a terminal node, then create a cluster node instead of n, and add both n and di as its direct children; if n is an non-terminal node, then repeat this procedure and insert di to the sub-tree with n as root recursively.",
                "Here h is the length between n and the root of S-tree.",
                "The more the stories in a cluster similar to each other, the better the cluster represents the stories in it.",
                "Hence we add no constraints on the maximum of trees height and degree of a node.",
                "Therefore, we cannot give the complexity of this indexing-tree based procedure.",
                "But we will give the number of comparing times needed by the new procedure in our experiments in section7. 5.",
                "Term Reweighting Methods In this section, two term reweighting methods are proposed to improve NED accuracy.",
                "In the first method, a new way is explored for better using of cluster (topic) information.",
                "The second one finds a better way to make use of named entities based on news classification. 5.1 Term Reweighting Based on Distribution Distance TF-IDF is the most prevalent model used in information retrieval systems.",
                "The basic idea is that the fewer documents a term appears in, the more important the term is in discrimination of documents (relevant or not relevant to a query containing the term).",
                "Nevertheless, in TDT domain, we need to discriminate documents with regard to topics rather than queries.",
                "Intuitively, using cluster (topic) vectors to compare with subsequent news stories should outperform using story vectors.",
                "Unfortunately, the experimental results do not support this intuition [4][5].",
                "Based on observation on data, we find the reason is that a news topic usually contains many directly or indirectly related events, while they all have their own sub-subjects which are usually different with each other.",
                "Take the topic described in section 1 as an example, events like the explosion and salvage have very low similarities with events about criminal trial, therefore stories about trial would have low similarity with the topic vector built on its previous events.",
                "This section focuses on how to effectively make use of topic information and at the same time avoid the problem of content decentralization.",
                "At first, we classify terms into 5 classes to help analysis the needs of the modified model: Term class A: terms that occur frequently in the whole corpus, e.g., year and people.",
                "Terms of this class should be given low weights because they do not help much for topic discrimination.",
                "Term class B: terms that occur frequently within a news category, e.g., election, storm.",
                "They are useful to distinguish two stories in different news categories.",
                "However, they cannot provide information to determine whether two stories are on the same or different topics.",
                "In another words, term election and term storm are not helpful in differentiate two election campaigns and two storm disasters.",
                "Therefore, terms of this class should be assigned lower weights.",
                "Term class C: terms that occur frequently in a topic, and infrequently in other topics, e.g., the name of a crash plane, the name of a specific hurricane.",
                "News stories that belong to different topics rarely have overlap terms in this class.",
                "The more frequently a term appears in a topic, the more important the term is for a story belonging to the topic, therefore the term should be set higher weight.",
                "Term class D: terms that appear in a topic exclusively, but not frequently.",
                "For example, the name of a fireman who did very well in a salvage action, which may appears in only two or three stories but never appeared in other topics.",
                "Terms of this type should receive more weights than in TF-IDF model.",
                "However, since they are not popular in the topic, it is not appropriate to give them too high weights.",
                "Term class E: terms with low document frequency, and appear in different topics.",
                "Terms of this class should receive lower weights.",
                "Now we analyze whether TF-IDF model can give proper weights to the five classes of terms.",
                "Obviously, terms of class A are lowly weighted in TF-IDF model, which is conformable with the requirement described above.",
                "In TF-IDF model, terms of class B are highly dependant with the number of stories in a news class.",
                "TF-IDF model cannot provide low weights if the story containing the term belongs to a relative small news class.",
                "For a term of class C, the more frequently it appears in a topic, the less weight TFIDF model gives to it.",
                "This strongly conflicts with the requirement of terms in class C. For terms of class D, TF-IDF model gives them high weights correctly.",
                "But for terms of class E, TF-IDF model gives high weights to them which are not conformable with the requirement of low weights.",
                "To sum up, terms of class B, C, E cannot be properly weighted in TF-IDF model.",
                "So, we propose a modified model to resolve this problem.",
                "When θ init andθ new are set closely, we assume that most of the stories in a first-level cluster (a direct child node of root node) are on the same topic.",
                "Therefore, we make use of a first-level cluster to capture term distribution (df for all the terms within the cluster) within the topic dynamically.",
                "KL divergence of term distribution in a first-level cluster and the whole story set is used to adjust term weights:  ( , , ) * (1 * ( || )) ( , , ) ( , , ) * (1 * ( || )) cw tw cw tw w d D weight d t w KL P P weight d t w weight d t w KL P P γ γ ∈ + = +∑ (5) where ( ) ( ) ( ) ( ) 1,cw cw c c c c df w df w p y p y N N = = − (6) ( ) ( ) ( ) ( ) 1,t t tw tw t t df w df w p y p y N N = = − (7) where dfc(w) is the number of documents containing term w within cluster C, and Nc is the number of documents in cluster C, and Nt is the total number of documents that arrive before time step t. γ is a const parameter, now is manually set 3.",
                "KL divergence is defined as follows [17]: ( ) ( || ) ( ) log ( )x p x KL P Q p x q x = ∑ (8) The basic idea is: for a story in a topic, the more a term occurs within the topic, and the less it occurs in other topics, it should be assigned higher weights.",
                "Obviously, modified model can meet all the requirements of the five term classes listed above. 5.2 Term Reweighting Based on Term Type and Story Class Previous work found that some classes of news stories could achieve good improvements by giving extra weight to named entities.",
                "But we find that terms of different types should be given different amount of extra weight for different classes of news stories.",
                "We use open-NLP1 to recognize named entity types and part-ofspeech tags for terms that appear in news stories.",
                "Named entity types include person name, organization name, location name, date, time, money and percentage, and five POSs are selected: none (NN), verb (VB), adjective (JJ), adverb (RB) and cardinal number (CD).",
                "Statistical analysis shows topic-level discriminative terms types for different classes of stories.",
                "For the sake of convenience, named entity type and part-of-speech tags are uniformly called term type in subsequent sections.",
                "Determining whether two stories are about the same topic is a basic component for NED task.",
                "So at first we use 2 χ statistic to compute correlations between terms and topics.",
                "For a term t and a topic T, a contingence table is derived: Table 1.",
                "A 2×2 Contingence Table Doc Number belong to topic T not belong to topic T include t A B not include t C D The 2 χ statistic for a specific term t with respect to topic T is defined to be [16]: 2 2 ( , ) ( ) * ( ) ( ) * ( ) * ( ) * ( ) w T A B C D AD CB A C B D A B C D χ = + + + − + + + + (9) News topics for the TDT task are further classified into 11 rules of interpretations (ROIs) 2 .",
                "The ROI can be seen as a higher level class of stories.",
                "The average correlation between a term type and a topic ROI is computed as: 2 avg 2 ( , )( ( , ) )k m m km kT R w P w TP R p w T R P χ χ ∈ ∈ ∑ ∑（ , ）= 1 1 k=1…K, m=1…M (10) where K is the number of term types (set 12 constantly in the paper).",
                "M is the number news classes (ROIs, set 11 in the paper).",
                "Pk represents the set of all terms of type k, and Rm represents the set of all topics of class m, p(t,T) means the probability that t occurs in topic T. Because of limitation of space, only parts of the term types (9 term types) and parts of news classes (8 classes) are listed in table 2 with the average correlation values between them.",
                "The statistics is derived from labeled data in TDT2 corpus. (Results in table 2 are already normalized for convenience in comparison.)",
                "The statistics in table 2 indicates the usefulness of different term types in topic discrimination with respect to different news classes.",
                "We can see that, location name is the most useful term type for three news classes: Natural Disasters, Violence or War, Finances.",
                "And for three other categories Elections, Legal/Criminal Cases, Science and Discovery, person name is the most discriminative term type.",
                "For Scandals/Hearings, date is the most important information for topic discrimination.",
                "In addition, Legal/Criminal Cases and Finance topics have higher correlation with money terms, while Science and Discovery have higher correlation with percentage terms.",
                "Non-name terms are more stable for different classes. 1 . http://opennlp.sourceforge.net/ 2 . http://projects.ldc.upenn.edu/TDT3/Guide/label.html From the analysis of table 2, it is reasonable to adjust term weight according to their term type and the news class the story belongs to.",
                "New term weights are reweighted as follows: ( ) ( ) ( ) ( ) ( , , ) * ( , , ) ( , , ) * class d D type w T class d D type w w d weight d t w weight d t w weight d t w α α ∈ = ∑ (11) where type(w) represents the type of term w, and class(d) represents the class of story d, c kα is reweighting parameter for news class c and term type k. In the work, we just simply use statistics in table 2 as the reweighting parameters.",
                "Even thought using the statistics directly may not the best choice, we do not discuss how to automatically obtain the best parameters.",
                "We will try to use machine learning techniques to obtain the best parameters in the future work.",
                "In the work, we use BoosTexter [20] to classify all stories into one of the 11 ROIs.",
                "BoosTexter is a boosting based machine learning program, which creates a series of simple rules for building a classifier for text or attribute-value data.",
                "We use term weight generated using TF-IDF model as feature for story classification.",
                "We trained the model on the 12000 judged English stories in TDT2, and classify the rest of the stories in TDT2 and all stories in TDT3.",
                "Classification results are used for term reweighting in formula (11).",
                "Since the class labels of topic-off stories are not given in TDT datasets, we cannot give the classification accuracy here.",
                "Thus we do not discuss the effects of classification accuracy to NED performance in the paper. 6.",
                "EXPERIMENTAL SETUP 6.1 Datasets We used two LDC [18] datasets TDT2 and TDT3 for our experiments.",
                "TDT2 contains news stories from January to June 1998.",
                "It contains around 54,000 stories from sources like ABC, Associated Press, CNN, New York Times, Public Radio International, Voice of America etc.",
                "Only English stories in the collection were considered.",
                "TDT3 contains approximately 31,000 English stories collected from October to December 1998.",
                "In addition to the sources used in TDT2, it also contains stories from NBC and MSNBC TV broadcasts.",
                "We used transcribed versions of the TV and radio broadcasts besides textual news.",
                "TDT2 dataset is labeled with about 100 topics, and approximately 12,000 English stories belong to at least one of these topics.",
                "TDT3 dataset is labeled with about 120 topics, and approximately 8000 English stories belong to at least one of these topics.",
                "All the topics are classified into 11 Rules of Interpretation: (1)Elections, (2)Scandals/Hearings, (3)Legal/Criminal Cases, (4)Natural Disasters, (5)Accidents, (6)Ongoing Violence or War, (7)Science and Discovery News, (8)Finance, (9)New Law, (10)Sports News, (11)MISC.",
                "News. 6.2 Evaluation Metric TDT uses a cost function CDet that combines the probabilities of missing a new story and a false alarm [19]: * * * *Det Miss Miss Target FA FA NontargetC C P P C P P= + (12) Table 2.",
                "Average correlation between term types and news classes where CMiss means the cost of missing a new story, PMiss means the probability of missing a new story, and PTarget means the probability of seeing a new story in the data; CFA means the cost of a false alarm, PFA means the probability of a false alarm, and PNontarget means the probability of seeing an old story.",
                "The cost CDet is normalized such that a perfect system scores 0 and a trivial system, which is the better one of mark all stories as new or old, scores 1: ( ( * , * ) ) Det Det Miss Target FA Nontarget C Norm C min C P C P = (13) New event detection system gives two outputs for each story.",
                "The first part is yes or no indicating whether the story triggers a new event or not.",
                "The second part is a score indicating confidence of the first decision.",
                "Confidence scores can be used to plot DET curve, i.e., curves that plot false alarm vs. miss probabilities.",
                "Minimum normalized cost can be determined if optimal threshold on the score were chosen. 7.",
                "EXPERIMENTAL RESULTS 7.1 Main Results To test the approaches proposed in the model, we implemented and tested five systems: System-1: this system is used as baseline.",
                "It is implemented based on the basic model described in section 3, i.e., using incremental TF-IDF model to generate term weights, and using Hellinger distance to compute document similarity.",
                "Similarity score normalization is also employed [8].",
                "S-S detection procedure is used.",
                "System-2: this system is the same as system-1 except that S-C detection procedure is used.",
                "System-3: this system is the same as system-1 except that it uses the new detection procedure which is based on indexing-tree.",
                "System-4: implemented based on the approach presented in section 5.1, i.e., terms are reweighted according to the distance between term distributions in a cluster and all stories.",
                "The new detection procedure is used.",
                "System-5: implemented based on the approach presented in section 5.2, i.e., terms of different types are reweighted according to news class using trained parameters.",
                "The new detection procedure is used.",
                "The following are some other NED systems: System-6: [21] for each pair of stories, it computes three similarity values for named entity, non-named entity and all terms respectively.",
                "And employ Support Vector Machine to predict new or old using the similarity values as features.",
                "System-7: [8] it extended a basic incremental TF-IDF model to include source-specific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, etc.",
                "System-8: [13] it split document representation into two parts: named entities and non-named entities, and choose one effective part for each news class.",
                "Table 3 and table 4 show topic-weighted normalized costs and comparing times on TDT2 and TDT3 datasets respectively.",
                "Since no heldout data set for fine-tuning the threshold θ new was available for experiments on TDT2, we only report minimum normalized costs for our systems in table 3.",
                "System-5 outperforms all other systems including system-6, and it performs only 2.78e+8 comparing times in detection procedure which is only 13.4% of system-1.",
                "Table 3.",
                "NED results on TDT2 Systems Min Norm(CDet) Cmp times System-1 0.5749 2.08e+9 System-2① 0.6673 3.77e+8 System-3② 0.5765 2.81e+8 System-4② 0.5431 2.99e+8 System-5② 0.5089 2.78e+8 System-6 0.5300 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 When evaluating on the normalized costs on TDT3, we use the optimal thresholds obtained from TDT2 data set for all systems.",
                "System-2 reduces comparing times to 1.29e+9 which is just 18.3% of system-1, but at the same time it also gets a deteriorated minimum normalized cost which is 0.0499 higher than system-1.",
                "System-3 uses the new detection procedure based on news indexing-tree.",
                "It requires even less comparing times than system-2.",
                "This is because story-story comparisons usually yield greater similarities than story-cluster ones, so stories tend to be combined Location Person Date Organization Money Percentage NN JJ CD Elections 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 Scandals/Hearings 0.66 0.62 0.28 1 0.11 0.02 0.27 0.13 0.05 Legal/Criminal Cases 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 Natural Disasters 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 Violence or War 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 Science and Discovery 0.11 1 0.01 0.22 0.08 0.12 0.19 0.08 0.03 Finances 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 Sports 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 together in system-3.",
                "And system-3 is basically equivalent to system-1 in accuracy results.",
                "System-4 adjusts term weights based on the distance of term distributions between the whole corpus and cluster story set, yielding a good improvement by 0.0468 compared to system-1.",
                "The best system (system-5) has a minimum normalized cost 0.5012, which is 0.0797 better than system-1, and also better than any other results previously reported for this dataset [8, 13].",
                "Further more, system-5 only needs 1.05e+8 comparing times which is 14.9% of system-1.",
                "Table 4.",
                "NED results on TDT3 Systems Norm(CDet) Min Norm(CDet) Cmp times System-1 0.6159 0.5809 7.04e+8 System-2① 0.6493 0.6308 1.29e+8 System-3② 0.6197 0.5868 1.03e+8 System-4② 0.5601 0.5341 1.03e+8 System-5② 0.5413 0.5012 1.05e+8 System-7 -- 0.5783 -System-8 -- 0.5229 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 Figure5 shows the five DET curves for our systems on data set TDT3.",
                "System-5 achieves the minimum cost at a false alarm rate of 0.0157 and a miss rate of 0.4310.",
                "We can observe that System4 and System-5 obtain lower miss probability at regions of low false alarm probabilities.",
                "The hypothesis is that, more weight value is transferred to key terms of topics from non-key terms.",
                "Similarity score between two stories belonging to different topics are lower than before, because their overlapping terms are usually not key terms of their topics. 7.2 Parameter selection for indexing-tree detection Figure 3 shows the minimum normalized costs obtained by system-3 on TDT3 using different parameters.",
                "Theθ init parameter is tested on six values spanning from 0.03 to 0.18.",
                "And the λ parameter is tested on four values 1, 2, 3 and 4.",
                "We can see that, whenθ init is set to 0.12, which is the closest one toθ new, the costs are lower than others.",
                "This is easy to explain, because when stories belonging to the same topic are put in a cluster, it is more reasonable for the cluster to represent the stories in it.",
                "When parameter λ is set to 3 or 4, the costs are better than other cases, but there is no much difference between 3 and 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ MinCost 0.6 0.65 0.7 0.75 0.8 0.85 0.9 Figure 3.",
                "Min Cost on TDT3 (δ =0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ Comparingtimes 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 Figure 4.",
                "Comparing times on TDT3 (δ =0.15) Figure 4 gives the comparing times used by system-3 on TDT3 with the same parameters as figure 3.",
                "The comparing times are strongly dependent onθ init.",
                "Because the greaterθ init is, the less stories combined together, the more comparing times are needed for new event decision.",
                "So we useθ init =0.13,λ =3,δ =0.15 for system-3, 4, and 5.",
                "In this parameter setting, we can get both low minimum normalized costs and less comparing times. 8.",
                "CONCLUSION We have proposed a news indexing-tree based detection procedure in our model.",
                "It reduces comparing times to about one seventh of traditional method without hurting NED accuracy.",
                "We also have presented two extensions to the basic TF-IDF model.",
                "The first extension is made by adjust term weights based on term distributions between the whole corpus and a cluster story set.",
                "And the second extension to basic TF-IDF model is better use of term types (named entities types and part-of-speed) according to news categories.",
                "Our experimental results on TDT2 and TDT3 datasets show that both of the two extensions contribute significantly to improvement in accuracy.",
                "We did not consider news time information as a clue for NED task, since most of the topics last for a long time and TDT data sets only span for a relative short period (no more than 6 months).",
                "For the future work, we want to collect news set which span for a longer period from internet, and integrate time information in NED task.",
                "Since topic is a relative coarse-grained news cluster, we also want to refine cluster granularity to event-level, and identify different events and their relations within a topic.",
                "Acknowledgments This work is supported by the National Natural Science Foundation of China under Grant No. 90604025.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] In Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. .01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90 1 2 5 10 20 40 60 80 90 False Alarm Probability (in %) MissProbability(in%) SYSTEM1 Topic Weighted Curve SYSTEM1 Min Norm(Cost) SYSTEM2 Topic Weighted Curve SYSTEM2 Min Norm(Cost) SYSTEM3 Topic Weighted Curve SYSTEM3 Min Norm(Cost) SYSTEM4 Topic Weighted Curve SYSTEM4 Min Norm(Cost) SYSTEM5 Topic Weighted Curve SYSTEM5 Min Norm(Cost) Random Performance Figure 5.",
                "DET curves on TDT3 [3] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B.T.",
                "Archibald, and X. Liu.",
                "Learning Approaches for Detecting and Tracking News Events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), 1999, 32-43. [4] Y. Yang, T. Pierce, and J. Carbonell.",
                "A Study on Retrospective and On-line Event Detection.",
                "In Proceedings of SIGIR-98, Melbourne, Australia, 1998, 28-36. [5] J. Allan, V. Lavrenko, D. Malin, and R. Swan.",
                "Detections, Bounds, and Timelines: Umass and tdt-3.",
                "In Proceedings of Topic Detection and Tracking Workshop (TDT-3), Vienna, VA, 2000, 167-174. [6] R. Papka and J. Allan.",
                "On-line New Event Detection Using Single Pass Clustering TITLE2:.",
                "Technical Report UM-CS1998-021, 1998. [7] W. Lam, H. Meng, K. Wong, and J.",
                "Yen.",
                "Using Contextual Analysis for News Event Detection.",
                "International Journal on Intelligent Systems, 2001, 525-546. [8] B. Thorsten, C. Francine, and F. Ayman.",
                "A System for New Event Detection.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2003, 330-337. [9] S. Nicola and C. Joe.",
                "Combining Semantic and Syntactic Document Classifiers to Improve First Story Detection.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2001, 424425. [10] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topicconditioned Novelty Detection.",
                "In Proceedings of the 8th ACM SIGKDD International Conference, ACM Press. 2002, 688-693. [11] M. Juha, A.M. Helena, and S. Marko.",
                "Applying Semantic Classes in Event Detection and Tracking.",
                "In Proceedings of International Conference on Natural Language Processing (ICON 2002), 2002, pages 175-183. [12] M. Juha, A.M. Helena, and S. Marko.",
                "Simple Semantics in Topic Detection and Tracking.",
                "Information Retrieval, 7(3-4): 2004, 347-368. [13] K. Giridhar and J. Allan.",
                "Text Classification and Named Entities for New Event Detection.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2004, 297-304. [14] J. P. Callan, W. B. Croft, and S. M. Harding.",
                "The INQUERY Retrieval System.",
                "In Proceedings of DEXA-92, 3rd International Conference on Database and Expert Systems Applications, 1992, 78-83. [15] R. Krovetz.",
                "Viewing Morphology as An Inference Process.",
                "In Proceedings of ACM SIGIR93, 1993, 61-81. [16] Y. Yang and J. Pedersen.",
                "A Comparative Study on Feature Selection in Text Categorization.",
                "In J. D. H. Fisher, editor, The Fourteenth International Conference on Machine Learning (ICML97), Morgan Kaufmann, 1997, 412-420. [17] T. M. Cover, and J.A.",
                "Thomas.",
                "Elements of Information Theory.",
                "Wiley. 1991. [18] The linguistic data consortium, http://www.ldc,upenn.edu/. [19] The 2001 TDT task definition and evaluation plan, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm. [20] R. E. Schapire and Y.",
                "Singer.",
                "Boostexter: A Boosting-based System for Text Categorization.",
                "In Machine Learning 39(2/3):1, Kluwer Academic Publishers, 2000, 35-168. [21] K. Giridhar and J. Allan. 2005.",
                "Using Names and Topics for New Event Detection.",
                "In Proceedings of Human Technology Conference and Conference on Empirical Methods in Natural Language, Vancouver, 2005, 121-128"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Los resultados experimentales en dos conjuntos de datos del consorcio de datos lingüísticos (LDC) TDT2 y TDT3 muestran que el modelo propuesto puede mejorar significativamente la eficiencia y la precisión de la tarea NED, en comparación con el \"sistema de referencia\" y otros sistemas existentes."
            ],
            "translated_text": "",
            "candidates": [
                "sistema de referencia",
                "sistema de referencia"
            ],
            "error": []
        },
        "existing system": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "New Event Detection Based on Indexing-tree and Named Entity Zhang Kuo Tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn Li Juan Zi Tsinghua University Beijing, 100084, China 86-10-62781461 ljz@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn ABSTRACT New Event Detection (NED) aims at detecting from one or multiple streams of news stories that which one is reported on a new event (i.e.",
                "not reported previously).",
                "With the overwhelming volume of news available today, there is an increasing need for a NED system which is able to detect new events more efficiently and accurately.",
                "In this paper we propose a new NED model to speed up the NED task by using news indexing-tree dynamically.",
                "Moreover, based on the observation that terms of different types have different effects for NED task, two term reweighting approaches are proposed to improve NED accuracy.",
                "In the first approach, we propose to adjust term weights dynamically based on previous story clusters and in the second approach, we propose to employ statistics on training data to learn the named entity reweighting model for each class of stories.",
                "Experimental results on two Linguistic Data Consortium (LDC) datasets TDT2 and TDT3 show that the proposed model can improve both efficiency and accuracy of NED task significantly, compared to the baseline system and other <br>existing system</br>s.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Search and Retrieval; H.4.2 [Information Systems Applications]: Types of Systemsdecision support.",
                "General Terms Algorithms, Performance, Experimentation 1.",
                "INTRODUCTION Topic Detection and Tracking (TDT) program aims to develop techniques which can effectively organize, search and structure news text materials from a variety of newswire and broadcast media [1].",
                "New Event Detection (NED) is one of the five tasks in TDT.",
                "It is the task of online identification of the earliest report for each topic as soon as that report arrives in the sequence of documents.",
                "A Topic is defined as a seminal event or activity, along with directly related events and activities [2].",
                "An Event is defined as something (non-trivial) happening in a certain place at a certain time [3].",
                "For instance, when a bomb explodes in a building, the exploding is the seminal event that triggers the topic, and other stories on the same topic would be those discussing salvaging efforts, the search for perpetrators, arrests and trial and so on.",
                "Useful news information is usually buried in a mass of data generated everyday.",
                "Therefore, NED systems are very useful for people who need to detect novel information from real-time news stream.",
                "These real-life needs often occur in domains like financial markets, news analysis, and intelligence gathering.",
                "In most of state-of-the-art (currently) NED systems, each news story on hand is compared to all the previous received stories.",
                "If all the similarities between them do not exceed a threshold, then the story triggers a new event.",
                "They are usually in the form of cosine similarity or Hellinger similarity metric.",
                "The core problem of NED is to identify whether two stories are on the same topic.",
                "Obviously, these systems cannot take advantage of topic information.",
                "Further more, it is not acceptable in real applications because of the large amount of computation required in the NED process.",
                "Other systems organize previous stories into clusters (each cluster corresponds to a topic), and new story is compared to the previous clusters instead of stories.",
                "This manner can reduce comparing times significantly.",
                "Nevertheless, it has been proved that this manner is less accurate [4, 5].",
                "This is because sometimes stories within a topic drift far away from each other, which could lead low similarity between a story and its topic.",
                "On the other hand, some proposed NED systems tried to improve accuracy by making better use of named entities [10, 11, 12, 13].",
                "However, none of the systems have considered that terms of different types (e.g.",
                "Noun, Verb or Person name) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "For example, the names of election candidates (Person name) are very important for stories of election class; the locations (Location name) where accidents happened are important for stories of accidents class.",
                "So, in NED, there still exist following three problems to be investigated: (1) How to speed up the detection procedure while do not decrease the detection accuracy? (2) How to make good use of cluster (topic) information to improve accuracy? (3) How to obtain better news story representation by better understanding of named entities.",
                "Driven by these problems, we have proposed three approaches in this paper. (1)To make the detection procedure faster, we propose a new NED procedure based on news indexing-tree created dynamically.",
                "Story indexing-tree is created by assembling similar stories together to form news clusters in different hierarchies according to their values of similarity.",
                "Comparisons between current story and previous clusters could help find the most similar story in less comparing times.",
                "The new procedure can reduce the amount of comparing times without hurting accuracy. (2)We use the clusters of the first floor in the indexing-tree as news topics, in which term weights are adjusted dynamically according to term distribution in the clusters.",
                "In this approach, cluster (topic) information is used properly, so the problem of theme decentralization is avoided. (3)Based on observations on the statistics obtained from training data, we found that terms of different types (e.g.",
                "Noun and Verb) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "And we propose to use statistics to optimize the weights of the terms of different types in a story according to the news class that the story belongs to.",
                "On TDT3 dataset, the new NED model just uses 14.9% comparing times of the basic model, while its minimum normalized cost is 0.5012, which is 0.0797 better than the basic model, and also better than any other results previously reported for this dataset [8, 13].",
                "The rest of the paper is organized as follows.",
                "We start off this paper by summarizing the previous work in NED in section 2.",
                "Section 3 presents the basic model for NED that most current systems use.",
                "Section 4 describes our new detection procedure based on news indexing-tree.",
                "In section 5, two term reweighting methods are proposed to improve NED accuracy.",
                "Section 6 gives our experimental data and evaluation metrics.",
                "We finally wrap up with the experimental results in Section 7, and the conclusions and future work in Section 8. 2.",
                "RELATED WORK Papka et al. proposed Single-Pass clustering on NED [6].",
                "When a new story was encountered, it was processed immediately to extract term features and a query representation of the storys content is built up.",
                "Then it was compared with all the previous queries.",
                "If the document did not trigger any queries by exceeding a threshold, it was marked as a new event.",
                "Lam et al build up previous query representations of story clusters, each of which corresponds to a topic [7].",
                "In this manner comparisons happen between stories and clusters.",
                "Recent years, most work focus on proposing better methods on comparison of stories and document representation.",
                "Brants et al. [8] extended a basic incremental TF-IDF model to include sourcespecific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, term reweighting based on inverse event frequencies, and segmentation of documents.",
                "Good improvements on TDT bench-marks were shown.",
                "Stokes et al. [9] utilized a combination of evidence from two distinct representations of a documents content.",
                "One of the representations was the usual free text vector, the other made use of lexical chains (created using WordNet) to build another term vector.",
                "Then the two representations are combined in a linear fashion.",
                "A marginal increase in effectiveness was achieved when the combined representation was used.",
                "Some efforts have been done on how to utilize named entities to improve NED.",
                "Yang et al. gave location named entities four times weight than other terms and named entities [10].",
                "DOREMI research group combined semantic similarities of person names, location names and time together with textual similarity [11][12].",
                "UMass [13] research group split document representation into two parts: named entities and non-named entities.",
                "And it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation.",
                "Both [10] and [13] used text categorization technique to classify news stories in advance.",
                "In [13] news stories are classified automatically at first, and then test sensitivities of names and non-name terms for NED for each class.",
                "In [10] frequent terms for each class are removed from document representation.",
                "For example, word election does not help identify different elections.",
                "In their work, effectiveness of different kinds of names (or terms with different POS) for NED in different news classes are not investigated.",
                "We use statistical analysis to reveal the fact and use it to improve NED performance. 3.",
                "BASIC MODEL In this section, we present the basic New Event Detection model which is similar to what most current systems apply.",
                "Then, we propose our new model by extending the basic model.",
                "New Event Detection systems use news story stream as input, in which stories are strictly time-ordered.",
                "Only previously received stories are available when dealing with current story.",
                "The output is a decision for whether the current story is on a new event or not and the confidence of the decision.",
                "Usually, a NED model consists of three parts: story representation, similarity calculation and detection procedure. 3.1 Story Representation Preprocessing is needed before generating story representation.",
                "For preprocessing, we tokenize words, recognize abbreviations, normalize abbreviations, add part-of-speech tags, remove stopwords included in the stop list used in InQuery [14], replace words with their stems using K-stem algorithm[15], and then generate word vector for each news story.",
                "We use incremental TF-IDF model for term weight calculation [4].",
                "In a TF-IDF model, term frequency in a news document is weighted by the inverse document frequency, which is generated from training corpus.",
                "When a new term occurs in testing process, there are two solutions: simply ignore the new term or set df of the term as a small const (e.g. df = 1).",
                "The new term receives too low weight in the first solution (0) and too high weight in the second solution.",
                "In incremental TF-IDF model, document frequencies are updated dynamically in each time step t: 1( ) ( ) ( )t t D tdf w df w df w−= + (1) where Dt represents news story set received in time t, and dfDt(w) means the number of documents that term w occurs in, and dft(w) means the total number of documents that term w occurs in before time t. In this work, each time window includes 50 news stories.",
                "Thus, each story d received in t is represented as follows: 1 2{ ( , , ), ( , , ),..., ( , , )}nd weight d t w weight d t w weight d t w→ where n means the number of distinct terms in story d, and ( , , )weight d t w means the weight of term w in story d at time t: log( ( , ) 1) log(( 1) /( ( ) 0.5)) ( , , ) log( ( , ) 1) log(( 1) /( ( ) 0.5)) t t t t w d tf d w N df w weight d t w tf d w N df w ∈ + + + = + + +∑ (2) where Nt means the total number of news stories before time t, and tf(d,w) means how many times term w occurs in news story d. 3.2 Similarity Calculation We use Hellinger distance for the calculation of similarity between two stories, for two stories d and d at time t, their similarity is defined as follows: , ( , , ) ( , , ) * ( , , ) w d d sim d d t weight d t w weight d t w ∈ = ∑ (3) 3.3 Detection Procedure For each story d received in time step t, the value ( ) ( ) ( ) ( ( , , )) time d time d n d max sim d d t < = (4) is a score used to determine whether d is a story about a new topic and at the same time is an indication of the confidence in our decision [8]. time(d) means the publication time of story d. If the score exceeds the thresholdθ new, then there exists a sufficiently similar document, thus d is a old story, otherwise, there is no sufficiently similar previous document, thus d is an new story. 4.",
                "New NED Procedure Traditional NED systems can be classified into two main types on the aspect of detection procedure: (1) S-S type, in which the story on hand is compared to each story received previously, and use the highest similarity to determine whether current story is about a new event; (2) S-C type, in which the story on hand is compared to all previous clusters each of which representing a topic, and the highest similarity is used for final decision for current story.",
                "If the highest similarity exceeds thresholdθ new, then it is an old story, and put it into the most similar cluster; otherwise it is a new story and create a new cluster.",
                "Previous work show that the first manner is more accurate than the second one [4][5].",
                "Since sometimes stories within a topic drift far away from each other, a story may have very low similarity with its topic.",
                "So using similarities between stories for determining new story is better than using similarities between story and clusters.",
                "Nevertheless, the first manner needs much more comparing times which means the first manner is low efficient.",
                "We propose a new detection procedure which uses comparisons with previous clusters to help find the most similar story in less comparing times, and the final new event decision is made according to the most similar story.",
                "Therefore, we can get both the accuracy of S-S type methods and the efficiency of S-C type methods.",
                "The new procedure creates a news indexing-tree dynamically, in which similar stories are put together to form a hierarchy of clusters.",
                "We index similar stories together by their common ancestor (a cluster node).",
                "Dissimilar stories are indexed in different clusters.",
                "When a story is coming, we use comparisons between the current story and previous hierarchical clusters to help find the most similar story which is useful for new event decision.",
                "After the new event decision is made, the current story is inserted to the indexing-tree for the following detection.",
                "The news indexing-tree is defined formally as follows: S-Tree = {r, NC , NS , E} where r is the root of S-Tree, NC is the set of all cluster nodes, NS is the set of all story nodes, and E is the set of all edges in S-Tree.",
                "We define a set of constraints for a S-Tree: ⅰ . , is an non-terminal node in the treeC i i N i∀ ∈ → ⅱ . , is a terminal node in the treeS i i N i∀ ∈ → ⅲ . , out degree of is at least 2C i i N i∀ ∈ → ⅳ . , is represented as the centroid of its desendantsC i i iN∀ ∈ → For a news story di, the comparison procedure and inserting procedure based on indexing-tree are defined as follows.",
                "An example is shown by Figure 1 and Figure 2.",
                "Figure 1.",
                "Comparison procedure Figure 2.",
                "Inserting procedure Comparison procedure: Step 1: compare di to all the direct child nodes of r and select λ nodes with highest similarities, e.g., C1 2 and C1 3 in Figure 1.",
                "Step 2: for each selected node in the last step, e.g.",
                "C1 2, compare di to all its direct child nodes, and select λ nodes with highest similarities, e.g.",
                "C2 2 and d8.",
                "Repeat step 2 for all non-terminal nodes.",
                "Step 3: record the terminal node with the highest similarty to di, e.g. s5, and the similarity value (0.20).",
                "Inserting di to the S-tree with r as root: Find the node n which is direct child of r in the path from r to the terminal node with highest similarity s, e.g.",
                "C1 2.",
                "If s is smaller than θ init+(h-1)δ , then add di to the tree as a direct child of r. Otherwise, if n is a terminal node, then create a cluster node instead of n, and add both n and di as its direct children; if n is an non-terminal node, then repeat this procedure and insert di to the sub-tree with n as root recursively.",
                "Here h is the length between n and the root of S-tree.",
                "The more the stories in a cluster similar to each other, the better the cluster represents the stories in it.",
                "Hence we add no constraints on the maximum of trees height and degree of a node.",
                "Therefore, we cannot give the complexity of this indexing-tree based procedure.",
                "But we will give the number of comparing times needed by the new procedure in our experiments in section7. 5.",
                "Term Reweighting Methods In this section, two term reweighting methods are proposed to improve NED accuracy.",
                "In the first method, a new way is explored for better using of cluster (topic) information.",
                "The second one finds a better way to make use of named entities based on news classification. 5.1 Term Reweighting Based on Distribution Distance TF-IDF is the most prevalent model used in information retrieval systems.",
                "The basic idea is that the fewer documents a term appears in, the more important the term is in discrimination of documents (relevant or not relevant to a query containing the term).",
                "Nevertheless, in TDT domain, we need to discriminate documents with regard to topics rather than queries.",
                "Intuitively, using cluster (topic) vectors to compare with subsequent news stories should outperform using story vectors.",
                "Unfortunately, the experimental results do not support this intuition [4][5].",
                "Based on observation on data, we find the reason is that a news topic usually contains many directly or indirectly related events, while they all have their own sub-subjects which are usually different with each other.",
                "Take the topic described in section 1 as an example, events like the explosion and salvage have very low similarities with events about criminal trial, therefore stories about trial would have low similarity with the topic vector built on its previous events.",
                "This section focuses on how to effectively make use of topic information and at the same time avoid the problem of content decentralization.",
                "At first, we classify terms into 5 classes to help analysis the needs of the modified model: Term class A: terms that occur frequently in the whole corpus, e.g., year and people.",
                "Terms of this class should be given low weights because they do not help much for topic discrimination.",
                "Term class B: terms that occur frequently within a news category, e.g., election, storm.",
                "They are useful to distinguish two stories in different news categories.",
                "However, they cannot provide information to determine whether two stories are on the same or different topics.",
                "In another words, term election and term storm are not helpful in differentiate two election campaigns and two storm disasters.",
                "Therefore, terms of this class should be assigned lower weights.",
                "Term class C: terms that occur frequently in a topic, and infrequently in other topics, e.g., the name of a crash plane, the name of a specific hurricane.",
                "News stories that belong to different topics rarely have overlap terms in this class.",
                "The more frequently a term appears in a topic, the more important the term is for a story belonging to the topic, therefore the term should be set higher weight.",
                "Term class D: terms that appear in a topic exclusively, but not frequently.",
                "For example, the name of a fireman who did very well in a salvage action, which may appears in only two or three stories but never appeared in other topics.",
                "Terms of this type should receive more weights than in TF-IDF model.",
                "However, since they are not popular in the topic, it is not appropriate to give them too high weights.",
                "Term class E: terms with low document frequency, and appear in different topics.",
                "Terms of this class should receive lower weights.",
                "Now we analyze whether TF-IDF model can give proper weights to the five classes of terms.",
                "Obviously, terms of class A are lowly weighted in TF-IDF model, which is conformable with the requirement described above.",
                "In TF-IDF model, terms of class B are highly dependant with the number of stories in a news class.",
                "TF-IDF model cannot provide low weights if the story containing the term belongs to a relative small news class.",
                "For a term of class C, the more frequently it appears in a topic, the less weight TFIDF model gives to it.",
                "This strongly conflicts with the requirement of terms in class C. For terms of class D, TF-IDF model gives them high weights correctly.",
                "But for terms of class E, TF-IDF model gives high weights to them which are not conformable with the requirement of low weights.",
                "To sum up, terms of class B, C, E cannot be properly weighted in TF-IDF model.",
                "So, we propose a modified model to resolve this problem.",
                "When θ init andθ new are set closely, we assume that most of the stories in a first-level cluster (a direct child node of root node) are on the same topic.",
                "Therefore, we make use of a first-level cluster to capture term distribution (df for all the terms within the cluster) within the topic dynamically.",
                "KL divergence of term distribution in a first-level cluster and the whole story set is used to adjust term weights:  ( , , ) * (1 * ( || )) ( , , ) ( , , ) * (1 * ( || )) cw tw cw tw w d D weight d t w KL P P weight d t w weight d t w KL P P γ γ ∈ + = +∑ (5) where ( ) ( ) ( ) ( ) 1,cw cw c c c c df w df w p y p y N N = = − (6) ( ) ( ) ( ) ( ) 1,t t tw tw t t df w df w p y p y N N = = − (7) where dfc(w) is the number of documents containing term w within cluster C, and Nc is the number of documents in cluster C, and Nt is the total number of documents that arrive before time step t. γ is a const parameter, now is manually set 3.",
                "KL divergence is defined as follows [17]: ( ) ( || ) ( ) log ( )x p x KL P Q p x q x = ∑ (8) The basic idea is: for a story in a topic, the more a term occurs within the topic, and the less it occurs in other topics, it should be assigned higher weights.",
                "Obviously, modified model can meet all the requirements of the five term classes listed above. 5.2 Term Reweighting Based on Term Type and Story Class Previous work found that some classes of news stories could achieve good improvements by giving extra weight to named entities.",
                "But we find that terms of different types should be given different amount of extra weight for different classes of news stories.",
                "We use open-NLP1 to recognize named entity types and part-ofspeech tags for terms that appear in news stories.",
                "Named entity types include person name, organization name, location name, date, time, money and percentage, and five POSs are selected: none (NN), verb (VB), adjective (JJ), adverb (RB) and cardinal number (CD).",
                "Statistical analysis shows topic-level discriminative terms types for different classes of stories.",
                "For the sake of convenience, named entity type and part-of-speech tags are uniformly called term type in subsequent sections.",
                "Determining whether two stories are about the same topic is a basic component for NED task.",
                "So at first we use 2 χ statistic to compute correlations between terms and topics.",
                "For a term t and a topic T, a contingence table is derived: Table 1.",
                "A 2×2 Contingence Table Doc Number belong to topic T not belong to topic T include t A B not include t C D The 2 χ statistic for a specific term t with respect to topic T is defined to be [16]: 2 2 ( , ) ( ) * ( ) ( ) * ( ) * ( ) * ( ) w T A B C D AD CB A C B D A B C D χ = + + + − + + + + (9) News topics for the TDT task are further classified into 11 rules of interpretations (ROIs) 2 .",
                "The ROI can be seen as a higher level class of stories.",
                "The average correlation between a term type and a topic ROI is computed as: 2 avg 2 ( , )( ( , ) )k m m km kT R w P w TP R p w T R P χ χ ∈ ∈ ∑ ∑（ , ）= 1 1 k=1…K, m=1…M (10) where K is the number of term types (set 12 constantly in the paper).",
                "M is the number news classes (ROIs, set 11 in the paper).",
                "Pk represents the set of all terms of type k, and Rm represents the set of all topics of class m, p(t,T) means the probability that t occurs in topic T. Because of limitation of space, only parts of the term types (9 term types) and parts of news classes (8 classes) are listed in table 2 with the average correlation values between them.",
                "The statistics is derived from labeled data in TDT2 corpus. (Results in table 2 are already normalized for convenience in comparison.)",
                "The statistics in table 2 indicates the usefulness of different term types in topic discrimination with respect to different news classes.",
                "We can see that, location name is the most useful term type for three news classes: Natural Disasters, Violence or War, Finances.",
                "And for three other categories Elections, Legal/Criminal Cases, Science and Discovery, person name is the most discriminative term type.",
                "For Scandals/Hearings, date is the most important information for topic discrimination.",
                "In addition, Legal/Criminal Cases and Finance topics have higher correlation with money terms, while Science and Discovery have higher correlation with percentage terms.",
                "Non-name terms are more stable for different classes. 1 . http://opennlp.sourceforge.net/ 2 . http://projects.ldc.upenn.edu/TDT3/Guide/label.html From the analysis of table 2, it is reasonable to adjust term weight according to their term type and the news class the story belongs to.",
                "New term weights are reweighted as follows: ( ) ( ) ( ) ( ) ( , , ) * ( , , ) ( , , ) * class d D type w T class d D type w w d weight d t w weight d t w weight d t w α α ∈ = ∑ (11) where type(w) represents the type of term w, and class(d) represents the class of story d, c kα is reweighting parameter for news class c and term type k. In the work, we just simply use statistics in table 2 as the reweighting parameters.",
                "Even thought using the statistics directly may not the best choice, we do not discuss how to automatically obtain the best parameters.",
                "We will try to use machine learning techniques to obtain the best parameters in the future work.",
                "In the work, we use BoosTexter [20] to classify all stories into one of the 11 ROIs.",
                "BoosTexter is a boosting based machine learning program, which creates a series of simple rules for building a classifier for text or attribute-value data.",
                "We use term weight generated using TF-IDF model as feature for story classification.",
                "We trained the model on the 12000 judged English stories in TDT2, and classify the rest of the stories in TDT2 and all stories in TDT3.",
                "Classification results are used for term reweighting in formula (11).",
                "Since the class labels of topic-off stories are not given in TDT datasets, we cannot give the classification accuracy here.",
                "Thus we do not discuss the effects of classification accuracy to NED performance in the paper. 6.",
                "EXPERIMENTAL SETUP 6.1 Datasets We used two LDC [18] datasets TDT2 and TDT3 for our experiments.",
                "TDT2 contains news stories from January to June 1998.",
                "It contains around 54,000 stories from sources like ABC, Associated Press, CNN, New York Times, Public Radio International, Voice of America etc.",
                "Only English stories in the collection were considered.",
                "TDT3 contains approximately 31,000 English stories collected from October to December 1998.",
                "In addition to the sources used in TDT2, it also contains stories from NBC and MSNBC TV broadcasts.",
                "We used transcribed versions of the TV and radio broadcasts besides textual news.",
                "TDT2 dataset is labeled with about 100 topics, and approximately 12,000 English stories belong to at least one of these topics.",
                "TDT3 dataset is labeled with about 120 topics, and approximately 8000 English stories belong to at least one of these topics.",
                "All the topics are classified into 11 Rules of Interpretation: (1)Elections, (2)Scandals/Hearings, (3)Legal/Criminal Cases, (4)Natural Disasters, (5)Accidents, (6)Ongoing Violence or War, (7)Science and Discovery News, (8)Finance, (9)New Law, (10)Sports News, (11)MISC.",
                "News. 6.2 Evaluation Metric TDT uses a cost function CDet that combines the probabilities of missing a new story and a false alarm [19]: * * * *Det Miss Miss Target FA FA NontargetC C P P C P P= + (12) Table 2.",
                "Average correlation between term types and news classes where CMiss means the cost of missing a new story, PMiss means the probability of missing a new story, and PTarget means the probability of seeing a new story in the data; CFA means the cost of a false alarm, PFA means the probability of a false alarm, and PNontarget means the probability of seeing an old story.",
                "The cost CDet is normalized such that a perfect system scores 0 and a trivial system, which is the better one of mark all stories as new or old, scores 1: ( ( * , * ) ) Det Det Miss Target FA Nontarget C Norm C min C P C P = (13) New event detection system gives two outputs for each story.",
                "The first part is yes or no indicating whether the story triggers a new event or not.",
                "The second part is a score indicating confidence of the first decision.",
                "Confidence scores can be used to plot DET curve, i.e., curves that plot false alarm vs. miss probabilities.",
                "Minimum normalized cost can be determined if optimal threshold on the score were chosen. 7.",
                "EXPERIMENTAL RESULTS 7.1 Main Results To test the approaches proposed in the model, we implemented and tested five systems: System-1: this system is used as baseline.",
                "It is implemented based on the basic model described in section 3, i.e., using incremental TF-IDF model to generate term weights, and using Hellinger distance to compute document similarity.",
                "Similarity score normalization is also employed [8].",
                "S-S detection procedure is used.",
                "System-2: this system is the same as system-1 except that S-C detection procedure is used.",
                "System-3: this system is the same as system-1 except that it uses the new detection procedure which is based on indexing-tree.",
                "System-4: implemented based on the approach presented in section 5.1, i.e., terms are reweighted according to the distance between term distributions in a cluster and all stories.",
                "The new detection procedure is used.",
                "System-5: implemented based on the approach presented in section 5.2, i.e., terms of different types are reweighted according to news class using trained parameters.",
                "The new detection procedure is used.",
                "The following are some other NED systems: System-6: [21] for each pair of stories, it computes three similarity values for named entity, non-named entity and all terms respectively.",
                "And employ Support Vector Machine to predict new or old using the similarity values as features.",
                "System-7: [8] it extended a basic incremental TF-IDF model to include source-specific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, etc.",
                "System-8: [13] it split document representation into two parts: named entities and non-named entities, and choose one effective part for each news class.",
                "Table 3 and table 4 show topic-weighted normalized costs and comparing times on TDT2 and TDT3 datasets respectively.",
                "Since no heldout data set for fine-tuning the threshold θ new was available for experiments on TDT2, we only report minimum normalized costs for our systems in table 3.",
                "System-5 outperforms all other systems including system-6, and it performs only 2.78e+8 comparing times in detection procedure which is only 13.4% of system-1.",
                "Table 3.",
                "NED results on TDT2 Systems Min Norm(CDet) Cmp times System-1 0.5749 2.08e+9 System-2① 0.6673 3.77e+8 System-3② 0.5765 2.81e+8 System-4② 0.5431 2.99e+8 System-5② 0.5089 2.78e+8 System-6 0.5300 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 When evaluating on the normalized costs on TDT3, we use the optimal thresholds obtained from TDT2 data set for all systems.",
                "System-2 reduces comparing times to 1.29e+9 which is just 18.3% of system-1, but at the same time it also gets a deteriorated minimum normalized cost which is 0.0499 higher than system-1.",
                "System-3 uses the new detection procedure based on news indexing-tree.",
                "It requires even less comparing times than system-2.",
                "This is because story-story comparisons usually yield greater similarities than story-cluster ones, so stories tend to be combined Location Person Date Organization Money Percentage NN JJ CD Elections 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 Scandals/Hearings 0.66 0.62 0.28 1 0.11 0.02 0.27 0.13 0.05 Legal/Criminal Cases 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 Natural Disasters 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 Violence or War 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 Science and Discovery 0.11 1 0.01 0.22 0.08 0.12 0.19 0.08 0.03 Finances 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 Sports 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 together in system-3.",
                "And system-3 is basically equivalent to system-1 in accuracy results.",
                "System-4 adjusts term weights based on the distance of term distributions between the whole corpus and cluster story set, yielding a good improvement by 0.0468 compared to system-1.",
                "The best system (system-5) has a minimum normalized cost 0.5012, which is 0.0797 better than system-1, and also better than any other results previously reported for this dataset [8, 13].",
                "Further more, system-5 only needs 1.05e+8 comparing times which is 14.9% of system-1.",
                "Table 4.",
                "NED results on TDT3 Systems Norm(CDet) Min Norm(CDet) Cmp times System-1 0.6159 0.5809 7.04e+8 System-2① 0.6493 0.6308 1.29e+8 System-3② 0.6197 0.5868 1.03e+8 System-4② 0.5601 0.5341 1.03e+8 System-5② 0.5413 0.5012 1.05e+8 System-7 -- 0.5783 -System-8 -- 0.5229 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 Figure5 shows the five DET curves for our systems on data set TDT3.",
                "System-5 achieves the minimum cost at a false alarm rate of 0.0157 and a miss rate of 0.4310.",
                "We can observe that System4 and System-5 obtain lower miss probability at regions of low false alarm probabilities.",
                "The hypothesis is that, more weight value is transferred to key terms of topics from non-key terms.",
                "Similarity score between two stories belonging to different topics are lower than before, because their overlapping terms are usually not key terms of their topics. 7.2 Parameter selection for indexing-tree detection Figure 3 shows the minimum normalized costs obtained by system-3 on TDT3 using different parameters.",
                "Theθ init parameter is tested on six values spanning from 0.03 to 0.18.",
                "And the λ parameter is tested on four values 1, 2, 3 and 4.",
                "We can see that, whenθ init is set to 0.12, which is the closest one toθ new, the costs are lower than others.",
                "This is easy to explain, because when stories belonging to the same topic are put in a cluster, it is more reasonable for the cluster to represent the stories in it.",
                "When parameter λ is set to 3 or 4, the costs are better than other cases, but there is no much difference between 3 and 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ MinCost 0.6 0.65 0.7 0.75 0.8 0.85 0.9 Figure 3.",
                "Min Cost on TDT3 (δ =0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ Comparingtimes 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 Figure 4.",
                "Comparing times on TDT3 (δ =0.15) Figure 4 gives the comparing times used by system-3 on TDT3 with the same parameters as figure 3.",
                "The comparing times are strongly dependent onθ init.",
                "Because the greaterθ init is, the less stories combined together, the more comparing times are needed for new event decision.",
                "So we useθ init =0.13,λ =3,δ =0.15 for system-3, 4, and 5.",
                "In this parameter setting, we can get both low minimum normalized costs and less comparing times. 8.",
                "CONCLUSION We have proposed a news indexing-tree based detection procedure in our model.",
                "It reduces comparing times to about one seventh of traditional method without hurting NED accuracy.",
                "We also have presented two extensions to the basic TF-IDF model.",
                "The first extension is made by adjust term weights based on term distributions between the whole corpus and a cluster story set.",
                "And the second extension to basic TF-IDF model is better use of term types (named entities types and part-of-speed) according to news categories.",
                "Our experimental results on TDT2 and TDT3 datasets show that both of the two extensions contribute significantly to improvement in accuracy.",
                "We did not consider news time information as a clue for NED task, since most of the topics last for a long time and TDT data sets only span for a relative short period (no more than 6 months).",
                "For the future work, we want to collect news set which span for a longer period from internet, and integrate time information in NED task.",
                "Since topic is a relative coarse-grained news cluster, we also want to refine cluster granularity to event-level, and identify different events and their relations within a topic.",
                "Acknowledgments This work is supported by the National Natural Science Foundation of China under Grant No. 90604025.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] In Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. .01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90 1 2 5 10 20 40 60 80 90 False Alarm Probability (in %) MissProbability(in%) SYSTEM1 Topic Weighted Curve SYSTEM1 Min Norm(Cost) SYSTEM2 Topic Weighted Curve SYSTEM2 Min Norm(Cost) SYSTEM3 Topic Weighted Curve SYSTEM3 Min Norm(Cost) SYSTEM4 Topic Weighted Curve SYSTEM4 Min Norm(Cost) SYSTEM5 Topic Weighted Curve SYSTEM5 Min Norm(Cost) Random Performance Figure 5.",
                "DET curves on TDT3 [3] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B.T.",
                "Archibald, and X. Liu.",
                "Learning Approaches for Detecting and Tracking News Events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), 1999, 32-43. [4] Y. Yang, T. Pierce, and J. Carbonell.",
                "A Study on Retrospective and On-line Event Detection.",
                "In Proceedings of SIGIR-98, Melbourne, Australia, 1998, 28-36. [5] J. Allan, V. Lavrenko, D. Malin, and R. Swan.",
                "Detections, Bounds, and Timelines: Umass and tdt-3.",
                "In Proceedings of Topic Detection and Tracking Workshop (TDT-3), Vienna, VA, 2000, 167-174. [6] R. Papka and J. Allan.",
                "On-line New Event Detection Using Single Pass Clustering TITLE2:.",
                "Technical Report UM-CS1998-021, 1998. [7] W. Lam, H. Meng, K. Wong, and J.",
                "Yen.",
                "Using Contextual Analysis for News Event Detection.",
                "International Journal on Intelligent Systems, 2001, 525-546. [8] B. Thorsten, C. Francine, and F. Ayman.",
                "A System for New Event Detection.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2003, 330-337. [9] S. Nicola and C. Joe.",
                "Combining Semantic and Syntactic Document Classifiers to Improve First Story Detection.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2001, 424425. [10] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topicconditioned Novelty Detection.",
                "In Proceedings of the 8th ACM SIGKDD International Conference, ACM Press. 2002, 688-693. [11] M. Juha, A.M. Helena, and S. Marko.",
                "Applying Semantic Classes in Event Detection and Tracking.",
                "In Proceedings of International Conference on Natural Language Processing (ICON 2002), 2002, pages 175-183. [12] M. Juha, A.M. Helena, and S. Marko.",
                "Simple Semantics in Topic Detection and Tracking.",
                "Information Retrieval, 7(3-4): 2004, 347-368. [13] K. Giridhar and J. Allan.",
                "Text Classification and Named Entities for New Event Detection.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2004, 297-304. [14] J. P. Callan, W. B. Croft, and S. M. Harding.",
                "The INQUERY Retrieval System.",
                "In Proceedings of DEXA-92, 3rd International Conference on Database and Expert Systems Applications, 1992, 78-83. [15] R. Krovetz.",
                "Viewing Morphology as An Inference Process.",
                "In Proceedings of ACM SIGIR93, 1993, 61-81. [16] Y. Yang and J. Pedersen.",
                "A Comparative Study on Feature Selection in Text Categorization.",
                "In J. D. H. Fisher, editor, The Fourteenth International Conference on Machine Learning (ICML97), Morgan Kaufmann, 1997, 412-420. [17] T. M. Cover, and J.A.",
                "Thomas.",
                "Elements of Information Theory.",
                "Wiley. 1991. [18] The linguistic data consortium, http://www.ldc,upenn.edu/. [19] The 2001 TDT task definition and evaluation plan, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm. [20] R. E. Schapire and Y.",
                "Singer.",
                "Boostexter: A Boosting-based System for Text Categorization.",
                "In Machine Learning 39(2/3):1, Kluwer Academic Publishers, 2000, 35-168. [21] K. Giridhar and J. Allan. 2005.",
                "Using Names and Topics for New Event Detection.",
                "In Proceedings of Human Technology Conference and Conference on Empirical Methods in Natural Language, Vancouver, 2005, 121-128"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Los resultados experimentales en dos conjuntos de datos del consorcio de datos lingüísticos (LDC) TDT2 y TDT3 muestran que el modelo propuesto puede mejorar significativamente la eficiencia y la precisión de la tarea NED, en comparación con el sistema de referencia y otros \"sistemas existentes\"."
            ],
            "translated_text": "",
            "candidates": [
                "sistema existente",
                "sistemas existentes"
            ],
            "error": []
        },
        "topic detection and track": {
            "translated_key": "Detección y pista de temas",
            "is_in_text": false,
            "original_annotated_sentences": [
                "New Event Detection Based on Indexing-tree and Named Entity Zhang Kuo Tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn Li Juan Zi Tsinghua University Beijing, 100084, China 86-10-62781461 ljz@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn ABSTRACT New Event Detection (NED) aims at detecting from one or multiple streams of news stories that which one is reported on a new event (i.e.",
                "not reported previously).",
                "With the overwhelming volume of news available today, there is an increasing need for a NED system which is able to detect new events more efficiently and accurately.",
                "In this paper we propose a new NED model to speed up the NED task by using news indexing-tree dynamically.",
                "Moreover, based on the observation that terms of different types have different effects for NED task, two term reweighting approaches are proposed to improve NED accuracy.",
                "In the first approach, we propose to adjust term weights dynamically based on previous story clusters and in the second approach, we propose to employ statistics on training data to learn the named entity reweighting model for each class of stories.",
                "Experimental results on two Linguistic Data Consortium (LDC) datasets TDT2 and TDT3 show that the proposed model can improve both efficiency and accuracy of NED task significantly, compared to the baseline system and other existing systems.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Search and Retrieval; H.4.2 [Information Systems Applications]: Types of Systemsdecision support.",
                "General Terms Algorithms, Performance, Experimentation 1.",
                "INTRODUCTION Topic Detection and Tracking (TDT) program aims to develop techniques which can effectively organize, search and structure news text materials from a variety of newswire and broadcast media [1].",
                "New Event Detection (NED) is one of the five tasks in TDT.",
                "It is the task of online identification of the earliest report for each topic as soon as that report arrives in the sequence of documents.",
                "A Topic is defined as a seminal event or activity, along with directly related events and activities [2].",
                "An Event is defined as something (non-trivial) happening in a certain place at a certain time [3].",
                "For instance, when a bomb explodes in a building, the exploding is the seminal event that triggers the topic, and other stories on the same topic would be those discussing salvaging efforts, the search for perpetrators, arrests and trial and so on.",
                "Useful news information is usually buried in a mass of data generated everyday.",
                "Therefore, NED systems are very useful for people who need to detect novel information from real-time news stream.",
                "These real-life needs often occur in domains like financial markets, news analysis, and intelligence gathering.",
                "In most of state-of-the-art (currently) NED systems, each news story on hand is compared to all the previous received stories.",
                "If all the similarities between them do not exceed a threshold, then the story triggers a new event.",
                "They are usually in the form of cosine similarity or Hellinger similarity metric.",
                "The core problem of NED is to identify whether two stories are on the same topic.",
                "Obviously, these systems cannot take advantage of topic information.",
                "Further more, it is not acceptable in real applications because of the large amount of computation required in the NED process.",
                "Other systems organize previous stories into clusters (each cluster corresponds to a topic), and new story is compared to the previous clusters instead of stories.",
                "This manner can reduce comparing times significantly.",
                "Nevertheless, it has been proved that this manner is less accurate [4, 5].",
                "This is because sometimes stories within a topic drift far away from each other, which could lead low similarity between a story and its topic.",
                "On the other hand, some proposed NED systems tried to improve accuracy by making better use of named entities [10, 11, 12, 13].",
                "However, none of the systems have considered that terms of different types (e.g.",
                "Noun, Verb or Person name) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "For example, the names of election candidates (Person name) are very important for stories of election class; the locations (Location name) where accidents happened are important for stories of accidents class.",
                "So, in NED, there still exist following three problems to be investigated: (1) How to speed up the detection procedure while do not decrease the detection accuracy? (2) How to make good use of cluster (topic) information to improve accuracy? (3) How to obtain better news story representation by better understanding of named entities.",
                "Driven by these problems, we have proposed three approaches in this paper. (1)To make the detection procedure faster, we propose a new NED procedure based on news indexing-tree created dynamically.",
                "Story indexing-tree is created by assembling similar stories together to form news clusters in different hierarchies according to their values of similarity.",
                "Comparisons between current story and previous clusters could help find the most similar story in less comparing times.",
                "The new procedure can reduce the amount of comparing times without hurting accuracy. (2)We use the clusters of the first floor in the indexing-tree as news topics, in which term weights are adjusted dynamically according to term distribution in the clusters.",
                "In this approach, cluster (topic) information is used properly, so the problem of theme decentralization is avoided. (3)Based on observations on the statistics obtained from training data, we found that terms of different types (e.g.",
                "Noun and Verb) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "And we propose to use statistics to optimize the weights of the terms of different types in a story according to the news class that the story belongs to.",
                "On TDT3 dataset, the new NED model just uses 14.9% comparing times of the basic model, while its minimum normalized cost is 0.5012, which is 0.0797 better than the basic model, and also better than any other results previously reported for this dataset [8, 13].",
                "The rest of the paper is organized as follows.",
                "We start off this paper by summarizing the previous work in NED in section 2.",
                "Section 3 presents the basic model for NED that most current systems use.",
                "Section 4 describes our new detection procedure based on news indexing-tree.",
                "In section 5, two term reweighting methods are proposed to improve NED accuracy.",
                "Section 6 gives our experimental data and evaluation metrics.",
                "We finally wrap up with the experimental results in Section 7, and the conclusions and future work in Section 8. 2.",
                "RELATED WORK Papka et al. proposed Single-Pass clustering on NED [6].",
                "When a new story was encountered, it was processed immediately to extract term features and a query representation of the storys content is built up.",
                "Then it was compared with all the previous queries.",
                "If the document did not trigger any queries by exceeding a threshold, it was marked as a new event.",
                "Lam et al build up previous query representations of story clusters, each of which corresponds to a topic [7].",
                "In this manner comparisons happen between stories and clusters.",
                "Recent years, most work focus on proposing better methods on comparison of stories and document representation.",
                "Brants et al. [8] extended a basic incremental TF-IDF model to include sourcespecific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, term reweighting based on inverse event frequencies, and segmentation of documents.",
                "Good improvements on TDT bench-marks were shown.",
                "Stokes et al. [9] utilized a combination of evidence from two distinct representations of a documents content.",
                "One of the representations was the usual free text vector, the other made use of lexical chains (created using WordNet) to build another term vector.",
                "Then the two representations are combined in a linear fashion.",
                "A marginal increase in effectiveness was achieved when the combined representation was used.",
                "Some efforts have been done on how to utilize named entities to improve NED.",
                "Yang et al. gave location named entities four times weight than other terms and named entities [10].",
                "DOREMI research group combined semantic similarities of person names, location names and time together with textual similarity [11][12].",
                "UMass [13] research group split document representation into two parts: named entities and non-named entities.",
                "And it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation.",
                "Both [10] and [13] used text categorization technique to classify news stories in advance.",
                "In [13] news stories are classified automatically at first, and then test sensitivities of names and non-name terms for NED for each class.",
                "In [10] frequent terms for each class are removed from document representation.",
                "For example, word election does not help identify different elections.",
                "In their work, effectiveness of different kinds of names (or terms with different POS) for NED in different news classes are not investigated.",
                "We use statistical analysis to reveal the fact and use it to improve NED performance. 3.",
                "BASIC MODEL In this section, we present the basic New Event Detection model which is similar to what most current systems apply.",
                "Then, we propose our new model by extending the basic model.",
                "New Event Detection systems use news story stream as input, in which stories are strictly time-ordered.",
                "Only previously received stories are available when dealing with current story.",
                "The output is a decision for whether the current story is on a new event or not and the confidence of the decision.",
                "Usually, a NED model consists of three parts: story representation, similarity calculation and detection procedure. 3.1 Story Representation Preprocessing is needed before generating story representation.",
                "For preprocessing, we tokenize words, recognize abbreviations, normalize abbreviations, add part-of-speech tags, remove stopwords included in the stop list used in InQuery [14], replace words with their stems using K-stem algorithm[15], and then generate word vector for each news story.",
                "We use incremental TF-IDF model for term weight calculation [4].",
                "In a TF-IDF model, term frequency in a news document is weighted by the inverse document frequency, which is generated from training corpus.",
                "When a new term occurs in testing process, there are two solutions: simply ignore the new term or set df of the term as a small const (e.g. df = 1).",
                "The new term receives too low weight in the first solution (0) and too high weight in the second solution.",
                "In incremental TF-IDF model, document frequencies are updated dynamically in each time step t: 1( ) ( ) ( )t t D tdf w df w df w−= + (1) where Dt represents news story set received in time t, and dfDt(w) means the number of documents that term w occurs in, and dft(w) means the total number of documents that term w occurs in before time t. In this work, each time window includes 50 news stories.",
                "Thus, each story d received in t is represented as follows: 1 2{ ( , , ), ( , , ),..., ( , , )}nd weight d t w weight d t w weight d t w→ where n means the number of distinct terms in story d, and ( , , )weight d t w means the weight of term w in story d at time t: log( ( , ) 1) log(( 1) /( ( ) 0.5)) ( , , ) log( ( , ) 1) log(( 1) /( ( ) 0.5)) t t t t w d tf d w N df w weight d t w tf d w N df w ∈ + + + = + + +∑ (2) where Nt means the total number of news stories before time t, and tf(d,w) means how many times term w occurs in news story d. 3.2 Similarity Calculation We use Hellinger distance for the calculation of similarity between two stories, for two stories d and d at time t, their similarity is defined as follows: , ( , , ) ( , , ) * ( , , ) w d d sim d d t weight d t w weight d t w ∈ = ∑ (3) 3.3 Detection Procedure For each story d received in time step t, the value ( ) ( ) ( ) ( ( , , )) time d time d n d max sim d d t < = (4) is a score used to determine whether d is a story about a new topic and at the same time is an indication of the confidence in our decision [8]. time(d) means the publication time of story d. If the score exceeds the thresholdθ new, then there exists a sufficiently similar document, thus d is a old story, otherwise, there is no sufficiently similar previous document, thus d is an new story. 4.",
                "New NED Procedure Traditional NED systems can be classified into two main types on the aspect of detection procedure: (1) S-S type, in which the story on hand is compared to each story received previously, and use the highest similarity to determine whether current story is about a new event; (2) S-C type, in which the story on hand is compared to all previous clusters each of which representing a topic, and the highest similarity is used for final decision for current story.",
                "If the highest similarity exceeds thresholdθ new, then it is an old story, and put it into the most similar cluster; otherwise it is a new story and create a new cluster.",
                "Previous work show that the first manner is more accurate than the second one [4][5].",
                "Since sometimes stories within a topic drift far away from each other, a story may have very low similarity with its topic.",
                "So using similarities between stories for determining new story is better than using similarities between story and clusters.",
                "Nevertheless, the first manner needs much more comparing times which means the first manner is low efficient.",
                "We propose a new detection procedure which uses comparisons with previous clusters to help find the most similar story in less comparing times, and the final new event decision is made according to the most similar story.",
                "Therefore, we can get both the accuracy of S-S type methods and the efficiency of S-C type methods.",
                "The new procedure creates a news indexing-tree dynamically, in which similar stories are put together to form a hierarchy of clusters.",
                "We index similar stories together by their common ancestor (a cluster node).",
                "Dissimilar stories are indexed in different clusters.",
                "When a story is coming, we use comparisons between the current story and previous hierarchical clusters to help find the most similar story which is useful for new event decision.",
                "After the new event decision is made, the current story is inserted to the indexing-tree for the following detection.",
                "The news indexing-tree is defined formally as follows: S-Tree = {r, NC , NS , E} where r is the root of S-Tree, NC is the set of all cluster nodes, NS is the set of all story nodes, and E is the set of all edges in S-Tree.",
                "We define a set of constraints for a S-Tree: ⅰ . , is an non-terminal node in the treeC i i N i∀ ∈ → ⅱ . , is a terminal node in the treeS i i N i∀ ∈ → ⅲ . , out degree of is at least 2C i i N i∀ ∈ → ⅳ . , is represented as the centroid of its desendantsC i i iN∀ ∈ → For a news story di, the comparison procedure and inserting procedure based on indexing-tree are defined as follows.",
                "An example is shown by Figure 1 and Figure 2.",
                "Figure 1.",
                "Comparison procedure Figure 2.",
                "Inserting procedure Comparison procedure: Step 1: compare di to all the direct child nodes of r and select λ nodes with highest similarities, e.g., C1 2 and C1 3 in Figure 1.",
                "Step 2: for each selected node in the last step, e.g.",
                "C1 2, compare di to all its direct child nodes, and select λ nodes with highest similarities, e.g.",
                "C2 2 and d8.",
                "Repeat step 2 for all non-terminal nodes.",
                "Step 3: record the terminal node with the highest similarty to di, e.g. s5, and the similarity value (0.20).",
                "Inserting di to the S-tree with r as root: Find the node n which is direct child of r in the path from r to the terminal node with highest similarity s, e.g.",
                "C1 2.",
                "If s is smaller than θ init+(h-1)δ , then add di to the tree as a direct child of r. Otherwise, if n is a terminal node, then create a cluster node instead of n, and add both n and di as its direct children; if n is an non-terminal node, then repeat this procedure and insert di to the sub-tree with n as root recursively.",
                "Here h is the length between n and the root of S-tree.",
                "The more the stories in a cluster similar to each other, the better the cluster represents the stories in it.",
                "Hence we add no constraints on the maximum of trees height and degree of a node.",
                "Therefore, we cannot give the complexity of this indexing-tree based procedure.",
                "But we will give the number of comparing times needed by the new procedure in our experiments in section7. 5.",
                "Term Reweighting Methods In this section, two term reweighting methods are proposed to improve NED accuracy.",
                "In the first method, a new way is explored for better using of cluster (topic) information.",
                "The second one finds a better way to make use of named entities based on news classification. 5.1 Term Reweighting Based on Distribution Distance TF-IDF is the most prevalent model used in information retrieval systems.",
                "The basic idea is that the fewer documents a term appears in, the more important the term is in discrimination of documents (relevant or not relevant to a query containing the term).",
                "Nevertheless, in TDT domain, we need to discriminate documents with regard to topics rather than queries.",
                "Intuitively, using cluster (topic) vectors to compare with subsequent news stories should outperform using story vectors.",
                "Unfortunately, the experimental results do not support this intuition [4][5].",
                "Based on observation on data, we find the reason is that a news topic usually contains many directly or indirectly related events, while they all have their own sub-subjects which are usually different with each other.",
                "Take the topic described in section 1 as an example, events like the explosion and salvage have very low similarities with events about criminal trial, therefore stories about trial would have low similarity with the topic vector built on its previous events.",
                "This section focuses on how to effectively make use of topic information and at the same time avoid the problem of content decentralization.",
                "At first, we classify terms into 5 classes to help analysis the needs of the modified model: Term class A: terms that occur frequently in the whole corpus, e.g., year and people.",
                "Terms of this class should be given low weights because they do not help much for topic discrimination.",
                "Term class B: terms that occur frequently within a news category, e.g., election, storm.",
                "They are useful to distinguish two stories in different news categories.",
                "However, they cannot provide information to determine whether two stories are on the same or different topics.",
                "In another words, term election and term storm are not helpful in differentiate two election campaigns and two storm disasters.",
                "Therefore, terms of this class should be assigned lower weights.",
                "Term class C: terms that occur frequently in a topic, and infrequently in other topics, e.g., the name of a crash plane, the name of a specific hurricane.",
                "News stories that belong to different topics rarely have overlap terms in this class.",
                "The more frequently a term appears in a topic, the more important the term is for a story belonging to the topic, therefore the term should be set higher weight.",
                "Term class D: terms that appear in a topic exclusively, but not frequently.",
                "For example, the name of a fireman who did very well in a salvage action, which may appears in only two or three stories but never appeared in other topics.",
                "Terms of this type should receive more weights than in TF-IDF model.",
                "However, since they are not popular in the topic, it is not appropriate to give them too high weights.",
                "Term class E: terms with low document frequency, and appear in different topics.",
                "Terms of this class should receive lower weights.",
                "Now we analyze whether TF-IDF model can give proper weights to the five classes of terms.",
                "Obviously, terms of class A are lowly weighted in TF-IDF model, which is conformable with the requirement described above.",
                "In TF-IDF model, terms of class B are highly dependant with the number of stories in a news class.",
                "TF-IDF model cannot provide low weights if the story containing the term belongs to a relative small news class.",
                "For a term of class C, the more frequently it appears in a topic, the less weight TFIDF model gives to it.",
                "This strongly conflicts with the requirement of terms in class C. For terms of class D, TF-IDF model gives them high weights correctly.",
                "But for terms of class E, TF-IDF model gives high weights to them which are not conformable with the requirement of low weights.",
                "To sum up, terms of class B, C, E cannot be properly weighted in TF-IDF model.",
                "So, we propose a modified model to resolve this problem.",
                "When θ init andθ new are set closely, we assume that most of the stories in a first-level cluster (a direct child node of root node) are on the same topic.",
                "Therefore, we make use of a first-level cluster to capture term distribution (df for all the terms within the cluster) within the topic dynamically.",
                "KL divergence of term distribution in a first-level cluster and the whole story set is used to adjust term weights:  ( , , ) * (1 * ( || )) ( , , ) ( , , ) * (1 * ( || )) cw tw cw tw w d D weight d t w KL P P weight d t w weight d t w KL P P γ γ ∈ + = +∑ (5) where ( ) ( ) ( ) ( ) 1,cw cw c c c c df w df w p y p y N N = = − (6) ( ) ( ) ( ) ( ) 1,t t tw tw t t df w df w p y p y N N = = − (7) where dfc(w) is the number of documents containing term w within cluster C, and Nc is the number of documents in cluster C, and Nt is the total number of documents that arrive before time step t. γ is a const parameter, now is manually set 3.",
                "KL divergence is defined as follows [17]: ( ) ( || ) ( ) log ( )x p x KL P Q p x q x = ∑ (8) The basic idea is: for a story in a topic, the more a term occurs within the topic, and the less it occurs in other topics, it should be assigned higher weights.",
                "Obviously, modified model can meet all the requirements of the five term classes listed above. 5.2 Term Reweighting Based on Term Type and Story Class Previous work found that some classes of news stories could achieve good improvements by giving extra weight to named entities.",
                "But we find that terms of different types should be given different amount of extra weight for different classes of news stories.",
                "We use open-NLP1 to recognize named entity types and part-ofspeech tags for terms that appear in news stories.",
                "Named entity types include person name, organization name, location name, date, time, money and percentage, and five POSs are selected: none (NN), verb (VB), adjective (JJ), adverb (RB) and cardinal number (CD).",
                "Statistical analysis shows topic-level discriminative terms types for different classes of stories.",
                "For the sake of convenience, named entity type and part-of-speech tags are uniformly called term type in subsequent sections.",
                "Determining whether two stories are about the same topic is a basic component for NED task.",
                "So at first we use 2 χ statistic to compute correlations between terms and topics.",
                "For a term t and a topic T, a contingence table is derived: Table 1.",
                "A 2×2 Contingence Table Doc Number belong to topic T not belong to topic T include t A B not include t C D The 2 χ statistic for a specific term t with respect to topic T is defined to be [16]: 2 2 ( , ) ( ) * ( ) ( ) * ( ) * ( ) * ( ) w T A B C D AD CB A C B D A B C D χ = + + + − + + + + (9) News topics for the TDT task are further classified into 11 rules of interpretations (ROIs) 2 .",
                "The ROI can be seen as a higher level class of stories.",
                "The average correlation between a term type and a topic ROI is computed as: 2 avg 2 ( , )( ( , ) )k m m km kT R w P w TP R p w T R P χ χ ∈ ∈ ∑ ∑（ , ）= 1 1 k=1…K, m=1…M (10) where K is the number of term types (set 12 constantly in the paper).",
                "M is the number news classes (ROIs, set 11 in the paper).",
                "Pk represents the set of all terms of type k, and Rm represents the set of all topics of class m, p(t,T) means the probability that t occurs in topic T. Because of limitation of space, only parts of the term types (9 term types) and parts of news classes (8 classes) are listed in table 2 with the average correlation values between them.",
                "The statistics is derived from labeled data in TDT2 corpus. (Results in table 2 are already normalized for convenience in comparison.)",
                "The statistics in table 2 indicates the usefulness of different term types in topic discrimination with respect to different news classes.",
                "We can see that, location name is the most useful term type for three news classes: Natural Disasters, Violence or War, Finances.",
                "And for three other categories Elections, Legal/Criminal Cases, Science and Discovery, person name is the most discriminative term type.",
                "For Scandals/Hearings, date is the most important information for topic discrimination.",
                "In addition, Legal/Criminal Cases and Finance topics have higher correlation with money terms, while Science and Discovery have higher correlation with percentage terms.",
                "Non-name terms are more stable for different classes. 1 . http://opennlp.sourceforge.net/ 2 . http://projects.ldc.upenn.edu/TDT3/Guide/label.html From the analysis of table 2, it is reasonable to adjust term weight according to their term type and the news class the story belongs to.",
                "New term weights are reweighted as follows: ( ) ( ) ( ) ( ) ( , , ) * ( , , ) ( , , ) * class d D type w T class d D type w w d weight d t w weight d t w weight d t w α α ∈ = ∑ (11) where type(w) represents the type of term w, and class(d) represents the class of story d, c kα is reweighting parameter for news class c and term type k. In the work, we just simply use statistics in table 2 as the reweighting parameters.",
                "Even thought using the statistics directly may not the best choice, we do not discuss how to automatically obtain the best parameters.",
                "We will try to use machine learning techniques to obtain the best parameters in the future work.",
                "In the work, we use BoosTexter [20] to classify all stories into one of the 11 ROIs.",
                "BoosTexter is a boosting based machine learning program, which creates a series of simple rules for building a classifier for text or attribute-value data.",
                "We use term weight generated using TF-IDF model as feature for story classification.",
                "We trained the model on the 12000 judged English stories in TDT2, and classify the rest of the stories in TDT2 and all stories in TDT3.",
                "Classification results are used for term reweighting in formula (11).",
                "Since the class labels of topic-off stories are not given in TDT datasets, we cannot give the classification accuracy here.",
                "Thus we do not discuss the effects of classification accuracy to NED performance in the paper. 6.",
                "EXPERIMENTAL SETUP 6.1 Datasets We used two LDC [18] datasets TDT2 and TDT3 for our experiments.",
                "TDT2 contains news stories from January to June 1998.",
                "It contains around 54,000 stories from sources like ABC, Associated Press, CNN, New York Times, Public Radio International, Voice of America etc.",
                "Only English stories in the collection were considered.",
                "TDT3 contains approximately 31,000 English stories collected from October to December 1998.",
                "In addition to the sources used in TDT2, it also contains stories from NBC and MSNBC TV broadcasts.",
                "We used transcribed versions of the TV and radio broadcasts besides textual news.",
                "TDT2 dataset is labeled with about 100 topics, and approximately 12,000 English stories belong to at least one of these topics.",
                "TDT3 dataset is labeled with about 120 topics, and approximately 8000 English stories belong to at least one of these topics.",
                "All the topics are classified into 11 Rules of Interpretation: (1)Elections, (2)Scandals/Hearings, (3)Legal/Criminal Cases, (4)Natural Disasters, (5)Accidents, (6)Ongoing Violence or War, (7)Science and Discovery News, (8)Finance, (9)New Law, (10)Sports News, (11)MISC.",
                "News. 6.2 Evaluation Metric TDT uses a cost function CDet that combines the probabilities of missing a new story and a false alarm [19]: * * * *Det Miss Miss Target FA FA NontargetC C P P C P P= + (12) Table 2.",
                "Average correlation between term types and news classes where CMiss means the cost of missing a new story, PMiss means the probability of missing a new story, and PTarget means the probability of seeing a new story in the data; CFA means the cost of a false alarm, PFA means the probability of a false alarm, and PNontarget means the probability of seeing an old story.",
                "The cost CDet is normalized such that a perfect system scores 0 and a trivial system, which is the better one of mark all stories as new or old, scores 1: ( ( * , * ) ) Det Det Miss Target FA Nontarget C Norm C min C P C P = (13) New event detection system gives two outputs for each story.",
                "The first part is yes or no indicating whether the story triggers a new event or not.",
                "The second part is a score indicating confidence of the first decision.",
                "Confidence scores can be used to plot DET curve, i.e., curves that plot false alarm vs. miss probabilities.",
                "Minimum normalized cost can be determined if optimal threshold on the score were chosen. 7.",
                "EXPERIMENTAL RESULTS 7.1 Main Results To test the approaches proposed in the model, we implemented and tested five systems: System-1: this system is used as baseline.",
                "It is implemented based on the basic model described in section 3, i.e., using incremental TF-IDF model to generate term weights, and using Hellinger distance to compute document similarity.",
                "Similarity score normalization is also employed [8].",
                "S-S detection procedure is used.",
                "System-2: this system is the same as system-1 except that S-C detection procedure is used.",
                "System-3: this system is the same as system-1 except that it uses the new detection procedure which is based on indexing-tree.",
                "System-4: implemented based on the approach presented in section 5.1, i.e., terms are reweighted according to the distance between term distributions in a cluster and all stories.",
                "The new detection procedure is used.",
                "System-5: implemented based on the approach presented in section 5.2, i.e., terms of different types are reweighted according to news class using trained parameters.",
                "The new detection procedure is used.",
                "The following are some other NED systems: System-6: [21] for each pair of stories, it computes three similarity values for named entity, non-named entity and all terms respectively.",
                "And employ Support Vector Machine to predict new or old using the similarity values as features.",
                "System-7: [8] it extended a basic incremental TF-IDF model to include source-specific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, etc.",
                "System-8: [13] it split document representation into two parts: named entities and non-named entities, and choose one effective part for each news class.",
                "Table 3 and table 4 show topic-weighted normalized costs and comparing times on TDT2 and TDT3 datasets respectively.",
                "Since no heldout data set for fine-tuning the threshold θ new was available for experiments on TDT2, we only report minimum normalized costs for our systems in table 3.",
                "System-5 outperforms all other systems including system-6, and it performs only 2.78e+8 comparing times in detection procedure which is only 13.4% of system-1.",
                "Table 3.",
                "NED results on TDT2 Systems Min Norm(CDet) Cmp times System-1 0.5749 2.08e+9 System-2① 0.6673 3.77e+8 System-3② 0.5765 2.81e+8 System-4② 0.5431 2.99e+8 System-5② 0.5089 2.78e+8 System-6 0.5300 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 When evaluating on the normalized costs on TDT3, we use the optimal thresholds obtained from TDT2 data set for all systems.",
                "System-2 reduces comparing times to 1.29e+9 which is just 18.3% of system-1, but at the same time it also gets a deteriorated minimum normalized cost which is 0.0499 higher than system-1.",
                "System-3 uses the new detection procedure based on news indexing-tree.",
                "It requires even less comparing times than system-2.",
                "This is because story-story comparisons usually yield greater similarities than story-cluster ones, so stories tend to be combined Location Person Date Organization Money Percentage NN JJ CD Elections 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 Scandals/Hearings 0.66 0.62 0.28 1 0.11 0.02 0.27 0.13 0.05 Legal/Criminal Cases 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 Natural Disasters 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 Violence or War 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 Science and Discovery 0.11 1 0.01 0.22 0.08 0.12 0.19 0.08 0.03 Finances 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 Sports 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 together in system-3.",
                "And system-3 is basically equivalent to system-1 in accuracy results.",
                "System-4 adjusts term weights based on the distance of term distributions between the whole corpus and cluster story set, yielding a good improvement by 0.0468 compared to system-1.",
                "The best system (system-5) has a minimum normalized cost 0.5012, which is 0.0797 better than system-1, and also better than any other results previously reported for this dataset [8, 13].",
                "Further more, system-5 only needs 1.05e+8 comparing times which is 14.9% of system-1.",
                "Table 4.",
                "NED results on TDT3 Systems Norm(CDet) Min Norm(CDet) Cmp times System-1 0.6159 0.5809 7.04e+8 System-2① 0.6493 0.6308 1.29e+8 System-3② 0.6197 0.5868 1.03e+8 System-4② 0.5601 0.5341 1.03e+8 System-5② 0.5413 0.5012 1.05e+8 System-7 -- 0.5783 -System-8 -- 0.5229 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 Figure5 shows the five DET curves for our systems on data set TDT3.",
                "System-5 achieves the minimum cost at a false alarm rate of 0.0157 and a miss rate of 0.4310.",
                "We can observe that System4 and System-5 obtain lower miss probability at regions of low false alarm probabilities.",
                "The hypothesis is that, more weight value is transferred to key terms of topics from non-key terms.",
                "Similarity score between two stories belonging to different topics are lower than before, because their overlapping terms are usually not key terms of their topics. 7.2 Parameter selection for indexing-tree detection Figure 3 shows the minimum normalized costs obtained by system-3 on TDT3 using different parameters.",
                "Theθ init parameter is tested on six values spanning from 0.03 to 0.18.",
                "And the λ parameter is tested on four values 1, 2, 3 and 4.",
                "We can see that, whenθ init is set to 0.12, which is the closest one toθ new, the costs are lower than others.",
                "This is easy to explain, because when stories belonging to the same topic are put in a cluster, it is more reasonable for the cluster to represent the stories in it.",
                "When parameter λ is set to 3 or 4, the costs are better than other cases, but there is no much difference between 3 and 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ MinCost 0.6 0.65 0.7 0.75 0.8 0.85 0.9 Figure 3.",
                "Min Cost on TDT3 (δ =0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ Comparingtimes 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 Figure 4.",
                "Comparing times on TDT3 (δ =0.15) Figure 4 gives the comparing times used by system-3 on TDT3 with the same parameters as figure 3.",
                "The comparing times are strongly dependent onθ init.",
                "Because the greaterθ init is, the less stories combined together, the more comparing times are needed for new event decision.",
                "So we useθ init =0.13,λ =3,δ =0.15 for system-3, 4, and 5.",
                "In this parameter setting, we can get both low minimum normalized costs and less comparing times. 8.",
                "CONCLUSION We have proposed a news indexing-tree based detection procedure in our model.",
                "It reduces comparing times to about one seventh of traditional method without hurting NED accuracy.",
                "We also have presented two extensions to the basic TF-IDF model.",
                "The first extension is made by adjust term weights based on term distributions between the whole corpus and a cluster story set.",
                "And the second extension to basic TF-IDF model is better use of term types (named entities types and part-of-speed) according to news categories.",
                "Our experimental results on TDT2 and TDT3 datasets show that both of the two extensions contribute significantly to improvement in accuracy.",
                "We did not consider news time information as a clue for NED task, since most of the topics last for a long time and TDT data sets only span for a relative short period (no more than 6 months).",
                "For the future work, we want to collect news set which span for a longer period from internet, and integrate time information in NED task.",
                "Since topic is a relative coarse-grained news cluster, we also want to refine cluster granularity to event-level, and identify different events and their relations within a topic.",
                "Acknowledgments This work is supported by the National Natural Science Foundation of China under Grant No. 90604025.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] In Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. .01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90 1 2 5 10 20 40 60 80 90 False Alarm Probability (in %) MissProbability(in%) SYSTEM1 Topic Weighted Curve SYSTEM1 Min Norm(Cost) SYSTEM2 Topic Weighted Curve SYSTEM2 Min Norm(Cost) SYSTEM3 Topic Weighted Curve SYSTEM3 Min Norm(Cost) SYSTEM4 Topic Weighted Curve SYSTEM4 Min Norm(Cost) SYSTEM5 Topic Weighted Curve SYSTEM5 Min Norm(Cost) Random Performance Figure 5.",
                "DET curves on TDT3 [3] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B.T.",
                "Archibald, and X. Liu.",
                "Learning Approaches for Detecting and Tracking News Events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), 1999, 32-43. [4] Y. Yang, T. Pierce, and J. Carbonell.",
                "A Study on Retrospective and On-line Event Detection.",
                "In Proceedings of SIGIR-98, Melbourne, Australia, 1998, 28-36. [5] J. Allan, V. Lavrenko, D. Malin, and R. Swan.",
                "Detections, Bounds, and Timelines: Umass and tdt-3.",
                "In Proceedings of Topic Detection and Tracking Workshop (TDT-3), Vienna, VA, 2000, 167-174. [6] R. Papka and J. Allan.",
                "On-line New Event Detection Using Single Pass Clustering TITLE2:.",
                "Technical Report UM-CS1998-021, 1998. [7] W. Lam, H. Meng, K. Wong, and J.",
                "Yen.",
                "Using Contextual Analysis for News Event Detection.",
                "International Journal on Intelligent Systems, 2001, 525-546. [8] B. Thorsten, C. Francine, and F. Ayman.",
                "A System for New Event Detection.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2003, 330-337. [9] S. Nicola and C. Joe.",
                "Combining Semantic and Syntactic Document Classifiers to Improve First Story Detection.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2001, 424425. [10] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topicconditioned Novelty Detection.",
                "In Proceedings of the 8th ACM SIGKDD International Conference, ACM Press. 2002, 688-693. [11] M. Juha, A.M. Helena, and S. Marko.",
                "Applying Semantic Classes in Event Detection and Tracking.",
                "In Proceedings of International Conference on Natural Language Processing (ICON 2002), 2002, pages 175-183. [12] M. Juha, A.M. Helena, and S. Marko.",
                "Simple Semantics in Topic Detection and Tracking.",
                "Information Retrieval, 7(3-4): 2004, 347-368. [13] K. Giridhar and J. Allan.",
                "Text Classification and Named Entities for New Event Detection.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2004, 297-304. [14] J. P. Callan, W. B. Croft, and S. M. Harding.",
                "The INQUERY Retrieval System.",
                "In Proceedings of DEXA-92, 3rd International Conference on Database and Expert Systems Applications, 1992, 78-83. [15] R. Krovetz.",
                "Viewing Morphology as An Inference Process.",
                "In Proceedings of ACM SIGIR93, 1993, 61-81. [16] Y. Yang and J. Pedersen.",
                "A Comparative Study on Feature Selection in Text Categorization.",
                "In J. D. H. Fisher, editor, The Fourteenth International Conference on Machine Learning (ICML97), Morgan Kaufmann, 1997, 412-420. [17] T. M. Cover, and J.A.",
                "Thomas.",
                "Elements of Information Theory.",
                "Wiley. 1991. [18] The linguistic data consortium, http://www.ldc,upenn.edu/. [19] The 2001 TDT task definition and evaluation plan, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm. [20] R. E. Schapire and Y.",
                "Singer.",
                "Boostexter: A Boosting-based System for Text Categorization.",
                "In Machine Learning 39(2/3):1, Kluwer Academic Publishers, 2000, 35-168. [21] K. Giridhar and J. Allan. 2005.",
                "Using Names and Topics for New Event Detection.",
                "In Proceedings of Human Technology Conference and Conference on Empirical Methods in Natural Language, Vancouver, 2005, 121-128"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "name entity": {
            "translated_key": "entidad de nombre",
            "is_in_text": false,
            "original_annotated_sentences": [
                "New Event Detection Based on Indexing-tree and Named Entity Zhang Kuo Tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn Li Juan Zi Tsinghua University Beijing, 100084, China 86-10-62781461 ljz@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn ABSTRACT New Event Detection (NED) aims at detecting from one or multiple streams of news stories that which one is reported on a new event (i.e.",
                "not reported previously).",
                "With the overwhelming volume of news available today, there is an increasing need for a NED system which is able to detect new events more efficiently and accurately.",
                "In this paper we propose a new NED model to speed up the NED task by using news indexing-tree dynamically.",
                "Moreover, based on the observation that terms of different types have different effects for NED task, two term reweighting approaches are proposed to improve NED accuracy.",
                "In the first approach, we propose to adjust term weights dynamically based on previous story clusters and in the second approach, we propose to employ statistics on training data to learn the named entity reweighting model for each class of stories.",
                "Experimental results on two Linguistic Data Consortium (LDC) datasets TDT2 and TDT3 show that the proposed model can improve both efficiency and accuracy of NED task significantly, compared to the baseline system and other existing systems.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Search and Retrieval; H.4.2 [Information Systems Applications]: Types of Systemsdecision support.",
                "General Terms Algorithms, Performance, Experimentation 1.",
                "INTRODUCTION Topic Detection and Tracking (TDT) program aims to develop techniques which can effectively organize, search and structure news text materials from a variety of newswire and broadcast media [1].",
                "New Event Detection (NED) is one of the five tasks in TDT.",
                "It is the task of online identification of the earliest report for each topic as soon as that report arrives in the sequence of documents.",
                "A Topic is defined as a seminal event or activity, along with directly related events and activities [2].",
                "An Event is defined as something (non-trivial) happening in a certain place at a certain time [3].",
                "For instance, when a bomb explodes in a building, the exploding is the seminal event that triggers the topic, and other stories on the same topic would be those discussing salvaging efforts, the search for perpetrators, arrests and trial and so on.",
                "Useful news information is usually buried in a mass of data generated everyday.",
                "Therefore, NED systems are very useful for people who need to detect novel information from real-time news stream.",
                "These real-life needs often occur in domains like financial markets, news analysis, and intelligence gathering.",
                "In most of state-of-the-art (currently) NED systems, each news story on hand is compared to all the previous received stories.",
                "If all the similarities between them do not exceed a threshold, then the story triggers a new event.",
                "They are usually in the form of cosine similarity or Hellinger similarity metric.",
                "The core problem of NED is to identify whether two stories are on the same topic.",
                "Obviously, these systems cannot take advantage of topic information.",
                "Further more, it is not acceptable in real applications because of the large amount of computation required in the NED process.",
                "Other systems organize previous stories into clusters (each cluster corresponds to a topic), and new story is compared to the previous clusters instead of stories.",
                "This manner can reduce comparing times significantly.",
                "Nevertheless, it has been proved that this manner is less accurate [4, 5].",
                "This is because sometimes stories within a topic drift far away from each other, which could lead low similarity between a story and its topic.",
                "On the other hand, some proposed NED systems tried to improve accuracy by making better use of named entities [10, 11, 12, 13].",
                "However, none of the systems have considered that terms of different types (e.g.",
                "Noun, Verb or Person name) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "For example, the names of election candidates (Person name) are very important for stories of election class; the locations (Location name) where accidents happened are important for stories of accidents class.",
                "So, in NED, there still exist following three problems to be investigated: (1) How to speed up the detection procedure while do not decrease the detection accuracy? (2) How to make good use of cluster (topic) information to improve accuracy? (3) How to obtain better news story representation by better understanding of named entities.",
                "Driven by these problems, we have proposed three approaches in this paper. (1)To make the detection procedure faster, we propose a new NED procedure based on news indexing-tree created dynamically.",
                "Story indexing-tree is created by assembling similar stories together to form news clusters in different hierarchies according to their values of similarity.",
                "Comparisons between current story and previous clusters could help find the most similar story in less comparing times.",
                "The new procedure can reduce the amount of comparing times without hurting accuracy. (2)We use the clusters of the first floor in the indexing-tree as news topics, in which term weights are adjusted dynamically according to term distribution in the clusters.",
                "In this approach, cluster (topic) information is used properly, so the problem of theme decentralization is avoided. (3)Based on observations on the statistics obtained from training data, we found that terms of different types (e.g.",
                "Noun and Verb) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "And we propose to use statistics to optimize the weights of the terms of different types in a story according to the news class that the story belongs to.",
                "On TDT3 dataset, the new NED model just uses 14.9% comparing times of the basic model, while its minimum normalized cost is 0.5012, which is 0.0797 better than the basic model, and also better than any other results previously reported for this dataset [8, 13].",
                "The rest of the paper is organized as follows.",
                "We start off this paper by summarizing the previous work in NED in section 2.",
                "Section 3 presents the basic model for NED that most current systems use.",
                "Section 4 describes our new detection procedure based on news indexing-tree.",
                "In section 5, two term reweighting methods are proposed to improve NED accuracy.",
                "Section 6 gives our experimental data and evaluation metrics.",
                "We finally wrap up with the experimental results in Section 7, and the conclusions and future work in Section 8. 2.",
                "RELATED WORK Papka et al. proposed Single-Pass clustering on NED [6].",
                "When a new story was encountered, it was processed immediately to extract term features and a query representation of the storys content is built up.",
                "Then it was compared with all the previous queries.",
                "If the document did not trigger any queries by exceeding a threshold, it was marked as a new event.",
                "Lam et al build up previous query representations of story clusters, each of which corresponds to a topic [7].",
                "In this manner comparisons happen between stories and clusters.",
                "Recent years, most work focus on proposing better methods on comparison of stories and document representation.",
                "Brants et al. [8] extended a basic incremental TF-IDF model to include sourcespecific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, term reweighting based on inverse event frequencies, and segmentation of documents.",
                "Good improvements on TDT bench-marks were shown.",
                "Stokes et al. [9] utilized a combination of evidence from two distinct representations of a documents content.",
                "One of the representations was the usual free text vector, the other made use of lexical chains (created using WordNet) to build another term vector.",
                "Then the two representations are combined in a linear fashion.",
                "A marginal increase in effectiveness was achieved when the combined representation was used.",
                "Some efforts have been done on how to utilize named entities to improve NED.",
                "Yang et al. gave location named entities four times weight than other terms and named entities [10].",
                "DOREMI research group combined semantic similarities of person names, location names and time together with textual similarity [11][12].",
                "UMass [13] research group split document representation into two parts: named entities and non-named entities.",
                "And it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation.",
                "Both [10] and [13] used text categorization technique to classify news stories in advance.",
                "In [13] news stories are classified automatically at first, and then test sensitivities of names and non-name terms for NED for each class.",
                "In [10] frequent terms for each class are removed from document representation.",
                "For example, word election does not help identify different elections.",
                "In their work, effectiveness of different kinds of names (or terms with different POS) for NED in different news classes are not investigated.",
                "We use statistical analysis to reveal the fact and use it to improve NED performance. 3.",
                "BASIC MODEL In this section, we present the basic New Event Detection model which is similar to what most current systems apply.",
                "Then, we propose our new model by extending the basic model.",
                "New Event Detection systems use news story stream as input, in which stories are strictly time-ordered.",
                "Only previously received stories are available when dealing with current story.",
                "The output is a decision for whether the current story is on a new event or not and the confidence of the decision.",
                "Usually, a NED model consists of three parts: story representation, similarity calculation and detection procedure. 3.1 Story Representation Preprocessing is needed before generating story representation.",
                "For preprocessing, we tokenize words, recognize abbreviations, normalize abbreviations, add part-of-speech tags, remove stopwords included in the stop list used in InQuery [14], replace words with their stems using K-stem algorithm[15], and then generate word vector for each news story.",
                "We use incremental TF-IDF model for term weight calculation [4].",
                "In a TF-IDF model, term frequency in a news document is weighted by the inverse document frequency, which is generated from training corpus.",
                "When a new term occurs in testing process, there are two solutions: simply ignore the new term or set df of the term as a small const (e.g. df = 1).",
                "The new term receives too low weight in the first solution (0) and too high weight in the second solution.",
                "In incremental TF-IDF model, document frequencies are updated dynamically in each time step t: 1( ) ( ) ( )t t D tdf w df w df w−= + (1) where Dt represents news story set received in time t, and dfDt(w) means the number of documents that term w occurs in, and dft(w) means the total number of documents that term w occurs in before time t. In this work, each time window includes 50 news stories.",
                "Thus, each story d received in t is represented as follows: 1 2{ ( , , ), ( , , ),..., ( , , )}nd weight d t w weight d t w weight d t w→ where n means the number of distinct terms in story d, and ( , , )weight d t w means the weight of term w in story d at time t: log( ( , ) 1) log(( 1) /( ( ) 0.5)) ( , , ) log( ( , ) 1) log(( 1) /( ( ) 0.5)) t t t t w d tf d w N df w weight d t w tf d w N df w ∈ + + + = + + +∑ (2) where Nt means the total number of news stories before time t, and tf(d,w) means how many times term w occurs in news story d. 3.2 Similarity Calculation We use Hellinger distance for the calculation of similarity between two stories, for two stories d and d at time t, their similarity is defined as follows: , ( , , ) ( , , ) * ( , , ) w d d sim d d t weight d t w weight d t w ∈ = ∑ (3) 3.3 Detection Procedure For each story d received in time step t, the value ( ) ( ) ( ) ( ( , , )) time d time d n d max sim d d t < = (4) is a score used to determine whether d is a story about a new topic and at the same time is an indication of the confidence in our decision [8]. time(d) means the publication time of story d. If the score exceeds the thresholdθ new, then there exists a sufficiently similar document, thus d is a old story, otherwise, there is no sufficiently similar previous document, thus d is an new story. 4.",
                "New NED Procedure Traditional NED systems can be classified into two main types on the aspect of detection procedure: (1) S-S type, in which the story on hand is compared to each story received previously, and use the highest similarity to determine whether current story is about a new event; (2) S-C type, in which the story on hand is compared to all previous clusters each of which representing a topic, and the highest similarity is used for final decision for current story.",
                "If the highest similarity exceeds thresholdθ new, then it is an old story, and put it into the most similar cluster; otherwise it is a new story and create a new cluster.",
                "Previous work show that the first manner is more accurate than the second one [4][5].",
                "Since sometimes stories within a topic drift far away from each other, a story may have very low similarity with its topic.",
                "So using similarities between stories for determining new story is better than using similarities between story and clusters.",
                "Nevertheless, the first manner needs much more comparing times which means the first manner is low efficient.",
                "We propose a new detection procedure which uses comparisons with previous clusters to help find the most similar story in less comparing times, and the final new event decision is made according to the most similar story.",
                "Therefore, we can get both the accuracy of S-S type methods and the efficiency of S-C type methods.",
                "The new procedure creates a news indexing-tree dynamically, in which similar stories are put together to form a hierarchy of clusters.",
                "We index similar stories together by their common ancestor (a cluster node).",
                "Dissimilar stories are indexed in different clusters.",
                "When a story is coming, we use comparisons between the current story and previous hierarchical clusters to help find the most similar story which is useful for new event decision.",
                "After the new event decision is made, the current story is inserted to the indexing-tree for the following detection.",
                "The news indexing-tree is defined formally as follows: S-Tree = {r, NC , NS , E} where r is the root of S-Tree, NC is the set of all cluster nodes, NS is the set of all story nodes, and E is the set of all edges in S-Tree.",
                "We define a set of constraints for a S-Tree: ⅰ . , is an non-terminal node in the treeC i i N i∀ ∈ → ⅱ . , is a terminal node in the treeS i i N i∀ ∈ → ⅲ . , out degree of is at least 2C i i N i∀ ∈ → ⅳ . , is represented as the centroid of its desendantsC i i iN∀ ∈ → For a news story di, the comparison procedure and inserting procedure based on indexing-tree are defined as follows.",
                "An example is shown by Figure 1 and Figure 2.",
                "Figure 1.",
                "Comparison procedure Figure 2.",
                "Inserting procedure Comparison procedure: Step 1: compare di to all the direct child nodes of r and select λ nodes with highest similarities, e.g., C1 2 and C1 3 in Figure 1.",
                "Step 2: for each selected node in the last step, e.g.",
                "C1 2, compare di to all its direct child nodes, and select λ nodes with highest similarities, e.g.",
                "C2 2 and d8.",
                "Repeat step 2 for all non-terminal nodes.",
                "Step 3: record the terminal node with the highest similarty to di, e.g. s5, and the similarity value (0.20).",
                "Inserting di to the S-tree with r as root: Find the node n which is direct child of r in the path from r to the terminal node with highest similarity s, e.g.",
                "C1 2.",
                "If s is smaller than θ init+(h-1)δ , then add di to the tree as a direct child of r. Otherwise, if n is a terminal node, then create a cluster node instead of n, and add both n and di as its direct children; if n is an non-terminal node, then repeat this procedure and insert di to the sub-tree with n as root recursively.",
                "Here h is the length between n and the root of S-tree.",
                "The more the stories in a cluster similar to each other, the better the cluster represents the stories in it.",
                "Hence we add no constraints on the maximum of trees height and degree of a node.",
                "Therefore, we cannot give the complexity of this indexing-tree based procedure.",
                "But we will give the number of comparing times needed by the new procedure in our experiments in section7. 5.",
                "Term Reweighting Methods In this section, two term reweighting methods are proposed to improve NED accuracy.",
                "In the first method, a new way is explored for better using of cluster (topic) information.",
                "The second one finds a better way to make use of named entities based on news classification. 5.1 Term Reweighting Based on Distribution Distance TF-IDF is the most prevalent model used in information retrieval systems.",
                "The basic idea is that the fewer documents a term appears in, the more important the term is in discrimination of documents (relevant or not relevant to a query containing the term).",
                "Nevertheless, in TDT domain, we need to discriminate documents with regard to topics rather than queries.",
                "Intuitively, using cluster (topic) vectors to compare with subsequent news stories should outperform using story vectors.",
                "Unfortunately, the experimental results do not support this intuition [4][5].",
                "Based on observation on data, we find the reason is that a news topic usually contains many directly or indirectly related events, while they all have their own sub-subjects which are usually different with each other.",
                "Take the topic described in section 1 as an example, events like the explosion and salvage have very low similarities with events about criminal trial, therefore stories about trial would have low similarity with the topic vector built on its previous events.",
                "This section focuses on how to effectively make use of topic information and at the same time avoid the problem of content decentralization.",
                "At first, we classify terms into 5 classes to help analysis the needs of the modified model: Term class A: terms that occur frequently in the whole corpus, e.g., year and people.",
                "Terms of this class should be given low weights because they do not help much for topic discrimination.",
                "Term class B: terms that occur frequently within a news category, e.g., election, storm.",
                "They are useful to distinguish two stories in different news categories.",
                "However, they cannot provide information to determine whether two stories are on the same or different topics.",
                "In another words, term election and term storm are not helpful in differentiate two election campaigns and two storm disasters.",
                "Therefore, terms of this class should be assigned lower weights.",
                "Term class C: terms that occur frequently in a topic, and infrequently in other topics, e.g., the name of a crash plane, the name of a specific hurricane.",
                "News stories that belong to different topics rarely have overlap terms in this class.",
                "The more frequently a term appears in a topic, the more important the term is for a story belonging to the topic, therefore the term should be set higher weight.",
                "Term class D: terms that appear in a topic exclusively, but not frequently.",
                "For example, the name of a fireman who did very well in a salvage action, which may appears in only two or three stories but never appeared in other topics.",
                "Terms of this type should receive more weights than in TF-IDF model.",
                "However, since they are not popular in the topic, it is not appropriate to give them too high weights.",
                "Term class E: terms with low document frequency, and appear in different topics.",
                "Terms of this class should receive lower weights.",
                "Now we analyze whether TF-IDF model can give proper weights to the five classes of terms.",
                "Obviously, terms of class A are lowly weighted in TF-IDF model, which is conformable with the requirement described above.",
                "In TF-IDF model, terms of class B are highly dependant with the number of stories in a news class.",
                "TF-IDF model cannot provide low weights if the story containing the term belongs to a relative small news class.",
                "For a term of class C, the more frequently it appears in a topic, the less weight TFIDF model gives to it.",
                "This strongly conflicts with the requirement of terms in class C. For terms of class D, TF-IDF model gives them high weights correctly.",
                "But for terms of class E, TF-IDF model gives high weights to them which are not conformable with the requirement of low weights.",
                "To sum up, terms of class B, C, E cannot be properly weighted in TF-IDF model.",
                "So, we propose a modified model to resolve this problem.",
                "When θ init andθ new are set closely, we assume that most of the stories in a first-level cluster (a direct child node of root node) are on the same topic.",
                "Therefore, we make use of a first-level cluster to capture term distribution (df for all the terms within the cluster) within the topic dynamically.",
                "KL divergence of term distribution in a first-level cluster and the whole story set is used to adjust term weights:  ( , , ) * (1 * ( || )) ( , , ) ( , , ) * (1 * ( || )) cw tw cw tw w d D weight d t w KL P P weight d t w weight d t w KL P P γ γ ∈ + = +∑ (5) where ( ) ( ) ( ) ( ) 1,cw cw c c c c df w df w p y p y N N = = − (6) ( ) ( ) ( ) ( ) 1,t t tw tw t t df w df w p y p y N N = = − (7) where dfc(w) is the number of documents containing term w within cluster C, and Nc is the number of documents in cluster C, and Nt is the total number of documents that arrive before time step t. γ is a const parameter, now is manually set 3.",
                "KL divergence is defined as follows [17]: ( ) ( || ) ( ) log ( )x p x KL P Q p x q x = ∑ (8) The basic idea is: for a story in a topic, the more a term occurs within the topic, and the less it occurs in other topics, it should be assigned higher weights.",
                "Obviously, modified model can meet all the requirements of the five term classes listed above. 5.2 Term Reweighting Based on Term Type and Story Class Previous work found that some classes of news stories could achieve good improvements by giving extra weight to named entities.",
                "But we find that terms of different types should be given different amount of extra weight for different classes of news stories.",
                "We use open-NLP1 to recognize named entity types and part-ofspeech tags for terms that appear in news stories.",
                "Named entity types include person name, organization name, location name, date, time, money and percentage, and five POSs are selected: none (NN), verb (VB), adjective (JJ), adverb (RB) and cardinal number (CD).",
                "Statistical analysis shows topic-level discriminative terms types for different classes of stories.",
                "For the sake of convenience, named entity type and part-of-speech tags are uniformly called term type in subsequent sections.",
                "Determining whether two stories are about the same topic is a basic component for NED task.",
                "So at first we use 2 χ statistic to compute correlations between terms and topics.",
                "For a term t and a topic T, a contingence table is derived: Table 1.",
                "A 2×2 Contingence Table Doc Number belong to topic T not belong to topic T include t A B not include t C D The 2 χ statistic for a specific term t with respect to topic T is defined to be [16]: 2 2 ( , ) ( ) * ( ) ( ) * ( ) * ( ) * ( ) w T A B C D AD CB A C B D A B C D χ = + + + − + + + + (9) News topics for the TDT task are further classified into 11 rules of interpretations (ROIs) 2 .",
                "The ROI can be seen as a higher level class of stories.",
                "The average correlation between a term type and a topic ROI is computed as: 2 avg 2 ( , )( ( , ) )k m m km kT R w P w TP R p w T R P χ χ ∈ ∈ ∑ ∑（ , ）= 1 1 k=1…K, m=1…M (10) where K is the number of term types (set 12 constantly in the paper).",
                "M is the number news classes (ROIs, set 11 in the paper).",
                "Pk represents the set of all terms of type k, and Rm represents the set of all topics of class m, p(t,T) means the probability that t occurs in topic T. Because of limitation of space, only parts of the term types (9 term types) and parts of news classes (8 classes) are listed in table 2 with the average correlation values between them.",
                "The statistics is derived from labeled data in TDT2 corpus. (Results in table 2 are already normalized for convenience in comparison.)",
                "The statistics in table 2 indicates the usefulness of different term types in topic discrimination with respect to different news classes.",
                "We can see that, location name is the most useful term type for three news classes: Natural Disasters, Violence or War, Finances.",
                "And for three other categories Elections, Legal/Criminal Cases, Science and Discovery, person name is the most discriminative term type.",
                "For Scandals/Hearings, date is the most important information for topic discrimination.",
                "In addition, Legal/Criminal Cases and Finance topics have higher correlation with money terms, while Science and Discovery have higher correlation with percentage terms.",
                "Non-name terms are more stable for different classes. 1 . http://opennlp.sourceforge.net/ 2 . http://projects.ldc.upenn.edu/TDT3/Guide/label.html From the analysis of table 2, it is reasonable to adjust term weight according to their term type and the news class the story belongs to.",
                "New term weights are reweighted as follows: ( ) ( ) ( ) ( ) ( , , ) * ( , , ) ( , , ) * class d D type w T class d D type w w d weight d t w weight d t w weight d t w α α ∈ = ∑ (11) where type(w) represents the type of term w, and class(d) represents the class of story d, c kα is reweighting parameter for news class c and term type k. In the work, we just simply use statistics in table 2 as the reweighting parameters.",
                "Even thought using the statistics directly may not the best choice, we do not discuss how to automatically obtain the best parameters.",
                "We will try to use machine learning techniques to obtain the best parameters in the future work.",
                "In the work, we use BoosTexter [20] to classify all stories into one of the 11 ROIs.",
                "BoosTexter is a boosting based machine learning program, which creates a series of simple rules for building a classifier for text or attribute-value data.",
                "We use term weight generated using TF-IDF model as feature for story classification.",
                "We trained the model on the 12000 judged English stories in TDT2, and classify the rest of the stories in TDT2 and all stories in TDT3.",
                "Classification results are used for term reweighting in formula (11).",
                "Since the class labels of topic-off stories are not given in TDT datasets, we cannot give the classification accuracy here.",
                "Thus we do not discuss the effects of classification accuracy to NED performance in the paper. 6.",
                "EXPERIMENTAL SETUP 6.1 Datasets We used two LDC [18] datasets TDT2 and TDT3 for our experiments.",
                "TDT2 contains news stories from January to June 1998.",
                "It contains around 54,000 stories from sources like ABC, Associated Press, CNN, New York Times, Public Radio International, Voice of America etc.",
                "Only English stories in the collection were considered.",
                "TDT3 contains approximately 31,000 English stories collected from October to December 1998.",
                "In addition to the sources used in TDT2, it also contains stories from NBC and MSNBC TV broadcasts.",
                "We used transcribed versions of the TV and radio broadcasts besides textual news.",
                "TDT2 dataset is labeled with about 100 topics, and approximately 12,000 English stories belong to at least one of these topics.",
                "TDT3 dataset is labeled with about 120 topics, and approximately 8000 English stories belong to at least one of these topics.",
                "All the topics are classified into 11 Rules of Interpretation: (1)Elections, (2)Scandals/Hearings, (3)Legal/Criminal Cases, (4)Natural Disasters, (5)Accidents, (6)Ongoing Violence or War, (7)Science and Discovery News, (8)Finance, (9)New Law, (10)Sports News, (11)MISC.",
                "News. 6.2 Evaluation Metric TDT uses a cost function CDet that combines the probabilities of missing a new story and a false alarm [19]: * * * *Det Miss Miss Target FA FA NontargetC C P P C P P= + (12) Table 2.",
                "Average correlation between term types and news classes where CMiss means the cost of missing a new story, PMiss means the probability of missing a new story, and PTarget means the probability of seeing a new story in the data; CFA means the cost of a false alarm, PFA means the probability of a false alarm, and PNontarget means the probability of seeing an old story.",
                "The cost CDet is normalized such that a perfect system scores 0 and a trivial system, which is the better one of mark all stories as new or old, scores 1: ( ( * , * ) ) Det Det Miss Target FA Nontarget C Norm C min C P C P = (13) New event detection system gives two outputs for each story.",
                "The first part is yes or no indicating whether the story triggers a new event or not.",
                "The second part is a score indicating confidence of the first decision.",
                "Confidence scores can be used to plot DET curve, i.e., curves that plot false alarm vs. miss probabilities.",
                "Minimum normalized cost can be determined if optimal threshold on the score were chosen. 7.",
                "EXPERIMENTAL RESULTS 7.1 Main Results To test the approaches proposed in the model, we implemented and tested five systems: System-1: this system is used as baseline.",
                "It is implemented based on the basic model described in section 3, i.e., using incremental TF-IDF model to generate term weights, and using Hellinger distance to compute document similarity.",
                "Similarity score normalization is also employed [8].",
                "S-S detection procedure is used.",
                "System-2: this system is the same as system-1 except that S-C detection procedure is used.",
                "System-3: this system is the same as system-1 except that it uses the new detection procedure which is based on indexing-tree.",
                "System-4: implemented based on the approach presented in section 5.1, i.e., terms are reweighted according to the distance between term distributions in a cluster and all stories.",
                "The new detection procedure is used.",
                "System-5: implemented based on the approach presented in section 5.2, i.e., terms of different types are reweighted according to news class using trained parameters.",
                "The new detection procedure is used.",
                "The following are some other NED systems: System-6: [21] for each pair of stories, it computes three similarity values for named entity, non-named entity and all terms respectively.",
                "And employ Support Vector Machine to predict new or old using the similarity values as features.",
                "System-7: [8] it extended a basic incremental TF-IDF model to include source-specific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, etc.",
                "System-8: [13] it split document representation into two parts: named entities and non-named entities, and choose one effective part for each news class.",
                "Table 3 and table 4 show topic-weighted normalized costs and comparing times on TDT2 and TDT3 datasets respectively.",
                "Since no heldout data set for fine-tuning the threshold θ new was available for experiments on TDT2, we only report minimum normalized costs for our systems in table 3.",
                "System-5 outperforms all other systems including system-6, and it performs only 2.78e+8 comparing times in detection procedure which is only 13.4% of system-1.",
                "Table 3.",
                "NED results on TDT2 Systems Min Norm(CDet) Cmp times System-1 0.5749 2.08e+9 System-2① 0.6673 3.77e+8 System-3② 0.5765 2.81e+8 System-4② 0.5431 2.99e+8 System-5② 0.5089 2.78e+8 System-6 0.5300 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 When evaluating on the normalized costs on TDT3, we use the optimal thresholds obtained from TDT2 data set for all systems.",
                "System-2 reduces comparing times to 1.29e+9 which is just 18.3% of system-1, but at the same time it also gets a deteriorated minimum normalized cost which is 0.0499 higher than system-1.",
                "System-3 uses the new detection procedure based on news indexing-tree.",
                "It requires even less comparing times than system-2.",
                "This is because story-story comparisons usually yield greater similarities than story-cluster ones, so stories tend to be combined Location Person Date Organization Money Percentage NN JJ CD Elections 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 Scandals/Hearings 0.66 0.62 0.28 1 0.11 0.02 0.27 0.13 0.05 Legal/Criminal Cases 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 Natural Disasters 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 Violence or War 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 Science and Discovery 0.11 1 0.01 0.22 0.08 0.12 0.19 0.08 0.03 Finances 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 Sports 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 together in system-3.",
                "And system-3 is basically equivalent to system-1 in accuracy results.",
                "System-4 adjusts term weights based on the distance of term distributions between the whole corpus and cluster story set, yielding a good improvement by 0.0468 compared to system-1.",
                "The best system (system-5) has a minimum normalized cost 0.5012, which is 0.0797 better than system-1, and also better than any other results previously reported for this dataset [8, 13].",
                "Further more, system-5 only needs 1.05e+8 comparing times which is 14.9% of system-1.",
                "Table 4.",
                "NED results on TDT3 Systems Norm(CDet) Min Norm(CDet) Cmp times System-1 0.6159 0.5809 7.04e+8 System-2① 0.6493 0.6308 1.29e+8 System-3② 0.6197 0.5868 1.03e+8 System-4② 0.5601 0.5341 1.03e+8 System-5② 0.5413 0.5012 1.05e+8 System-7 -- 0.5783 -System-8 -- 0.5229 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 Figure5 shows the five DET curves for our systems on data set TDT3.",
                "System-5 achieves the minimum cost at a false alarm rate of 0.0157 and a miss rate of 0.4310.",
                "We can observe that System4 and System-5 obtain lower miss probability at regions of low false alarm probabilities.",
                "The hypothesis is that, more weight value is transferred to key terms of topics from non-key terms.",
                "Similarity score between two stories belonging to different topics are lower than before, because their overlapping terms are usually not key terms of their topics. 7.2 Parameter selection for indexing-tree detection Figure 3 shows the minimum normalized costs obtained by system-3 on TDT3 using different parameters.",
                "Theθ init parameter is tested on six values spanning from 0.03 to 0.18.",
                "And the λ parameter is tested on four values 1, 2, 3 and 4.",
                "We can see that, whenθ init is set to 0.12, which is the closest one toθ new, the costs are lower than others.",
                "This is easy to explain, because when stories belonging to the same topic are put in a cluster, it is more reasonable for the cluster to represent the stories in it.",
                "When parameter λ is set to 3 or 4, the costs are better than other cases, but there is no much difference between 3 and 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ MinCost 0.6 0.65 0.7 0.75 0.8 0.85 0.9 Figure 3.",
                "Min Cost on TDT3 (δ =0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ Comparingtimes 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 Figure 4.",
                "Comparing times on TDT3 (δ =0.15) Figure 4 gives the comparing times used by system-3 on TDT3 with the same parameters as figure 3.",
                "The comparing times are strongly dependent onθ init.",
                "Because the greaterθ init is, the less stories combined together, the more comparing times are needed for new event decision.",
                "So we useθ init =0.13,λ =3,δ =0.15 for system-3, 4, and 5.",
                "In this parameter setting, we can get both low minimum normalized costs and less comparing times. 8.",
                "CONCLUSION We have proposed a news indexing-tree based detection procedure in our model.",
                "It reduces comparing times to about one seventh of traditional method without hurting NED accuracy.",
                "We also have presented two extensions to the basic TF-IDF model.",
                "The first extension is made by adjust term weights based on term distributions between the whole corpus and a cluster story set.",
                "And the second extension to basic TF-IDF model is better use of term types (named entities types and part-of-speed) according to news categories.",
                "Our experimental results on TDT2 and TDT3 datasets show that both of the two extensions contribute significantly to improvement in accuracy.",
                "We did not consider news time information as a clue for NED task, since most of the topics last for a long time and TDT data sets only span for a relative short period (no more than 6 months).",
                "For the future work, we want to collect news set which span for a longer period from internet, and integrate time information in NED task.",
                "Since topic is a relative coarse-grained news cluster, we also want to refine cluster granularity to event-level, and identify different events and their relations within a topic.",
                "Acknowledgments This work is supported by the National Natural Science Foundation of China under Grant No. 90604025.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] In Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. .01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90 1 2 5 10 20 40 60 80 90 False Alarm Probability (in %) MissProbability(in%) SYSTEM1 Topic Weighted Curve SYSTEM1 Min Norm(Cost) SYSTEM2 Topic Weighted Curve SYSTEM2 Min Norm(Cost) SYSTEM3 Topic Weighted Curve SYSTEM3 Min Norm(Cost) SYSTEM4 Topic Weighted Curve SYSTEM4 Min Norm(Cost) SYSTEM5 Topic Weighted Curve SYSTEM5 Min Norm(Cost) Random Performance Figure 5.",
                "DET curves on TDT3 [3] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B.T.",
                "Archibald, and X. Liu.",
                "Learning Approaches for Detecting and Tracking News Events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), 1999, 32-43. [4] Y. Yang, T. Pierce, and J. Carbonell.",
                "A Study on Retrospective and On-line Event Detection.",
                "In Proceedings of SIGIR-98, Melbourne, Australia, 1998, 28-36. [5] J. Allan, V. Lavrenko, D. Malin, and R. Swan.",
                "Detections, Bounds, and Timelines: Umass and tdt-3.",
                "In Proceedings of Topic Detection and Tracking Workshop (TDT-3), Vienna, VA, 2000, 167-174. [6] R. Papka and J. Allan.",
                "On-line New Event Detection Using Single Pass Clustering TITLE2:.",
                "Technical Report UM-CS1998-021, 1998. [7] W. Lam, H. Meng, K. Wong, and J.",
                "Yen.",
                "Using Contextual Analysis for News Event Detection.",
                "International Journal on Intelligent Systems, 2001, 525-546. [8] B. Thorsten, C. Francine, and F. Ayman.",
                "A System for New Event Detection.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2003, 330-337. [9] S. Nicola and C. Joe.",
                "Combining Semantic and Syntactic Document Classifiers to Improve First Story Detection.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2001, 424425. [10] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topicconditioned Novelty Detection.",
                "In Proceedings of the 8th ACM SIGKDD International Conference, ACM Press. 2002, 688-693. [11] M. Juha, A.M. Helena, and S. Marko.",
                "Applying Semantic Classes in Event Detection and Tracking.",
                "In Proceedings of International Conference on Natural Language Processing (ICON 2002), 2002, pages 175-183. [12] M. Juha, A.M. Helena, and S. Marko.",
                "Simple Semantics in Topic Detection and Tracking.",
                "Information Retrieval, 7(3-4): 2004, 347-368. [13] K. Giridhar and J. Allan.",
                "Text Classification and Named Entities for New Event Detection.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2004, 297-304. [14] J. P. Callan, W. B. Croft, and S. M. Harding.",
                "The INQUERY Retrieval System.",
                "In Proceedings of DEXA-92, 3rd International Conference on Database and Expert Systems Applications, 1992, 78-83. [15] R. Krovetz.",
                "Viewing Morphology as An Inference Process.",
                "In Proceedings of ACM SIGIR93, 1993, 61-81. [16] Y. Yang and J. Pedersen.",
                "A Comparative Study on Feature Selection in Text Categorization.",
                "In J. D. H. Fisher, editor, The Fourteenth International Conference on Machine Learning (ICML97), Morgan Kaufmann, 1997, 412-420. [17] T. M. Cover, and J.A.",
                "Thomas.",
                "Elements of Information Theory.",
                "Wiley. 1991. [18] The linguistic data consortium, http://www.ldc,upenn.edu/. [19] The 2001 TDT task definition and evaluation plan, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm. [20] R. E. Schapire and Y.",
                "Singer.",
                "Boostexter: A Boosting-based System for Text Categorization.",
                "In Machine Learning 39(2/3):1, Kluwer Academic Publishers, 2000, 35-168. [21] K. Giridhar and J. Allan. 2005.",
                "Using Names and Topics for New Event Detection.",
                "In Proceedings of Human Technology Conference and Conference on Empirical Methods in Natural Language, Vancouver, 2005, 121-128"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "real-time index": {
            "translated_key": "índice en tiempo real",
            "is_in_text": false,
            "original_annotated_sentences": [
                "New Event Detection Based on Indexing-tree and Named Entity Zhang Kuo Tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn Li Juan Zi Tsinghua University Beijing, 100084, China 86-10-62781461 ljz@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn ABSTRACT New Event Detection (NED) aims at detecting from one or multiple streams of news stories that which one is reported on a new event (i.e.",
                "not reported previously).",
                "With the overwhelming volume of news available today, there is an increasing need for a NED system which is able to detect new events more efficiently and accurately.",
                "In this paper we propose a new NED model to speed up the NED task by using news indexing-tree dynamically.",
                "Moreover, based on the observation that terms of different types have different effects for NED task, two term reweighting approaches are proposed to improve NED accuracy.",
                "In the first approach, we propose to adjust term weights dynamically based on previous story clusters and in the second approach, we propose to employ statistics on training data to learn the named entity reweighting model for each class of stories.",
                "Experimental results on two Linguistic Data Consortium (LDC) datasets TDT2 and TDT3 show that the proposed model can improve both efficiency and accuracy of NED task significantly, compared to the baseline system and other existing systems.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Search and Retrieval; H.4.2 [Information Systems Applications]: Types of Systemsdecision support.",
                "General Terms Algorithms, Performance, Experimentation 1.",
                "INTRODUCTION Topic Detection and Tracking (TDT) program aims to develop techniques which can effectively organize, search and structure news text materials from a variety of newswire and broadcast media [1].",
                "New Event Detection (NED) is one of the five tasks in TDT.",
                "It is the task of online identification of the earliest report for each topic as soon as that report arrives in the sequence of documents.",
                "A Topic is defined as a seminal event or activity, along with directly related events and activities [2].",
                "An Event is defined as something (non-trivial) happening in a certain place at a certain time [3].",
                "For instance, when a bomb explodes in a building, the exploding is the seminal event that triggers the topic, and other stories on the same topic would be those discussing salvaging efforts, the search for perpetrators, arrests and trial and so on.",
                "Useful news information is usually buried in a mass of data generated everyday.",
                "Therefore, NED systems are very useful for people who need to detect novel information from real-time news stream.",
                "These real-life needs often occur in domains like financial markets, news analysis, and intelligence gathering.",
                "In most of state-of-the-art (currently) NED systems, each news story on hand is compared to all the previous received stories.",
                "If all the similarities between them do not exceed a threshold, then the story triggers a new event.",
                "They are usually in the form of cosine similarity or Hellinger similarity metric.",
                "The core problem of NED is to identify whether two stories are on the same topic.",
                "Obviously, these systems cannot take advantage of topic information.",
                "Further more, it is not acceptable in real applications because of the large amount of computation required in the NED process.",
                "Other systems organize previous stories into clusters (each cluster corresponds to a topic), and new story is compared to the previous clusters instead of stories.",
                "This manner can reduce comparing times significantly.",
                "Nevertheless, it has been proved that this manner is less accurate [4, 5].",
                "This is because sometimes stories within a topic drift far away from each other, which could lead low similarity between a story and its topic.",
                "On the other hand, some proposed NED systems tried to improve accuracy by making better use of named entities [10, 11, 12, 13].",
                "However, none of the systems have considered that terms of different types (e.g.",
                "Noun, Verb or Person name) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "For example, the names of election candidates (Person name) are very important for stories of election class; the locations (Location name) where accidents happened are important for stories of accidents class.",
                "So, in NED, there still exist following three problems to be investigated: (1) How to speed up the detection procedure while do not decrease the detection accuracy? (2) How to make good use of cluster (topic) information to improve accuracy? (3) How to obtain better news story representation by better understanding of named entities.",
                "Driven by these problems, we have proposed three approaches in this paper. (1)To make the detection procedure faster, we propose a new NED procedure based on news indexing-tree created dynamically.",
                "Story indexing-tree is created by assembling similar stories together to form news clusters in different hierarchies according to their values of similarity.",
                "Comparisons between current story and previous clusters could help find the most similar story in less comparing times.",
                "The new procedure can reduce the amount of comparing times without hurting accuracy. (2)We use the clusters of the first floor in the indexing-tree as news topics, in which term weights are adjusted dynamically according to term distribution in the clusters.",
                "In this approach, cluster (topic) information is used properly, so the problem of theme decentralization is avoided. (3)Based on observations on the statistics obtained from training data, we found that terms of different types (e.g.",
                "Noun and Verb) have different effects for different classes of stories in determining whether two stories are on the same topic.",
                "And we propose to use statistics to optimize the weights of the terms of different types in a story according to the news class that the story belongs to.",
                "On TDT3 dataset, the new NED model just uses 14.9% comparing times of the basic model, while its minimum normalized cost is 0.5012, which is 0.0797 better than the basic model, and also better than any other results previously reported for this dataset [8, 13].",
                "The rest of the paper is organized as follows.",
                "We start off this paper by summarizing the previous work in NED in section 2.",
                "Section 3 presents the basic model for NED that most current systems use.",
                "Section 4 describes our new detection procedure based on news indexing-tree.",
                "In section 5, two term reweighting methods are proposed to improve NED accuracy.",
                "Section 6 gives our experimental data and evaluation metrics.",
                "We finally wrap up with the experimental results in Section 7, and the conclusions and future work in Section 8. 2.",
                "RELATED WORK Papka et al. proposed Single-Pass clustering on NED [6].",
                "When a new story was encountered, it was processed immediately to extract term features and a query representation of the storys content is built up.",
                "Then it was compared with all the previous queries.",
                "If the document did not trigger any queries by exceeding a threshold, it was marked as a new event.",
                "Lam et al build up previous query representations of story clusters, each of which corresponds to a topic [7].",
                "In this manner comparisons happen between stories and clusters.",
                "Recent years, most work focus on proposing better methods on comparison of stories and document representation.",
                "Brants et al. [8] extended a basic incremental TF-IDF model to include sourcespecific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, term reweighting based on inverse event frequencies, and segmentation of documents.",
                "Good improvements on TDT bench-marks were shown.",
                "Stokes et al. [9] utilized a combination of evidence from two distinct representations of a documents content.",
                "One of the representations was the usual free text vector, the other made use of lexical chains (created using WordNet) to build another term vector.",
                "Then the two representations are combined in a linear fashion.",
                "A marginal increase in effectiveness was achieved when the combined representation was used.",
                "Some efforts have been done on how to utilize named entities to improve NED.",
                "Yang et al. gave location named entities four times weight than other terms and named entities [10].",
                "DOREMI research group combined semantic similarities of person names, location names and time together with textual similarity [11][12].",
                "UMass [13] research group split document representation into two parts: named entities and non-named entities.",
                "And it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation.",
                "Both [10] and [13] used text categorization technique to classify news stories in advance.",
                "In [13] news stories are classified automatically at first, and then test sensitivities of names and non-name terms for NED for each class.",
                "In [10] frequent terms for each class are removed from document representation.",
                "For example, word election does not help identify different elections.",
                "In their work, effectiveness of different kinds of names (or terms with different POS) for NED in different news classes are not investigated.",
                "We use statistical analysis to reveal the fact and use it to improve NED performance. 3.",
                "BASIC MODEL In this section, we present the basic New Event Detection model which is similar to what most current systems apply.",
                "Then, we propose our new model by extending the basic model.",
                "New Event Detection systems use news story stream as input, in which stories are strictly time-ordered.",
                "Only previously received stories are available when dealing with current story.",
                "The output is a decision for whether the current story is on a new event or not and the confidence of the decision.",
                "Usually, a NED model consists of three parts: story representation, similarity calculation and detection procedure. 3.1 Story Representation Preprocessing is needed before generating story representation.",
                "For preprocessing, we tokenize words, recognize abbreviations, normalize abbreviations, add part-of-speech tags, remove stopwords included in the stop list used in InQuery [14], replace words with their stems using K-stem algorithm[15], and then generate word vector for each news story.",
                "We use incremental TF-IDF model for term weight calculation [4].",
                "In a TF-IDF model, term frequency in a news document is weighted by the inverse document frequency, which is generated from training corpus.",
                "When a new term occurs in testing process, there are two solutions: simply ignore the new term or set df of the term as a small const (e.g. df = 1).",
                "The new term receives too low weight in the first solution (0) and too high weight in the second solution.",
                "In incremental TF-IDF model, document frequencies are updated dynamically in each time step t: 1( ) ( ) ( )t t D tdf w df w df w−= + (1) where Dt represents news story set received in time t, and dfDt(w) means the number of documents that term w occurs in, and dft(w) means the total number of documents that term w occurs in before time t. In this work, each time window includes 50 news stories.",
                "Thus, each story d received in t is represented as follows: 1 2{ ( , , ), ( , , ),..., ( , , )}nd weight d t w weight d t w weight d t w→ where n means the number of distinct terms in story d, and ( , , )weight d t w means the weight of term w in story d at time t: log( ( , ) 1) log(( 1) /( ( ) 0.5)) ( , , ) log( ( , ) 1) log(( 1) /( ( ) 0.5)) t t t t w d tf d w N df w weight d t w tf d w N df w ∈ + + + = + + +∑ (2) where Nt means the total number of news stories before time t, and tf(d,w) means how many times term w occurs in news story d. 3.2 Similarity Calculation We use Hellinger distance for the calculation of similarity between two stories, for two stories d and d at time t, their similarity is defined as follows: , ( , , ) ( , , ) * ( , , ) w d d sim d d t weight d t w weight d t w ∈ = ∑ (3) 3.3 Detection Procedure For each story d received in time step t, the value ( ) ( ) ( ) ( ( , , )) time d time d n d max sim d d t < = (4) is a score used to determine whether d is a story about a new topic and at the same time is an indication of the confidence in our decision [8]. time(d) means the publication time of story d. If the score exceeds the thresholdθ new, then there exists a sufficiently similar document, thus d is a old story, otherwise, there is no sufficiently similar previous document, thus d is an new story. 4.",
                "New NED Procedure Traditional NED systems can be classified into two main types on the aspect of detection procedure: (1) S-S type, in which the story on hand is compared to each story received previously, and use the highest similarity to determine whether current story is about a new event; (2) S-C type, in which the story on hand is compared to all previous clusters each of which representing a topic, and the highest similarity is used for final decision for current story.",
                "If the highest similarity exceeds thresholdθ new, then it is an old story, and put it into the most similar cluster; otherwise it is a new story and create a new cluster.",
                "Previous work show that the first manner is more accurate than the second one [4][5].",
                "Since sometimes stories within a topic drift far away from each other, a story may have very low similarity with its topic.",
                "So using similarities between stories for determining new story is better than using similarities between story and clusters.",
                "Nevertheless, the first manner needs much more comparing times which means the first manner is low efficient.",
                "We propose a new detection procedure which uses comparisons with previous clusters to help find the most similar story in less comparing times, and the final new event decision is made according to the most similar story.",
                "Therefore, we can get both the accuracy of S-S type methods and the efficiency of S-C type methods.",
                "The new procedure creates a news indexing-tree dynamically, in which similar stories are put together to form a hierarchy of clusters.",
                "We index similar stories together by their common ancestor (a cluster node).",
                "Dissimilar stories are indexed in different clusters.",
                "When a story is coming, we use comparisons between the current story and previous hierarchical clusters to help find the most similar story which is useful for new event decision.",
                "After the new event decision is made, the current story is inserted to the indexing-tree for the following detection.",
                "The news indexing-tree is defined formally as follows: S-Tree = {r, NC , NS , E} where r is the root of S-Tree, NC is the set of all cluster nodes, NS is the set of all story nodes, and E is the set of all edges in S-Tree.",
                "We define a set of constraints for a S-Tree: ⅰ . , is an non-terminal node in the treeC i i N i∀ ∈ → ⅱ . , is a terminal node in the treeS i i N i∀ ∈ → ⅲ . , out degree of is at least 2C i i N i∀ ∈ → ⅳ . , is represented as the centroid of its desendantsC i i iN∀ ∈ → For a news story di, the comparison procedure and inserting procedure based on indexing-tree are defined as follows.",
                "An example is shown by Figure 1 and Figure 2.",
                "Figure 1.",
                "Comparison procedure Figure 2.",
                "Inserting procedure Comparison procedure: Step 1: compare di to all the direct child nodes of r and select λ nodes with highest similarities, e.g., C1 2 and C1 3 in Figure 1.",
                "Step 2: for each selected node in the last step, e.g.",
                "C1 2, compare di to all its direct child nodes, and select λ nodes with highest similarities, e.g.",
                "C2 2 and d8.",
                "Repeat step 2 for all non-terminal nodes.",
                "Step 3: record the terminal node with the highest similarty to di, e.g. s5, and the similarity value (0.20).",
                "Inserting di to the S-tree with r as root: Find the node n which is direct child of r in the path from r to the terminal node with highest similarity s, e.g.",
                "C1 2.",
                "If s is smaller than θ init+(h-1)δ , then add di to the tree as a direct child of r. Otherwise, if n is a terminal node, then create a cluster node instead of n, and add both n and di as its direct children; if n is an non-terminal node, then repeat this procedure and insert di to the sub-tree with n as root recursively.",
                "Here h is the length between n and the root of S-tree.",
                "The more the stories in a cluster similar to each other, the better the cluster represents the stories in it.",
                "Hence we add no constraints on the maximum of trees height and degree of a node.",
                "Therefore, we cannot give the complexity of this indexing-tree based procedure.",
                "But we will give the number of comparing times needed by the new procedure in our experiments in section7. 5.",
                "Term Reweighting Methods In this section, two term reweighting methods are proposed to improve NED accuracy.",
                "In the first method, a new way is explored for better using of cluster (topic) information.",
                "The second one finds a better way to make use of named entities based on news classification. 5.1 Term Reweighting Based on Distribution Distance TF-IDF is the most prevalent model used in information retrieval systems.",
                "The basic idea is that the fewer documents a term appears in, the more important the term is in discrimination of documents (relevant or not relevant to a query containing the term).",
                "Nevertheless, in TDT domain, we need to discriminate documents with regard to topics rather than queries.",
                "Intuitively, using cluster (topic) vectors to compare with subsequent news stories should outperform using story vectors.",
                "Unfortunately, the experimental results do not support this intuition [4][5].",
                "Based on observation on data, we find the reason is that a news topic usually contains many directly or indirectly related events, while they all have their own sub-subjects which are usually different with each other.",
                "Take the topic described in section 1 as an example, events like the explosion and salvage have very low similarities with events about criminal trial, therefore stories about trial would have low similarity with the topic vector built on its previous events.",
                "This section focuses on how to effectively make use of topic information and at the same time avoid the problem of content decentralization.",
                "At first, we classify terms into 5 classes to help analysis the needs of the modified model: Term class A: terms that occur frequently in the whole corpus, e.g., year and people.",
                "Terms of this class should be given low weights because they do not help much for topic discrimination.",
                "Term class B: terms that occur frequently within a news category, e.g., election, storm.",
                "They are useful to distinguish two stories in different news categories.",
                "However, they cannot provide information to determine whether two stories are on the same or different topics.",
                "In another words, term election and term storm are not helpful in differentiate two election campaigns and two storm disasters.",
                "Therefore, terms of this class should be assigned lower weights.",
                "Term class C: terms that occur frequently in a topic, and infrequently in other topics, e.g., the name of a crash plane, the name of a specific hurricane.",
                "News stories that belong to different topics rarely have overlap terms in this class.",
                "The more frequently a term appears in a topic, the more important the term is for a story belonging to the topic, therefore the term should be set higher weight.",
                "Term class D: terms that appear in a topic exclusively, but not frequently.",
                "For example, the name of a fireman who did very well in a salvage action, which may appears in only two or three stories but never appeared in other topics.",
                "Terms of this type should receive more weights than in TF-IDF model.",
                "However, since they are not popular in the topic, it is not appropriate to give them too high weights.",
                "Term class E: terms with low document frequency, and appear in different topics.",
                "Terms of this class should receive lower weights.",
                "Now we analyze whether TF-IDF model can give proper weights to the five classes of terms.",
                "Obviously, terms of class A are lowly weighted in TF-IDF model, which is conformable with the requirement described above.",
                "In TF-IDF model, terms of class B are highly dependant with the number of stories in a news class.",
                "TF-IDF model cannot provide low weights if the story containing the term belongs to a relative small news class.",
                "For a term of class C, the more frequently it appears in a topic, the less weight TFIDF model gives to it.",
                "This strongly conflicts with the requirement of terms in class C. For terms of class D, TF-IDF model gives them high weights correctly.",
                "But for terms of class E, TF-IDF model gives high weights to them which are not conformable with the requirement of low weights.",
                "To sum up, terms of class B, C, E cannot be properly weighted in TF-IDF model.",
                "So, we propose a modified model to resolve this problem.",
                "When θ init andθ new are set closely, we assume that most of the stories in a first-level cluster (a direct child node of root node) are on the same topic.",
                "Therefore, we make use of a first-level cluster to capture term distribution (df for all the terms within the cluster) within the topic dynamically.",
                "KL divergence of term distribution in a first-level cluster and the whole story set is used to adjust term weights:  ( , , ) * (1 * ( || )) ( , , ) ( , , ) * (1 * ( || )) cw tw cw tw w d D weight d t w KL P P weight d t w weight d t w KL P P γ γ ∈ + = +∑ (5) where ( ) ( ) ( ) ( ) 1,cw cw c c c c df w df w p y p y N N = = − (6) ( ) ( ) ( ) ( ) 1,t t tw tw t t df w df w p y p y N N = = − (7) where dfc(w) is the number of documents containing term w within cluster C, and Nc is the number of documents in cluster C, and Nt is the total number of documents that arrive before time step t. γ is a const parameter, now is manually set 3.",
                "KL divergence is defined as follows [17]: ( ) ( || ) ( ) log ( )x p x KL P Q p x q x = ∑ (8) The basic idea is: for a story in a topic, the more a term occurs within the topic, and the less it occurs in other topics, it should be assigned higher weights.",
                "Obviously, modified model can meet all the requirements of the five term classes listed above. 5.2 Term Reweighting Based on Term Type and Story Class Previous work found that some classes of news stories could achieve good improvements by giving extra weight to named entities.",
                "But we find that terms of different types should be given different amount of extra weight for different classes of news stories.",
                "We use open-NLP1 to recognize named entity types and part-ofspeech tags for terms that appear in news stories.",
                "Named entity types include person name, organization name, location name, date, time, money and percentage, and five POSs are selected: none (NN), verb (VB), adjective (JJ), adverb (RB) and cardinal number (CD).",
                "Statistical analysis shows topic-level discriminative terms types for different classes of stories.",
                "For the sake of convenience, named entity type and part-of-speech tags are uniformly called term type in subsequent sections.",
                "Determining whether two stories are about the same topic is a basic component for NED task.",
                "So at first we use 2 χ statistic to compute correlations between terms and topics.",
                "For a term t and a topic T, a contingence table is derived: Table 1.",
                "A 2×2 Contingence Table Doc Number belong to topic T not belong to topic T include t A B not include t C D The 2 χ statistic for a specific term t with respect to topic T is defined to be [16]: 2 2 ( , ) ( ) * ( ) ( ) * ( ) * ( ) * ( ) w T A B C D AD CB A C B D A B C D χ = + + + − + + + + (9) News topics for the TDT task are further classified into 11 rules of interpretations (ROIs) 2 .",
                "The ROI can be seen as a higher level class of stories.",
                "The average correlation between a term type and a topic ROI is computed as: 2 avg 2 ( , )( ( , ) )k m m km kT R w P w TP R p w T R P χ χ ∈ ∈ ∑ ∑（ , ）= 1 1 k=1…K, m=1…M (10) where K is the number of term types (set 12 constantly in the paper).",
                "M is the number news classes (ROIs, set 11 in the paper).",
                "Pk represents the set of all terms of type k, and Rm represents the set of all topics of class m, p(t,T) means the probability that t occurs in topic T. Because of limitation of space, only parts of the term types (9 term types) and parts of news classes (8 classes) are listed in table 2 with the average correlation values between them.",
                "The statistics is derived from labeled data in TDT2 corpus. (Results in table 2 are already normalized for convenience in comparison.)",
                "The statistics in table 2 indicates the usefulness of different term types in topic discrimination with respect to different news classes.",
                "We can see that, location name is the most useful term type for three news classes: Natural Disasters, Violence or War, Finances.",
                "And for three other categories Elections, Legal/Criminal Cases, Science and Discovery, person name is the most discriminative term type.",
                "For Scandals/Hearings, date is the most important information for topic discrimination.",
                "In addition, Legal/Criminal Cases and Finance topics have higher correlation with money terms, while Science and Discovery have higher correlation with percentage terms.",
                "Non-name terms are more stable for different classes. 1 . http://opennlp.sourceforge.net/ 2 . http://projects.ldc.upenn.edu/TDT3/Guide/label.html From the analysis of table 2, it is reasonable to adjust term weight according to their term type and the news class the story belongs to.",
                "New term weights are reweighted as follows: ( ) ( ) ( ) ( ) ( , , ) * ( , , ) ( , , ) * class d D type w T class d D type w w d weight d t w weight d t w weight d t w α α ∈ = ∑ (11) where type(w) represents the type of term w, and class(d) represents the class of story d, c kα is reweighting parameter for news class c and term type k. In the work, we just simply use statistics in table 2 as the reweighting parameters.",
                "Even thought using the statistics directly may not the best choice, we do not discuss how to automatically obtain the best parameters.",
                "We will try to use machine learning techniques to obtain the best parameters in the future work.",
                "In the work, we use BoosTexter [20] to classify all stories into one of the 11 ROIs.",
                "BoosTexter is a boosting based machine learning program, which creates a series of simple rules for building a classifier for text or attribute-value data.",
                "We use term weight generated using TF-IDF model as feature for story classification.",
                "We trained the model on the 12000 judged English stories in TDT2, and classify the rest of the stories in TDT2 and all stories in TDT3.",
                "Classification results are used for term reweighting in formula (11).",
                "Since the class labels of topic-off stories are not given in TDT datasets, we cannot give the classification accuracy here.",
                "Thus we do not discuss the effects of classification accuracy to NED performance in the paper. 6.",
                "EXPERIMENTAL SETUP 6.1 Datasets We used two LDC [18] datasets TDT2 and TDT3 for our experiments.",
                "TDT2 contains news stories from January to June 1998.",
                "It contains around 54,000 stories from sources like ABC, Associated Press, CNN, New York Times, Public Radio International, Voice of America etc.",
                "Only English stories in the collection were considered.",
                "TDT3 contains approximately 31,000 English stories collected from October to December 1998.",
                "In addition to the sources used in TDT2, it also contains stories from NBC and MSNBC TV broadcasts.",
                "We used transcribed versions of the TV and radio broadcasts besides textual news.",
                "TDT2 dataset is labeled with about 100 topics, and approximately 12,000 English stories belong to at least one of these topics.",
                "TDT3 dataset is labeled with about 120 topics, and approximately 8000 English stories belong to at least one of these topics.",
                "All the topics are classified into 11 Rules of Interpretation: (1)Elections, (2)Scandals/Hearings, (3)Legal/Criminal Cases, (4)Natural Disasters, (5)Accidents, (6)Ongoing Violence or War, (7)Science and Discovery News, (8)Finance, (9)New Law, (10)Sports News, (11)MISC.",
                "News. 6.2 Evaluation Metric TDT uses a cost function CDet that combines the probabilities of missing a new story and a false alarm [19]: * * * *Det Miss Miss Target FA FA NontargetC C P P C P P= + (12) Table 2.",
                "Average correlation between term types and news classes where CMiss means the cost of missing a new story, PMiss means the probability of missing a new story, and PTarget means the probability of seeing a new story in the data; CFA means the cost of a false alarm, PFA means the probability of a false alarm, and PNontarget means the probability of seeing an old story.",
                "The cost CDet is normalized such that a perfect system scores 0 and a trivial system, which is the better one of mark all stories as new or old, scores 1: ( ( * , * ) ) Det Det Miss Target FA Nontarget C Norm C min C P C P = (13) New event detection system gives two outputs for each story.",
                "The first part is yes or no indicating whether the story triggers a new event or not.",
                "The second part is a score indicating confidence of the first decision.",
                "Confidence scores can be used to plot DET curve, i.e., curves that plot false alarm vs. miss probabilities.",
                "Minimum normalized cost can be determined if optimal threshold on the score were chosen. 7.",
                "EXPERIMENTAL RESULTS 7.1 Main Results To test the approaches proposed in the model, we implemented and tested five systems: System-1: this system is used as baseline.",
                "It is implemented based on the basic model described in section 3, i.e., using incremental TF-IDF model to generate term weights, and using Hellinger distance to compute document similarity.",
                "Similarity score normalization is also employed [8].",
                "S-S detection procedure is used.",
                "System-2: this system is the same as system-1 except that S-C detection procedure is used.",
                "System-3: this system is the same as system-1 except that it uses the new detection procedure which is based on indexing-tree.",
                "System-4: implemented based on the approach presented in section 5.1, i.e., terms are reweighted according to the distance between term distributions in a cluster and all stories.",
                "The new detection procedure is used.",
                "System-5: implemented based on the approach presented in section 5.2, i.e., terms of different types are reweighted according to news class using trained parameters.",
                "The new detection procedure is used.",
                "The following are some other NED systems: System-6: [21] for each pair of stories, it computes three similarity values for named entity, non-named entity and all terms respectively.",
                "And employ Support Vector Machine to predict new or old using the similarity values as features.",
                "System-7: [8] it extended a basic incremental TF-IDF model to include source-specific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, etc.",
                "System-8: [13] it split document representation into two parts: named entities and non-named entities, and choose one effective part for each news class.",
                "Table 3 and table 4 show topic-weighted normalized costs and comparing times on TDT2 and TDT3 datasets respectively.",
                "Since no heldout data set for fine-tuning the threshold θ new was available for experiments on TDT2, we only report minimum normalized costs for our systems in table 3.",
                "System-5 outperforms all other systems including system-6, and it performs only 2.78e+8 comparing times in detection procedure which is only 13.4% of system-1.",
                "Table 3.",
                "NED results on TDT2 Systems Min Norm(CDet) Cmp times System-1 0.5749 2.08e+9 System-2① 0.6673 3.77e+8 System-3② 0.5765 2.81e+8 System-4② 0.5431 2.99e+8 System-5② 0.5089 2.78e+8 System-6 0.5300 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 When evaluating on the normalized costs on TDT3, we use the optimal thresholds obtained from TDT2 data set for all systems.",
                "System-2 reduces comparing times to 1.29e+9 which is just 18.3% of system-1, but at the same time it also gets a deteriorated minimum normalized cost which is 0.0499 higher than system-1.",
                "System-3 uses the new detection procedure based on news indexing-tree.",
                "It requires even less comparing times than system-2.",
                "This is because story-story comparisons usually yield greater similarities than story-cluster ones, so stories tend to be combined Location Person Date Organization Money Percentage NN JJ CD Elections 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 Scandals/Hearings 0.66 0.62 0.28 1 0.11 0.02 0.27 0.13 0.05 Legal/Criminal Cases 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 Natural Disasters 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 Violence or War 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 Science and Discovery 0.11 1 0.01 0.22 0.08 0.12 0.19 0.08 0.03 Finances 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 Sports 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 together in system-3.",
                "And system-3 is basically equivalent to system-1 in accuracy results.",
                "System-4 adjusts term weights based on the distance of term distributions between the whole corpus and cluster story set, yielding a good improvement by 0.0468 compared to system-1.",
                "The best system (system-5) has a minimum normalized cost 0.5012, which is 0.0797 better than system-1, and also better than any other results previously reported for this dataset [8, 13].",
                "Further more, system-5 only needs 1.05e+8 comparing times which is 14.9% of system-1.",
                "Table 4.",
                "NED results on TDT3 Systems Norm(CDet) Min Norm(CDet) Cmp times System-1 0.6159 0.5809 7.04e+8 System-2① 0.6493 0.6308 1.29e+8 System-3② 0.6197 0.5868 1.03e+8 System-4② 0.5601 0.5341 1.03e+8 System-5② 0.5413 0.5012 1.05e+8 System-7 -- 0.5783 -System-8 -- 0.5229 -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 Figure5 shows the five DET curves for our systems on data set TDT3.",
                "System-5 achieves the minimum cost at a false alarm rate of 0.0157 and a miss rate of 0.4310.",
                "We can observe that System4 and System-5 obtain lower miss probability at regions of low false alarm probabilities.",
                "The hypothesis is that, more weight value is transferred to key terms of topics from non-key terms.",
                "Similarity score between two stories belonging to different topics are lower than before, because their overlapping terms are usually not key terms of their topics. 7.2 Parameter selection for indexing-tree detection Figure 3 shows the minimum normalized costs obtained by system-3 on TDT3 using different parameters.",
                "Theθ init parameter is tested on six values spanning from 0.03 to 0.18.",
                "And the λ parameter is tested on four values 1, 2, 3 and 4.",
                "We can see that, whenθ init is set to 0.12, which is the closest one toθ new, the costs are lower than others.",
                "This is easy to explain, because when stories belonging to the same topic are put in a cluster, it is more reasonable for the cluster to represent the stories in it.",
                "When parameter λ is set to 3 or 4, the costs are better than other cases, but there is no much difference between 3 and 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ MinCost 0.6 0.65 0.7 0.75 0.8 0.85 0.9 Figure 3.",
                "Min Cost on TDT3 (δ =0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ Comparingtimes 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 Figure 4.",
                "Comparing times on TDT3 (δ =0.15) Figure 4 gives the comparing times used by system-3 on TDT3 with the same parameters as figure 3.",
                "The comparing times are strongly dependent onθ init.",
                "Because the greaterθ init is, the less stories combined together, the more comparing times are needed for new event decision.",
                "So we useθ init =0.13,λ =3,δ =0.15 for system-3, 4, and 5.",
                "In this parameter setting, we can get both low minimum normalized costs and less comparing times. 8.",
                "CONCLUSION We have proposed a news indexing-tree based detection procedure in our model.",
                "It reduces comparing times to about one seventh of traditional method without hurting NED accuracy.",
                "We also have presented two extensions to the basic TF-IDF model.",
                "The first extension is made by adjust term weights based on term distributions between the whole corpus and a cluster story set.",
                "And the second extension to basic TF-IDF model is better use of term types (named entities types and part-of-speed) according to news categories.",
                "Our experimental results on TDT2 and TDT3 datasets show that both of the two extensions contribute significantly to improvement in accuracy.",
                "We did not consider news time information as a clue for NED task, since most of the topics last for a long time and TDT data sets only span for a relative short period (no more than 6 months).",
                "For the future work, we want to collect news set which span for a longer period from internet, and integrate time information in NED task.",
                "Since topic is a relative coarse-grained news cluster, we also want to refine cluster granularity to event-level, and identify different events and their relations within a topic.",
                "Acknowledgments This work is supported by the National Natural Science Foundation of China under Grant No. 90604025.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] In Topic Detection and Tracking.",
                "Event-based Information Organization.",
                "Kluwer Academic Publishers, 2002. .01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90 1 2 5 10 20 40 60 80 90 False Alarm Probability (in %) MissProbability(in%) SYSTEM1 Topic Weighted Curve SYSTEM1 Min Norm(Cost) SYSTEM2 Topic Weighted Curve SYSTEM2 Min Norm(Cost) SYSTEM3 Topic Weighted Curve SYSTEM3 Min Norm(Cost) SYSTEM4 Topic Weighted Curve SYSTEM4 Min Norm(Cost) SYSTEM5 Topic Weighted Curve SYSTEM5 Min Norm(Cost) Random Performance Figure 5.",
                "DET curves on TDT3 [3] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B.T.",
                "Archibald, and X. Liu.",
                "Learning Approaches for Detecting and Tracking News Events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), 1999, 32-43. [4] Y. Yang, T. Pierce, and J. Carbonell.",
                "A Study on Retrospective and On-line Event Detection.",
                "In Proceedings of SIGIR-98, Melbourne, Australia, 1998, 28-36. [5] J. Allan, V. Lavrenko, D. Malin, and R. Swan.",
                "Detections, Bounds, and Timelines: Umass and tdt-3.",
                "In Proceedings of Topic Detection and Tracking Workshop (TDT-3), Vienna, VA, 2000, 167-174. [6] R. Papka and J. Allan.",
                "On-line New Event Detection Using Single Pass Clustering TITLE2:.",
                "Technical Report UM-CS1998-021, 1998. [7] W. Lam, H. Meng, K. Wong, and J.",
                "Yen.",
                "Using Contextual Analysis for News Event Detection.",
                "International Journal on Intelligent Systems, 2001, 525-546. [8] B. Thorsten, C. Francine, and F. Ayman.",
                "A System for New Event Detection.",
                "In Proceedings of the 26th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2003, 330-337. [9] S. Nicola and C. Joe.",
                "Combining Semantic and Syntactic Document Classifiers to Improve First Story Detection.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2001, 424425. [10] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.",
                "Topicconditioned Novelty Detection.",
                "In Proceedings of the 8th ACM SIGKDD International Conference, ACM Press. 2002, 688-693. [11] M. Juha, A.M. Helena, and S. Marko.",
                "Applying Semantic Classes in Event Detection and Tracking.",
                "In Proceedings of International Conference on Natural Language Processing (ICON 2002), 2002, pages 175-183. [12] M. Juha, A.M. Helena, and S. Marko.",
                "Simple Semantics in Topic Detection and Tracking.",
                "Information Retrieval, 7(3-4): 2004, 347-368. [13] K. Giridhar and J. Allan.",
                "Text Classification and Named Entities for New Event Detection.",
                "In Proceedings of the 27th Annual International ACM SIGIR Conference, New York, NY, USA.",
                "ACM Press. 2004, 297-304. [14] J. P. Callan, W. B. Croft, and S. M. Harding.",
                "The INQUERY Retrieval System.",
                "In Proceedings of DEXA-92, 3rd International Conference on Database and Expert Systems Applications, 1992, 78-83. [15] R. Krovetz.",
                "Viewing Morphology as An Inference Process.",
                "In Proceedings of ACM SIGIR93, 1993, 61-81. [16] Y. Yang and J. Pedersen.",
                "A Comparative Study on Feature Selection in Text Categorization.",
                "In J. D. H. Fisher, editor, The Fourteenth International Conference on Machine Learning (ICML97), Morgan Kaufmann, 1997, 412-420. [17] T. M. Cover, and J.A.",
                "Thomas.",
                "Elements of Information Theory.",
                "Wiley. 1991. [18] The linguistic data consortium, http://www.ldc,upenn.edu/. [19] The 2001 TDT task definition and evaluation plan, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm. [20] R. E. Schapire and Y.",
                "Singer.",
                "Boostexter: A Boosting-based System for Text Categorization.",
                "In Machine Learning 39(2/3):1, Kluwer Academic Publishers, 2000, 35-168. [21] K. Giridhar and J. Allan. 2005.",
                "Using Names and Topics for New Event Detection.",
                "In Proceedings of Human Technology Conference and Conference on Empirical Methods in Natural Language, Vancouver, 2005, 121-128"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        }
    }
}