{
    "id": "H-84",
    "original_text": "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner. Previous research focused only on organizing news stories by their topics into a flat hierarchy. We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly. In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models. We call the process of recognizing events and their dependencies event threading. We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories. We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem. Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies. Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them. Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1. INTRODUCTION News forms a major portion of information disseminated in the world everyday. Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day. Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly. This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization. One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories. For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics. However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events. This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3]. For example, when a bomb explodes in a building, that is the seminal event that triggers the topic. Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on. We see that there is a pattern of dependencies between pairs of events in the topic. In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators. In this work we investigate methods for modeling the structure of a topic in terms of its events. By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them. We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages. We refer to the resulting interconnected structure of events as the event model of the topic. Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do. From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster. The rest of the paper is organized as follows. In section 2, we discuss related work. In section 3, we define the problem and use an example to illustrate threading of events within a news topic. In section 4, we describe how we built the corpus for our problem. Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure. In section 7 we present our experiments and results. Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2. RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part. Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7]. Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion. Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6]. The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships. Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models. Our work differs from theirs in that we do not constrain the dependency to be linear. Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic. In TDT, researchers have traditionally considered topics as flatclusters [1]. However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure. However this structure still did not explicitly model any dependencies between events. In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events. However, the paper stopped short of proposing any models to the problem. Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3. PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT. We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1. Story: A story is a news article delivering some information to users. In TDT, a story is assumed to refer to only a single topic. In this work, we also assume that each story discusses a single event. In other words, a story is the smallest atomic unit in the hierarchy (topic event story). Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2. Event: An event is something that happens at some specific time and place [10]. In our work, we represent an event by a set of stories that discuss it. Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3. Topic: A set of news stories strongly connected by a seminal event. We expand on this definition and interpret a topic as a series of related events. Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events. We will describe this representation of a topic in more detail in the next section. 4. Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3]. Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5. Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events. Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics. Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories. We first define our problem and representation of our model formally and then illustrate with the help of an example. We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication. We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event. The last constraint tells us that every story belongs to one of the events in . In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events. It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering. By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A. By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A. For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident. Clearly, the investigations are a result of the crash. Hence an arrow from A to B falls under the category of causal dependency. Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba. Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A. An arrow in such scenario captures what we call time ordering. In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical. A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges. This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic. To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news). This topic has 23 stories which form 5 events. An event model of this topic can be represented as in figure 1. Each box in the figure indicates an event in the topic of Osamas indictment. The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1. Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward. Thus all the dependencies in the example are causal. Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ . We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies. Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment. Event threading is strongly related to topic detection and tracking, but also different from it significantly. It goes beyond topics, and models the relationships between events. Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1. The number of events is unknown. 2. The granularity of events is hard to define. 3. The dependencies among events are hard to model. 4. Since it is a brand new research area, no standard evaluation metrics and benchmark data is available. In the next few sections, we will describe our attempts to tackle these problems. 4. LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus. The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news. If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators. The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme. We believe modeling such stories would be a useful first step before dealing with more complex data sets. We hired an annotator to create truth data. Annotation includes defining the event membership for each story and also the dependencies. We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3. In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location. The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B. This is to satisfy our assumption that each story corresponds to a unique event. The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible. We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small. As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic. We believe that this would help make her understanding of the events more concrete. We however, do not use or model these titles in our algorithms. In defining dependencies between events, we imposed no restrictions on the graph structure. Each event could have single, multiple or no parents. Further, the graph could have cycles or orphannodes. The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time. From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly. Table 1 shows that the training and test sets have fairly similar statistics. Feature Training set Test set Num. topics 26 27 Avg. Num. Stories/Topic 28.69 26.74 Avg. Doc. Len. 64.60 64.04 Avg. Num. Stories/Event 5.65 6.22 Avg. Num. Events/Topic 5.07 4.29 Avg. Num. Dependencies/Topic 3.07 2.92 Avg. Num. Dependencies/Event 0.61 0.68 Avg. Num. Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5. EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake). Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure. And different event granularities may bring huge discrepancy between Å¼ and Å. This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution. Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies. Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å. Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ. In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake. As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation. Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event. È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event. Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼. Note that the direction of dependency is important in comparison. È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å. Again, the direction of dependency is taken into consideration. Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2. We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6. TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them. In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them. For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream. This task is similar to traditional clustering but features other than word distributions may also be critical in our application. In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features. Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature. Additionally, named-entities such as person and location names are another obvious feature when forming events. Stories in the same event tend to be related to the same person(s) and locations(s). In this subsection, we present an agglomerative clustering algorithm that combines all these features. In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story. So the similarity between two events, to start with, is exactly the similarity between the corresponding stories. The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features. In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them. Ó×´×½ ×¾µ is the cosine similarity of the term vectors. ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0. È Ö´×½ ×¾µ is similarly defined for person name. We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities. The time period of each topic differs a lot, from a few days to a few months. So we normalize the time difference using the whole duration of that topic. The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively. T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor. In each iteration, we find the most similar event pair and merge them. We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question. A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world. For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general. We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them. Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent. In this subsection, we describe the models we considered for capturing dependencies. In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼. First we define a couple of features that the following models will employ. First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication. Now, the event-time-ordering function Ø is defined as follows. Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories. We will also use average cosine similarity between two events as a feature and it is defined as follows. Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events. The direction of dependency is determined by the time-ordering of the first stories in the respective events. Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function. In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú . We point out that this is not to be confused with the complete-link algorithm in clustering. Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì. Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent. We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate. The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent. An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì. Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼. Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7. EXPERIMENTS Our experiments consists of three parts. First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1. Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2. Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model. This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components. The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance. All the parameters are learned by tuning on the training set. We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training. We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline. The results on the training and test sets are in Table 2 and 3 respectively. We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion. Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test). The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering. In equation 12, ½ ½, ¾ ¿ ¼. And « ¼ in equation 13. This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used. Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12. All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm. When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì. Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs. We had expected locations and person names to improve the result, but it is not the case. Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events. Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time. Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity. However, for most applications, it is not available. We used it only as a cheat experiment for comparison with other algorithms. On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies. We use the true mapping function and by implication the true events Î . We build our dependency structure ¼ using all the five models described in section 6.2. We first train our models on the 26 training topics. Training involves learning the best threshold Ì for each of the models. We then test the performances of all the trained models on the 27 test topics. We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF). We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents. Table 4 lists the results on the training set. We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level. Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level. In table 5 we present the comparison of the models on the test set. Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set. The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set. However all the other models are better than the baseline including the best similarity which is statistically significant. Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure. We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant. On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set. Although there is a lot of room for improvement, we believe this is a good first step. Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model. Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation. From the clustering techniques, we choose the best performing Cos+TD. As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies. Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure. For each algorithm, we need to optimize both the clustering threshold and the dependency threshold. We did this empirically on the training set and the optimal values are listed in table 6. The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level. On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance. Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality. Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance. The results on the test set present a very similar story as shown in table 7. We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly. The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8. DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics. Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies. In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them. We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity. Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system. However, the performance deteriorates rapidly if the system has to discover the events by itself. Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines. Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level. Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments. Hence, we should focus not only on improving dependencies but also on clustering at the same time. As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies. And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events. We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers. We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures. Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments. This work was supported in part by the Center 452 Model Cluster T Dep. T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903. Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9. REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang. Topic detection and tracking pilot study: Final report. In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar. Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor. Topic Detection and Tracking:Event based Information Organization. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal. Temporal summaries of new topics. In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18. ACM Press, 2001. [5] Regina Barzilay and Lillian Lee. Catching the drift: Probabilistic content models, with applications to generation and summarization. In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft. Discovering and comparing topic hierarchies. In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles. Threading electronic mail: a preliminary study. Inf. Process. Manage., 33(2):209-217, 1997. [8] Juha Makkonen. Investigations on event evolution in tdt. In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim. Hierarchical text classification and evaluation. In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu. Learning approaches for detecting and tracking news events. In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453",
    "original_translation": "Enhebrado de eventos dentro de los temas de noticias Ramesh Nallapati, Ao Feng, Fuchun Peng, Centro James Allan para la recuperación de información inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 Nmramesh, Aofeng, Fuchun, Allan @Cs.UMass.Edu Resumen con el volumen abrumadorDe las noticias en línea disponibles hoy, existe una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se centraron solo en organizar noticias de sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda el tema rápidamente. En este trabajo, intentamos capturar la rica estructura de los eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocimiento de eventos y sus dependencias. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una lista plana de historias sobre el tema. Definimos formalmente el nuevo problema, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas, como la localidad temporal de historias para el reconocimiento de eventos y el pedido de tiempo para capturar dependencias. Nuestros experimentos en un conjunto de datos etiquetados manualmente muestran que nuestros modelos identifican efectivamente los eventos y capturan las dependencias entre ellos. Categorías y descriptores de sujetos H.3.3 [Búsqueda y recuperación de información]: algoritmos de términos generales de agrupación, experimentación, medición 1. Introducción Las noticias forman una parte importante de la información difundida en el mundo todos los días. Las personas comunes y los analistas de noticias están muy interesados en mantenerse al tanto de las cosas nuevas que suceden en las noticias, pero se está volviendo muy difícil hacer frente a los enormes volúmenes de información que llega cada día. Por lo tanto, existe una creciente necesidad de técnicas automáticas para organizar las noticias de una manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Topic Detection and Tracking (TDT) [3] que ejecuta una competencia anual abierta en tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT es organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una mera colección de historias: se caracteriza por una estructura definitiva de eventos interrelacionados. De hecho, esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas con algún evento seminal del mundo real donde un evento se define como algo que ocurre en un momento y ubicación específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de perpetradores, arrestos y juicios, etc. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de intentos de rescate está influenciado por el evento de bombardeo y también lo es el evento de búsqueda de perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos a no solo identificar los eventos que conforman un tema, sino también establecer dependencias generalmente causales. Llamamos al proceso de reconocer eventos e identificar las dependencias entre ellos, una analogía con el subproceso de correo electrónico que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura de eventos interconectada resultante como el modelo de evento del tema. Aunque este documento se centra en los eventos de enhebrado dentro de un tema de noticias existente, esperamos que dicha estructura de dependencia basada en eventos refleje con mayor precisión la estructura de las noticias que los temas estrictamente limitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados lo ayuda a obtener una visión general rápida del tema y también le permite navegar a través del tema más rápido. El resto del documento está organizado de la siguiente manera. En la Sección 2, discutimos el trabajo relacionado. En la Sección 3, definimos el problema y usamos un ejemplo para ilustrar el enhebrado de los eventos dentro de un tema de noticias. En la Sección 4, describimos cómo construimos el corpus para nuestro problema. La Sección 5 presenta nuestras técnicas de evaluación, mientras que la Sección 6 describe las técnicas que utilizamos para la estructura de eventos de modelado. En la Sección 7 presentamos nuestros experimentos y resultados. La Sección 8 concluye el documento con algunas observaciones sobre nuestros resultados y comentarios sobre el trabajo futuro.446 2. Trabajo relacionado El proceso de enhebramiento de eventos juntos está relacionado con el enhebrado del correo electrónico solo por nombre en su mayor parte. El correo electrónico generalmente incorpora una fuerte estructura de mensajes referenciados y encabezados de temas formateados constantemente, aunque las técnicas de recuperación de información son útiles cuando la estructura se rompe [7]. El subproceso de correo electrónico captura dependencias de referencia entre mensajes y no intenta reflejar ninguna estructura subyacente del mundo del mundo en discusión. Otra área de investigación que analiza la estructura dentro de un tema es la clasificación de temas de texto jerárquico [9, 6]. La jerarquía dentro de un tema impone una estructura sobre el tema, pero no sabemos de un esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones de eventos subyacentes. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del suyo, ya que no limitamos la dependencia para ser lineal. Además, sus algoritmos están sintonizados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras esperamos que nuestros algoritmos se generalicen sobre cualquier tema. En TDT, los investigadores han considerado tradicionalmente temas como planos planos [1]. Sin embargo, en TDT-2003, se ha propuesto una estructura jerárquica de la detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modeló explícitamente ninguna dependencia entre los eventos. En una obra más cercana a la nuestra, Makkonen [8] sugirió modelar temas de noticias en términos de sus eventos en evolución. Sin embargo, el documento no se detuvo en proponer cualquier modelo al problema. Otro trabajo relacionado que se ocupó del análisis dentro de un tema de noticias incluye resumen temporal de temas de noticias [4].3. Definición y notación del problema En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (de cara regular) a continuación para mayor claridad.1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se supone que una historia se refiere a un solo tema. En este trabajo, también suponemos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña de la jerarquía (historia del evento del tema). Claramente, ambos supuestos no son necesariamente verdaderos en la realidad, pero los aceptamos por simplicidad en el modelado.2. Evento: un evento es algo que sucede en algún momento y lugar específico [10]. En nuestro trabajo, representamos un evento de un conjunto de historias que lo discuten. Después de la suposición de atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede estar representado por un conjunto de grupos no superpuestos de noticias.3. Tema: Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada uno que representa un evento y un conjunto de bordes (dirigidos o no dirigidos) entre pares de estos grupos que representan las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección.4. Detección y seguimiento de temas (TDT): la detección de temas detecta grupos de historias que discuten el mismo tema;El seguimiento del tema detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se refiere principalmente a las historias de agrupación en temas que los discuten.5. Enhebrado de eventos: el hilo de eventos detecta eventos dentro de un tema, y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y el TDT es que centramos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más grandes. Además, el enhebrado de eventos modela la relación o las dependencias entre pares de eventos en un tema, mientras que TDT modela temas como grupos de historias no relacionados. Primero definimos nuestro problema y representación de nuestro modelo formalmente y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de noticias de ò ë × ½ ¡¡¡¡× ò sobre un tema determinado y su tiempo de publicación. Definimos un conjunto de eventos ½ ¡¡Ñ con las siguientes restricciones: ¾ ¾ ë (1) × Ø (2) × ¾ × Ø × ¾ (3) mientras que la primera restricción dice que cada evento es un elemento en la potencia del poderConjunto de S, la segunda restricción asegura que cada historia pueda pertenecer como máximo un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en. De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´ × µ IFF × ¾ (4) Además, también definimos un conjunto de bordes dirigidos ´ µ que denotan dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: mientras que la existencia de un borde en sí representa la relación de dos eventos, la dirección podría implicar la causalidad o el orden temporal. Por dependencia causal queremos decir que la aparición del evento B está relacionada y es una consecuencia de la ocurrencia del evento A. Por orden temporal, queremos decir que el evento B ocurrió después del evento A y está relacionado con A pero no es necesariamente una consecuencia de A. Por ejemplo, considere los siguientes dos eventos: accidente aéreo (evento A) e investigaciones posteriores (Evento B) en un tema sobre un incidente de accidente aéreo. Claramente, las investigaciones son el resultado del accidente. Por lo tanto, una flecha de A a B se encuentra en la categoría de dependencia causal. Ahora considere el par de eventos que Pope llega a Cuba (Evento A) y Pope se encuentra con Castro (Evento B) en un tema que discute la visita de los papas a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en este escenario captura lo que llamamos ordenar tiempo. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una elección más simple (y por lo tanto menos controvertida) sería ignorar la dirección en las dependencias por completo y considerar solo bordes no dirigidos. Esta elección definitivamente tiene sentido como un primer paso, pero elegimos el primero, ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de la tabla de flujo para el tema. Para que la idea de que el evento sea más concreto, considere el ejemplo del tema TDT3 30005, titulado Osama bin Ladens acusación (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede representarse como en la Figura 1. Cada cuadro de la figura indica un evento en el tema de la acusación de Osamas. La aparición del evento 2, a saber, el juicio y la acusación de Osama depende del evento de evidencia reunida por la CIA, es decir, el evento 1. Del mismo modo, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, amenazas de militantes, reacciones 447 del mundo musulmán y el anuncio de la recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo aún más nuestra notación, llamamos a un evento a un padre de B y B el hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ para ser una tupla del conjunto de eventos y un conjunto de dependencias. El juicio y (5) (3) (4) CIA anuncia la recompensa de las reacciones del mundo musulmán de las amenazas de militantes islámicos de (2) (1) acusación de Osama de la CIA reunida por evidencia Figura 1: Un modelo de evento del tema TDT Osama bin Ladens acusación. El enhebrado de eventos está fuertemente relacionado con la detección y el seguimiento de temas, pero también es diferente de él significativamente. Va más allá de los temas y modela las relaciones entre los eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y el seguimiento de los temas y es más desafiante debido a al menos las siguientes dificultades.1. Se desconoce el número de eventos.2. La granularidad de los eventos es difícil de definir.3. Las dependencias entre los eventos son difíciles de modelar.4. Dado que es un área de investigación nueva, no hay métricas de evaluación estándar y datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos de abordar estos problemas.4. Datos etiquetados Elegimos 28 temas del Corpus TDT2 y 25 temas del Corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias en el tema de CNN Headline News. Si el tema contenía más de 30 historias de CNN, elegimos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no tienden a desviarse o desviarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de tratar con conjuntos de datos más complejos. Contratamos a un anotador para crear datos de verdad. La anotación incluye definir la membresía del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y 25 temas de TDT3. Al identificar los eventos en un tema, se le pidió al anotador que siguiera ampliamente la definición de TDT de un evento, es decir, algo que ocurre en un momento y ubicación específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias discute tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. También se alentó al anotador a evitar eventos de singleton, eventos que contienen una sola noticia, si es posible. Nos dimos cuenta de nuestra propia experiencia que las personas difieren en su percepción de un evento, especialmente cuando el número de historias en ese evento es pequeña. Como parte de las pautas, instruimos al anotador que asigne títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no usamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del gráfico. Cada evento podría tener padres solteros, múltiples o nulos. Además, el gráfico podría tener ciclos o huérfanas. Sin embargo, el anotador recibió instrucciones de asignar una dependencia del evento A al evento B si y solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de pruebas de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos al azar. La Tabla 1 muestra que los conjuntos de capacitación y prueba tienen estadísticas bastante similares. Testamento de capacitación de características Conjunto de prueba Num.Temas 26 27 AVG. Numer Historias/Tema 28.69 26.74 AVG. Doc. Len.64.60 64.04 avg. Numer Historias/Evento 5.65 6.22 AVG. Numer Eventos/Tema 5.07 4.29 AVG. Numer Dependencias/Tema 3.07 2.92 AVG. Numer Dependencias/Evento 0.61 0.68 AVG. Numer Días/Tema 30.65 34.48 Tabla 1: Estadísticas de datos anotados 5. Evaluación Un sistema puede generar algún modelo de evento Å¼ ´ ¼ ¼ µ usando ciertos algoritmos, que generalmente es diferente del modelo de verdad Å ´ µ (suponemos que el anotador no cometió ningún error). Comparar un evento de evento del sistema Å¼ con el verdadero modelo Å requiere comparar todos los modelos de eventos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden traer una gran discrepancia entre Å¼ y Å. Esto ciertamente no es trivial, ya que incluso prueba si dos gráficos son isomórficos no tienen una solución de tiempo polinomial conocida. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas acuerdan sus membresías y dependencias de eventos. Específicamente, comparamos dos tipos de pares de historias: ¯ pares de clúster (´åµ): estos son el conjunto completo de pares no ordenados ´ × × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´åµ ´ × × µ × × ¾ ë ´ × µ ´ × µ (5) donde está la función en Å que mapea las historias a los eventos definidos en la ecuación 4. ¯ Pares de dependencia (´åµ): estos son el conjuntoDe todos los pares ordenados de historias ´ × × µ, de modo que hay una dependencia desde el evento de × hasta el evento de × en el modelo Å.´åµ ´ × × µ ´ ´ × µ ´ × µ ¾ (6) Tenga en cuenta que el par de la historia se ordena aquí, por lo que ´ × × µ no es equivalente a ´ × × µ. En nuestra evaluación, un par correcto con pares de dependencia de clúster 448 (b-> d) incorrecto (a, c) (a-> b) (c-> b) (b-> d) d, e d, e (d, E) (d, e) (a-> c) (a-> e) (b-> c) (b-> e) (b-> e) precisión del clúster: 1/2 recuerdo del clúster: 1/2Recuerdo de dependencia: 2/6 Precisión de dependencia: 2/4 (A-> D) True Model Sistema de eventos Modelo de evento A, B C A, C B Pares de clúster (A, B) Pares de dependencia Figura 2: La dirección de medidas de evaluación se considerará un error. Como mencionamos anteriormente en la Sección 3, ignorar la dirección puede simplificar el problema, pero perderemos la expresividad de nuestra representación. Dados estos dos conjuntos de pares de historias correspondientes al verdadero Modelo de eventos Å y al Modelo de eventos del sistema Å¼, definimos el recuerdo y la precisión para cada categoría de la siguiente manera.¯ Precisión de clúster (CP): es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. È è´ ´ × µ ´ × µ ¼´ × µ ¼´ × µ ´åµ ´å¼µ ´å¼µ (7) donde ¼ es la función de mapeo de eventos de la historia correspondiente al modelo Å¼.¯ Recuerdo del clúster (CR): es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo verdadero evento. Ê è´ ¼´ × µ ¼´ × µ ´ × µ ´ × µ ´åµ ´å¼µ ´åµ (8) ¯ Precisión de dependencia (DP): es la probabilidad de que haya una dependencia entre los eventos de dos historias seleccionadas aleatoriamente× y × en el verdadero modelo Å dado que tienen una dependencia en el modelo del sistema Å¼. Tenga en cuenta que la dirección de dependencia es importante en comparación. È´´´ ´ × µ ´ × µµ ¾ ´ ¼´ × µ ¼´ × µµ ¾ ¼ ´åµ ´å¼µ ´å¼a (9) ¯ RECUERDO DE DEPENENCIA (DR): es la probabilidad de que haya una dependencia entre los eventos entre los eventosDe dos historias seleccionadas al azar × y × en el modelo del sistema Å¼, dado que tienen una dependencia en el verdadero modelo Å. Nuevamente, se tiene en cuenta la dirección de dependencia. Ê è´´ ¼´ × µ ¼´ × µo ¾ ¼ ´ ´ × µ ´ × µµ ¾ µ ´åµ ´å¼µ ´åµ (10) Las medidas se ilustran mediante un ejemplo en la Figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación.¾ ¢ è ¢ ê è · ê ¾ ¢ è ¢ ê è · ê â ¾ ¢ ¢ · (11) donde y son las medidas de clúster y dependencia F1 respectivamente y es la medida F1 conjunta (â) que usamosMida el rendimiento general.6. Técnicas La tarea del modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellas. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas subasinas.6.1 Agrupación de cada tema se compone de múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se supone que todas las historias en el mismo tema están disponibles al mismo tiempo, en lugar de entrar en un flujo de texto. Esta tarea es similar a la agrupación tradicional, pero las características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupación de texto, la similitud entre dos historias es el producto interno de sus vectores TF-IDF, por lo tanto, lo usamos como una de nuestras características. Las historias en el mismo evento tienden a seguir la localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades con nombre, como los nombres de la persona y la ubicación, son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con las mismas personas y ubicaciones. En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. Sin embargo, en nuestros experimentos, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo.6.1. Entonces, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud û × ùñ´ × ½ × ¾µ entre dos pisos × ½ y × ¾ viene dada por la siguiente fórmula: × × ùñ´ × ½ × ¾µ ½ Ó × ´ × ½ × ¾µ · ¾äó ´ × ½ × ¾µ · ¿È Ö´ × ½ × ¾µ (12) Aquí ½, ¾, ¿son los pesos en diferentes características. En este trabajo, los determinamos empíricamente, pero en el futuro, uno puede considerar técnicas de aprendizaje más sofisticadas para determinarlas. Ó × ´ × ½ × ¾µ es la similitud cosena de los vectores térmicos. Äó ´ × ½ × ¾µ es 1 si hay alguna ubicación que aparece en ambas historias, de lo contrario es 0. È Ö´ × ½ × ¾µ se define de manera similar para el nombre de la persona. Usamos la descomposición del tiempo al calcular la similitud de los pares de historias, es decir, la mayor diferencia de tiempo entre dos historias, menores son sus similitudes. El período de tiempo de cada tema difiere mucho, de unos pocos días a unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando toda la duración de ese tema. La similitud ajustada por desintegración de tiempo 449 × ñ´ × ½ × ¾ µ se da por × ñ´ × ½ × ¾µ × × × × ½ × ¾µ «Ø½ Ø¾ ì (13) donde Ø½ y Ø¾ son las sellos de tiempo para la historia 1 y2 respectivamente. T es la diferencia horaria entre la historia más temprana y la última en el tema dado.«Es el factor de descomposición de tiempo. En cada iteración, encontramos el par de eventos más similar y fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos ù y Ú: ¯ Enlace promedio: en este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre ù y Ú como se muestra a continuación: × ñ´ ù Ú µÈ × ù¾ ù è × ú¾ × × × ù × ú µ ù Ú (14) ¯ Enlace completo: la similitud entre dos eventos viene dada por las similitudes más pequeñas de las parejas.× ñ´ ù ú µ ñ ò × ù¾ ù × ú¾ ú × ñ´ × ù × ú µ (15) ¯ enlace único: Aquí la similitud está dada por la mejor similitud entre todos los pares de historias.× ñ´ ù Ú µ ñ ü × ù¾ ù × ú¾ ú × ñ´ × ù × ú µ (16) Este proceso continúa hasta que la similitud máxima cae por debajo del umbral o el número de clústeres es menor que un número dado.6.2 Modelado de dependencia La captura de dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide las dependencias no solo en función de la información en los eventos, sino también en su base de su vasto repertorio de conocimiento de dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1, un humano conoce el juicio y la acusación de Osama está influenciada por la evidencia reunida por la CIA porque él/ella comprende el proceso de derecho en general. Creemos que un modelo robusto debería incorporar dicho conocimiento del dominio en la captura de dependencias, pero en este trabajo, como primer paso, confiaremos en las características de la superficie, como la orden del tiempo de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que tales características son útiles para capturar en gran medida las dependencias. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, suponemos que ya nos dan el mapeo ¼ ë y solo nos centramos en modelar los bordes ¼. Primero definimos un par de características que emplearán los siguientes modelos. Primero definimos una función de pedido de tiempo 1-1 Ø ë ½ ¡¡¡¡¡¡'s que clasifica historias en orden ascendente por su tiempo de publicación. Ahora, la función de pedido en el tiempo de evento Ø se define de la siguiente manera. Ø ½ ¡¡¡¡Ñ × Ø ù ú ¾ Ø ´ ùµ Ø ´ Úµ ´µ ñ × × ù¾ Ø × × ùµ × × × Ú¾ ú Ø´ × × ÚN (17) En otras palabras, Ø TimeDers Based Based Based Based Based Baseders Baseders basadosen el pedido de tiempo de sus respectivas primeras historias. También utilizaremos la similitud de coseno promedio entre dos eventos como una característica y se define de la siguiente manera. Ú ë ñ´ ù ú µ è × ù¾ ù è × ú¾ ú Ó × ´ × ù × ú µ ù Ú (18) 6.2.1 Modelo de enlace completo En este modelo, asumimos que hay dependencias entre todos los pares de eventos de eventos. La dirección de dependencia se determina por el pedido de tiempo de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera.¼ ´ ù ú µ Ø ´ ùµ Ø ´ Ú µ (19) donde Ø es la función de orden del tiempo de evento. En otras palabras, la ventaja de dependencia se dirige desde el evento ù hasta el evento Ú, si la primera historia en evento ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en la agrupación. Aunque usamos los mismos nombres, será claro en el contexto a cuál nos referimos.6.2.2 umbral simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos ù y Ú solo si la similitud de coseno promedio entre el evento y el evento Ú es mayor que un umbral ì. Formalmente, ¼ ´ ù ú µ ú ë ñ´ ù ú µ ì Ø ´ ùµ Ø ´ ú µ (20) 6.2.3 Modelo principal más cercano en este modelo, suponemos que cada evento puede tener como máximo uno padre. Definimos el conjunto de dependencias de la siguiente manera.¼ ´ ù ú µ ë Ñ´ ù ú µ ì Ø ´ ú Ø ´ ùµ · ½ (21) Por lo tanto, para cada evento, el modelo principal más cercano considera solo el evento que precede como definido por Ø como un candidato potencial. El candidato se asigna como padre solo si la similitud promedio excede un umbral predefinido ì.6.2.4 Best Simility Model Este modelo también supone que cada evento puede tener como máximo padre. A un evento se asigna a un padre ù si y solo si ù es el evento anterior más similar a Ú y la similitud excede un umbral ì. Matemáticamente, esto se puede expresar como: ¼ ´ ù ú µ ú ë ñ´ ù ú µ ù Ö ü ü û Ø ´ ´µ Ø ´ ú µ ú ë ñ´ û Ú µ (22) 6.2.5 Modelo de árbol de expansión máxima en estoModelo, primero construimos un árbol de expansión máximo (MST) utilizando un algoritmo codicioso en el siguiente gráfico pesado totalmente conectado y no dirigido cuyos vértices son los eventos y cuyos bordes se definen como los siguientes: ´ ù Ú µ µ û ù Ú µ ú ë ë ë ë ë ë ë ë ë ë ë´ ù ú µ (23) Sea Åëì´ µ el conjunto de bordes en el árbol de expansión máximo de ¼. Ahora nuestros bordes de dependencia dirigidos se definen de la siguiente manera.¼ ´ ù ú µ ´ ù Ú µ ¾ Åëì´ µ Ø ´ ùµ Ø ´ úµ ú ë ñ ù ú µ ì (24) 450 Así en este modelo, asignamos dependencias entre los eventos más similares en el tema.7. Experimentos Nuestros experimentos constan de tres partes. Primero modelamos solo la parte de agrupación de eventos (definiendo la función de mapeo ¼) utilizando algoritmos de agrupación descritos en la Sección 6.1. Luego modelamos solo las dependencias al proporcionar al sistema los clústeres verdaderos y ejecutar solo los algoritmos de dependencia de la Sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupación y dependencia para producir el modelo de evento completo. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación.7.1 Agrupación Hemos probado varias variaciones del algoritmo ì para estudiar los efectos de varias características en el rendimiento de la agrupación. Todos los parámetros se aprenden sintonizar en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con parámetros fijados en sus valores óptimos aprendidos de la capacitación. Usamos clusmodel aglomerativo mejor t cp cr cf p-valor p cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+LOC+AVG-LNK 0.07 0.37 0.74 0.45cos+PER+AVG-LNK 0.07 0.390.70 0.46cos+TD+AVG-LNK 0.04 0.45 0.70 0.53 2.9E-4* COS+N (T)+AVG-LNK-0.41 0.62 0.48 7.5E-2 Cos+N (T)+T+AVG-LNK 0.03 0.42 0.420.62 0.49 2.4e-2* cos+td+n (t)+avg-lnk-0.44 0.66 0.52 7.0e-3* cos+td+n (t)+t+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Línea de base (COS+AVG-LNK) 0.05 0.39 0.67 0.46Table 2: Comparación de algoritmos de agrupación aglomerativa (conjunto de entrenamiento) basado solo en similitud de coseno como nuestra línea de base de agrupación. Los resultados en los conjuntos de entrenamiento y prueba se encuentran en las Tabas 2 y 3 respectivamente. Utilizamos el clúster F1-Masure (CF) promediado sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF P-VALUE Value cos+1-LNK 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+loc+avg-lnk 0.37 0.73 0.45cos+per+avg-lnk 0.44 0.62 0.45cos+td+avg-lnk0.48 0.70 0.54 0.014* cos+n (t)+avg-lnk 0.41 0.71 0.51 0.31 cos+n (t)+t+avg-lnk 0.43 0.69* 0.52 0.14 cos+td+n (t)+avg-lnk 0.43 0.760.54 0.025* cos+td+n (t)+t+avg-lnk 0.47 0.69 0.54 0.0095* línea de referencia (cos+avg-lnk) 0.44 0.67 0.50Table 3: comparación de algoritmos de agrupamiento aglomerativo (conjunto de top) marcado conA £ significa que es una mejora estadísticamente significativa sobre la línea de base (nivel de confianza del 95%, una prueba t de cola). Los métodos que se muestran en la Tabla 2 y 3 son: ¯ Basora: peso del vector TF-IDF, similitud de coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿¼. Y «¼ en la ecuación 13. Este valor F es el máximo obtenido ajustando el umbral.¯ COS+1-LNK: Se utiliza la comparación de enlaces individuales (ver la ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, otras configuraciones son las mismas que la ejecución de la línea de base.¯ Cos+All-Lnk: se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único, pero toma la similitud mínima de todos los pares de historias.¯ COS+LOC+AVG-LNK: Los nombres de ubicación se utilizan al calcular la similitud.¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este usan el enlace promedio (Ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora del rendimiento.¯ cos+per+avg-lnk: ¿¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud.¯ COS+TD+AVG-LNK: Coeficiente de descomposición de tiempo «½ en la ecuación 13, lo que significa que la similitud entre dos historias se detendrá a ½ si están en diferentes extremos del tema.¯ COS+N (T)+AVG-LNK: Use el número de eventos verdaderos para controlar el algoritmo de agrupación aglomerativa. Cuando el número de grupos es menos que el de los eventos de la verdad, deje de fusionar grupos.¯ cos+n (t)+t+avg-lnk: similar a n (t) pero también detiene la aglomeración si la similitud máxima está por debajo del umbral ì.¯ cos+td:+n (t)+avg-lnk: similar a n (t) pero las similitudes se descomponen, «½ en la ecuación 13. ¯ cos+td+n (t)+t+avg-lnk: similara TD+N (verdad) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral ì. Nuestros experimentos demuestran que las similitudes de enlace único y el enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de pisos. Esperábamos que las ubicaciones y los nombres de las personas mejorara el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias en el tema comparten los mismos lugares o personas, independientemente del evento al que pertenecen, por lo que estas características pueden ser más útiles para identificar temas en lugar de eventos. La descomposición del tiempo es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a ser adyacentes entre sí en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía el algoritmo de agrupación para obtener una granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trucos para comparar con otros algoritmos. En general, la descomposición del tiempo resultó a la característica más poderosa además de la similitud de coseno tanto en los conjuntos de entrenamiento como en los conjuntos de pruebas.7.2 Dependencias En esta subsección, nuestro objetivo es modelar solo dependencias. Utilizamos la verdadera función de mapeo y, por implicación, los verdaderos eventos î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la Sección 6.2. Primero entrenamos a nuestros modelos en los 26 temas de entrenamiento. La capacitación implica aprender el mejor umbral ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de precisión de dependencia (DP), recuerdo de dependencia (DR) y dependencia de la medida F (DF). Consideramos que el modelo de enlace completo es nuestra línea de base ya que para cada evento considera trivialmente que todos los eventos anteriores son padres. La Tabla 4 enumera los resultados en el conjunto de capacitación. Vemos que si bien todos los algoritmos, excepto MST, superan el algoritmo de enlace completo de línea de base, el algoritmo principal más cercano es estadísticamente significativo desde la línea de base en términos de su valor DF utilizando una prueba T emparejada con un nivel de confianza del 95%. Modelo mejor ì DP DR DF P-Valor P Strenom más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Tresh inmediato.0.045 0.45 0.76 0.52 0.14 enlace completo - 0.36 0.93 0.48 Tabla 4: Resultados en el conjunto de entrenamiento: El mejor ì es el valor óptimo del umbral ì.* Indica que el modelo correspondiente es estadísticamente significativo en comparación con la línea de base que usa una prueba t de una cola y un nivel de confianza del 95%. En la Tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no usamos ningún ajuste, pero establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo principal más cercano, que fue significativamente mejor que la línea de base en el conjunto de entrenamiento, resulta peor que la línea de base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que la línea de base, incluida la mejor similitud que es estadísticamente significativa. Observe que todos los modelos que funcionan mejor que la línea de base en términos de DF, en realidad sacrifican su rendimiento de recuperación en comparación con la línea de base, pero mejoran su precisión sustancialmente, mejorando así su rendimiento en la medida de DF. Notamos que tanto el umbral simple como la mejor similitud son mejores que la línea de base tanto en los conjuntos de entrenamiento como de prueba, aunque la mejora no es significativa. En general, observamos que las características de nivel de superficie que utilizamos capturan las dependencias a un nivel razonable que alcanza un mejor valor de 0.72 df en el conjunto de pruebas. Aunque hay mucho margen de mejora, creemos que este es un buen primer paso. Modelo DP DR DF P-Valor Patrio más cercano 0.61 0.60 0.60 Best Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Thresh simple.0.57 0.75 0.64 0.24 línea de base (enlace completo) 0.50 0.94 0.63Table 5: Resultados en el conjunto de pruebas 7.3 Combinando la agrupación y dependencias Ahora que hemos estudiado los algoritmos de agrupación y dependencia de forma aislada, combinamos los algoritmos de mejor rendimiento y construimos los eventos completos de los eventos completosmodelo. Dado que no se ha demostrado que ninguno de los algoritmos de dependencia sea consistente y significativamente mejor que los demás, los usamos todos en nuestra experimentación. Desde las técnicas de agrupación, elegimos el costoso TD de mejor rendimiento. Como línea de base, utilizamos una combinación de las líneas de base en cada componentes, es decir, COS para agrupación y enlace completo para dependencias. Tenga en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de capacitación porque nuestra función objetivo para optimizar ahora es JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupación como el umbral de dependencia. Hicimos esto empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la Tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la Tabla 6, indican que el umbral simple COS+TD+es significativamente mejor que la línea de base en términos de la JF de valor F conjunto, utilizando un TTest emparejado de una cola al nivel de confianza del 95%. En general, notamos que si bien el rendimiento de la agrupación es comparable a los experimentos en la Sección 7.1, el rendimiento general se ve socavado por el rendimiento de bajo dependencia. A diferencia de nuestros experimentos en la Sección 7.2, donde habíamos proporcionado los verdaderos grupos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad del clúster. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido sustancialmente, lo que reduce el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la de la Tabla 7. También notamos una buena cantidad de consistencia en el rendimiento de los algoritmos de combinación.COS+TD+umbral simple supera significativamente la línea de base. Los resultados del conjunto de pruebas también apuntan al hecho de que el componente de agrupación sigue siendo un cuello de botella para lograr un buen rendimiento general.8. Discusión y conclusiones En este documento, hemos presentado una nueva perspectiva de los temas de modelado de noticias. Al contrario de la visión de TDT de los temas como una colección plana de noticias, vemos un tema de noticias como una estructura relacional de eventos interconectados por las dependencias. En este artículo, también propusimos algunos enfoques para las historias de agrupación en eventos y construir dependencias entre ellos. Desarrollamos un enfoque de agrupación basado en Timedecay que aprovecha la temporalocalización de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque de referencia basado en la similitud de coseno. Nuestros experimentos también muestran que podemos hacerlo bastante bien en las dependencias utilizando solo las características de la superficie, como la cosinesimilaridad y los sellos de tiempo de las noticias, siempre que se proporcionen verdaderos eventos al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí solo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que las líneas de base. Nuestros resultados indican que las dependencias de modelado pueden ser un problema muy difícil, especialmente cuando el rendimiento de la agrupación está por debajo del nivel ideal. Los errores en la agrupación tienen un efecto de aumento en los errores en las dependencias como hemos visto en nuestros experimentos. Por lo tanto, debemos centrarnos no solo en mejorar las dependencias sino también en la agrupación al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a los datos y descubrir nuevas características que influyen en la agrupación y las dependencias. Y para las dependencias de modelado, un marco probabilístico debería ser una mejor opción ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar el rendimiento de la agrupación y la dependencia alternativamente como lo sugiere uno de los revisores. También esperamos expandir nuestro corpus etiquetado aún más para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF P-VALUE POS+TD+PARADA más cercana 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Simility 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.000.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+umbral simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Base (cos+de enlace completo) 0.10-0.58 0.31 0.38 0.20 0.67 0.3033TableEstablecer modelo CP CR CF DP DR DF JF P-Value POS+TD+Padre más cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Mejor similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.330 0.28 0.37cos+td+umbral simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* línea de base (cos+enlace completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Resultados combinados en el conjunto de prueba para la recuperación de información inteligente y en parte por el número de concesión SpawarsyScensdN66001-02-1-8903. Cualquier opinión, hallazgos y conclusiones o recomendaciones expresadas en este material son los autores y no reflejan necesariamente las del patrocinador.9. Referencias [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron e Y. Yang. Estudio piloto de detección y seguimiento de temas: informe final. En Actas del Taller de transcripción y comprensión de Noticias de Broadcast DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolívar. Evaluación intrínseca flexible de la agrupación jerárquica para TDT.Volumen en el proceso.de la Duodécima Conferencia Internacional de ACM sobre Gestión de Información y Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª Conferencia Anual de ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captura de la deriva: modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y el Capítulo de América del Norte de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubrir y comparar jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Paso de correo electrónico: un estudio preliminar. Inf. Proceso. Manag., 33 (2): 209-217, 1997. [8] Juha Makkonen. Investigaciones sobre evolución del evento en TDT. En Actas del Taller de Estudiantes HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación y evaluación de texto jerárquico. En Actas de la Conferencia Internacional IEEE de 2001 sobre minería de datos, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En IEEE Intelligent Systems, número especial sobre aplicaciones de recuperación de información inteligente, volumen 14 (4), páginas 32-43, 1999. 453",
    "original_sentences": [
        "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
        "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
        "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
        "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
        "We call the process of recognizing events and their dependencies event threading.",
        "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
        "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
        "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
        "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
        "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
        "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
        "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
        "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
        "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
        "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
        "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
        "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
        "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
        "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
        "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
        "We see that there is a pattern of dependencies between pairs of events in the topic.",
        "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
        "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
        "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
        "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
        "We refer to the resulting interconnected structure of events as the event model of the topic.",
        "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
        "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
        "The rest of the paper is organized as follows.",
        "In section 2, we discuss related work.",
        "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
        "In section 4, we describe how we built the corpus for our problem.",
        "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
        "In section 7 we present our experiments and results.",
        "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
        "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
        "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
        "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
        "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
        "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
        "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
        "Our work differs from theirs in that we do not constrain the dependency to be linear.",
        "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
        "In TDT, researchers have traditionally considered topics as flatclusters [1].",
        "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
        "However this structure still did not explicitly model any dependencies between events.",
        "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
        "However, the paper stopped short of proposing any models to the problem.",
        "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
        "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
        "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
        "Story: A story is a news article delivering some information to users.",
        "In TDT, a story is assumed to refer to only a single topic.",
        "In this work, we also assume that each story discusses a single event.",
        "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
        "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
        "Event: An event is something that happens at some specific time and place [10].",
        "In our work, we represent an event by a set of stories that discuss it.",
        "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
        "Topic: A set of news stories strongly connected by a seminal event.",
        "We expand on this definition and interpret a topic as a series of related events.",
        "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
        "We will describe this representation of a topic in more detail in the next section. 4.",
        "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
        "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
        "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
        "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
        "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
        "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
        "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
        "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
        "The last constraint tells us that every story belongs to one of the events in .",
        "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
        "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
        "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
        "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
        "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
        "Clearly, the investigations are a result of the crash.",
        "Hence an arrow from A to B falls under the category of causal dependency.",
        "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
        "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
        "An arrow in such scenario captures what we call time ordering.",
        "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
        "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
        "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
        "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
        "This topic has 23 stories which form 5 events.",
        "An event model of this topic can be represented as in figure 1.",
        "Each box in the figure indicates an event in the topic of Osamas indictment.",
        "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
        "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
        "Thus all the dependencies in the example are causal.",
        "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
        "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
        "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
        "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
        "It goes beyond topics, and models the relationships between events.",
        "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
        "The number of events is unknown. 2.",
        "The granularity of events is hard to define. 3.",
        "The dependencies among events are hard to model. 4.",
        "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
        "In the next few sections, we will describe our attempts to tackle these problems. 4.",
        "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
        "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
        "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
        "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
        "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
        "We hired an annotator to create truth data.",
        "Annotation includes defining the event membership for each story and also the dependencies.",
        "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
        "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
        "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
        "This is to satisfy our assumption that each story corresponds to a unique event.",
        "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
        "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
        "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
        "We believe that this would help make her understanding of the events more concrete.",
        "We however, do not use or model these titles in our algorithms.",
        "In defining dependencies between events, we imposed no restrictions on the graph structure.",
        "Each event could have single, multiple or no parents.",
        "Further, the graph could have cycles or orphannodes.",
        "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
        "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
        "Table 1 shows that the training and test sets have fairly similar statistics.",
        "Feature Training set Test set Num. topics 26 27 Avg.",
        "Num.",
        "Stories/Topic 28.69 26.74 Avg.",
        "Doc.",
        "Len. 64.60 64.04 Avg.",
        "Num.",
        "Stories/Event 5.65 6.22 Avg.",
        "Num.",
        "Events/Topic 5.07 4.29 Avg.",
        "Num.",
        "Dependencies/Topic 3.07 2.92 Avg.",
        "Num.",
        "Dependencies/Event 0.61 0.68 Avg.",
        "Num.",
        "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
        "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
        "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
        "And different event granularities may bring huge discrepancy between Å¼ and Å.",
        "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
        "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
        "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
        "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
        "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
        "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
        "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
        "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
        "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
        "Note that the direction of dependency is important in comparison.",
        "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
        "Again, the direction of dependency is taken into consideration.",
        "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
        "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
        "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
        "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
        "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
        "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
        "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
        "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
        "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
        "Stories in the same event tend to be related to the same person(s) and locations(s).",
        "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
        "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
        "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
        "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
        "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
        "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
        "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
        "È Ö´×½ ×¾µ is similarly defined for person name.",
        "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
        "The time period of each topic differs a lot, from a few days to a few months.",
        "So we normalize the time difference using the whole duration of that topic.",
        "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
        "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
        "In each iteration, we find the most similar event pair and merge them.",
        "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
        "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
        "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
        "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
        "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
        "In this subsection, we describe the models we considered for capturing dependencies.",
        "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
        "First we define a couple of features that the following models will employ.",
        "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
        "Now, the event-time-ordering function Ø is defined as follows.",
        "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
        "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
        "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
        "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
        "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
        "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
        "We point out that this is not to be confused with the complete-link algorithm in clustering.",
        "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
        "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
        "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
        "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
        "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
        "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
        "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
        "EXPERIMENTS Our experiments consists of three parts.",
        "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
        "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
        "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
        "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
        "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
        "All the parameters are learned by tuning on the training set.",
        "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
        "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
        "The results on the training and test sets are in Table 2 and 3 respectively.",
        "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
        "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
        "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
        "In equation 12, ½ ½, ¾ ¿ ¼.",
        "And « ¼ in equation 13.",
        "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
        "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
        "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
        "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
        "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
        "We had expected locations and person names to improve the result, but it is not the case.",
        "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
        "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
        "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
        "However, for most applications, it is not available.",
        "We used it only as a cheat experiment for comparison with other algorithms.",
        "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
        "We use the true mapping function and by implication the true events Î .",
        "We build our dependency structure ¼ using all the five models described in section 6.2.",
        "We first train our models on the 26 training topics.",
        "Training involves learning the best threshold Ì for each of the models.",
        "We then test the performances of all the trained models on the 27 test topics.",
        "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
        "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
        "Table 4 lists the results on the training set.",
        "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
        "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
        "In table 5 we present the comparison of the models on the test set.",
        "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
        "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
        "However all the other models are better than the baseline including the best similarity which is statistically significant.",
        "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
        "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
        "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
        "Although there is a lot of room for improvement, we believe this is a good first step.",
        "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
        "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
        "From the clustering techniques, we choose the best performing Cos+TD.",
        "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
        "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
        "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
        "We did this empirically on the training set and the optimal values are listed in table 6.",
        "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
        "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
        "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
        "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
        "The results on the test set present a very similar story as shown in table 7.",
        "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
        "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
        "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
        "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
        "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
        "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
        "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
        "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
        "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
        "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
        "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
        "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
        "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
        "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
        "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
        "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
        "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
        "This work was supported in part by the Center 452 Model Cluster T Dep.",
        "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
        "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
        "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
        "Topic detection and tracking pilot study: Final report.",
        "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
        "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
        "Topic Detection and Tracking:Event based Information Organization.",
        "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
        "Temporal summaries of new topics.",
        "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
        "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
        "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
        "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
        "Discovering and comparing topic hierarchies.",
        "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
        "Threading electronic mail: a preliminary study.",
        "Inf.",
        "Process.",
        "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
        "Investigations on event evolution in tdt.",
        "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
        "Hierarchical text classification and evaluation.",
        "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
        "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
        "Learning approaches for detecting and tracking news events.",
        "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
    ],
    "error_count": 0,
    "keys": {
        "event threading": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "<br>event threading</br> within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies <br>event threading</br>.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them <br>event threading</br>, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "<br>event threading</br>: <br>event threading</br> detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between <br>event threading</br> and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally <br>event threading</br> models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of <br>event threading</br> more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "<br>event threading</br> is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, <br>event threading</br> can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "\"Enhebrado de eventos\" dentro de los temas de noticias Ramesh Nallapati, Ao Feng, Fuchun Peng, Centro James Allan para la recuperación de información inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 Nmramesh, Aofeng, Fuchun, Allan @Cs.UMass.Edu Resumen con elVolumen abrumador de noticias en línea disponibles hoy, existe una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente.",
                "Llamamos al proceso de reconocimiento de eventos y sus dependencias \"enhebramiento de eventos\".",
                "Llamamos al proceso de reconocer eventos e identificar las dependencias entre ellos \"enhebramiento de eventos\", una analogía para el subproceso de correo electrónico que muestra conexiones entre mensajes de correo electrónico relacionados.",
                "\"Event Hushing\": \"Event Hushing\" detecta eventos dentro de un tema, y también captura las dependencias entre los eventos.",
                "Por lo tanto, la principal diferencia entre \"enhebrado de eventos\" y TDT es que centramos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más grandes.",
                "Además, el \"enhebrado de eventos\" modela la relación o las dependencias entre pares de eventos en un tema, mientras que TDT modela temas como grupos de historias no relacionados.",
                "Para que la idea de \"enhebrar el evento\" sea más concreto, considere el ejemplo del tema TDT3 30005, titulado Osama bin Ladens acusación (en las noticias de 1998).",
                "\"Event Hushing\" está fuertemente relacionado con la detección y el seguimiento de los temas, pero también es diferente de él significativamente.",
                "Por lo tanto, el \"enhebrado de eventos\" puede considerarse como una extensión adicional de la detección y el seguimiento de los temas y es más desafiante debido a al menos las siguientes dificultades.1."
            ],
            "translated_text": "",
            "candidates": [
                "enhebrado de eventos",
                "Enhebrado de eventos",
                "enhebrado de eventos",
                "enhebramiento de eventos",
                "enhebrado de eventos",
                "enhebramiento de eventos",
                "enhebrado de eventos",
                "Event Hushing",
                "Event Hushing",
                "enhebrado de eventos",
                "enhebrado de eventos",
                "enhebrado de eventos",
                "enhebrado de eventos",
                "enhebrado de eventos",
                "enhebrar el evento",
                "enhebrado de eventos",
                "Event Hushing",
                "Enhebrado de eventos",
                "enhebrado de eventos"
            ],
            "error": []
        },
        "automatic technique": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for <br>automatic technique</br>s to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for <br>automatic technique</br>s to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Enhebrado de eventos dentro de los temas de noticias Ramesh Nallapati, Ao Feng, Fuchun Peng, Centro James Allan para la recuperación de información inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 Nmramesh, Aofeng, Fuchun, Allan @Cs.UMass.Edu Resumen con el volumen abrumadorDe las noticias en línea disponibles hoy, existe una creciente necesidad de \"técnicas automáticas\" para analizar y presentar noticias al usuario de manera significativa y eficiente.",
                "Por lo tanto, existe una creciente necesidad de \"técnicas automáticas\" para organizar las noticias de una manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente."
            ],
            "translated_text": "",
            "candidates": [
                "técnica automática",
                "técnicas automáticas",
                "técnica automática",
                "técnicas automáticas"
            ],
            "error": []
        },
        "flat hierarchy": {
            "translated_key": "jerarquía plana",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a <br>flat hierarchy</br>.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Investigaciones anteriores se centraron solo en organizar noticias de sus temas en una \"jerarquía plana\"."
            ],
            "translated_text": "",
            "candidates": [
                "jerarquía plana",
                "jerarquía plana"
            ],
            "error": []
        },
        "dependency": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based <br>dependency</br> structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the <br>dependency</br> to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional <br>dependency</br>: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal <br>dependency</br> we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal <br>dependency</br>.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a <br>dependency</br> from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their <br>dependency</br> structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ <br>dependency</br> pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a <br>dependency</br> from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) <br>dependency</br> pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 <br>dependency</br> Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ <br>dependency</br> Precision(DP): It is the probability that there is a <br>dependency</br> between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of <br>dependency</br> is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ <br>dependency</br> Recall(DR): It is the probability that there is a <br>dependency</br> between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of <br>dependency</br> is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and <br>dependency</br> F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 <br>dependency</br> modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of <br>dependency</br> is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the <br>dependency</br> edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a <br>dependency</br> between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed <br>dependency</br> edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the <br>dependency</br> algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and <br>dependency</br> algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our <br>dependency</br> structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of <br>dependency</br> Precision (DP), <br>dependency</br> Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and <br>dependency</br> algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the <br>dependency</br> algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the <br>dependency</br> threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low <br>dependency</br> performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the <br>dependency</br> algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and <br>dependency</br> performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Aunque este documento se centra en los eventos de enhebrado dentro de un tema de noticias existente, esperamos que dicha estructura de \"dependencia\" basada en eventos refleje con mayor precisión la estructura de las noticias que los temas estrictamente limitados.",
                "Nuestro trabajo difiere del suyo en el sentido de que no limitamos que la \"dependencia\" sea lineal.",
                "Es importante explicar lo que queremos decir con esta \"dependencia\" direccional: mientras que la existencia de un borde en sí representa la relación de dos eventos, la dirección podría implicar la causalidad o el orden temporal.",
                "Por \"dependencia\" causal queremos decir que la aparición del evento B está relacionada y es una consecuencia de la ocurrencia del evento A.",
                "Por lo tanto, una flecha de A a B se encuentra en la categoría de \"dependencia\" causal.",
                "Sin embargo, el anotador recibió instrucciones de asignar una \"dependencia\" del evento A al evento B si y solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A tiempo.",
                "Comparar un modelo de evento de sistema Å¼ con el verdadero modelo Å requiere comparar todos los modelos de eventos, incluida su estructura de \"dependencia\".",
                "Formalmente, ´åµ ´ × × µ × ×.El conjunto de todos los pares ordenados de historias ´ × × µ de tal manera que hay una \"dependencia\" desde el evento de × hasta el evento de × en el modelo Å.´åµ ´ × × µ ´ ´ × µ ´ × µ ¾ (6) Tenga en cuenta que el par de la historia se ordena aquí, por lo que ´ × × µ no es equivalente a ´ × × µ.",
                "En nuestra evaluación, un par correcto con pares de clúster 448 (b-> d) incorrecto (a, c) \"dependencia\" (a-> b) (c-> b) (b-> d) d, e d, e(D, e) (d, e) (a-> c) (a-> e) (b-> c) (b-> e) (b-> e) precisión del clúster: 1/2 recuerdo del clúster: 1/2 RECUERDO DE \"DEMPERENCIA\": 2/6 Precisión de dependencia: 2/4 (A-> D) True Modelo de eventos Sistema de eventos Modelo de evento A, B C A, C B Pares de clúster (A, B) Pares de dependencia Figura 2: La dirección de las medidas de evaluación seráconsiderado un error.",
                "Ê è´ ¼´ × µ ¼´ × × ´ × µ ´ × µ ´åµ ´å¼a ´åµ (8) ¯ \"dependencia\" Precisión (DP): es la probabilidad de que haya una \"dependencia\" entre los eventos de los eventos deDos historias seleccionadas al azar × y × en el verdadero modelo Å dado que tienen una dependencia en el modelo del modelo Å¼."
            ],
            "translated_text": "",
            "candidates": [
                "dependencia",
                "dependencia",
                "dependencia",
                "dependencia",
                "dependencia",
                "dependencia",
                "Dependencia",
                "dependencia",
                "dependencia",
                "dependencia",
                "dependencia",
                "dependencia",
                "dependencia",
                "dependencia",
                "dependencia",
                "dependencia",
                "dependencia",
                "dependencia",
                "DEMPERENCIA",
                "dependencia",
                "dependencia",
                "dependencia"
            ],
            "error": []
        },
        "novel feature": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account <br>novel feature</br>s such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta \"características novedosas\", como la localidad temporal de historias para el reconocimiento de eventos y el pedido de tiempo para capturar dependencias."
            ],
            "translated_text": "",
            "candidates": [
                "característica novedosa",
                "características novedosas"
            ],
            "error": []
        },
        "temporal locality": {
            "translated_key": "localidad temporal",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as <br>temporal locality</br> of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow <br>temporal locality</br>, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas, como \"localidad temporal\" de historias para el reconocimiento de eventos y el pedido de tiempo para capturar dependencias.",
                "Las historias en el mismo evento tienden a seguir la \"localidad temporal\", por lo que la marca de tiempo de cada historia puede ser una característica útil."
            ],
            "translated_text": "",
            "candidates": [
                "localidad temporal",
                "localidad temporal",
                "localidad temporal",
                "localidad temporal"
            ],
            "error": []
        },
        "event recognition": {
            "translated_key": "reconocimiento de eventos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for <br>event recognition</br> and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas, como la localidad temporal de historias para \"reconocimiento de eventos\" y ordenar el tiempo para capturar dependencias."
            ],
            "translated_text": "",
            "candidates": [
                "reconocimiento de eventos",
                "reconocimiento de eventos"
            ],
            "error": []
        },
        "time-ordering": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and <br>time-ordering</br> for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as <br>time-ordering</br> of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 <br>time-ordering</br> function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-<br>time-ordering</br> function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the <br>time-ordering</br> of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the <br>time-ordering</br> of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-<br>time-ordering</br> function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas, como la localidad temporal de historias para el reconocimiento de eventos y el \"pedido de tiempo\" para capturar dependencias.",
                "Creemos que un modelo robusto debería incorporar dicho conocimiento del dominio en la captura de dependencias, pero en este trabajo, como primer paso, confiaremos en las características de la superficie como el \"pedido de tiempo\" de las noticias y las distribuciones de palabras para modelarlas.",
                "Primero definimos una función de 1-1 \"pedido de tiempo\" Ø ë ½ ¡¡¡¡¡¡'s que clasifica historias en orden ascendente por su tiempo de publicación.",
                "Ahora, la función del evento: \"pedido de tiempo\" Ø se define de la siguiente manera.",
                "Ø ½ ¡¡¡¡Ñ × Ø ù ú ¾ Ø ´ ùµ Ø ´ Úµ ´µ ñ × × ù¾ Ø × × ùµ × × × Ú¾ ú Ø´ × × ÚN (17) En otras palabras, Ø TimeDers Based Based Based Based Based Baseders Baseders basadosen el \"pedido de tiempo\" de sus respectivas primeras historias.",
                "La dirección de dependencia está determinada por el \"pedido de tiempo\" de las primeras historias en los eventos respectivos.",
                "Formalmente, los bordes del sistema se definen de la siguiente manera.¼ ´ ù ú µ Ø ´ ùµ Ø ´ Ú µ (19) donde Ø es la función de \"ordenamiento de tiempo\" de evento."
            ],
            "translated_text": "",
            "candidates": [
                "pedido de tiempo",
                "pedido de tiempo",
                "pedido de tiempo",
                "pedido de tiempo",
                "pedido de tiempo",
                "pedido de tiempo",
                "pedido de tiempo",
                "pedido de tiempo",
                "pedido de tiempo",
                "pedido de tiempo",
                "pedido de tiempo",
                "pedido de tiempo",
                "pedido de tiempo",
                "ordenamiento de tiempo"
            ],
            "error": []
        },
        "news organization": {
            "translated_key": "organización de noticias",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of <br>news organization</br>.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Este problema es abordado por un programa de investigación llamado Topic Detection and Tracking (TDT) [3] que ejecuta una competencia anual abierta en tareas estandarizadas de \"organización de noticias\"."
            ],
            "translated_text": "",
            "candidates": [
                "organización de noticias",
                "organización de noticias"
            ],
            "error": []
        },
        "topic detection": {
            "translated_key": "detección de temas",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called <br>topic detection</br> and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of <br>topic detection</br> has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "<br>topic detection</br> and tracking (TDT) :<br>topic detection</br> detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to <br>topic detection</br> and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of <br>topic detection</br> and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "<br>topic detection</br> and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "<br>topic detection</br> and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Este problema es abordado por un programa de investigación llamado \"Detección de temas\" y seguimiento (TDT) [3] que ejecuta una competencia anual abierta en tareas estandarizadas de organización de noticias.",
                "Sin embargo, en TDT-2003, se ha propuesto una estructura jerárquica de \"detección de temas\" y [2] realizó intentos útiles para adoptar la nueva estructura.",
                "\"Detección de temas\" y seguimiento (TDT): \"Detección de temas\" detecta grupos de historias que discuten el mismo tema;El seguimiento del tema detecta historias que discuten un tema previamente conocido [3].",
                "El hilo de eventos está fuertemente relacionado con la \"detección de temas\" y el seguimiento, pero también es diferente de él significativamente.",
                "Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la \"detección de temas\" y el seguimiento y es más desafiante debido a al menos las siguientes dificultades.1.",
                "\"Detección de temas\" y estudio piloto de seguimiento: informe final.",
                "\"Detección de temas\" y seguimiento: organización de información basada en eventos."
            ],
            "translated_text": "",
            "candidates": [
                "detección de temas",
                "Detección de temas",
                "detección de temas",
                "detección de temas",
                "detección de temas",
                "Detección de temas",
                "Detección de temas",
                "detección de temas",
                "detección de temas",
                "Detección de temas",
                "detección de temas",
                "detección de temas",
                "Detección de temas",
                "detección de temas",
                "Detección de temas"
            ],
            "error": []
        },
        "clusters of topics": {
            "translated_key": "grupos de temas",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into <br>clusters of topics</br>.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Por ejemplo, la tarea de detección de TDT es organizar una colección de noticias en \"grupos de temas\"."
            ],
            "translated_text": "",
            "candidates": [
                "grupos de temas",
                "grupos de temas"
            ],
            "error": []
        },
        "topic cluster": {
            "translated_key": "clúster de temas",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "inter-related event": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of <br>inter-related event</br>s.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Sin embargo, un tema en las noticias es más que una mera colección de historias: se caracteriza por una estructura definitiva de \"eventos interrelacionados\"."
            ],
            "translated_text": "",
            "candidates": [
                "evento interrelacionado",
                "eventos interrelacionados"
            ],
            "error": []
        },
        "seminal event": {
            "translated_key": "evento seminal",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the <br>seminal event</br> that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a <br>seminal event</br>.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Por ejemplo, cuando una bomba explota en un edificio, ese es el \"evento seminal\" que desencadena el tema.",
                "Tema: Un conjunto de noticias fuertemente conectadas por un \"evento seminal\"."
            ],
            "translated_text": "",
            "candidates": [
                "evento seminal",
                "evento seminal",
                "evento seminal",
                "evento seminal"
            ],
            "error": []
        },
        "event model": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the <br>event model</br> of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An <br>event model</br> of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an <br>event model</br> Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An <br>event model</br> of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some <br>event model</br> Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system <br>event model</br> Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True <br>event model</br> System <br>event model</br> A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true <br>event model</br> Å and the system <br>event model</br> Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete <br>event model</br>.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire <br>event model</br>.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Nos referimos a la estructura de eventos interconectada resultante como el \"modelo de eventos\" del tema.",
                "Un \"modelo de evento\" de este tema se puede representar como en la Figura 1.",
                "Definimos un \"modelo de evento\" Å ´ µ para ser una tupla del conjunto de eventos y un conjunto de dependencias.",
                "Juicio y (5) (3) (4) CIA anuncia recompensa Reacciones del mundo musulmán de las amenazas de militantes islámicos de (2) (1) Osama acusación de la CIA reunida por evidencia Figura 1: Un \"modelo de evento\" del tema TDT Osama bin Ladens acusación.",
                "Evaluación Un sistema puede generar algunos \"modelo de evento\" Å¼ ´ ¼ ¼ µ usando ciertos algoritmos, que generalmente es diferente del modelo de verdad Å ´ µ (suponemos que el anotador no cometió ningún error).",
                "Comparar un \"modelo de evento\" del sistema Å¼ con el verdadero modelo Å requiere comparar todos los modelos de eventos, incluida su estructura de dependencia.",
                "En nuestra evaluación, un par correcto con pares de dependencia de clúster 448 (b-> d) incorrecto (a, c) (a-> b) (c-> b) (b-> d) d, e d, e (d, E) (d, e) (a-> c) (a-> e) (b-> c) (b-> e) (b-> e) precisión del clúster: 1/2 recuerdo del clúster: 1/2Recuerdo de dependencia: 2/6 Precisión de dependencia: 2/4 (a-> d) Verdadero \"Modelo de evento\" Sistema \"Modelo de eventos\" A, B C A, C B Pares de clúster (A, B) Pares de dependencia Figura 2: La dirección de las medidas de evaluación seráconsiderado un error.",
                "Dados estos dos conjuntos de pares de historias correspondientes al verdadero \"Modelo de eventos\" Å y el sistema \"Modelo de eventos\" Å¼, definimos el recuerdo y la precisión para cada categoría de la siguiente manera.¯ Precisión de clúster (CP): es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema.",
                "Finalmente, experimentamos con combinaciones de algoritmos de agrupación y dependencia para producir el \"modelo de evento\" completo.",
                "Modelo DP DR DF P-Valor Patrio más cercano 0.61 0.60 0.60 Best Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Thresh simple.0.57 0.75 0.64 0.24 línea de base (enlace completo) 0.50 0.94 0.63table 5: Resultados en el conjunto de pruebas 7.3 Combinando la agrupación y dependencias Ahora que hemos estudiado los algoritmos de agrupación y dependencia de forma aislada, combinamos los algoritmos de mejor rendimiento y construimos todo el \"\"modelo de evento \"."
            ],
            "translated_text": "",
            "candidates": [
                "modelo de evento",
                "modelo de eventos",
                "Modelo de eventos",
                "modelo de evento",
                "modelo de evento",
                "modelo de evento",
                "modelo de evento",
                "modelo de evento",
                "modelo de evento",
                "modelo de evento",
                "modelo de evento",
                "modelo de evento",
                "modelo de evento",
                "Modelo de evento",
                "Modelo de eventos",
                "modelo de evento",
                "Modelo de eventos",
                "Modelo de eventos",
                "modelo de evento",
                "modelo de evento",
                "modelo de evento",
                "modelo de evento "
            ],
            "error": []
        },
        "quick overview": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a <br>quick overview</br> of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados lo ayuda a obtener una \"descripción general\" del tema y también le permite navegar a través del tema más rápido."
            ],
            "translated_text": "",
            "candidates": [
                "vista rápida",
                "descripción general"
            ],
            "error": []
        },
        "hidden markov model": {
            "translated_key": "modelo oculto de Markov",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "flatcluster": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as <br>flatcluster</br>s [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "En TDT, los investigadores han considerado tradicionalmente los temas como \"FlatCluster\" S [1]."
            ],
            "translated_text": "",
            "candidates": [
                "platero",
                "FlatCluster"
            ],
            "error": []
        },
        "atomicity": {
            "translated_key": "Atomicidad",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of <br>atomicity</br> of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Después de la suposición de \"atomicidad\" de una historia, esto significa que cualquier conjunto de eventos distintos puede estar representado por un conjunto de grupos de noticias no superpuestas.3."
            ],
            "translated_text": "",
            "candidates": [
                "Atomicidad",
                "atomicidad"
            ],
            "error": []
        },
        "microscopic event": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on <br>microscopic event</br>s rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Por lo tanto, la principal diferencia entre el enhebrado de eventos y el TDT es que centramos nuestro esfuerzo de modelado en \"Eventos microscópicos\" en lugar de temas más grandes."
            ],
            "translated_text": "",
            "candidates": [
                "evento microscópico",
                "Eventos microscópicos"
            ],
            "error": []
        },
        "mapping function": {
            "translated_key": "función de mapeo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a <br>mapping function</br> from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event <br>mapping function</br> corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the <br>mapping function</br> ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true <br>mapping function</br> and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "De hecho, esto nos permite definir una \"función de mapeo\" de historias a eventos de la siguiente manera: ´ × µ iff × ¾ (4) Además, también definimos un conjunto de bordes dirigidos ´ µ que denotan dependencias entre eventos.",
                "È è´ ´ × µ ´ × µ ¼´ × µ ¼´ × µuce ´åµ ´å¼a ´å¼a (7) donde ¼ es la \"función de mapeo\" de la historia que corresponde al modelo Å¼.¯ Recuerdo del clúster (CR): es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo verdadero evento.",
                "Primero modelamos solo la parte de agrupación de eventos (definiendo la \"función de mapeo\" ¼) utilizando algoritmos de agrupación descritos en la Sección 6.1.",
                "Utilizamos la verdadera \"función de mapeo\" y por implicación los verdaderos eventos î."
            ],
            "translated_text": "",
            "candidates": [
                "función de mapeo",
                "función de mapeo",
                "función de mapeo",
                "función de mapeo",
                "función de mapeo",
                "función de mapeo",
                "función de mapeo",
                "función de mapeo"
            ],
            "error": []
        },
        "directed edge": {
            "translated_key": "borde dirigido",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of <br>directed edge</br>s ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only un<br>directed edge</br>s.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´ × µ IFF × ¾ (4) Además, también definimos un conjunto de \"borde dirigido\" S ´ µ que denota dependencias entre los eventos.",
                "Una elección más simple (y por lo tanto menos controvertida) sería ignorar la dirección en las dependencias por completo y considerar solo la ONU \"borde dirigido\" s."
            ],
            "translated_text": "",
            "candidates": [
                "borde dirigido",
                "borde dirigido",
                "borde dirigido",
                "borde dirigido"
            ],
            "error": []
        },
        "time ordering": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call <br>time ordering</br>.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Una flecha en este escenario captura lo que llamamos \"pedidos de tiempo\"."
            ],
            "translated_text": "",
            "candidates": [
                "pedido de tiempo",
                "pedidos de tiempo"
            ],
            "error": []
        },
        "agglomerative clustering": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an <br>agglomerative clustering</br> algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 <br>agglomerative clustering</br> with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of <br>agglomerative clustering</br> algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of <br>agglomerative clustering</br> algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the <br>agglomerative clustering</br> algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "En esta subsección, presentamos un algoritmo de \"agrupación aglomerativa\" que combina todas estas características.",
                "Sin embargo, en nuestros experimentos, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo.6.1.1 \"Agrupación aglomerativa\" con Time Decay (ACDT) Inicializamos nuestros eventos a Singleton Events (Clusters), es decir, cada clúster contiene exactamente una historia.",
                "Usamos clusmodel aglomerativo mejor t cp cr cf p-valor p cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+LOC+AVG-LNK 0.07 0.37 0.74 0.45cos+PER+AVG-LNK 0.07 0.390.70 0.46cos+TD+AVG-LNK 0.04 0.45 0.70 0.53 2.9E-4* COS+N (T)+AVG-LNK-0.41 0.62 0.48 7.5E-2 Cos+N (T)+T+AVG-LNK 0.03 0.42 0.420.62 0.49 2.4e-2* cos+td+n (t)+avg-lnk-0.44 0.66 0.52 7.0e-3* cos+td+n (t)+t+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Línea de base (COS+AVG-LNK) 0.05 0.39 0.67 0.46Table 2: Comparación de algoritmos de \"agrupación aglomerativa\" (conjunto de entrenamiento) basados en solo similitud de coseno como nuestra línea de base de agrupación.",
                "Modelo CP CR CF P-VALUE Value cos+1-LNK 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+loc+avg-lnk 0.37 0.73 0.45cos+per+avg-lnk 0.44 0.62 0.45cos+td+avg-lnk0.48 0.70 0.54 0.014* cos+n (t)+avg-lnk 0.41 0.71 0.51 0.31 cos+n (t)+t+avg-lnk 0.43 0.69* 0.52 0.14 cos+td+n (t)+avg-lnk 0.43 0.760.54 0.025* cos+td+n (t)+t+avg-lnk 0.47 0.69 0.54 0.0095* línea de base (cos+avg-lnk) 0.44 0.67 0.50table 3: comparación de \"agrupamiento aglomerativo\" algorithms (testet) p-valueMarcado con una £ significa que es una mejora estadísticamente significativa sobre la línea de base (nivel de confianza del 95%, una prueba t de cola).",
                "Todos los algoritmos a partir de este usan el enlace promedio (Ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora del rendimiento.¯ cos+per+avg-lnk: ¿¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud.¯ COS+TD+AVG-LNK: Coeficiente de descomposición de tiempo «½ en la ecuación 13, lo que significa que la similitud entre dos historias se detendrá a ½ si están en diferentes extremos del tema.¯ COS+N (T)+AVG-LNK: Use el número de eventos verdaderos para controlar el algoritmo de \"agrupación aglomerativa\"."
            ],
            "translated_text": "",
            "candidates": [
                "agrupación aglomerativa",
                "agrupación aglomerativa",
                "agrupación aglomerativa",
                "Agrupación aglomerativa",
                "agrupación aglomerativa",
                "agrupación aglomerativa",
                "agrupación aglomerativa",
                "agrupamiento aglomerativo",
                "agrupación aglomerativa",
                "agrupación aglomerativa"
            ],
            "error": []
        },
        "cosine similarity": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the <br>cosine similarity</br> of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average <br>cosine similarity</br> between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average <br>cosine similarity</br> between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only <br>cosine similarity</br> as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, <br>cosine similarity</br>, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides <br>cosine similarity</br> on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on <br>cosine similarity</br>.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Ó × ´ × ½ × ¾µ es la \"similitud cosena\" del término vectores.",
                "También usaremos \"similitud coseno\" promedio entre dos eventos como una característica y se define de la siguiente manera.",
                "Aunque usamos los mismos nombres, será claro en el contexto a cuál nos referimos.6.2.2 umbral simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos y solo si la \"similitud coseno\" promedio entre el evento y el evento ú es mayor que un umbralI.",
                "Usamos clusmodel aglomerativo mejor t cp cr cf p-valor p cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+LOC+AVG-LNK 0.07 0.37 0.74 0.45cos+PER+AVG-LNK 0.07 0.390.70 0.46cos+TD+AVG-LNK 0.04 0.45 0.70 0.53 2.9E-4* COS+N (T)+AVG-LNK-0.41 0.62 0.48 7.5E-2 Cos+N (T)+T+AVG-LNK 0.03 0.42 0.420.62 0.49 2.4e-2* cos+td+n (t)+avg-lnk-0.44 0.66 0.52 7.0e-3* cos+td+n (t)+t+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Línea de base (COS+AVG-LNK) 0.05 0.39 0.67 0.46Table 2: Comparación de algoritmos de agrupación aglomerativa (conjunto de entrenamiento) basado en solo \"similitud coseno\" como nuestra línea de base de agrupación.",
                "Los métodos que se muestran en la Tabla 2 y 3 son: ¯ Basora: peso del vector TF-IDF, \"similitud de coseno\", enlace promedio en la agrupación.",
                "En general, la descomposición del tiempo resultó a la característica más poderosa además de la \"similitud de coseno\" tanto en los conjuntos de entrenamiento como en los conjuntos de pruebas.7.2 Dependencias En esta subsección, nuestro objetivo es modelar solo dependencias.",
                "Desarrollamos un enfoque de agrupación basado en Timedecay que aprovecha la temporalocalización de las noticias en el mismo evento y demostramos que funciona significativamente mejor que el enfoque de referencia basado en \"similitud de coseno\"."
            ],
            "translated_text": "",
            "candidates": [
                "similitud de coseno",
                "similitud cosena",
                "similitud de coseno",
                "similitud coseno",
                "similitud de coseno",
                "similitud coseno",
                "similitud de coseno",
                "similitud coseno",
                "similitud de coseno",
                "similitud de coseno",
                "similitud de coseno",
                "similitud de coseno",
                "similitud de coseno",
                "similitud de coseno"
            ],
            "error": []
        },
        "term vector": {
            "translated_key": "Vector de término",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the <br>term vector</br>s.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Ó × ´ × ½ × ¾µ es la similitud cosena del \"Vector de término\" s."
            ],
            "translated_text": "",
            "candidates": [
                "Vector de término",
                "Vector de término"
            ],
            "error": []
        },
        "simple thresholding": {
            "translated_key": "umbral simple",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 <br>simple thresholding</br> This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+<br>simple thresholding</br> 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Aunque usamos los mismos nombres, será claro en el contexto a cuál nos referimos.6.2.2 \"umbral simple\" Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos ù y Ú solo si la similitud de coseno promedio entre el evento y el evento Ú es mayor que un umbralI.",
                "T CP CR CF DP DR DF JF P-VALUE POS+TD+PARADA más cercana 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Simility 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.000.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+umbral simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Base (cos+de enlace completo) 0.10-0.58 0.31 0.38 0.20 0.67 0.3033TableEstablecer modelo CP CR CF DP DR DF JF P-Value POS+TD+Padre más cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Mejor similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.330 0.28 0.37cos+td+\"umbral simple\" 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* línea de base (cos+de enlace completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39table 7: Resultados combinados en el conjunto de pruebas para recuperación de información inteligente y en parte por SpawarsyScensd con subvenciónNúmero N66001-02-1-8903."
            ],
            "translated_text": "",
            "candidates": [
                "umbral simple",
                "umbral simple",
                "umbral simple",
                "umbral simple"
            ],
            "error": []
        },
        "maximum spanning tree": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 <br>maximum spanning tree</br> model In this model, we first build a <br>maximum spanning tree</br> (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Matemáticamente, esto se puede expresar como: ¼ ´ ù ú µ ú ë ñ´ ù ú ì ù ö ü ü û Ø ´ ûµ Ø ´ ú µ ú ë ñ´ û Ú µ (22) 6.2.5 \"Modelo\" Modelo \"Modelo\"En este modelo, primero construimos un \"árbol de expansión máximo\" (MST) utilizando un algoritmo codicioso en el siguiente gráfico pesado y no dirigido totalmente conectados cuyos vértices son los eventos y cuyos bordes se definen como los siguientes: ´ ù ú µ µ µ ù Úµ ú ë ñ´ ù ú µ (23) Sea Åëì´ µ el conjunto de bordes en el árbol de expansión máxima de ¼."
            ],
            "translated_text": "",
            "candidates": [
                "Árbol de expansión máxima",
                "Modelo",
                "Modelo",
                "árbol de expansión máximo"
            ],
            "error": []
        },
        "correct granularity": {
            "translated_key": "granularidad correcta",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get <br>correct granularity</br>.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía el algoritmo de agrupación para obtener \"granularidad correcta\"."
            ],
            "translated_text": "",
            "candidates": [
                "granularidad correcta",
                "granularidad correcta"
            ],
            "error": []
        },
        "dependency precision": {
            "translated_key": "precisión de dependencia",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 <br>dependency precision</br>: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ <br>dependency precision</br>(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of <br>dependency precision</br> (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "En nuestra evaluación, un par correcto con pares de dependencia de clúster 448 (b-> d) incorrecto (a, c) (a-> b) (c-> b) (b-> d) d, e d, e (d, E) (d, e) (a-> c) (a-> e) (b-> c) (b-> e) (b-> e) precisión del clúster: 1/2 recuerdo del clúster: 1/2Recuerdo de dependencia: 2/6 \"Precisión de dependencia\": 2/4 (a-> d) True Event Model System Event Model A, B C A, C B Pares de clúster (A, B) Pares de dependencia Figura 2: La dirección de las medidas de evaluación se considerará Aerror.",
                "Ê è´ ¼´ × µ ¼´ × × ´ × µ ´ × µ ´åµ ´å¼µ ´åµ (8) ¯ \"Precisión de dependencia\" (DP): es la probabilidad de que haya una dependencia entre los eventos de dos aleatorios de dos aleatoriosHistorias seleccionadas × y × en el verdadero modelo Å dado que tienen una dependencia en el modelo del modelo Å¼.",
                "Evaluamos nuestro rendimiento 451 utilizando los valores promedio de \"precisión de dependencia\" (DP), recuperación de dependencia (DR) y dependencia F-Medición (DF)."
            ],
            "translated_text": "",
            "candidates": [
                "precisión de dependencia",
                "Precisión de dependencia",
                "precisión de dependencia",
                "Precisión de dependencia",
                "precisión de dependencia",
                "precisión de dependencia"
            ],
            "error": []
        },
        "dependency recall": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 <br>dependency recall</br>: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ <br>dependency recall</br>(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), <br>dependency recall</br> (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "En nuestra evaluación, un par correcto con pares de dependencia de clúster 448 (b-> d) incorrecto (a, c) (a-> b) (c-> b) (b-> d) d, e d, e (d, E) (d, e) (a-> c) (a-> e) (b-> c) (b-> e) (b-> e) precisión del clúster: 1/2 recuerdo del clúster: 1/2\"Recuerdo de dependencia\": 2/6 Precisión de dependencia: 2/4 (a-> d) True Modelo de evento Sistema de eventos Modelo de evento A, B C A, C B Pares de clúster (A, B) Pares de dependencia Figura 2: La dirección de las medidas de evaluación se considerará Aerror.",
                "È è´´ ´ × µ ´ × µo ¾ ´ ¼´ × µ ¼´ × µo ¾ ¼ ´åµ ´å¼µ ´å¼a (9) ¯ \"Recuerdo de dependencia\" (DR): es la probabilidad de que hay una dependencia entreLos eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el verdadero modelo Å.",
                "Evaluamos nuestro rendimiento 451 utilizando los valores promedio de precisión de dependencia (DP), \"recuperación de dependencia\" (DR) y dependencia de la medida F (DF)."
            ],
            "translated_text": "",
            "candidates": [
                "recuerdo de dependencia",
                "Recuerdo de dependencia",
                "recuerdo de dependencia",
                "Recuerdo de dependencia",
                "recuerdo de dependencia",
                "recuperación de dependencia"
            ],
            "error": []
        },
        "dependency f-measure": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and <br>dependency f-measure</br> (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Evaluamos nuestro rendimiento 451 utilizando los valores promedio de precisión de dependencia (DP), recuerdo de dependencia (DR) y \"Medición F de dependencia\" (DF)."
            ],
            "translated_text": "",
            "candidates": [
                "Dependencia F-Medición",
                "Medición F de dependencia"
            ],
            "error": []
        },
        "temporallocalization": {
            "translated_key": "temporalocalización",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of <br>temporallocalization</br> of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Desarrollamos un enfoque de agrupación basado en Timedecay que aprovecha la \"temporalocalización\" de las noticias en el mismo evento y demostramos que funciona significativamente mejor que el enfoque de referencia basado en la similitud de coseno."
            ],
            "translated_text": "",
            "candidates": [
                "temporalocalización",
                "temporalocalización"
            ],
            "error": []
        },
        "timedecay": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a <br>timedecay</br> based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Desarrollamos un enfoque de agrupación basado en \"Timedecay\" que aprovecha la temporalocalización de las noticias en el mismo evento y demostramos que funciona significativamente mejor que el enfoque de referencia basado en la similitud coseno."
            ],
            "translated_text": "",
            "candidates": [
                "tiempo en decaida",
                "Timedecay"
            ],
            "error": []
        },
        "event": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "<br>event</br> Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our <br>event</br> models.",
                "We call the process of recognizing events and their dependencies <br>event</br> threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for <br>event</br> recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld <br>event</br> where an <br>event</br> is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal <br>event</br> that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the <br>event</br> of rescue attempts is influenced by the <br>event</br> of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them <br>event</br> threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the <br>event</br> model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such <br>event</br> based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling <br>event</br> structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying <br>event</br> relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of <br>event</br> and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single <br>event</br>.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic <br>event</br> story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "<br>event</br>: An <br>event</br> is something that happens at some specific time and place [10].",
                "In our work, we represent an <br>event</br> by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal <br>event</br>.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an <br>event</br> and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "<br>event</br> threading: <br>event</br> threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between <br>event</br> threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally <br>event</br> threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each <br>event</br> is an element in the power set of S, the second constraint ensures that each story can belong to at most one <br>event</br>.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of <br>event</br> B is related to and is a consequence of the occurrence of <br>event</br> A.",
                "By temporal ordering, we mean that <br>event</br> B happened after <br>event</br> A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (<br>event</br> A) and subsequent investigations (<br>event</br> B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(<br>event</br> A) and Pope meets Castro(<br>event</br> B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but <br>event</br> B is not necessarily a consequence of the occurrence of <br>event</br> A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of <br>event</br> threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An <br>event</br> model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an <br>event</br> in the topic of Osamas indictment.",
                "The occurrence of <br>event</br> 2, namely Trial and Indictment of Osama is dependent on the <br>event</br> of evidence gathered by CIA, i.e., event 1.",
                "Similarly, <br>event</br> 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an <br>event</br> A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an <br>event</br> model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An <br>event</br> model of TDT topic Osama bin Ladens indictment.",
                "<br>event</br> threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, <br>event</br> threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the <br>event</br> membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an <br>event</br>, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single <br>event</br> C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique <br>event</br>.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an <br>event</br> especially when the number of stories in that <br>event</br> is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each <br>event</br> could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from <br>event</br> A to <br>event</br> B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/<br>event</br> 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/<br>event</br> 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some <br>event</br> model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system <br>event</br> model Å¼ with the true model Å requires comparing the entire <br>event</br> models including their dependency structure.",
                "And different <br>event</br> granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their <br>event</br>-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same <br>event</br> given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the <br>event</br> of × to the <br>event</br> of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True <br>event</br> model System <br>event</br> model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true <br>event</br> model Å and the system <br>event</br> model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-<br>event</br> mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-<br>event</br> given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of <br>event</br> modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same <br>event</br> tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same <br>event</br> tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar <br>event</br> pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the <br>event</br>-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the <br>event</br>-time-ordering function.",
                "In other words, the dependency edge is directed from <br>event</br> Ù to <br>event</br> Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between <br>event</br> Ù and <br>event</br> Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each <br>event</br> can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each <br>event</br> Ú , the nearest parent model considers only the <br>event</br> preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each <br>event</br> can have at most one parent.",
                "An <br>event</br> Ú is assigned a parent Ù if and only if Ù is the most similar earlier <br>event</br> to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the <br>event</br> clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete <br>event</br> model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the <br>event</br> they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same <br>event</br> tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each <br>event</br>, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire <br>event</br> model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same <br>event</br> and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex <br>event</br> structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:<br>event</br> based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on <br>event</br> evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "\"Evento\" enhebrado dentro de los temas de noticias Ramesh Nallapati, Ao Feng, Fuchun Peng, Centro James Allan para la recuperación de información inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 Nmramesh, Aofeng, Fuchun, Allan @Cs.UMass.Edu Resumen con elVolumen abrumador de noticias en línea disponibles hoy, existe una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente.",
                "En este trabajo, intentamos capturar la rica estructura de los eventos y sus dependencias en un tema de noticias a través de nuestros modelos de \"evento\".",
                "Llamamos al proceso de reconocimiento de eventos y sus dependencias \"eventos\".",
                "Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas, como la localidad temporal de historias para el reconocimiento de \"evento\" y el pedido de tiempo para capturar dependencias.",
                "De hecho, esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún \"evento\" seminal de Realworld donde un \"evento\" se define como algo que ocurre en un momento y ubicación específicos [3].",
                "Por ejemplo, cuando una bomba explota en un edificio, ese es el \"evento\" seminal que desencadena el tema.",
                "En el ejemplo anterior, el \"evento\" de los intentos de rescate está influenciado por el \"evento\" del bombardeo y también lo es el evento de búsqueda de perpetradores.",
                "Llamamos al proceso de reconocer eventos e identificar las dependencias entre ellos \"eventos\", una analogía con el subproceso de correo electrónico que muestra conexiones entre mensajes de correo electrónico relacionados.",
                "Nos referimos a la estructura de eventos interconectada resultante como el modelo de \"evento\" del tema.",
                "Aunque este documento se centra en los eventos de enhebrado dentro de un tema de noticias existente, esperamos que dicha estructura de dependencia basada en el \"evento\" refleje con mayor precisión la estructura de las noticias que los temas estrictamente limitados."
            ],
            "translated_text": "",
            "candidates": [
                "evento",
                "Evento",
                "evento",
                "evento",
                "evento",
                "eventos",
                "evento",
                "evento",
                "evento",
                "evento",
                "evento",
                "evento",
                "evento",
                "evento",
                "evento",
                "evento",
                "evento",
                "eventos",
                "evento",
                "evento",
                "evento",
                "evento"
            ],
            "error": []
        },
        "thread": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event <br>thread</br>ing.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event <br>thread</br>ing, an analogy to email <br>thread</br>ing that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on <br>thread</br>ing events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate <br>thread</br>ing of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of <br>thread</br>ing events together is related to <br>thread</br>ing of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email <br>thread</br>ing captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event <br>thread</br>ing: Event <br>thread</br>ing detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event <br>thread</br>ing and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event <br>thread</br>ing models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event <br>thread</br>ing more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event <br>thread</br>ing is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event <br>thread</br>ing can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ Cluster pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) Cluster pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Cluster precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ Cluster Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ Cluster Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the cluster and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each cluster contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the Cluster F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the cluster quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model Cluster T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Llamamos al proceso de reconocimiento de eventos y su evento de dependencias \"hilo\".",
                "Llamamos al proceso de reconocimiento de eventos e identificación de dependencias entre ellos \"hilo\", una analogía al correo electrónico \"hilo\" que muestra conexiones entre los mensajes de correo electrónico relacionados.",
                "Aunque este documento se centra en los eventos de \"hilo\" dentro de un tema de noticias existente, esperamos que dicha estructura de dependencia basada en eventos refleje con mayor precisión la estructura de las noticias que los temas estrictamente limitados.",
                "En la Sección 3, definimos el problema y usamos un ejemplo para ilustrar el \"hilo\" de los eventos dentro de un tema de noticias.",
                "Trabajo relacionado El proceso de eventos de \"subproceso\" juntos está relacionado con el \"hilo\" de correo electrónico solo por nombre en su mayor parte.",
                "El correo electrónico \"hilo\" captura dependencias de referencia entre mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión.",
                "Evento \"Hilo\" ING: Evento \"Thread\" Ing detecta eventos dentro de un tema, y también captura las dependencias entre los eventos.",
                "Por lo tanto, la principal diferencia entre el evento \"hilo\" y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más grandes.",
                "Además, el evento \"hilo\" modela la relación o las dependencias entre pares de eventos en un tema, mientras que TDT modela temas como grupos de historias no relacionados.",
                "Para hacer que la idea del evento \"hilo\" sea más concreto, considere el ejemplo del tema TDT3 30005, titulado Osama bin Ladens acusación (en las noticias de 1998)."
            ],
            "translated_text": "",
            "candidates": [
                "hilo",
                "hilo",
                "hilo",
                "hilo",
                "hilo",
                "hilo",
                "hilo",
                "hilo",
                "hilo",
                "hilo",
                "subproceso",
                "hilo",
                "hilo",
                "hilo",
                "hilo",
                "Hilo",
                "Thread",
                "hilo",
                "hilo",
                "hilo",
                "hilo",
                "hilo",
                "hilo"
            ],
            "error": []
        },
        "cluster": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Event Threading within News Topics Ramesh Nallapati, Ao Feng, Fuchun Peng, James Allan Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 nmramesh,aofeng,fuchun,allan @cs.umass.edu ABSTRACT With the overwhelming volume of online news available today, there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner.",
                "Previous research focused only on organizing news stories by their topics into a flat hierarchy.",
                "We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.",
                "In this work, we attempt to capture the rich structure of events and their dependencies in a news topic through our event models.",
                "We call the process of recognizing events and their dependencies event threading.",
                "We believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on-topic stories.",
                "We formally define the novel problem, suggest evaluation metrics and present a few techniques for solving the problem.",
                "Besides the standard word based features, our approaches take into account novel features such as temporal locality of stories for event recognition and time-ordering for capturing dependencies.",
                "Our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Clustering General Terms Algorithms, Experimentation, Measurement 1.",
                "INTRODUCTION News forms a major portion of information disseminated in the world everyday.",
                "Common people and news analysts alike are very interested in keeping abreast of new things that happen in the news, but it is becoming very difficult to cope with the huge volumes of information that arrives each day.",
                "Hence there is an increasing need for automatic techniques to organize news stories in a way that helps users interpret and analyze them quickly.",
                "This problem is addressed by a research program called Topic Detection and Tracking (TDT) [3] that runs an open annual competition on standardized tasks of news organization.",
                "One of the shortcomings of current TDT evaluation is its view of news topics as flat collection of stories.",
                "For example, the detection task of TDT is to arrange a collection of news stories into clusters of topics.",
                "However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events.",
                "This is indeed recognized by TDT which defines a topic as a set of news stories that are strongly related by some seminal realworld event where an event is defined as something that happens at a specific time and location [3].",
                "For example, when a bomb explodes in a building, that is the seminal event that triggers the topic.",
                "Other events in the topic may include the rescue attempts, the search for perpetrators, arrests and trials and so on.",
                "We see that there is a pattern of dependencies between pairs of events in the topic.",
                "In the above example, the event of rescue attempts is influenced by the event of bombing and so is the event of search for perpetrators.",
                "In this work we investigate methods for modeling the structure of a topic in terms of its events.",
                "By structure, we mean not only identifying the events that make up a topic, but also establishing dependencies-generally causal-among them.",
                "We call the process of recognizing events and identifying dependencies among them event threading, an analogy to email threading that shows connections between related email messages.",
                "We refer to the resulting interconnected structure of events as the event model of the topic.",
                "Although this paper focuses on threading events within an existing news topic, we expect that such event based dependency structure more accurately reflects the structure of news than strictly bounded topics do.",
                "From a users perspective, we believe that our view of a news topic as a set of interconnected events helps him/her get a quick overview of the topic and also allows him/her navigate through the topic faster.",
                "The rest of the paper is organized as follows.",
                "In section 2, we discuss related work.",
                "In section 3, we define the problem and use an example to illustrate threading of events within a news topic.",
                "In section 4, we describe how we built the corpus for our problem.",
                "Section 5 presents our evaluation techniques while section 6 describes the techniques we use for modeling event structure.",
                "In section 7 we present our experiments and results.",
                "Section 8 concludes the paper with a few observations on our results and comments on future work. 446 2.",
                "RELATED WORK The process of threading events together is related to threading of electronic mail only by name for the most part.",
                "Email usually incorporates a strong structure of referenced messages and consistently formatted subject headings-though information retrieval techniques are useful when the structure breaks down [7].",
                "Email threading captures reference dependencies between messages and does not attempt to reflect any underlying real-world structure of the matter under discussion.",
                "Another area of research that looks at the structure within a topic is hierarchical text classification of topics [9, 6].",
                "The hierarchy within a topic does impose a structure on the topic, but we do not know of an effort to explore the extent to which that structure reflects the underlying event relationships.",
                "Barzilay and Lee [5] proposed a content structure modeling technique where topics within text are learnt using unsupervised methods, and a linear order of these topics is modeled using hidden Markov models.",
                "Our work differs from theirs in that we do not constrain the dependency to be linear.",
                "Also their algorithms are tuned to work on specific genres of topics such as earthquakes, accidents, etc., while we expect our algorithms to generalize over any topic.",
                "In TDT, researchers have traditionally considered topics as flatclusters [1].",
                "However, in TDT-2003, a hierarchical structure of topic detection has been proposed and [2] made useful attempts to adopt the new structure.",
                "However this structure still did not explicitly model any dependencies between events.",
                "In a work closest to ours, Makkonen [8] suggested modeling news topics in terms of its evolving events.",
                "However, the paper stopped short of proposing any models to the problem.",
                "Other related work that dealt with analysis within a news topic includes temporal summarization of news topics [4]. 3.",
                "PROBLEM DEFINITION AND NOTATION In this work, we have adhered to the definition of event and topic as defined in TDT.",
                "We present some definitions (in italics) and our interpretations (regular-faced) below for clarity. 1.",
                "Story: A story is a news article delivering some information to users.",
                "In TDT, a story is assumed to refer to only a single topic.",
                "In this work, we also assume that each story discusses a single event.",
                "In other words, a story is the smallest atomic unit in the hierarchy (topic event story).",
                "Clearly, both the assumptions are not necessarily true in reality, but we accept them for simplicity in modeling. 2.",
                "Event: An event is something that happens at some specific time and place [10].",
                "In our work, we represent an event by a set of stories that discuss it.",
                "Following the assumption of atomicity of a story, this means that any set of distinct events can be represented by a set of non-overlapping clusters of news stories. 3.",
                "Topic: A set of news stories strongly connected by a seminal event.",
                "We expand on this definition and interpret a topic as a series of related events.",
                "Thus a topic can be represented by clusters of stories each representing an event and a set of (directed or undirected) edges between pairs of these clusters representing the dependencies between these events.",
                "We will describe this representation of a topic in more detail in the next section. 4.",
                "Topic detection and tracking (TDT) :Topic detection detects clusters of stories that discuss the same topic; Topic tracking detects stories that discuss a previously known topic [3].",
                "Thus TDT concerns itself mainly with clustering stories into topics that discuss them. 5.",
                "Event threading: Event threading detects events within in a topic, and also captures the dependencies among the events.",
                "Thus the main difference between event threading and TDT is that we focus our modeling effort on microscopic events rather than larger topics.",
                "Additionally event threading models the relatedness or dependencies between pairs of events in a topic while TDT models topics as unrelated clusters of stories.",
                "We first define our problem and representation of our model formally and then illustrate with the help of an example.",
                "We are given a set of Ò news stories Ë ×½ ¡ ¡ ¡ ×Ò on a given topic Ì and their time of publication.",
                "We define a set of events ½ ¡ ¡ ¡ Ñ with the following constraints: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) While the first constraint says that each event is an element in the power set of S, the second constraint ensures that each story can belong to at most one event.",
                "The last constraint tells us that every story belongs to one of the events in .",
                "In fact this allows us to define a mapping function from stories to events as follows: ´× µ iff × ¾ (4) Further, we also define a set of directed edges ´ µ which denote dependencies between events.",
                "It is important to explain what we mean by this directional dependency: While the existence of an edge itself represents relatedness of two events, the direction could imply causality or temporal-ordering.",
                "By causal dependency we mean that the occurrence of event B is related to and is a consequence of the occurrence of event A.",
                "By temporal ordering, we mean that event B happened after event A and is related to A but is not necessarily a consequence of A.",
                "For example, consider the following two events: plane crash (event A) and subsequent investigations (event B) in a topic on a plane crash incident.",
                "Clearly, the investigations are a result of the crash.",
                "Hence an arrow from A to B falls under the category of causal dependency.",
                "Now consider the pair of events Pope arrives in Cuba(event A) and Pope meets Castro(event B) in a topic that discusses Popes visit to Cuba.",
                "Now events A and B are closely related through their association with the Pope and Cuba but event B is not necessarily a consequence of the occurrence of event A.",
                "An arrow in such scenario captures what we call time ordering.",
                "In this work, we do not make an attempt to distinguish between these two kinds of dependencies and our models treats them as identical.",
                "A simpler (and hence less controversial) choice would be to ignore direction in the dependencies altogether and consider only undirected edges.",
                "This choice definitely makes sense as a first step but we chose the former since we believe directional edges make more sense to the user as they provide a more illustrative flow-chart perspective to the topic.",
                "To make the idea of event threading more concrete, consider the example of TDT3 topic 30005, titled Osama bin Ladens Indictment (in the 1998 news).",
                "This topic has 23 stories which form 5 events.",
                "An event model of this topic can be represented as in figure 1.",
                "Each box in the figure indicates an event in the topic of Osamas indictment.",
                "The occurrence of event 2, namely Trial and Indictment of Osama is dependent on the event of evidence gathered by CIA, i.e., event 1.",
                "Similarly, event 2 influences the occurrences of events 3, 4 and 5, namely Threats from Militants, Reactions 447 from Muslim World and announcement of reward.",
                "Thus all the dependencies in the example are causal.",
                "Extending our notation further, we call an event A a parent of B and B the child of A, if ´ µ ¾ .",
                "We define an event model Å ´ µ to be a tuple of the set of events and set of dependencies.",
                "Trial and (5) (3) (4) CIA announces reward Muslim world Reactions from Islamic militants Threats from (2) (1) Osama Indictment of CIA gathered by Evidence Figure 1: An event model of TDT topic Osama bin Ladens indictment.",
                "Event threading is strongly related to topic detection and tracking, but also different from it significantly.",
                "It goes beyond topics, and models the relationships between events.",
                "Thus, event threading can be considered as a further extension of topic detection and tracking and is more challenging due to at least the following difficulties. 1.",
                "The number of events is unknown. 2.",
                "The granularity of events is hard to define. 3.",
                "The dependencies among events are hard to model. 4.",
                "Since it is a brand new research area, no standard evaluation metrics and benchmark data is available.",
                "In the next few sections, we will describe our attempts to tackle these problems. 4.",
                "LABELED DATA We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.",
                "The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.",
                "If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for annotators.",
                "The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.",
                "We believe modeling such stories would be a useful first step before dealing with more complex data sets.",
                "We hired an annotator to create truth data.",
                "Annotation includes defining the event membership for each story and also the dependencies.",
                "We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.",
                "In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., something that happens at a specific time and location.",
                "The annotator was encouraged to merge two events A and B into a single event C if any of the stories discusses both A and B.",
                "This is to satisfy our assumption that each story corresponds to a unique event.",
                "The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.",
                "We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.",
                "As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.",
                "We believe that this would help make her understanding of the events more concrete.",
                "We however, do not use or model these titles in our algorithms.",
                "In defining dependencies between events, we imposed no restrictions on the graph structure.",
                "Each event could have single, multiple or no parents.",
                "Further, the graph could have cycles or orphannodes.",
                "The annotator was however instructed to assign a dependency from event A to event B if and only if the occurrence of B is either causally influenced by A or is closely related to A and follows A in time.",
                "From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.",
                "Table 1 shows that the training and test sets have fairly similar statistics.",
                "Feature Training set Test set Num. topics 26 27 Avg.",
                "Num.",
                "Stories/Topic 28.69 26.74 Avg.",
                "Doc.",
                "Len. 64.60 64.04 Avg.",
                "Num.",
                "Stories/Event 5.65 6.22 Avg.",
                "Num.",
                "Events/Topic 5.07 4.29 Avg.",
                "Num.",
                "Dependencies/Topic 3.07 2.92 Avg.",
                "Num.",
                "Dependencies/Event 0.61 0.68 Avg.",
                "Num.",
                "Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 5.",
                "EVALUATION A system can generate some event model Å¼ ´ ¼ ¼µ using certain algorithms, which is usually different from the truth model Å ´ µ (we assume the annotator did not make any mistake).",
                "Comparing a system event model Å¼ with the true model Å requires comparing the entire event models including their dependency structure.",
                "And different event granularities may bring huge discrepancy between Å¼ and Å.",
                "This is certainly non-trivial as even testing whether two graphs are isomorphic has no known polynomial time solution.",
                "Hence instead of comparing the actual structure we examine a pair of stories at a time and verify if the system and true labels agree on their event-memberships and dependencies.",
                "Specifically, we compare two kinds of story pairs: ¯ <br>cluster</br> pairs ( ´Åµ): These are the complete set of unordered pairs ´× × µ of stories × and × that fall within the same event given a model Å.",
                "Formally, ´Åµ ´× × µ × × ¾ Ë ´× µ ´× µ (5) where is the function in Å that maps stories to events as defined in equation 4. ¯ Dependency pairs ( ´Åµ): These are the set of all ordered pairs of stories ´× × µ such that there is a dependency from the event of × to the event of × in the model Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Note the story pair is ordered here, so ´× × µ is not equivalent to ´× × µ.",
                "In our evaluation, a correct pair with wrong 448 (B->D) <br>cluster</br> pairs (A,C) Dependency pairs (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) <br>cluster</br> precision: 1/2 Cluster Recall: 1/2 Dependency Recall: 2/6 Dependency Precision: 2/4 (A->D) True event model System event model A,B C A,C B Cluster pairs (A,B) Dependency pairs Figure 2: Evaluation measures direction will be considered a mistake.",
                "As we mentioned earlier in section 3, ignoring the direction may make the problem simpler, but we will lose the expressiveness of our representation.",
                "Given these two sets of story pairs corresponding to the true event model Å and the system event model Å¼, we define recall and precision for each category as follows. ¯ <br>cluster</br> Precision (CP): It is the probability that two randomly selected stories × and × are in the same true-event given that they are in the same system event.",
                "È È´ ´× µ ´× µ ¼´× µ ¼´× µµ ´Åµ ´Å¼µ ´Å¼µ (7) where ¼ is the story-event mapping function corresponding to the model Å¼. ¯ <br>cluster</br> Recall(CR): It is the probability that two randomly selected stories × and × are in the same system-event given that they are in the same true event.",
                "Ê È´ ¼´× µ ¼´× µ ´× µ ´× µµ ´Åµ ´Å¼µ ´Åµ (8) ¯ Dependency Precision(DP): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the true model Å given that they have a dependency in the system model Å¼.",
                "Note that the direction of dependency is important in comparison.",
                "È È´´ ´× µ ´× µµ ¾ ´ ¼´× µ ¼´× µµ ¾ ¼µ ´Åµ ´Å¼µ ´Å¼µ (9) ¯ Dependency Recall(DR): It is the probability that there is a dependency between the events of two randomly selected stories × and × in the system model Å¼ given that they have a dependency in the true model Å.",
                "Again, the direction of dependency is taken into consideration.",
                "Ê È´´ ¼´× µ ¼´× µµ ¾ ¼ ´ ´× µ ´× µµ ¾ µ ´Åµ ´Å¼µ ´Åµ (10) The measures are illustrated by an example in figure 2.",
                "We also combine these measures using the well known F1-measure commonly used in text classification and other research areas as shown below. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) where and are the <br>cluster</br> and dependency F1-measures respectively and Â is the Joint F1-measure (Â ) that we use to measure the overall performance. 6.",
                "TECHNIQUES The task of event modeling can be split into two parts: clustering the stories into unique events in the topic and constructing dependencies among them.",
                "In the following subsections, we describe techniques we developed for each of these sub-tasks. 6.1 Clustering Each topic is composed of multiple events, so stories must be clustered into events before we can model the dependencies among them.",
                "For simplicity, all stories in the same topic are assumed to be available at one time, rather than coming in a text stream.",
                "This task is similar to traditional clustering but features other than word distributions may also be critical in our application.",
                "In many text clustering systems, the similarity between two stories is the inner product of their tf-idf vectors, hence we use it as one of our features.",
                "Stories in the same event tend to follow temporal locality, so the time stamp of each story can be a useful feature.",
                "Additionally, named-entities such as person and location names are another obvious feature when forming events.",
                "Stories in the same event tend to be related to the same person(s) and locations(s).",
                "In this subsection, we present an agglomerative clustering algorithm that combines all these features.",
                "In our experiments, however, we study the effect of each feature on the performance separately using modified versions of this algorithm. 6.1.1 Agglomerative clustering with time decay (ACDT) We initialize our events to singleton events (clusters), i.e., each <br>cluster</br> contains exactly one story.",
                "So the similarity between two events, to start with, is exactly the similarity between the corresponding stories.",
                "The similarity Û×ÙÑ´×½ ×¾µ between two stories ×½ and ×¾ is given by the following formula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Here ½, ¾, ¿ are the weights on different features.",
                "In this work, we determined them empirically, but in the future, one can consider more sophisticated learning techniques to determine them.",
                "Ó×´×½ ×¾µ is the cosine similarity of the term vectors.",
                "ÄÓ ´×½ ×¾µ is 1 if there is some location that appears in both stories, otherwise it is 0.",
                "È Ö´×½ ×¾µ is similarly defined for person name.",
                "We use time decay when calculating similarity of story pairs, i.e., the larger time difference between two stories, the smaller their similarities.",
                "The time period of each topic differs a lot, from a few days to a few months.",
                "So we normalize the time difference using the whole duration of that topic.",
                "The time decay adjusted similarity 449 × Ñ´×½ ×¾µ is given by × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ  « Ø½ Ø¾ Ì (13) where Ø½ and Ø¾ are the time stamps for story 1 and 2 respectively.",
                "T is the time difference between the earliest and the latest story in the given topic. « is the time decay factor.",
                "In each iteration, we find the most similar event pair and merge them.",
                "We have three different ways to compute the similarity between two events Ù and Ú: ¯ Average link: In this case the similarity is the average of the similarities of all pairs of stories between Ù and Ú as shown below: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Complete link: The similarity between two events is given by the smallest of the pair-wise similarities. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Single link: Here the similarity is given by the best similarity between all pairs of stories. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) This process continues until the maximum similarity falls below the threshold or the number of clusters is smaller than a given number. 6.2 Dependency modeling Capturing dependencies is an extremely hard problem because it may require a deeper understanding of the events in question.",
                "A human annotator decides on dependencies not just based on the information in the events but also based on his/her vast repertoire of domain-knowledge and general understanding of how things operate in the world.",
                "For example, in Figure 1 a human knows Trial and indictment of Osama is influenced by Evidence gathered by CIA because he/she understands the process of law in general.",
                "We believe a robust model should incorporate such domain knowledge in capturing dependencies, but in this work, as a first step, we will rely on surface-features such as time-ordering of news stories and word distributions to model them.",
                "Our experiments in later sections demonstrate that such features are indeed useful in capturing dependencies to a large extent.",
                "In this subsection, we describe the models we considered for capturing dependencies.",
                "In the rest of the discussion in this subsection, we assume that we are already given the mapping ¼ Ë and we focus only on modeling the edges ¼.",
                "First we define a couple of features that the following models will employ.",
                "First we define a 1-1 time-ordering function Ø Ë ½ ¡ ¡ ¡ Ò that sorts stories in ascending order by their time of publication.",
                "Now, the event-time-ordering function Ø is defined as follows.",
                "Ø ½ ¡ ¡ ¡ Ñ × Ø Ù Ú ¾ Ø ´ Ùµ Ø ´ Úµ ´µ Ñ Ò ×Ù¾ Ù Ø´×Ùµ Ñ Ò ×Ú¾ Ú Ø´×Úµ (17) In other words, Ø time-orders events based on the time-ordering of their respective first stories.",
                "We will also use average cosine similarity between two events as a feature and it is defined as follows.",
                "Ú Ë Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú Ó×´×Ù ×Ú µ Ù Ú (18) 6.2.1 Complete-Link model In this model, we assume that there are dependencies between all pairs of events.",
                "The direction of dependency is determined by the time-ordering of the first stories in the respective events.",
                "Formally, the system edges are defined as follows. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) where Ø is the event-time-ordering function.",
                "In other words, the dependency edge is directed from event Ù to event Ú , if the first story in event Ù is earlier than the first story in event Ú .",
                "We point out that this is not to be confused with the complete-link algorithm in clustering.",
                "Although we use the same names, it will be clear from the context which one we refer to. 6.2.2 Simple Thresholding This model is an extension of the complete link model with an additional constraint that there is a dependency between any two events Ù and Ú only if the average cosine similarity between event Ù and event Ú is greater than a threshold Ì.",
                "Formally, ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Ùµ Ø ´ Ú µ (20) 6.2.3 Nearest Parent Model In this model, we assume that each event can have at most one parent.",
                "We define the set of dependencies as follows. ¼ ´ Ù Úµ Ú Ë Ñ´ Ù Ú µ Ì Ø ´ Úµ Ø ´ Ùµ · ½ (21) Thus, for each event Ú , the nearest parent model considers only the event preceding it as defined by Ø as a potential candidate.",
                "The candidate is assigned as the parent only if the average similarity exceeds a pre-defined threshold Ì. 6.2.4 Best Similarity Model This model also assumes that each event can have at most one parent.",
                "An event Ú is assigned a parent Ù if and only if Ù is the most similar earlier event to Ú and the similarity exceeds a threshold Ì.",
                "Mathematically, this can be expressed as: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Maximum Spanning Tree model In this model, we first build a maximum spanning tree (MST) using a greedy algorithm on the following fully connected weighted, undirected graph whose vertices are the events and whose edges are defined as follows: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Let ÅËÌ´ µ be the set of edges in the maximum spanning tree of ¼.",
                "Now our directed dependency edges are defined as follows. ¼ ´ Ù Ú µ ´ Ù Ú µ ¾ ÅËÌ´ µ Ø ´ Ùµ Ø ´ Úµ Ú Ë Ñ´ Ù Ú µ Ì (24) 450 Thus in this model, we assign dependencies between the most similar events in the topic. 7.",
                "EXPERIMENTS Our experiments consists of three parts.",
                "First we modeled only the event clustering part (defining the mapping function ¼) using clustering algorithms described in section 6.1.",
                "Then we modeled only the dependencies by providing to the system the true clusters and running only the dependency algorithms of section 6.2.",
                "Finally, we experimented with combinations of clustering and dependency algorithms to produce the complete event model.",
                "This way of experimentation allows us to compare the performance of our algorithms in isolation and in association with other components.",
                "The following subsections present the three parts of our experimentation. 7.1 Clustering We have tried several variations of the Ì algorithm to study the effects of various features on the clustering performance.",
                "All the parameters are learned by tuning on the training set.",
                "We also tested the algorithms on the test set with parameters fixed at their optimal values learned from training.",
                "We used agglomerative clusModel best T CP CR CF P-value cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+Loc+avg-lnk 0.07 0.37 0.74 0.45cos+Per+avg-lnk 0.07 0.39 0.70 0.46cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Table 2: Comparison of agglomerative clustering algorithms (training set) tering based on only cosine similarity as our clustering baseline.",
                "The results on the training and test sets are in Table 2 and 3 respectively.",
                "We use the <br>cluster</br> F1-measure (CF) averaged over all topics as our evaluation criterion.",
                "Model CP CR CF P-value cos+1-lnk 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+Loc+avg-lnk 0.37 0.73 0.45cos+Per+avg-lnk 0.44 0.62 0.45cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Table 3: Comparison of agglomerative clustering algorithms (test set) P-value marked with a £ means that it is a statistically significant improvement over the baseline (95% confidence level, one tailed T-test).",
                "The methods shown in table 2 and 3 are: ¯ Baseline: tf-idf vector weight, cosine similarity, average link in clustering.",
                "In equation 12, ½ ½, ¾ ¿ ¼.",
                "And « ¼ in equation 13.",
                "This F-value is the maximum obtained by tuning the threshold. ¯ cos+1-lnk: Single link comparison (see equation 16) is used where similarity of two clusters is the maximum of all story pairs, other configurations are the same as the baseline run. ¯ cos+all-lnk: Complete link algorithm of equation 15 is used.",
                "Similar to single link but it takes the minimum similarity of all story pairs. ¯ cos+Loc+avg-lnk: Location names are used when calculating similarity. ¾ ¼ ¼ in equation 12.",
                "All algorithms starting from this one use average link (equation 14), since single link and complete link do not show any improvement of performance. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ in equation 12, i.e., we put some weight on person names in the similarity. ¯ cos+TD+avg-lnk: Time Decay coefficient « ½ in equation 13, which means the similarity between two stories will be decayed to ½ if they are at different ends of the topic. ¯ cos+N(T)+avg-lnk: Use the number of true events to control the agglomerative clustering algorithm.",
                "When the number of clusters is fewer than that of truth events, stop merging clusters. ¯ cos+N(T)+T+avg-lnk: similar to N(T) but also stop agglomeration if the maximal similarity is below the threshold Ì. ¯ cos+TD:+N(T)+avg-lnk: similar to N(T) but the similarities are decayed, « ½ in equation 13. ¯ cos+TD+N(T)+T+avg-lnk: similar to TD+N(Truth) but calculation halts when the maximal similarity is smaller than the threshold Ì.",
                "Our experiments demonstrate that single link and complete link similarities perform worse than average link, which is reasonable since average link is less sensitive to one or two story pairs.",
                "We had expected locations and person names to improve the result, but it is not the case.",
                "Analysis of topics shows that many on-topic stories share the same locations or persons irrespective of the event they belong to, so these features may be more useful in identifying topics rather than events.",
                "Time decay is successful because events are temporally localized, i.e., stories discussing the same event tend to be adjacent to each other in terms of time.",
                "Also we noticed that providing the number of true events improves the performance since it guides the clustering algorithm to get correct granularity.",
                "However, for most applications, it is not available.",
                "We used it only as a cheat experiment for comparison with other algorithms.",
                "On the whole, time decay proved to the most powerful feature besides cosine similarity on both training and test sets. 7.2 Dependencies In this subsection, our goal is to model only dependencies.",
                "We use the true mapping function and by implication the true events Î .",
                "We build our dependency structure ¼ using all the five models described in section 6.2.",
                "We first train our models on the 26 training topics.",
                "Training involves learning the best threshold Ì for each of the models.",
                "We then test the performances of all the trained models on the 27 test topics.",
                "We evaluate our performance 451 using the average values of Dependency Precision (DP), Dependency Recall (DR) and Dependency F-measure (DF).",
                "We consider the complete-link model to be our baseline since for each event, it trivially considers all earlier events to be parents.",
                "Table 4 lists the results on the training set.",
                "We see that while all the algorithms except MST outperform the baseline complete-link algorithm , the nearest Parent algorithm is statistically significant from the baseline in terms of its DF-value using a one-tailed paired T-test at 95% confidence level.",
                "Model best Ì DP DR DF P-value Nearest Parent 0.025 0.55 0.62 0.56 0.04* Best Similarity 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48Simple Thresh. 0.045 0.45 0.76 0.52 0.14 Complete-link - 0.36 0.93 0.48Table 4: Results on the training set: Best Ì is the optimal value of the threshold Ì. * indicates the corresponding model is statistically significant compared to the baseline using a one-tailed, paired T-test at 95% confidence level.",
                "In table 5 we present the comparison of the models on the test set.",
                "Here, we do not use any tuning but set the threshold to the corresponding optimal values learned from the training set.",
                "The results throw some surprises: The nearest parent model, which was significantly better than the baseline on training set, turns out to be worse than the baseline on the test set.",
                "However all the other models are better than the baseline including the best similarity which is statistically significant.",
                "Notice that all the models that perform better than the baseline in terms of DF, actually sacrifice their recall performance compared to the baseline, but improve on their precision substantially thereby improving their performance on the DF-measure.",
                "We notice that both simple-thresholding and best similarity are better than the baseline on both training and test sets although the improvement is not significant.",
                "On the whole, we observe that the surface-level features we used capture the dependencies to a reasonable level achieving a best value of 0.72 DF on the test set.",
                "Although there is a lot of room for improvement, we believe this is a good first step.",
                "Model DP DR DF P-value Nearest Parent 0.61 0.60 0.60Best Similarity 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Simple Thresh. 0.57 0.75 0.64 0.24 Baseline (Complete-link) 0.50 0.94 0.63Table 5: Results on the test set 7.3 Combining Clustering and Dependencies Now that we have studied the clustering and dependency algorithms in isolation, we combine the best performing algorithms and build the entire event model.",
                "Since none of the dependency algorithms has been shown to be consistently and significantly better than the others, we use all of them in our experimentation.",
                "From the clustering techniques, we choose the best performing Cos+TD.",
                "As a baseline, we use a combination of the baselines in each components, i.e., cos for clustering and complete-link for dependencies.",
                "Note that we need to retrain all the algorithms on the training set because our objective function to optimize is now JF, the joint F-measure.",
                "For each algorithm, we need to optimize both the clustering threshold and the dependency threshold.",
                "We did this empirically on the training set and the optimal values are listed in table 6.",
                "The results on the training set, also presented in table 6, indicate that cos+TD+Simple-Thresholding is significantly better than the baseline in terms of the joint F-value JF, using a one-tailed paired Ttest at 95% confidence level.",
                "On the whole, we notice that while the clustering performance is comparable to the experiments in section 7.1, the overall performance is undermined by the low dependency performance.",
                "Unlike our experiments in section 7.2 where we had provided the true clusters to the system, in this case, the system has to deal with deterioration in the <br>cluster</br> quality.",
                "Hence the performance of the dependency algorithms has suffered substantially thereby lowering the overall performance.",
                "The results on the test set present a very similar story as shown in table 7.",
                "We also notice a fair amount of consistency in the performance of the combination algorithms. cos+TD+Simple-Thresholding outperforms the baseline significantly.",
                "The test set results also point to the fact that the clustering component remains a bottleneck in achieving an overall good performance. 8.",
                "DISCUSSION AND CONCLUSIONS In this paper, we have presented a new perspective of modeling news topics.",
                "Contrary to the TDT view of topics as flat collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.",
                "In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.",
                "We developed a timedecay based clustering approach that takes advantage of temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.",
                "Our experiments also show that we can do fairly well on dependencies using only surface-features such as cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.",
                "However, the performance deteriorates rapidly if the system has to discover the events by itself.",
                "Despite that discouraging result, we have shown that our combined algorithms perform significantly better than the baselines.",
                "Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.",
                "Errors in clustering have a magnifying effect on errors in dependencies as we have seen in our experiments.",
                "Hence, we should focus not only on improving dependencies but also on clustering at the same time.",
                "As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.",
                "And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite answer of yes/no for the causal relations among some events.",
                "We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.",
                "We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.",
                "Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.",
                "This work was supported in part by the Center 452 Model <br>cluster</br> T Dep.",
                "T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by SPAWARSYSCENSD grant number N66001-02-1-8903.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. 9.",
                "REFERENCES [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang.",
                "Topic detection and tracking pilot study: Final report.",
                "In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218, 1998. [2] J. Allan, A. Feng, and A. Bolivar.",
                "Flexible intrinsic evaluation of hierarchical clustering for tdt. volume In the Proc. of the ACM Twelfth International Conference on Information and Knowledge Management, pages 263-270, Nov 2003. [3] James Allan, editor.",
                "Topic Detection and Tracking:Event based Information Organization.",
                "Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta, and Vikas Khandelwal.",
                "Temporal summaries of new topics.",
                "In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10-18.",
                "ACM Press, 2001. [5] Regina Barzilay and Lillian Lee.",
                "Catching the drift: Probabilistic content models, with applications to generation and summarization.",
                "In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics(HLT-NAACL), pages 113-120, 2004. [6] D. Lawrie and W. B. Croft.",
                "Discovering and comparing topic hierarchies.",
                "In Proceedings of RIAO 2000 Conference, pages 314-330, 1999. [7] David D. Lewis and Kimberly A. Knowles.",
                "Threading electronic mail: a preliminary study.",
                "Inf.",
                "Process.",
                "Manage., 33(2):209-217, 1997. [8] Juha Makkonen.",
                "Investigations on event evolution in tdt.",
                "In Proceedings of HLT-NAACL 2003 Student Workshop, pages 43-48, 2004. [9] Aixin Sun and Ee-Peng Lim.",
                "Hierarchical text classification and evaluation.",
                "In Proceedings of the 2001 IEEE International Conference on Data Mining, pages 521-528.",
                "IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald, and Xin Liu.",
                "Learning approaches for detecting and tracking news events.",
                "In IEEE Intelligent Systems Special Issue on Applications of Intelligent Information Retrieval, volume 14 (4), pages 32-43, 1999. 453"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Específicamente, comparamos dos tipos de pares de historias: ¯ pares de \"clúster\" (´åµ): estos son el conjunto completo de pares no ordenados ´ × × µ de historias × y × que caen dentro del mismo evento dado un modelo Å.",
                "En nuestra evaluación, un par correcto con pares de dependencia 448 (b-> d) \"clúster\" (a, c) (a-> b) (c-> b) (b-> d) d, e d, e d, e d, e d, e d, e d, e d.(D, e) (d, e) (a-> c) (a-> e) (b-> c) (b-> e) (b-> e) \"clúster\" precisión: 1/2 recuerdo del clúster: 1/2 Recuerdo de dependencia: 2/6 Precisión de dependencia: 2/4 (A-> D) Sistema de eventos verdadero Sistema de eventos Modelo A, B C A, C B Pares de clúster (A, B) Pares de dependencia Figura 2: La dirección de las medidas de evaluación seráconsiderado un error.",
                "Dados estos dos conjuntos de pares de historias correspondientes al verdadero Modelo de eventos Å y al Modelo de eventos del sistema Å¼, definimos el recuerdo y la precisión para cada categoría de la siguiente manera.¯ \"Cluster\" Precision (CP): es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema.",
                "È è´ ´ × µ ´ × µ ¼´ × µ ¼´ × µ ´åµ ´å¼µ ´å¼µ (7) donde ¼ es la función de mapeo de eventos de la historia correspondiente al modelo Å¼.¯ \"Clúster\" Recuerde (CR): es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo verdadero evento.",
                "También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación.¾ ¢ è ¢ ê è · ê ¾ ¢ è ¢ ê è · ê â ¾ ¢ ¢ · (11) donde y somos el \"clúster\" y la dependencia de las medidas F1 respectivamente y es la medida F1 conjunta (â) que nosotrosUso para medir el rendimiento general.6.",
                "Sin embargo, en nuestros experimentos, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo.6.1.1 Agrupación aglomerativa con decadencia de tiempo (ACDT) Inicializamos nuestros eventos a Singleton Events (grupos), es decir, cada \"clúster\" contiene exactamente una historia.",
                "Utilizamos la medida F1 \"clúster\" (CF) promediada sobre todos los temas como nuestro criterio de evaluación.",
                "A diferencia de nuestros experimentos en la Sección 7.2, donde habíamos proporcionado los clústeres verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad del \"clúster\".",
                "Este trabajo fue apoyado en parte por el modelo 452 \"Cluster\" T Dep."
            ],
            "translated_text": "",
            "candidates": [
                "grupo",
                "clúster",
                "grupo",
                "clúster",
                "clúster",
                "grupo",
                "Cluster",
                "grupo",
                "Clúster",
                "Clúster",
                "clúster",
                "grupo",
                "clúster",
                "grupo",
                "clúster",
                "grupo",
                "clúster",
                "grupo",
                "Cluster"
            ],
            "error": []
        }
    }
}