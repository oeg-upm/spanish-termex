{
    "original_text": "Achieving performance under OpenMP on ccNUMA and software distributed shared memory systems OpenMP is emerging as a viable high-level programming model for shared memory parallel systems. It was conceived to enable easy, portable application development on this range of systems, and it has also been implemented on cache-coherent Non-Uniform Memory Access (ccNUMA) architectures. Unfortunately, it is hard to obtain high performance on the latter architecture, particularly when large numbers of threads are involved. In this paper, we discuss the difficulties faced when writing OpenMP programs for ccNUMA systems, and explain how the vendors have attempted to overcome them. We focus on one such system, the SGI Origin 2000, and perform a variety of experiments designed to illustrate the impact of the vendors efforts. We compare codes written in a standard, loop-level parallel style under OpenMP with alternative versions written in a Single Program Multiple Data (SPMD) fashion, also realized via OpenMP, and show that the latter consistently provides superior performance. A carefully chosen set of language extensions can help us translate programs from the former style to the latter (or to compile directly, but in a similar manner). Syntax for these extensions can be borrowed from HPF, and some aspects of HPF compiler technology can help the translation process. It is our expectation that an extended language, if well compiled, would improve the attractiveness of OpenMP as a language for high-performance computation on an important class of modern architectures",
    "original_translation": "Alcanzar un rendimiento bajo OpenMP en ccNUMA y sistemas de memoria compartida distribuida por software OpenMP está emergiendo como un modelo de programación de alto nivel viable para sistemas paralelos de memoria compartida. Fue concebido para permitir el desarrollo de aplicaciones fáciles y portátiles en esta gama de sistemas, y también se ha implementado en arquitecturas de acceso de memoria no uniforme (ccNUMA) compatibles con caché. Desafortunadamente, es difícil obtener un alto rendimiento en esta última arquitectura, especialmente cuando se trata de un gran número de hilos. En este artículo, discutimos las dificultades que enfrentan al escribir programas OpenMP para sistemas ccNUMA, y explicamos cómo los vendedores han intentado superarlos. Nos centramos en uno de esos sistemas, el SGI Origin 2000, y realizamos una variedad de experimentos diseñados para ilustrar el impacto de los esfuerzos de los proveedores. Comparamos códigos escritos en un estilo paralelo estándar, a nivel de bucle bajo OpenMP con versiones alternativas escritas en una manera de un programa único de datos múltiples (SPMD), también realizado a través de OpenMP, y mostrar que este último proporciona consistentemente un rendimiento superior. Un conjunto cuidadosamente elegido de extensiones de lenguaje puede ayudarnos a traducir programas del estilo anterior al segundo (o a compilar directamente, pero de una manera similar). La sintaxis para estas extensiones se puede tomar prestada de HPF, y algunos aspectos de la tecnología de compilador de HPF pueden ayudar al proceso de traducción. Esperamos que un lenguaje extendido, si está bien compilado, mejore el atractivo de OpenMP como lenguaje para la computación de alto rendimiento en una importante clase de arquitecturas modernas",
    "error_count": 4,
    "keys": {
        "cache-coherent Non-Uniform Memory Access": {
            "translated_key": "cache-coherente Non-Uniform Memory Access",
            "translated_annotated_text": "Alcanzar un rendimiento bajo OpenMP en ccNUMA y sistemas de memoria compartida distribuida por software OpenMP está emergiendo como un modelo de programación de alto nivel viable para sistemas paralelos de memoria compartida. Fue concebido para permitir el desarrollo de aplicaciones fáciles y portátiles en esta gama de sistemas, y también se ha implementado en arquitecturas <br>cache-coherente Non-Uniform Memory Access</br> (ccNUMA). Desafortunadamente, es difícil obtener un alto rendimiento en esta última arquitectura, especialmente cuando se trata de un gran número de hilos. En este artículo, discutimos las dificultades que enfrentan al escribir programas OpenMP para sistemas ccNUMA, y explicamos cómo los vendedores han intentado superarlos. Nos centramos en uno de esos sistemas, el SGI Origin 2000, y realizamos una variedad de experimentos diseñados para ilustrar el impacto de los esfuerzos de los proveedores. Comparamos códigos escritos en un estilo paralelo estándar, a nivel de bucle bajo OpenMP con versiones alternativas escritas en una manera de un programa único de datos múltiples (SPMD), también realizado a través de OpenMP, y mostrar que este último proporciona consistentemente un rendimiento superior. Un conjunto cuidadosamente elegido de extensiones de lenguaje puede ayudarnos a traducir programas del estilo anterior al segundo (o a compilar directamente, pero de una manera similar). La sintaxis para estas extensiones se puede tomar prestada de HPF, y algunos aspectos de la tecnología de compilador de HPF pueden ayudar al proceso de traducción. Esperamos que un lenguaje extendido, si está bien compilado, mejore el atractivo de OpenMP como lenguaje para la computación de alto rendimiento en una importante clase de arquitecturas modernas ",
            "error": [
                ""
            ]
        },
        "OpenMP": {
            "translated_key": "OpenMP",
            "translated_annotated_text": "Alcanzar un rendimiento bajo <br>OpenMP</br> en ccNUMA y sistemas de memoria compartida distribuida por software <br>OpenMP</br> está emergiendo como un modelo de programación viable de alto nivel para sistemas paralelos de memoria compartida. Fue concebido para permitir el desarrollo de aplicaciones fáciles y portátiles en esta gama de sistemas, y también se ha implementado en arquitecturas de acceso de memoria no uniforme (ccNUMA) compatibles con caché. Desafortunadamente, es difícil obtener un alto rendimiento en esta última arquitectura, especialmente cuando se trata de un gran número de hilos. En este artículo, discutimos las dificultades que enfrentan al escribir programas <br>OpenMP</br> para sistemas ccNUMA, y explicamos cómo los vendedores han intentado superarlos. Nos centramos en uno de esos sistemas, el SGI Origin 2000, y realizamos una variedad de experimentos diseñados para ilustrar el impacto de los esfuerzos de los proveedores. Comparamos códigos escritos en un estilo paralelo estándar, a nivel de bucle bajo <br>OpenMP</br> con versiones alternativas escritas en una manera de un programa único de datos múltiples (SPMD), también realizadas a través de <br>OpenMP</br>, y mostramos que este último proporciona consistentemente un rendimiento superior. Un conjunto cuidadosamente elegido de extensiones de lenguaje puede ayudarnos a traducir programas del estilo anterior al segundo (o a compilar directamente, pero de una manera similar). La sintaxis para estas extensiones se puede tomar prestada de HPF, y algunos aspectos de la tecnología de compilador de HPF pueden ayudar al proceso de traducción. Esperamos que un lenguaje extendido, si está bien compilado, mejore el atractivo de <br>OpenMP</br> como lenguaje para la computación de alto rendimiento en una importante clase de arquitecturas modernas ",
            "error": [
                ""
            ]
        },
        "programming model": {
            "translated_key": [],
            "translated_annotated_text": "Alcanzar un rendimiento bajo OpenMP en ccNUMA y sistemas de memoria compartida distribuida por software OpenMP está emergiendo como un modelo de programación viable de alto nivel <br> para sistemas paralelos de memoria compartida. Fue concebido para permitir el desarrollo de aplicaciones fáciles y portátiles en esta gama de sistemas, y también se ha implementado en arquitecturas de acceso de memoria no uniforme (ccNUMA) compatibles con caché. Desafortunadamente, es difícil obtener un alto rendimiento en esta última arquitectura, especialmente cuando se trata de un gran número de hilos. En este artículo, discutimos las dificultades que enfrentan al escribir programas OpenMP para sistemas ccNUMA, y explicamos cómo los vendedores han intentado superarlos. Nos centramos en uno de esos sistemas, el SGI Origin 2000, y realizamos una variedad de experimentos diseñados para ilustrar el impacto de los esfuerzos de los proveedores. Comparamos códigos escritos en un estilo paralelo estándar, a nivel de bucle bajo OpenMP con versiones alternativas escritas en una manera de un programa único de datos múltiples (SPMD), también realizado a través de OpenMP, y mostrar que este último proporciona consistentemente un rendimiento superior. Un conjunto cuidadosamente elegido de extensiones de lenguaje puede ayudarnos a traducir programas del estilo anterior al segundo (o a compilar directamente, pero de una manera similar). La sintaxis para estas extensiones se puede tomar prestada de HPF, y algunos aspectos de la tecnología de compilador de HPF pueden ayudar al proceso de traducción. Esperamos que un lenguaje extendido, si está bien compilado, mejore el atractivo de OpenMP como lenguaje para la computación de alto rendimiento en una importante clase de arquitecturas modernas ",
            "error": []
        },
        "shared memory parallel systems": {
            "translated_key": " ",
            "translated_annotated_text": "Alcanzar un rendimiento bajo OpenMP en ccNUMA y sistemas de memoria compartida distribuida por software OpenMP está emergiendo como un modelo de programación de alto nivel viable para sistemas paralelos de memoria compartida <br> </br>. Fue concebido para permitir el desarrollo de aplicaciones fáciles y portátiles en esta gama de sistemas, y también se ha implementado en arquitecturas de acceso de memoria no uniforme (ccNUMA) compatibles con caché. Desafortunadamente, es difícil obtener un alto rendimiento en esta última arquitectura, especialmente cuando se trata de un gran número de hilos. En este artículo, discutimos las dificultades que enfrentan al escribir programas OpenMP para sistemas ccNUMA, y explicamos cómo los vendedores han intentado superarlos. Nos centramos en uno de esos sistemas, el SGI Origin 2000, y realizamos una variedad de experimentos diseñados para ilustrar el impacto de los esfuerzos de los proveedores. Comparamos códigos escritos en un estilo paralelo estándar, a nivel de bucle bajo OpenMP con versiones alternativas escritas en una manera de un programa único de datos múltiples (SPMD), también realizado a través de OpenMP, y mostrar que este último proporciona consistentemente un rendimiento superior. Un conjunto cuidadosamente elegido de extensiones de lenguaje puede ayudarnos a traducir programas del estilo anterior al segundo (o a compilar directamente, pero de una manera similar). La sintaxis para estas extensiones se puede tomar prestada de HPF, y algunos aspectos de la tecnología de compilador de HPF pueden ayudar al proceso de traducción. Esperamos que un lenguaje extendido, si está bien compilado, mejore el atractivo de OpenMP como lenguaje para la computación de alto rendimiento en una importante clase de arquitecturas modernas ",
            "error": [
                ""
            ]
        },
        "HPF": {
            "translated_key": "HPF",
            "translated_annotated_text": "Alcanzar un rendimiento bajo OpenMP en ccNUMA y sistemas de memoria compartida distribuida por software OpenMP está emergiendo como un modelo de programación de alto nivel viable para sistemas paralelos de memoria compartida. Fue concebido para permitir el desarrollo de aplicaciones fáciles y portátiles en esta gama de sistemas, y también se ha implementado en arquitecturas de acceso de memoria no uniforme (ccNUMA) compatibles con caché. Desafortunadamente, es difícil obtener un alto rendimiento en esta última arquitectura, especialmente cuando se trata de un gran número de hilos. En este artículo, discutimos las dificultades que enfrentan al escribir programas OpenMP para sistemas ccNUMA, y explicamos cómo los vendedores han intentado superarlos. Nos centramos en uno de esos sistemas, el SGI Origin 2000, y realizamos una variedad de experimentos diseñados para ilustrar el impacto de los esfuerzos de los proveedores. Comparamos códigos escritos en un estilo paralelo estándar, a nivel de bucle bajo OpenMP con versiones alternativas escritas en una manera de un programa único de datos múltiples (SPMD), también realizado a través de OpenMP, y mostrar que este último proporciona consistentemente un rendimiento superior. Un conjunto cuidadosamente elegido de extensiones de lenguaje puede ayudarnos a traducir programas del estilo anterior al segundo (o a compilar directamente, pero de una manera similar). La sintaxis para estas extensiones se puede tomar prestada de <br>HPF</br>, y algunos aspectos de la tecnología del compilador <br>HPF</br> pueden ayudar al proceso de traducción. Esperamos que un lenguaje extendido, si está bien compilado, mejore el atractivo de OpenMP como lenguaje para la computación de alto rendimiento en una importante clase de arquitecturas modernas ",
            "error": [
                ""
            ]
        },
        "Single Program Multiple Data": {
            "translated_key": "Single Program Múltiples Datos",
            "translated_annotated_text": "Alcanzar un rendimiento bajo OpenMP en ccNUMA y sistemas de memoria compartida distribuida por software OpenMP está emergiendo como un modelo de programación de alto nivel viable para sistemas paralelos de memoria compartida. Fue concebido para permitir el desarrollo de aplicaciones fáciles y portátiles en esta gama de sistemas, y también se ha implementado en arquitecturas de acceso de memoria no uniforme (ccNUMA) compatibles con caché. Desafortunadamente, es difícil obtener un alto rendimiento en esta última arquitectura, especialmente cuando se trata de un gran número de hilos. En este artículo, discutimos las dificultades que enfrentan al escribir programas OpenMP para sistemas ccNUMA, y explicamos cómo los vendedores han intentado superarlos. Nos centramos en uno de esos sistemas, el SGI Origin 2000, y realizamos una variedad de experimentos diseñados para ilustrar el impacto de los esfuerzos de los proveedores. Comparamos códigos escritos en un estilo paralelo estándar, a nivel de bucle bajo OpenMP con versiones alternativas escritas en una manera <br>Single Program Múltiples Datos</br> (SPMD), también realizada a través de OpenMP, y mostramos que este último proporciona consistentemente un rendimiento superior. Un conjunto cuidadosamente elegido de extensiones de lenguaje puede ayudarnos a traducir programas del estilo anterior al segundo (o a compilar directamente, pero de una manera similar). La sintaxis para estas extensiones se puede tomar prestada de HPF, y algunos aspectos de la tecnología de compilador de HPF pueden ayudar al proceso de traducción. Esperamos que un lenguaje extendido, si está bien compilado, mejore el atractivo de OpenMP como lenguaje para la computación de alto rendimiento en una importante clase de arquitecturas modernas ",
            "error": [
                ""
            ]
        },
        "parallel programming": {
            "translated_key": [],
            "translated_annotated_text": "Alcanzar un rendimiento bajo OpenMP en ccNUMA y sistemas de memoria compartida distribuida por software OpenMP está emergiendo como un modelo de programación de alto nivel viable para sistemas paralelos de memoria compartida. Fue concebido para permitir el desarrollo de aplicaciones fáciles y portátiles en esta gama de sistemas, y también se ha implementado en arquitecturas de acceso de memoria no uniforme (ccNUMA) compatibles con caché. Desafortunadamente, es difícil obtener un alto rendimiento en esta última arquitectura, especialmente cuando se trata de un gran número de hilos. En este artículo, discutimos las dificultades que enfrentan al escribir programas OpenMP para sistemas ccNUMA, y explicamos cómo los vendedores han intentado superarlos. Nos centramos en uno de esos sistemas, el SGI Origin 2000, y realizamos una variedad de experimentos diseñados para ilustrar el impacto de los esfuerzos de los proveedores. Comparamos códigos escritos en un estilo paralelo estándar, a nivel de bucle bajo OpenMP con versiones alternativas escritas en una manera de un programa único de datos múltiples (SPMD), también realizado a través de OpenMP, y mostrar que este último proporciona consistentemente un rendimiento superior. Un conjunto cuidadosamente elegido de extensiones de lenguaje puede ayudarnos a traducir programas del estilo anterior al segundo (o a compilar directamente, pero de una manera similar). La sintaxis para estas extensiones se puede tomar prestada de HPF, y algunos aspectos de la tecnología de compilador de HPF pueden ayudar al proceso de traducción. Esperamos que un lenguaje extendido, si está bien compilado, mejore el atractivo de OpenMP como lenguaje para la computación de alto rendimiento en una importante clase de arquitecturas modernas ",
            "error": []
        },
        "distributed shared memory systems": {
            "translated_key": "distribuido sistemas de memoria compartida",
            "translated_annotated_text": "Alcanzar un rendimiento bajo OpenMP en ccNUMA y software <br>distribuido sistemas de memoria compartida</br> OpenMP está emergiendo como un modelo de programación de alto nivel viable para sistemas paralelos de memoria compartida. Fue concebido para permitir el desarrollo de aplicaciones fáciles y portátiles en esta gama de sistemas, y también se ha implementado en arquitecturas de acceso de memoria no uniforme (ccNUMA) compatibles con caché. Desafortunadamente, es difícil obtener un alto rendimiento en esta última arquitectura, especialmente cuando se trata de un gran número de hilos. En este artículo, discutimos las dificultades que enfrentan al escribir programas OpenMP para sistemas ccNUMA, y explicamos cómo los vendedores han intentado superarlos. Nos centramos en uno de esos sistemas, el SGI Origin 2000, y realizamos una variedad de experimentos diseñados para ilustrar el impacto de los esfuerzos de los proveedores. Comparamos códigos escritos en un estilo paralelo estándar, a nivel de bucle bajo OpenMP con versiones alternativas escritas en una manera de un programa único de datos múltiples (SPMD), también realizado a través de OpenMP, y mostrar que este último proporciona consistentemente un rendimiento superior. Un conjunto cuidadosamente elegido de extensiones de lenguaje puede ayudarnos a traducir programas del estilo anterior al segundo (o a compilar directamente, pero de una manera similar). La sintaxis para estas extensiones se puede tomar prestada de HPF, y algunos aspectos de la tecnología de compilador de HPF pueden ayudar al proceso de traducción. Esperamos que un lenguaje extendido, si está bien compilado, mejore el atractivo de OpenMP como lenguaje para la computación de alto rendimiento en una importante clase de arquitecturas modernas ",
            "error": [
                ""
            ]
        },
        "software performance evaluation": {
            "translated_key": [],
            "translated_annotated_text": "Alcanzar un rendimiento bajo OpenMP en ccNUMA y sistemas de memoria compartida distribuida por software OpenMP está emergiendo como un modelo de programación de alto nivel viable para sistemas paralelos de memoria compartida. Fue concebido para permitir el desarrollo de aplicaciones fáciles y portátiles en esta gama de sistemas, y también se ha implementado en arquitecturas de acceso de memoria no uniforme (ccNUMA) compatibles con caché. Desafortunadamente, es difícil obtener un alto rendimiento en esta última arquitectura, especialmente cuando se trata de un gran número de hilos. En este artículo, discutimos las dificultades que enfrentan al escribir programas OpenMP para sistemas ccNUMA, y explicamos cómo los vendedores han intentado superarlos. Nos centramos en uno de esos sistemas, el SGI Origin 2000, y realizamos una variedad de experimentos diseñados para ilustrar el impacto de los esfuerzos de los proveedores. Comparamos códigos escritos en un estilo paralelo estándar, a nivel de bucle bajo OpenMP con versiones alternativas escritas en una manera de un programa único de datos múltiples (SPMD), también realizado a través de OpenMP, y mostrar que este último proporciona consistentemente un rendimiento superior. Un conjunto cuidadosamente elegido de extensiones de lenguaje puede ayudarnos a traducir programas del estilo anterior al segundo (o a compilar directamente, pero de una manera similar). La sintaxis para estas extensiones se puede tomar prestada de HPF, y algunos aspectos de la tecnología de compilador de HPF pueden ayudar al proceso de traducción. Esperamos que un lenguaje extendido, si está bien compilado, mejore el atractivo de OpenMP como lenguaje para la computación de alto rendimiento en una importante clase de arquitecturas modernas ",
            "error": []
        }
    }
}