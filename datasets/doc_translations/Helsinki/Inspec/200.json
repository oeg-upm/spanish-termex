{
    "original_text": "Preintegration lateral inhibition enhances unsupervised learning A large and influential class of neural network architectures uses postintegration lateral inhibition as a mechanism for competition. We argue that these algorithms are computationally deficient in that they fail to generate, or learn, appropriate perceptual representations under certain circumstances. An alternative neural network architecture is presented here in which nodes compete for the right to receive inputs rather than for the right to generate outputs. This form of competition, implemented through preintegration lateral inhibition, does provide appropriate coding properties and can be used to learn such representations efficiently. Furthermore, this architecture is consistent with both neuroanatomical and neuropsychological data. We thus argue that preintegration lateral inhibition has computational advantages over conventional neural network architectures while remaining equally biologically plausible",
    "original_translation": "La inhibición lateral previa a la integración mejora el aprendizaje no supervisado Una clase grande e influyente de arquitecturas de redes neuronales utiliza la inhibición lateral posterior a la integración como mecanismo de competencia. Argumentamos que estos algoritmos son computacionalmente deficientes en que no generan, o aprenden, representaciones perceptivas apropiadas bajo ciertas circunstancias. Aquí se presenta una arquitectura alternativa de red neuronal en la que los nodos compiten por el derecho a recibir entradas en lugar de por el derecho a generar salidas. Esta forma de competencia, implementada a través de la inhibición lateral de preintegración, proporciona propiedades de codificación adecuadas y puede ser utilizada para aprender tales representaciones de manera eficiente. Además, esta arquitectura es coherente con los datos neuroanatómicos y neuropsicológicos. Por lo tanto, argumentamos que la inhibición lateral de preintegración tiene ventajas computacionales sobre las arquitecturas de redes neuronales convencionales, mientras que sigue siendo igualmente biológicamente plausible",
    "error_count": 4,
    "keys": {
        "neural network architectures": {
            "translated_key": [
                "arquitecturas de redes neuronales",
                "arquitecturas de red neuronal"
            ],
            "translated_annotated_text": "La inhibición lateral previa a la integración mejora el aprendizaje no supervisado Una clase grande e influyente de \"arquitecturas de redes neuronales\" utiliza la inhibición lateral posterior a la integración como mecanismo de competencia. Argumentamos que estos algoritmos son computacionalmente deficientes en que no generan, o aprenden, representaciones perceptivas apropiadas bajo ciertas circunstancias. Aquí se presenta una arquitectura alternativa de red neuronal en la que los nodos compiten por el derecho a recibir entradas en lugar de por el derecho a generar salidas. Esta forma de competencia, implementada a través de la inhibición lateral de preintegración, proporciona propiedades de codificación adecuadas y puede ser utilizada para aprender tales representaciones de manera eficiente. Además, esta arquitectura es coherente con los datos neuroanatómicos y neuropsicológicos. Por lo tanto, argumentamos que la inhibición lateral de preintegración tiene ventajas computacionales sobre las \"arquitecturas de red neuronal\" convencionales, mientras que sigue siendo igualmente biológicamente plausible ",
            "error": [
                "arquitecturas de redes neuronales",
                "arquitecturas de red neuronal"
            ]
        },
        "postintegration lateral inhibition": {
            "translated_key": "inhibición lateral posterior a la integración",
            "translated_annotated_text": "La inhibición lateral previa a la integración mejora el aprendizaje no supervisado Una clase grande e influyente de arquitecturas de redes neuronales utiliza la \"inhibición lateral posterior a la integración\" como mecanismo de competencia. Argumentamos que estos algoritmos son computacionalmente deficientes en que no generan, o aprenden, representaciones perceptivas apropiadas bajo ciertas circunstancias. Aquí se presenta una arquitectura alternativa de red neuronal en la que los nodos compiten por el derecho a recibir entradas en lugar de por el derecho a generar salidas. Esta forma de competencia, implementada a través de la inhibición lateral de preintegración, proporciona propiedades de codificación adecuadas y puede ser utilizada para aprender tales representaciones de manera eficiente. Además, esta arquitectura es coherente con los datos neuroanatómicos y neuropsicológicos. Por lo tanto, argumentamos que la inhibición lateral de preintegración tiene ventajas computacionales sobre las arquitecturas de redes neuronales convencionales, mientras que sigue siendo igualmente biológicamente plausible ",
            "error": [
                ""
            ]
        },
        "competition": {
            "translated_key": "competencia",
            "translated_annotated_text": "La inhibición lateral previa a la integración mejora el aprendizaje no supervisado Una clase grande e influyente de arquitecturas de redes neuronales utiliza la inhibición lateral posterior a la integración como mecanismo de \"competencia\". Argumentamos que estos algoritmos son computacionalmente deficientes en que no generan, o aprenden, representaciones perceptivas apropiadas bajo ciertas circunstancias. Aquí se presenta una arquitectura alternativa de red neuronal en la que los nodos compiten por el derecho a recibir entradas en lugar de por el derecho a generar salidas. Esta forma de \"competencia\", implementada a través de la inhibición lateral de preintegración, proporciona las propiedades de codificación adecuadas y puede ser utilizada para aprender tales representaciones de manera eficiente. Además, esta arquitectura es coherente con los datos neuroanatómicos y neuropsicológicos. Por lo tanto, argumentamos que la inhibición lateral de preintegración tiene ventajas computacionales sobre las arquitecturas de redes neuronales convencionales, mientras que sigue siendo igualmente biológicamente plausible ",
            "error": [
                ""
            ]
        },
        "preintegration lateral inhibition": {
            "translated_key": [
                "inhibición lateral de preintegración",
                "inhibición lateral de la preintegración"
            ],
            "translated_annotated_text": "La inhibición lateral previa a la integración mejora el aprendizaje no supervisado Una clase grande e influyente de arquitecturas de redes neuronales utiliza la inhibición lateral posterior a la integración como mecanismo de competencia. Argumentamos que estos algoritmos son computacionalmente deficientes en que no generan, o aprenden, representaciones perceptivas apropiadas bajo ciertas circunstancias. Aquí se presenta una arquitectura alternativa de red neuronal en la que los nodos compiten por el derecho a recibir entradas en lugar de por el derecho a generar salidas. Esta forma de competencia, implementada a través de la \"inhibición lateral de preintegración\", proporciona las propiedades de codificación adecuadas y puede ser utilizada para aprender tales representaciones de manera eficiente. Además, esta arquitectura es coherente con los datos neuroanatómicos y neuropsicológicos. Por lo tanto, argumentamos que la \"inhibición lateral de la preintegración\" tiene ventajas computacionales sobre las arquitecturas de redes neuronales convencionales mientras permanece igualmente biológicamente plausible ",
            "error": [
                "inhibición lateral de preintegración",
                "inhibición lateral de la preintegración"
            ]
        },
        "neural network": {
            "translated_key": "red neuronal",
            "translated_annotated_text": "La inhibición lateral previa a la integración mejora el aprendizaje no supervisado Una clase grande e influyente de arquitecturas de \"red neuronal\" utiliza la inhibición lateral posterior a la integración como mecanismo de competencia. Argumentamos que estos algoritmos son computacionalmente deficientes en que no generan, o aprenden, representaciones perceptivas apropiadas bajo ciertas circunstancias. Aquí se presenta una arquitectura alternativa de \"red neuronal\" en la que los nodos compiten por el derecho a recibir entradas y no por el derecho a generar salidas. Esta forma de competencia, implementada a través de la inhibición lateral de preintegración, proporciona propiedades de codificación adecuadas y puede ser utilizada para aprender tales representaciones de manera eficiente. Además, esta arquitectura es coherente con los datos neuroanatómicos y neuropsicológicos. Por lo tanto, argumentamos que la inhibición lateral de preintegración tiene ventajas computacionales sobre las arquitecturas convencionales de \"red neuronal\" mientras permanece igualmente biológicamente plausible ",
            "error": [
                ""
            ]
        },
        "unsupervised learning": {
            "translated_key": "aprendizaje no supervisado",
            "translated_annotated_text": "La inhibición lateral previa a la integración mejora el \"aprendizaje no supervisado\" Una clase grande e influyente de arquitecturas de redes neuronales utiliza la inhibición lateral posterior a la integración como mecanismo de competencia. Argumentamos que estos algoritmos son computacionalmente deficientes en que no generan, o aprenden, representaciones perceptivas apropiadas bajo ciertas circunstancias. Aquí se presenta una arquitectura alternativa de red neuronal en la que los nodos compiten por el derecho a recibir entradas en lugar de por el derecho a generar salidas. Esta forma de competencia, implementada a través de la inhibición lateral de preintegración, proporciona propiedades de codificación adecuadas y puede ser utilizada para aprender tales representaciones de manera eficiente. Además, esta arquitectura es coherente con los datos neuroanatómicos y neuropsicológicos. Por lo tanto, argumentamos que la inhibición lateral de preintegración tiene ventajas computacionales sobre las arquitecturas de redes neuronales convencionales, mientras que sigue siendo igualmente biológicamente plausible ",
            "error": [
                ""
            ]
        },
        "neural net architecture": {
            "translated_key": [],
            "translated_annotated_text": "La inhibición lateral previa a la integración mejora el aprendizaje no supervisado Una clase grande e influyente de arquitecturas de redes neuronales utiliza la inhibición lateral posterior a la integración como mecanismo de competencia. Argumentamos que estos algoritmos son computacionalmente deficientes en que no generan, o aprenden, representaciones perceptivas apropiadas bajo ciertas circunstancias. Aquí se presenta una arquitectura alternativa de red neuronal en la que los nodos compiten por el derecho a recibir entradas en lugar de por el derecho a generar salidas. Esta forma de competencia, implementada a través de la inhibición lateral de preintegración, proporciona propiedades de codificación adecuadas y puede ser utilizada para aprender tales representaciones de manera eficiente. Además, esta arquitectura es coherente con los datos neuroanatómicos y neuropsicológicos. Por lo tanto, argumentamos que la inhibición lateral de preintegración tiene ventajas computacionales sobre las arquitecturas de redes neuronales convencionales, mientras que sigue siendo igualmente biológicamente plausible ",
            "error": []
        },
        "neural nets": {
            "translated_key": [],
            "translated_annotated_text": "La inhibición lateral previa a la integración mejora el aprendizaje no supervisado Una clase grande e influyente de arquitecturas de redes neuronales utiliza la inhibición lateral posterior a la integración como mecanismo de competencia. Argumentamos que estos algoritmos son computacionalmente deficientes en que no generan, o aprenden, representaciones perceptivas apropiadas bajo ciertas circunstancias. Aquí se presenta una arquitectura alternativa de red neuronal en la que los nodos compiten por el derecho a recibir entradas en lugar de por el derecho a generar salidas. Esta forma de competencia, implementada a través de la inhibición lateral de preintegración, proporciona propiedades de codificación adecuadas y puede ser utilizada para aprender tales representaciones de manera eficiente. Además, esta arquitectura es coherente con los datos neuroanatómicos y neuropsicológicos. Por lo tanto, argumentamos que la inhibición lateral de preintegración tiene ventajas computacionales sobre las arquitecturas de redes neuronales convencionales, mientras que sigue siendo igualmente biológicamente plausible ",
            "error": []
        }
    }
}