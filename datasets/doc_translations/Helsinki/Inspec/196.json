{
    "original_text": "On the emergence of rules in neural networks A simple associationist neural network learns to factor abstract rules (i.e., grammars) from sequences of arbitrary input symbols by inventing abstract representations that accommodate unseen symbol sets as well as unseen but similar grammars. The neural network is shown to have the ability to transfer grammatical knowledge to both new symbol vocabularies and new grammars. Analysis of the state-space shows that the network learns generalized abstract structures of the input and is not simply memorizing the input strings. These representations are context sensitive, hierarchical, and based on the state variable of the finite-state machines that the neural network has learned. Generalization to new symbol sets or grammars arises from the spatial nature of the internal representations used by the network, allowing new symbol sets to be encoded close to symbol sets that have already been learned in the hidden unit space of the network. The results are counter to the arguments that learning algorithms based on weight adaptation after each exemplar presentation (such as the long term potentiation found in the mammalian nervous system) cannot in principle extract symbolic knowledge from positive examples as prescribed by prevailing human linguistic theory and evolutionary psychology",
    "original_translation": "Sobre la aparición de reglas en las redes neuronales Una simple red neuronal asociacionista aprende a factorizar reglas abstractas (es decir, gramáticas) de secuencias de símbolos de entrada arbitrarios inventando representaciones abstractas que acomodan conjuntos de símbolos invisibles, así como gramáticas invisibles pero similares. Se demuestra que la red neuronal tiene la capacidad de transferir conocimientos gramaticales tanto a los vocabularios de nuevos símbolos como a las nuevas gramáticas. El análisis del espacio-estado muestra que la red aprende estructuras abstractas generalizadas de la entrada y no está simplemente memorizando las cadenas de entrada. Estas representaciones son sensibles al contexto, jerárquicas y se basan en la variable de estado de las máquinas de estado finito que la red neuronal ha aprendido. La generalización de nuevos conjuntos de símbolos o gramáticas surge de la naturaleza espacial de las representaciones internas utilizadas por la red, permitiendo que nuevos conjuntos de símbolos sean codificados cerca de conjuntos de símbolos que ya han sido aprendidos en el espacio de unidad oculto de la red. Los resultados son contrarios a los argumentos de que los algoritmos de aprendizaje basados en la adaptación del peso después de cada presentación ejemplar (como la potenciación a largo plazo encontrada en el sistema nervioso mamífero) no pueden en principio extraer el conocimiento simbólico de ejemplos positivos prescritos por la teoría lingüística humana predominante y la psicología evolutiva.",
    "error_count": 5,
    "keys": {
        "associationist neural network": {
            "translated_key": "red neuronal asociacionista",
            "translated_annotated_text": "Sobre la aparición de reglas en redes neuronales Una simple \"red neuronal asociacionista\" aprende a factorizar reglas abstractas (es decir, gramáticas) de secuencias de símbolos de entrada arbitrarios inventando representaciones abstractas que acomodan conjuntos de símbolos invisibles, así como gramáticas invisibles pero similares. Se demuestra que la red neuronal tiene la capacidad de transferir conocimientos gramaticales tanto a los vocabularios de nuevos símbolos como a las nuevas gramáticas. El análisis del espacio-estado muestra que la red aprende estructuras abstractas generalizadas de la entrada y no está simplemente memorizando las cadenas de entrada. Estas representaciones son sensibles al contexto, jerárquicas y se basan en la variable de estado de las máquinas de estado finito que la red neuronal ha aprendido. La generalización de nuevos conjuntos de símbolos o gramáticas surge de la naturaleza espacial de las representaciones internas utilizadas por la red, permitiendo que nuevos conjuntos de símbolos sean codificados cerca de conjuntos de símbolos que ya han sido aprendidos en el espacio de unidad oculto de la red. Los resultados son contrarios a los argumentos de que los algoritmos de aprendizaje basados en la adaptación del peso después de cada presentación ejemplar (como la potenciación a largo plazo encontrada en el sistema nervioso mamífero) no pueden en principio extraer el conocimiento simbólico de ejemplos positivos prescritos por la teoría lingüística humana predominante y la psicología evolutiva. ",
            "error": [
                ""
            ]
        },
        "learns": {
            "translated_key": "aprende",
            "translated_annotated_text": "Sobre la aparición de reglas en las redes neuronales Una simple red neuronal asociacionista \"aprende\" a factorizar reglas abstractas (es decir, gramáticas) de secuencias de símbolos de entrada arbitrarios inventando representaciones abstractas que acomodan conjuntos de símbolos invisibles, así como gramáticas invisibles pero similares. Se demuestra que la red neuronal tiene la capacidad de transferir conocimientos gramaticales tanto a los vocabularios de nuevos símbolos como a las nuevas gramáticas. El análisis del espacio-estado muestra que la red \"aprende\" estructuras abstractas generalizadas de la entrada y no está simplemente memorizando las cadenas de entrada. Estas representaciones son sensibles al contexto, jerárquicas y se basan en la variable de estado de las máquinas de estado finito que la red neuronal ha aprendido. La generalización de nuevos conjuntos de símbolos o gramáticas surge de la naturaleza espacial de las representaciones internas utilizadas por la red, permitiendo que nuevos conjuntos de símbolos sean codificados cerca de conjuntos de símbolos que ya han sido aprendidos en el espacio de unidad oculto de la red. Los resultados son contrarios a los argumentos de que los algoritmos de aprendizaje basados en la adaptación del peso después de cada presentación ejemplar (como la potenciación a largo plazo encontrada en el sistema nervioso mamífero) no pueden en principio extraer el conocimiento simbólico de ejemplos positivos prescritos por la teoría lingüística humana predominante y la psicología evolutiva. ",
            "error": [
                ""
            ]
        },
        "abstract rules": {
            "translated_key": "reglas abstractas",
            "translated_annotated_text": "Sobre la aparición de reglas en las redes neuronales Una simple red neuronal asociacionista aprende a factor \"reglas abstractas\" (es decir, gramáticas) de secuencias de símbolos de entrada arbitrarios inventando representaciones abstractas que acomodan conjuntos de símbolos invisibles, así como gramáticas invisibles pero similares. Se demuestra que la red neuronal tiene la capacidad de transferir conocimientos gramaticales tanto a los vocabularios de nuevos símbolos como a las nuevas gramáticas. El análisis del espacio-estado muestra que la red aprende estructuras abstractas generalizadas de la entrada y no está simplemente memorizando las cadenas de entrada. Estas representaciones son sensibles al contexto, jerárquicas y se basan en la variable de estado de las máquinas de estado finito que la red neuronal ha aprendido. La generalización de nuevos conjuntos de símbolos o gramáticas surge de la naturaleza espacial de las representaciones internas utilizadas por la red, permitiendo que nuevos conjuntos de símbolos sean codificados cerca de conjuntos de símbolos que ya han sido aprendidos en el espacio de unidad oculto de la red. Los resultados son contrarios a los argumentos de que los algoritmos de aprendizaje basados en la adaptación del peso después de cada presentación ejemplar (como la potenciación a largo plazo encontrada en el sistema nervioso mamífero) no pueden en principio extraer el conocimiento simbólico de ejemplos positivos prescritos por la teoría lingüística humana predominante y la psicología evolutiva. ",
            "error": [
                ""
            ]
        },
        "neural network": {
            "translated_key": "red neuronal",
            "translated_annotated_text": "Sobre la aparición de reglas en las redes neuronales Una simple \"red neuronal\" asociacionista aprende a factorizar reglas abstractas (es decir, gramáticas) de secuencias de símbolos de entrada arbitrarios inventando representaciones abstractas que acomodan conjuntos de símbolos invisibles, así como gramáticas invisibles pero similares. Se demuestra que la \"red neuronal\" tiene la capacidad de transferir conocimientos gramaticales tanto a nuevos símbolos vocabularios como a nuevas gramáticas. El análisis del espacio-estado muestra que la red aprende estructuras abstractas generalizadas de la entrada y no está simplemente memorizando las cadenas de entrada. Estas representaciones son sensibles al contexto, jerárquicas y se basan en la variable de estado de las máquinas de estado finito que la \"red neuronal\" ha aprendido. La generalización de nuevos conjuntos de símbolos o gramáticas surge de la naturaleza espacial de las representaciones internas utilizadas por la red, permitiendo que nuevos conjuntos de símbolos sean codificados cerca de conjuntos de símbolos que ya han sido aprendidos en el espacio de unidad oculto de la red. Los resultados son contrarios a los argumentos de que los algoritmos de aprendizaje basados en la adaptación del peso después de cada presentación ejemplar (como la potenciación a largo plazo encontrada en el sistema nervioso mamífero) no pueden en principio extraer el conocimiento simbólico de ejemplos positivos prescritos por la teoría lingüística humana predominante y la psicología evolutiva. ",
            "error": [
                ""
            ]
        },
        "state-space": {
            "translated_key": "estado-espacio",
            "translated_annotated_text": "Sobre la aparición de reglas en las redes neuronales Una simple red neuronal asociacionista aprende a factorizar reglas abstractas (es decir, gramáticas) de secuencias de símbolos de entrada arbitrarios inventando representaciones abstractas que acomodan conjuntos de símbolos invisibles, así como gramáticas invisibles pero similares. Se demuestra que la red neuronal tiene la capacidad de transferir conocimientos gramaticales tanto a los vocabularios de nuevos símbolos como a las nuevas gramáticas. El análisis del \"estado-espacio\" muestra que la red aprende estructuras abstractas generalizadas de la entrada y no está simplemente memorizando las cadenas de entrada. Estas representaciones son sensibles al contexto, jerárquicas y se basan en la variable de estado de las máquinas de estado finito que la red neuronal ha aprendido. La generalización de nuevos conjuntos de símbolos o gramáticas surge de la naturaleza espacial de las representaciones internas utilizadas por la red, permitiendo que nuevos conjuntos de símbolos sean codificados cerca de conjuntos de símbolos que ya han sido aprendidos en el espacio de unidad oculto de la red. Los resultados son contrarios a los argumentos de que los algoritmos de aprendizaje basados en la adaptación del peso después de cada presentación ejemplar (como la potenciación a largo plazo encontrada en el sistema nervioso mamífero) no pueden en principio extraer el conocimiento simbólico de ejemplos positivos prescritos por la teoría lingüística humana predominante y la psicología evolutiva. ",
            "error": [
                ""
            ]
        },
        "symbolic knowledge": {
            "translated_key": "conocimiento simbólico",
            "translated_annotated_text": "Sobre la aparición de reglas en las redes neuronales Una simple red neuronal asociacionista aprende a factorizar reglas abstractas (es decir, gramáticas) de secuencias de símbolos de entrada arbitrarios inventando representaciones abstractas que acomodan conjuntos de símbolos invisibles, así como gramáticas invisibles pero similares. Se demuestra que la red neuronal tiene la capacidad de transferir conocimientos gramaticales tanto a los vocabularios de nuevos símbolos como a las nuevas gramáticas. El análisis del espacio-estado muestra que la red aprende estructuras abstractas generalizadas de la entrada y no está simplemente memorizando las cadenas de entrada. Estas representaciones son sensibles al contexto, jerárquicas y se basan en la variable de estado de las máquinas de estado finito que la red neuronal ha aprendido. La generalización de nuevos conjuntos de símbolos o gramáticas surge de la naturaleza espacial de las representaciones internas utilizadas por la red, permitiendo que nuevos conjuntos de símbolos sean codificados cerca de conjuntos de símbolos que ya han sido aprendidos en el espacio de unidad oculto de la red. Los resultados son contrarios a los argumentos de que los algoritmos de aprendizaje basados en la adaptación del peso después de cada presentación ejemplar (como la potenciación a largo plazo encontrada en el sistema nervioso mamífero) no pueden en principio extraer el \"conocimiento simbólico\" de ejemplos positivos prescritos por la teoría lingüística humana predominante y la psicología evolutiva. ",
            "error": [
                ""
            ]
        },
        "cognitive neurosciences": {
            "translated_key": [],
            "translated_annotated_text": "Sobre la aparición de reglas en las redes neuronales Una simple red neuronal asociacionista aprende a factorizar reglas abstractas (es decir, gramáticas) de secuencias de símbolos de entrada arbitrarios inventando representaciones abstractas que acomodan conjuntos de símbolos invisibles, así como gramáticas invisibles pero similares. Se demuestra que la red neuronal tiene la capacidad de transferir conocimientos gramaticales tanto a los vocabularios de nuevos símbolos como a las nuevas gramáticas. El análisis del espacio-estado muestra que la red aprende estructuras abstractas generalizadas de la entrada y no está simplemente memorizando las cadenas de entrada. Estas representaciones son sensibles al contexto, jerárquicas y se basan en la variable de estado de las máquinas de estado finito que la red neuronal ha aprendido. La generalización de nuevos conjuntos de símbolos o gramáticas surge de la naturaleza espacial de las representaciones internas utilizadas por la red, permitiendo que nuevos conjuntos de símbolos sean codificados cerca de conjuntos de símbolos que ya han sido aprendidos en el espacio de unidad oculto de la red. Los resultados son contrarios a los argumentos de que los algoritmos de aprendizaje basados en la adaptación del peso después de cada presentación ejemplar (como la potenciación a largo plazo encontrada en el sistema nervioso mamífero) no pueden en principio extraer el conocimiento simbólico de ejemplos positivos prescritos por la teoría lingüística humana predominante y la psicología evolutiva. ",
            "error": []
        },
        "associationist learning": {
            "translated_key": [],
            "translated_annotated_text": "Sobre la aparición de reglas en las redes neuronales Una simple red neuronal asociacionista aprende a factorizar reglas abstractas (es decir, gramáticas) de secuencias de símbolos de entrada arbitrarios inventando representaciones abstractas que acomodan conjuntos de símbolos invisibles, así como gramáticas invisibles pero similares. Se demuestra que la red neuronal tiene la capacidad de transferir conocimientos gramaticales tanto a los vocabularios de nuevos símbolos como a las nuevas gramáticas. El análisis del espacio-estado muestra que la red aprende estructuras abstractas generalizadas de la entrada y no está simplemente memorizando las cadenas de entrada. Estas representaciones son sensibles al contexto, jerárquicas y se basan en la variable de estado de las máquinas de estado finito que la red neuronal ha aprendido. La generalización de nuevos conjuntos de símbolos o gramáticas surge de la naturaleza espacial de las representaciones internas utilizadas por la red, permitiendo que nuevos conjuntos de símbolos sean codificados cerca de conjuntos de símbolos que ya han sido aprendidos en el espacio de unidad oculto de la red. Los resultados son contrarios a los argumentos de que los algoritmos de aprendizaje basados en la adaptación del peso después de cada presentación ejemplar (como la potenciación a largo plazo encontrada en el sistema nervioso mamífero) no pueden en principio extraer el conocimiento simbólico de ejemplos positivos prescritos por la teoría lingüística humana predominante y la psicología evolutiva. ",
            "error": []
        },
        "associative processing": {
            "translated_key": [],
            "translated_annotated_text": "Sobre la aparición de reglas en las redes neuronales Una simple red neuronal asociacionista aprende a factorizar reglas abstractas (es decir, gramáticas) de secuencias de símbolos de entrada arbitrarios inventando representaciones abstractas que acomodan conjuntos de símbolos invisibles, así como gramáticas invisibles pero similares. Se demuestra que la red neuronal tiene la capacidad de transferir conocimientos gramaticales tanto a los vocabularios de nuevos símbolos como a las nuevas gramáticas. El análisis del espacio-estado muestra que la red aprende estructuras abstractas generalizadas de la entrada y no está simplemente memorizando las cadenas de entrada. Estas representaciones son sensibles al contexto, jerárquicas y se basan en la variable de estado de las máquinas de estado finito que la red neuronal ha aprendido. La generalización de nuevos conjuntos de símbolos o gramáticas surge de la naturaleza espacial de las representaciones internas utilizadas por la red, permitiendo que nuevos conjuntos de símbolos sean codificados cerca de conjuntos de símbolos que ya han sido aprendidos en el espacio de unidad oculto de la red. Los resultados son contrarios a los argumentos de que los algoritmos de aprendizaje basados en la adaptación del peso después de cada presentación ejemplar (como la potenciación a largo plazo encontrada en el sistema nervioso mamífero) no pueden en principio extraer el conocimiento simbólico de ejemplos positivos prescritos por la teoría lingüística humana predominante y la psicología evolutiva. ",
            "error": []
        },
        "learning (artificial intelligence)": {
            "translated_key": [],
            "translated_annotated_text": "Sobre la aparición de reglas en las redes neuronales Una simple red neuronal asociacionista aprende a factorizar reglas abstractas (es decir, gramáticas) de secuencias de símbolos de entrada arbitrarios inventando representaciones abstractas que acomodan conjuntos de símbolos invisibles, así como gramáticas invisibles pero similares. Se demuestra que la red neuronal tiene la capacidad de transferir conocimientos gramaticales tanto a los vocabularios de nuevos símbolos como a las nuevas gramáticas. El análisis del espacio-estado muestra que la red aprende estructuras abstractas generalizadas de la entrada y no está simplemente memorizando las cadenas de entrada. Estas representaciones son sensibles al contexto, jerárquicas y se basan en la variable de estado de las máquinas de estado finito que la red neuronal ha aprendido. La generalización de nuevos conjuntos de símbolos o gramáticas surge de la naturaleza espacial de las representaciones internas utilizadas por la red, permitiendo que nuevos conjuntos de símbolos sean codificados cerca de conjuntos de símbolos que ya han sido aprendidos en el espacio de unidad oculto de la red. Los resultados son contrarios a los argumentos de que los algoritmos de aprendizaje basados en la adaptación del peso después de cada presentación ejemplar (como la potenciación a largo plazo encontrada en el sistema nervioso mamífero) no pueden en principio extraer el conocimiento simbólico de ejemplos positivos prescritos por la teoría lingüística humana predominante y la psicología evolutiva. ",
            "error": []
        },
        "neural nets": {
            "translated_key": [],
            "translated_annotated_text": "Sobre la aparición de reglas en las redes neuronales Una simple red neuronal asociacionista aprende a factorizar reglas abstractas (es decir, gramáticas) de secuencias de símbolos de entrada arbitrarios inventando representaciones abstractas que acomodan conjuntos de símbolos invisibles, así como gramáticas invisibles pero similares. Se demuestra que la red neuronal tiene la capacidad de transferir conocimientos gramaticales tanto a los vocabularios de nuevos símbolos como a las nuevas gramáticas. El análisis del espacio-estado muestra que la red aprende estructuras abstractas generalizadas de la entrada y no está simplemente memorizando las cadenas de entrada. Estas representaciones son sensibles al contexto, jerárquicas y se basan en la variable de estado de las máquinas de estado finito que la red neuronal ha aprendido. La generalización de nuevos conjuntos de símbolos o gramáticas surge de la naturaleza espacial de las representaciones internas utilizadas por la red, permitiendo que nuevos conjuntos de símbolos sean codificados cerca de conjuntos de símbolos que ya han sido aprendidos en el espacio de unidad oculto de la red. Los resultados son contrarios a los argumentos de que los algoritmos de aprendizaje basados en la adaptación del peso después de cada presentación ejemplar (como la potenciación a largo plazo encontrada en el sistema nervioso mamífero) no pueden en principio extraer el conocimiento simbólico de ejemplos positivos prescritos por la teoría lingüística humana predominante y la psicología evolutiva. ",
            "error": []
        }
    }
}