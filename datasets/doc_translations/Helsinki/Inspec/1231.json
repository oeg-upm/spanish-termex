{
    "original_text": "Efficient parallel programming on scalable shared memory systems with High Performance Fortran OpenMP offers a high-level interface for parallel programming on scalable shared memory (SMP) architectures. It provides the user with simple work-sharing directives while it relies on the compiler to generate parallel programs based on thread parallelism. However, the lack of language features for exploiting data locality often results in poor performance since the non-uniform memory access times on scalable SMP machines cannot be neglected. High Performance Fortran (HPF), the de-facto standard for data parallel programming, offers a rich set of data distribution directives in order to exploit data locality, but it has been mainly targeted towards distributed memory machines. In this paper we describe an optimized execution model for HPF programs on SMP machines that avails itself with mechanisms provided by OpenMP for work sharing and thread parallelism, while exploiting data locality based on user-specified distribution directives. Data locality does not only ensure that most memory accesses are close to the executing threads and are therefore faster, but it also minimizes synchronization overheads, especially in the case of unstructured reductions. The proposed shared memory execution model for HPF relies on a small set of language extensions, which resemble the OpenMP work-sharing features. These extensions, together with an optimized shared memory parallelization and execution model, have been implemented in the ADAPTOR HPF compilation system and experimental results verify the efficiency of the chosen approach",
    "original_translation": "Una programación paralela eficiente en sistemas de memoria compartida escalables con Fortran OpenMP de alto rendimiento ofrece una interfaz de alto nivel para la programación paralela en arquitecturas de memoria compartida escalables (SMP). Proporciona al usuario directivas simples de trabajo compartido, mientras que confía en el compilador para generar programas paralelos basados en el paralelismo hilo. Sin embargo, la falta de características lingüísticas para explotar la localidad de datos a menudo resulta en un mal rendimiento ya que los tiempos de acceso a la memoria no uniforme en máquinas SMP escalables no pueden ser descuidados. Alto rendimiento Fortran (HPF), el estándar de facto para la programación paralela de datos, ofrece un rico conjunto de directivas de distribución de datos con el fin de explotar la localidad de datos, pero se ha dirigido principalmente a máquinas de memoria distribuida. En este artículo describimos un modelo de ejecución optimizado para programas HPF en máquinas SMP que se sirve de mecanismos proporcionados por OpenMP para compartir trabajo e hilo paralelismo, mientras se explota la localidad de datos basada en directivas de distribución especificadas por el usuario. La localidad de datos no sólo garantiza que la mayoría de los accesos de memoria están cerca de los hilos de ejecución y por lo tanto son más rápidos, sino que también minimiza los gastos generales de sincronización, especialmente en el caso de reducciones no estructuradas. El modelo de ejecución de memoria compartida propuesto para HPF se basa en un pequeño conjunto de extensiones de lenguaje, que se asemejan a las características de trabajo compartido de OpenMP. Estas extensiones, junto con un modelo optimizado de paralelización y ejecución de memoria compartida, se han implementado en el sistema de compilación ADAPTOR HPF y los resultados experimentales verifican la eficiencia del enfoque elegido.",
    "error_count": 4,
    "keys": {
        "parallel programming": {
            "translated_key": "Programación paralela",
            "translated_annotated_text": "\"Programación paralela\" eficiente en sistemas de memoria compartida escalable con Fortran OpenMP de alto rendimiento ofrece una interfaz de alto nivel para \"programación paralela\" en arquitecturas de memoria compartida escalable (SMP). Proporciona al usuario directivas simples de trabajo compartido, mientras que confía en el compilador para generar programas paralelos basados en el paralelismo hilo. Sin embargo, la falta de características lingüísticas para explotar la localidad de datos a menudo resulta en un mal rendimiento ya que los tiempos de acceso a la memoria no uniforme en máquinas SMP escalables no pueden ser descuidados. Alto rendimiento Fortran (HPF), el estándar de facto para la \"programación paralela\" de datos, ofrece un rico conjunto de directivas de distribución de datos con el fin de explotar la localidad de datos, pero se ha dirigido principalmente a máquinas de memoria distribuida. En este artículo describimos un modelo de ejecución optimizado para programas HPF en máquinas SMP que se sirve de mecanismos proporcionados por OpenMP para compartir trabajo e hilo paralelismo, mientras se explota la localidad de datos basada en directivas de distribución especificadas por el usuario. La localidad de datos no sólo garantiza que la mayoría de los accesos de memoria están cerca de los hilos de ejecución y por lo tanto son más rápidos, sino que también minimiza los gastos generales de sincronización, especialmente en el caso de reducciones no estructuradas. El modelo de ejecución de memoria compartida propuesto para HPF se basa en un pequeño conjunto de extensiones de lenguaje, que se asemejan a las características de trabajo compartido de OpenMP. Estas extensiones, junto con un modelo optimizado de paralelización y ejecución de memoria compartida, se han implementado en el sistema de compilación ADAPTOR HPF y los resultados experimentales verifican la eficiencia del enfoque elegido. ",
            "error": [
                ""
            ]
        },
        "scalable shared memory": {
            "translated_key": "memoria compartida escalable",
            "translated_annotated_text": "Programación paralela eficiente en sistemas de \"memoria compartida escalable\" con Fortran OpenMP de alto rendimiento ofrece una interfaz de alto nivel para la programación paralela en arquitecturas de \"memoria compartida escalable\" (SMP). Proporciona al usuario directivas simples de trabajo compartido, mientras que confía en el compilador para generar programas paralelos basados en el paralelismo hilo. Sin embargo, la falta de características lingüísticas para explotar la localidad de datos a menudo resulta en un mal rendimiento ya que los tiempos de acceso a la memoria no uniforme en máquinas SMP escalables no pueden ser descuidados. Alto rendimiento Fortran (HPF), el estándar de facto para la programación paralela de datos, ofrece un rico conjunto de directivas de distribución de datos con el fin de explotar la localidad de datos, pero se ha dirigido principalmente a máquinas de memoria distribuida. En este artículo describimos un modelo de ejecución optimizado para programas HPF en máquinas SMP que se sirve de mecanismos proporcionados por OpenMP para compartir trabajo e hilo paralelismo, mientras se explota la localidad de datos basada en directivas de distribución especificadas por el usuario. La localidad de datos no sólo garantiza que la mayoría de los accesos de memoria están cerca de los hilos de ejecución y por lo tanto son más rápidos, sino que también minimiza los gastos generales de sincronización, especialmente en el caso de reducciones no estructuradas. El modelo de ejecución de memoria compartida propuesto para HPF se basa en un pequeño conjunto de extensiones de lenguaje, que se asemejan a las características de trabajo compartido de OpenMP. Estas extensiones, junto con un modelo optimizado de paralelización y ejecución de memoria compartida, se han implementado en el sistema de compilación ADAPTOR HPF y los resultados experimentales verifican la eficiencia del enfoque elegido. ",
            "error": [
                ""
            ]
        },
        "High Performance Fortran": {
            "translated_key": "High Performance Fortran",
            "translated_annotated_text": "Programación paralela eficiente en sistemas de memoria compartida escalable con \"High Performance Fortran\" OpenMP ofrece una interfaz de alto nivel para la programación paralela en arquitecturas de memoria compartida escalable (SMP). Proporciona al usuario directivas simples de trabajo compartido, mientras que confía en el compilador para generar programas paralelos basados en el paralelismo hilo. Sin embargo, la falta de características lingüísticas para explotar la localidad de datos a menudo resulta en un mal rendimiento ya que los tiempos de acceso a la memoria no uniforme en máquinas SMP escalables no pueden ser descuidados. \"High Performance Fortran\" (HPF), el estándar de facto para la programación paralela de datos, ofrece un rico conjunto de directivas de distribución de datos con el fin de explotar la localidad de datos, pero se ha dirigido principalmente a máquinas de memoria distribuida. En este artículo describimos un modelo de ejecución optimizado para programas HPF en máquinas SMP que se sirve de mecanismos proporcionados por OpenMP para compartir trabajo e hilo paralelismo, mientras se explota la localidad de datos basada en directivas de distribución especificadas por el usuario. La localidad de datos no sólo garantiza que la mayoría de los accesos de memoria están cerca de los hilos de ejecución y por lo tanto son más rápidos, sino que también minimiza los gastos generales de sincronización, especialmente en el caso de reducciones no estructuradas. El modelo de ejecución de memoria compartida propuesto para HPF se basa en un pequeño conjunto de extensiones de lenguaje, que se asemejan a las características de trabajo compartido de OpenMP. Estas extensiones, junto con un modelo optimizado de paralelización y ejecución de memoria compartida, se han implementado en el sistema de compilación ADAPTOR HPF y los resultados experimentales verifican la eficiencia del enfoque elegido. ",
            "error": [
                ""
            ]
        },
        "multiprocessor architectures": {
            "translated_key": [],
            "translated_annotated_text": "Una programación paralela eficiente en sistemas de memoria compartida escalables con Fortran OpenMP de alto rendimiento ofrece una interfaz de alto nivel para la programación paralela en arquitecturas de memoria compartida escalables (SMP). Proporciona al usuario directivas simples de trabajo compartido, mientras que confía en el compilador para generar programas paralelos basados en el paralelismo hilo. Sin embargo, la falta de características lingüísticas para explotar la localidad de datos a menudo resulta en un mal rendimiento ya que los tiempos de acceso a la memoria no uniforme en máquinas SMP escalables no pueden ser descuidados. Alto rendimiento Fortran (HPF), el estándar de facto para la programación paralela de datos, ofrece un rico conjunto de directivas de distribución de datos con el fin de explotar la localidad de datos, pero se ha dirigido principalmente a máquinas de memoria distribuida. En este artículo describimos un modelo de ejecución optimizado para programas HPF en máquinas SMP que se sirve de mecanismos proporcionados por OpenMP para compartir trabajo e hilo paralelismo, mientras se explota la localidad de datos basada en directivas de distribución especificadas por el usuario. La localidad de datos no sólo garantiza que la mayoría de los accesos de memoria están cerca de los hilos de ejecución y por lo tanto son más rápidos, sino que también minimiza los gastos generales de sincronización, especialmente en el caso de reducciones no estructuradas. El modelo de ejecución de memoria compartida propuesto para HPF se basa en un pequeño conjunto de extensiones de lenguaje, que se asemejan a las características de trabajo compartido de OpenMP. Estas extensiones, junto con un modelo optimizado de paralelización y ejecución de memoria compartida, se han implementado en el sistema de compilación ADAPTOR HPF y los resultados experimentales verifican la eficiencia del enfoque elegido. ",
            "error": []
        },
        "scalable hardware": {
            "translated_key": [],
            "translated_annotated_text": "Una programación paralela eficiente en sistemas de memoria compartida escalables con Fortran OpenMP de alto rendimiento ofrece una interfaz de alto nivel para la programación paralela en arquitecturas de memoria compartida escalables (SMP). Proporciona al usuario directivas simples de trabajo compartido, mientras que confía en el compilador para generar programas paralelos basados en el paralelismo hilo. Sin embargo, la falta de características lingüísticas para explotar la localidad de datos a menudo resulta en un mal rendimiento ya que los tiempos de acceso a la memoria no uniforme en máquinas SMP escalables no pueden ser descuidados. Alto rendimiento Fortran (HPF), el estándar de facto para la programación paralela de datos, ofrece un rico conjunto de directivas de distribución de datos con el fin de explotar la localidad de datos, pero se ha dirigido principalmente a máquinas de memoria distribuida. En este artículo describimos un modelo de ejecución optimizado para programas HPF en máquinas SMP que se sirve de mecanismos proporcionados por OpenMP para compartir trabajo e hilo paralelismo, mientras se explota la localidad de datos basada en directivas de distribución especificadas por el usuario. La localidad de datos no sólo garantiza que la mayoría de los accesos de memoria están cerca de los hilos de ejecución y por lo tanto son más rápidos, sino que también minimiza los gastos generales de sincronización, especialmente en el caso de reducciones no estructuradas. El modelo de ejecución de memoria compartida propuesto para HPF se basa en un pequeño conjunto de extensiones de lenguaje, que se asemejan a las características de trabajo compartido de OpenMP. Estas extensiones, junto con un modelo optimizado de paralelización y ejecución de memoria compartida, se han implementado en el sistema de compilación ADAPTOR HPF y los resultados experimentales verifican la eficiencia del enfoque elegido. ",
            "error": []
        },
        "shared memory multiprocessor": {
            "translated_key": [],
            "translated_annotated_text": "Una programación paralela eficiente en sistemas de memoria compartida escalables con Fortran OpenMP de alto rendimiento ofrece una interfaz de alto nivel para la programación paralela en arquitecturas de memoria compartida escalables (SMP). Proporciona al usuario directivas simples de trabajo compartido, mientras que confía en el compilador para generar programas paralelos basados en el paralelismo hilo. Sin embargo, la falta de características lingüísticas para explotar la localidad de datos a menudo resulta en un mal rendimiento ya que los tiempos de acceso a la memoria no uniforme en máquinas SMP escalables no pueden ser descuidados. Alto rendimiento Fortran (HPF), el estándar de facto para la programación paralela de datos, ofrece un rico conjunto de directivas de distribución de datos con el fin de explotar la localidad de datos, pero se ha dirigido principalmente a máquinas de memoria distribuida. En este artículo describimos un modelo de ejecución optimizado para programas HPF en máquinas SMP que se sirve de mecanismos proporcionados por OpenMP para compartir trabajo e hilo paralelismo, mientras se explota la localidad de datos basada en directivas de distribución especificadas por el usuario. La localidad de datos no sólo garantiza que la mayoría de los accesos de memoria están cerca de los hilos de ejecución y por lo tanto son más rápidos, sino que también minimiza los gastos generales de sincronización, especialmente en el caso de reducciones no estructuradas. El modelo de ejecución de memoria compartida propuesto para HPF se basa en un pequeño conjunto de extensiones de lenguaje, que se asemejan a las características de trabajo compartido de OpenMP. Estas extensiones, junto con un modelo optimizado de paralelización y ejecución de memoria compartida, se han implementado en el sistema de compilación ADAPTOR HPF y los resultados experimentales verifican la eficiencia del enfoque elegido. ",
            "error": []
        },
        "FORTRAN": {
            "translated_key": [],
            "translated_annotated_text": "Una programación paralela eficiente en sistemas de memoria compartida escalables con Fortran OpenMP de alto rendimiento ofrece una interfaz de alto nivel para la programación paralela en arquitecturas de memoria compartida escalables (SMP). Proporciona al usuario directivas simples de trabajo compartido, mientras que confía en el compilador para generar programas paralelos basados en el paralelismo hilo. Sin embargo, la falta de características lingüísticas para explotar la localidad de datos a menudo resulta en un mal rendimiento ya que los tiempos de acceso a la memoria no uniforme en máquinas SMP escalables no pueden ser descuidados. Alto rendimiento Fortran (HPF), el estándar de facto para la programación paralela de datos, ofrece un rico conjunto de directivas de distribución de datos con el fin de explotar la localidad de datos, pero se ha dirigido principalmente a máquinas de memoria distribuida. En este artículo describimos un modelo de ejecución optimizado para programas HPF en máquinas SMP que se sirve de mecanismos proporcionados por OpenMP para compartir trabajo e hilo paralelismo, mientras se explota la localidad de datos basada en directivas de distribución especificadas por el usuario. La localidad de datos no sólo garantiza que la mayoría de los accesos de memoria están cerca de los hilos de ejecución y por lo tanto son más rápidos, sino que también minimiza los gastos generales de sincronización, especialmente en el caso de reducciones no estructuradas. El modelo de ejecución de memoria compartida propuesto para HPF se basa en un pequeño conjunto de extensiones de lenguaje, que se asemejan a las características de trabajo compartido de OpenMP. Estas extensiones, junto con un modelo optimizado de paralelización y ejecución de memoria compartida, se han implementado en el sistema de compilación ADAPTOR HPF y los resultados experimentales verifican la eficiencia del enfoque elegido. ",
            "error": []
        },
        "shared memory systems": {
            "translated_key": "sistemas de memoria compartidos",
            "translated_annotated_text": "Programación paralela eficiente en \"sistemas de memoria compartidos\" escalables con Fortran OpenMP de alto rendimiento ofrece una interfaz de alto nivel para la programación paralela en arquitecturas de memoria compartida escalable (SMP). Proporciona al usuario directivas simples de trabajo compartido, mientras que confía en el compilador para generar programas paralelos basados en el paralelismo hilo. Sin embargo, la falta de características lingüísticas para explotar la localidad de datos a menudo resulta en un mal rendimiento ya que los tiempos de acceso a la memoria no uniforme en máquinas SMP escalables no pueden ser descuidados. Alto rendimiento Fortran (HPF), el estándar de facto para la programación paralela de datos, ofrece un rico conjunto de directivas de distribución de datos con el fin de explotar la localidad de datos, pero se ha dirigido principalmente a máquinas de memoria distribuida. En este artículo describimos un modelo de ejecución optimizado para programas HPF en máquinas SMP que se sirve de mecanismos proporcionados por OpenMP para compartir trabajo e hilo paralelismo, mientras se explota la localidad de datos basada en directivas de distribución especificadas por el usuario. La localidad de datos no sólo garantiza que la mayoría de los accesos de memoria están cerca de los hilos de ejecución y por lo tanto son más rápidos, sino que también minimiza los gastos generales de sincronización, especialmente en el caso de reducciones no estructuradas. El modelo de ejecución de memoria compartida propuesto para HPF se basa en un pequeño conjunto de extensiones de lenguaje, que se asemejan a las características de trabajo compartido de OpenMP. Estas extensiones, junto con un modelo optimizado de paralelización y ejecución de memoria compartida, se han implementado en el sistema de compilación ADAPTOR HPF y los resultados experimentales verifican la eficiencia del enfoque elegido. ",
            "error": [
                ""
            ]
        }
    }
}