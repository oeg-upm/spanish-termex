{"Artificial Neural Networks (ANN) have been widely used in science and engineering problems. They attempt to model the ability of biological nervous systems to recognize patterns and objects. ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa. Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996). During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error. Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996). We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer.": "Las redes neuronales artificiales (ANN) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Tha. Diferentes tipos de funciones primitivas y configuraciones de red resultan en diferentes modelos (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento se ajustan los pesos de conexión de red si la separación de entradas y clases predefinidas incurre en un error. La convergencia avanza hasta que la reducción del error entre las iteraciones alcanza un umbral de desintegración (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de avance con una sola capa oculta de nodos, un Perceptrón Multi-Layer (MLP) (Venables y Ripley, 2002), y seleccionamos uno de los dos posibles parámetros: tamaño, el número de nodos en la capa oculta."}