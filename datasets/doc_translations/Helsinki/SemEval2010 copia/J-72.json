{
    "original_text": "Applying Learning Algorithms to Preference Elicitation Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from learning theory. We show that learning algorithms can be used as a basis for preference elicitation algorithms. The resulting elicitation algorithms perform a polynomial number of queries. We also give conditions under which the resulting algorithms have polynomial communication. Our conversion procedure allows us to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions. In particular, we obtain an algorithm that elicits XOR bids with polynomial communication. Categories and Subject Descriptors F.2.0 [Analysis of Algorithms and Problem Complexity]: General; J.4 [Social and Behavioral Sciences]: Economics; I.2.6 [Artificial Intelligence]: Learning General Terms Algorithms, Economics, Theory 1. INTRODUCTION In a combinatorial auction, agents may bid on bundles of goods rather than individual goods alone. Since there are an exponential number of bundles (in the number of goods), communicating values over these bundles can be problematic. Communicating valuations in a one-shot fashion can be prohibitively expensive if the number of goods is only moderately large. Furthermore, it might even be hard for agents to determine their valuations for single bundles [14]. It is in the interest of such agents to have auction protocols which require them to bid on as few bundles as possible. Even if agents can efficiently compute their valuations, they might still be reluctant to reveal them entirely in the course of an auction, because such information may be valuable to their competitors. These considerations motivate the need for auction protocols that minimize the communication and information revelation required to determine an optimal allocation of goods. There has been recent work exploring the links between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from computational learning theory [5, 19]. In learning theory, the goal is to learn a function via various types of queries, such as What is the functions value on these inputs? In preference elicitation, the goal is to elicit enough partial information about preferences to be able to compute an optimal allocation. Though the goals of learning and preference elicitation differ somewhat, it is clear that these problems share similar structure, and it should come as no surprise that techniques from one field should be relevant to the other. We show that any exact learning algorithm with membership and equivalence queries can be converted into a preference elicitation algorithm with value and demand queries. The resulting elicitation algorithm guarantees elicitation in a polynomial number of value and demand queries. Here we mean polynomial in the number of goods, agents, and the sizes of the agents valuation functions in a given encoding scheme. Preference elicitation schemes have not traditionally considered this last parameter. We argue that complexity guarantees for elicitation schemes should allow dependence on this parameter. Introducing this parameter also allows us to guarantee polynomial worst-case communication, which usually cannot be achieved in the number of goods and agents alone. Finally, we use our conversion procedure to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions. Of course, a one-shot combinatorial auction where agents provide their entire valuation functions at once would also have polynomial communication in the size of the agents valuations, and only require one query. The advantage of our scheme is that agents can be viewed as black-boxes that provide incremental information about their valuations. There is no burden on the agents to formulate their valuations in an encoding scheme of the auctioneers choosing. We expect this to be an important consideration in practice. Also, with our scheme entire revelation only happens in the worst-case. 180 For now, we leave the issue of incentives aside when deriving elicitation algorithms. Our focus is on the time and communication complexity of preference elicitation regardless of incentive constraints, and on the relationship between the complexities of learning and preference elicitation. Related work. Zinkevich et al. [19] consider the problem of learning restricted classes of valuation functions which can be represented using read-once formulas and Toolbox DNF. Read-once formulas can represent certain substitutabilities, but no complementarities, whereas the opposite holds for Toolbox DNF. Since their work is also grounded in learning theory, they allow dependence on the size of the target valuation as we do (though read-once valuations can always be succinctly represented anyway). Their work only makes use of value queries, which are quite limited in power. Because we allow ourselves demand queries, we are able to derive an elicitation scheme for general valuation functions. Blum et al. [5] provide results relating the complexities of query learning and preference elicitation. They consider models with membership and equivalence queries in query learning, and value and demand queries in preference elicitation. They show that certain classes of functions can be efficiently learned yet not efficiently elicited, and vice-versa. In contrast, our work shows that given a more general (yet still quite standard) version of demand query than the type they consider, the complexity of preference elicitation is no greater than the complexity of learning. We will show that demand queries can simulate equivalence queries until we have enough information about valuations to imply a solution to the elicitation problem. Nisan and Segal [12] study the communication complexity of preference elicitation. They show that for many rich classes of valuations, the worst-case communication complexity of computing an optimal allocation is exponential. Their results apply to the black-box model of computational complexity. In this model algorithms are allowed to ask questions about agent valuations and receive honest responses, without any insight into how the agents internally compute their valuations. This is in fact the basic framework of learning theory. Our work also addresses the issue of communication complexity, and we are able to derive algorithms that provide significant communication guarantees despite Nisan and Segals negative results. Their work motivates the need to rely on the sizes of agents valuation functions in stating worst-case results. 2. THE MODELS 2.1 Query Learning The query learning model we consider here is called exact learning from membership and equivalence queries, introduced by Angluin [2]. In this model the learning algorithms objective is to exactly identify an unknown target function f : X → Y via queries to an oracle. The target function is drawn from a function class C that is known to the algorithm. Typically the domain X is some subset of {0, 1}m , and the range Y is either {0, 1} or some subset of the real numbers Ê. As the algorithm progresses, it constructs a manifest hypothesis ˜f which is its current estimate of the target function. Upon termination, the manifest hypothesis of a correct learning algorithm satisfies ˜f(x) = f(x) for all x ∈ X. It is important to specify the representation that will be used to encode functions from C. For example, consider the following function from {0, 1}m to Ê: f(x) = 2 if x consists of m 1s, and f(x) = 0 otherwise. This function may simply be represented as a list of 2m values. Or it may be encoded as the polynomial 2x1 · · · xm, which is much more succinct. The choice of encoding may thus have a significant impact on the time and space requirements of the learning algorithm. Let size(f) be the size of the encoding of f with respect to the given representation class. Most representation classes have a natural measure of encoding size. The size of a polynomial can be defined as the number of non-zero coefficients in the polynomial, for example. We will usually only refer to representation classes; the corresponding function classes will be implied. For example, the representation class of monotone DNF formulae implies the function class of monotone Boolean functions. Two types of queries are commonly used for exact learning: membership and equivalence queries. On a membership query, the learner presents some x ∈ X and the oracle replies with f(x). On an equivalence query, the learner presents its manifest hypothesis ˜f. The oracle either replies YES if ˜f = f, or returns a counterexample x such that ˜f(x) = f(x). An equivalence query is proper if size( ˜f) ≤ size(f) at the time the manifest hypothesis is presented. We are interested in efficient learning algorithms. The following definitions are adapted from Kearns and Vazirani [9]: Definition 1. The representation class C is polynomialquery exactly learnable from membership and equivalence queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to membership and equivalence queries of an oracle such that for any target function f ∈ C, L outputs after at most p(size(f), m) queries a function ˜f ∈ C such that ˜f(x) = f(x) for all instances x. Similarly, the representation class C is efficiently exactly learnable from membership and equivalence queries if the algorithm L outputs a correct hypothesis in time p(size(f), m), for some fixed polynomial p(·, ·). Here m is the dimension of the domain. Since the target function must be reconstructed, we also necessarily allow polynomial dependence on size(f). 2.2 Preference Elicitation In a combinatorial auction, a set of goods M is to be allocated among a set of agents N so as to maximize the sum of the agents valuations. Such an allocation is called efficient in the economics literature, but we will refer to it as optimal and reserve the term efficient to refer to computational efficiency. We let n = |N| and m = |M|. An allocation is a partition of the objects into bundles (S1, . . . , Sn), such that Si ∩ Sj = ∅ for all distinct i, j ∈ N. Let Γ be the set of possible allocations. Each agent i ∈ N has a valuation function vi : 2M → Ê over the space of possible bundles. Each valuation vi is drawn from a known class of valuations Vi. The valuation classes do not need to coincide. We will assume that all the valuations considered are normalized, meaning v(∅) = 0, and that there are no externalities, meaning vi(S1, ..., Sn) = vi(Si), for all agents i ∈ N, for any allocation (S1, ..., Sn) ∈ Γ (that is, an agent cares only about the bundle allocated to her). Valuations satisfying these conditions are called general valuations.1 We 1 Often general valuations are made to satisfy the additional 181 also assume that agents have quasi-linear utility functions, meaning that agents utilities can be divided into monetary and non-monetary components. If an agent i is allocated bundle S at price p, it derives utility ui(S, p) = vi(S) − p. A valuation function may be viewed as a vector of 2m − 1 non-negative real-values. Of course there may also be more succinct representations for certain valuation classes, and there has been much research into concise bidding languages for various types of valuations [11]. A classic example which we will refer to again later is the XOR bidding language. In this language, the agent provides a list of atomic bids, which consist of a bundle together with its value. To determine the value of a bundle S given these bids, one searches for the bundle S of highest value listed in the atomic bids such that S ⊆ S. It is then the case that v(S) = v(S ). As in the learning theory setting, we will usually only refer to bidding languages rather than valuation classes, because the corresponding valuation classes will then be implied. For example, the XOR bidding language implies the class of valuations satisfying free-disposal, which is the condition that A ⊆ B ⇒ v(A) ≤ v(B). We let size(v1, . . . , vn) = Èn i=1 size(vi). That is, the size of a vector of valuations is the size of the concatenation of the valuations representations in their respective encoding schemes (bidding languages). To make an analogy to computational learning theory, we assume that all representation classes considered are polynomially interpretable [11], meaning that the value of a bundle may be computed in polynomial time given the valuation functions representation. More formally, a representation class (bidding language) C is polynomially interpretable if there exists an algorithm that given as input some v ∈ C and an instance x ∈ X computes the value v(x) in time q(size(v), m), for some fixed polynomial q(·, ·).2 In the intermediate rounds of an (iterative) auction, the auctioneer will have elicited information about the agents valuation functions via various types of queries. She will thus have constructed a set of manifest valuations, denoted ˜v1, . . . , ˜vn.3 The values of these functions may correspond exactly to the true agent values, or they may for example be upper or lower bounds on the true values, depending on the types of queries made. They may also simply be default or random values if no information has been acquired about certain bundles. The goal in the preference elicitation problem is to construct a set of manifest valuations such that: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) That is, the manifest valuations provide enough information to compute an allocation that is optimal with respect to the true valuations. Note that we only require one such optimal allocation. condition of free-disposal (monotonicity), but we do not need it at this point. 2 This excludes OR∗ , assuming P = NP, because interpreting bids from this language is NP-hard by reduction from weighted set-packing, and there is no well-studied representation class in learning theory that is clearly analogous to OR∗ . 3 This view of iterative auctions is meant to parallel the learning setting. In many combinatorial auctions, manifest valuations are not explicitly maintained but rather simply implied by the history of bids. Two typical queries used in preference elicitation are value and demand queries. On a value query, the auctioneer presents a bundle S ⊆ M and the agent responds with her (exact) value for the bundle v(S) [8]. On a demand query, the auctioneer presents a vector of non-negative prices p ∈ Ê(2m ) over the bundles together with a bundle S. The agent responds YES if it is the case that S ∈ arg max S ⊆M   v(S ) − p(S ) ¡ or otherwise presents a bundle S such that v(S ) − p(S ) > v(S) − p(S) That is, the agent either confirms that the presented bundle is most preferred at the quoted prices, or indicates a better one [15].4 Note that we include ∅ as a bundle, so the agent will only respond YES if its utility for the proposed bundle is non-negative. Note also that communicating nonlinear prices does not necessarily entail quoting a price for every possible bundle. There may be more succinct ways of communicating this vector, as we show in section 5. We make the following definitions to parallel the query learning setting and to simplify the statements of later results: Definition 2. The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to value and demand queries of the agents such that for any (v1, . . . , vn) ∈ V1 × . . . × Vn, L outputs after at most p(size(v1, . . . , vn), m) queries an allocation (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si). Similarly, the representation class C can be efficiently elicited from value and demand queries if the algorithm L outputs an optimal allocation with communication p(size(v1, . . . , vn), m), for some fixed polynomial p(·, ·). There are some key differences here with the query learning definition. We have dropped the term exactly since the valuation functions need not be determined exactly in order to compute an optimal allocation. Also, an efficient elicitation algorithm is polynomial communication, rather than polynomial time. This reflects the fact that communication rather than runtime is the bottleneck in elicitation. Computing an optimal allocation of goods even when given the true valuations is NP-hard for a wide range of valuation classes. It is thus unreasonable to require polynomial time in the definition of an efficient preference elicitation algorithm. We are happy to focus on the communication complexity of elicitation because this problem is widely believed to be more significant in practice than that of winner determination [11].5 4 This differs slightly from the definition provided by Blum et al. [5] Their demand queries are restricted to linear prices over the goods, where the price of a bundle is the sum of the prices of its underlying goods. In contrast our demand queries allow for nonlinear prices, i.e. a distinct price for every possible bundle. This is why the lower bound in their Theorem 2 does not contradict our result that follows. 5 Though the winner determination problem is NP-hard for general valuations, there exist many algorithms that solve it efficiently in practice. These range from special purpose algorithms [7, 16] to approaches using off-the-shelf IP solvers [1]. 182 Since the valuations need not be elicited exactly it is initially less clear whether the polynomial dependence on size(v1, . . . , vn) is justified in this setting. Intuitively, this parameter is justified because we must learn valuations exactly when performing elicitation, in the worst-case. We address this in the next section. 3. PARALLELSBETWEEN EQUIVALENCE AND DEMAND QUERIES We have described the query learning and preference elicitation settings in a manner that highlights their similarities. Value and membership queries are clear analogs. Slightly less obvious is the fact that equivalence and demand queries are also analogs. To see this, we need the concept of Lindahl prices. Lindahl prices are nonlinear and non-anonymous prices over the bundles. They are nonlinear in the sense that each bundle is assigned a price, and this price is not necessarily the sum of prices over its underlying goods. They are non-anonymous in the sense that two agents may face different prices for the same bundle of goods. Thus Lindahl prices are of the form pi(S), for all S ⊆ M, for all i ∈ N. Lindahl prices are presented to the agents in demand queries. When agents have normalized quasi-linear utility functions, Bikhchandani and Ostroy [4] show that there always exist Lindahl prices such that (S1, . . . , Sn) is an optimal allocation if and only if Si ∈ arg max Si   vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) Condition (1) states that each agent is allocated a bundle that maximizes its utility at the given prices. Condition (2) states that the allocation maximizes the auctioneers revenue at the given prices. The scenario in which these conditions hold is called a Lindahl equilibrium, or often a competitive equilibrium. We say that the Lindahl prices support the optimal allocation. It is therefore sufficient to announce supporting Lindahl prices to verify an optimal allocation. Once we have found an allocation with supporting Lindahl prices, the elicitation problem is solved. The problem of finding an optimal allocation (with respect to the manifest valuations) can be formulated as a linear program whose solutions are guaranteed to be integral [4]. The dual variables to this linear program are supporting Lindahl prices for the resulting allocation. The objective function to the dual program is: min pi(S) πs + i∈N πi (3) with πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) The optimal values of πi and πs correspond to the maximal utility to agent i with respect to its manifest valuation and the maximal revenue to the seller. There is usually a range of possible Lindahl prices supporting a given optimal allocation. The agents manifest valuations are in fact valid Lindahl prices, and we refer to them as maximal Lindahl prices. Out of all possible vectors of Lindahl prices, maximal Lindahl prices maximize the utility of the auctioneer, in fact giving her the entire social welfare. Conversely, prices that maximize the È i∈N πi component of the objective (the sum of the agents utilities) are minimal Lindahl prices. Any Lindahl prices will do for our results, but some may have better elicitation properties than others. Note that a demand query with maximal Lindahl prices is almost identical to an equivalence query, since in both cases we communicate the manifest valuation to the agent. We leave for future work the question of which Lindahl prices to choose to minimize preference elicitation. Considering now why demand and equivalence queries are direct analogs, first note that given the πi in some Lindahl equilibrium, setting pi(S) = max{0, ˜vi(S) − πi} (4) for all i ∈ N and S ⊆ M yields valid Lindahl prices. These prices leave every agent indifferent across all bundles with positive price, and satisfy condition (1). Thus demand queries can also implicitly communicate manifest valuations, since Lindahl prices will typically be an additive constant away from these by equality (4). In the following lemma we show how to obtain counterexamples to equivalence queries through demand queries. Lemma 1. Suppose an agent replies with a preferred bundle S when proposed a bundle S and supporting Lindahl prices p(S) (supporting with respect to the the agents manifest valuation). Then either ˜v(S) = v(S) or ˜v(S ) = v(S ). Proof. We have the following inequalities: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) Inequality (5) holds because the prices support the proposed allocation with respect to the manifest valuation. Inequality (6) holds because the agent in fact prefers S to S given the prices, according to its response to the demand query. If it were the case that ˜v(S) = v(S) and ˜v(S ) = v(S ), these inequalities would represent a contradiction. Thus at least one of S and S is a counterexample to the agents manifest valuation. Finally, we justify dependence on size(v1, . . . , vn) in elicitation problems. Nisan and Segal (Proposition 1, [12]) and Parkes (Theorem 1, [13]) show that supporting Lindahl prices must necessarily be revealed in the course of any preference elicitation protocol which terminates with an optimal allocation. Furthermore, Nisan and Segal (Lemma 1, [12]) state that in the worst-case agents prices must coincide with their valuations (up to a constant), when the valuation class is rich enough to contain dual valuations (as will be the case with most interesting classes). Since revealing Lindahl prices is a necessary condition for establishing an optimal allocation, and since Lindahl prices contain the same information as valuation functions (in the worst-case), allowing for dependence on size(v1, . . . , vn) in elicitation problems is entirely natural. 183 4. FROM LEARNING TO PREFERENCE ELICITATION The key to converting a learning algorithm to an elicitation algorithm is to simulate equivalence queries with demand and value queries until an optimal allocation is found. Because of our Lindahl price construction, when all agents reply YES to a demand query, we have found an optimal allocation, analogous to the case where an agent replies YES to an equivalence query when the target function has been exactly learned. Otherwise, we can obtain a counterexample to an equivalence query given an agents response to a demand query. Theorem 1. The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if they can each be polynomial-query exactly learned from membership and equivalence queries. Proof. Consider the elicitation algorithm in Figure 1. Each membership query in step 1 is simulated with a value query since these are in fact identical. Consider step 4. If all agents reply YES, condition (1) holds. Condition (2) holds because the computed allocation is revenue-maximizing for the auctioneer, regardless of the agents true valuations. Thus an optimal allocation has been found. Otherwise, at least one of Si or Si is a counterexample to ˜vi, by Lemma 1. We identify a counterexample by performing value queries on both these bundles, and provide it to Ai as a response to its equivalence query. This procedure will halt, since in the worst-case all agent valuations will be learned exactly, in which case the optimal allocation and Lindahl prices will be accepted by all agents. The procedure performs a polynomial number of queries, since A1, . . . , An are all polynomial-query learning algorithms. Note that the conversion procedure results in a preference elicitation algorithm, not a learning algorithm. That is, the resulting algorithm does not simply learn the valuations exactly, then compute an optimal allocation. Rather, it elicits partial information about the valuations through value queries, and periodically tests whether enough information has been gathered by proposing an allocation to the agents through demand queries. It is possible to generate a Lindahl equilibrium for valuations v1, . . . , vn using an allocation and prices derived using manifest valuations ˜v1, . . . , ˜vn, and finding an optimal allocation does not imply that the agents valuations have been exactly learned. The use of demand queries to simulate equivalence queries enables this early halting. We would not obtain this property with equivalence queries based on manifest valuations. 5. COMMUNICATION COMPLEXITY In this section, we turn to the issue of the communication complexity of elicitation. Nisan and Segal [12] show that for a variety of rich valuation spaces (such as general and submodular valuations), the worst-case communication burden of determining Lindahl prices is exponential in the number of goods, m. The communication burden is measured in terms of the number of bits transmitted between agents and auctioneer in the case of discrete communication, or in terms of the number of real numbers transmitted in the case of continuous communication. Converting efficient learning algorithms to an elicitation algorithm produces an algorithm whose queries have sizes polynomial in the parameters m and size(v1, . . . , vn). Theorem 2. The representation classes V1, . . . , Vn can be efficiently elicited from value and demand queries if they can each be efficiently exactly learned from membership and equivalence queries. Proof. The size of any value query is O(m): the message consists solely of the queried bundle. To communicate Lindahl prices to agent i, it is sufficient to communicate the agents manifest valuation function and the value πi, by equality (4). Note that an efficient learning algorithm never builds up a manifest hypothesis of superpolynomial size, because the algorithms runtime would then also be superpolynomial, contradicting efficiency. Thus communicating the manifest valuation requires size at most p(size(vi), m), for some polynomial p that upper-bounds the runtime of the efficient learning algorithm. Representing the surplus πi to agent i cannot require space greater than q(size(˜vi), m) for some fixed polynomial q, because we assume that the chosen representation is polynomially interpretable, and thus any value generated will be of polynomial size. We must also communicate to i its allocated bundle, so the total message size for a demand query is at most p(size(vi), m) + q(p(size(vi), m), m)+O(m). Clearly, an agents response to a value or demand query has size at most q(size(vi), m) + O(m). Thus the value and demand queries, and the responses to these queries, are always of polynomial size. An efficient learning algorithm performs a polynomial number of queries, so the total communication of the resulting elicitation algorithm is polynomial in the relevant parameters. There will often be explicit bounds on the number of membership and equivalence queries performed by a learning algorithm, with constants that are not masked by big-O notation. These bounds can be translated to explicit bounds on the number of value and demand queries made by the resulting elicitation algorithm. We upper-bounded the size of the manifest hypothesis with the runtime of the learning algorithm in Theorem 2. We are likely to be able to do much better than this in practice. Recall that an equivalence query is proper if size( ˜f) ≤ size(f) at the time the query is made. If the learning algorithms equivalence queries are all proper, it may then also be possible to provide tight bounds on the communication requirements of the resulting elicitation algorithm. Theorem 2 show that elicitation algorithms that depend on the size(v1, . . . , vn) parameter sidestep Nisan and Segals [12] negative results on the worst-case communication complexity of efficient allocation problems. They provide guarantees with respect to the sizes of the instances of valuation functions faced at any run of the algorithm. These algorithms will fare well if the chosen representation class provides succinct representations for the simplest and most common of valuations, and thus the focus moves back to one of compact yet expressive bidding languages. We consider these issues below. 6. APPLICATIONS In this section, we demonstrate the application of our methods to particular representation classes for combinatorial valuations. We have shown that the preference elicitation problem for valuation classes V1, . . . , Vn can be reduced 184 Given: exact learning algorithms A1, . . . , An for valuations classes V1, . . . , Vn respectively. Loop until there is a signal to halt: 1. Run A1, . . . , An in parallel on their respective agents until each requires a response to an equivalence query, or has halted with the agents exact valuation. 2. Compute an optimal allocation (S1, . . . , Sn) and corresponding Lindahl prices with respect to the manifest valuations ˜v1, . . . , ˜vn determined so far. 3. Present the allocation and prices to the agents in the form of a demand query. 4. If they all reply YES, output the allocation and halt. Otherwise there is some agent i that has replied with some preferred bundle Si. Perform value queries on Si and Si to find a counterexample to ˜vi, and provide it to Ai. Figure 1: Converting learning algorithms to an elicitation algorithm. to the problem of finding an efficient learning algorithm for each of these classes separately. This is significant because there already exist learning algorithms for a wealth of function classes, and because it may often be simpler to solve each learning subproblem separately than to attack the preference elicitation problem directly. We can develop an elicitation algorithm that is tailored to each agents valuation, with the underlying learning algorithms linked together at the demand query stages in an algorithm-independent way. We show that existing learning algorithms for polynomials, monotone DNF formulae, and linear-threshold functions can be converted into preference elicitation algorithms for general valuations, valuations with free-disposal, and valuations with substitutabilities, respectively. We focus on representations that are polynomially interpretable, because the computational learning theory literature places a heavy emphasis on computational tractability [18]. In interpreting the methods we emphasize the expressiveness and succinctness of each representation class. The representation class, which in combinatorial auction terms defines a bidding language, must necessarily be expressive enough to represent all possible valuations of interest, and should also succinctly represent the simplest and most common functions in the class. 6.1 Polynomial Representations Schapire and Sellie [17] give a learning algorithm for sparse multivariate polynomials that can be used as the basis for a combinatorial auction protocol. The equivalence queries made by this algorithm are all proper. Specifically, their algorithm learns the representation class of t-sparse multivariate polynomials over the real numbers, where the variables may take on values either 0 or 1. A t-sparse polynomial has at most t terms, where a term is a product of variables, e.g. x1x3x4. A polynomial over the real numbers has coefficients drawn from the real numbers. Polynomials are expressive: every valuation function v : 2M → Ê+ can be uniquely written as a polynomial [17]. To get an idea of the succinctness of polynomials as a bidding language, consider the additive and single-item valuations presented by Nisan [11]. In the additive valuation, the value of a bundle is the number of goods the bundle contains. In the single-item valuation, all bundles have value 1, except ∅ which has value 0 (i.e. the agent is satisfied as soon as it has acquired a single item). It is not hard to show that the single-item valuation requires polynomials of size 2m − 1, while polynomials of size m suffice for the additive valuation. Polynomials are thus appropriate for valuations that are mostly additive, with a few substitutabilities and complementarities that can be introduced by adjusting coefficients. The learning algorithm for polynomials makes at most mti +2 equivalence queries and at most (mti +1)(t2 i +3ti)/2 membership queries to an agent i, where ti is the sparcity of the polynomial representing vi [17]. We therefore obtain an algorithm that elicits general valuations with a polynomial number of queries and polynomial communication.6 6.2 XOR Representations The XOR bidding language is standard in the combinatorial auctions literature. Recall that an XOR bid is characterized by a set of bundles B ⊆ 2M and a value function w : B → Ê+ defined on those bundles, which induces the valuation function: v(B) = max {B ∈B | B ⊆B} w(B ) (7) XOR bids can represent valuations that satisfy free-disposal (and only such valuations), which again is the property that A ⊆ B ⇒ v(A) ≤ v(B). The XOR bidding language is slightly less expressive than polynomials, because polynomials can represent valuations that do not satisfy free-disposal. However, XOR is as expressive as required in most economic settings. Nisan [11] notes that XOR bids can represent the single-item valuation with m atomic bids, but 2m − 1 atomic bids are needed to represent the additive valuation. Since the opposite holds for polynomials, these two languages are incomparable in succinctness, and somewhat complementary for practical use. Blum et al. [5] note that monotone DNF formulae are the analogs of XOR bids in the learning theory literature. A monotone DNF formula is a disjunction of conjunctions in which the variables appear unnegated, for example x1x2 ∨ x3 ∨ x2x4x5. Note that such formulae can be represented as XOR bids where each atomic bid has value 1; thus XOR bids generalize monotone DNF formulae from Boolean to real-valued functions. These insights allow us to generalize a classic learning algorithm for monotone DNF ([3] Theorem 6 Note that Theorem 1 applies even if valuations do not satisfy free-disposal. 185 1, [18] Theorem B) to a learning algorithm for XOR bids.7 Lemma 2. An XOR bid containing t atomic bids can be exactly learned with t + 1 equivalence queries and at most tm membership queries. Proof. The algorithm will identify each atomic bid in the target XOR bid in turn. Initialize the manifest valuation ˜v to the bid that is identically zero on all bundles (this is an XOR bid containing 0 atomic bids). Present ˜v as an equivalence query. If the response is YES, we are done. Otherwise we obtain a bundle S for which v(S) = ˜v(S). Create a bundle T as follows. First initialize T = S. For each item i in T, check via a membership query whether v(T) = v(T − {i}). If so set T = T − {i}. Otherwise leave T as is and proceed to the next item. We claim that (T, v(T)) is an atomic bid of the target XOR bid. For each item i in T, we have v(T) = v(T − {i}). To see this, note that at some point when generating T, we had a ¯T such that T ⊆ ¯T ⊆ S and v( ¯T) > v( ¯T − {i}), so that i was kept in ¯T. Note that v(S) = v( ¯T) = v(T) because the value of the bundle S is maintained throughout the process of deleting items. Now assume v(T) = v(T − {i}). Then v( ¯T) = v(T) = v(T − {i}) > v( ¯T − {i}) which contradicts free-disposal, since T − {i} ⊆ ¯T − {i}. Thus v(T) > v(T − {i}) for all items i in T. This implies that (T, v(T)) is an atomic bid of v. If this were not the case, T would take on the maximum value of its strict subsets, by the definition of an XOR bid, and we would have v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T) which is a contradiction. We now show that v(T) = ˜v(T), which will imply that (T, v(T)) is not an atomic bid of our manifest hypothesis by induction. Assume that every atomic bid (R, ˜v(R)) identified so far is indeed an atomic bid of v (meaning R is indeed listed in an atomic bid of v as having value v(R) = ˜v(R)). This assumption holds vacuously when the manifest valuation is initialized. Using the notation from (7), let ( ˜B, ˜w) be our hypothesis, and (B, w) be the target function. We have ˜B ⊆ B, and ˜w(B) = w(B) for B ∈ ˜B by assumption. Thus, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Now assume v(T) = ˜v(T). Then, ˜v(T) = v(T) = v(S) = ˜v(S) (9) The second equality follows from the fact that the value remains constant when we derive T from S. The last inequality holds because S is a counterexample to the manifest valuation. From equation (9) and free-disposal, we 7 The cited algorithm was also used as the basis for Zinkevich et al.s [19] elicitation algorithm for Toolbox DNF. Recall that Toolbox DNF are polynomials with non-negative coefficients. For these representations, an equivalence query can be simulated with a value query on the bundle containing all goods. have ˜v(T) < ˜v(S). Then again from equation (9) it follows that v(S) < ˜v(S). This contradicts (8), so we in fact have v(T) = ˜v(T). Thus (T, v(T)) is not currently in our hypothesis as an atomic bid, or we would correctly have ˜v(T) = v(T) by the induction hypothesis. We add (T, v(T)) to our hypothesis and repeat the process above, performing additional equivalence queries until all atomic bids have been identified. After each equivalence query, an atomic bid is identified with at most m membership queries. Each counterexample leads to the discovery of a new atomic bid. Thus we make at most tm membership queries and exactly t + 1 equivalence queries. The number of time steps required by this algorithm is essentially the same as the number of queries performed, so the algorithm is efficient. Applying Theorem 2, we therefore obtain the following corollary: Theorem 3. The representation class of XOR bids can be efficiently elicited from value and demand queries. This contrasts with Blum et al.s negative results ([5], Theorem 2) stating that monotone DNF (and hence XOR bids) cannot be efficiently elicited when the demand queries are restricted to linear and anonymous prices over the goods. 6.3 Linear-Threshold Representations Polynomials, XOR bids, and all languages based on the OR bidding language (such as XOR-of-OR, OR-of-XOR, and OR∗ ) fail to succinctly represent the majority valuation [11]. In this valuation, bundles have value 1 if they contain at least m/2 items, and value 0 otherwise. More generally, consider the r-of-S family of valuations where bundles have value 1 if they contain at least r items from a specified set of items S ⊆ M, and value 0 otherwise. The majority valuation is a special case of the r-of-S valuation with r = m/2 and S = M. These valuations are appropriate for representing substitutabilities: once a required set of items has been obtained, no other items can add value. Letting k = |S|, such valuations are succinctly represented by r-of-k threshold functions. These functions take the form of linear inequalities: xi1 + . . . + xik ≥ r where the function has value 1 if the inequality holds, and 0 otherwise. Here i1, . . . , ik are the items in S. Littlestones WINNOW 2 algorithm can learn such functions using equivalence queries only, using at most 8r2 + 5k + 14kr ln m + 1 queries [10]. To provide this guarantee, r must be known to the algorithm, but S (and k) are unknown. The elicitation algorithm that results from WINNOW 2 uses demand queries only (value queries are not necessary here because the values of counterexamples are implied when there are only two possible values). Note that r-of-k threshold functions can always be succinctly represented in O(m) space. Thus we obtain an algorithm that can elicit such functions with a polynomial number of queries and polynomial communication, in the parameters n and m alone. 186 7. CONCLUSIONS AND FUTURE WORK We have shown that exact learning algorithms with membership and equivalence queries can be used as a basis for preference elicitation algorithms with value and demand queries. At the heart of this result is the fact that demand queries may be viewed as modified equivalence queries, specialized to the problem of preference elicitation. Our result allows us to apply the wealth of available learning algorithms to the problem of preference elicitation. A learning approach to elicitation also motivates a different approach to designing elicitation algorithms that decomposes neatly across agent types. If the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design learning algorithms tailored to each agents valuations and integrate them into an elicitation scheme. The resulting elicitation algorithm makes a polynomial number of queries, and makes polynomial communication if the original learning algorithms are efficient. We do not require that agent valuations can be learned with value and demand queries. Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed. This is the preference elicitation problem. Theorem 1 implies that elicitation with value and demand queries is no harder than learning with membership and equivalence queries, but it does not provide any asymptotic improvements over the learning algorithms complexity. It would be interesting to find examples of valuation classes for which elicitation is easier than learning. Blum et al. [5] provide such an example when considering membership/value queries only (Theorem 4). In future work we plan to address the issue of incentives when converting learning algorithms to elicitation algorithms. In the learning setting, we usually assume that oracles will provide honest responses to queries; in the elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility. We also plan to implement the algorithms for learning polynomials and XOR bids as elicitation algorithms, and test their performance against other established combinatorial auction protocols [6, 15]. An interesting question here is: which Lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation? We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence queries. Finally, it would be useful to determine whether the OR∗ bidding language [11] can be efficiently learned (and hence elicited), given this languages expressiveness and succinctness for a wide variety of valuation classes. Acknowledgements We would like to thank Debasis Mishra for helpful discussions. This work is supported in part by NSF grant IIS0238147. 8. REFERENCES [1] A. Andersson, M. Tenhunen, and F. Ygge. Integer programming for combinatorial auction winner determination. In Proceedings of the Fourth International Conference on Multiagent Systems (ICMAS-00), 2000. [2] D. Angluin. Learning regular sets from queries and counterexamples. Information and Computation, 75:87-106, November 1987. [3] D. Angluin. Queries and concept learning. Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani and J. Ostroy. The Package Assignment Model. Journal of Economic Theory, 107(2), December 2002. [5] A. Blum, J. Jackson, T. Sandholm, and M. Zinkevich. Preference elicitation and query learning. In Proc. 16th Annual Conference on Computational Learning Theory (COLT), Washington DC, 2003. [6] W. Conen and T. Sandholm. Partial-revelation VCG mechanism for combinatorial auctions. In Proc. the 18th National Conference on Artificial Intelligence (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, and Y. Shoham. Taming the computational complexity of combinatorial auctions: Optimal and approximate approaches. In Proc. the 16th International Joint Conference on Artificial Intelligence (IJCAI), pages 548-553, 1999. [8] B. Hudson and T. Sandholm. Using value queries in combinatorial auctions. In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. [9] M. J. Kearns and U. V. Vazirani. An Introduction to Computational Learning Theory. MIT Press, 1994. [10] N. Littlestone. Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm. Machine Learning, 2:285-318, 1988. [11] N. Nisan. Bidding and allocation in combinatorial auctions. In Proc. the ACM Conference on Electronic Commerce, pages 1-12, 2000. [12] N. Nisan and I. Segal. The communication requirements of efficient allocations and supporting Lindahl prices. Working Paper, Hebrew University, 2003. [13] D. C. Parkes. Price-based information certificates for minimal-revelation combinatorial auctions. In Padget et al., editor, Agent-Mediated Electronic Commerce IV,LNAI 2531, pages 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. Auction design with costly preference elicitation. In Special Issues of Annals of Mathematics and AI on the Foundations of Electronic Commerce, Forthcoming (2003). [15] D. C. Parkes and L. H. Ungar. Iterative combinatorial auctions: Theory and practice. In Proc. 17th National Conference on Artificial Intelligence (AAAI-00), pages 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin, and D. Levine. CABOB: A fast optimal algorithm for combinatorial auctions. In Proc. the 17th International Joint Conference on Artificial Intelligence (IJCAI), pages 1102-1108, 2001. [17] R. Schapire and L. Sellie. Learning sparse multivariate polynomials over a field with queries and counterexamples. In Proceedings of the Sixth Annual ACM Workshop on Computational Learning Theory, pages 17-26. ACM Press, 1993. 187 [18] L. Valiant. A theory of the learnable. Commun. ACM, 27(11):1134-1142, Nov. 1984. [19] M. Zinkevich, A. Blum, and T. Sandholm. On polynomial-time preference elicitation with value-queries. In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. 188",
    "original_translation": "Aplicando algoritmos de aprendizaje a la eliminación de preferencia Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de excitación Demostramos que los algoritmos de aprendizaje pueden ser usados como base para algoritmos de excitación de preferencias. Los algoritmos de excitación resultantes realizan un número polinomio de consultas. También damos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. En particular, se obtiene un algoritmo que provoca pujas XOR con comunicación polinómica. Categorías y Descriptores sujetos F.2.0 [Análisis de algoritmos y complejidad de problemas]: General; J.4 [Ciencias Sociales y Conductuales]: Economía; I.2.6 [Inteligencia Artificial]: Términos generales de aprendizaje Algoritmos, Economía, Teoría 1. INTRODUCCIÓN En una subasta combinatoria, los agentes pueden pujar por paquetes de bienes en lugar de por cada uno de ellos. Puesto que hay un número exponencial de paquetes (en el número de bienes), comunicar los valores sobre estos paquetes puede ser problemático. Comunicar las valoraciones de una sola vez puede ser prohibitivamente costoso si el número de bienes es sólo moderadamente grande. Además, incluso podría ser difícil para los agentes determinar sus valoraciones para paquetes únicos [14]. A esos agentes les interesa disponer de protocolos de subasta que les obliguen a pujar en el menor número posible de paquetes. Incluso si los agentes pueden calcular eficientemente sus valoraciones, podrían ser reacios a revelarlas enteramente en el curso de una subasta, porque tal información puede ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información necesaria para determinar una asignación óptima de los bienes. Ha habido un trabajo reciente explorando los vínculos entre el problema de la excitación de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje computacional [5, 19]. En teoría de aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, tales como ¿Cuál es el valor de las funciones en estas entradas? En la obtención de preferencia, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Demostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia se puede convertir en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de excitación resultante garantiza la excitación en un número polinomio de consultas de valor y demanda. Aquí queremos decir polinomio en el número de bienes, agentes, y los tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Argumentamos que las garantías de complejidad para los esquemas de excitación deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar la comunicación polinómica en el peor de los casos, que normalmente no se puede lograr en el número de productos y agentes por sí solos. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. Por supuesto, una subasta combinatoria de un solo disparo donde los agentes proporcionan todas sus funciones de valoración a la vez también tendría comunicación polinómica en el tamaño de las valoraciones de los agentes, y sólo requieren una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay ninguna carga para los agentes de formular sus valoraciones en un esquema de codificación de los subastadores que elijan. Esperamos que esta sea una consideración importante en la práctica. Además, con nuestro esquema la revelación entera sólo ocurre en el peor de los casos. 180 Por ahora, dejamos a un lado la cuestión de los incentivos al derivar algoritmos de excitación. Nos centramos en el tiempo y la complejidad de la comunicación de la obtención de preferencias, independientemente de las limitaciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich y otros [19] considerar el problema del aprendizaje de clases restringidas de funciones de valoración que se pueden representar utilizando fórmulas de lectura once y Toolbox DNF. Las fórmulas Read-once pueden representar ciertas sustitutibilidades, pero no complementariedades, mientras que lo contrario se mantiene para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten depender del tamaño de la valoración objetivo como lo hacemos (aunque las valoraciones de read-once siempre se pueden representar sucintamente de todos modos). Su trabajo sólo hace uso de consultas de valor, que son bastante limitados en el poder. Debido a que nos permitimos pedir consultas, somos capaces de derivar un esquema de excitación para las funciones de valoración general. Blum et al. [5] proporcionar resultados relacionados con las complejidades del aprendizaje de la consulta y la excitación de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje de consultas, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones se pueden aprender eficientemente, pero no se pueden obtener eficientemente, y viceversa. En contraste, nuestro trabajo muestra que dada una versión más general (todavía bastante estándar) de la consulta de demanda que el tipo que consideran, la complejidad de la excitación de preferencia no es mayor que la complejidad del aprendizaje. Demostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre valoraciones para implicar una solución al problema de excitación. Nisan y Segal [12] estudian la complejidad comunicativa de la excitación de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos de la computación una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo se permite a los algoritmos hacer preguntas sobre valoraciones de agentes y recibir respuestas honestas, sin ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda la cuestión de la complejidad de la comunicación, y somos capaces de derivar algoritmos que proporcionan garantías de comunicación significativas a pesar de los resultados negativos de Nisan y Segals. Su trabajo motiva la necesidad de confiar en el tamaño de los agentes funciones de valoración para indicar los peores resultados. 2. LOS MODELOS 2.1 Aprendizaje de la consulta El modelo de aprendizaje de la consulta que consideramos aquí se llama aprendizaje exacto de la membresía y consultas de equivalencia, introducido por Angluin [2]. En este modelo el objetivo de los algoritmos de aprendizaje es identificar exactamente una función diana desconocida f : X → Y a través de consultas a un oráculo. La función de destino se extrae de una función de clase C que es conocida por el algoritmo. Típicamente el dominio X es algún subconjunto de {0, 1}m, y el rango Y es {0, 1} o algún subconjunto de los números reales. A medida que el algoritmo avanza, construye una hipótesis manifiesta?f que es su estimación actual de la función de destino. Después de la terminación, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface?f(x) = f(x) para todos x?X. Es importante especificar la representación que se utilizará para codificar funciones de C. Por ejemplo, considere la siguiente función de {0, 1}m a ♥: f(x) = 2 si x consiste en m 1s, y f(x) = 0 de otra manera. Esta función puede representarse simplemente como una lista de valores de 2m. O puede codificarse como el polinomio 2x1 · · · xm, que es mucho más sucinto. Así pues, la elección de la codificación puede tener un impacto significativo en las necesidades de tiempo y espacio del algoritmo de aprendizaje. Let size(f) ser el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes distintos de cero en el polinomio, por ejemplo. Por lo general, sólo nos referiremos a las clases de representación; las clases de funciones correspondientes serán implícitas. Por ejemplo, la clase de representación de fórmulas DNF monotonas implica la clase de función de funciones booleanas monotonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: la membresía y las consultas de equivalencia. En una consulta de membresía, el aprendiz presenta algunas x x x y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta f. El oráculo responde SÍ si?f = f, o devuelve un contraejemplo x de tal manera que?f(x) = f(x). Una consulta de equivalencia es apropiada si el tamaño( ̃f) ≤ tamaño(f) en el momento de presentar la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones se adaptan a partir de Kearns y Vazirani [9]: Definición 1. La clase de representación C es polinomialquery exactamente aprendeble de las consultas de membresía y equivalencia si hay un polinomial fijo p(·, ·) y un algoritmo L con acceso a la membresía y consultas de equivalencia de un oráculo tal que para cualquier función de destino f • C, L salidas después de a lo sumo p(size(f), m) consultas de una función?f • C tal que?f Del mismo modo, la clase de representación C se puede aprender exactamente de las consultas de membresía y equivalencia si el algoritmo L produce una hipótesis correcta en el tiempo p(size(f), m), para algunos polinomios fijos p(·, ·). Aquí m es la dimensión del dominio. Dado que la función de destino debe ser reconstruida, también permitimos necesariamente la dependencia polinómica del tamaño (f). 2.2 Eliminación de preferencias En una subasta combinatoria, un conjunto de bienes M se asignará entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Tal asignación se llama eficiente en la literatura de economía, pero nos referiremos a ella como óptima y reservar el término eficiente para referirse a la eficiencia computacional. Dejamos n = N y m = M. Una asignación es una partición de los objetos en paquetes (S1,. . . , Sn), de tal manera que Si â € ¬ Sj = â € para todos los i, j â € N. Let â € € sea el conjunto de posibles asignaciones. Cada agente i+N tiene una función de valoración vi : 2M → • sobre el espacio de los paquetes posibles. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no tienen que coincidir. Asumimos que todas las valoraciones consideradas están normalizadas, es decir, v() = 0, y que no hay externalidades, es decir, vi(S1,..., Sn) = vi(Si), para todos los agentes i  N, para cualquier asignación (S1,..., Sn)  (es decir, un agente se preocupa sólo por el paquete asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales.1 Nosotros 1 A menudo las valoraciones generales se hacen para satisfacer los 181 adicionales también asumen que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que los agentes utilidades pueden ser divididos en componentes monetarios y no monetarios. Si a un agente i se le asigna el paquete S al precio p, deriva utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más sucintas para ciertas clases de valoración, y ha habido mucha investigación en lenguajes de licitación concisos para diversos tipos de valoraciones [11]. Un ejemplo clásico al que nos referiremos más adelante es el lenguaje de licitación XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, que consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estas pujas, se busca el paquete S del valor más alto listado en las pujas atómicas de tal manera que S  S. Es entonces el caso que v(S) = v(S). Al igual que en el contexto de la teoría del aprendizaje, por lo general sólo nos referiremos a idiomas de oferta en lugar de clases de valoración, ya que las clases de valoración correspondientes serán implícitas. Por ejemplo, el lenguaje de licitación XOR implica la clase de valoraciones que satisfacen la disposición libre, que es la condición de que A  B ♥ v(A) ≤ v(B). Dejamos el tamaño(v1,. . . , vn) = Èn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de licitación). Para hacer una analogía con la teoría del aprendizaje computacional, suponemos que todas las clases de representación consideradas son polinomiamente interpretables [11], lo que significa que el valor de un paquete puede ser calculado en tiempo polinomio dada la representación de funciones de valoración. Más formalmente, una clase de representación (lenguaje de licitación) C es polinomialmente interpretable si existe un algoritmo que da como entrada algunos v • C y una instancia x • X calcula el valor v(x) en el tiempo q(size(v), m), para algún polinomio fijo q(·, ·).2 En las rondas intermedias de una subasta (terativa), el subastador habrá obtenido información sobre las funciones de Por lo tanto, habrá construido un conjunto de valoraciones manifiestas, denotadas . . Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha adquirido información sobre ciertos paquetes. El objetivo en el problema de la excitación de preferencia es construir un conjunto de valoraciones manifiestas tales que: arg max (S1,...,Sn) iÃ3n Ã3vi(Si)  arg max (S1,...,Sn) iÃ3n vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que es óptima con respecto a las valoraciones verdaderas. Tenga en cuenta que sólo se requiere una asignación óptima. condición de la libre eliminación (monotonicidad), pero no la necesitamos en este punto. 2 Esto excluye OR*, asumiendo P = NP, porque la interpretación de las ofertas de este lenguaje es NP-duro por reducción de set-embalaje ponderado, y no hay clase de representación bien estudiada en teoría de aprendizaje que es claramente análogo a OR*. 3 Esta visión de las subastas iterativas tiene por objeto paralelizar el entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente están implícitas por la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son consultas de valor y demanda. En una consulta de valor, el subastador presenta un paquete S  M y el agente responde con su valor (exacto) para el paquete v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p • • • (2m ) sobre los paquetes junto con un paquete S. El agente responde SI si es el caso de que S • arg max S M v(S ) − p(S ) ¡ o de otro modo presenta un paquete S tal que v(S ) − p(S ) > v( Tenga en cuenta también que comunicar precios no lineales no implica necesariamente citar un precio por cada paquete posible. Puede haber formas más sucintas de comunicar este vector, como se muestra en la sección 5. Hacemos las siguientes definiciones para paralelizar la configuración de aprendizaje de la consulta y para simplificar las declaraciones de resultados posteriores: Definición 2. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si hay un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes tales que para cualquier (v1,. . . , vn) V1 ×. . . × Vn, L salidas después de como máximo p(size(v1,. . . , vn), m) consulta una asignación (S1,. . . , Sn) arg max(S1,...,Sn) È vi(Si). Del mismo modo, la clase de representación C se puede obtener eficientemente de las consultas de valor y demanda si el algoritmo L produce una asignación óptima con comunicación p(size(v1, ). . . , vn), m), para algunos polinomios fijos p(·, ·). Hay algunas diferencias clave aquí con la definición de aprendizaje de la consulta. Hemos eliminado el término exactamente ya que las funciones de valoración no necesitan ser determinadas exactamente con el fin de calcular una asignación óptima. Además, un algoritmo de excitación eficiente es la comunicación polinomio, en lugar de tiempo polinomio. Esto refleja el hecho de que la comunicación en lugar del tiempo de espera es el cuello de botella en la excitación. Cálculo de una asignación óptima de bienes incluso cuando se dan las valoraciones verdaderas es NP-duro para una amplia gama de clases de valoración. Por lo tanto, no es razonable exigir tiempo polinomio en la definición de un algoritmo de excitación de preferencias eficiente. Nos complace centrarnos en la complejidad comunicativa de la excitación porque se cree que este problema es más significativo en la práctica que el de la determinación del ganador [11].5 4 Esto difiere ligeramente de la definición proporcionada por Blum et al. [5] Sus consultas sobre la demanda se limitan a precios lineales sobre las mercancías, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir. un precio distinto por cada paquete posible. Es por eso que el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. 5 Aunque el problema de determinación del ganador es NP-hard para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta aproximaciones usando solucionadores IP fuera de la plataforma [1]. 182 Dado que no es necesario obtener exactamente las valoraciones, es inicialmente menos claro si la dependencia polinómica del tamaño (v1, ). . . , vn) está justificado en este contexto. Intuitivamente, este parámetro está justificado porque debemos aprender valoraciones exactamente cuando se realiza la excitación, en el peor de los casos. Nos ocupamos de esto en la siguiente sección. 3. PARALLESBETWEEN EQUIVALENCIA Y QUERIDAS DE DEMANDA Hemos descrito los ajustes de aprendizaje y excitación de preferencias de la consulta de una manera que destaca sus similitudes. Las consultas de valor y membresía son claras analógicas. Un poco menos obvio es el hecho de que las consultas de equivalencia y demanda también son analógicas. Para ver esto, necesitamos el concepto de precios Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios sobre sus bienes subyacentes. Son no anónimos en el sentido de que dos agentes pueden tener que hacer frente a precios diferentes para el mismo paquete de mercancías. Así los precios de Lindahl son de la forma pi(S), para todos S  M, para todos los precios de i  N. Lindahl se presentan a los agentes en consultas de la demanda. Cuando los agentes han normalizado las funciones de utilidad cuasi-lineal, Bikhchandani y Ostroy [4] muestran que siempre existen precios Lindahl tales que (S1,. . . , Sn) es una asignación óptima si y sólo si Si • arg max Si vi(Si) − pi(Si) • i N (1) (S1,. . . , Sn)  arg max (S1,...,Sn) iN pi(Si) (2) Condición (1) establece que cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos de los subastadores a los precios indicados. El escenario en el que se mantienen estas condiciones se llama equilibrio Lindahl, o a menudo un equilibrio competitivo. Decimos que los precios de Lindahl apoyan la asignación óptima. Por lo tanto, basta con anunciar los precios de apoyo de Lindahl para verificar una asignación óptima. Una vez que hemos encontrado una asignación con el apoyo de precios Lindahl, el problema de excitación se resuelve. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones estén garantizadas como integrales [4]. Las variables duales de este programa lineal están soportando los precios de Lindahl para la asignación resultante. La función objetiva del programa dual es: min pi(S) Por lo general, hay una gama de posibles precios Lindahl que apoyan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios válidos Lindahl, y nos referimos a ellos como precios máximos Lindahl. De todos los vectores posibles de precios Lindahl, precios máximos Lindahl maximizar la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È iÃ3N πi del objetivo (la suma de los agentes de utilidades) son precios mínimos Lindahl. Cualquier Lindahl precios hará para nuestros resultados, pero algunos pueden tener mejores propiedades de excitación que otros. Tenga en cuenta que una consulta de demanda con precios máximos de Lindahl es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para el trabajo futuro la cuestión de los precios de Lindahl para elegir minimizar la obtención de preferencias. Teniendo en cuenta ahora por qué las consultas de demanda y equivalencia son analógicas directas, primero tenga en cuenta que dado el πi en algún equilibrio Lindahl, establecer pi(S) = max{0, Estos precios dejan a cada agente indiferente en todos los paquetes con precio positivo, y satisfacen la condición (1). Así, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl típicamente serán una constante aditivo lejos de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos de consultas de equivalencia a través de consultas de demanda. Lemma 1. Supongamos que un agente responde con un paquete preferido S cuando se propone un paquete S y soporta los precios de Lindahl p(S) (soportando con respecto a la valoración manifiesta de los agentes). A continuación, o bien?v(S) = v(S) o?v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: Φv(S) − p(S) ≥ Desigualdad (6) se mantiene porque el agente de hecho prefiere S a S dados los precios, de acuerdo con su respuesta a la consulta de demanda. Si fuera el caso de que?v(S) = v(S) y Así, al menos uno de S y S es un contraejemplo de la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño(v1,. . . , vn) en problemas de excitación. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que apoyar los precios de Lindahl debe necesariamente revelarse en el curso de cualquier protocolo de obtención de preferencias que termina con una asignación óptima. Además, Nisan y Segal (Lemma 1, [12]) afirman que en el peor de los casos los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones dobles (como será el caso de las clases más interesantes). Puesto que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y puesto que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitiendo la dependencia del tamaño(v1,. . . , vn) en problemas de excitación es totalmente natural. 183 4. DE APRENDIZAJE A LA LICITACIÓN DE PREFERENCIA La clave para convertir un algoritmo de aprendizaje a un algoritmo de excitación es simular consultas de equivalencia con consultas de demanda y valor hasta que se encuentre una asignación óptima. Debido a nuestra construcción de precios Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en que un agente responde SÍ a una consulta de equivalencia cuando la función de destino se ha aprendido exactamente. De lo contrario, podemos obtener un contraejemplo a una consulta de equivalencia dada una respuesta de agentes a una consulta de demanda. Teorema 1. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si cada uno puede ser polinomio-consulta exactamente aprendido de consultas de membresía y equivalencia. Prueba. Considere el algoritmo de excitación en la Figura 1. Cada consulta de membresía en el paso 1 es simulada con una consulta de valor ya que estas son de hecho idénticas. Considere el paso 4. Si todos los agentes responden SÍ, la condición (1) se mantiene. Condición (2) se mantiene porque la asignación calculada es la maximización de ingresos para el subastador, independientemente de los agentes verdaderas valoraciones. Así pues, se ha encontrado una asignación óptima. De lo contrario, por lo menos uno de Si o Si es un contraejemplo a Vi, por Lemma 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones del agente se conocerán exactamente, en cuyo caso la asignación óptima y los precios Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinomio de consultas, desde A1,. . . , A son todos los algoritmos de aprendizaje polinomio-quería. Tenga en cuenta que el procedimiento de conversión resulta en un algoritmo de excitación de preferencias, no un algoritmo de aprendizaje. Es decir, el algoritmo resultante no simplemente aprender las valoraciones exactamente, a continuación, calcular una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor, y periódicamente comprueba si se ha reunido suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio Lindahl para las valoraciones v1,. . . , vn utilizando una asignación y precios derivados de valoraciones manifiestas . . y encontrar una asignación óptima no implica que las valoraciones de los agentes se hayan aprendido exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta interrupción temprana. No obtendremos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE COMUNICACIÓN En esta sección, pasamos a la cuestión de la complejidad comunicativa de la excitación. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (tales como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos de determinar los precios de Lindahl es exponencial en el número de mercancías, m. La carga de comunicación se mide en términos del número de bits transmitidos entre agentes y subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. La conversión de algoritmos de aprendizaje eficientes a un algoritmo de excitación produce un algoritmo cuyas consultas tienen tamaños polinomios en los parámetros m y tamaño (v1, ). . . , vn). Teorema 2. Las clases de representación V1,. . . , Vn se puede obtener de forma eficiente de las consultas de valor y demanda si cada uno puede ser aprendido exactamente de las consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, basta con comunicar la función de valoración manifiesta de los agentes y el valor Nótese que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinomio, porque el tiempo de ejecución de los algoritmos también sería superpolinomio, contradiciendo la eficiencia. Por lo tanto, la comunicación de la valoración manifiesta requiere tamaño a lo sumo p(size(vi), m), para algunos polinomios p que limita superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representando el excedente πi al agente no se puede requerir espacio mayor que q(size( También debemos comunicarnos con su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es como máximo p(size(vi), m) + q(p(size(vi), m), m)+O(m). Claramente, una respuesta de agentes a una consulta de valor o demanda tiene un tamaño máximo de q(size(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, son siempre de tamaño polinomio. Un algoritmo de aprendizaje eficiente realiza un número polinomio de consultas, por lo que la comunicación total del algoritmo de excitación resultante es polinomio en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites pueden ser traducidos a límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de excitación resultante. Con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2 se determinó el tamaño de la hipótesis manifiesta. Es probable que podamos hacerlo mucho mejor que esto en la práctica. Recuerde que una consulta de equivalencia es apropiada si size( ̃f) ≤ size(f) en el momento de realizar la consulta. Si las consultas de equivalencia de algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites estrechos en los requisitos de comunicación del algoritmo de excitación resultante. El teorema 2 muestra que los algoritmos de excitación que dependen del tamaño (v1,. . . El parámetro, vn) evita los resultados negativos de Nisan y Segals [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto al tamaño de las instancias de las funciones de valoración que se enfrentan a cualquier ejecución del algoritmo. Estos algoritmos van bien si la clase de representación elegida proporciona representaciones sucintas para la más simple y común de las valoraciones, y por lo tanto el enfoque se mueve de nuevo a uno de lenguajes de licitación compactos pero expresivos. A continuación se examinan estas cuestiones. 6. APLICACIONES En esta sección, demostramos la aplicación de nuestros métodos a clases particulares de representación para valoraciones combinatorias. Hemos demostrado que el problema de excitación de preferencias para las clases de valoración V1,. . . , Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1,. . . , Una para las valoraciones de las clases V1,. . . , Vn respectivamente. Encaje hasta que haya una señal para detenerse: 1. Corre A1,. . . , Un en paralelo sobre sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se ha detenido con los agentes valoración exacta. 2. Calcular una asignación óptima (S1,. . . , Sn ) y los correspondientes precios de Lindahl con respecto a las valoraciones manifiestas . . , їvn determinado hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de consulta de demanda. 4. Si todos ellos responden SÍ, salida la asignación y parada. De lo contrario hay algún agente i que ha respondido con algún paquete preferido Si. Realizar consultas de valor en Si y Si para encontrar un contraejemplo a ‡vi, y proporcionarlo a Ai. Figura 1: Convertir algoritmos de aprendizaje a un algoritmo de excitación. al problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de función, y porque a menudo puede ser más simple resolver cada subproblema de aprendizaje por separado que atacar el problema de excitación de preferencias directamente. Podemos desarrollar un algoritmo de excitación que se adapta a cada valoración de agentes, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Demostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas de DNF monotono y funciones de umbral lineal se pueden convertir en algoritmos de excitación de preferencia para valoraciones generales, valoraciones con eliminación libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en las representaciones que son polinomialmente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la traqueabilidad computacional [18]. Al interpretar los métodos enfatizamos la expresividad y sucinta de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de licitación, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debe representar sucintamente las funciones más simples y comunes de la clase. 6.1 Las Representaciones Polinómicas Schapire y Sellie [17] dan un algoritmo de aprendizaje para polinomios multivariables escasos que pueden utilizarse como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas apropiadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados de t-sparse sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-sparse tiene como máximo t términos, donde un término es un producto de variables, por ejemplo. x1x3x4. Un polinomio sobre los números reales tiene coeficientes extraídos de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M →  se puede escribir exclusivamente como un polinomio [17]. Para tener una idea de la sucintaidad de los polinomios como lenguaje de licitación, considere las valoraciones aditivas y mono-ítem presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es el número de mercancías que contiene el paquete. En la valoración de un solo elemento, todos los paquetes tienen valor 1, excepto el valor 0 (i.e. el agente está satisfecho tan pronto como ha adquirido un único artículo). No es difícil demostrar que la valoración de un solo elemento requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Por lo tanto, los polinomios son adecuados para valoraciones que en su mayoría son aditivas, con algunas sustituibilidades y complementariedades que pueden introducirse ajustando los coeficientes. El algoritmo de aprendizaje para polinomios hace como máximo consultas de equivalencia mti +2 y como máximo (mti +1) (t2 i +3ti)/2 consultas de membresía a un agente i, donde ti es la esparcidad del polinomio que representa vi [17]. Por lo tanto, se obtiene un algoritmo que provoca valoraciones generales con un número polinomio de consultas y comunicación polinomio.6 6.2 XOR Representaciones El lenguaje de licitación XOR es estándar en la literatura de subastas combinatoria. Recordemos que una oferta XOR se caracteriza por un conjunto de paquetes B  2M y una función de valor w : B →  definida en esos paquetes, que induce la función de valoración: v(B) = max {B  B  B  B} w(B) (7) Las ofertas XOR pueden representar valoraciones que satisfacen la libre eliminación (y sólo tales valoraciones), que de nuevo es la propiedad que A  B El lenguaje de licitación XOR es ligeramente menos expresivo que los polinomios, porque los polinomios pueden representar valoraciones que no satisfacen la libre eliminación. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas de XOR pueden representar la valoración de un solo elemento con ofertas atómicas m, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario se aplica a los polinomios, estas dos lenguas son incomparables en sucintas y algo complementarias para su uso práctico. Blum et al. [5] note que las fórmulas DNF monotonas son los análogos de las pujas XOR en la literatura de teoría del aprendizaje. Una fórmula de DNF monotona es una disyunción de conjunciones en las que las variables aparecen sin negación, por ejemplo x1x2 x3 x2x4x5. Tenga en cuenta que tales fórmulas pueden ser representadas como ofertas XOR donde cada oferta atómica tiene valor 1; por lo tanto XOR ofrece generalizar fórmulas DNF monotono de Boolean a funciones de valor real. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para el DNF monotono ([3] Teorema 6 Tenga en cuenta que el Teorema 1 se aplica incluso si las valoraciones no satisfacen la eliminación libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lemma 2. Una oferta XOR que contiene ofertas t atómicas se puede aprender exactamente con consultas de equivalencia t + 1 y a lo sumo consultas de membresía tm. Prueba. El algoritmo identificará cada puja atómica en la puja XOR objetivo a su vez. Initialice la valoración manifiesta v a la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presente ‡v como consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un paquete S para el que v(S) = Crear un paquete T de la siguiente manera. Primero inicialice T = S. Para cada elemento i en T, compruebe a través de una consulta de membresía si v(T) = v(T − {i}). Si así se establece T = T − {i}. De lo contrario, deje T como está y pase al siguiente punto. Afirmamos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada ítem i en T, tenemos v(T) = v(T − {i}). Para ver esto, tenga en cuenta que en algún momento al generar T, tuvimos un ̄T tal que T  ̄T  S y v( ̄T) > v( ̄T − {i}), de modo que me mantuvo en ̄T. Tenga en cuenta que v(S) = v( ̄T) = v(T) porque el valor del paquete S se mantiene durante todo el proceso de eliminación de elementos. Ahora asume v(T) = v(T − {i}). Entonces v( ̄T) = v(T) = v(T − {i}) > v( ̄T − {i}) que contradice la libre eliminación, ya que T {i}  ̄T − {i}. Por lo tanto v(T) > v(T − {i}) para todos los ítems i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si este no fuera el caso, T tomaría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = máx itat {max T T Ahora mostramos que v(T) = ̃v(T), que implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Asumir que toda oferta atómica (R, Esta suposición se mantiene vagamente cuando se inicializa la valoración manifiesta. Usando la notación de (7), dejar ( Tenemos B  B, y Bw(B) = w(B) para B Por lo tanto,?v(S) = max {B} {B} {B} {B} {B} {B} = max {B} {B} {B} ≤ {B} {B} {B} {B} {S} w(B} = v(S) (8) Ahora asume v(T) {v(T La segunda igualdad se deriva del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad sostiene porque S es un contraejemplo de la valoración manifiesta. De la ecuación (9) y la eliminación libre, nosotros 7 El algoritmo citado también se utilizó como base para Zinkevich et al.s [19] algoritmo de excitación para Toolbox DNF. Recuerde que Toolbox DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia se puede simular con una consulta de valor en el paquete que contiene todas las mercancías. que tengan ‡v(T) < Entonces de nuevo de la ecuación (9) se deduce que v(S) < Esto contradice (8), por lo que de hecho tenemos v(T) = Por lo tanto (T, v(T)) no está actualmente en nuestra hipótesis como una oferta atómica, o tendríamos correctamente?v(T) = v(T) por la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas adicionales de equivalencia hasta que todas las ofertas atómicas hayan sido identificadas. Después de cada consulta de equivalencia, una oferta atómica se identifica con como máximo m consultas de membresía. Cada contraejemplo conduce al descubrimiento de una nueva oferta atómica. Por lo tanto, hacemos a lo sumo consultas de membresía tm y exactamente consultas de equivalencia t + 1. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR se puede obtener eficientemente de las consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al.s ([5], Teorema 2) afirmando que el DNF monotono (y por lo tanto las ofertas XOR) no se pueden obtener de manera eficiente cuando las consultas de demanda se limitan a precios lineales y anónimos sobre las mercancías. 6.3 Las representaciones lineales de umbral polinomios, las ofertas XOR y todas las lenguas basadas en el lenguaje de licitación OR (como XOR-de-OR, OR-de-XOR y OR*) no representan sucintamente la valoración mayoritaria [11]. En esta valoración, los paquetes tienen valor 1 si contienen al menos m/2 ítems, y valor 0 de lo contrario. Más generalmente, considere la familia de r-of-S de valoraciones donde los paquetes tienen valor 1 si contienen al menos r artículos de un conjunto especificado de ítems S  M, y valor 0 de otra manera. La valoración mayoritaria es un caso especial de la valoración de r-of-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar las sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede añadir valor. Dejando k = S, tales valoraciones están sucintamente representadas por funciones de umbral r-of-k. Estas funciones adoptan la forma de desigualdades lineales: xi1 +. . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se mantiene, y 0 de lo contrario. Aquí i1,. . . , ik son los elementos en S. Littlestones WINNOW 2 algoritmo puede aprender tales funciones utilizando consultas de equivalencia sólo, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de excitación que resulta de WINNOW 2 sólo utiliza consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos están implícitos cuando sólo hay dos valores posibles). Tenga en cuenta que las funciones de umbral r-of-k siempre se pueden representar sucintamente en el espacio O(m). Así se obtiene un algoritmo que puede generar tales funciones con un número polinomio de consultas y comunicación polinomio, en los parámetros n y m solos. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exactos con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de excitación de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas en el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la riqueza de algoritmos de aprendizaje disponibles al problema de la excitación de preferencias. Un enfoque de aprendizaje para la excitación también motiva un enfoque diferente para diseñar algoritmos de excitación que se descomponen cuidadosamente entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivos, muchos sustitutos, etc.), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de excitación. El algoritmo de excitación resultante hace un número polinomio de consultas, y hace comunicación polinomio si los algoritmos de aprendizaje originales son eficientes. No exigimos que las valoraciones de agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia sólo pueden ser, y sólo necesitan ser, simuladas hasta el punto en que se ha calculado una asignación óptima. Este es el problema de la excitación de preferencias. Teorema 1 implica que la excitación con consultas de valor y demanda no es más difícil que aprender con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las que la excitación es más fácil que el aprendizaje. Blum et al. [5] proporcionar tal ejemplo al considerar solamente consultas de membresía/valor (Teorema 4). En el trabajo futuro planeamos abordar la cuestión de los incentivos al convertir algoritmos de aprendizaje a algoritmos de excitación. En el entorno de aprendizaje, por lo general suponemos que los oráculos proporcionarán respuestas honestas a las preguntas; en el entorno de excitación, los agentes son generalmente egoístas y proporcionarán respuestas posiblemente deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para el aprendizaje de polinomios y ofertas XOR como algoritmos de excitación, y probar su rendimiento contra otros protocolos de subasta combinatoria establecidos [6, 15]. Una pregunta interesante aquí es: ¿qué precios Lindahl en el rango máximo a mínimo son los mejores para citar con el fin de minimizar la revelación de información? Suponemos que la revelación de información se reduce al pasar de precios máximos a precios mínimos de Lindahl, es decir, a medida que desplazamos las consultas de demanda más lejos de las consultas de equivalencia. Por último, sería útil determinar si el lenguaje de licitación de OR* [11] puede aprenderse (y, por lo tanto, obtenerse) de manera eficiente, dada la expresividad y sucinta de estas lenguas para una amplia variedad de clases de valoración. Agradecimientos Queremos agradecer a Debasis Mishra por sus útiles discusiones. Este trabajo está apoyado en parte por la subvención de NSF IIS0238147. 8. REFERENCIAS [1] A. Andersson, M. Tenhunen, y F. Ygge. Programación integral para la determinación del ganador de la subasta combinatoria. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprender conjuntos regulares de consultas y contraejemplos. Información e computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje conceptual. Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El modelo de asignación de paquetes. Diario de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Provocación de preferencias y aprendizaje de consultas. En Proc. 16a Conferencia Anual sobre Teoría del Aprendizaje Computacional (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. la 18a Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, e Y. Shoham. Domar la complejidad computacional de las subastas combinatoria: Enfoques óptimos y aproximados. En Proc. , 16a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), págs. 548 a 553, 1999. [8] B. Hudson y T. Sandholm. Uso de consultas de valor en subastas combinatoria. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría del aprendizaje computacional. MIT Press, 1994. [10] N. Littlestone. Aprender rápidamente cuando los atributos irrelevantes abundan: Un nuevo algoritmo de umbral lineal. Machine Learning, 2:285-318, 1988. [11] N. Nisan. Licitación y asignación en subastas combinatoria. En Proc. la Conferencia de la ACM sobre Comercio Electrónico, págs. 1 a 12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y el apoyo a los precios Lindahl. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de mínima revelación. En Padget et al., editor, Agent-Mediated Electronic Commerce IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. Diseño de subastas con costosas preferencias. En Temas Especiales de Anales de Matemáticas y AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17a Conferencia Nacional sobre Inteligencia Artificial (AAAI-00), págs. 74 a 81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. la 17a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariables escasos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de ACM sobre Teoría del Aprendizaje Computacional, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendido. Comun. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum, y T. Sandholm. Sobre la excitación de la preferencia polinomio-tiempo con las consultas de valor. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188",
    "error_count": 13,
    "keys": {
        "parallel": {
            "translated_key": [
                "paralizar",
                "paralelar",
                "paralelo"
            ],
            "translated_annotated_text": "Aplicando algoritmos de aprendizaje a la eliminación de preferencia Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de excitación Demostramos que los algoritmos de aprendizaje pueden ser usados como base para algoritmos de excitación de preferencias. Los algoritmos de excitación resultantes realizan un número polinomio de consultas. También damos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. En particular, se obtiene un algoritmo que provoca pujas XOR con comunicación polinómica. Categorías y Descriptores sujetos F.2.0 [Análisis de algoritmos y complejidad de problemas]: General; J.4 [Ciencias Sociales y Conductuales]: Economía; I.2.6 [Inteligencia Artificial]: Términos generales de aprendizaje Algoritmos, Economía, Teoría 1. INTRODUCCIÓN En una subasta combinatoria, los agentes pueden pujar por paquetes de bienes en lugar de por cada uno de ellos. Puesto que hay un número exponencial de paquetes (en el número de bienes), comunicar los valores sobre estos paquetes puede ser problemático. Comunicar las valoraciones de una sola vez puede ser prohibitivamente costoso si el número de bienes es sólo moderadamente grande. Además, incluso podría ser difícil para los agentes determinar sus valoraciones para paquetes únicos [14]. A esos agentes les interesa disponer de protocolos de subasta que les obliguen a pujar en el menor número posible de paquetes. Incluso si los agentes pueden calcular eficientemente sus valoraciones, podrían ser reacios a revelarlas enteramente en el curso de una subasta, porque tal información puede ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información necesaria para determinar una asignación óptima de los bienes. Ha habido un trabajo reciente explorando los vínculos entre el problema de la excitación de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje computacional [5, 19]. En teoría de aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, tales como ¿Cuál es el valor de las funciones en estas entradas? En la obtención de preferencia, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Demostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia se puede convertir en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de excitación resultante garantiza la excitación en un número polinomio de consultas de valor y demanda. Aquí queremos decir polinomio en el número de bienes, agentes, y los tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Argumentamos que las garantías de complejidad para los esquemas de excitación deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar la comunicación polinómica en el peor de los casos, que normalmente no se puede lograr en el número de productos y agentes por sí solos. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. Por supuesto, una subasta combinatoria de un solo disparo donde los agentes proporcionan todas sus funciones de valoración a la vez también tendría comunicación polinómica en el tamaño de las valoraciones de los agentes, y sólo requieren una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay ninguna carga para los agentes de formular sus valoraciones en un esquema de codificación de los subastadores que elijan. Esperamos que esta sea una consideración importante en la práctica. Además, con nuestro esquema la revelación entera sólo ocurre en el peor de los casos. 180 Por ahora, dejamos a un lado la cuestión de los incentivos al derivar algoritmos de excitación. Nos centramos en el tiempo y la complejidad de la comunicación de la obtención de preferencias, independientemente de las limitaciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich y otros [19] considerar el problema del aprendizaje de clases restringidas de funciones de valoración que se pueden representar utilizando fórmulas de lectura once y Toolbox DNF. Las fórmulas Read-once pueden representar ciertas sustitutibilidades, pero no complementariedades, mientras que lo contrario se mantiene para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten depender del tamaño de la valoración objetivo como lo hacemos (aunque las valoraciones de read-once siempre se pueden representar sucintamente de todos modos). Su trabajo sólo hace uso de consultas de valor, que son bastante limitados en el poder. Debido a que nos permitimos pedir consultas, somos capaces de derivar un esquema de excitación para las funciones de valoración general. Blum et al. [5] proporcionar resultados relacionados con las complejidades del aprendizaje de la consulta y la excitación de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje de consultas, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones se pueden aprender eficientemente, pero no se pueden obtener eficientemente, y viceversa. En contraste, nuestro trabajo muestra que dada una versión más general (todavía bastante estándar) de la consulta de demanda que el tipo que consideran, la complejidad de la excitación de preferencia no es mayor que la complejidad del aprendizaje. Demostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre valoraciones para implicar una solución al problema de excitación. Nisan y Segal [12] estudian la complejidad comunicativa de la excitación de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos de la computación una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo se permite a los algoritmos hacer preguntas sobre valoraciones de agentes y recibir respuestas honestas, sin ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda la cuestión de la complejidad de la comunicación, y somos capaces de derivar algoritmos que proporcionan garantías de comunicación significativas a pesar de los resultados negativos de Nisan y Segals. Su trabajo motiva la necesidad de confiar en el tamaño de los agentes funciones de valoración para indicar los peores resultados. 2. LOS MODELOS 2.1 Aprendizaje de la consulta El modelo de aprendizaje de la consulta que consideramos aquí se llama aprendizaje exacto de la membresía y consultas de equivalencia, introducido por Angluin [2]. En este modelo el objetivo de los algoritmos de aprendizaje es identificar exactamente una función diana desconocida f : X → Y a través de consultas a un oráculo. La función de destino se extrae de una función de clase C que es conocida por el algoritmo. Típicamente el dominio X es algún subconjunto de {0, 1}m, y el rango Y es {0, 1} o algún subconjunto de los números reales. A medida que el algoritmo avanza, construye una hipótesis manifiesta?f que es su estimación actual de la función de destino. Después de la terminación, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface?f(x) = f(x) para todos x?X. Es importante especificar la representación que se utilizará para codificar funciones de C. Por ejemplo, considere la siguiente función de {0, 1}m a ♥: f(x) = 2 si x consiste en m 1s, y f(x) = 0 de otra manera. Esta función puede representarse simplemente como una lista de valores de 2m. O puede codificarse como el polinomio 2x1 · · · xm, que es mucho más sucinto. Así pues, la elección de la codificación puede tener un impacto significativo en las necesidades de tiempo y espacio del algoritmo de aprendizaje. Let size(f) ser el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes distintos de cero en el polinomio, por ejemplo. Por lo general, sólo nos referiremos a las clases de representación; las clases de funciones correspondientes serán implícitas. Por ejemplo, la clase de representación de fórmulas DNF monotonas implica la clase de función de funciones booleanas monotonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: la membresía y las consultas de equivalencia. En una consulta de membresía, el aprendiz presenta algunas x x x y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta f. El oráculo responde SÍ si?f = f, o devuelve un contraejemplo x de tal manera que?f(x) = f(x). Una consulta de equivalencia es apropiada si el tamaño( ̃f) ≤ tamaño(f) en el momento de presentar la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones se adaptan a partir de Kearns y Vazirani [9]: Definición 1. La clase de representación C es polinomialquery exactamente aprendeble de las consultas de membresía y equivalencia si hay un polinomial fijo p(·, ·) y un algoritmo L con acceso a la membresía y consultas de equivalencia de un oráculo tal que para cualquier función de destino f • C, L salidas después de a lo sumo p(size(f), m) consultas de una función?f • C tal que?f Del mismo modo, la clase de representación C se puede aprender exactamente de las consultas de membresía y equivalencia si el algoritmo L produce una hipótesis correcta en el tiempo p(size(f), m), para algunos polinomios fijos p(·, ·). Aquí m es la dimensión del dominio. Dado que la función de destino debe ser reconstruida, también permitimos necesariamente la dependencia polinómica del tamaño (f). 2.2 Eliminación de preferencias En una subasta combinatoria, un conjunto de bienes M se asignará entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Tal asignación se llama eficiente en la literatura de economía, pero nos referiremos a ella como óptima y reservar el término eficiente para referirse a la eficiencia computacional. Dejamos n = N y m = M. Una asignación es una partición de los objetos en paquetes (S1,. . . , Sn), de tal manera que Si â € ¬ Sj = â € para todos los i, j â € N. Let â € € sea el conjunto de posibles asignaciones. Cada agente i+N tiene una función de valoración vi : 2M → • sobre el espacio de los paquetes posibles. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no tienen que coincidir. Asumimos que todas las valoraciones consideradas están normalizadas, es decir, v() = 0, y que no hay externalidades, es decir, vi(S1,..., Sn) = vi(Si), para todos los agentes i  N, para cualquier asignación (S1,..., Sn)  (es decir, un agente se preocupa sólo por el paquete asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales.1 Nosotros 1 A menudo las valoraciones generales se hacen para satisfacer los 181 adicionales también asumen que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que los agentes utilidades pueden ser divididos en componentes monetarios y no monetarios. Si a un agente i se le asigna el paquete S al precio p, deriva utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más sucintas para ciertas clases de valoración, y ha habido mucha investigación en lenguajes de licitación concisos para diversos tipos de valoraciones [11]. Un ejemplo clásico al que nos referiremos más adelante es el lenguaje de licitación XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, que consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estas pujas, se busca el paquete S del valor más alto listado en las pujas atómicas de tal manera que S  S. Es entonces el caso que v(S) = v(S). Al igual que en el contexto de la teoría del aprendizaje, por lo general sólo nos referiremos a idiomas de oferta en lugar de clases de valoración, ya que las clases de valoración correspondientes serán implícitas. Por ejemplo, el lenguaje de licitación XOR implica la clase de valoraciones que satisfacen la disposición libre, que es la condición de que A  B ♥ v(A) ≤ v(B). Dejamos el tamaño(v1,. . . , vn) = Èn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de licitación). Para hacer una analogía con la teoría del aprendizaje computacional, suponemos que todas las clases de representación consideradas son polinomiamente interpretables [11], lo que significa que el valor de un paquete puede ser calculado en tiempo polinomio dada la representación de funciones de valoración. Más formalmente, una clase de representación (lenguaje de licitación) C es polinomialmente interpretable si existe un algoritmo que da como entrada algunos v • C y una instancia x • X calcula el valor v(x) en el tiempo q(size(v), m), para algún polinomio fijo q(·, ·).2 En las rondas intermedias de una subasta (terativa), el subastador habrá obtenido información sobre las funciones de Por lo tanto, habrá construido un conjunto de valoraciones manifiestas, denotadas . . Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha adquirido información sobre ciertos paquetes. El objetivo en el problema de la excitación de preferencia es construir un conjunto de valoraciones manifiestas tales que: arg max (S1,...,Sn) iÃ3n Ã3vi(Si)  arg max (S1,...,Sn) iÃ3n vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que es óptima con respecto a las valoraciones verdaderas. Tenga en cuenta que sólo se requiere una asignación óptima. condición de la libre eliminación (monotonicidad), pero no la necesitamos en este punto. 2 Esto excluye OR*, asumiendo P = NP, porque la interpretación de las ofertas de este lenguaje es NP-duro por reducción de set-embalaje ponderado, y no hay clase de representación bien estudiada en teoría de aprendizaje que es claramente análogo a OR*. 3 Esta visión de las subastas iterativas está destinada a \"paralizar\" el entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente están implícitas por la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son consultas de valor y demanda. En una consulta de valor, el subastador presenta un paquete S  M y el agente responde con su valor (exacto) para el paquete v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p • • • (2m ) sobre los paquetes junto con un paquete S. El agente responde SI si es el caso de que S • arg max S M v(S ) − p(S ) ¡ o de otro modo presenta un paquete S tal que v(S ) − p(S ) > v( Tenga en cuenta también que comunicar precios no lineales no implica necesariamente citar un precio por cada paquete posible. Puede haber formas más sucintas de comunicar este vector, como se muestra en la sección 5. Hacemos las siguientes definiciones para \"paralelar\" la configuración de aprendizaje de la consulta y para simplificar las declaraciones de resultados posteriores: Definición 2. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si hay un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes tales que para cualquier (v1,. . . , vn) V1 ×. . . × Vn, L salidas después de como máximo p(size(v1,. . . , vn), m) consulta una asignación (S1,. . . , Sn) arg max(S1,...,Sn) È vi(Si). Del mismo modo, la clase de representación C se puede obtener eficientemente de las consultas de valor y demanda si el algoritmo L produce una asignación óptima con comunicación p(size(v1, ). . . , vn), m), para algunos polinomios fijos p(·, ·). Hay algunas diferencias clave aquí con la definición de aprendizaje de la consulta. Hemos eliminado el término exactamente ya que las funciones de valoración no necesitan ser determinadas exactamente con el fin de calcular una asignación óptima. Además, un algoritmo de excitación eficiente es la comunicación polinomio, en lugar de tiempo polinomio. Esto refleja el hecho de que la comunicación en lugar del tiempo de espera es el cuello de botella en la excitación. Cálculo de una asignación óptima de bienes incluso cuando se dan las valoraciones verdaderas es NP-duro para una amplia gama de clases de valoración. Por lo tanto, no es razonable exigir tiempo polinomio en la definición de un algoritmo de excitación de preferencias eficiente. Nos complace centrarnos en la complejidad comunicativa de la excitación porque se cree que este problema es más significativo en la práctica que el de la determinación del ganador [11].5 4 Esto difiere ligeramente de la definición proporcionada por Blum et al. [5] Sus consultas sobre la demanda se limitan a precios lineales sobre las mercancías, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir. un precio distinto por cada paquete posible. Es por eso que el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. 5 Aunque el problema de determinación del ganador es NP-hard para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta aproximaciones usando solucionadores IP fuera de la plataforma [1]. 182 Dado que no es necesario obtener exactamente las valoraciones, es inicialmente menos claro si la dependencia polinómica del tamaño (v1, ). . . , vn) está justificado en este contexto. Intuitivamente, este parámetro está justificado porque debemos aprender valoraciones exactamente cuando se realiza la excitación, en el peor de los casos. Nos ocupamos de esto en la siguiente sección. 3. PARALLESBETWEEN EQUIVALENCIA Y QUERIDAS DE DEMANDA Hemos descrito los ajustes de aprendizaje y excitación de preferencias de la consulta de una manera que destaca sus similitudes. Las consultas de valor y membresía son claras analógicas. Un poco menos obvio es el hecho de que las consultas de equivalencia y demanda también son analógicas. Para ver esto, necesitamos el concepto de precios Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios sobre sus bienes subyacentes. Son no anónimos en el sentido de que dos agentes pueden tener que hacer frente a precios diferentes para el mismo paquete de mercancías. Así los precios de Lindahl son de la forma pi(S), para todos S  M, para todos los precios de i  N. Lindahl se presentan a los agentes en consultas de la demanda. Cuando los agentes han normalizado las funciones de utilidad cuasi-lineal, Bikhchandani y Ostroy [4] muestran que siempre existen precios Lindahl tales que (S1,. . . , Sn) es una asignación óptima si y sólo si Si • arg max Si vi(Si) − pi(Si) • i N (1) (S1,. . . , Sn)  arg max (S1,...,Sn) iN pi(Si) (2) Condición (1) establece que cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos de los subastadores a los precios indicados. El escenario en el que se mantienen estas condiciones se llama equilibrio Lindahl, o a menudo un equilibrio competitivo. Decimos que los precios de Lindahl apoyan la asignación óptima. Por lo tanto, basta con anunciar los precios de apoyo de Lindahl para verificar una asignación óptima. Una vez que hemos encontrado una asignación con el apoyo de precios Lindahl, el problema de excitación se resuelve. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones estén garantizadas como integrales [4]. Las variables duales de este programa lineal están soportando los precios de Lindahl para la asignación resultante. La función objetiva del programa dual es: min pi(S) Por lo general, hay una gama de posibles precios Lindahl que apoyan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios válidos Lindahl, y nos referimos a ellos como precios máximos Lindahl. De todos los vectores posibles de precios Lindahl, precios máximos Lindahl maximizar la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È iÃ3N πi del objetivo (la suma de los agentes de utilidades) son precios mínimos Lindahl. Cualquier Lindahl precios hará para nuestros resultados, pero algunos pueden tener mejores propiedades de excitación que otros. Tenga en cuenta que una consulta de demanda con precios máximos de Lindahl es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para el trabajo futuro la cuestión de los precios de Lindahl para elegir minimizar la obtención de preferencias. Teniendo en cuenta ahora por qué las consultas de demanda y equivalencia son analógicas directas, primero tenga en cuenta que dado el πi en algún equilibrio Lindahl, establecer pi(S) = max{0, Estos precios dejan a cada agente indiferente en todos los paquetes con precio positivo, y satisfacen la condición (1). Así, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl típicamente serán una constante aditivo lejos de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos de consultas de equivalencia a través de consultas de demanda. Lemma 1. Supongamos que un agente responde con un paquete preferido S cuando se propone un paquete S y soporta los precios de Lindahl p(S) (soportando con respecto a la valoración manifiesta de los agentes). A continuación, o bien?v(S) = v(S) o?v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: Φv(S) − p(S) ≥ Desigualdad (6) se mantiene porque el agente de hecho prefiere S a S dados los precios, de acuerdo con su respuesta a la consulta de demanda. Si fuera el caso de que?v(S) = v(S) y Así, al menos uno de S y S es un contraejemplo de la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño(v1,. . . , vn) en problemas de excitación. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que apoyar los precios de Lindahl debe necesariamente revelarse en el curso de cualquier protocolo de obtención de preferencias que termina con una asignación óptima. Además, Nisan y Segal (Lemma 1, [12]) afirman que en el peor de los casos los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones dobles (como será el caso de las clases más interesantes). Puesto que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y puesto que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitiendo la dependencia del tamaño(v1,. . . , vn) en problemas de excitación es totalmente natural. 183 4. DE APRENDIZAJE A LA LICITACIÓN DE PREFERENCIA La clave para convertir un algoritmo de aprendizaje a un algoritmo de excitación es simular consultas de equivalencia con consultas de demanda y valor hasta que se encuentre una asignación óptima. Debido a nuestra construcción de precios Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en que un agente responde SÍ a una consulta de equivalencia cuando la función de destino se ha aprendido exactamente. De lo contrario, podemos obtener un contraejemplo a una consulta de equivalencia dada una respuesta de agentes a una consulta de demanda. Teorema 1. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si cada uno puede ser polinomio-consulta exactamente aprendido de consultas de membresía y equivalencia. Prueba. Considere el algoritmo de excitación en la Figura 1. Cada consulta de membresía en el paso 1 es simulada con una consulta de valor ya que estas son de hecho idénticas. Considere el paso 4. Si todos los agentes responden SÍ, la condición (1) se mantiene. Condición (2) se mantiene porque la asignación calculada es la maximización de ingresos para el subastador, independientemente de los agentes verdaderas valoraciones. Así pues, se ha encontrado una asignación óptima. De lo contrario, por lo menos uno de Si o Si es un contraejemplo a Vi, por Lemma 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones del agente se conocerán exactamente, en cuyo caso la asignación óptima y los precios Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinomio de consultas, desde A1,. . . , A son todos los algoritmos de aprendizaje polinomio-quería. Tenga en cuenta que el procedimiento de conversión resulta en un algoritmo de excitación de preferencias, no un algoritmo de aprendizaje. Es decir, el algoritmo resultante no simplemente aprender las valoraciones exactamente, a continuación, calcular una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor, y periódicamente comprueba si se ha reunido suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio Lindahl para las valoraciones v1,. . . , vn utilizando una asignación y precios derivados de valoraciones manifiestas . . y encontrar una asignación óptima no implica que las valoraciones de los agentes se hayan aprendido exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta interrupción temprana. No obtendremos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE COMUNICACIÓN En esta sección, pasamos a la cuestión de la complejidad comunicativa de la excitación. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (tales como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos de determinar los precios de Lindahl es exponencial en el número de mercancías, m. La carga de comunicación se mide en términos del número de bits transmitidos entre agentes y subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. La conversión de algoritmos de aprendizaje eficientes a un algoritmo de excitación produce un algoritmo cuyas consultas tienen tamaños polinomios en los parámetros m y tamaño (v1, ). . . , vn). Teorema 2. Las clases de representación V1,. . . , Vn se puede obtener de forma eficiente de las consultas de valor y demanda si cada uno puede ser aprendido exactamente de las consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, basta con comunicar la función de valoración manifiesta de los agentes y el valor Nótese que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinomio, porque el tiempo de ejecución de los algoritmos también sería superpolinomio, contradiciendo la eficiencia. Por lo tanto, la comunicación de la valoración manifiesta requiere tamaño a lo sumo p(size(vi), m), para algunos polinomios p que limita superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representando el excedente πi al agente no se puede requerir espacio mayor que q(size( También debemos comunicarnos con su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es como máximo p(size(vi), m) + q(p(size(vi), m), m)+O(m). Claramente, una respuesta de agentes a una consulta de valor o demanda tiene un tamaño máximo de q(size(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, son siempre de tamaño polinomio. Un algoritmo de aprendizaje eficiente realiza un número polinomio de consultas, por lo que la comunicación total del algoritmo de excitación resultante es polinomio en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites pueden ser traducidos a límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de excitación resultante. Con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2 se determinó el tamaño de la hipótesis manifiesta. Es probable que podamos hacerlo mucho mejor que esto en la práctica. Recuerde que una consulta de equivalencia es apropiada si size( ̃f) ≤ size(f) en el momento de realizar la consulta. Si las consultas de equivalencia de algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites estrechos en los requisitos de comunicación del algoritmo de excitación resultante. El teorema 2 muestra que los algoritmos de excitación que dependen del tamaño (v1,. . . El parámetro, vn) evita los resultados negativos de Nisan y Segals [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto al tamaño de las instancias de las funciones de valoración que se enfrentan a cualquier ejecución del algoritmo. Estos algoritmos van bien si la clase de representación elegida proporciona representaciones sucintas para la más simple y común de las valoraciones, y por lo tanto el enfoque se mueve de nuevo a uno de lenguajes de licitación compactos pero expresivos. A continuación se examinan estas cuestiones. 6. APLICACIONES En esta sección, demostramos la aplicación de nuestros métodos a clases particulares de representación para valoraciones combinatorias. Hemos demostrado que el problema de excitación de preferencias para las clases de valoración V1,. . . , Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1,. . . , Una para las valoraciones de las clases V1,. . . , Vn respectivamente. Encaje hasta que haya una señal para detenerse: 1. Corre A1,. . . , Un en \"paralelo\" en sus respectivos agentes hasta que cada uno requiere una respuesta a una consulta de equivalencia, o se ha detenido con los agentes valoración exacta. 2. Calcular una asignación óptima (S1,. . . , Sn ) y los correspondientes precios de Lindahl con respecto a las valoraciones manifiestas . . , їvn determinado hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de consulta de demanda. 4. Si todos ellos responden SÍ, salida la asignación y parada. De lo contrario hay algún agente i que ha respondido con algún paquete preferido Si. Realizar consultas de valor en Si y Si para encontrar un contraejemplo a ‡vi, y proporcionarlo a Ai. Figura 1: Convertir algoritmos de aprendizaje a un algoritmo de excitación. al problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de función, y porque a menudo puede ser más simple resolver cada subproblema de aprendizaje por separado que atacar el problema de excitación de preferencias directamente. Podemos desarrollar un algoritmo de excitación que se adapta a cada valoración de agentes, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Demostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas de DNF monotono y funciones de umbral lineal se pueden convertir en algoritmos de excitación de preferencia para valoraciones generales, valoraciones con eliminación libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en las representaciones que son polinomialmente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la traqueabilidad computacional [18]. Al interpretar los métodos enfatizamos la expresividad y sucinta de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de licitación, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debe representar sucintamente las funciones más simples y comunes de la clase. 6.1 Las Representaciones Polinómicas Schapire y Sellie [17] dan un algoritmo de aprendizaje para polinomios multivariables escasos que pueden utilizarse como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas apropiadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados de t-sparse sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-sparse tiene como máximo t términos, donde un término es un producto de variables, por ejemplo. x1x3x4. Un polinomio sobre los números reales tiene coeficientes extraídos de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M →  se puede escribir exclusivamente como un polinomio [17]. Para tener una idea de la sucintaidad de los polinomios como lenguaje de licitación, considere las valoraciones aditivas y mono-ítem presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es el número de mercancías que contiene el paquete. En la valoración de un solo elemento, todos los paquetes tienen valor 1, excepto el valor 0 (i.e. el agente está satisfecho tan pronto como ha adquirido un único artículo). No es difícil demostrar que la valoración de un solo elemento requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Por lo tanto, los polinomios son adecuados para valoraciones que en su mayoría son aditivas, con algunas sustituibilidades y complementariedades que pueden introducirse ajustando los coeficientes. El algoritmo de aprendizaje para polinomios hace como máximo consultas de equivalencia mti +2 y como máximo (mti +1) (t2 i +3ti)/2 consultas de membresía a un agente i, donde ti es la esparcidad del polinomio que representa vi [17]. Por lo tanto, se obtiene un algoritmo que provoca valoraciones generales con un número polinomio de consultas y comunicación polinomio.6 6.2 XOR Representaciones El lenguaje de licitación XOR es estándar en la literatura de subastas combinatoria. Recordemos que una oferta XOR se caracteriza por un conjunto de paquetes B  2M y una función de valor w : B →  definida en esos paquetes, que induce la función de valoración: v(B) = max {B  B  B  B} w(B) (7) Las ofertas XOR pueden representar valoraciones que satisfacen la libre eliminación (y sólo tales valoraciones), que de nuevo es la propiedad que A  B El lenguaje de licitación XOR es ligeramente menos expresivo que los polinomios, porque los polinomios pueden representar valoraciones que no satisfacen la libre eliminación. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas de XOR pueden representar la valoración de un solo elemento con ofertas atómicas m, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario se aplica a los polinomios, estas dos lenguas son incomparables en sucintas y algo complementarias para su uso práctico. Blum et al. [5] note que las fórmulas DNF monotonas son los análogos de las pujas XOR en la literatura de teoría del aprendizaje. Una fórmula de DNF monotona es una disyunción de conjunciones en las que las variables aparecen sin negación, por ejemplo x1x2 x3 x2x4x5. Tenga en cuenta que tales fórmulas pueden ser representadas como ofertas XOR donde cada oferta atómica tiene valor 1; por lo tanto XOR ofrece generalizar fórmulas DNF monotono de Boolean a funciones de valor real. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para el DNF monotono ([3] Teorema 6 Tenga en cuenta que el Teorema 1 se aplica incluso si las valoraciones no satisfacen la eliminación libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lemma 2. Una oferta XOR que contiene ofertas t atómicas se puede aprender exactamente con consultas de equivalencia t + 1 y a lo sumo consultas de membresía tm. Prueba. El algoritmo identificará cada puja atómica en la puja XOR objetivo a su vez. Initialice la valoración manifiesta v a la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presente ‡v como consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un paquete S para el que v(S) = Crear un paquete T de la siguiente manera. Primero inicialice T = S. Para cada elemento i en T, compruebe a través de una consulta de membresía si v(T) = v(T − {i}). Si así se establece T = T − {i}. De lo contrario, deje T como está y pase al siguiente punto. Afirmamos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada ítem i en T, tenemos v(T) = v(T − {i}). Para ver esto, tenga en cuenta que en algún momento al generar T, tuvimos un ̄T tal que T  ̄T  S y v( ̄T) > v( ̄T − {i}), de modo que me mantuvo en ̄T. Tenga en cuenta que v(S) = v( ̄T) = v(T) porque el valor del paquete S se mantiene durante todo el proceso de eliminación de elementos. Ahora asume v(T) = v(T − {i}). Entonces v( ̄T) = v(T) = v(T − {i}) > v( ̄T − {i}) que contradice la libre eliminación, ya que T {i}  ̄T − {i}. Por lo tanto v(T) > v(T − {i}) para todos los ítems i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si este no fuera el caso, T tomaría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = máx itat {max T T Ahora mostramos que v(T) = ̃v(T), que implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Asumir que toda oferta atómica (R, Esta suposición se mantiene vagamente cuando se inicializa la valoración manifiesta. Usando la notación de (7), dejar ( Tenemos B  B, y Bw(B) = w(B) para B Por lo tanto,?v(S) = max {B} {B} {B} {B} {B} {B} = max {B} {B} {B} ≤ {B} {B} {B} {B} {S} w(B} = v(S) (8) Ahora asume v(T) {v(T La segunda igualdad se deriva del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad sostiene porque S es un contraejemplo de la valoración manifiesta. De la ecuación (9) y la eliminación libre, nosotros 7 El algoritmo citado también se utilizó como base para Zinkevich et al.s [19] algoritmo de excitación para Toolbox DNF. Recuerde que Toolbox DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia se puede simular con una consulta de valor en el paquete que contiene todas las mercancías. que tengan ‡v(T) < Entonces de nuevo de la ecuación (9) se deduce que v(S) < Esto contradice (8), por lo que de hecho tenemos v(T) = Por lo tanto (T, v(T)) no está actualmente en nuestra hipótesis como una oferta atómica, o tendríamos correctamente?v(T) = v(T) por la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas adicionales de equivalencia hasta que todas las ofertas atómicas hayan sido identificadas. Después de cada consulta de equivalencia, una oferta atómica se identifica con como máximo m consultas de membresía. Cada contraejemplo conduce al descubrimiento de una nueva oferta atómica. Por lo tanto, hacemos a lo sumo consultas de membresía tm y exactamente consultas de equivalencia t + 1. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR se puede obtener eficientemente de las consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al.s ([5], Teorema 2) afirmando que el DNF monotono (y por lo tanto las ofertas XOR) no se pueden obtener de manera eficiente cuando las consultas de demanda se limitan a precios lineales y anónimos sobre las mercancías. 6.3 Las representaciones lineales de umbral polinomios, las ofertas XOR y todas las lenguas basadas en el lenguaje de licitación OR (como XOR-de-OR, OR-de-XOR y OR*) no representan sucintamente la valoración mayoritaria [11]. En esta valoración, los paquetes tienen valor 1 si contienen al menos m/2 ítems, y valor 0 de lo contrario. Más generalmente, considere la familia de r-of-S de valoraciones donde los paquetes tienen valor 1 si contienen al menos r artículos de un conjunto especificado de ítems S  M, y valor 0 de otra manera. La valoración mayoritaria es un caso especial de la valoración de r-of-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar las sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede añadir valor. Dejando k = S, tales valoraciones están sucintamente representadas por funciones de umbral r-of-k. Estas funciones adoptan la forma de desigualdades lineales: xi1 +. . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se mantiene, y 0 de lo contrario. Aquí i1,. . . , ik son los elementos en S. Littlestones WINNOW 2 algoritmo puede aprender tales funciones utilizando consultas de equivalencia sólo, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de excitación que resulta de WINNOW 2 sólo utiliza consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos están implícitos cuando sólo hay dos valores posibles). Tenga en cuenta que las funciones de umbral r-of-k siempre se pueden representar sucintamente en el espacio O(m). Así se obtiene un algoritmo que puede generar tales funciones con un número polinomio de consultas y comunicación polinomio, en los parámetros n y m solos. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exactos con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de excitación de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas en el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la riqueza de algoritmos de aprendizaje disponibles al problema de la excitación de preferencias. Un enfoque de aprendizaje para la excitación también motiva un enfoque diferente para diseñar algoritmos de excitación que se descomponen cuidadosamente entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivos, muchos sustitutos, etc.), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de excitación. El algoritmo de excitación resultante hace un número polinomio de consultas, y hace comunicación polinomio si los algoritmos de aprendizaje originales son eficientes. No exigimos que las valoraciones de agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia sólo pueden ser, y sólo necesitan ser, simuladas hasta el punto en que se ha calculado una asignación óptima. Este es el problema de la excitación de preferencias. Teorema 1 implica que la excitación con consultas de valor y demanda no es más difícil que aprender con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las que la excitación es más fácil que el aprendizaje. Blum et al. [5] proporcionar tal ejemplo al considerar solamente consultas de membresía/valor (Teorema 4). En el trabajo futuro planeamos abordar la cuestión de los incentivos al convertir algoritmos de aprendizaje a algoritmos de excitación. En el entorno de aprendizaje, por lo general suponemos que los oráculos proporcionarán respuestas honestas a las preguntas; en el entorno de excitación, los agentes son generalmente egoístas y proporcionarán respuestas posiblemente deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para el aprendizaje de polinomios y ofertas XOR como algoritmos de excitación, y probar su rendimiento contra otros protocolos de subasta combinatoria establecidos [6, 15]. Una pregunta interesante aquí es: ¿qué precios Lindahl en el rango máximo a mínimo son los mejores para citar con el fin de minimizar la revelación de información? Suponemos que la revelación de información se reduce al pasar de precios máximos a precios mínimos de Lindahl, es decir, a medida que desplazamos las consultas de demanda más lejos de las consultas de equivalencia. Por último, sería útil determinar si el lenguaje de licitación de OR* [11] puede aprenderse (y, por lo tanto, obtenerse) de manera eficiente, dada la expresividad y sucinta de estas lenguas para una amplia variedad de clases de valoración. Agradecimientos Queremos agradecer a Debasis Mishra por sus útiles discusiones. Este trabajo está apoyado en parte por la subvención de NSF IIS0238147. 8. REFERENCIAS [1] A. Andersson, M. Tenhunen, y F. Ygge. Programación integral para la determinación del ganador de la subasta combinatoria. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprender conjuntos regulares de consultas y contraejemplos. Información e computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje conceptual. Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El modelo de asignación de paquetes. Diario de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Provocación de preferencias y aprendizaje de consultas. En Proc. 16a Conferencia Anual sobre Teoría del Aprendizaje Computacional (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. la 18a Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, e Y. Shoham. Domar la complejidad computacional de las subastas combinatoria: Enfoques óptimos y aproximados. En Proc. , 16a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), págs. 548 a 553, 1999. [8] B. Hudson y T. Sandholm. Uso de consultas de valor en subastas combinatoria. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría del aprendizaje computacional. MIT Press, 1994. [10] N. Littlestone. Aprender rápidamente cuando los atributos irrelevantes abundan: Un nuevo algoritmo de umbral lineal. Machine Learning, 2:285-318, 1988. [11] N. Nisan. Licitación y asignación en subastas combinatoria. En Proc. la Conferencia de la ACM sobre Comercio Electrónico, págs. 1 a 12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y el apoyo a los precios Lindahl. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de mínima revelación. En Padget et al., editor, Agent-Mediated Electronic Commerce IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. Diseño de subastas con costosas preferencias. En Temas Especiales de Anales de Matemáticas y AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17a Conferencia Nacional sobre Inteligencia Artificial (AAAI-00), págs. 74 a 81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. la 17a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariables escasos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de ACM sobre Teoría del Aprendizaje Computacional, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendido. Comun. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum, y T. Sandholm. Sobre la excitación de la preferencia polinomio-tiempo con las consultas de valor. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "error": [
                "paralizar",
                "paralelar",
                "paralelo"
            ]
        },
        "preference elicitation problem": {
            "translated_key": [
                "problema de excitación Demostramos que los algoritmos de aprendizaje pueden ser usados como base para algoritmos de excitación de preferencias. Los algoritmos de excitación resultantes realizan un número polinomio de consultas. También damos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. En particular, se obtiene un algoritmo que provoca pujas XOR con comunicación polinómica. Categorías y Descriptores sujetos F.2.0 [Análisis de algoritmos y complejidad de problemas]: General; J.4 [Ciencias Sociales y Conductuales]: Economía; I.2.6 [Inteligencia Artificial]: Términos generales de aprendizaje Algoritmos, Economía, Teoría 1. INTRODUCCIÓN En una subasta combinatoria, los agentes pueden pujar por paquetes de bienes en lugar de por cada uno de ellos. Puesto que hay un número exponencial de paquetes (en el número de bienes), comunicar los valores sobre estos paquetes puede ser problemático. Comunicar las valoraciones de una sola vez puede ser prohibitivamente costoso si el número de bienes es sólo moderadamente grande. Además, incluso podría ser difícil para los agentes determinar sus valoraciones para paquetes únicos [14]. A esos agentes les interesa disponer de protocolos de subasta que les obliguen a pujar en el menor número posible de paquetes. Incluso si los agentes pueden calcular eficientemente sus valoraciones, podrían ser reacios a revelarlas enteramente en el curso de una subasta, porque tal información puede ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información necesaria para determinar una asignación óptima de los bienes. Ha habido un trabajo reciente explorando los vínculos entre el ",
                " en las subastas combinatoria y el problema de aprender una función desconocida de la teoría del aprendizaje computacional [5, 19]. En teoría de aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, tales como ¿Cuál es el valor de las funciones en estas entradas? En la obtención de preferencia, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Demostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia se puede convertir en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de excitación resultante garantiza la excitación en un número polinomio de consultas de valor y demanda. Aquí queremos decir polinomio en el número de bienes, agentes, y los tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Argumentamos que las garantías de complejidad para los esquemas de excitación deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar la comunicación polinómica en el peor de los casos, que normalmente no se puede lograr en el número de productos y agentes por sí solos. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. Por supuesto, una subasta combinatoria de un solo disparo donde los agentes proporcionan todas sus funciones de valoración a la vez también tendría comunicación polinómica en el tamaño de las valoraciones de los agentes, y sólo requieren una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay ninguna carga para los agentes de formular sus valoraciones en un esquema de codificación de los subastadores que elijan. Esperamos que esta sea una consideración importante en la práctica. Además, con nuestro esquema la revelación entera sólo ocurre en el peor de los casos. 180 Por ahora, dejamos a un lado la cuestión de los incentivos al derivar algoritmos de excitación. Nos centramos en el tiempo y la complejidad de la comunicación de la obtención de preferencias, independientemente de las limitaciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich y otros [19] considerar el problema del aprendizaje de clases restringidas de funciones de valoración que se pueden representar utilizando fórmulas de lectura once y Toolbox DNF. Las fórmulas Read-once pueden representar ciertas sustitutibilidades, pero no complementariedades, mientras que lo contrario se mantiene para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten depender del tamaño de la valoración objetivo como lo hacemos (aunque las valoraciones de read-once siempre se pueden representar sucintamente de todos modos). Su trabajo sólo hace uso de consultas de valor, que son bastante limitados en el poder. Debido a que nos permitimos pedir consultas, somos capaces de derivar un esquema de excitación para las funciones de valoración general. Blum et al. [5] proporcionar resultados relacionados con las complejidades del aprendizaje de la consulta y la excitación de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje de consultas, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones se pueden aprender eficientemente, pero no se pueden obtener eficientemente, y viceversa. En contraste, nuestro trabajo muestra que dada una versión más general (todavía bastante estándar) de la consulta de demanda que el tipo que consideran, la complejidad de la excitación de preferencia no es mayor que la complejidad del aprendizaje. Demostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre valoraciones para implicar una solución al problema de excitación. Nisan y Segal [12] estudian la complejidad comunicativa de la excitación de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos de la computación una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo se permite a los algoritmos hacer preguntas sobre valoraciones de agentes y recibir respuestas honestas, sin ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda la cuestión de la complejidad de la comunicación, y somos capaces de derivar algoritmos que proporcionan garantías de comunicación significativas a pesar de los resultados negativos de Nisan y Segals. Su trabajo motiva la necesidad de confiar en el tamaño de los agentes funciones de valoración para indicar los peores resultados. 2. LOS MODELOS 2.1 Aprendizaje de la consulta El modelo de aprendizaje de la consulta que consideramos aquí se llama aprendizaje exacto de la membresía y consultas de equivalencia, introducido por Angluin [2]. En este modelo el objetivo de los algoritmos de aprendizaje es identificar exactamente una función diana desconocida f : X → Y a través de consultas a un oráculo. La función de destino se extrae de una función de clase C que es conocida por el algoritmo. Típicamente el dominio X es algún subconjunto de {0, 1}m, y el rango Y es {0, 1} o algún subconjunto de los números reales. A medida que el algoritmo avanza, construye una hipótesis manifiesta?f que es su estimación actual de la función de destino. Después de la terminación, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface?f(x) = f(x) para todos x?X. Es importante especificar la representación que se utilizará para codificar funciones de C. Por ejemplo, considere la siguiente función de {0, 1}m a ♥: f(x) = 2 si x consiste en m 1s, y f(x) = 0 de otra manera. Esta función puede representarse simplemente como una lista de valores de 2m. O puede codificarse como el polinomio 2x1 · · · xm, que es mucho más sucinto. Así pues, la elección de la codificación puede tener un impacto significativo en las necesidades de tiempo y espacio del algoritmo de aprendizaje. Let size(f) ser el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes distintos de cero en el polinomio, por ejemplo. Por lo general, sólo nos referiremos a las clases de representación; las clases de funciones correspondientes serán implícitas. Por ejemplo, la clase de representación de fórmulas DNF monotonas implica la clase de función de funciones booleanas monotonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: la membresía y las consultas de equivalencia. En una consulta de membresía, el aprendiz presenta algunas x x x y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta f. El oráculo responde SÍ si?f = f, o devuelve un contraejemplo x de tal manera que?f(x) = f(x). Una consulta de equivalencia es apropiada si el tamaño( ̃f) ≤ tamaño(f) en el momento de presentar la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones se adaptan a partir de Kearns y Vazirani [9]: Definición 1. La clase de representación C es polinomialquery exactamente aprendeble de las consultas de membresía y equivalencia si hay un polinomial fijo p(·, ·) y un algoritmo L con acceso a la membresía y consultas de equivalencia de un oráculo tal que para cualquier función de destino f • C, L salidas después de a lo sumo p(size(f), m) consultas de una función?f • C tal que?f Del mismo modo, la clase de representación C se puede aprender exactamente de las consultas de membresía y equivalencia si el algoritmo L produce una hipótesis correcta en el tiempo p(size(f), m), para algunos polinomios fijos p(·, ·). Aquí m es la dimensión del dominio. Dado que la función de destino debe ser reconstruida, también permitimos necesariamente la dependencia polinómica del tamaño (f). 2.2 Eliminación de preferencias En una subasta combinatoria, un conjunto de bienes M se asignará entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Tal asignación se llama eficiente en la literatura de economía, pero nos referiremos a ella como óptima y reservar el término eficiente para referirse a la eficiencia computacional. Dejamos n = N y m = M. Una asignación es una partición de los objetos en paquetes (S1,. . . , Sn), de tal manera que Si â € ¬ Sj = â € para todos los i, j â € N. Let â € € sea el conjunto de posibles asignaciones. Cada agente i+N tiene una función de valoración vi : 2M → • sobre el espacio de los paquetes posibles. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no tienen que coincidir. Asumimos que todas las valoraciones consideradas están normalizadas, es decir, v() = 0, y que no hay externalidades, es decir, vi(S1,..., Sn) = vi(Si), para todos los agentes i  N, para cualquier asignación (S1,..., Sn)  (es decir, un agente se preocupa sólo por el paquete asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales.1 Nosotros 1 A menudo las valoraciones generales se hacen para satisfacer los 181 adicionales también asumen que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que los agentes utilidades pueden ser divididos en componentes monetarios y no monetarios. Si a un agente i se le asigna el paquete S al precio p, deriva utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más sucintas para ciertas clases de valoración, y ha habido mucha investigación en lenguajes de licitación concisos para diversos tipos de valoraciones [11]. Un ejemplo clásico al que nos referiremos más adelante es el lenguaje de licitación XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, que consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estas pujas, se busca el paquete S del valor más alto listado en las pujas atómicas de tal manera que S  S. Es entonces el caso que v(S) = v(S). Al igual que en el contexto de la teoría del aprendizaje, por lo general sólo nos referiremos a idiomas de oferta en lugar de clases de valoración, ya que las clases de valoración correspondientes serán implícitas. Por ejemplo, el lenguaje de licitación XOR implica la clase de valoraciones que satisfacen la disposición libre, que es la condición de que A  B ♥ v(A) ≤ v(B). Dejamos el tamaño(v1,. . . , vn) = Èn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de licitación). Para hacer una analogía con la teoría del aprendizaje computacional, suponemos que todas las clases de representación consideradas son polinomiamente interpretables [11], lo que significa que el valor de un paquete puede ser calculado en tiempo polinomio dada la representación de funciones de valoración. Más formalmente, una clase de representación (lenguaje de licitación) C es polinomialmente interpretable si existe un algoritmo que da como entrada algunos v • C y una instancia x • X calcula el valor v(x) en el tiempo q(size(v), m), para algún polinomio fijo q(·, ·).2 En las rondas intermedias de una subasta (terativa), el subastador habrá obtenido información sobre las funciones de Por lo tanto, habrá construido un conjunto de valoraciones manifiestas, denotadas . . Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha adquirido información sobre ciertos paquetes. El objetivo en el ",
                " es construir un conjunto de valoraciones manifiestas tales que: arg max (S1,...,Sn) iÃ3n ̃vi(Si)  arg max (S1,...,Sn) iÃ3n vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que es óptima con respecto a las valoraciones verdaderas. Tenga en cuenta que sólo se requiere una asignación óptima. condición de la libre eliminación (monotonicidad), pero no la necesitamos en este punto. 2 Esto excluye OR*, asumiendo P = NP, porque la interpretación de las ofertas de este lenguaje es NP-duro por reducción de set-embalaje ponderado, y no hay clase de representación bien estudiada en teoría de aprendizaje que es claramente análogo a OR*. 3 Esta visión de las subastas iterativas tiene por objeto paralelizar el entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente están implícitas por la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son consultas de valor y demanda. En una consulta de valor, el subastador presenta un paquete S  M y el agente responde con su valor (exacto) para el paquete v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p • • • (2m ) sobre los paquetes junto con un paquete S. El agente responde SI si es el caso de que S • arg max S M v(S ) − p(S ) ¡ o de otro modo presenta un paquete S tal que v(S ) − p(S ) > v( Tenga en cuenta también que comunicar precios no lineales no implica necesariamente citar un precio por cada paquete posible. Puede haber formas más sucintas de comunicar este vector, como se muestra en la sección 5. Hacemos las siguientes definiciones para paralelizar la configuración de aprendizaje de la consulta y para simplificar las declaraciones de resultados posteriores: Definición 2. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si hay un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes tales que para cualquier (v1,. . . , vn) V1 ×. . . × Vn, L salidas después de como máximo p(size(v1,. . . , vn), m) consulta una asignación (S1,. . . , Sn) arg max(S1,...,Sn) È vi(Si). Del mismo modo, la clase de representación C se puede obtener eficientemente de las consultas de valor y demanda si el algoritmo L produce una asignación óptima con comunicación p(size(v1, ). . . , vn), m), para algunos polinomios fijos p(·, ·). Hay algunas diferencias clave aquí con la definición de aprendizaje de la consulta. Hemos eliminado el término exactamente ya que las funciones de valoración no necesitan ser determinadas exactamente con el fin de calcular una asignación óptima. Además, un algoritmo de excitación eficiente es la comunicación polinomio, en lugar de tiempo polinomio. Esto refleja el hecho de que la comunicación en lugar del tiempo de espera es el cuello de botella en la excitación. Cálculo de una asignación óptima de bienes incluso cuando se dan las valoraciones verdaderas es NP-duro para una amplia gama de clases de valoración. Por lo tanto, no es razonable exigir tiempo polinomio en la definición de un algoritmo de excitación de preferencias eficiente. Nos complace centrarnos en la complejidad comunicativa de la excitación porque se cree que este problema es más significativo en la práctica que el de la determinación del ganador [11].5 4 Esto difiere ligeramente de la definición proporcionada por Blum et al. [5] Sus consultas sobre la demanda se limitan a precios lineales sobre las mercancías, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir. un precio distinto por cada paquete posible. Es por eso que el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. 5 Aunque el problema de determinación del ganador es NP-hard para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta aproximaciones usando solucionadores IP fuera de la plataforma [1]. 182 Dado que no es necesario obtener exactamente las valoraciones, es inicialmente menos claro si la dependencia polinómica del tamaño (v1, ). . . , vn) está justificado en este contexto. Intuitivamente, este parámetro está justificado porque debemos aprender valoraciones exactamente cuando se realiza la excitación, en el peor de los casos. Nos ocupamos de esto en la siguiente sección. 3. PARALLESBETWEEN EQUIVALENCIA Y QUERIDAS DE DEMANDA Hemos descrito los ajustes de aprendizaje y excitación de preferencias de la consulta de una manera que destaca sus similitudes. Las consultas de valor y membresía son claras analógicas. Un poco menos obvio es el hecho de que las consultas de equivalencia y demanda también son analógicas. Para ver esto, necesitamos el concepto de precios Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios sobre sus bienes subyacentes. Son no anónimos en el sentido de que dos agentes pueden tener que hacer frente a precios diferentes para el mismo paquete de mercancías. Así los precios de Lindahl son de la forma pi(S), para todos S  M, para todos los precios de i  N. Lindahl se presentan a los agentes en consultas de la demanda. Cuando los agentes han normalizado las funciones de utilidad cuasi-lineal, Bikhchandani y Ostroy [4] muestran que siempre existen precios Lindahl tales que (S1,. . . , Sn) es una asignación óptima si y sólo si Si • arg max Si vi(Si) − pi(Si) • i N (1) (S1,. . . , Sn)  arg max (S1,...,Sn) iN pi(Si) (2) Condición (1) establece que cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos de los subastadores a los precios indicados. El escenario en el que se mantienen estas condiciones se llama equilibrio Lindahl, o a menudo un equilibrio competitivo. Decimos que los precios de Lindahl apoyan la asignación óptima. Por lo tanto, basta con anunciar los precios de apoyo de Lindahl para verificar una asignación óptima. Una vez que hemos encontrado una asignación con el apoyo de precios Lindahl, el problema de excitación se resuelve. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones estén garantizadas como integrales [4]. Las variables duales de este programa lineal están soportando los precios de Lindahl para la asignación resultante. La función objetiva del programa dual es: min pi(S) Por lo general, hay una gama de posibles precios Lindahl que apoyan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios válidos Lindahl, y nos referimos a ellos como precios máximos Lindahl. De todos los vectores posibles de precios Lindahl, precios máximos Lindahl maximizar la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È iÃ3N πi del objetivo (la suma de los agentes de utilidades) son precios mínimos Lindahl. Cualquier Lindahl precios hará para nuestros resultados, pero algunos pueden tener mejores propiedades de excitación que otros. Tenga en cuenta que una consulta de demanda con precios máximos de Lindahl es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para el trabajo futuro la cuestión de los precios de Lindahl para elegir minimizar la obtención de preferencias. Teniendo en cuenta ahora por qué las consultas de demanda y equivalencia son analógicas directas, primero tenga en cuenta que dado el πi en algún equilibrio Lindahl, establecer pi(S) = max{0, Estos precios dejan a cada agente indiferente en todos los paquetes con precio positivo, y satisfacen la condición (1). Así, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl típicamente serán una constante aditivo lejos de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos de consultas de equivalencia a través de consultas de demanda. Lemma 1. Supongamos que un agente responde con un paquete preferido S cuando se propone un paquete S y soporta los precios de Lindahl p(S) (soportando con respecto a la valoración manifiesta de los agentes). A continuación, o bien?v(S) = v(S) o?v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: Φv(S) − p(S) ≥ Desigualdad (6) se mantiene porque el agente de hecho prefiere S a S dados los precios, de acuerdo con su respuesta a la consulta de demanda. Si fuera el caso de que?v(S) = v(S) y Así, al menos uno de S y S es un contraejemplo de la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño(v1,. . . , vn) en problemas de excitación. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que apoyar los precios de Lindahl debe necesariamente revelarse en el curso de cualquier protocolo de obtención de preferencias que termina con una asignación óptima. Además, Nisan y Segal (Lemma 1, [12]) afirman que en el peor de los casos los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones dobles (como será el caso de las clases más interesantes). Puesto que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y puesto que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitiendo la dependencia del tamaño(v1,. . . , vn) en problemas de excitación es totalmente natural. 183 4. DE APRENDIZAJE A LA LICITACIÓN DE PREFERENCIA La clave para convertir un algoritmo de aprendizaje a un algoritmo de excitación es simular consultas de equivalencia con consultas de demanda y valor hasta que se encuentre una asignación óptima. Debido a nuestra construcción de precios Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en que un agente responde SÍ a una consulta de equivalencia cuando la función de destino se ha aprendido exactamente. De lo contrario, podemos obtener un contraejemplo a una consulta de equivalencia dada una respuesta de agentes a una consulta de demanda. Teorema 1. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si cada uno puede ser polinomio-consulta exactamente aprendido de consultas de membresía y equivalencia. Prueba. Considere el algoritmo de excitación en la Figura 1. Cada consulta de membresía en el paso 1 es simulada con una consulta de valor ya que estas son de hecho idénticas. Considere el paso 4. Si todos los agentes responden SÍ, la condición (1) se mantiene. Condición (2) se mantiene porque la asignación calculada es la maximización de ingresos para el subastador, independientemente de los agentes verdaderas valoraciones. Así pues, se ha encontrado una asignación óptima. De lo contrario, por lo menos uno de Si o Si es un contraejemplo a Vi, por Lemma 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones del agente se conocerán exactamente, en cuyo caso la asignación óptima y los precios Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinomio de consultas, desde A1,. . . , A son todos los algoritmos de aprendizaje polinomio-quería. Tenga en cuenta que el procedimiento de conversión resulta en un algoritmo de excitación de preferencias, no un algoritmo de aprendizaje. Es decir, el algoritmo resultante no simplemente aprender las valoraciones exactamente, a continuación, calcular una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor, y periódicamente comprueba si se ha reunido suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio Lindahl para las valoraciones v1,. . . , vn utilizando una asignación y precios derivados de valoraciones manifiestas . . y encontrar una asignación óptima no implica que las valoraciones de los agentes se hayan aprendido exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta interrupción temprana. No obtendremos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE COMUNICACIÓN En esta sección, pasamos a la cuestión de la complejidad comunicativa de la excitación. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (tales como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos de determinar los precios de Lindahl es exponencial en el número de mercancías, m. La carga de comunicación se mide en términos del número de bits transmitidos entre agentes y subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. La conversión de algoritmos de aprendizaje eficientes a un algoritmo de excitación produce un algoritmo cuyas consultas tienen tamaños polinomios en los parámetros m y tamaño (v1, ). . . , vn). Teorema 2. Las clases de representación V1,. . . , Vn se puede obtener de forma eficiente de las consultas de valor y demanda si cada uno puede ser aprendido exactamente de las consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, basta con comunicar la función de valoración manifiesta de los agentes y el valor Nótese que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinomio, porque el tiempo de ejecución de los algoritmos también sería superpolinomio, contradiciendo la eficiencia. Por lo tanto, la comunicación de la valoración manifiesta requiere tamaño a lo sumo p(size(vi), m), para algunos polinomios p que limita superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representando el excedente πi al agente no se puede requerir espacio mayor que q(size( También debemos comunicarnos con su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es como máximo p(size(vi), m) + q(p(size(vi), m), m)+O(m). Claramente, una respuesta de agentes a una consulta de valor o demanda tiene un tamaño máximo de q(size(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, son siempre de tamaño polinomio. Un algoritmo de aprendizaje eficiente realiza un número polinomio de consultas, por lo que la comunicación total del algoritmo de excitación resultante es polinomio en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites pueden ser traducidos a límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de excitación resultante. Con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2 se determinó el tamaño de la hipótesis manifiesta. Es probable que podamos hacerlo mucho mejor que esto en la práctica. Recuerde que una consulta de equivalencia es apropiada si size( ̃f) ≤ size(f) en el momento de realizar la consulta. Si las consultas de equivalencia de algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites estrechos en los requisitos de comunicación del algoritmo de excitación resultante. El teorema 2 muestra que los algoritmos de excitación que dependen del tamaño (v1,. . . El parámetro, vn) evita los resultados negativos de Nisan y Segals [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto al tamaño de las instancias de las funciones de valoración que se enfrentan a cualquier ejecución del algoritmo. Estos algoritmos van bien si la clase de representación elegida proporciona representaciones sucintas para la más simple y común de las valoraciones, y por lo tanto el enfoque se mueve de nuevo a uno de lenguajes de licitación compactos pero expresivos. A continuación se examinan estas cuestiones. 6. APLICACIONES En esta sección, demostramos la aplicación de nuestros métodos a clases particulares de representación para valoraciones combinatorias. Hemos demostrado que el ",
                " para las clases de valoración V1,. . . , Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1,. . . , Una para las valoraciones de las clases V1,. . . , Vn respectivamente. Encaje hasta que haya una señal para detenerse: 1. Corre A1,. . . , Un en paralelo sobre sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se ha detenido con los agentes valoración exacta. 2. Calcular una asignación óptima (S1,. . . , Sn ) y los correspondientes precios de Lindahl con respecto a las valoraciones manifiestas . . , їvn determinado hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de consulta de demanda. 4. Si todos ellos responden SÍ, salida la asignación y parada. De lo contrario hay algún agente i que ha respondido con algún paquete preferido Si. Realizar consultas de valor en Si y Si para encontrar un contraejemplo a ‡vi, y proporcionarlo a Ai. Figura 1: Convertir algoritmos de aprendizaje a un algoritmo de excitación. al problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de función, y porque a menudo puede ser más simple resolver cada subproblema de aprendizaje por separado que atacar el ",
                " directamente. Podemos desarrollar un algoritmo de excitación que se adapta a cada valoración de agentes, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Demostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas de DNF monotono y funciones de umbral lineal se pueden convertir en algoritmos de excitación de preferencia para valoraciones generales, valoraciones con eliminación libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en las representaciones que son polinomialmente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la traqueabilidad computacional [18]. Al interpretar los métodos enfatizamos la expresividad y sucinta de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de licitación, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debe representar sucintamente las funciones más simples y comunes de la clase. 6.1 Las Representaciones Polinómicas Schapire y Sellie [17] dan un algoritmo de aprendizaje para polinomios multivariables escasos que pueden utilizarse como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas apropiadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados de t-sparse sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-sparse tiene como máximo t términos, donde un término es un producto de variables, por ejemplo. x1x3x4. Un polinomio sobre los números reales tiene coeficientes extraídos de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M →  se puede escribir exclusivamente como un polinomio [17]. Para tener una idea de la sucintaidad de los polinomios como lenguaje de licitación, considere las valoraciones aditivas y mono-ítem presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es el número de mercancías que contiene el paquete. En la valoración de un solo elemento, todos los paquetes tienen valor 1, excepto el valor 0 (i.e. el agente está satisfecho tan pronto como ha adquirido un único artículo). No es difícil demostrar que la valoración de un solo elemento requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Por lo tanto, los polinomios son adecuados para valoraciones que en su mayoría son aditivas, con algunas sustituibilidades y complementariedades que pueden introducirse ajustando los coeficientes. El algoritmo de aprendizaje para polinomios hace como máximo consultas de equivalencia mti +2 y como máximo (mti +1) (t2 i +3ti)/2 consultas de membresía a un agente i, donde ti es la esparcidad del polinomio que representa vi [17]. Por lo tanto, se obtiene un algoritmo que provoca valoraciones generales con un número polinomio de consultas y comunicación polinomio.6 6.2 XOR Representaciones El lenguaje de licitación XOR es estándar en la literatura de subastas combinatoria. Recordemos que una oferta XOR se caracteriza por un conjunto de paquetes B  2M y una función de valor w : B →  definida en esos paquetes, que induce la función de valoración: v(B) = max {B  B  B  B} w(B) (7) Las ofertas XOR pueden representar valoraciones que satisfacen la libre eliminación (y sólo tales valoraciones), que de nuevo es la propiedad que A  B El lenguaje de licitación XOR es ligeramente menos expresivo que los polinomios, porque los polinomios pueden representar valoraciones que no satisfacen la libre eliminación. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas de XOR pueden representar la valoración de un solo elemento con ofertas atómicas m, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario se aplica a los polinomios, estas dos lenguas son incomparables en sucintas y algo complementarias para su uso práctico. Blum et al. [5] note que las fórmulas DNF monotonas son los análogos de las pujas XOR en la literatura de teoría del aprendizaje. Una fórmula de DNF monotona es una disyunción de conjunciones en las que las variables aparecen sin negación, por ejemplo x1x2 x3 x2x4x5. Tenga en cuenta que tales fórmulas pueden ser representadas como ofertas XOR donde cada oferta atómica tiene valor 1; por lo tanto XOR ofrece generalizar fórmulas DNF monotono de Boolean a funciones de valor real. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para el DNF monotono ([3] Teorema 6 Tenga en cuenta que el Teorema 1 se aplica incluso si las valoraciones no satisfacen la eliminación libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lemma 2. Una oferta XOR que contiene ofertas t atómicas se puede aprender exactamente con consultas de equivalencia t + 1 y a lo sumo consultas de membresía tm. Prueba. El algoritmo identificará cada puja atómica en la puja XOR objetivo a su vez. Initialice la valoración manifiesta v a la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presente ‡v como consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un paquete S para el que v(S) = Crear un paquete T de la siguiente manera. Primero inicialice T = S. Para cada elemento i en T, compruebe a través de una consulta de membresía si v(T) = v(T − {i}). Si así se establece T = T − {i}. De lo contrario, deje T como está y pase al siguiente punto. Afirmamos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada ítem i en T, tenemos v(T) = v(T − {i}). Para ver esto, tenga en cuenta que en algún momento al generar T, tuvimos un ̄T tal que T  ̄T  S y v( ̄T) > v( ̄T − {i}), de modo que me mantuvo en ̄T. Tenga en cuenta que v(S) = v( ̄T) = v(T) porque el valor del paquete S se mantiene durante todo el proceso de eliminación de elementos. Ahora asume v(T) = v(T − {i}). Entonces v( ̄T) = v(T) = v(T − {i}) > v( ̄T − {i}) que contradice la libre eliminación, ya que T {i}  ̄T − {i}. Por lo tanto v(T) > v(T − {i}) para todos los ítems i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si este no fuera el caso, T tomaría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = máx itat {max T T Ahora mostramos que v(T) = ̃v(T), que implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Asumir que toda oferta atómica (R, Esta suposición se mantiene vagamente cuando se inicializa la valoración manifiesta. Usando la notación de (7), dejar ( Tenemos B  B, y Bw(B) = w(B) para B Por lo tanto,?v(S) = max {B} {B} {B} {B} {B} {B} = max {B} {B} {B} ≤ {B} {B} {B} {B} {S} w(B} = v(S) (8) Ahora asume v(T) {v(T La segunda igualdad se deriva del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad sostiene porque S es un contraejemplo de la valoración manifiesta. De la ecuación (9) y la eliminación libre, nosotros 7 El algoritmo citado también se utilizó como base para Zinkevich et al.s [19] algoritmo de excitación para Toolbox DNF. Recuerde que Toolbox DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia se puede simular con una consulta de valor en el paquete que contiene todas las mercancías. que tengan ‡v(T) < Entonces de nuevo de la ecuación (9) se deduce que v(S) < Esto contradice (8), por lo que de hecho tenemos v(T) = Por lo tanto (T, v(T)) no está actualmente en nuestra hipótesis como una oferta atómica, o tendríamos correctamente?v(T) = v(T) por la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas adicionales de equivalencia hasta que todas las ofertas atómicas hayan sido identificadas. Después de cada consulta de equivalencia, una oferta atómica se identifica con como máximo m consultas de membresía. Cada contraejemplo conduce al descubrimiento de una nueva oferta atómica. Por lo tanto, hacemos a lo sumo consultas de membresía tm y exactamente consultas de equivalencia t + 1. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR se puede obtener eficientemente de las consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al.s ([5], Teorema 2) afirmando que el DNF monotono (y por lo tanto las ofertas XOR) no se pueden obtener de manera eficiente cuando las consultas de demanda se limitan a precios lineales y anónimos sobre las mercancías. 6.3 Las representaciones lineales de umbral polinomios, las ofertas XOR y todas las lenguas basadas en el lenguaje de licitación OR (como XOR-de-OR, OR-de-XOR y OR*) no representan sucintamente la valoración mayoritaria [11]. En esta valoración, los paquetes tienen valor 1 si contienen al menos m/2 ítems, y valor 0 de lo contrario. Más generalmente, considere la familia de r-of-S de valoraciones donde los paquetes tienen valor 1 si contienen al menos r artículos de un conjunto especificado de ítems S  M, y valor 0 de otra manera. La valoración mayoritaria es un caso especial de la valoración de r-of-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar las sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede añadir valor. Dejando k = S, tales valoraciones están sucintamente representadas por funciones de umbral r-of-k. Estas funciones adoptan la forma de desigualdades lineales: xi1 +. . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se mantiene, y 0 de lo contrario. Aquí i1,. . . , ik son los elementos en S. Littlestones WINNOW 2 algoritmo puede aprender tales funciones utilizando consultas de equivalencia sólo, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de excitación que resulta de WINNOW 2 sólo utiliza consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos están implícitos cuando sólo hay dos valores posibles). Tenga en cuenta que las funciones de umbral r-of-k siempre se pueden representar sucintamente en el espacio O(m). Así se obtiene un algoritmo que puede generar tales funciones con un número polinomio de consultas y comunicación polinomio, en los parámetros n y m solos. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exactos con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de excitación de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas en el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la riqueza de algoritmos de aprendizaje disponibles al problema de la excitación de preferencias. Un enfoque de aprendizaje para la excitación también motiva un enfoque diferente para diseñar algoritmos de excitación que se descomponen cuidadosamente entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivos, muchos sustitutos, etc.), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de excitación. El algoritmo de excitación resultante hace un número polinomio de consultas, y hace comunicación polinomio si los algoritmos de aprendizaje originales son eficientes. No exigimos que las valoraciones de agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia sólo pueden ser, y sólo necesitan ser, simuladas hasta el punto en que se ha calculado una asignación óptima. Este es el "
            ],
            "translated_annotated_text": "Aplicando algoritmos de aprendizaje a la eliminación preferente Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el \"problema de excitación Demostramos que los algoritmos de aprendizaje pueden ser usados como base para algoritmos de excitación de preferencias. Los algoritmos de excitación resultantes realizan un número polinomio de consultas. También damos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. En particular, se obtiene un algoritmo que provoca pujas XOR con comunicación polinómica. Categorías y Descriptores sujetos F.2.0 [Análisis de algoritmos y complejidad de problemas]: General; J.4 [Ciencias Sociales y Conductuales]: Economía; I.2.6 [Inteligencia Artificial]: Términos generales de aprendizaje Algoritmos, Economía, Teoría 1. INTRODUCCIÓN En una subasta combinatoria, los agentes pueden pujar por paquetes de bienes en lugar de por cada uno de ellos. Puesto que hay un número exponencial de paquetes (en el número de bienes), comunicar los valores sobre estos paquetes puede ser problemático. Comunicar las valoraciones de una sola vez puede ser prohibitivamente costoso si el número de bienes es sólo moderadamente grande. Además, incluso podría ser difícil para los agentes determinar sus valoraciones para paquetes únicos [14]. A esos agentes les interesa disponer de protocolos de subasta que les obliguen a pujar en el menor número posible de paquetes. Incluso si los agentes pueden calcular eficientemente sus valoraciones, podrían ser reacios a revelarlas enteramente en el curso de una subasta, porque tal información puede ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información necesaria para determinar una asignación óptima de los bienes. Ha habido un trabajo reciente explorando los vínculos entre el \"problema de la excitación preferente\" en las subastas combinatoria y el problema de aprender una función desconocida de la teoría del aprendizaje computacional [5, 19]. En teoría de aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, tales como ¿Cuál es el valor de las funciones en estas entradas? En la obtención de preferencia, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Demostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia se puede convertir en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de excitación resultante garantiza la excitación en un número polinomio de consultas de valor y demanda. Aquí queremos decir polinomio en el número de bienes, agentes, y los tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Argumentamos que las garantías de complejidad para los esquemas de excitación deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar la comunicación polinómica en el peor de los casos, que normalmente no se puede lograr en el número de productos y agentes por sí solos. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. Por supuesto, una subasta combinatoria de un solo disparo donde los agentes proporcionan todas sus funciones de valoración a la vez también tendría comunicación polinómica en el tamaño de las valoraciones de los agentes, y sólo requieren una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay ninguna carga para los agentes de formular sus valoraciones en un esquema de codificación de los subastadores que elijan. Esperamos que esta sea una consideración importante en la práctica. Además, con nuestro esquema la revelación entera sólo ocurre en el peor de los casos. 180 Por ahora, dejamos a un lado la cuestión de los incentivos al derivar algoritmos de excitación. Nos centramos en el tiempo y la complejidad de la comunicación de la obtención de preferencias, independientemente de las limitaciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich y otros [19] considerar el problema del aprendizaje de clases restringidas de funciones de valoración que se pueden representar utilizando fórmulas de lectura once y Toolbox DNF. Las fórmulas Read-once pueden representar ciertas sustitutibilidades, pero no complementariedades, mientras que lo contrario se mantiene para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten depender del tamaño de la valoración objetivo como lo hacemos (aunque las valoraciones de read-once siempre se pueden representar sucintamente de todos modos). Su trabajo sólo hace uso de consultas de valor, que son bastante limitados en el poder. Debido a que nos permitimos pedir consultas, somos capaces de derivar un esquema de excitación para las funciones de valoración general. Blum et al. [5] proporcionar resultados relacionados con las complejidades del aprendizaje de la consulta y la excitación de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje de consultas, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones se pueden aprender eficientemente, pero no se pueden obtener eficientemente, y viceversa. En contraste, nuestro trabajo muestra que dada una versión más general (todavía bastante estándar) de la consulta de demanda que el tipo que consideran, la complejidad de la excitación de preferencia no es mayor que la complejidad del aprendizaje. Demostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre valoraciones para implicar una solución al problema de excitación. Nisan y Segal [12] estudian la complejidad comunicativa de la excitación de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos de la computación una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo se permite a los algoritmos hacer preguntas sobre valoraciones de agentes y recibir respuestas honestas, sin ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda la cuestión de la complejidad de la comunicación, y somos capaces de derivar algoritmos que proporcionan garantías de comunicación significativas a pesar de los resultados negativos de Nisan y Segals. Su trabajo motiva la necesidad de confiar en el tamaño de los agentes funciones de valoración para indicar los peores resultados. 2. LOS MODELOS 2.1 Aprendizaje de la consulta El modelo de aprendizaje de la consulta que consideramos aquí se llama aprendizaje exacto de la membresía y consultas de equivalencia, introducido por Angluin [2]. En este modelo el objetivo de los algoritmos de aprendizaje es identificar exactamente una función diana desconocida f : X → Y a través de consultas a un oráculo. La función de destino se extrae de una función de clase C que es conocida por el algoritmo. Típicamente el dominio X es algún subconjunto de {0, 1}m, y el rango Y es {0, 1} o algún subconjunto de los números reales. A medida que el algoritmo avanza, construye una hipótesis manifiesta?f que es su estimación actual de la función de destino. Después de la terminación, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface?f(x) = f(x) para todos x?X. Es importante especificar la representación que se utilizará para codificar funciones de C. Por ejemplo, considere la siguiente función de {0, 1}m a ♥: f(x) = 2 si x consiste en m 1s, y f(x) = 0 de otra manera. Esta función puede representarse simplemente como una lista de valores de 2m. O puede codificarse como el polinomio 2x1 · · · xm, que es mucho más sucinto. Así pues, la elección de la codificación puede tener un impacto significativo en las necesidades de tiempo y espacio del algoritmo de aprendizaje. Let size(f) ser el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes distintos de cero en el polinomio, por ejemplo. Por lo general, sólo nos referiremos a las clases de representación; las clases de funciones correspondientes serán implícitas. Por ejemplo, la clase de representación de fórmulas DNF monotonas implica la clase de función de funciones booleanas monotonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: la membresía y las consultas de equivalencia. En una consulta de membresía, el aprendiz presenta algunas x x x y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta f. El oráculo responde SÍ si?f = f, o devuelve un contraejemplo x de tal manera que?f(x) = f(x). Una consulta de equivalencia es apropiada si el tamaño( ̃f) ≤ tamaño(f) en el momento de presentar la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones se adaptan a partir de Kearns y Vazirani [9]: Definición 1. La clase de representación C es polinomialquery exactamente aprendeble de las consultas de membresía y equivalencia si hay un polinomial fijo p(·, ·) y un algoritmo L con acceso a la membresía y consultas de equivalencia de un oráculo tal que para cualquier función de destino f • C, L salidas después de a lo sumo p(size(f), m) consultas de una función?f • C tal que?f Del mismo modo, la clase de representación C se puede aprender exactamente de las consultas de membresía y equivalencia si el algoritmo L produce una hipótesis correcta en el tiempo p(size(f), m), para algunos polinomios fijos p(·, ·). Aquí m es la dimensión del dominio. Dado que la función de destino debe ser reconstruida, también permitimos necesariamente la dependencia polinómica del tamaño (f). 2.2 Eliminación de preferencias En una subasta combinatoria, un conjunto de bienes M se asignará entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Tal asignación se llama eficiente en la literatura de economía, pero nos referiremos a ella como óptima y reservar el término eficiente para referirse a la eficiencia computacional. Dejamos n = N y m = M. Una asignación es una partición de los objetos en paquetes (S1,. . . , Sn), de tal manera que Si â € ¬ Sj = â € para todos los i, j â € N. Let â € € sea el conjunto de posibles asignaciones. Cada agente i+N tiene una función de valoración vi : 2M → • sobre el espacio de los paquetes posibles. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no tienen que coincidir. Asumimos que todas las valoraciones consideradas están normalizadas, es decir, v() = 0, y que no hay externalidades, es decir, vi(S1,..., Sn) = vi(Si), para todos los agentes i  N, para cualquier asignación (S1,..., Sn)  (es decir, un agente se preocupa sólo por el paquete asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales.1 Nosotros 1 A menudo las valoraciones generales se hacen para satisfacer los 181 adicionales también asumen que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que los agentes utilidades pueden ser divididos en componentes monetarios y no monetarios. Si a un agente i se le asigna el paquete S al precio p, deriva utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más sucintas para ciertas clases de valoración, y ha habido mucha investigación en lenguajes de licitación concisos para diversos tipos de valoraciones [11]. Un ejemplo clásico al que nos referiremos más adelante es el lenguaje de licitación XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, que consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estas pujas, se busca el paquete S del valor más alto listado en las pujas atómicas de tal manera que S  S. Es entonces el caso que v(S) = v(S). Al igual que en el contexto de la teoría del aprendizaje, por lo general sólo nos referiremos a idiomas de oferta en lugar de clases de valoración, ya que las clases de valoración correspondientes serán implícitas. Por ejemplo, el lenguaje de licitación XOR implica la clase de valoraciones que satisfacen la disposición libre, que es la condición de que A  B ♥ v(A) ≤ v(B). Dejamos el tamaño(v1,. . . , vn) = Èn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de licitación). Para hacer una analogía con la teoría del aprendizaje computacional, suponemos que todas las clases de representación consideradas son polinomiamente interpretables [11], lo que significa que el valor de un paquete puede ser calculado en tiempo polinomio dada la representación de funciones de valoración. Más formalmente, una clase de representación (lenguaje de licitación) C es polinomialmente interpretable si existe un algoritmo que da como entrada algunos v • C y una instancia x • X calcula el valor v(x) en el tiempo q(size(v), m), para algún polinomio fijo q(·, ·).2 En las rondas intermedias de una subasta (terativa), el subastador habrá obtenido información sobre las funciones de Por lo tanto, habrá construido un conjunto de valoraciones manifiestas, denotadas . . Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha adquirido información sobre ciertos paquetes. El objetivo en el \"problema de la excitación de preferencia\" es construir un conjunto de valoraciones manifiestas tales que: arg max (S1,...,Sn) iÃ3n ̃vi(Si)  arg max (S1,...,Sn) iÃ3n vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que es óptima con respecto a las valoraciones verdaderas. Tenga en cuenta que sólo se requiere una asignación óptima. condición de la libre eliminación (monotonicidad), pero no la necesitamos en este punto. 2 Esto excluye OR*, asumiendo P = NP, porque la interpretación de las ofertas de este lenguaje es NP-duro por reducción de set-embalaje ponderado, y no hay clase de representación bien estudiada en teoría de aprendizaje que es claramente análogo a OR*. 3 Esta visión de las subastas iterativas tiene por objeto paralelizar el entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente están implícitas por la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son consultas de valor y demanda. En una consulta de valor, el subastador presenta un paquete S  M y el agente responde con su valor (exacto) para el paquete v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p • • • (2m ) sobre los paquetes junto con un paquete S. El agente responde SI si es el caso de que S • arg max S M v(S ) − p(S ) ¡ o de otro modo presenta un paquete S tal que v(S ) − p(S ) > v( Tenga en cuenta también que comunicar precios no lineales no implica necesariamente citar un precio por cada paquete posible. Puede haber formas más sucintas de comunicar este vector, como se muestra en la sección 5. Hacemos las siguientes definiciones para paralelizar la configuración de aprendizaje de la consulta y para simplificar las declaraciones de resultados posteriores: Definición 2. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si hay un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes tales que para cualquier (v1,. . . , vn) V1 ×. . . × Vn, L salidas después de como máximo p(size(v1,. . . , vn), m) consulta una asignación (S1,. . . , Sn) arg max(S1,...,Sn) È vi(Si). Del mismo modo, la clase de representación C se puede obtener eficientemente de las consultas de valor y demanda si el algoritmo L produce una asignación óptima con comunicación p(size(v1, ). . . , vn), m), para algunos polinomios fijos p(·, ·). Hay algunas diferencias clave aquí con la definición de aprendizaje de la consulta. Hemos eliminado el término exactamente ya que las funciones de valoración no necesitan ser determinadas exactamente con el fin de calcular una asignación óptima. Además, un algoritmo de excitación eficiente es la comunicación polinomio, en lugar de tiempo polinomio. Esto refleja el hecho de que la comunicación en lugar del tiempo de espera es el cuello de botella en la excitación. Cálculo de una asignación óptima de bienes incluso cuando se dan las valoraciones verdaderas es NP-duro para una amplia gama de clases de valoración. Por lo tanto, no es razonable exigir tiempo polinomio en la definición de un algoritmo de excitación de preferencias eficiente. Nos complace centrarnos en la complejidad comunicativa de la excitación porque se cree que este problema es más significativo en la práctica que el de la determinación del ganador [11].5 4 Esto difiere ligeramente de la definición proporcionada por Blum et al. [5] Sus consultas sobre la demanda se limitan a precios lineales sobre las mercancías, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir. un precio distinto por cada paquete posible. Es por eso que el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. 5 Aunque el problema de determinación del ganador es NP-hard para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta aproximaciones usando solucionadores IP fuera de la plataforma [1]. 182 Dado que no es necesario obtener exactamente las valoraciones, es inicialmente menos claro si la dependencia polinómica del tamaño (v1, ). . . , vn) está justificado en este contexto. Intuitivamente, este parámetro está justificado porque debemos aprender valoraciones exactamente cuando se realiza la excitación, en el peor de los casos. Nos ocupamos de esto en la siguiente sección. 3. PARALLESBETWEEN EQUIVALENCIA Y QUERIDAS DE DEMANDA Hemos descrito los ajustes de aprendizaje y excitación de preferencias de la consulta de una manera que destaca sus similitudes. Las consultas de valor y membresía son claras analógicas. Un poco menos obvio es el hecho de que las consultas de equivalencia y demanda también son analógicas. Para ver esto, necesitamos el concepto de precios Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios sobre sus bienes subyacentes. Son no anónimos en el sentido de que dos agentes pueden tener que hacer frente a precios diferentes para el mismo paquete de mercancías. Así los precios de Lindahl son de la forma pi(S), para todos S  M, para todos los precios de i  N. Lindahl se presentan a los agentes en consultas de la demanda. Cuando los agentes han normalizado las funciones de utilidad cuasi-lineal, Bikhchandani y Ostroy [4] muestran que siempre existen precios Lindahl tales que (S1,. . . , Sn) es una asignación óptima si y sólo si Si • arg max Si vi(Si) − pi(Si) • i N (1) (S1,. . . , Sn)  arg max (S1,...,Sn) iN pi(Si) (2) Condición (1) establece que cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos de los subastadores a los precios indicados. El escenario en el que se mantienen estas condiciones se llama equilibrio Lindahl, o a menudo un equilibrio competitivo. Decimos que los precios de Lindahl apoyan la asignación óptima. Por lo tanto, basta con anunciar los precios de apoyo de Lindahl para verificar una asignación óptima. Una vez que hemos encontrado una asignación con el apoyo de precios Lindahl, el problema de excitación se resuelve. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones estén garantizadas como integrales [4]. Las variables duales de este programa lineal están soportando los precios de Lindahl para la asignación resultante. La función objetiva del programa dual es: min pi(S) Por lo general, hay una gama de posibles precios Lindahl que apoyan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios válidos Lindahl, y nos referimos a ellos como precios máximos Lindahl. De todos los vectores posibles de precios Lindahl, precios máximos Lindahl maximizar la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È iÃ3N πi del objetivo (la suma de los agentes de utilidades) son precios mínimos Lindahl. Cualquier Lindahl precios hará para nuestros resultados, pero algunos pueden tener mejores propiedades de excitación que otros. Tenga en cuenta que una consulta de demanda con precios máximos de Lindahl es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para el trabajo futuro la cuestión de los precios de Lindahl para elegir minimizar la obtención de preferencias. Teniendo en cuenta ahora por qué las consultas de demanda y equivalencia son analógicas directas, primero tenga en cuenta que dado el πi en algún equilibrio Lindahl, establecer pi(S) = max{0, Estos precios dejan a cada agente indiferente en todos los paquetes con precio positivo, y satisfacen la condición (1). Así, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl típicamente serán una constante aditivo lejos de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos de consultas de equivalencia a través de consultas de demanda. Lemma 1. Supongamos que un agente responde con un paquete preferido S cuando se propone un paquete S y soporta los precios de Lindahl p(S) (soportando con respecto a la valoración manifiesta de los agentes). A continuación, o bien?v(S) = v(S) o?v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: Φv(S) − p(S) ≥ Desigualdad (6) se mantiene porque el agente de hecho prefiere S a S dados los precios, de acuerdo con su respuesta a la consulta de demanda. Si fuera el caso de que?v(S) = v(S) y Así, al menos uno de S y S es un contraejemplo de la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño(v1,. . . , vn) en problemas de excitación. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que apoyar los precios de Lindahl debe necesariamente revelarse en el curso de cualquier protocolo de obtención de preferencias que termina con una asignación óptima. Además, Nisan y Segal (Lemma 1, [12]) afirman que en el peor de los casos los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones dobles (como será el caso de las clases más interesantes). Puesto que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y puesto que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitiendo la dependencia del tamaño(v1,. . . , vn) en problemas de excitación es totalmente natural. 183 4. DE APRENDIZAJE A LA LICITACIÓN DE PREFERENCIA La clave para convertir un algoritmo de aprendizaje a un algoritmo de excitación es simular consultas de equivalencia con consultas de demanda y valor hasta que se encuentre una asignación óptima. Debido a nuestra construcción de precios Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en que un agente responde SÍ a una consulta de equivalencia cuando la función de destino se ha aprendido exactamente. De lo contrario, podemos obtener un contraejemplo a una consulta de equivalencia dada una respuesta de agentes a una consulta de demanda. Teorema 1. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si cada uno puede ser polinomio-consulta exactamente aprendido de consultas de membresía y equivalencia. Prueba. Considere el algoritmo de excitación en la Figura 1. Cada consulta de membresía en el paso 1 es simulada con una consulta de valor ya que estas son de hecho idénticas. Considere el paso 4. Si todos los agentes responden SÍ, la condición (1) se mantiene. Condición (2) se mantiene porque la asignación calculada es la maximización de ingresos para el subastador, independientemente de los agentes verdaderas valoraciones. Así pues, se ha encontrado una asignación óptima. De lo contrario, por lo menos uno de Si o Si es un contraejemplo a Vi, por Lemma 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones del agente se conocerán exactamente, en cuyo caso la asignación óptima y los precios Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinomio de consultas, desde A1,. . . , A son todos los algoritmos de aprendizaje polinomio-quería. Tenga en cuenta que el procedimiento de conversión resulta en un algoritmo de excitación de preferencias, no un algoritmo de aprendizaje. Es decir, el algoritmo resultante no simplemente aprender las valoraciones exactamente, a continuación, calcular una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor, y periódicamente comprueba si se ha reunido suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio Lindahl para las valoraciones v1,. . . , vn utilizando una asignación y precios derivados de valoraciones manifiestas . . y encontrar una asignación óptima no implica que las valoraciones de los agentes se hayan aprendido exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta interrupción temprana. No obtendremos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE COMUNICACIÓN En esta sección, pasamos a la cuestión de la complejidad comunicativa de la excitación. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (tales como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos de determinar los precios de Lindahl es exponencial en el número de mercancías, m. La carga de comunicación se mide en términos del número de bits transmitidos entre agentes y subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. La conversión de algoritmos de aprendizaje eficientes a un algoritmo de excitación produce un algoritmo cuyas consultas tienen tamaños polinomios en los parámetros m y tamaño (v1, ). . . , vn). Teorema 2. Las clases de representación V1,. . . , Vn se puede obtener de forma eficiente de las consultas de valor y demanda si cada uno puede ser aprendido exactamente de las consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, basta con comunicar la función de valoración manifiesta de los agentes y el valor Nótese que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinomio, porque el tiempo de ejecución de los algoritmos también sería superpolinomio, contradiciendo la eficiencia. Por lo tanto, la comunicación de la valoración manifiesta requiere tamaño a lo sumo p(size(vi), m), para algunos polinomios p que limita superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representando el excedente πi al agente no se puede requerir espacio mayor que q(size( También debemos comunicarnos con su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es como máximo p(size(vi), m) + q(p(size(vi), m), m)+O(m). Claramente, una respuesta de agentes a una consulta de valor o demanda tiene un tamaño máximo de q(size(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, son siempre de tamaño polinomio. Un algoritmo de aprendizaje eficiente realiza un número polinomio de consultas, por lo que la comunicación total del algoritmo de excitación resultante es polinomio en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites pueden ser traducidos a límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de excitación resultante. Con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2 se determinó el tamaño de la hipótesis manifiesta. Es probable que podamos hacerlo mucho mejor que esto en la práctica. Recuerde que una consulta de equivalencia es apropiada si size( ̃f) ≤ size(f) en el momento de realizar la consulta. Si las consultas de equivalencia de algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites estrechos en los requisitos de comunicación del algoritmo de excitación resultante. El teorema 2 muestra que los algoritmos de excitación que dependen del tamaño (v1,. . . El parámetro, vn) evita los resultados negativos de Nisan y Segals [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto al tamaño de las instancias de las funciones de valoración que se enfrentan a cualquier ejecución del algoritmo. Estos algoritmos van bien si la clase de representación elegida proporciona representaciones sucintas para la más simple y común de las valoraciones, y por lo tanto el enfoque se mueve de nuevo a uno de lenguajes de licitación compactos pero expresivos. A continuación se examinan estas cuestiones. 6. APLICACIONES En esta sección, demostramos la aplicación de nuestros métodos a clases particulares de representación para valoraciones combinatorias. Hemos demostrado que el \"problema de excitación de preferencia\" para las clases de valoración V1,. . . , Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1,. . . , Una para las valoraciones de las clases V1,. . . , Vn respectivamente. Encaje hasta que haya una señal para detenerse: 1. Corre A1,. . . , Un en paralelo sobre sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se ha detenido con los agentes valoración exacta. 2. Calcular una asignación óptima (S1,. . . , Sn ) y los correspondientes precios de Lindahl con respecto a las valoraciones manifiestas . . , їvn determinado hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de consulta de demanda. 4. Si todos ellos responden SÍ, salida la asignación y parada. De lo contrario hay algún agente i que ha respondido con algún paquete preferido Si. Realizar consultas de valor en Si y Si para encontrar un contraejemplo a ‡vi, y proporcionarlo a Ai. Figura 1: Convertir algoritmos de aprendizaje a un algoritmo de excitación. al problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de función, y porque a menudo puede ser más simple resolver cada subproblema de aprendizaje por separado que atacar el \"problema de excitación de preferencia\" directamente. Podemos desarrollar un algoritmo de excitación que se adapta a cada valoración de agentes, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Demostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas de DNF monotono y funciones de umbral lineal se pueden convertir en algoritmos de excitación de preferencia para valoraciones generales, valoraciones con eliminación libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en las representaciones que son polinomialmente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la traqueabilidad computacional [18]. Al interpretar los métodos enfatizamos la expresividad y sucinta de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de licitación, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debe representar sucintamente las funciones más simples y comunes de la clase. 6.1 Las Representaciones Polinómicas Schapire y Sellie [17] dan un algoritmo de aprendizaje para polinomios multivariables escasos que pueden utilizarse como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas apropiadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados de t-sparse sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-sparse tiene como máximo t términos, donde un término es un producto de variables, por ejemplo. x1x3x4. Un polinomio sobre los números reales tiene coeficientes extraídos de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M →  se puede escribir exclusivamente como un polinomio [17]. Para tener una idea de la sucintaidad de los polinomios como lenguaje de licitación, considere las valoraciones aditivas y mono-ítem presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es el número de mercancías que contiene el paquete. En la valoración de un solo elemento, todos los paquetes tienen valor 1, excepto el valor 0 (i.e. el agente está satisfecho tan pronto como ha adquirido un único artículo). No es difícil demostrar que la valoración de un solo elemento requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Por lo tanto, los polinomios son adecuados para valoraciones que en su mayoría son aditivas, con algunas sustituibilidades y complementariedades que pueden introducirse ajustando los coeficientes. El algoritmo de aprendizaje para polinomios hace como máximo consultas de equivalencia mti +2 y como máximo (mti +1) (t2 i +3ti)/2 consultas de membresía a un agente i, donde ti es la esparcidad del polinomio que representa vi [17]. Por lo tanto, se obtiene un algoritmo que provoca valoraciones generales con un número polinomio de consultas y comunicación polinomio.6 6.2 XOR Representaciones El lenguaje de licitación XOR es estándar en la literatura de subastas combinatoria. Recordemos que una oferta XOR se caracteriza por un conjunto de paquetes B  2M y una función de valor w : B →  definida en esos paquetes, que induce la función de valoración: v(B) = max {B  B  B  B} w(B) (7) Las ofertas XOR pueden representar valoraciones que satisfacen la libre eliminación (y sólo tales valoraciones), que de nuevo es la propiedad que A  B El lenguaje de licitación XOR es ligeramente menos expresivo que los polinomios, porque los polinomios pueden representar valoraciones que no satisfacen la libre eliminación. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas de XOR pueden representar la valoración de un solo elemento con ofertas atómicas m, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario se aplica a los polinomios, estas dos lenguas son incomparables en sucintas y algo complementarias para su uso práctico. Blum et al. [5] note que las fórmulas DNF monotonas son los análogos de las pujas XOR en la literatura de teoría del aprendizaje. Una fórmula de DNF monotona es una disyunción de conjunciones en las que las variables aparecen sin negación, por ejemplo x1x2 x3 x2x4x5. Tenga en cuenta que tales fórmulas pueden ser representadas como ofertas XOR donde cada oferta atómica tiene valor 1; por lo tanto XOR ofrece generalizar fórmulas DNF monotono de Boolean a funciones de valor real. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para el DNF monotono ([3] Teorema 6 Tenga en cuenta que el Teorema 1 se aplica incluso si las valoraciones no satisfacen la eliminación libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lemma 2. Una oferta XOR que contiene ofertas t atómicas se puede aprender exactamente con consultas de equivalencia t + 1 y a lo sumo consultas de membresía tm. Prueba. El algoritmo identificará cada puja atómica en la puja XOR objetivo a su vez. Initialice la valoración manifiesta v a la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presente ‡v como consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un paquete S para el que v(S) = Crear un paquete T de la siguiente manera. Primero inicialice T = S. Para cada elemento i en T, compruebe a través de una consulta de membresía si v(T) = v(T − {i}). Si así se establece T = T − {i}. De lo contrario, deje T como está y pase al siguiente punto. Afirmamos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada ítem i en T, tenemos v(T) = v(T − {i}). Para ver esto, tenga en cuenta que en algún momento al generar T, tuvimos un ̄T tal que T  ̄T  S y v( ̄T) > v( ̄T − {i}), de modo que me mantuvo en ̄T. Tenga en cuenta que v(S) = v( ̄T) = v(T) porque el valor del paquete S se mantiene durante todo el proceso de eliminación de elementos. Ahora asume v(T) = v(T − {i}). Entonces v( ̄T) = v(T) = v(T − {i}) > v( ̄T − {i}) que contradice la libre eliminación, ya que T {i}  ̄T − {i}. Por lo tanto v(T) > v(T − {i}) para todos los ítems i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si este no fuera el caso, T tomaría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = máx itat {max T T Ahora mostramos que v(T) = ̃v(T), que implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Asumir que toda oferta atómica (R, Esta suposición se mantiene vagamente cuando se inicializa la valoración manifiesta. Usando la notación de (7), dejar ( Tenemos B  B, y Bw(B) = w(B) para B Por lo tanto,?v(S) = max {B} {B} {B} {B} {B} {B} = max {B} {B} {B} ≤ {B} {B} {B} {B} {S} w(B} = v(S) (8) Ahora asume v(T) {v(T La segunda igualdad se deriva del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad sostiene porque S es un contraejemplo de la valoración manifiesta. De la ecuación (9) y la eliminación libre, nosotros 7 El algoritmo citado también se utilizó como base para Zinkevich et al.s [19] algoritmo de excitación para Toolbox DNF. Recuerde que Toolbox DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia se puede simular con una consulta de valor en el paquete que contiene todas las mercancías. que tengan ‡v(T) < Entonces de nuevo de la ecuación (9) se deduce que v(S) < Esto contradice (8), por lo que de hecho tenemos v(T) = Por lo tanto (T, v(T)) no está actualmente en nuestra hipótesis como una oferta atómica, o tendríamos correctamente?v(T) = v(T) por la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas adicionales de equivalencia hasta que todas las ofertas atómicas hayan sido identificadas. Después de cada consulta de equivalencia, una oferta atómica se identifica con como máximo m consultas de membresía. Cada contraejemplo conduce al descubrimiento de una nueva oferta atómica. Por lo tanto, hacemos a lo sumo consultas de membresía tm y exactamente consultas de equivalencia t + 1. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR se puede obtener eficientemente de las consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al.s ([5], Teorema 2) afirmando que el DNF monotono (y por lo tanto las ofertas XOR) no se pueden obtener de manera eficiente cuando las consultas de demanda se limitan a precios lineales y anónimos sobre las mercancías. 6.3 Las representaciones lineales de umbral polinomios, las ofertas XOR y todas las lenguas basadas en el lenguaje de licitación OR (como XOR-de-OR, OR-de-XOR y OR*) no representan sucintamente la valoración mayoritaria [11]. En esta valoración, los paquetes tienen valor 1 si contienen al menos m/2 ítems, y valor 0 de lo contrario. Más generalmente, considere la familia de r-of-S de valoraciones donde los paquetes tienen valor 1 si contienen al menos r artículos de un conjunto especificado de ítems S  M, y valor 0 de otra manera. La valoración mayoritaria es un caso especial de la valoración de r-of-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar las sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede añadir valor. Dejando k = S, tales valoraciones están sucintamente representadas por funciones de umbral r-of-k. Estas funciones adoptan la forma de desigualdades lineales: xi1 +. . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se mantiene, y 0 de lo contrario. Aquí i1,. . . , ik son los elementos en S. Littlestones WINNOW 2 algoritmo puede aprender tales funciones utilizando consultas de equivalencia sólo, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de excitación que resulta de WINNOW 2 sólo utiliza consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos están implícitos cuando sólo hay dos valores posibles). Tenga en cuenta que las funciones de umbral r-of-k siempre se pueden representar sucintamente en el espacio O(m). Así se obtiene un algoritmo que puede generar tales funciones con un número polinomio de consultas y comunicación polinomio, en los parámetros n y m solos. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exactos con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de excitación de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas en el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la riqueza de algoritmos de aprendizaje disponibles al problema de la excitación de preferencias. Un enfoque de aprendizaje para la excitación también motiva un enfoque diferente para diseñar algoritmos de excitación que se descomponen cuidadosamente entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivos, muchos sustitutos, etc.), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de excitación. El algoritmo de excitación resultante hace un número polinomio de consultas, y hace comunicación polinomio si los algoritmos de aprendizaje originales son eficientes. No exigimos que las valoraciones de agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia sólo pueden ser, y sólo necesitan ser, simuladas hasta el punto en que se ha calculado una asignación óptima. Este es el \"problema de la excitación de preferencia\". Teorema 1 implica que la excitación con consultas de valor y demanda no es más difícil que aprender con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las que la excitación es más fácil que el aprendizaje. Blum et al. [5] proporcionar tal ejemplo al considerar solamente consultas de membresía/valor (Teorema 4). En el trabajo futuro planeamos abordar la cuestión de los incentivos al convertir algoritmos de aprendizaje a algoritmos de excitación. En el entorno de aprendizaje, por lo general suponemos que los oráculos proporcionarán respuestas honestas a las preguntas; en el entorno de excitación, los agentes son generalmente egoístas y proporcionarán respuestas posiblemente deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para el aprendizaje de polinomios y ofertas XOR como algoritmos de excitación, y probar su rendimiento contra otros protocolos de subasta combinatoria establecidos [6, 15]. Una pregunta interesante aquí es: ¿qué precios Lindahl en el rango máximo a mínimo son los mejores para citar con el fin de minimizar la revelación de información? Suponemos que la revelación de información se reduce al pasar de precios máximos a precios mínimos de Lindahl, es decir, a medida que desplazamos las consultas de demanda más lejos de las consultas de equivalencia. Por último, sería útil determinar si el lenguaje de licitación de OR* [11] puede aprenderse (y, por lo tanto, obtenerse) de manera eficiente, dada la expresividad y sucinta de estas lenguas para una amplia variedad de clases de valoración. Agradecimientos Queremos agradecer a Debasis Mishra por sus útiles discusiones. Este trabajo está apoyado en parte por la subvención de NSF IIS0238147. 8. REFERENCIAS [1] A. Andersson, M. Tenhunen, y F. Ygge. Programación integral para la determinación del ganador de la subasta combinatoria. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprender conjuntos regulares de consultas y contraejemplos. Información e computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje conceptual. Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El modelo de asignación de paquetes. Diario de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Provocación de preferencias y aprendizaje de consultas. En Proc. 16a Conferencia Anual sobre Teoría del Aprendizaje Computacional (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. la 18a Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, e Y. Shoham. Domar la complejidad computacional de las subastas combinatoria: Enfoques óptimos y aproximados. En Proc. , 16a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), págs. 548 a 553, 1999. [8] B. Hudson y T. Sandholm. Uso de consultas de valor en subastas combinatoria. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría del aprendizaje computacional. MIT Press, 1994. [10] N. Littlestone. Aprender rápidamente cuando los atributos irrelevantes abundan: Un nuevo algoritmo de umbral lineal. Machine Learning, 2:285-318, 1988. [11] N. Nisan. Licitación y asignación en subastas combinatoria. En Proc. la Conferencia de la ACM sobre Comercio Electrónico, págs. 1 a 12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y el apoyo a los precios Lindahl. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de mínima revelación. En Padget et al., editor, Agent-Mediated Electronic Commerce IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. Diseño de subastas con costosas preferencias. En Temas Especiales de Anales de Matemáticas y AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17a Conferencia Nacional sobre Inteligencia Artificial (AAAI-00), págs. 74 a 81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. la 17a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariables escasos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de ACM sobre Teoría del Aprendizaje Computacional, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendido. Comun. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum, y T. Sandholm. Sobre la excitación de la preferencia polinomio-tiempo con las consultas de valor. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "error": [
                "problema de excitación Demostramos que los algoritmos de aprendizaje pueden ser usados como base para algoritmos de excitación de preferencias. Los algoritmos de excitación resultantes realizan un número polinomio de consultas. También damos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. En particular, se obtiene un algoritmo que provoca pujas XOR con comunicación polinómica. Categorías y Descriptores sujetos F.2.0 [Análisis de algoritmos y complejidad de problemas]: General; J.4 [Ciencias Sociales y Conductuales]: Economía; I.2.6 [Inteligencia Artificial]: Términos generales de aprendizaje Algoritmos, Economía, Teoría 1. INTRODUCCIÓN En una subasta combinatoria, los agentes pueden pujar por paquetes de bienes en lugar de por cada uno de ellos. Puesto que hay un número exponencial de paquetes (en el número de bienes), comunicar los valores sobre estos paquetes puede ser problemático. Comunicar las valoraciones de una sola vez puede ser prohibitivamente costoso si el número de bienes es sólo moderadamente grande. Además, incluso podría ser difícil para los agentes determinar sus valoraciones para paquetes únicos [14]. A esos agentes les interesa disponer de protocolos de subasta que les obliguen a pujar en el menor número posible de paquetes. Incluso si los agentes pueden calcular eficientemente sus valoraciones, podrían ser reacios a revelarlas enteramente en el curso de una subasta, porque tal información puede ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información necesaria para determinar una asignación óptima de los bienes. Ha habido un trabajo reciente explorando los vínculos entre el ",
                " en las subastas combinatoria y el problema de aprender una función desconocida de la teoría del aprendizaje computacional [5, 19]. En teoría de aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, tales como ¿Cuál es el valor de las funciones en estas entradas? En la obtención de preferencia, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Demostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia se puede convertir en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de excitación resultante garantiza la excitación en un número polinomio de consultas de valor y demanda. Aquí queremos decir polinomio en el número de bienes, agentes, y los tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Argumentamos que las garantías de complejidad para los esquemas de excitación deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar la comunicación polinómica en el peor de los casos, que normalmente no se puede lograr en el número de productos y agentes por sí solos. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. Por supuesto, una subasta combinatoria de un solo disparo donde los agentes proporcionan todas sus funciones de valoración a la vez también tendría comunicación polinómica en el tamaño de las valoraciones de los agentes, y sólo requieren una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay ninguna carga para los agentes de formular sus valoraciones en un esquema de codificación de los subastadores que elijan. Esperamos que esta sea una consideración importante en la práctica. Además, con nuestro esquema la revelación entera sólo ocurre en el peor de los casos. 180 Por ahora, dejamos a un lado la cuestión de los incentivos al derivar algoritmos de excitación. Nos centramos en el tiempo y la complejidad de la comunicación de la obtención de preferencias, independientemente de las limitaciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich y otros [19] considerar el problema del aprendizaje de clases restringidas de funciones de valoración que se pueden representar utilizando fórmulas de lectura once y Toolbox DNF. Las fórmulas Read-once pueden representar ciertas sustitutibilidades, pero no complementariedades, mientras que lo contrario se mantiene para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten depender del tamaño de la valoración objetivo como lo hacemos (aunque las valoraciones de read-once siempre se pueden representar sucintamente de todos modos). Su trabajo sólo hace uso de consultas de valor, que son bastante limitados en el poder. Debido a que nos permitimos pedir consultas, somos capaces de derivar un esquema de excitación para las funciones de valoración general. Blum et al. [5] proporcionar resultados relacionados con las complejidades del aprendizaje de la consulta y la excitación de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje de consultas, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones se pueden aprender eficientemente, pero no se pueden obtener eficientemente, y viceversa. En contraste, nuestro trabajo muestra que dada una versión más general (todavía bastante estándar) de la consulta de demanda que el tipo que consideran, la complejidad de la excitación de preferencia no es mayor que la complejidad del aprendizaje. Demostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre valoraciones para implicar una solución al problema de excitación. Nisan y Segal [12] estudian la complejidad comunicativa de la excitación de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos de la computación una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo se permite a los algoritmos hacer preguntas sobre valoraciones de agentes y recibir respuestas honestas, sin ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda la cuestión de la complejidad de la comunicación, y somos capaces de derivar algoritmos que proporcionan garantías de comunicación significativas a pesar de los resultados negativos de Nisan y Segals. Su trabajo motiva la necesidad de confiar en el tamaño de los agentes funciones de valoración para indicar los peores resultados. 2. LOS MODELOS 2.1 Aprendizaje de la consulta El modelo de aprendizaje de la consulta que consideramos aquí se llama aprendizaje exacto de la membresía y consultas de equivalencia, introducido por Angluin [2]. En este modelo el objetivo de los algoritmos de aprendizaje es identificar exactamente una función diana desconocida f : X → Y a través de consultas a un oráculo. La función de destino se extrae de una función de clase C que es conocida por el algoritmo. Típicamente el dominio X es algún subconjunto de {0, 1}m, y el rango Y es {0, 1} o algún subconjunto de los números reales. A medida que el algoritmo avanza, construye una hipótesis manifiesta?f que es su estimación actual de la función de destino. Después de la terminación, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface?f(x) = f(x) para todos x?X. Es importante especificar la representación que se utilizará para codificar funciones de C. Por ejemplo, considere la siguiente función de {0, 1}m a ♥: f(x) = 2 si x consiste en m 1s, y f(x) = 0 de otra manera. Esta función puede representarse simplemente como una lista de valores de 2m. O puede codificarse como el polinomio 2x1 · · · xm, que es mucho más sucinto. Así pues, la elección de la codificación puede tener un impacto significativo en las necesidades de tiempo y espacio del algoritmo de aprendizaje. Let size(f) ser el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes distintos de cero en el polinomio, por ejemplo. Por lo general, sólo nos referiremos a las clases de representación; las clases de funciones correspondientes serán implícitas. Por ejemplo, la clase de representación de fórmulas DNF monotonas implica la clase de función de funciones booleanas monotonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: la membresía y las consultas de equivalencia. En una consulta de membresía, el aprendiz presenta algunas x x x y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta f. El oráculo responde SÍ si?f = f, o devuelve un contraejemplo x de tal manera que?f(x) = f(x). Una consulta de equivalencia es apropiada si el tamaño( ̃f) ≤ tamaño(f) en el momento de presentar la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones se adaptan a partir de Kearns y Vazirani [9]: Definición 1. La clase de representación C es polinomialquery exactamente aprendeble de las consultas de membresía y equivalencia si hay un polinomial fijo p(·, ·) y un algoritmo L con acceso a la membresía y consultas de equivalencia de un oráculo tal que para cualquier función de destino f • C, L salidas después de a lo sumo p(size(f), m) consultas de una función?f • C tal que?f Del mismo modo, la clase de representación C se puede aprender exactamente de las consultas de membresía y equivalencia si el algoritmo L produce una hipótesis correcta en el tiempo p(size(f), m), para algunos polinomios fijos p(·, ·). Aquí m es la dimensión del dominio. Dado que la función de destino debe ser reconstruida, también permitimos necesariamente la dependencia polinómica del tamaño (f). 2.2 Eliminación de preferencias En una subasta combinatoria, un conjunto de bienes M se asignará entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Tal asignación se llama eficiente en la literatura de economía, pero nos referiremos a ella como óptima y reservar el término eficiente para referirse a la eficiencia computacional. Dejamos n = N y m = M. Una asignación es una partición de los objetos en paquetes (S1,. . . , Sn), de tal manera que Si â € ¬ Sj = â € para todos los i, j â € N. Let â € € sea el conjunto de posibles asignaciones. Cada agente i+N tiene una función de valoración vi : 2M → • sobre el espacio de los paquetes posibles. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no tienen que coincidir. Asumimos que todas las valoraciones consideradas están normalizadas, es decir, v() = 0, y que no hay externalidades, es decir, vi(S1,..., Sn) = vi(Si), para todos los agentes i  N, para cualquier asignación (S1,..., Sn)  (es decir, un agente se preocupa sólo por el paquete asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales.1 Nosotros 1 A menudo las valoraciones generales se hacen para satisfacer los 181 adicionales también asumen que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que los agentes utilidades pueden ser divididos en componentes monetarios y no monetarios. Si a un agente i se le asigna el paquete S al precio p, deriva utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más sucintas para ciertas clases de valoración, y ha habido mucha investigación en lenguajes de licitación concisos para diversos tipos de valoraciones [11]. Un ejemplo clásico al que nos referiremos más adelante es el lenguaje de licitación XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, que consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estas pujas, se busca el paquete S del valor más alto listado en las pujas atómicas de tal manera que S  S. Es entonces el caso que v(S) = v(S). Al igual que en el contexto de la teoría del aprendizaje, por lo general sólo nos referiremos a idiomas de oferta en lugar de clases de valoración, ya que las clases de valoración correspondientes serán implícitas. Por ejemplo, el lenguaje de licitación XOR implica la clase de valoraciones que satisfacen la disposición libre, que es la condición de que A  B ♥ v(A) ≤ v(B). Dejamos el tamaño(v1,. . . , vn) = Èn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de licitación). Para hacer una analogía con la teoría del aprendizaje computacional, suponemos que todas las clases de representación consideradas son polinomiamente interpretables [11], lo que significa que el valor de un paquete puede ser calculado en tiempo polinomio dada la representación de funciones de valoración. Más formalmente, una clase de representación (lenguaje de licitación) C es polinomialmente interpretable si existe un algoritmo que da como entrada algunos v • C y una instancia x • X calcula el valor v(x) en el tiempo q(size(v), m), para algún polinomio fijo q(·, ·).2 En las rondas intermedias de una subasta (terativa), el subastador habrá obtenido información sobre las funciones de Por lo tanto, habrá construido un conjunto de valoraciones manifiestas, denotadas . . Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha adquirido información sobre ciertos paquetes. El objetivo en el ",
                " es construir un conjunto de valoraciones manifiestas tales que: arg max (S1,...,Sn) iÃ3n ̃vi(Si)  arg max (S1,...,Sn) iÃ3n vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que es óptima con respecto a las valoraciones verdaderas. Tenga en cuenta que sólo se requiere una asignación óptima. condición de la libre eliminación (monotonicidad), pero no la necesitamos en este punto. 2 Esto excluye OR*, asumiendo P = NP, porque la interpretación de las ofertas de este lenguaje es NP-duro por reducción de set-embalaje ponderado, y no hay clase de representación bien estudiada en teoría de aprendizaje que es claramente análogo a OR*. 3 Esta visión de las subastas iterativas tiene por objeto paralelizar el entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente están implícitas por la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son consultas de valor y demanda. En una consulta de valor, el subastador presenta un paquete S  M y el agente responde con su valor (exacto) para el paquete v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p • • • (2m ) sobre los paquetes junto con un paquete S. El agente responde SI si es el caso de que S • arg max S M v(S ) − p(S ) ¡ o de otro modo presenta un paquete S tal que v(S ) − p(S ) > v( Tenga en cuenta también que comunicar precios no lineales no implica necesariamente citar un precio por cada paquete posible. Puede haber formas más sucintas de comunicar este vector, como se muestra en la sección 5. Hacemos las siguientes definiciones para paralelizar la configuración de aprendizaje de la consulta y para simplificar las declaraciones de resultados posteriores: Definición 2. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si hay un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes tales que para cualquier (v1,. . . , vn) V1 ×. . . × Vn, L salidas después de como máximo p(size(v1,. . . , vn), m) consulta una asignación (S1,. . . , Sn) arg max(S1,...,Sn) È vi(Si). Del mismo modo, la clase de representación C se puede obtener eficientemente de las consultas de valor y demanda si el algoritmo L produce una asignación óptima con comunicación p(size(v1, ). . . , vn), m), para algunos polinomios fijos p(·, ·). Hay algunas diferencias clave aquí con la definición de aprendizaje de la consulta. Hemos eliminado el término exactamente ya que las funciones de valoración no necesitan ser determinadas exactamente con el fin de calcular una asignación óptima. Además, un algoritmo de excitación eficiente es la comunicación polinomio, en lugar de tiempo polinomio. Esto refleja el hecho de que la comunicación en lugar del tiempo de espera es el cuello de botella en la excitación. Cálculo de una asignación óptima de bienes incluso cuando se dan las valoraciones verdaderas es NP-duro para una amplia gama de clases de valoración. Por lo tanto, no es razonable exigir tiempo polinomio en la definición de un algoritmo de excitación de preferencias eficiente. Nos complace centrarnos en la complejidad comunicativa de la excitación porque se cree que este problema es más significativo en la práctica que el de la determinación del ganador [11].5 4 Esto difiere ligeramente de la definición proporcionada por Blum et al. [5] Sus consultas sobre la demanda se limitan a precios lineales sobre las mercancías, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir. un precio distinto por cada paquete posible. Es por eso que el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. 5 Aunque el problema de determinación del ganador es NP-hard para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta aproximaciones usando solucionadores IP fuera de la plataforma [1]. 182 Dado que no es necesario obtener exactamente las valoraciones, es inicialmente menos claro si la dependencia polinómica del tamaño (v1, ). . . , vn) está justificado en este contexto. Intuitivamente, este parámetro está justificado porque debemos aprender valoraciones exactamente cuando se realiza la excitación, en el peor de los casos. Nos ocupamos de esto en la siguiente sección. 3. PARALLESBETWEEN EQUIVALENCIA Y QUERIDAS DE DEMANDA Hemos descrito los ajustes de aprendizaje y excitación de preferencias de la consulta de una manera que destaca sus similitudes. Las consultas de valor y membresía son claras analógicas. Un poco menos obvio es el hecho de que las consultas de equivalencia y demanda también son analógicas. Para ver esto, necesitamos el concepto de precios Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios sobre sus bienes subyacentes. Son no anónimos en el sentido de que dos agentes pueden tener que hacer frente a precios diferentes para el mismo paquete de mercancías. Así los precios de Lindahl son de la forma pi(S), para todos S  M, para todos los precios de i  N. Lindahl se presentan a los agentes en consultas de la demanda. Cuando los agentes han normalizado las funciones de utilidad cuasi-lineal, Bikhchandani y Ostroy [4] muestran que siempre existen precios Lindahl tales que (S1,. . . , Sn) es una asignación óptima si y sólo si Si • arg max Si vi(Si) − pi(Si) • i N (1) (S1,. . . , Sn)  arg max (S1,...,Sn) iN pi(Si) (2) Condición (1) establece que cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos de los subastadores a los precios indicados. El escenario en el que se mantienen estas condiciones se llama equilibrio Lindahl, o a menudo un equilibrio competitivo. Decimos que los precios de Lindahl apoyan la asignación óptima. Por lo tanto, basta con anunciar los precios de apoyo de Lindahl para verificar una asignación óptima. Una vez que hemos encontrado una asignación con el apoyo de precios Lindahl, el problema de excitación se resuelve. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones estén garantizadas como integrales [4]. Las variables duales de este programa lineal están soportando los precios de Lindahl para la asignación resultante. La función objetiva del programa dual es: min pi(S) Por lo general, hay una gama de posibles precios Lindahl que apoyan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios válidos Lindahl, y nos referimos a ellos como precios máximos Lindahl. De todos los vectores posibles de precios Lindahl, precios máximos Lindahl maximizar la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È iÃ3N πi del objetivo (la suma de los agentes de utilidades) son precios mínimos Lindahl. Cualquier Lindahl precios hará para nuestros resultados, pero algunos pueden tener mejores propiedades de excitación que otros. Tenga en cuenta que una consulta de demanda con precios máximos de Lindahl es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para el trabajo futuro la cuestión de los precios de Lindahl para elegir minimizar la obtención de preferencias. Teniendo en cuenta ahora por qué las consultas de demanda y equivalencia son analógicas directas, primero tenga en cuenta que dado el πi en algún equilibrio Lindahl, establecer pi(S) = max{0, Estos precios dejan a cada agente indiferente en todos los paquetes con precio positivo, y satisfacen la condición (1). Así, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl típicamente serán una constante aditivo lejos de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos de consultas de equivalencia a través de consultas de demanda. Lemma 1. Supongamos que un agente responde con un paquete preferido S cuando se propone un paquete S y soporta los precios de Lindahl p(S) (soportando con respecto a la valoración manifiesta de los agentes). A continuación, o bien?v(S) = v(S) o?v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: Φv(S) − p(S) ≥ Desigualdad (6) se mantiene porque el agente de hecho prefiere S a S dados los precios, de acuerdo con su respuesta a la consulta de demanda. Si fuera el caso de que?v(S) = v(S) y Así, al menos uno de S y S es un contraejemplo de la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño(v1,. . . , vn) en problemas de excitación. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que apoyar los precios de Lindahl debe necesariamente revelarse en el curso de cualquier protocolo de obtención de preferencias que termina con una asignación óptima. Además, Nisan y Segal (Lemma 1, [12]) afirman que en el peor de los casos los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones dobles (como será el caso de las clases más interesantes). Puesto que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y puesto que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitiendo la dependencia del tamaño(v1,. . . , vn) en problemas de excitación es totalmente natural. 183 4. DE APRENDIZAJE A LA LICITACIÓN DE PREFERENCIA La clave para convertir un algoritmo de aprendizaje a un algoritmo de excitación es simular consultas de equivalencia con consultas de demanda y valor hasta que se encuentre una asignación óptima. Debido a nuestra construcción de precios Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en que un agente responde SÍ a una consulta de equivalencia cuando la función de destino se ha aprendido exactamente. De lo contrario, podemos obtener un contraejemplo a una consulta de equivalencia dada una respuesta de agentes a una consulta de demanda. Teorema 1. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si cada uno puede ser polinomio-consulta exactamente aprendido de consultas de membresía y equivalencia. Prueba. Considere el algoritmo de excitación en la Figura 1. Cada consulta de membresía en el paso 1 es simulada con una consulta de valor ya que estas son de hecho idénticas. Considere el paso 4. Si todos los agentes responden SÍ, la condición (1) se mantiene. Condición (2) se mantiene porque la asignación calculada es la maximización de ingresos para el subastador, independientemente de los agentes verdaderas valoraciones. Así pues, se ha encontrado una asignación óptima. De lo contrario, por lo menos uno de Si o Si es un contraejemplo a Vi, por Lemma 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones del agente se conocerán exactamente, en cuyo caso la asignación óptima y los precios Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinomio de consultas, desde A1,. . . , A son todos los algoritmos de aprendizaje polinomio-quería. Tenga en cuenta que el procedimiento de conversión resulta en un algoritmo de excitación de preferencias, no un algoritmo de aprendizaje. Es decir, el algoritmo resultante no simplemente aprender las valoraciones exactamente, a continuación, calcular una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor, y periódicamente comprueba si se ha reunido suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio Lindahl para las valoraciones v1,. . . , vn utilizando una asignación y precios derivados de valoraciones manifiestas . . y encontrar una asignación óptima no implica que las valoraciones de los agentes se hayan aprendido exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta interrupción temprana. No obtendremos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE COMUNICACIÓN En esta sección, pasamos a la cuestión de la complejidad comunicativa de la excitación. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (tales como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos de determinar los precios de Lindahl es exponencial en el número de mercancías, m. La carga de comunicación se mide en términos del número de bits transmitidos entre agentes y subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. La conversión de algoritmos de aprendizaje eficientes a un algoritmo de excitación produce un algoritmo cuyas consultas tienen tamaños polinomios en los parámetros m y tamaño (v1, ). . . , vn). Teorema 2. Las clases de representación V1,. . . , Vn se puede obtener de forma eficiente de las consultas de valor y demanda si cada uno puede ser aprendido exactamente de las consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, basta con comunicar la función de valoración manifiesta de los agentes y el valor Nótese que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinomio, porque el tiempo de ejecución de los algoritmos también sería superpolinomio, contradiciendo la eficiencia. Por lo tanto, la comunicación de la valoración manifiesta requiere tamaño a lo sumo p(size(vi), m), para algunos polinomios p que limita superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representando el excedente πi al agente no se puede requerir espacio mayor que q(size( También debemos comunicarnos con su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es como máximo p(size(vi), m) + q(p(size(vi), m), m)+O(m). Claramente, una respuesta de agentes a una consulta de valor o demanda tiene un tamaño máximo de q(size(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, son siempre de tamaño polinomio. Un algoritmo de aprendizaje eficiente realiza un número polinomio de consultas, por lo que la comunicación total del algoritmo de excitación resultante es polinomio en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites pueden ser traducidos a límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de excitación resultante. Con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2 se determinó el tamaño de la hipótesis manifiesta. Es probable que podamos hacerlo mucho mejor que esto en la práctica. Recuerde que una consulta de equivalencia es apropiada si size( ̃f) ≤ size(f) en el momento de realizar la consulta. Si las consultas de equivalencia de algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites estrechos en los requisitos de comunicación del algoritmo de excitación resultante. El teorema 2 muestra que los algoritmos de excitación que dependen del tamaño (v1,. . . El parámetro, vn) evita los resultados negativos de Nisan y Segals [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto al tamaño de las instancias de las funciones de valoración que se enfrentan a cualquier ejecución del algoritmo. Estos algoritmos van bien si la clase de representación elegida proporciona representaciones sucintas para la más simple y común de las valoraciones, y por lo tanto el enfoque se mueve de nuevo a uno de lenguajes de licitación compactos pero expresivos. A continuación se examinan estas cuestiones. 6. APLICACIONES En esta sección, demostramos la aplicación de nuestros métodos a clases particulares de representación para valoraciones combinatorias. Hemos demostrado que el ",
                " para las clases de valoración V1,. . . , Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1,. . . , Una para las valoraciones de las clases V1,. . . , Vn respectivamente. Encaje hasta que haya una señal para detenerse: 1. Corre A1,. . . , Un en paralelo sobre sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se ha detenido con los agentes valoración exacta. 2. Calcular una asignación óptima (S1,. . . , Sn ) y los correspondientes precios de Lindahl con respecto a las valoraciones manifiestas . . , їvn determinado hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de consulta de demanda. 4. Si todos ellos responden SÍ, salida la asignación y parada. De lo contrario hay algún agente i que ha respondido con algún paquete preferido Si. Realizar consultas de valor en Si y Si para encontrar un contraejemplo a ‡vi, y proporcionarlo a Ai. Figura 1: Convertir algoritmos de aprendizaje a un algoritmo de excitación. al problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de función, y porque a menudo puede ser más simple resolver cada subproblema de aprendizaje por separado que atacar el ",
                " directamente. Podemos desarrollar un algoritmo de excitación que se adapta a cada valoración de agentes, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Demostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas de DNF monotono y funciones de umbral lineal se pueden convertir en algoritmos de excitación de preferencia para valoraciones generales, valoraciones con eliminación libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en las representaciones que son polinomialmente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la traqueabilidad computacional [18]. Al interpretar los métodos enfatizamos la expresividad y sucinta de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de licitación, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debe representar sucintamente las funciones más simples y comunes de la clase. 6.1 Las Representaciones Polinómicas Schapire y Sellie [17] dan un algoritmo de aprendizaje para polinomios multivariables escasos que pueden utilizarse como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas apropiadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados de t-sparse sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-sparse tiene como máximo t términos, donde un término es un producto de variables, por ejemplo. x1x3x4. Un polinomio sobre los números reales tiene coeficientes extraídos de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M →  se puede escribir exclusivamente como un polinomio [17]. Para tener una idea de la sucintaidad de los polinomios como lenguaje de licitación, considere las valoraciones aditivas y mono-ítem presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es el número de mercancías que contiene el paquete. En la valoración de un solo elemento, todos los paquetes tienen valor 1, excepto el valor 0 (i.e. el agente está satisfecho tan pronto como ha adquirido un único artículo). No es difícil demostrar que la valoración de un solo elemento requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Por lo tanto, los polinomios son adecuados para valoraciones que en su mayoría son aditivas, con algunas sustituibilidades y complementariedades que pueden introducirse ajustando los coeficientes. El algoritmo de aprendizaje para polinomios hace como máximo consultas de equivalencia mti +2 y como máximo (mti +1) (t2 i +3ti)/2 consultas de membresía a un agente i, donde ti es la esparcidad del polinomio que representa vi [17]. Por lo tanto, se obtiene un algoritmo que provoca valoraciones generales con un número polinomio de consultas y comunicación polinomio.6 6.2 XOR Representaciones El lenguaje de licitación XOR es estándar en la literatura de subastas combinatoria. Recordemos que una oferta XOR se caracteriza por un conjunto de paquetes B  2M y una función de valor w : B →  definida en esos paquetes, que induce la función de valoración: v(B) = max {B  B  B  B} w(B) (7) Las ofertas XOR pueden representar valoraciones que satisfacen la libre eliminación (y sólo tales valoraciones), que de nuevo es la propiedad que A  B El lenguaje de licitación XOR es ligeramente menos expresivo que los polinomios, porque los polinomios pueden representar valoraciones que no satisfacen la libre eliminación. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas de XOR pueden representar la valoración de un solo elemento con ofertas atómicas m, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario se aplica a los polinomios, estas dos lenguas son incomparables en sucintas y algo complementarias para su uso práctico. Blum et al. [5] note que las fórmulas DNF monotonas son los análogos de las pujas XOR en la literatura de teoría del aprendizaje. Una fórmula de DNF monotona es una disyunción de conjunciones en las que las variables aparecen sin negación, por ejemplo x1x2 x3 x2x4x5. Tenga en cuenta que tales fórmulas pueden ser representadas como ofertas XOR donde cada oferta atómica tiene valor 1; por lo tanto XOR ofrece generalizar fórmulas DNF monotono de Boolean a funciones de valor real. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para el DNF monotono ([3] Teorema 6 Tenga en cuenta que el Teorema 1 se aplica incluso si las valoraciones no satisfacen la eliminación libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lemma 2. Una oferta XOR que contiene ofertas t atómicas se puede aprender exactamente con consultas de equivalencia t + 1 y a lo sumo consultas de membresía tm. Prueba. El algoritmo identificará cada puja atómica en la puja XOR objetivo a su vez. Initialice la valoración manifiesta v a la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presente ‡v como consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un paquete S para el que v(S) = Crear un paquete T de la siguiente manera. Primero inicialice T = S. Para cada elemento i en T, compruebe a través de una consulta de membresía si v(T) = v(T − {i}). Si así se establece T = T − {i}. De lo contrario, deje T como está y pase al siguiente punto. Afirmamos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada ítem i en T, tenemos v(T) = v(T − {i}). Para ver esto, tenga en cuenta que en algún momento al generar T, tuvimos un ̄T tal que T  ̄T  S y v( ̄T) > v( ̄T − {i}), de modo que me mantuvo en ̄T. Tenga en cuenta que v(S) = v( ̄T) = v(T) porque el valor del paquete S se mantiene durante todo el proceso de eliminación de elementos. Ahora asume v(T) = v(T − {i}). Entonces v( ̄T) = v(T) = v(T − {i}) > v( ̄T − {i}) que contradice la libre eliminación, ya que T {i}  ̄T − {i}. Por lo tanto v(T) > v(T − {i}) para todos los ítems i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si este no fuera el caso, T tomaría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = máx itat {max T T Ahora mostramos que v(T) = ̃v(T), que implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Asumir que toda oferta atómica (R, Esta suposición se mantiene vagamente cuando se inicializa la valoración manifiesta. Usando la notación de (7), dejar ( Tenemos B  B, y Bw(B) = w(B) para B Por lo tanto,?v(S) = max {B} {B} {B} {B} {B} {B} = max {B} {B} {B} ≤ {B} {B} {B} {B} {S} w(B} = v(S) (8) Ahora asume v(T) {v(T La segunda igualdad se deriva del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad sostiene porque S es un contraejemplo de la valoración manifiesta. De la ecuación (9) y la eliminación libre, nosotros 7 El algoritmo citado también se utilizó como base para Zinkevich et al.s [19] algoritmo de excitación para Toolbox DNF. Recuerde que Toolbox DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia se puede simular con una consulta de valor en el paquete que contiene todas las mercancías. que tengan ‡v(T) < Entonces de nuevo de la ecuación (9) se deduce que v(S) < Esto contradice (8), por lo que de hecho tenemos v(T) = Por lo tanto (T, v(T)) no está actualmente en nuestra hipótesis como una oferta atómica, o tendríamos correctamente?v(T) = v(T) por la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas adicionales de equivalencia hasta que todas las ofertas atómicas hayan sido identificadas. Después de cada consulta de equivalencia, una oferta atómica se identifica con como máximo m consultas de membresía. Cada contraejemplo conduce al descubrimiento de una nueva oferta atómica. Por lo tanto, hacemos a lo sumo consultas de membresía tm y exactamente consultas de equivalencia t + 1. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR se puede obtener eficientemente de las consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al.s ([5], Teorema 2) afirmando que el DNF monotono (y por lo tanto las ofertas XOR) no se pueden obtener de manera eficiente cuando las consultas de demanda se limitan a precios lineales y anónimos sobre las mercancías. 6.3 Las representaciones lineales de umbral polinomios, las ofertas XOR y todas las lenguas basadas en el lenguaje de licitación OR (como XOR-de-OR, OR-de-XOR y OR*) no representan sucintamente la valoración mayoritaria [11]. En esta valoración, los paquetes tienen valor 1 si contienen al menos m/2 ítems, y valor 0 de lo contrario. Más generalmente, considere la familia de r-of-S de valoraciones donde los paquetes tienen valor 1 si contienen al menos r artículos de un conjunto especificado de ítems S  M, y valor 0 de otra manera. La valoración mayoritaria es un caso especial de la valoración de r-of-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar las sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede añadir valor. Dejando k = S, tales valoraciones están sucintamente representadas por funciones de umbral r-of-k. Estas funciones adoptan la forma de desigualdades lineales: xi1 +. . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se mantiene, y 0 de lo contrario. Aquí i1,. . . , ik son los elementos en S. Littlestones WINNOW 2 algoritmo puede aprender tales funciones utilizando consultas de equivalencia sólo, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de excitación que resulta de WINNOW 2 sólo utiliza consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos están implícitos cuando sólo hay dos valores posibles). Tenga en cuenta que las funciones de umbral r-of-k siempre se pueden representar sucintamente en el espacio O(m). Así se obtiene un algoritmo que puede generar tales funciones con un número polinomio de consultas y comunicación polinomio, en los parámetros n y m solos. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exactos con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de excitación de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas en el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la riqueza de algoritmos de aprendizaje disponibles al problema de la excitación de preferencias. Un enfoque de aprendizaje para la excitación también motiva un enfoque diferente para diseñar algoritmos de excitación que se descomponen cuidadosamente entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivos, muchos sustitutos, etc.), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de excitación. El algoritmo de excitación resultante hace un número polinomio de consultas, y hace comunicación polinomio si los algoritmos de aprendizaje originales son eficientes. No exigimos que las valoraciones de agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia sólo pueden ser, y sólo necesitan ser, simuladas hasta el punto en que se ha calculado una asignación óptima. Este es el "
            ]
        },
        "combinatorial auction": {
            "translated_key": "subasta combinatoria",
            "translated_annotated_text": "Aplicando algoritmos de aprendizaje a la eliminación de preferencia Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de excitación Demostramos que los algoritmos de aprendizaje pueden ser usados como base para algoritmos de excitación de preferencias. Los algoritmos de excitación resultantes realizan un número polinomio de consultas. También damos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de \"subasta combinatoria\" a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. En particular, se obtiene un algoritmo que provoca pujas XOR con comunicación polinómica. Categorías y Descriptores sujetos F.2.0 [Análisis de algoritmos y complejidad de problemas]: General; J.4 [Ciencias Sociales y Conductuales]: Economía; I.2.6 [Inteligencia Artificial]: Términos generales de aprendizaje Algoritmos, Economía, Teoría 1. INTRODUCCIÓN En una \"subasta combinatoria\", los agentes pueden pujar sobre paquetes de bienes en lugar de solo bienes individuales. Puesto que hay un número exponencial de paquetes (en el número de bienes), comunicar los valores sobre estos paquetes puede ser problemático. Comunicar las valoraciones de una sola vez puede ser prohibitivamente costoso si el número de bienes es sólo moderadamente grande. Además, incluso podría ser difícil para los agentes determinar sus valoraciones para paquetes únicos [14]. A esos agentes les interesa disponer de protocolos de subasta que les obliguen a pujar en el menor número posible de paquetes. Incluso si los agentes pueden calcular eficientemente sus valoraciones, podrían ser reacios a revelarlas enteramente en el curso de una subasta, porque tal información puede ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información necesaria para determinar una asignación óptima de los bienes. Ha habido un trabajo reciente explorando los vínculos entre el problema de la excitación de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje computacional [5, 19]. En teoría de aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, tales como ¿Cuál es el valor de las funciones en estas entradas? En la obtención de preferencia, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Demostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia se puede convertir en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de excitación resultante garantiza la excitación en un número polinomio de consultas de valor y demanda. Aquí queremos decir polinomio en el número de bienes, agentes, y los tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Argumentamos que las garantías de complejidad para los esquemas de excitación deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar la comunicación polinómica en el peor de los casos, que normalmente no se puede lograr en el número de productos y agentes por sí solos. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de \"subasta combinatoria\" a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. Por supuesto, una \"subasta combinatoria\" única en la que los agentes proporcionan todas sus funciones de valoración a la vez también tendría comunicación polinómica en el tamaño de las valoraciones de los agentes, y sólo requieren una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay ninguna carga para los agentes de formular sus valoraciones en un esquema de codificación de los subastadores que elijan. Esperamos que esta sea una consideración importante en la práctica. Además, con nuestro esquema la revelación entera sólo ocurre en el peor de los casos. 180 Por ahora, dejamos a un lado la cuestión de los incentivos al derivar algoritmos de excitación. Nos centramos en el tiempo y la complejidad de la comunicación de la obtención de preferencias, independientemente de las limitaciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich y otros [19] considerar el problema del aprendizaje de clases restringidas de funciones de valoración que se pueden representar utilizando fórmulas de lectura once y Toolbox DNF. Las fórmulas Read-once pueden representar ciertas sustitutibilidades, pero no complementariedades, mientras que lo contrario se mantiene para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten depender del tamaño de la valoración objetivo como lo hacemos (aunque las valoraciones de read-once siempre se pueden representar sucintamente de todos modos). Su trabajo sólo hace uso de consultas de valor, que son bastante limitados en el poder. Debido a que nos permitimos pedir consultas, somos capaces de derivar un esquema de excitación para las funciones de valoración general. Blum et al. [5] proporcionar resultados relacionados con las complejidades del aprendizaje de la consulta y la excitación de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje de consultas, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones se pueden aprender eficientemente, pero no se pueden obtener eficientemente, y viceversa. En contraste, nuestro trabajo muestra que dada una versión más general (todavía bastante estándar) de la consulta de demanda que el tipo que consideran, la complejidad de la excitación de preferencia no es mayor que la complejidad del aprendizaje. Demostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre valoraciones para implicar una solución al problema de excitación. Nisan y Segal [12] estudian la complejidad comunicativa de la excitación de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos de la computación una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo se permite a los algoritmos hacer preguntas sobre valoraciones de agentes y recibir respuestas honestas, sin ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda la cuestión de la complejidad de la comunicación, y somos capaces de derivar algoritmos que proporcionan garantías de comunicación significativas a pesar de los resultados negativos de Nisan y Segals. Su trabajo motiva la necesidad de confiar en el tamaño de los agentes funciones de valoración para indicar los peores resultados. 2. LOS MODELOS 2.1 Aprendizaje de la consulta El modelo de aprendizaje de la consulta que consideramos aquí se llama aprendizaje exacto de la membresía y consultas de equivalencia, introducido por Angluin [2]. En este modelo el objetivo de los algoritmos de aprendizaje es identificar exactamente una función diana desconocida f : X → Y a través de consultas a un oráculo. La función de destino se extrae de una función de clase C que es conocida por el algoritmo. Típicamente el dominio X es algún subconjunto de {0, 1}m, y el rango Y es {0, 1} o algún subconjunto de los números reales. A medida que el algoritmo avanza, construye una hipótesis manifiesta?f que es su estimación actual de la función de destino. Después de la terminación, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface?f(x) = f(x) para todos x?X. Es importante especificar la representación que se utilizará para codificar funciones de C. Por ejemplo, considere la siguiente función de {0, 1}m a ♥: f(x) = 2 si x consiste en m 1s, y f(x) = 0 de otra manera. Esta función puede representarse simplemente como una lista de valores de 2m. O puede codificarse como el polinomio 2x1 · · · xm, que es mucho más sucinto. Así pues, la elección de la codificación puede tener un impacto significativo en las necesidades de tiempo y espacio del algoritmo de aprendizaje. Let size(f) ser el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes distintos de cero en el polinomio, por ejemplo. Por lo general, sólo nos referiremos a las clases de representación; las clases de funciones correspondientes serán implícitas. Por ejemplo, la clase de representación de fórmulas DNF monotonas implica la clase de función de funciones booleanas monotonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: la membresía y las consultas de equivalencia. En una consulta de membresía, el aprendiz presenta algunas x x x y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta f. El oráculo responde SÍ si?f = f, o devuelve un contraejemplo x de tal manera que?f(x) = f(x). Una consulta de equivalencia es apropiada si el tamaño( ̃f) ≤ tamaño(f) en el momento de presentar la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones se adaptan a partir de Kearns y Vazirani [9]: Definición 1. La clase de representación C es polinomialquery exactamente aprendeble de las consultas de membresía y equivalencia si hay un polinomial fijo p(·, ·) y un algoritmo L con acceso a la membresía y consultas de equivalencia de un oráculo tal que para cualquier función de destino f • C, L salidas después de a lo sumo p(size(f), m) consultas de una función?f • C tal que?f Del mismo modo, la clase de representación C se puede aprender exactamente de las consultas de membresía y equivalencia si el algoritmo L produce una hipótesis correcta en el tiempo p(size(f), m), para algunos polinomios fijos p(·, ·). Aquí m es la dimensión del dominio. Dado que la función de destino debe ser reconstruida, también permitimos necesariamente la dependencia polinómica del tamaño (f). 2.2 Eliminación de preferencias En una \"subasta combinatoria\", un conjunto de bienes M se asignará entre un conjunto de agentes N a fin de maximizar la suma de las valoraciones de los agentes. Tal asignación se llama eficiente en la literatura de economía, pero nos referiremos a ella como óptima y reservar el término eficiente para referirse a la eficiencia computacional. Dejamos n = N y m = M. Una asignación es una partición de los objetos en paquetes (S1,. . . , Sn), de tal manera que Si â € ¬ Sj = â € para todos los i, j â € N. Let â € € sea el conjunto de posibles asignaciones. Cada agente i+N tiene una función de valoración vi : 2M → • sobre el espacio de los paquetes posibles. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no tienen que coincidir. Asumimos que todas las valoraciones consideradas están normalizadas, es decir, v() = 0, y que no hay externalidades, es decir, vi(S1,..., Sn) = vi(Si), para todos los agentes i  N, para cualquier asignación (S1,..., Sn)  (es decir, un agente se preocupa sólo por el paquete asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales.1 Nosotros 1 A menudo las valoraciones generales se hacen para satisfacer los 181 adicionales también asumen que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que los agentes utilidades pueden ser divididos en componentes monetarios y no monetarios. Si a un agente i se le asigna el paquete S al precio p, deriva utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más sucintas para ciertas clases de valoración, y ha habido mucha investigación en lenguajes de licitación concisos para diversos tipos de valoraciones [11]. Un ejemplo clásico al que nos referiremos más adelante es el lenguaje de licitación XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, que consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estas pujas, se busca el paquete S del valor más alto listado en las pujas atómicas de tal manera que S  S. Es entonces el caso que v(S) = v(S). Al igual que en el contexto de la teoría del aprendizaje, por lo general sólo nos referiremos a idiomas de oferta en lugar de clases de valoración, ya que las clases de valoración correspondientes serán implícitas. Por ejemplo, el lenguaje de licitación XOR implica la clase de valoraciones que satisfacen la disposición libre, que es la condición de que A  B ♥ v(A) ≤ v(B). Dejamos el tamaño(v1,. . . , vn) = Èn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de licitación). Para hacer una analogía con la teoría del aprendizaje computacional, suponemos que todas las clases de representación consideradas son polinomiamente interpretables [11], lo que significa que el valor de un paquete puede ser calculado en tiempo polinomio dada la representación de funciones de valoración. Más formalmente, una clase de representación (lenguaje de licitación) C es polinomialmente interpretable si existe un algoritmo que da como entrada algunos v • C y una instancia x • X calcula el valor v(x) en el tiempo q(size(v), m), para algún polinomio fijo q(·, ·).2 En las rondas intermedias de una subasta (terativa), el subastador habrá obtenido información sobre las funciones de Por lo tanto, habrá construido un conjunto de valoraciones manifiestas, denotadas . . Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha adquirido información sobre ciertos paquetes. El objetivo en el problema de la excitación de preferencia es construir un conjunto de valoraciones manifiestas tales que: arg max (S1,...,Sn) iÃ3n Ã3vi(Si)  arg max (S1,...,Sn) iÃ3n vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que es óptima con respecto a las valoraciones verdaderas. Tenga en cuenta que sólo se requiere una asignación óptima. condición de la libre eliminación (monotonicidad), pero no la necesitamos en este punto. 2 Esto excluye OR*, asumiendo P = NP, porque la interpretación de las ofertas de este lenguaje es NP-duro por reducción de set-embalaje ponderado, y no hay clase de representación bien estudiada en teoría de aprendizaje que es claramente análogo a OR*. 3 Esta visión de las subastas iterativas tiene por objeto paralelizar el entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente están implícitas por la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son consultas de valor y demanda. En una consulta de valor, el subastador presenta un paquete S  M y el agente responde con su valor (exacto) para el paquete v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p • • • (2m ) sobre los paquetes junto con un paquete S. El agente responde SI si es el caso de que S • arg max S M v(S ) − p(S ) ¡ o de otro modo presenta un paquete S tal que v(S ) − p(S ) > v( Tenga en cuenta también que comunicar precios no lineales no implica necesariamente citar un precio por cada paquete posible. Puede haber formas más sucintas de comunicar este vector, como se muestra en la sección 5. Hacemos las siguientes definiciones para paralelizar la configuración de aprendizaje de la consulta y para simplificar las declaraciones de resultados posteriores: Definición 2. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si hay un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes tales que para cualquier (v1,. . . , vn) V1 ×. . . × Vn, L salidas después de como máximo p(size(v1,. . . , vn), m) consulta una asignación (S1,. . . , Sn) arg max(S1,...,Sn) È vi(Si). Del mismo modo, la clase de representación C se puede obtener eficientemente de las consultas de valor y demanda si el algoritmo L produce una asignación óptima con comunicación p(size(v1, ). . . , vn), m), para algunos polinomios fijos p(·, ·). Hay algunas diferencias clave aquí con la definición de aprendizaje de la consulta. Hemos eliminado el término exactamente ya que las funciones de valoración no necesitan ser determinadas exactamente con el fin de calcular una asignación óptima. Además, un algoritmo de excitación eficiente es la comunicación polinomio, en lugar de tiempo polinomio. Esto refleja el hecho de que la comunicación en lugar del tiempo de espera es el cuello de botella en la excitación. Cálculo de una asignación óptima de bienes incluso cuando se dan las valoraciones verdaderas es NP-duro para una amplia gama de clases de valoración. Por lo tanto, no es razonable exigir tiempo polinomio en la definición de un algoritmo de excitación de preferencias eficiente. Nos complace centrarnos en la complejidad comunicativa de la excitación porque se cree que este problema es más significativo en la práctica que el de la determinación del ganador [11].5 4 Esto difiere ligeramente de la definición proporcionada por Blum et al. [5] Sus consultas sobre la demanda se limitan a precios lineales sobre las mercancías, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir. un precio distinto por cada paquete posible. Es por eso que el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. 5 Aunque el problema de determinación del ganador es NP-hard para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta aproximaciones usando solucionadores IP fuera de la plataforma [1]. 182 Dado que no es necesario obtener exactamente las valoraciones, es inicialmente menos claro si la dependencia polinómica del tamaño (v1, ). . . , vn) está justificado en este contexto. Intuitivamente, este parámetro está justificado porque debemos aprender valoraciones exactamente cuando se realiza la excitación, en el peor de los casos. Nos ocupamos de esto en la siguiente sección. 3. PARALLESBETWEEN EQUIVALENCIA Y QUERIDAS DE DEMANDA Hemos descrito los ajustes de aprendizaje y excitación de preferencias de la consulta de una manera que destaca sus similitudes. Las consultas de valor y membresía son claras analógicas. Un poco menos obvio es el hecho de que las consultas de equivalencia y demanda también son analógicas. Para ver esto, necesitamos el concepto de precios Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios sobre sus bienes subyacentes. Son no anónimos en el sentido de que dos agentes pueden tener que hacer frente a precios diferentes para el mismo paquete de mercancías. Así los precios de Lindahl son de la forma pi(S), para todos S  M, para todos los precios de i  N. Lindahl se presentan a los agentes en consultas de la demanda. Cuando los agentes han normalizado las funciones de utilidad cuasi-lineal, Bikhchandani y Ostroy [4] muestran que siempre existen precios Lindahl tales que (S1,. . . , Sn) es una asignación óptima si y sólo si Si • arg max Si vi(Si) − pi(Si) • i N (1) (S1,. . . , Sn)  arg max (S1,...,Sn) iN pi(Si) (2) Condición (1) establece que cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos de los subastadores a los precios indicados. El escenario en el que se mantienen estas condiciones se llama equilibrio Lindahl, o a menudo un equilibrio competitivo. Decimos que los precios de Lindahl apoyan la asignación óptima. Por lo tanto, basta con anunciar los precios de apoyo de Lindahl para verificar una asignación óptima. Una vez que hemos encontrado una asignación con el apoyo de precios Lindahl, el problema de excitación se resuelve. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones estén garantizadas como integrales [4]. Las variables duales de este programa lineal están soportando los precios de Lindahl para la asignación resultante. La función objetiva del programa dual es: min pi(S) Por lo general, hay una gama de posibles precios Lindahl que apoyan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios válidos Lindahl, y nos referimos a ellos como precios máximos Lindahl. De todos los vectores posibles de precios Lindahl, precios máximos Lindahl maximizar la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È iÃ3N πi del objetivo (la suma de los agentes de utilidades) son precios mínimos Lindahl. Cualquier Lindahl precios hará para nuestros resultados, pero algunos pueden tener mejores propiedades de excitación que otros. Tenga en cuenta que una consulta de demanda con precios máximos de Lindahl es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para el trabajo futuro la cuestión de los precios de Lindahl para elegir minimizar la obtención de preferencias. Teniendo en cuenta ahora por qué las consultas de demanda y equivalencia son analógicas directas, primero tenga en cuenta que dado el πi en algún equilibrio Lindahl, establecer pi(S) = max{0, Estos precios dejan a cada agente indiferente en todos los paquetes con precio positivo, y satisfacen la condición (1). Así, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl típicamente serán una constante aditivo lejos de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos de consultas de equivalencia a través de consultas de demanda. Lemma 1. Supongamos que un agente responde con un paquete preferido S cuando se propone un paquete S y soporta los precios de Lindahl p(S) (soportando con respecto a la valoración manifiesta de los agentes). A continuación, o bien?v(S) = v(S) o?v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: Φv(S) − p(S) ≥ Desigualdad (6) se mantiene porque el agente de hecho prefiere S a S dados los precios, de acuerdo con su respuesta a la consulta de demanda. Si fuera el caso de que?v(S) = v(S) y Así, al menos uno de S y S es un contraejemplo de la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño(v1,. . . , vn) en problemas de excitación. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que apoyar los precios de Lindahl debe necesariamente revelarse en el curso de cualquier protocolo de obtención de preferencias que termina con una asignación óptima. Además, Nisan y Segal (Lemma 1, [12]) afirman que en el peor de los casos los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones dobles (como será el caso de las clases más interesantes). Puesto que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y puesto que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitiendo la dependencia del tamaño(v1,. . . , vn) en problemas de excitación es totalmente natural. 183 4. DE APRENDIZAJE A LA LICITACIÓN DE PREFERENCIA La clave para convertir un algoritmo de aprendizaje a un algoritmo de excitación es simular consultas de equivalencia con consultas de demanda y valor hasta que se encuentre una asignación óptima. Debido a nuestra construcción de precios Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en que un agente responde SÍ a una consulta de equivalencia cuando la función de destino se ha aprendido exactamente. De lo contrario, podemos obtener un contraejemplo a una consulta de equivalencia dada una respuesta de agentes a una consulta de demanda. Teorema 1. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si cada uno puede ser polinomio-consulta exactamente aprendido de consultas de membresía y equivalencia. Prueba. Considere el algoritmo de excitación en la Figura 1. Cada consulta de membresía en el paso 1 es simulada con una consulta de valor ya que estas son de hecho idénticas. Considere el paso 4. Si todos los agentes responden SÍ, la condición (1) se mantiene. Condición (2) se mantiene porque la asignación calculada es la maximización de ingresos para el subastador, independientemente de los agentes verdaderas valoraciones. Así pues, se ha encontrado una asignación óptima. De lo contrario, por lo menos uno de Si o Si es un contraejemplo a Vi, por Lemma 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones del agente se conocerán exactamente, en cuyo caso la asignación óptima y los precios Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinomio de consultas, desde A1,. . . , A son todos los algoritmos de aprendizaje polinomio-quería. Tenga en cuenta que el procedimiento de conversión resulta en un algoritmo de excitación de preferencias, no un algoritmo de aprendizaje. Es decir, el algoritmo resultante no simplemente aprender las valoraciones exactamente, a continuación, calcular una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor, y periódicamente comprueba si se ha reunido suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio Lindahl para las valoraciones v1,. . . , vn utilizando una asignación y precios derivados de valoraciones manifiestas . . y encontrar una asignación óptima no implica que las valoraciones de los agentes se hayan aprendido exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta interrupción temprana. No obtendremos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE COMUNICACIÓN En esta sección, pasamos a la cuestión de la complejidad comunicativa de la excitación. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (tales como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos de determinar los precios de Lindahl es exponencial en el número de mercancías, m. La carga de comunicación se mide en términos del número de bits transmitidos entre agentes y subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. La conversión de algoritmos de aprendizaje eficientes a un algoritmo de excitación produce un algoritmo cuyas consultas tienen tamaños polinomios en los parámetros m y tamaño (v1, ). . . , vn). Teorema 2. Las clases de representación V1,. . . , Vn se puede obtener de forma eficiente de las consultas de valor y demanda si cada uno puede ser aprendido exactamente de las consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, basta con comunicar la función de valoración manifiesta de los agentes y el valor Nótese que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinomio, porque el tiempo de ejecución de los algoritmos también sería superpolinomio, contradiciendo la eficiencia. Por lo tanto, la comunicación de la valoración manifiesta requiere tamaño a lo sumo p(size(vi), m), para algunos polinomios p que limita superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representando el excedente πi al agente no se puede requerir espacio mayor que q(size( También debemos comunicarnos con su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es como máximo p(size(vi), m) + q(p(size(vi), m), m)+O(m). Claramente, una respuesta de agentes a una consulta de valor o demanda tiene un tamaño máximo de q(size(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, son siempre de tamaño polinomio. Un algoritmo de aprendizaje eficiente realiza un número polinomio de consultas, por lo que la comunicación total del algoritmo de excitación resultante es polinomio en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites pueden ser traducidos a límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de excitación resultante. Con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2 se determinó el tamaño de la hipótesis manifiesta. Es probable que podamos hacerlo mucho mejor que esto en la práctica. Recuerde que una consulta de equivalencia es apropiada si size( ̃f) ≤ size(f) en el momento de realizar la consulta. Si las consultas de equivalencia de algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites estrechos en los requisitos de comunicación del algoritmo de excitación resultante. El teorema 2 muestra que los algoritmos de excitación que dependen del tamaño (v1,. . . El parámetro, vn) evita los resultados negativos de Nisan y Segals [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto al tamaño de las instancias de las funciones de valoración que se enfrentan a cualquier ejecución del algoritmo. Estos algoritmos van bien si la clase de representación elegida proporciona representaciones sucintas para la más simple y común de las valoraciones, y por lo tanto el enfoque se mueve de nuevo a uno de lenguajes de licitación compactos pero expresivos. A continuación se examinan estas cuestiones. 6. APLICACIONES En esta sección, demostramos la aplicación de nuestros métodos a clases particulares de representación para valoraciones combinatorias. Hemos demostrado que el problema de excitación de preferencias para las clases de valoración V1,. . . , Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1,. . . , Una para las valoraciones de las clases V1,. . . , Vn respectivamente. Encaje hasta que haya una señal para detenerse: 1. Corre A1,. . . , Un en paralelo sobre sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se ha detenido con los agentes valoración exacta. 2. Calcular una asignación óptima (S1,. . . , Sn ) y los correspondientes precios de Lindahl con respecto a las valoraciones manifiestas . . , їvn determinado hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de consulta de demanda. 4. Si todos ellos responden SÍ, salida la asignación y parada. De lo contrario hay algún agente i que ha respondido con algún paquete preferido Si. Realizar consultas de valor en Si y Si para encontrar un contraejemplo a ‡vi, y proporcionarlo a Ai. Figura 1: Convertir algoritmos de aprendizaje a un algoritmo de excitación. al problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de función, y porque a menudo puede ser más simple resolver cada subproblema de aprendizaje por separado que atacar el problema de excitación de preferencias directamente. Podemos desarrollar un algoritmo de excitación que se adapta a cada valoración de agentes, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Demostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas de DNF monotono y funciones de umbral lineal se pueden convertir en algoritmos de excitación de preferencia para valoraciones generales, valoraciones con eliminación libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en las representaciones que son polinomialmente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la traqueabilidad computacional [18]. Al interpretar los métodos enfatizamos la expresividad y sucinta de cada clase de representación. La clase de representación, que en términos de \"subasta combinatoria\" define un lenguaje de licitación, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debe representar sucintamente las funciones más simples y comunes de la clase. 6.1 Las Representaciones Polinómicas Schapire y Sellie [17] dan un algoritmo de aprendizaje para polinomios multivariables escasos que pueden utilizarse como base para un protocolo de \"subasta combinatoria\". Las consultas de equivalencia realizadas por este algoritmo son todas apropiadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados de t-sparse sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-sparse tiene como máximo t términos, donde un término es un producto de variables, por ejemplo. x1x3x4. Un polinomio sobre los números reales tiene coeficientes extraídos de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M →  se puede escribir exclusivamente como un polinomio [17]. Para tener una idea de la sucintaidad de los polinomios como lenguaje de licitación, considere las valoraciones aditivas y mono-ítem presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es el número de mercancías que contiene el paquete. En la valoración de un solo elemento, todos los paquetes tienen valor 1, excepto el valor 0 (i.e. el agente está satisfecho tan pronto como ha adquirido un único artículo). No es difícil demostrar que la valoración de un solo elemento requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Por lo tanto, los polinomios son adecuados para valoraciones que en su mayoría son aditivas, con algunas sustituibilidades y complementariedades que pueden introducirse ajustando los coeficientes. El algoritmo de aprendizaje para polinomios hace como máximo consultas de equivalencia mti +2 y como máximo (mti +1) (t2 i +3ti)/2 consultas de membresía a un agente i, donde ti es la esparcidad del polinomio que representa vi [17]. Por lo tanto, se obtiene un algoritmo que provoca valoraciones generales con un número polinomio de consultas y comunicación polinomio.6 6.2 XOR Representaciones El lenguaje de licitación XOR es estándar en la literatura de subastas combinatoria. Recordemos que una oferta XOR se caracteriza por un conjunto de paquetes B  2M y una función de valor w : B →  definida en esos paquetes, que induce la función de valoración: v(B) = max {B  B  B  B} w(B) (7) Las ofertas XOR pueden representar valoraciones que satisfacen la libre eliminación (y sólo tales valoraciones), que de nuevo es la propiedad que A  B El lenguaje de licitación XOR es ligeramente menos expresivo que los polinomios, porque los polinomios pueden representar valoraciones que no satisfacen la libre eliminación. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas de XOR pueden representar la valoración de un solo elemento con ofertas atómicas m, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario se aplica a los polinomios, estas dos lenguas son incomparables en sucintas y algo complementarias para su uso práctico. Blum et al. [5] note que las fórmulas DNF monotonas son los análogos de las pujas XOR en la literatura de teoría del aprendizaje. Una fórmula de DNF monotona es una disyunción de conjunciones en las que las variables aparecen sin negación, por ejemplo x1x2 x3 x2x4x5. Tenga en cuenta que tales fórmulas pueden ser representadas como ofertas XOR donde cada oferta atómica tiene valor 1; por lo tanto XOR ofrece generalizar fórmulas DNF monotono de Boolean a funciones de valor real. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para el DNF monotono ([3] Teorema 6 Tenga en cuenta que el Teorema 1 se aplica incluso si las valoraciones no satisfacen la eliminación libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lemma 2. Una oferta XOR que contiene ofertas t atómicas se puede aprender exactamente con consultas de equivalencia t + 1 y a lo sumo consultas de membresía tm. Prueba. El algoritmo identificará cada puja atómica en la puja XOR objetivo a su vez. Initialice la valoración manifiesta v a la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presente ‡v como consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un paquete S para el que v(S) = Crear un paquete T de la siguiente manera. Primero inicialice T = S. Para cada elemento i en T, compruebe a través de una consulta de membresía si v(T) = v(T − {i}). Si así se establece T = T − {i}. De lo contrario, deje T como está y pase al siguiente punto. Afirmamos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada ítem i en T, tenemos v(T) = v(T − {i}). Para ver esto, tenga en cuenta que en algún momento al generar T, tuvimos un ̄T tal que T  ̄T  S y v( ̄T) > v( ̄T − {i}), de modo que me mantuvo en ̄T. Tenga en cuenta que v(S) = v( ̄T) = v(T) porque el valor del paquete S se mantiene durante todo el proceso de eliminación de elementos. Ahora asume v(T) = v(T − {i}). Entonces v( ̄T) = v(T) = v(T − {i}) > v( ̄T − {i}) que contradice la libre eliminación, ya que T {i}  ̄T − {i}. Por lo tanto v(T) > v(T − {i}) para todos los ítems i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si este no fuera el caso, T tomaría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = máx itat {max T T Ahora mostramos que v(T) = ̃v(T), que implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Asumir que toda oferta atómica (R, Esta suposición se mantiene vagamente cuando se inicializa la valoración manifiesta. Usando la notación de (7), dejar ( Tenemos B  B, y Bw(B) = w(B) para B Por lo tanto,?v(S) = max {B} {B} {B} {B} {B} {B} = max {B} {B} {B} ≤ {B} {B} {B} {B} {S} w(B} = v(S) (8) Ahora asume v(T) {v(T La segunda igualdad se deriva del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad sostiene porque S es un contraejemplo de la valoración manifiesta. De la ecuación (9) y la eliminación libre, nosotros 7 El algoritmo citado también se utilizó como base para Zinkevich et al.s [19] algoritmo de excitación para Toolbox DNF. Recuerde que Toolbox DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia se puede simular con una consulta de valor en el paquete que contiene todas las mercancías. que tengan ‡v(T) < Entonces de nuevo de la ecuación (9) se deduce que v(S) < Esto contradice (8), por lo que de hecho tenemos v(T) = Por lo tanto (T, v(T)) no está actualmente en nuestra hipótesis como una oferta atómica, o tendríamos correctamente?v(T) = v(T) por la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas adicionales de equivalencia hasta que todas las ofertas atómicas hayan sido identificadas. Después de cada consulta de equivalencia, una oferta atómica se identifica con como máximo m consultas de membresía. Cada contraejemplo conduce al descubrimiento de una nueva oferta atómica. Por lo tanto, hacemos a lo sumo consultas de membresía tm y exactamente consultas de equivalencia t + 1. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR se puede obtener eficientemente de las consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al.s ([5], Teorema 2) afirmando que el DNF monotono (y por lo tanto las ofertas XOR) no se pueden obtener de manera eficiente cuando las consultas de demanda se limitan a precios lineales y anónimos sobre las mercancías. 6.3 Las representaciones lineales de umbral polinomios, las ofertas XOR y todas las lenguas basadas en el lenguaje de licitación OR (como XOR-de-OR, OR-de-XOR y OR*) no representan sucintamente la valoración mayoritaria [11]. En esta valoración, los paquetes tienen valor 1 si contienen al menos m/2 ítems, y valor 0 de lo contrario. Más generalmente, considere la familia de r-of-S de valoraciones donde los paquetes tienen valor 1 si contienen al menos r artículos de un conjunto especificado de ítems S  M, y valor 0 de otra manera. La valoración mayoritaria es un caso especial de la valoración de r-of-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar las sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede añadir valor. Dejando k = S, tales valoraciones están sucintamente representadas por funciones de umbral r-of-k. Estas funciones adoptan la forma de desigualdades lineales: xi1 +. . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se mantiene, y 0 de lo contrario. Aquí i1,. . . , ik son los elementos en S. Littlestones WINNOW 2 algoritmo puede aprender tales funciones utilizando consultas de equivalencia sólo, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de excitación que resulta de WINNOW 2 sólo utiliza consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos están implícitos cuando sólo hay dos valores posibles). Tenga en cuenta que las funciones de umbral r-of-k siempre se pueden representar sucintamente en el espacio O(m). Así se obtiene un algoritmo que puede generar tales funciones con un número polinomio de consultas y comunicación polinomio, en los parámetros n y m solos. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exactos con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de excitación de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas en el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la riqueza de algoritmos de aprendizaje disponibles al problema de la excitación de preferencias. Un enfoque de aprendizaje para la excitación también motiva un enfoque diferente para diseñar algoritmos de excitación que se descomponen cuidadosamente entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivos, muchos sustitutos, etc.), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de excitación. El algoritmo de excitación resultante hace un número polinomio de consultas, y hace comunicación polinomio si los algoritmos de aprendizaje originales son eficientes. No exigimos que las valoraciones de agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia sólo pueden ser, y sólo necesitan ser, simuladas hasta el punto en que se ha calculado una asignación óptima. Este es el problema de la excitación de preferencias. Teorema 1 implica que la excitación con consultas de valor y demanda no es más difícil que aprender con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las que la excitación es más fácil que el aprendizaje. Blum et al. [5] proporcionar tal ejemplo al considerar solamente consultas de membresía/valor (Teorema 4). En el trabajo futuro planeamos abordar la cuestión de los incentivos al convertir algoritmos de aprendizaje a algoritmos de excitación. En el entorno de aprendizaje, por lo general suponemos que los oráculos proporcionarán respuestas honestas a las preguntas; en el entorno de excitación, los agentes son generalmente egoístas y proporcionarán respuestas posiblemente deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para el aprendizaje de polinomios y pujas XOR como algoritmos de excitación, y probar su rendimiento contra otros protocolos de \"subasta combinatoria\" establecidos [6, 15]. Una pregunta interesante aquí es: ¿qué precios Lindahl en el rango máximo a mínimo son los mejores para citar con el fin de minimizar la revelación de información? Suponemos que la revelación de información se reduce al pasar de precios máximos a precios mínimos de Lindahl, es decir, a medida que desplazamos las consultas de demanda más lejos de las consultas de equivalencia. Por último, sería útil determinar si el lenguaje de licitación de OR* [11] puede aprenderse (y, por lo tanto, obtenerse) de manera eficiente, dada la expresividad y sucinta de estas lenguas para una amplia variedad de clases de valoración. Agradecimientos Queremos agradecer a Debasis Mishra por sus útiles discusiones. Este trabajo está apoyado en parte por la subvención de NSF IIS0238147. 8. REFERENCIAS [1] A. Andersson, M. Tenhunen, y F. Ygge. Programación integral para la determinación del ganador de la \"subasta combinatoria\". En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprender conjuntos regulares de consultas y contraejemplos. Información e computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje conceptual. Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El modelo de asignación de paquetes. Diario de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Provocación de preferencias y aprendizaje de consultas. En Proc. 16a Conferencia Anual sobre Teoría del Aprendizaje Computacional (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. la 18a Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, e Y. Shoham. Domar la complejidad computacional de las subastas combinatoria: Enfoques óptimos y aproximados. En Proc. , 16a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), págs. 548 a 553, 1999. [8] B. Hudson y T. Sandholm. Uso de consultas de valor en subastas combinatoria. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría del aprendizaje computacional. MIT Press, 1994. [10] N. Littlestone. Aprender rápidamente cuando los atributos irrelevantes abundan: Un nuevo algoritmo de umbral lineal. Machine Learning, 2:285-318, 1988. [11] N. Nisan. Licitación y asignación en subastas combinatoria. En Proc. la Conferencia de la ACM sobre Comercio Electrónico, págs. 1 a 12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y el apoyo a los precios Lindahl. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de mínima revelación. En Padget et al., editor, Agent-Mediated Electronic Commerce IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. Diseño de subastas con costosas preferencias. En Temas Especiales de Anales de Matemáticas y AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17a Conferencia Nacional sobre Inteligencia Artificial (AAAI-00), págs. 74 a 81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. la 17a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariables escasos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de ACM sobre Teoría del Aprendizaje Computacional, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendido. Comun. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum, y T. Sandholm. Sobre la excitación de la preferencia polinomio-tiempo con las consultas de valor. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "error": [
                ""
            ]
        },
        "learning": {
            "translated_key": "aprendizaje",
            "translated_annotated_text": "Aplicando algoritmos de aprendizaje a la eliminación de preferencia Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de excitación Demostramos que los algoritmos de \"aprendizaje\" pueden ser usados como base para algoritmos de excitación de preferencias. Los algoritmos de excitación resultantes realizan un número polinomio de consultas. También damos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de \"aprendizaje\" para polinomios, DNF monotono y funciones de umbral lineal. En particular, se obtiene un algoritmo que provoca pujas XOR con comunicación polinómica. Categorías y Descriptores sujetos F.2.0 [Análisis de algoritmos y complejidad de problemas]: General; J.4 [Ciencias Sociales y Conductuales]: Economía; I.2.6 [Inteligencia Artificial]: Términos generales de aprendizaje Algoritmos, Economía, Teoría 1. INTRODUCCIÓN En una subasta combinatoria, los agentes pueden pujar por paquetes de bienes en lugar de por cada uno de ellos. Puesto que hay un número exponencial de paquetes (en el número de bienes), comunicar los valores sobre estos paquetes puede ser problemático. Comunicar las valoraciones de una sola vez puede ser prohibitivamente costoso si el número de bienes es sólo moderadamente grande. Además, incluso podría ser difícil para los agentes determinar sus valoraciones para paquetes únicos [14]. A esos agentes les interesa disponer de protocolos de subasta que les obliguen a pujar en el menor número posible de paquetes. Incluso si los agentes pueden calcular eficientemente sus valoraciones, podrían ser reacios a revelarlas enteramente en el curso de una subasta, porque tal información puede ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información necesaria para determinar una asignación óptima de los bienes. Ha habido un trabajo reciente explorando los vínculos entre el problema de la excitación de preferencias en subastas combinatorias y el problema de \"aprendizaje\" una función desconocida de la teoría del \"aprendizaje\" computacional [5, 19]. En la teoría del \"aprendizaje\", el objetivo es aprender una función a través de varios tipos de consultas, tales como ¿Cuál es el valor de las funciones en estas entradas? En la obtención de preferencia, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del \"aprendizaje\" y la excitación de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Demostramos que cualquier algoritmo exacto de \"aprendizaje\" con consultas de membresía y equivalencia se puede convertir en un algoritmo de excitación de preferencias con consultas de valor y demanda. El algoritmo de excitación resultante garantiza la excitación en un número polinomio de consultas de valor y demanda. Aquí queremos decir polinomio en el número de bienes, agentes, y los tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Argumentamos que las garantías de complejidad para los esquemas de excitación deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar la comunicación polinómica en el peor de los casos, que normalmente no se puede lograr en el número de productos y agentes por sí solos. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de \"aprendizaje\" para polinomios, DNF monotono y funciones de umbral lineal. Por supuesto, una subasta combinatoria de un solo disparo donde los agentes proporcionan todas sus funciones de valoración a la vez también tendría comunicación polinómica en el tamaño de las valoraciones de los agentes, y sólo requieren una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay ninguna carga para los agentes de formular sus valoraciones en un esquema de codificación de los subastadores que elijan. Esperamos que esta sea una consideración importante en la práctica. Además, con nuestro esquema la revelación entera sólo ocurre en el peor de los casos. 180 Por ahora, dejamos a un lado la cuestión de los incentivos al derivar algoritmos de excitación. Nos centramos en la complejidad del tiempo y la comunicación de la obtención de preferencias, independientemente de las limitaciones de incentivos, y en la relación entre las complejidades del \"aprendizaje\" y la obtención de preferencias. Trabajo relacionado. Zinkevich y otros [19] considerar el problema de \"aprendizaje\" clases restringidas de funciones de valoración que pueden ser representadas utilizando fórmulas de lectura-once y Toolbox DNF. Las fórmulas Read-once pueden representar ciertas sustitutibilidades, pero no complementariedades, mientras que lo contrario se mantiene para Toolbox DNF. Dado que su trabajo también se basa en la teoría del \"aprendizaje\", permiten depender del tamaño de la valoración objetivo como lo hacemos nosotros (aunque las valoraciones de read-once siempre se pueden representar sucintamente de todos modos). Su trabajo sólo hace uso de consultas de valor, que son bastante limitados en el poder. Debido a que nos permitimos pedir consultas, somos capaces de derivar un esquema de excitación para las funciones de valoración general. Blum et al. [5] proporcionar resultados relacionados con las complejidades de la consulta \"aprendizaje\" y la excitación de preferencias. Consideran modelos con consultas de membresía y equivalencia en la consulta \"aprendizaje\", y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones se pueden aprender eficientemente, pero no se pueden obtener eficientemente, y viceversa. En contraste, nuestro trabajo muestra que dada una versión más general (todavía bastante estándar) de la consulta de demanda que el tipo que consideran, la complejidad de la excitación de preferencia no es mayor que la complejidad del \"aprendizaje\". Demostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre valoraciones para implicar una solución al problema de excitación. Nisan y Segal [12] estudian la complejidad comunicativa de la excitación de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos de la computación una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo se permite a los algoritmos hacer preguntas sobre valoraciones de agentes y recibir respuestas honestas, sin ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del \"aprendizaje\". Nuestro trabajo también aborda la cuestión de la complejidad de la comunicación, y somos capaces de derivar algoritmos que proporcionan garantías de comunicación significativas a pesar de los resultados negativos de Nisan y Segals. Su trabajo motiva la necesidad de confiar en el tamaño de los agentes funciones de valoración para indicar los peores resultados. 2. LOS MODELOS 2.1 Aprendizaje de la consulta El modelo de \"aprendizaje\" de consulta que consideramos aquí se llama \"aprendizaje\" exacto de las consultas de membresía y equivalencia, introducido por Angluin [2]. En este modelo el objetivo de los algoritmos de \"aprendizaje\" es identificar exactamente una función de destino desconocida f : X → Y a través de consultas a un oráculo. La función de destino se extrae de una función de clase C que es conocida por el algoritmo. Típicamente el dominio X es algún subconjunto de {0, 1}m, y el rango Y es {0, 1} o algún subconjunto de los números reales. A medida que el algoritmo avanza, construye una hipótesis manifiesta?f que es su estimación actual de la función de destino. Después de la terminación, la hipótesis manifiesta de un algoritmo correcto de \"aprendizaje\" satisface?f(x) = f(x) para todos x?X. Es importante especificar la representación que se utilizará para codificar funciones de C. Por ejemplo, considere la siguiente función de {0, 1}m a ♥: f(x) = 2 si x consiste en m 1s, y f(x) = 0 de otra manera. Esta función puede representarse simplemente como una lista de valores de 2m. O puede codificarse como el polinomio 2x1 · · · xm, que es mucho más sucinto. Así pues, la elección de la codificación puede tener un impacto significativo en los requisitos de tiempo y espacio del algoritmo de \"aprendizaje\". Let size(f) ser el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes distintos de cero en el polinomio, por ejemplo. Por lo general, sólo nos referiremos a las clases de representación; las clases de funciones correspondientes serán implícitas. Por ejemplo, la clase de representación de fórmulas DNF monotonas implica la clase de función de funciones booleanas monotonas. Dos tipos de consultas se utilizan comúnmente para \"aprendizaje\" exacto: consultas de membresía y equivalencia. En una consulta de membresía, el aprendiz presenta algunas x x x y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta f. El oráculo responde SÍ si?f = f, o devuelve un contraejemplo x de tal manera que?f(x) = f(x). Una consulta de equivalencia es apropiada si el tamaño( ̃f) ≤ tamaño(f) en el momento de presentar la hipótesis manifiesta. Estamos interesados en algoritmos eficientes de \"aprendizaje\". Las siguientes definiciones se adaptan a partir de Kearns y Vazirani [9]: Definición 1. La clase de representación C es polinomialquery exactamente aprendeble de las consultas de membresía y equivalencia si hay un polinomial fijo p(·, ·) y un algoritmo L con acceso a la membresía y consultas de equivalencia de un oráculo tal que para cualquier función de destino f • C, L salidas después de a lo sumo p(size(f), m) consultas de una función?f • C tal que?f Del mismo modo, la clase de representación C se puede aprender exactamente de las consultas de membresía y equivalencia si el algoritmo L produce una hipótesis correcta en el tiempo p(size(f), m), para algunos polinomios fijos p(·, ·). Aquí m es la dimensión del dominio. Dado que la función de destino debe ser reconstruida, también permitimos necesariamente la dependencia polinómica del tamaño (f). 2.2 Eliminación de preferencias En una subasta combinatoria, un conjunto de bienes M se asignará entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Tal asignación se llama eficiente en la literatura de economía, pero nos referiremos a ella como óptima y reservar el término eficiente para referirse a la eficiencia computacional. Dejamos n = N y m = M. Una asignación es una partición de los objetos en paquetes (S1,. . . , Sn), de tal manera que Si â € ¬ Sj = â € para todos los i, j â € N. Let â € € sea el conjunto de posibles asignaciones. Cada agente i+N tiene una función de valoración vi : 2M → • sobre el espacio de los paquetes posibles. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no tienen que coincidir. Asumimos que todas las valoraciones consideradas están normalizadas, es decir, v() = 0, y que no hay externalidades, es decir, vi(S1,..., Sn) = vi(Si), para todos los agentes i  N, para cualquier asignación (S1,..., Sn)  (es decir, un agente se preocupa sólo por el paquete asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales.1 Nosotros 1 A menudo las valoraciones generales se hacen para satisfacer los 181 adicionales también asumen que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que los agentes utilidades pueden ser divididos en componentes monetarios y no monetarios. Si a un agente i se le asigna el paquete S al precio p, deriva utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más sucintas para ciertas clases de valoración, y ha habido mucha investigación en lenguajes de licitación concisos para diversos tipos de valoraciones [11]. Un ejemplo clásico al que nos referiremos más adelante es el lenguaje de licitación XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, que consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estas pujas, se busca el paquete S del valor más alto listado en las pujas atómicas de tal manera que S  S. Es entonces el caso que v(S) = v(S). Como en el contexto de la teoría del \"aprendizaje\", por lo general sólo nos referiremos a idiomas de oferta en lugar de clases de valoración, ya que las clases de valoración correspondientes serán implícitas. Por ejemplo, el lenguaje de licitación XOR implica la clase de valoraciones que satisfacen la disposición libre, que es la condición de que A  B ♥ v(A) ≤ v(B). Dejamos el tamaño(v1,. . . , vn) = Èn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de licitación). Para hacer una analogía con la teoría del \"aprendizaje\" computacional, suponemos que todas las clases de representación consideradas son polinomialmente interpretables [11], lo que significa que el valor de un paquete puede ser calculado en tiempo polinomio dada la representación de funciones de valoración. Más formalmente, una clase de representación (lenguaje de licitación) C es polinomialmente interpretable si existe un algoritmo que da como entrada algunos v • C y una instancia x • X calcula el valor v(x) en el tiempo q(size(v), m), para algún polinomio fijo q(·, ·).2 En las rondas intermedias de una subasta (terativa), el subastador habrá obtenido información sobre las funciones de Por lo tanto, habrá construido un conjunto de valoraciones manifiestas, denotadas . . Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha adquirido información sobre ciertos paquetes. El objetivo en el problema de la excitación de preferencia es construir un conjunto de valoraciones manifiestas tales que: arg max (S1,...,Sn) iÃ3n Ã3vi(Si)  arg max (S1,...,Sn) iÃ3n vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que es óptima con respecto a las valoraciones verdaderas. Tenga en cuenta que sólo se requiere una asignación óptima. condición de la libre eliminación (monotonicidad), pero no la necesitamos en este punto. 2 Esto excluye OR*, asumiendo P = NP, porque interpretar las ofertas de este lenguaje es NP-duro por reducción de set-embalaje ponderado, y no hay clase de representación bien estudiada en la teoría del \"aprendizaje\" que es claramente análogo a OR*. 3 Esta visión de las subastas iterativas tiene por objeto paralelizar la configuración de \"aprendizaje\". En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente están implícitas por la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son consultas de valor y demanda. En una consulta de valor, el subastador presenta un paquete S  M y el agente responde con su valor (exacto) para el paquete v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p • • • (2m ) sobre los paquetes junto con un paquete S. El agente responde SI si es el caso de que S • arg max S M v(S ) − p(S ) ¡ o de otro modo presenta un paquete S tal que v(S ) − p(S ) > v( Tenga en cuenta también que comunicar precios no lineales no implica necesariamente citar un precio por cada paquete posible. Puede haber formas más sucintas de comunicar este vector, como se muestra en la sección 5. Hacemos las siguientes definiciones para paralelizar la configuración de la consulta \"aprendizaje\" y para simplificar las declaraciones de resultados posteriores: Definición 2. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si hay un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes tales que para cualquier (v1,. . . , vn) V1 ×. . . × Vn, L salidas después de como máximo p(size(v1,. . . , vn), m) consulta una asignación (S1,. . . , Sn) arg max(S1,...,Sn) È vi(Si). Del mismo modo, la clase de representación C se puede obtener eficientemente de las consultas de valor y demanda si el algoritmo L produce una asignación óptima con comunicación p(size(v1, ). . . , vn), m), para algunos polinomios fijos p(·, ·). Hay algunas diferencias clave aquí con la definición de \"aprendizaje\". Hemos eliminado el término exactamente ya que las funciones de valoración no necesitan ser determinadas exactamente con el fin de calcular una asignación óptima. Además, un algoritmo de excitación eficiente es la comunicación polinomio, en lugar de tiempo polinomio. Esto refleja el hecho de que la comunicación en lugar del tiempo de espera es el cuello de botella en la excitación. Cálculo de una asignación óptima de bienes incluso cuando se dan las valoraciones verdaderas es NP-duro para una amplia gama de clases de valoración. Por lo tanto, no es razonable exigir tiempo polinomio en la definición de un algoritmo de excitación de preferencias eficiente. Nos complace centrarnos en la complejidad comunicativa de la excitación porque se cree que este problema es más significativo en la práctica que el de la determinación del ganador [11].5 4 Esto difiere ligeramente de la definición proporcionada por Blum et al. [5] Sus consultas sobre la demanda se limitan a precios lineales sobre las mercancías, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir. un precio distinto por cada paquete posible. Es por eso que el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. 5 Aunque el problema de determinación del ganador es NP-hard para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta aproximaciones usando solucionadores IP fuera de la plataforma [1]. 182 Dado que no es necesario obtener exactamente las valoraciones, es inicialmente menos claro si la dependencia polinómica del tamaño (v1, ). . . , vn) está justificado en este contexto. Intuitivamente, este parámetro está justificado porque debemos aprender valoraciones exactamente cuando se realiza la excitación, en el peor de los casos. Nos ocupamos de esto en la siguiente sección. 3. PARAALLELSBETWEEN EQUIVALENCIA Y QUERIDAS DE DEMANDA Hemos descrito la consulta \"aprendizaje\" y los ajustes de excitación de preferencias de una manera que destaca sus similitudes. Las consultas de valor y membresía son claras analógicas. Un poco menos obvio es el hecho de que las consultas de equivalencia y demanda también son analógicas. Para ver esto, necesitamos el concepto de precios Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios sobre sus bienes subyacentes. Son no anónimos en el sentido de que dos agentes pueden tener que hacer frente a precios diferentes para el mismo paquete de mercancías. Así los precios de Lindahl son de la forma pi(S), para todos S  M, para todos los precios de i  N. Lindahl se presentan a los agentes en consultas de la demanda. Cuando los agentes han normalizado las funciones de utilidad cuasi-lineal, Bikhchandani y Ostroy [4] muestran que siempre existen precios Lindahl tales que (S1,. . . , Sn) es una asignación óptima si y sólo si Si • arg max Si vi(Si) − pi(Si) • i N (1) (S1,. . . , Sn)  arg max (S1,...,Sn) iN pi(Si) (2) Condición (1) establece que cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos de los subastadores a los precios indicados. El escenario en el que se mantienen estas condiciones se llama equilibrio Lindahl, o a menudo un equilibrio competitivo. Decimos que los precios de Lindahl apoyan la asignación óptima. Por lo tanto, basta con anunciar los precios de apoyo de Lindahl para verificar una asignación óptima. Una vez que hemos encontrado una asignación con el apoyo de precios Lindahl, el problema de excitación se resuelve. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones estén garantizadas como integrales [4]. Las variables duales de este programa lineal están soportando los precios de Lindahl para la asignación resultante. La función objetiva del programa dual es: min pi(S) Por lo general, hay una gama de posibles precios Lindahl que apoyan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios válidos Lindahl, y nos referimos a ellos como precios máximos Lindahl. De todos los vectores posibles de precios Lindahl, precios máximos Lindahl maximizar la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È iÃ3N πi del objetivo (la suma de los agentes de utilidades) son precios mínimos Lindahl. Cualquier Lindahl precios hará para nuestros resultados, pero algunos pueden tener mejores propiedades de excitación que otros. Tenga en cuenta que una consulta de demanda con precios máximos de Lindahl es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para el trabajo futuro la cuestión de los precios de Lindahl para elegir minimizar la obtención de preferencias. Teniendo en cuenta ahora por qué las consultas de demanda y equivalencia son analógicas directas, primero tenga en cuenta que dado el πi en algún equilibrio Lindahl, establecer pi(S) = max{0, Estos precios dejan a cada agente indiferente en todos los paquetes con precio positivo, y satisfacen la condición (1). Así, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl típicamente serán una constante aditivo lejos de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos de consultas de equivalencia a través de consultas de demanda. Lemma 1. Supongamos que un agente responde con un paquete preferido S cuando se propone un paquete S y soporta los precios de Lindahl p(S) (soportando con respecto a la valoración manifiesta de los agentes). A continuación, o bien?v(S) = v(S) o?v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: Φv(S) − p(S) ≥ Desigualdad (6) se mantiene porque el agente de hecho prefiere S a S dados los precios, de acuerdo con su respuesta a la consulta de demanda. Si fuera el caso de que?v(S) = v(S) y Así, al menos uno de S y S es un contraejemplo de la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño(v1,. . . , vn) en problemas de excitación. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que apoyar los precios de Lindahl debe necesariamente revelarse en el curso de cualquier protocolo de obtención de preferencias que termina con una asignación óptima. Además, Nisan y Segal (Lemma 1, [12]) afirman que en el peor de los casos los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones dobles (como será el caso de las clases más interesantes). Puesto que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y puesto que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitiendo la dependencia del tamaño(v1,. . . , vn) en problemas de excitación es totalmente natural. 183 4. DE APRENDIZAR A LA ELICITACIÓN DE PREFERENCIA La clave para convertir un algoritmo de \"aprendizaje\" a un algoritmo de excitación es simular consultas de equivalencia con consultas de demanda y valor hasta que se encuentre una asignación óptima. Debido a nuestra construcción de precios Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en que un agente responde SÍ a una consulta de equivalencia cuando la función de destino se ha aprendido exactamente. De lo contrario, podemos obtener un contraejemplo a una consulta de equivalencia dada una respuesta de agentes a una consulta de demanda. Teorema 1. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si cada uno puede ser polinomio-consulta exactamente aprendido de consultas de membresía y equivalencia. Prueba. Considere el algoritmo de excitación en la Figura 1. Cada consulta de membresía en el paso 1 es simulada con una consulta de valor ya que estas son de hecho idénticas. Considere el paso 4. Si todos los agentes responden SÍ, la condición (1) se mantiene. Condición (2) se mantiene porque la asignación calculada es la maximización de ingresos para el subastador, independientemente de los agentes verdaderas valoraciones. Así pues, se ha encontrado una asignación óptima. De lo contrario, por lo menos uno de Si o Si es un contraejemplo a Vi, por Lemma 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones del agente se conocerán exactamente, en cuyo caso la asignación óptima y los precios Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinomio de consultas, desde A1,. . . , A son todos los algoritmos de \"aprendizaje\" de la demanda polinómica. Tenga en cuenta que el procedimiento de conversión resulta en un algoritmo de excitación de preferencias, no un algoritmo de \"aprendizaje\". Es decir, el algoritmo resultante no simplemente aprender las valoraciones exactamente, a continuación, calcular una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor, y periódicamente comprueba si se ha reunido suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio Lindahl para las valoraciones v1,. . . , vn utilizando una asignación y precios derivados de valoraciones manifiestas . . y encontrar una asignación óptima no implica que las valoraciones de los agentes se hayan aprendido exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta interrupción temprana. No obtendremos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE COMUNICACIÓN En esta sección, pasamos a la cuestión de la complejidad comunicativa de la excitación. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (tales como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos de determinar los precios de Lindahl es exponencial en el número de mercancías, m. La carga de comunicación se mide en términos del número de bits transmitidos entre agentes y subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. Convertir algoritmos eficientes de \"aprendizaje\" a un algoritmo de excitación produce un algoritmo cuyas consultas tienen tamaños polinomios en los parámetros m y tamaño (v1, ). . . , vn). Teorema 2. Las clases de representación V1,. . . , Vn se puede obtener de forma eficiente de las consultas de valor y demanda si cada uno puede ser aprendido exactamente de las consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, basta con comunicar la función de valoración manifiesta de los agentes y el valor Nótese que un algoritmo eficiente de \"aprendizaje\" nunca construye una hipótesis manifiesta de tamaño superpolinomio, porque el tiempo de ejecución de los algoritmos sería entonces también superpolinomio, contradiciendo la eficiencia. Por lo tanto, la comunicación de la valoración manifiesta requiere tamaño a lo sumo p(size(vi), m), para algunos polinomios p que limita superiormente el tiempo de ejecución del algoritmo de \"aprendizaje\" eficiente. Representando el excedente πi al agente no se puede requerir espacio mayor que q(size( También debemos comunicarnos con su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es como máximo p(size(vi), m) + q(p(size(vi), m), m)+O(m). Claramente, una respuesta de agentes a una consulta de valor o demanda tiene un tamaño máximo de q(size(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, son siempre de tamaño polinomio. Un algoritmo de \"aprendizaje\" eficiente realiza un número polinomio de consultas, por lo que la comunicación total del algoritmo de excitación resultante es polinomio en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de \"aprendizaje\", con constantes que no están enmascaradas por la notación big-O. Estos límites pueden ser traducidos a límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de excitación resultante. Con el tiempo de ejecución del algoritmo \"aprendizaje\" en el Teorema 2 se determinó el tamaño de la hipótesis manifiesta. Es probable que podamos hacerlo mucho mejor que esto en la práctica. Recuerde que una consulta de equivalencia es apropiada si size( ̃f) ≤ size(f) en el momento de realizar la consulta. Si las consultas de equivalencia de algoritmos de \"aprendizaje\" son todas adecuadas, entonces también puede ser posible proporcionar límites estrechos en los requisitos de comunicación del algoritmo de excitación resultante. El teorema 2 muestra que los algoritmos de excitación que dependen del tamaño (v1,. . . El parámetro, vn) evita los resultados negativos de Nisan y Segals [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto al tamaño de las instancias de las funciones de valoración que se enfrentan a cualquier ejecución del algoritmo. Estos algoritmos van bien si la clase de representación elegida proporciona representaciones sucintas para la más simple y común de las valoraciones, y por lo tanto el enfoque se mueve de nuevo a uno de lenguajes de licitación compactos pero expresivos. A continuación se examinan estas cuestiones. 6. APLICACIONES En esta sección, demostramos la aplicación de nuestros métodos a clases particulares de representación para valoraciones combinatorias. Hemos demostrado que el problema de excitación de preferencias para las clases de valoración V1,. . . , Vn se puede reducir 184 Dado: algoritmos exactos de \"aprendizaje\" A1,. . . , Una para las valoraciones de las clases V1,. . . , Vn respectivamente. Encaje hasta que haya una señal para detenerse: 1. Corre A1,. . . , Un en paralelo sobre sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se ha detenido con los agentes valoración exacta. 2. Calcular una asignación óptima (S1,. . . , Sn ) y los correspondientes precios de Lindahl con respecto a las valoraciones manifiestas . . , їvn determinado hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de consulta de demanda. 4. Si todos ellos responden SÍ, salida la asignación y parada. De lo contrario hay algún agente i que ha respondido con algún paquete preferido Si. Realizar consultas de valor en Si y Si para encontrar un contraejemplo a ‡vi, y proporcionarlo a Ai. Figura 1: Convertir algoritmos de \"aprendizaje\" a un algoritmo de excitación. al problema de encontrar un algoritmo de \"aprendizaje\" eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de \"aprendizaje\" para una gran cantidad de clases de funciones, y porque a menudo puede ser más simple resolver cada subproblema de \"aprendizaje\" por separado que atacar el problema de excitación de preferencias directamente. Podemos desarrollar un algoritmo de excitación que se adapta a cada valoración de agentes, con los algoritmos de \"aprendizaje\" subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Demostramos que los algoritmos de \"aprendizaje\" existentes para polinomios, fórmulas de DNF monotono y funciones de umbral lineal pueden convertirse en algoritmos de excitación de preferencia para valoraciones generales, valoraciones con eliminación libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en las representaciones que son polinomialmente interpretables, porque la literatura de la teoría del \"aprendizaje\" computacional pone un énfasis pesado en la traqueabilidad computacional [18]. Al interpretar los métodos enfatizamos la expresividad y sucinta de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de licitación, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debe representar sucintamente las funciones más simples y comunes de la clase. 6.1 Representaciones polinómicas Schapire y Sellie [17] dan un algoritmo de \"aprendizaje\" para polinomios multivariables escasos que pueden ser utilizados como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas apropiadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados de t-sparse sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-sparse tiene como máximo t términos, donde un término es un producto de variables, por ejemplo. x1x3x4. Un polinomio sobre los números reales tiene coeficientes extraídos de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M →  se puede escribir exclusivamente como un polinomio [17]. Para tener una idea de la sucintaidad de los polinomios como lenguaje de licitación, considere las valoraciones aditivas y mono-ítem presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es el número de mercancías que contiene el paquete. En la valoración de un solo elemento, todos los paquetes tienen valor 1, excepto el valor 0 (i.e. el agente está satisfecho tan pronto como ha adquirido un único artículo). No es difícil demostrar que la valoración de un solo elemento requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Por lo tanto, los polinomios son adecuados para valoraciones que en su mayoría son aditivas, con algunas sustituibilidades y complementariedades que pueden introducirse ajustando los coeficientes. El algoritmo de \"aprendizaje\" para polinomios hace como máximo consultas de equivalencia mti +2 y como máximo (mti +1) (t2 i +3ti)/2 consultas de membresía a un agente i, donde ti es la esparcidad del polinomio que representa vi [17]. Por lo tanto, se obtiene un algoritmo que provoca valoraciones generales con un número polinomio de consultas y comunicación polinomio.6 6.2 XOR Representaciones El lenguaje de licitación XOR es estándar en la literatura de subastas combinatoria. Recordemos que una oferta XOR se caracteriza por un conjunto de paquetes B  2M y una función de valor w : B →  definida en esos paquetes, que induce la función de valoración: v(B) = max {B  B  B  B} w(B) (7) Las ofertas XOR pueden representar valoraciones que satisfacen la libre eliminación (y sólo tales valoraciones), que de nuevo es la propiedad que A  B El lenguaje de licitación XOR es ligeramente menos expresivo que los polinomios, porque los polinomios pueden representar valoraciones que no satisfacen la libre eliminación. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas de XOR pueden representar la valoración de un solo elemento con ofertas atómicas m, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario se aplica a los polinomios, estas dos lenguas son incomparables en sucintas y algo complementarias para su uso práctico. Blum et al. [5] note que las fórmulas DNF monotonas son los análogos de las ofertas XOR en la literatura teórica del \"aprendizaje\". Una fórmula de DNF monotona es una disyunción de conjunciones en las que las variables aparecen sin negación, por ejemplo x1x2 x3 x2x4x5. Tenga en cuenta que tales fórmulas pueden ser representadas como ofertas XOR donde cada oferta atómica tiene valor 1; por lo tanto XOR ofrece generalizar fórmulas DNF monotono de Boolean a funciones de valor real. Estas ideas nos permiten generalizar un algoritmo clásico de \"aprendizaje\" para el DNF monotono ([3] Teorema 6 Tenga en cuenta que el Teorema 1 se aplica incluso si las valoraciones no satisfacen la eliminación libre. 185 1, [18] Teorema B) a un algoritmo de \"aprendizaje\" para ofertas XOR.7 Lemma 2. Una oferta XOR que contiene ofertas t atómicas se puede aprender exactamente con consultas de equivalencia t + 1 y a lo sumo consultas de membresía tm. Prueba. El algoritmo identificará cada puja atómica en la puja XOR objetivo a su vez. Initialice la valoración manifiesta v a la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presente ‡v como consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un paquete S para el que v(S) = Crear un paquete T de la siguiente manera. Primero inicialice T = S. Para cada elemento i en T, compruebe a través de una consulta de membresía si v(T) = v(T − {i}). Si así se establece T = T − {i}. De lo contrario, deje T como está y pase al siguiente punto. Afirmamos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada ítem i en T, tenemos v(T) = v(T − {i}). Para ver esto, tenga en cuenta que en algún momento al generar T, tuvimos un ̄T tal que T  ̄T  S y v( ̄T) > v( ̄T − {i}), de modo que me mantuvo en ̄T. Tenga en cuenta que v(S) = v( ̄T) = v(T) porque el valor del paquete S se mantiene durante todo el proceso de eliminación de elementos. Ahora asume v(T) = v(T − {i}). Entonces v( ̄T) = v(T) = v(T − {i}) > v( ̄T − {i}) que contradice la libre eliminación, ya que T {i}  ̄T − {i}. Por lo tanto v(T) > v(T − {i}) para todos los ítems i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si este no fuera el caso, T tomaría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = máx itat {max T T Ahora mostramos que v(T) = ̃v(T), que implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Asumir que toda oferta atómica (R, Esta suposición se mantiene vagamente cuando se inicializa la valoración manifiesta. Usando la notación de (7), dejar ( Tenemos B  B, y Bw(B) = w(B) para B Por lo tanto,?v(S) = max {B} {B} {B} {B} {B} {B} = max {B} {B} {B} ≤ {B} {B} {B} {B} {S} w(B} = v(S) (8) Ahora asume v(T) {v(T La segunda igualdad se deriva del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad sostiene porque S es un contraejemplo de la valoración manifiesta. De la ecuación (9) y la eliminación libre, nosotros 7 El algoritmo citado también se utilizó como base para Zinkevich et al.s [19] algoritmo de excitación para Toolbox DNF. Recuerde que Toolbox DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia se puede simular con una consulta de valor en el paquete que contiene todas las mercancías. que tengan ‡v(T) < Entonces de nuevo de la ecuación (9) se deduce que v(S) < Esto contradice (8), por lo que de hecho tenemos v(T) = Por lo tanto (T, v(T)) no está actualmente en nuestra hipótesis como una oferta atómica, o tendríamos correctamente?v(T) = v(T) por la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas adicionales de equivalencia hasta que todas las ofertas atómicas hayan sido identificadas. Después de cada consulta de equivalencia, una oferta atómica se identifica con como máximo m consultas de membresía. Cada contraejemplo conduce al descubrimiento de una nueva oferta atómica. Por lo tanto, hacemos a lo sumo consultas de membresía tm y exactamente consultas de equivalencia t + 1. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR se puede obtener eficientemente de las consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al.s ([5], Teorema 2) afirmando que el DNF monotono (y por lo tanto las ofertas XOR) no se pueden obtener de manera eficiente cuando las consultas de demanda se limitan a precios lineales y anónimos sobre las mercancías. 6.3 Las representaciones lineales de umbral polinomios, las ofertas XOR y todas las lenguas basadas en el lenguaje de licitación OR (como XOR-de-OR, OR-de-XOR y OR*) no representan sucintamente la valoración mayoritaria [11]. En esta valoración, los paquetes tienen valor 1 si contienen al menos m/2 ítems, y valor 0 de lo contrario. Más generalmente, considere la familia de r-of-S de valoraciones donde los paquetes tienen valor 1 si contienen al menos r artículos de un conjunto especificado de ítems S  M, y valor 0 de otra manera. La valoración mayoritaria es un caso especial de la valoración de r-of-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar las sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede añadir valor. Dejando k = S, tales valoraciones están sucintamente representadas por funciones de umbral r-of-k. Estas funciones adoptan la forma de desigualdades lineales: xi1 +. . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se mantiene, y 0 de lo contrario. Aquí i1,. . . , ik son los elementos en S. Littlestones WINNOW 2 algoritmo puede aprender tales funciones utilizando consultas de equivalencia sólo, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de excitación que resulta de WINNOW 2 sólo utiliza consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos están implícitos cuando sólo hay dos valores posibles). Tenga en cuenta que las funciones de umbral r-of-k siempre se pueden representar sucintamente en el espacio O(m). Así se obtiene un algoritmo que puede generar tales funciones con un número polinomio de consultas y comunicación polinomio, en los parámetros n y m solos. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos exactos de \"aprendizaje\" con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de excitación de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas en el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la riqueza de algoritmos de \"aprendizaje\" disponibles al problema de la excitación de preferencias. Un enfoque de \"aprendizaje\" para la excitación también motiva un enfoque diferente para diseñar algoritmos de excitación que se descomponen cuidadosamente entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (en su mayoría aditivos, muchos sustitutos, etc.), puede diseñar algoritmos de \"aprendizaje\" adaptados a las valoraciones de cada agente e integrarlos en un esquema de excitación. El algoritmo de excitación resultante hace un número polinomio de consultas, y hace comunicación polinomio si los algoritmos originales de \"aprendizaje\" son eficientes. No exigimos que las valoraciones de agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia sólo pueden ser, y sólo necesitan ser, simuladas hasta el punto en que se ha calculado una asignación óptima. Este es el problema de la excitación de preferencias. Teorema 1 implica que la excitación con consultas de valor y demanda no es más difícil que \"aprendizaje\" con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de algoritmos de \"aprendizaje\". Sería interesante encontrar ejemplos de clases de valoración para las que la excitación es más fácil que el \"aprendizaje\". Blum et al. [5] proporcionar tal ejemplo al considerar solamente consultas de membresía/valor (Teorema 4). En el trabajo futuro planeamos abordar el tema de los incentivos al convertir algoritmos de \"aprendizaje\" a algoritmos de excitación. En el contexto del \"aprendizaje\", generalmente asumimos que los oráculos proporcionarán respuestas honestas a las preguntas; en el contexto de la excitación, los agentes son generalmente egoístas y proporcionarán respuestas posiblemente deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para los polinomios de \"aprendizaje\" y las ofertas de XOR como algoritmos de excitación, y probar su rendimiento contra otros protocolos de subasta combinatoria establecidos [6, 15]. Una pregunta interesante aquí es: ¿qué precios Lindahl en el rango máximo a mínimo son los mejores para citar con el fin de minimizar la revelación de información? Suponemos que la revelación de información se reduce al pasar de precios máximos a precios mínimos de Lindahl, es decir, a medida que desplazamos las consultas de demanda más lejos de las consultas de equivalencia. Por último, sería útil determinar si el lenguaje de licitación de OR* [11] puede aprenderse (y, por lo tanto, obtenerse) de manera eficiente, dada la expresividad y sucinta de estas lenguas para una amplia variedad de clases de valoración. Agradecimientos Queremos agradecer a Debasis Mishra por sus útiles discusiones. Este trabajo está apoyado en parte por la subvención de NSF IIS0238147. 8. REFERENCIAS [1] A. Andersson, M. Tenhunen, y F. Ygge. Programación integral para la determinación del ganador de la subasta combinatoria. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprender conjuntos regulares de consultas y contraejemplos. Información e computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y concepto \"aprendizaje\". Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El modelo de asignación de paquetes. Diario de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Evocación de preferencia y consulta \"aprendizaje\". En Proc. 16a Conferencia Anual sobre Teoría del Aprendizaje Computacional (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. la 18a Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, e Y. Shoham. Domar la complejidad computacional de las subastas combinatoria: Enfoques óptimos y aproximados. En Proc. , 16a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), págs. 548 a 553, 1999. [8] B. Hudson y T. Sandholm. Uso de consultas de valor en subastas combinatoria. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría del aprendizaje computacional. MIT Press, 1994. [10] N. Littlestone. Aprender rápidamente cuando los atributos irrelevantes abundan: Un nuevo algoritmo de umbral lineal. Machine Learning, 2:285-318, 1988. [11] N. Nisan. Licitación y asignación en subastas combinatoria. En Proc. la Conferencia de la ACM sobre Comercio Electrónico, págs. 1 a 12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y el apoyo a los precios Lindahl. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de mínima revelación. En Padget et al., editor, Agent-Mediated Electronic Commerce IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. Diseño de subastas con costosas preferencias. En Temas Especiales de Anales de Matemáticas y AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17a Conferencia Nacional sobre Inteligencia Artificial (AAAI-00), págs. 74 a 81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. la 17a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariables escasos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de ACM sobre Teoría del Aprendizaje Computacional, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendido. Comun. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum, y T. Sandholm. Sobre la excitación de la preferencia polinomio-tiempo con las consultas de valor. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "error": [
                ""
            ]
        },
        "learning theory": {
            "translated_key": [
                "teoría de aprendizaje",
                "teoría del aprendizaje",
                "teoría del aprendizaje",
                "teoría del aprendizaje",
                "teoría de aprendizaje",
                "teoría de aprendizaje",
                "teoría de aprendizaje",
                "teoría del aprendizaje",
                "teoría del aprendizaje"
            ],
            "translated_annotated_text": "Aplicando algoritmos de aprendizaje a la eliminación de preferencia Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de excitación Demostramos que los algoritmos de aprendizaje pueden ser usados como base para algoritmos de excitación de preferencias. Los algoritmos de excitación resultantes realizan un número polinomio de consultas. También damos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. En particular, se obtiene un algoritmo que provoca pujas XOR con comunicación polinómica. Categorías y Descriptores sujetos F.2.0 [Análisis de algoritmos y complejidad de problemas]: General; J.4 [Ciencias Sociales y Conductuales]: Economía; I.2.6 [Inteligencia Artificial]: Términos generales de aprendizaje Algoritmos, Economía, Teoría 1. INTRODUCCIÓN En una subasta combinatoria, los agentes pueden pujar por paquetes de bienes en lugar de por cada uno de ellos. Puesto que hay un número exponencial de paquetes (en el número de bienes), comunicar los valores sobre estos paquetes puede ser problemático. Comunicar las valoraciones de una sola vez puede ser prohibitivamente costoso si el número de bienes es sólo moderadamente grande. Además, incluso podría ser difícil para los agentes determinar sus valoraciones para paquetes únicos [14]. A esos agentes les interesa disponer de protocolos de subasta que les obliguen a pujar en el menor número posible de paquetes. Incluso si los agentes pueden calcular eficientemente sus valoraciones, podrían ser reacios a revelarlas enteramente en el curso de una subasta, porque tal información puede ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información necesaria para determinar una asignación óptima de los bienes. Ha habido un trabajo reciente explorando los vínculos entre el problema de la excitación de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la \"teoría de aprendizaje\" computacional [5, 19]. En la \"teoría del aprendizaje\", el objetivo es aprender una función a través de varios tipos de consultas, tales como ¿Cuál es el valor de las funciones en estas entradas? En la obtención de preferencia, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Demostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia se puede convertir en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de excitación resultante garantiza la excitación en un número polinomio de consultas de valor y demanda. Aquí queremos decir polinomio en el número de bienes, agentes, y los tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Argumentamos que las garantías de complejidad para los esquemas de excitación deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar la comunicación polinómica en el peor de los casos, que normalmente no se puede lograr en el número de productos y agentes por sí solos. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. Por supuesto, una subasta combinatoria de un solo disparo donde los agentes proporcionan todas sus funciones de valoración a la vez también tendría comunicación polinómica en el tamaño de las valoraciones de los agentes, y sólo requieren una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay ninguna carga para los agentes de formular sus valoraciones en un esquema de codificación de los subastadores que elijan. Esperamos que esta sea una consideración importante en la práctica. Además, con nuestro esquema la revelación entera sólo ocurre en el peor de los casos. 180 Por ahora, dejamos a un lado la cuestión de los incentivos al derivar algoritmos de excitación. Nos centramos en el tiempo y la complejidad de la comunicación de la obtención de preferencias, independientemente de las limitaciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich y otros [19] considerar el problema del aprendizaje de clases restringidas de funciones de valoración que se pueden representar utilizando fórmulas de lectura once y Toolbox DNF. Las fórmulas Read-once pueden representar ciertas sustitutibilidades, pero no complementariedades, mientras que lo contrario se mantiene para Toolbox DNF. Dado que su trabajo también se basa en la \"teoría del aprendizaje\", permiten depender del tamaño de la valoración objetivo como lo hacemos (aunque las valoraciones de read-once siempre se pueden representar sucintamente de todos modos). Su trabajo sólo hace uso de consultas de valor, que son bastante limitados en el poder. Debido a que nos permitimos pedir consultas, somos capaces de derivar un esquema de excitación para las funciones de valoración general. Blum et al. [5] proporcionar resultados relacionados con las complejidades del aprendizaje de la consulta y la excitación de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje de consultas, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones se pueden aprender eficientemente, pero no se pueden obtener eficientemente, y viceversa. En contraste, nuestro trabajo muestra que dada una versión más general (todavía bastante estándar) de la consulta de demanda que el tipo que consideran, la complejidad de la excitación de preferencia no es mayor que la complejidad del aprendizaje. Demostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre valoraciones para implicar una solución al problema de excitación. Nisan y Segal [12] estudian la complejidad comunicativa de la excitación de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos de la computación una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo se permite a los algoritmos hacer preguntas sobre valoraciones de agentes y recibir respuestas honestas, sin ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es, de hecho, el marco básico de la \"teoría del aprendizaje\". Nuestro trabajo también aborda la cuestión de la complejidad de la comunicación, y somos capaces de derivar algoritmos que proporcionan garantías de comunicación significativas a pesar de los resultados negativos de Nisan y Segals. Su trabajo motiva la necesidad de confiar en el tamaño de los agentes funciones de valoración para indicar los peores resultados. 2. LOS MODELOS 2.1 Aprendizaje de la consulta El modelo de aprendizaje de la consulta que consideramos aquí se llama aprendizaje exacto de la membresía y consultas de equivalencia, introducido por Angluin [2]. En este modelo el objetivo de los algoritmos de aprendizaje es identificar exactamente una función diana desconocida f : X → Y a través de consultas a un oráculo. La función de destino se extrae de una función de clase C que es conocida por el algoritmo. Típicamente el dominio X es algún subconjunto de {0, 1}m, y el rango Y es {0, 1} o algún subconjunto de los números reales. A medida que el algoritmo avanza, construye una hipótesis manifiesta?f que es su estimación actual de la función de destino. Después de la terminación, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface?f(x) = f(x) para todos x?X. Es importante especificar la representación que se utilizará para codificar funciones de C. Por ejemplo, considere la siguiente función de {0, 1}m a ♥: f(x) = 2 si x consiste en m 1s, y f(x) = 0 de otra manera. Esta función puede representarse simplemente como una lista de valores de 2m. O puede codificarse como el polinomio 2x1 · · · xm, que es mucho más sucinto. Así pues, la elección de la codificación puede tener un impacto significativo en las necesidades de tiempo y espacio del algoritmo de aprendizaje. Let size(f) ser el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes distintos de cero en el polinomio, por ejemplo. Por lo general, sólo nos referiremos a las clases de representación; las clases de funciones correspondientes serán implícitas. Por ejemplo, la clase de representación de fórmulas DNF monotonas implica la clase de función de funciones booleanas monotonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: la membresía y las consultas de equivalencia. En una consulta de membresía, el aprendiz presenta algunas x x x y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta f. El oráculo responde SÍ si?f = f, o devuelve un contraejemplo x de tal manera que?f(x) = f(x). Una consulta de equivalencia es apropiada si el tamaño( ̃f) ≤ tamaño(f) en el momento de presentar la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones se adaptan a partir de Kearns y Vazirani [9]: Definición 1. La clase de representación C es polinomialquery exactamente aprendeble de las consultas de membresía y equivalencia si hay un polinomial fijo p(·, ·) y un algoritmo L con acceso a la membresía y consultas de equivalencia de un oráculo tal que para cualquier función de destino f • C, L salidas después de a lo sumo p(size(f), m) consultas de una función?f • C tal que?f Del mismo modo, la clase de representación C se puede aprender exactamente de las consultas de membresía y equivalencia si el algoritmo L produce una hipótesis correcta en el tiempo p(size(f), m), para algunos polinomios fijos p(·, ·). Aquí m es la dimensión del dominio. Dado que la función de destino debe ser reconstruida, también permitimos necesariamente la dependencia polinómica del tamaño (f). 2.2 Eliminación de preferencias En una subasta combinatoria, un conjunto de bienes M se asignará entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Tal asignación se llama eficiente en la literatura de economía, pero nos referiremos a ella como óptima y reservar el término eficiente para referirse a la eficiencia computacional. Dejamos n = N y m = M. Una asignación es una partición de los objetos en paquetes (S1,. . . , Sn), de tal manera que Si â € ¬ Sj = â € para todos los i, j â € N. Let â € € sea el conjunto de posibles asignaciones. Cada agente i+N tiene una función de valoración vi : 2M → • sobre el espacio de los paquetes posibles. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no tienen que coincidir. Asumimos que todas las valoraciones consideradas están normalizadas, es decir, v() = 0, y que no hay externalidades, es decir, vi(S1,..., Sn) = vi(Si), para todos los agentes i  N, para cualquier asignación (S1,..., Sn)  (es decir, un agente se preocupa sólo por el paquete asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales.1 Nosotros 1 A menudo las valoraciones generales se hacen para satisfacer los 181 adicionales también asumen que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que los agentes utilidades pueden ser divididos en componentes monetarios y no monetarios. Si a un agente i se le asigna el paquete S al precio p, deriva utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más sucintas para ciertas clases de valoración, y ha habido mucha investigación en lenguajes de licitación concisos para diversos tipos de valoraciones [11]. Un ejemplo clásico al que nos referiremos más adelante es el lenguaje de licitación XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, que consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estas pujas, se busca el paquete S del valor más alto listado en las pujas atómicas de tal manera que S  S. Es entonces el caso que v(S) = v(S). Al igual que en el contexto de la \"teoría de aprendizaje\", por lo general sólo nos referiremos a idiomas de oferta en lugar de clases de valoración, ya que las clases de valoración correspondientes serán implícitas. Por ejemplo, el lenguaje de licitación XOR implica la clase de valoraciones que satisfacen la disposición libre, que es la condición de que A  B ♥ v(A) ≤ v(B). Dejamos el tamaño(v1,. . . , vn) = Èn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de licitación). Para hacer una analogía con la \"teoría de aprendizaje\" computacional, suponemos que todas las clases de representación consideradas son polinomiamente interpretables [11], lo que significa que el valor de un paquete puede ser calculado en tiempo polinomio dada la representación de funciones de valoración. Más formalmente, una clase de representación (lenguaje de licitación) C es polinomialmente interpretable si existe un algoritmo que da como entrada algunos v • C y una instancia x • X calcula el valor v(x) en el tiempo q(size(v), m), para algún polinomio fijo q(·, ·).2 En las rondas intermedias de una subasta (terativa), el subastador habrá obtenido información sobre las funciones de Por lo tanto, habrá construido un conjunto de valoraciones manifiestas, denotadas . . Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha adquirido información sobre ciertos paquetes. El objetivo en el problema de la excitación de preferencia es construir un conjunto de valoraciones manifiestas tales que: arg max (S1,...,Sn) iÃ3n Ã3vi(Si)  arg max (S1,...,Sn) iÃ3n vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que es óptima con respecto a las valoraciones verdaderas. Tenga en cuenta que sólo se requiere una asignación óptima. condición de la libre eliminación (monotonicidad), pero no la necesitamos en este punto. 2 Esto excluye OR*, asumiendo P = NP, porque interpretar las ofertas de este lenguaje es NP-duro por reducción de set-embalaje ponderado, y no hay clase de representación bien estudiada en \"teoría de aprendizaje\" que es claramente análogo a OR*. 3 Esta visión de las subastas iterativas tiene por objeto paralelizar el entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente están implícitas por la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son consultas de valor y demanda. En una consulta de valor, el subastador presenta un paquete S  M y el agente responde con su valor (exacto) para el paquete v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p • • • (2m ) sobre los paquetes junto con un paquete S. El agente responde SI si es el caso de que S • arg max S M v(S ) − p(S ) ¡ o de otro modo presenta un paquete S tal que v(S ) − p(S ) > v( Tenga en cuenta también que comunicar precios no lineales no implica necesariamente citar un precio por cada paquete posible. Puede haber formas más sucintas de comunicar este vector, como se muestra en la sección 5. Hacemos las siguientes definiciones para paralelizar la configuración de aprendizaje de la consulta y para simplificar las declaraciones de resultados posteriores: Definición 2. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si hay un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes tales que para cualquier (v1,. . . , vn) V1 ×. . . × Vn, L salidas después de como máximo p(size(v1,. . . , vn), m) consulta una asignación (S1,. . . , Sn) arg max(S1,...,Sn) È vi(Si). Del mismo modo, la clase de representación C se puede obtener eficientemente de las consultas de valor y demanda si el algoritmo L produce una asignación óptima con comunicación p(size(v1, ). . . , vn), m), para algunos polinomios fijos p(·, ·). Hay algunas diferencias clave aquí con la definición de aprendizaje de la consulta. Hemos eliminado el término exactamente ya que las funciones de valoración no necesitan ser determinadas exactamente con el fin de calcular una asignación óptima. Además, un algoritmo de excitación eficiente es la comunicación polinomio, en lugar de tiempo polinomio. Esto refleja el hecho de que la comunicación en lugar del tiempo de espera es el cuello de botella en la excitación. Cálculo de una asignación óptima de bienes incluso cuando se dan las valoraciones verdaderas es NP-duro para una amplia gama de clases de valoración. Por lo tanto, no es razonable exigir tiempo polinomio en la definición de un algoritmo de excitación de preferencias eficiente. Nos complace centrarnos en la complejidad comunicativa de la excitación porque se cree que este problema es más significativo en la práctica que el de la determinación del ganador [11].5 4 Esto difiere ligeramente de la definición proporcionada por Blum et al. [5] Sus consultas sobre la demanda se limitan a precios lineales sobre las mercancías, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir. un precio distinto por cada paquete posible. Es por eso que el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. 5 Aunque el problema de determinación del ganador es NP-hard para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta aproximaciones usando solucionadores IP fuera de la plataforma [1]. 182 Dado que no es necesario obtener exactamente las valoraciones, es inicialmente menos claro si la dependencia polinómica del tamaño (v1, ). . . , vn) está justificado en este contexto. Intuitivamente, este parámetro está justificado porque debemos aprender valoraciones exactamente cuando se realiza la excitación, en el peor de los casos. Nos ocupamos de esto en la siguiente sección. 3. PARALLESBETWEEN EQUIVALENCIA Y QUERIDAS DE DEMANDA Hemos descrito los ajustes de aprendizaje y excitación de preferencias de la consulta de una manera que destaca sus similitudes. Las consultas de valor y membresía son claras analógicas. Un poco menos obvio es el hecho de que las consultas de equivalencia y demanda también son analógicas. Para ver esto, necesitamos el concepto de precios Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios sobre sus bienes subyacentes. Son no anónimos en el sentido de que dos agentes pueden tener que hacer frente a precios diferentes para el mismo paquete de mercancías. Así los precios de Lindahl son de la forma pi(S), para todos S  M, para todos los precios de i  N. Lindahl se presentan a los agentes en consultas de la demanda. Cuando los agentes han normalizado las funciones de utilidad cuasi-lineal, Bikhchandani y Ostroy [4] muestran que siempre existen precios Lindahl tales que (S1,. . . , Sn) es una asignación óptima si y sólo si Si • arg max Si vi(Si) − pi(Si) • i N (1) (S1,. . . , Sn)  arg max (S1,...,Sn) iN pi(Si) (2) Condición (1) establece que cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos de los subastadores a los precios indicados. El escenario en el que se mantienen estas condiciones se llama equilibrio Lindahl, o a menudo un equilibrio competitivo. Decimos que los precios de Lindahl apoyan la asignación óptima. Por lo tanto, basta con anunciar los precios de apoyo de Lindahl para verificar una asignación óptima. Una vez que hemos encontrado una asignación con el apoyo de precios Lindahl, el problema de excitación se resuelve. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones estén garantizadas como integrales [4]. Las variables duales de este programa lineal están soportando los precios de Lindahl para la asignación resultante. La función objetiva del programa dual es: min pi(S) Por lo general, hay una gama de posibles precios Lindahl que apoyan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios válidos Lindahl, y nos referimos a ellos como precios máximos Lindahl. De todos los vectores posibles de precios Lindahl, precios máximos Lindahl maximizar la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È iÃ3N πi del objetivo (la suma de los agentes de utilidades) son precios mínimos Lindahl. Cualquier Lindahl precios hará para nuestros resultados, pero algunos pueden tener mejores propiedades de excitación que otros. Tenga en cuenta que una consulta de demanda con precios máximos de Lindahl es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para el trabajo futuro la cuestión de los precios de Lindahl para elegir minimizar la obtención de preferencias. Teniendo en cuenta ahora por qué las consultas de demanda y equivalencia son analógicas directas, primero tenga en cuenta que dado el πi en algún equilibrio Lindahl, establecer pi(S) = max{0, Estos precios dejan a cada agente indiferente en todos los paquetes con precio positivo, y satisfacen la condición (1). Así, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl típicamente serán una constante aditivo lejos de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos de consultas de equivalencia a través de consultas de demanda. Lemma 1. Supongamos que un agente responde con un paquete preferido S cuando se propone un paquete S y soporta los precios de Lindahl p(S) (soportando con respecto a la valoración manifiesta de los agentes). A continuación, o bien?v(S) = v(S) o?v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: Φv(S) − p(S) ≥ Desigualdad (6) se mantiene porque el agente de hecho prefiere S a S dados los precios, de acuerdo con su respuesta a la consulta de demanda. Si fuera el caso de que?v(S) = v(S) y Así, al menos uno de S y S es un contraejemplo de la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño(v1,. . . , vn) en problemas de excitación. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que apoyar los precios de Lindahl debe necesariamente revelarse en el curso de cualquier protocolo de obtención de preferencias que termina con una asignación óptima. Además, Nisan y Segal (Lemma 1, [12]) afirman que en el peor de los casos los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones dobles (como será el caso de las clases más interesantes). Puesto que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y puesto que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitiendo la dependencia del tamaño(v1,. . . , vn) en problemas de excitación es totalmente natural. 183 4. DE APRENDIZAJE A LA LICITACIÓN DE PREFERENCIA La clave para convertir un algoritmo de aprendizaje a un algoritmo de excitación es simular consultas de equivalencia con consultas de demanda y valor hasta que se encuentre una asignación óptima. Debido a nuestra construcción de precios Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en que un agente responde SÍ a una consulta de equivalencia cuando la función de destino se ha aprendido exactamente. De lo contrario, podemos obtener un contraejemplo a una consulta de equivalencia dada una respuesta de agentes a una consulta de demanda. Teorema 1. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si cada uno puede ser polinomio-consulta exactamente aprendido de consultas de membresía y equivalencia. Prueba. Considere el algoritmo de excitación en la Figura 1. Cada consulta de membresía en el paso 1 es simulada con una consulta de valor ya que estas son de hecho idénticas. Considere el paso 4. Si todos los agentes responden SÍ, la condición (1) se mantiene. Condición (2) se mantiene porque la asignación calculada es la maximización de ingresos para el subastador, independientemente de los agentes verdaderas valoraciones. Así pues, se ha encontrado una asignación óptima. De lo contrario, por lo menos uno de Si o Si es un contraejemplo a Vi, por Lemma 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones del agente se conocerán exactamente, en cuyo caso la asignación óptima y los precios Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinomio de consultas, desde A1,. . . , A son todos los algoritmos de aprendizaje polinomio-quería. Tenga en cuenta que el procedimiento de conversión resulta en un algoritmo de excitación de preferencias, no un algoritmo de aprendizaje. Es decir, el algoritmo resultante no simplemente aprender las valoraciones exactamente, a continuación, calcular una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor, y periódicamente comprueba si se ha reunido suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio Lindahl para las valoraciones v1,. . . , vn utilizando una asignación y precios derivados de valoraciones manifiestas . . y encontrar una asignación óptima no implica que las valoraciones de los agentes se hayan aprendido exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta interrupción temprana. No obtendremos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE COMUNICACIÓN En esta sección, pasamos a la cuestión de la complejidad comunicativa de la excitación. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (tales como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos de determinar los precios de Lindahl es exponencial en el número de mercancías, m. La carga de comunicación se mide en términos del número de bits transmitidos entre agentes y subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. La conversión de algoritmos de aprendizaje eficientes a un algoritmo de excitación produce un algoritmo cuyas consultas tienen tamaños polinomios en los parámetros m y tamaño (v1, ). . . , vn). Teorema 2. Las clases de representación V1,. . . , Vn se puede obtener de forma eficiente de las consultas de valor y demanda si cada uno puede ser aprendido exactamente de las consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, basta con comunicar la función de valoración manifiesta de los agentes y el valor Nótese que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinomio, porque el tiempo de ejecución de los algoritmos también sería superpolinomio, contradiciendo la eficiencia. Por lo tanto, la comunicación de la valoración manifiesta requiere tamaño a lo sumo p(size(vi), m), para algunos polinomios p que limita superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representando el excedente πi al agente no se puede requerir espacio mayor que q(size( También debemos comunicarnos con su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es como máximo p(size(vi), m) + q(p(size(vi), m), m)+O(m). Claramente, una respuesta de agentes a una consulta de valor o demanda tiene un tamaño máximo de q(size(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, son siempre de tamaño polinomio. Un algoritmo de aprendizaje eficiente realiza un número polinomio de consultas, por lo que la comunicación total del algoritmo de excitación resultante es polinomio en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites pueden ser traducidos a límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de excitación resultante. Con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2 se determinó el tamaño de la hipótesis manifiesta. Es probable que podamos hacerlo mucho mejor que esto en la práctica. Recuerde que una consulta de equivalencia es apropiada si size( ̃f) ≤ size(f) en el momento de realizar la consulta. Si las consultas de equivalencia de algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites estrechos en los requisitos de comunicación del algoritmo de excitación resultante. El teorema 2 muestra que los algoritmos de excitación que dependen del tamaño (v1,. . . El parámetro, vn) evita los resultados negativos de Nisan y Segals [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto al tamaño de las instancias de las funciones de valoración que se enfrentan a cualquier ejecución del algoritmo. Estos algoritmos van bien si la clase de representación elegida proporciona representaciones sucintas para la más simple y común de las valoraciones, y por lo tanto el enfoque se mueve de nuevo a uno de lenguajes de licitación compactos pero expresivos. A continuación se examinan estas cuestiones. 6. APLICACIONES En esta sección, demostramos la aplicación de nuestros métodos a clases particulares de representación para valoraciones combinatorias. Hemos demostrado que el problema de excitación de preferencias para las clases de valoración V1,. . . , Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1,. . . , Una para las valoraciones de las clases V1,. . . , Vn respectivamente. Encaje hasta que haya una señal para detenerse: 1. Corre A1,. . . , Un en paralelo sobre sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se ha detenido con los agentes valoración exacta. 2. Calcular una asignación óptima (S1,. . . , Sn ) y los correspondientes precios de Lindahl con respecto a las valoraciones manifiestas . . , їvn determinado hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de consulta de demanda. 4. Si todos ellos responden SÍ, salida la asignación y parada. De lo contrario hay algún agente i que ha respondido con algún paquete preferido Si. Realizar consultas de valor en Si y Si para encontrar un contraejemplo a ‡vi, y proporcionarlo a Ai. Figura 1: Convertir algoritmos de aprendizaje a un algoritmo de excitación. al problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de función, y porque a menudo puede ser más simple resolver cada subproblema de aprendizaje por separado que atacar el problema de excitación de preferencias directamente. Podemos desarrollar un algoritmo de excitación que se adapta a cada valoración de agentes, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Demostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas de DNF monotono y funciones de umbral lineal se pueden convertir en algoritmos de excitación de preferencia para valoraciones generales, valoraciones con eliminación libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en las representaciones que son polinomialmente interpretables, porque la literatura computacional \"teoría del aprendizaje\" pone un énfasis pesado en la traqueabilidad computacional [18]. Al interpretar los métodos enfatizamos la expresividad y sucinta de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de licitación, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debe representar sucintamente las funciones más simples y comunes de la clase. 6.1 Las Representaciones Polinómicas Schapire y Sellie [17] dan un algoritmo de aprendizaje para polinomios multivariables escasos que pueden utilizarse como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas apropiadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados de t-sparse sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-sparse tiene como máximo t términos, donde un término es un producto de variables, por ejemplo. x1x3x4. Un polinomio sobre los números reales tiene coeficientes extraídos de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M →  se puede escribir exclusivamente como un polinomio [17]. Para tener una idea de la sucintaidad de los polinomios como lenguaje de licitación, considere las valoraciones aditivas y mono-ítem presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es el número de mercancías que contiene el paquete. En la valoración de un solo elemento, todos los paquetes tienen valor 1, excepto el valor 0 (i.e. el agente está satisfecho tan pronto como ha adquirido un único artículo). No es difícil demostrar que la valoración de un solo elemento requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Por lo tanto, los polinomios son adecuados para valoraciones que en su mayoría son aditivas, con algunas sustituibilidades y complementariedades que pueden introducirse ajustando los coeficientes. El algoritmo de aprendizaje para polinomios hace como máximo consultas de equivalencia mti +2 y como máximo (mti +1) (t2 i +3ti)/2 consultas de membresía a un agente i, donde ti es la esparcidad del polinomio que representa vi [17]. Por lo tanto, se obtiene un algoritmo que provoca valoraciones generales con un número polinomio de consultas y comunicación polinomio.6 6.2 XOR Representaciones El lenguaje de licitación XOR es estándar en la literatura de subastas combinatoria. Recordemos que una oferta XOR se caracteriza por un conjunto de paquetes B  2M y una función de valor w : B →  definida en esos paquetes, que induce la función de valoración: v(B) = max {B  B  B  B} w(B) (7) Las ofertas XOR pueden representar valoraciones que satisfacen la libre eliminación (y sólo tales valoraciones), que de nuevo es la propiedad que A  B El lenguaje de licitación XOR es ligeramente menos expresivo que los polinomios, porque los polinomios pueden representar valoraciones que no satisfacen la libre eliminación. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas de XOR pueden representar la valoración de un solo elemento con ofertas atómicas m, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario se aplica a los polinomios, estas dos lenguas son incomparables en sucintas y algo complementarias para su uso práctico. Blum et al. [5] note que las fórmulas DNF monotonas son los análogos de las ofertas XOR en la literatura de la \"teoría del aprendizaje\". Una fórmula de DNF monotona es una disyunción de conjunciones en las que las variables aparecen sin negación, por ejemplo x1x2 x3 x2x4x5. Tenga en cuenta que tales fórmulas pueden ser representadas como ofertas XOR donde cada oferta atómica tiene valor 1; por lo tanto XOR ofrece generalizar fórmulas DNF monotono de Boolean a funciones de valor real. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para el DNF monotono ([3] Teorema 6 Tenga en cuenta que el Teorema 1 se aplica incluso si las valoraciones no satisfacen la eliminación libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lemma 2. Una oferta XOR que contiene ofertas t atómicas se puede aprender exactamente con consultas de equivalencia t + 1 y a lo sumo consultas de membresía tm. Prueba. El algoritmo identificará cada puja atómica en la puja XOR objetivo a su vez. Initialice la valoración manifiesta v a la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presente ‡v como consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un paquete S para el que v(S) = Crear un paquete T de la siguiente manera. Primero inicialice T = S. Para cada elemento i en T, compruebe a través de una consulta de membresía si v(T) = v(T − {i}). Si así se establece T = T − {i}. De lo contrario, deje T como está y pase al siguiente punto. Afirmamos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada ítem i en T, tenemos v(T) = v(T − {i}). Para ver esto, tenga en cuenta que en algún momento al generar T, tuvimos un ̄T tal que T  ̄T  S y v( ̄T) > v( ̄T − {i}), de modo que me mantuvo en ̄T. Tenga en cuenta que v(S) = v( ̄T) = v(T) porque el valor del paquete S se mantiene durante todo el proceso de eliminación de elementos. Ahora asume v(T) = v(T − {i}). Entonces v( ̄T) = v(T) = v(T − {i}) > v( ̄T − {i}) que contradice la libre eliminación, ya que T {i}  ̄T − {i}. Por lo tanto v(T) > v(T − {i}) para todos los ítems i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si este no fuera el caso, T tomaría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = máx itat {max T T Ahora mostramos que v(T) = ̃v(T), que implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Asumir que toda oferta atómica (R, Esta suposición se mantiene vagamente cuando se inicializa la valoración manifiesta. Usando la notación de (7), dejar ( Tenemos B  B, y Bw(B) = w(B) para B Por lo tanto,?v(S) = max {B} {B} {B} {B} {B} {B} = max {B} {B} {B} ≤ {B} {B} {B} {B} {S} w(B} = v(S) (8) Ahora asume v(T) {v(T La segunda igualdad se deriva del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad sostiene porque S es un contraejemplo de la valoración manifiesta. De la ecuación (9) y la eliminación libre, nosotros 7 El algoritmo citado también se utilizó como base para Zinkevich et al.s [19] algoritmo de excitación para Toolbox DNF. Recuerde que Toolbox DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia se puede simular con una consulta de valor en el paquete que contiene todas las mercancías. que tengan ‡v(T) < Entonces de nuevo de la ecuación (9) se deduce que v(S) < Esto contradice (8), por lo que de hecho tenemos v(T) = Por lo tanto (T, v(T)) no está actualmente en nuestra hipótesis como una oferta atómica, o tendríamos correctamente?v(T) = v(T) por la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas adicionales de equivalencia hasta que todas las ofertas atómicas hayan sido identificadas. Después de cada consulta de equivalencia, una oferta atómica se identifica con como máximo m consultas de membresía. Cada contraejemplo conduce al descubrimiento de una nueva oferta atómica. Por lo tanto, hacemos a lo sumo consultas de membresía tm y exactamente consultas de equivalencia t + 1. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR se puede obtener eficientemente de las consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al.s ([5], Teorema 2) afirmando que el DNF monotono (y por lo tanto las ofertas XOR) no se pueden obtener de manera eficiente cuando las consultas de demanda se limitan a precios lineales y anónimos sobre las mercancías. 6.3 Las representaciones lineales de umbral polinomios, las ofertas XOR y todas las lenguas basadas en el lenguaje de licitación OR (como XOR-de-OR, OR-de-XOR y OR*) no representan sucintamente la valoración mayoritaria [11]. En esta valoración, los paquetes tienen valor 1 si contienen al menos m/2 ítems, y valor 0 de lo contrario. Más generalmente, considere la familia de r-of-S de valoraciones donde los paquetes tienen valor 1 si contienen al menos r artículos de un conjunto especificado de ítems S  M, y valor 0 de otra manera. La valoración mayoritaria es un caso especial de la valoración de r-of-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar las sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede añadir valor. Dejando k = S, tales valoraciones están sucintamente representadas por funciones de umbral r-of-k. Estas funciones adoptan la forma de desigualdades lineales: xi1 +. . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se mantiene, y 0 de lo contrario. Aquí i1,. . . , ik son los elementos en S. Littlestones WINNOW 2 algoritmo puede aprender tales funciones utilizando consultas de equivalencia sólo, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de excitación que resulta de WINNOW 2 sólo utiliza consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos están implícitos cuando sólo hay dos valores posibles). Tenga en cuenta que las funciones de umbral r-of-k siempre se pueden representar sucintamente en el espacio O(m). Así se obtiene un algoritmo que puede generar tales funciones con un número polinomio de consultas y comunicación polinomio, en los parámetros n y m solos. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exactos con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de excitación de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas en el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la riqueza de algoritmos de aprendizaje disponibles al problema de la excitación de preferencias. Un enfoque de aprendizaje para la excitación también motiva un enfoque diferente para diseñar algoritmos de excitación que se descomponen cuidadosamente entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivos, muchos sustitutos, etc.), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de excitación. El algoritmo de excitación resultante hace un número polinomio de consultas, y hace comunicación polinomio si los algoritmos de aprendizaje originales son eficientes. No exigimos que las valoraciones de agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia sólo pueden ser, y sólo necesitan ser, simuladas hasta el punto en que se ha calculado una asignación óptima. Este es el problema de la excitación de preferencias. Teorema 1 implica que la excitación con consultas de valor y demanda no es más difícil que aprender con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las que la excitación es más fácil que el aprendizaje. Blum et al. [5] proporcionar tal ejemplo al considerar solamente consultas de membresía/valor (Teorema 4). En el trabajo futuro planeamos abordar la cuestión de los incentivos al convertir algoritmos de aprendizaje a algoritmos de excitación. En el entorno de aprendizaje, por lo general suponemos que los oráculos proporcionarán respuestas honestas a las preguntas; en el entorno de excitación, los agentes son generalmente egoístas y proporcionarán respuestas posiblemente deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para el aprendizaje de polinomios y ofertas XOR como algoritmos de excitación, y probar su rendimiento contra otros protocolos de subasta combinatoria establecidos [6, 15]. Una pregunta interesante aquí es: ¿qué precios Lindahl en el rango máximo a mínimo son los mejores para citar con el fin de minimizar la revelación de información? Suponemos que la revelación de información se reduce al pasar de precios máximos a precios mínimos de Lindahl, es decir, a medida que desplazamos las consultas de demanda más lejos de las consultas de equivalencia. Por último, sería útil determinar si el lenguaje de licitación de OR* [11] puede aprenderse (y, por lo tanto, obtenerse) de manera eficiente, dada la expresividad y sucinta de estas lenguas para una amplia variedad de clases de valoración. Agradecimientos Queremos agradecer a Debasis Mishra por sus útiles discusiones. Este trabajo está apoyado en parte por la subvención de NSF IIS0238147. 8. REFERENCIAS [1] A. Andersson, M. Tenhunen, y F. Ygge. Programación integral para la determinación del ganador de la subasta combinatoria. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprender conjuntos regulares de consultas y contraejemplos. Información e computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje conceptual. Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El modelo de asignación de paquetes. Diario de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Provocación de preferencias y aprendizaje de consultas. En Proc. 16a Conferencia Anual sobre Teoría del Aprendizaje Computacional (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. la 18a Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, e Y. Shoham. Domar la complejidad computacional de las subastas combinatoria: Enfoques óptimos y aproximados. En Proc. , 16a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), págs. 548 a 553, 1999. [8] B. Hudson y T. Sandholm. Uso de consultas de valor en subastas combinatoria. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría del aprendizaje computacional. MIT Press, 1994. [10] N. Littlestone. Aprender rápidamente cuando los atributos irrelevantes abundan: Un nuevo algoritmo de umbral lineal. Machine Learning, 2:285-318, 1988. [11] N. Nisan. Licitación y asignación en subastas combinatoria. En Proc. la Conferencia de la ACM sobre Comercio Electrónico, págs. 1 a 12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y el apoyo a los precios Lindahl. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de mínima revelación. En Padget et al., editor, Agent-Mediated Electronic Commerce IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. Diseño de subastas con costosas preferencias. En Temas Especiales de Anales de Matemáticas y AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17a Conferencia Nacional sobre Inteligencia Artificial (AAAI-00), págs. 74 a 81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. la 17a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariables escasos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de ACM sobre Teoría del Aprendizaje Computacional, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendido. Comun. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum, y T. Sandholm. Sobre la excitación de la preferencia polinomio-tiempo con las consultas de valor. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "error": [
                "teoría de aprendizaje",
                "teoría del aprendizaje",
                "teoría del aprendizaje",
                "teoría del aprendizaje",
                "teoría de aprendizaje",
                "teoría de aprendizaje",
                "teoría de aprendizaje",
                "teoría del aprendizaje",
                "teoría del aprendizaje"
            ]
        },
        "learning algorithm": {
            "translated_key": "algoritmo de aprendizaje",
            "translated_annotated_text": "Aplicando algoritmos de aprendizaje a la eliminación de preferencia Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de excitación Demostramos que los algoritmos de aprendizaje pueden ser usados como base para algoritmos de excitación de preferencias. Los algoritmos de excitación resultantes realizan un número polinomio de consultas. También damos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. En particular, se obtiene un algoritmo que provoca pujas XOR con comunicación polinómica. Categorías y Descriptores sujetos F.2.0 [Análisis de algoritmos y complejidad de problemas]: General; J.4 [Ciencias Sociales y Conductuales]: Economía; I.2.6 [Inteligencia Artificial]: Términos generales de aprendizaje Algoritmos, Economía, Teoría 1. INTRODUCCIÓN En una subasta combinatoria, los agentes pueden pujar por paquetes de bienes en lugar de por cada uno de ellos. Puesto que hay un número exponencial de paquetes (en el número de bienes), comunicar los valores sobre estos paquetes puede ser problemático. Comunicar las valoraciones de una sola vez puede ser prohibitivamente costoso si el número de bienes es sólo moderadamente grande. Además, incluso podría ser difícil para los agentes determinar sus valoraciones para paquetes únicos [14]. A esos agentes les interesa disponer de protocolos de subasta que les obliguen a pujar en el menor número posible de paquetes. Incluso si los agentes pueden calcular eficientemente sus valoraciones, podrían ser reacios a revelarlas enteramente en el curso de una subasta, porque tal información puede ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información necesaria para determinar una asignación óptima de los bienes. Ha habido un trabajo reciente explorando los vínculos entre el problema de la excitación de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje computacional [5, 19]. En teoría de aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, tales como ¿Cuál es el valor de las funciones en estas entradas? En la obtención de preferencia, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Demostramos que cualquier \"algoritmo de aprendizaje\" exacto con consultas de membresía y equivalencia se puede convertir en un algoritmo de excitación de preferencias con consultas de valor y demanda. El algoritmo de excitación resultante garantiza la excitación en un número polinomio de consultas de valor y demanda. Aquí queremos decir polinomio en el número de bienes, agentes, y los tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Argumentamos que las garantías de complejidad para los esquemas de excitación deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar la comunicación polinómica en el peor de los casos, que normalmente no se puede lograr en el número de productos y agentes por sí solos. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. Por supuesto, una subasta combinatoria de un solo disparo donde los agentes proporcionan todas sus funciones de valoración a la vez también tendría comunicación polinómica en el tamaño de las valoraciones de los agentes, y sólo requieren una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay ninguna carga para los agentes de formular sus valoraciones en un esquema de codificación de los subastadores que elijan. Esperamos que esta sea una consideración importante en la práctica. Además, con nuestro esquema la revelación entera sólo ocurre en el peor de los casos. 180 Por ahora, dejamos a un lado la cuestión de los incentivos al derivar algoritmos de excitación. Nos centramos en el tiempo y la complejidad de la comunicación de la obtención de preferencias, independientemente de las limitaciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich y otros [19] considerar el problema del aprendizaje de clases restringidas de funciones de valoración que se pueden representar utilizando fórmulas de lectura once y Toolbox DNF. Las fórmulas Read-once pueden representar ciertas sustitutibilidades, pero no complementariedades, mientras que lo contrario se mantiene para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten depender del tamaño de la valoración objetivo como lo hacemos (aunque las valoraciones de read-once siempre se pueden representar sucintamente de todos modos). Su trabajo sólo hace uso de consultas de valor, que son bastante limitados en el poder. Debido a que nos permitimos pedir consultas, somos capaces de derivar un esquema de excitación para las funciones de valoración general. Blum et al. [5] proporcionar resultados relacionados con las complejidades del aprendizaje de la consulta y la excitación de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje de consultas, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones se pueden aprender eficientemente, pero no se pueden obtener eficientemente, y viceversa. En contraste, nuestro trabajo muestra que dada una versión más general (todavía bastante estándar) de la consulta de demanda que el tipo que consideran, la complejidad de la excitación de preferencia no es mayor que la complejidad del aprendizaje. Demostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre valoraciones para implicar una solución al problema de excitación. Nisan y Segal [12] estudian la complejidad comunicativa de la excitación de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos de la computación una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo se permite a los algoritmos hacer preguntas sobre valoraciones de agentes y recibir respuestas honestas, sin ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda la cuestión de la complejidad de la comunicación, y somos capaces de derivar algoritmos que proporcionan garantías de comunicación significativas a pesar de los resultados negativos de Nisan y Segals. Su trabajo motiva la necesidad de confiar en el tamaño de los agentes funciones de valoración para indicar los peores resultados. 2. LOS MODELOS 2.1 Aprendizaje de la consulta El modelo de aprendizaje de la consulta que consideramos aquí se llama aprendizaje exacto de la membresía y consultas de equivalencia, introducido por Angluin [2]. En este modelo el objetivo de los algoritmos de aprendizaje es identificar exactamente una función diana desconocida f : X → Y a través de consultas a un oráculo. La función de destino se extrae de una función de clase C que es conocida por el algoritmo. Típicamente el dominio X es algún subconjunto de {0, 1}m, y el rango Y es {0, 1} o algún subconjunto de los números reales. A medida que el algoritmo avanza, construye una hipótesis manifiesta?f que es su estimación actual de la función de destino. Después de la terminación, la hipótesis manifiesta de un \"algoritmo de aprendizaje\" correcto satisface?f(x) = f(x) para todos x?X. Es importante especificar la representación que se utilizará para codificar funciones de C. Por ejemplo, considere la siguiente función de {0, 1}m a ♥: f(x) = 2 si x consiste en m 1s, y f(x) = 0 de otra manera. Esta función puede representarse simplemente como una lista de valores de 2m. O puede codificarse como el polinomio 2x1 · · · xm, que es mucho más sucinto. Así pues, la elección de la codificación puede tener un impacto significativo en los requisitos de tiempo y espacio del \"algoritmo de aprendizaje\". Let size(f) ser el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes distintos de cero en el polinomio, por ejemplo. Por lo general, sólo nos referiremos a las clases de representación; las clases de funciones correspondientes serán implícitas. Por ejemplo, la clase de representación de fórmulas DNF monotonas implica la clase de función de funciones booleanas monotonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: la membresía y las consultas de equivalencia. En una consulta de membresía, el aprendiz presenta algunas x x x y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta f. El oráculo responde SÍ si?f = f, o devuelve un contraejemplo x de tal manera que?f(x) = f(x). Una consulta de equivalencia es apropiada si el tamaño( ̃f) ≤ tamaño(f) en el momento de presentar la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones se adaptan a partir de Kearns y Vazirani [9]: Definición 1. La clase de representación C es polinomialquery exactamente aprendeble de las consultas de membresía y equivalencia si hay un polinomial fijo p(·, ·) y un algoritmo L con acceso a la membresía y consultas de equivalencia de un oráculo tal que para cualquier función de destino f • C, L salidas después de a lo sumo p(size(f), m) consultas de una función?f • C tal que?f Del mismo modo, la clase de representación C se puede aprender exactamente de las consultas de membresía y equivalencia si el algoritmo L produce una hipótesis correcta en el tiempo p(size(f), m), para algunos polinomios fijos p(·, ·). Aquí m es la dimensión del dominio. Dado que la función de destino debe ser reconstruida, también permitimos necesariamente la dependencia polinómica del tamaño (f). 2.2 Eliminación de preferencias En una subasta combinatoria, un conjunto de bienes M se asignará entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Tal asignación se llama eficiente en la literatura de economía, pero nos referiremos a ella como óptima y reservar el término eficiente para referirse a la eficiencia computacional. Dejamos n = N y m = M. Una asignación es una partición de los objetos en paquetes (S1,. . . , Sn), de tal manera que Si â € ¬ Sj = â € para todos los i, j â € N. Let â € € sea el conjunto de posibles asignaciones. Cada agente i+N tiene una función de valoración vi : 2M → • sobre el espacio de los paquetes posibles. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no tienen que coincidir. Asumimos que todas las valoraciones consideradas están normalizadas, es decir, v() = 0, y que no hay externalidades, es decir, vi(S1,..., Sn) = vi(Si), para todos los agentes i  N, para cualquier asignación (S1,..., Sn)  (es decir, un agente se preocupa sólo por el paquete asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales.1 Nosotros 1 A menudo las valoraciones generales se hacen para satisfacer los 181 adicionales también asumen que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que los agentes utilidades pueden ser divididos en componentes monetarios y no monetarios. Si a un agente i se le asigna el paquete S al precio p, deriva utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más sucintas para ciertas clases de valoración, y ha habido mucha investigación en lenguajes de licitación concisos para diversos tipos de valoraciones [11]. Un ejemplo clásico al que nos referiremos más adelante es el lenguaje de licitación XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, que consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estas pujas, se busca el paquete S del valor más alto listado en las pujas atómicas de tal manera que S  S. Es entonces el caso que v(S) = v(S). Al igual que en el contexto de la teoría del aprendizaje, por lo general sólo nos referiremos a idiomas de oferta en lugar de clases de valoración, ya que las clases de valoración correspondientes serán implícitas. Por ejemplo, el lenguaje de licitación XOR implica la clase de valoraciones que satisfacen la disposición libre, que es la condición de que A  B ♥ v(A) ≤ v(B). Dejamos el tamaño(v1,. . . , vn) = Èn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de licitación). Para hacer una analogía con la teoría del aprendizaje computacional, suponemos que todas las clases de representación consideradas son polinomiamente interpretables [11], lo que significa que el valor de un paquete puede ser calculado en tiempo polinomio dada la representación de funciones de valoración. Más formalmente, una clase de representación (lenguaje de licitación) C es polinomialmente interpretable si existe un algoritmo que da como entrada algunos v • C y una instancia x • X calcula el valor v(x) en el tiempo q(size(v), m), para algún polinomio fijo q(·, ·).2 En las rondas intermedias de una subasta (terativa), el subastador habrá obtenido información sobre las funciones de Por lo tanto, habrá construido un conjunto de valoraciones manifiestas, denotadas . . Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha adquirido información sobre ciertos paquetes. El objetivo en el problema de la excitación de preferencia es construir un conjunto de valoraciones manifiestas tales que: arg max (S1,...,Sn) iÃ3n Ã3vi(Si)  arg max (S1,...,Sn) iÃ3n vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que es óptima con respecto a las valoraciones verdaderas. Tenga en cuenta que sólo se requiere una asignación óptima. condición de la libre eliminación (monotonicidad), pero no la necesitamos en este punto. 2 Esto excluye OR*, asumiendo P = NP, porque la interpretación de las ofertas de este lenguaje es NP-duro por reducción de set-embalaje ponderado, y no hay clase de representación bien estudiada en teoría de aprendizaje que es claramente análogo a OR*. 3 Esta visión de las subastas iterativas tiene por objeto paralelizar el entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente están implícitas por la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son consultas de valor y demanda. En una consulta de valor, el subastador presenta un paquete S  M y el agente responde con su valor (exacto) para el paquete v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p • • • (2m ) sobre los paquetes junto con un paquete S. El agente responde SI si es el caso de que S • arg max S M v(S ) − p(S ) ¡ o de otro modo presenta un paquete S tal que v(S ) − p(S ) > v( Tenga en cuenta también que comunicar precios no lineales no implica necesariamente citar un precio por cada paquete posible. Puede haber formas más sucintas de comunicar este vector, como se muestra en la sección 5. Hacemos las siguientes definiciones para paralelizar la configuración de aprendizaje de la consulta y para simplificar las declaraciones de resultados posteriores: Definición 2. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si hay un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes tales que para cualquier (v1,. . . , vn) V1 ×. . . × Vn, L salidas después de como máximo p(size(v1,. . . , vn), m) consulta una asignación (S1,. . . , Sn) arg max(S1,...,Sn) È vi(Si). Del mismo modo, la clase de representación C se puede obtener eficientemente de las consultas de valor y demanda si el algoritmo L produce una asignación óptima con comunicación p(size(v1, ). . . , vn), m), para algunos polinomios fijos p(·, ·). Hay algunas diferencias clave aquí con la definición de aprendizaje de la consulta. Hemos eliminado el término exactamente ya que las funciones de valoración no necesitan ser determinadas exactamente con el fin de calcular una asignación óptima. Además, un algoritmo de excitación eficiente es la comunicación polinomio, en lugar de tiempo polinomio. Esto refleja el hecho de que la comunicación en lugar del tiempo de espera es el cuello de botella en la excitación. Cálculo de una asignación óptima de bienes incluso cuando se dan las valoraciones verdaderas es NP-duro para una amplia gama de clases de valoración. Por lo tanto, no es razonable exigir tiempo polinomio en la definición de un algoritmo de excitación de preferencias eficiente. Nos complace centrarnos en la complejidad comunicativa de la excitación porque se cree que este problema es más significativo en la práctica que el de la determinación del ganador [11].5 4 Esto difiere ligeramente de la definición proporcionada por Blum et al. [5] Sus consultas sobre la demanda se limitan a precios lineales sobre las mercancías, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir. un precio distinto por cada paquete posible. Es por eso que el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. 5 Aunque el problema de determinación del ganador es NP-hard para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta aproximaciones usando solucionadores IP fuera de la plataforma [1]. 182 Dado que no es necesario obtener exactamente las valoraciones, es inicialmente menos claro si la dependencia polinómica del tamaño (v1, ). . . , vn) está justificado en este contexto. Intuitivamente, este parámetro está justificado porque debemos aprender valoraciones exactamente cuando se realiza la excitación, en el peor de los casos. Nos ocupamos de esto en la siguiente sección. 3. PARALLESBETWEEN EQUIVALENCIA Y QUERIDAS DE DEMANDA Hemos descrito los ajustes de aprendizaje y excitación de preferencias de la consulta de una manera que destaca sus similitudes. Las consultas de valor y membresía son claras analógicas. Un poco menos obvio es el hecho de que las consultas de equivalencia y demanda también son analógicas. Para ver esto, necesitamos el concepto de precios Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios sobre sus bienes subyacentes. Son no anónimos en el sentido de que dos agentes pueden tener que hacer frente a precios diferentes para el mismo paquete de mercancías. Así los precios de Lindahl son de la forma pi(S), para todos S  M, para todos los precios de i  N. Lindahl se presentan a los agentes en consultas de la demanda. Cuando los agentes han normalizado las funciones de utilidad cuasi-lineal, Bikhchandani y Ostroy [4] muestran que siempre existen precios Lindahl tales que (S1,. . . , Sn) es una asignación óptima si y sólo si Si • arg max Si vi(Si) − pi(Si) • i N (1) (S1,. . . , Sn)  arg max (S1,...,Sn) iN pi(Si) (2) Condición (1) establece que cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos de los subastadores a los precios indicados. El escenario en el que se mantienen estas condiciones se llama equilibrio Lindahl, o a menudo un equilibrio competitivo. Decimos que los precios de Lindahl apoyan la asignación óptima. Por lo tanto, basta con anunciar los precios de apoyo de Lindahl para verificar una asignación óptima. Una vez que hemos encontrado una asignación con el apoyo de precios Lindahl, el problema de excitación se resuelve. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones estén garantizadas como integrales [4]. Las variables duales de este programa lineal están soportando los precios de Lindahl para la asignación resultante. La función objetiva del programa dual es: min pi(S) Por lo general, hay una gama de posibles precios Lindahl que apoyan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios válidos Lindahl, y nos referimos a ellos como precios máximos Lindahl. De todos los vectores posibles de precios Lindahl, precios máximos Lindahl maximizar la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È iÃ3N πi del objetivo (la suma de los agentes de utilidades) son precios mínimos Lindahl. Cualquier Lindahl precios hará para nuestros resultados, pero algunos pueden tener mejores propiedades de excitación que otros. Tenga en cuenta que una consulta de demanda con precios máximos de Lindahl es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para el trabajo futuro la cuestión de los precios de Lindahl para elegir minimizar la obtención de preferencias. Teniendo en cuenta ahora por qué las consultas de demanda y equivalencia son analógicas directas, primero tenga en cuenta que dado el πi en algún equilibrio Lindahl, establecer pi(S) = max{0, Estos precios dejan a cada agente indiferente en todos los paquetes con precio positivo, y satisfacen la condición (1). Así, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl típicamente serán una constante aditivo lejos de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos de consultas de equivalencia a través de consultas de demanda. Lemma 1. Supongamos que un agente responde con un paquete preferido S cuando se propone un paquete S y soporta los precios de Lindahl p(S) (soportando con respecto a la valoración manifiesta de los agentes). A continuación, o bien?v(S) = v(S) o?v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: Φv(S) − p(S) ≥ Desigualdad (6) se mantiene porque el agente de hecho prefiere S a S dados los precios, de acuerdo con su respuesta a la consulta de demanda. Si fuera el caso de que?v(S) = v(S) y Así, al menos uno de S y S es un contraejemplo de la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño(v1,. . . , vn) en problemas de excitación. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que apoyar los precios de Lindahl debe necesariamente revelarse en el curso de cualquier protocolo de obtención de preferencias que termina con una asignación óptima. Además, Nisan y Segal (Lemma 1, [12]) afirman que en el peor de los casos los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones dobles (como será el caso de las clases más interesantes). Puesto que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y puesto que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitiendo la dependencia del tamaño(v1,. . . , vn) en problemas de excitación es totalmente natural. 183 4. DE APRENDIZAR A LA ELICITACIÓN DE PREFERENCIA La clave para convertir un \"algoritmo de aprendizaje\" a un algoritmo de excitación es simular consultas de equivalencia con consultas de demanda y valor hasta que se encuentre una asignación óptima. Debido a nuestra construcción de precios Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en que un agente responde SÍ a una consulta de equivalencia cuando la función de destino se ha aprendido exactamente. De lo contrario, podemos obtener un contraejemplo a una consulta de equivalencia dada una respuesta de agentes a una consulta de demanda. Teorema 1. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si cada uno puede ser polinomio-consulta exactamente aprendido de consultas de membresía y equivalencia. Prueba. Considere el algoritmo de excitación en la Figura 1. Cada consulta de membresía en el paso 1 es simulada con una consulta de valor ya que estas son de hecho idénticas. Considere el paso 4. Si todos los agentes responden SÍ, la condición (1) se mantiene. Condición (2) se mantiene porque la asignación calculada es la maximización de ingresos para el subastador, independientemente de los agentes verdaderas valoraciones. Así pues, se ha encontrado una asignación óptima. De lo contrario, por lo menos uno de Si o Si es un contraejemplo a Vi, por Lemma 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones del agente se conocerán exactamente, en cuyo caso la asignación óptima y los precios Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinomio de consultas, desde A1,. . . , A son todos los algoritmos de aprendizaje polinomio-quería. Tenga en cuenta que el procedimiento de conversión resulta en un algoritmo de excitación de preferencias, no un \"algoritmo de aprendizaje\". Es decir, el algoritmo resultante no simplemente aprender las valoraciones exactamente, a continuación, calcular una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor, y periódicamente comprueba si se ha reunido suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio Lindahl para las valoraciones v1,. . . , vn utilizando una asignación y precios derivados de valoraciones manifiestas . . y encontrar una asignación óptima no implica que las valoraciones de los agentes se hayan aprendido exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta interrupción temprana. No obtendremos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE COMUNICACIÓN En esta sección, pasamos a la cuestión de la complejidad comunicativa de la excitación. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (tales como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos de determinar los precios de Lindahl es exponencial en el número de mercancías, m. La carga de comunicación se mide en términos del número de bits transmitidos entre agentes y subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. La conversión de algoritmos de aprendizaje eficientes a un algoritmo de excitación produce un algoritmo cuyas consultas tienen tamaños polinomios en los parámetros m y tamaño (v1, ). . . , vn). Teorema 2. Las clases de representación V1,. . . , Vn se puede obtener de forma eficiente de las consultas de valor y demanda si cada uno puede ser aprendido exactamente de las consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, basta con comunicar la función de valoración manifiesta de los agentes y el valor Nótese que un \"algoritmo de aprendizaje\" eficiente nunca construye una hipótesis manifiesta de tamaño superpolinomio, porque el tiempo de ejecución de los algoritmos sería entonces también superpolinomio, contradiciendo la eficiencia. Por lo tanto, la comunicación de la valoración manifiesta requiere tamaño a lo sumo p(size(vi), m), para algunos polinomios p que limita superiormente el tiempo de ejecución del \"algoritmo de aprendizaje\" eficiente. Representando el excedente πi al agente no se puede requerir espacio mayor que q(size( También debemos comunicarnos con su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es como máximo p(size(vi), m) + q(p(size(vi), m), m)+O(m). Claramente, una respuesta de agentes a una consulta de valor o demanda tiene un tamaño máximo de q(size(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, son siempre de tamaño polinomio. Un \"algoritmo de aprendizaje\" eficiente realiza un número polinomio de consultas, por lo que la comunicación total del algoritmo de excitación resultante es polinomio en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un \"algoritmo de aprendizaje\", con constantes que no están enmascaradas por la notación big-O. Estos límites pueden ser traducidos a límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de excitación resultante. Con el tiempo de ejecución del \"algoritmo de aprendizaje\" en el Teorema 2 hemos limitado el tamaño de la hipótesis manifiesta. Es probable que podamos hacerlo mucho mejor que esto en la práctica. Recuerde que una consulta de equivalencia es apropiada si size( ̃f) ≤ size(f) en el momento de realizar la consulta. Si las consultas de equivalencia de algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites estrechos en los requisitos de comunicación del algoritmo de excitación resultante. El teorema 2 muestra que los algoritmos de excitación que dependen del tamaño (v1,. . . El parámetro, vn) evita los resultados negativos de Nisan y Segals [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto al tamaño de las instancias de las funciones de valoración que se enfrentan a cualquier ejecución del algoritmo. Estos algoritmos van bien si la clase de representación elegida proporciona representaciones sucintas para la más simple y común de las valoraciones, y por lo tanto el enfoque se mueve de nuevo a uno de lenguajes de licitación compactos pero expresivos. A continuación se examinan estas cuestiones. 6. APLICACIONES En esta sección, demostramos la aplicación de nuestros métodos a clases particulares de representación para valoraciones combinatorias. Hemos demostrado que el problema de excitación de preferencias para las clases de valoración V1,. . . , Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1,. . . , Una para las valoraciones de las clases V1,. . . , Vn respectivamente. Encaje hasta que haya una señal para detenerse: 1. Corre A1,. . . , Un en paralelo sobre sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se ha detenido con los agentes valoración exacta. 2. Calcular una asignación óptima (S1,. . . , Sn ) y los correspondientes precios de Lindahl con respecto a las valoraciones manifiestas . . , їvn determinado hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de consulta de demanda. 4. Si todos ellos responden SÍ, salida la asignación y parada. De lo contrario hay algún agente i que ha respondido con algún paquete preferido Si. Realizar consultas de valor en Si y Si para encontrar un contraejemplo a ‡vi, y proporcionarlo a Ai. Figura 1: Convertir algoritmos de aprendizaje a un algoritmo de excitación. al problema de encontrar un \"algoritmo de aprendizaje\" eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de función, y porque a menudo puede ser más simple resolver cada subproblema de aprendizaje por separado que atacar el problema de excitación de preferencias directamente. Podemos desarrollar un algoritmo de excitación que se adapta a cada valoración de agentes, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Demostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas de DNF monotono y funciones de umbral lineal se pueden convertir en algoritmos de excitación de preferencia para valoraciones generales, valoraciones con eliminación libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en las representaciones que son polinomialmente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la traqueabilidad computacional [18]. Al interpretar los métodos enfatizamos la expresividad y sucinta de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de licitación, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debe representar sucintamente las funciones más simples y comunes de la clase. 6.1 Las Representaciones Polinómicas Schapire y Sellie [17] dan un \"algoritmo de aprendizaje\" para polinomios multivariables escasos que pueden utilizarse como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas apropiadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados de t-sparse sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-sparse tiene como máximo t términos, donde un término es un producto de variables, por ejemplo. x1x3x4. Un polinomio sobre los números reales tiene coeficientes extraídos de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M →  se puede escribir exclusivamente como un polinomio [17]. Para tener una idea de la sucintaidad de los polinomios como lenguaje de licitación, considere las valoraciones aditivas y mono-ítem presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es el número de mercancías que contiene el paquete. En la valoración de un solo elemento, todos los paquetes tienen valor 1, excepto el valor 0 (i.e. el agente está satisfecho tan pronto como ha adquirido un único artículo). No es difícil demostrar que la valoración de un solo elemento requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Por lo tanto, los polinomios son adecuados para valoraciones que en su mayoría son aditivas, con algunas sustituibilidades y complementariedades que pueden introducirse ajustando los coeficientes. El \"algoritmo de aprendizaje\" para polinomios hace como máximo consultas de equivalencia mti +2 y como máximo (mti +1) (t2 i +3ti)/2 consultas de membresía a un agente i, donde ti es la esparcidad del polinomio que representa vi [17]. Por lo tanto, se obtiene un algoritmo que provoca valoraciones generales con un número polinomio de consultas y comunicación polinomio.6 6.2 XOR Representaciones El lenguaje de licitación XOR es estándar en la literatura de subastas combinatoria. Recordemos que una oferta XOR se caracteriza por un conjunto de paquetes B  2M y una función de valor w : B →  definida en esos paquetes, que induce la función de valoración: v(B) = max {B  B  B  B} w(B) (7) Las ofertas XOR pueden representar valoraciones que satisfacen la libre eliminación (y sólo tales valoraciones), que de nuevo es la propiedad que A  B El lenguaje de licitación XOR es ligeramente menos expresivo que los polinomios, porque los polinomios pueden representar valoraciones que no satisfacen la libre eliminación. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas de XOR pueden representar la valoración de un solo elemento con ofertas atómicas m, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario se aplica a los polinomios, estas dos lenguas son incomparables en sucintas y algo complementarias para su uso práctico. Blum et al. [5] note que las fórmulas DNF monotonas son los análogos de las pujas XOR en la literatura de teoría del aprendizaje. Una fórmula de DNF monotona es una disyunción de conjunciones en las que las variables aparecen sin negación, por ejemplo x1x2 x3 x2x4x5. Tenga en cuenta que tales fórmulas pueden ser representadas como ofertas XOR donde cada oferta atómica tiene valor 1; por lo tanto XOR ofrece generalizar fórmulas DNF monotono de Boolean a funciones de valor real. Estas ideas nos permiten generalizar un \"algoritmo de aprendizaje\" clásico para el DNF monotono ([3] Teorema 6 Tenga en cuenta que el Teorema 1 se aplica incluso si las valoraciones no satisfacen la eliminación libre. 185 1, [18] Teorema B) a un \"algoritmo de aprendizaje\" para ofertas XOR.7 Lemma 2. Una oferta XOR que contiene ofertas t atómicas se puede aprender exactamente con consultas de equivalencia t + 1 y a lo sumo consultas de membresía tm. Prueba. El algoritmo identificará cada puja atómica en la puja XOR objetivo a su vez. Initialice la valoración manifiesta v a la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presente ‡v como consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un paquete S para el que v(S) = Crear un paquete T de la siguiente manera. Primero inicialice T = S. Para cada elemento i en T, compruebe a través de una consulta de membresía si v(T) = v(T − {i}). Si así se establece T = T − {i}. De lo contrario, deje T como está y pase al siguiente punto. Afirmamos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada ítem i en T, tenemos v(T) = v(T − {i}). Para ver esto, tenga en cuenta que en algún momento al generar T, tuvimos un ̄T tal que T  ̄T  S y v( ̄T) > v( ̄T − {i}), de modo que me mantuvo en ̄T. Tenga en cuenta que v(S) = v( ̄T) = v(T) porque el valor del paquete S se mantiene durante todo el proceso de eliminación de elementos. Ahora asume v(T) = v(T − {i}). Entonces v( ̄T) = v(T) = v(T − {i}) > v( ̄T − {i}) que contradice la libre eliminación, ya que T {i}  ̄T − {i}. Por lo tanto v(T) > v(T − {i}) para todos los ítems i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si este no fuera el caso, T tomaría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = máx itat {max T T Ahora mostramos que v(T) = ̃v(T), que implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Asumir que toda oferta atómica (R, Esta suposición se mantiene vagamente cuando se inicializa la valoración manifiesta. Usando la notación de (7), dejar ( Tenemos B  B, y Bw(B) = w(B) para B Por lo tanto,?v(S) = max {B} {B} {B} {B} {B} {B} = max {B} {B} {B} ≤ {B} {B} {B} {B} {S} w(B} = v(S) (8) Ahora asume v(T) {v(T La segunda igualdad se deriva del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad sostiene porque S es un contraejemplo de la valoración manifiesta. De la ecuación (9) y la eliminación libre, nosotros 7 El algoritmo citado también se utilizó como base para Zinkevich et al.s [19] algoritmo de excitación para Toolbox DNF. Recuerde que Toolbox DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia se puede simular con una consulta de valor en el paquete que contiene todas las mercancías. que tengan ‡v(T) < Entonces de nuevo de la ecuación (9) se deduce que v(S) < Esto contradice (8), por lo que de hecho tenemos v(T) = Por lo tanto (T, v(T)) no está actualmente en nuestra hipótesis como una oferta atómica, o tendríamos correctamente?v(T) = v(T) por la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas adicionales de equivalencia hasta que todas las ofertas atómicas hayan sido identificadas. Después de cada consulta de equivalencia, una oferta atómica se identifica con como máximo m consultas de membresía. Cada contraejemplo conduce al descubrimiento de una nueva oferta atómica. Por lo tanto, hacemos a lo sumo consultas de membresía tm y exactamente consultas de equivalencia t + 1. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR se puede obtener eficientemente de las consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al.s ([5], Teorema 2) afirmando que el DNF monotono (y por lo tanto las ofertas XOR) no se pueden obtener de manera eficiente cuando las consultas de demanda se limitan a precios lineales y anónimos sobre las mercancías. 6.3 Las representaciones lineales de umbral polinomios, las ofertas XOR y todas las lenguas basadas en el lenguaje de licitación OR (como XOR-de-OR, OR-de-XOR y OR*) no representan sucintamente la valoración mayoritaria [11]. En esta valoración, los paquetes tienen valor 1 si contienen al menos m/2 ítems, y valor 0 de lo contrario. Más generalmente, considere la familia de r-of-S de valoraciones donde los paquetes tienen valor 1 si contienen al menos r artículos de un conjunto especificado de ítems S  M, y valor 0 de otra manera. La valoración mayoritaria es un caso especial de la valoración de r-of-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar las sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede añadir valor. Dejando k = S, tales valoraciones están sucintamente representadas por funciones de umbral r-of-k. Estas funciones adoptan la forma de desigualdades lineales: xi1 +. . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se mantiene, y 0 de lo contrario. Aquí i1,. . . , ik son los elementos en S. Littlestones WINNOW 2 algoritmo puede aprender tales funciones utilizando consultas de equivalencia sólo, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de excitación que resulta de WINNOW 2 sólo utiliza consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos están implícitos cuando sólo hay dos valores posibles). Tenga en cuenta que las funciones de umbral r-of-k siempre se pueden representar sucintamente en el espacio O(m). Así se obtiene un algoritmo que puede generar tales funciones con un número polinomio de consultas y comunicación polinomio, en los parámetros n y m solos. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exactos con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de excitación de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas en el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la riqueza de algoritmos de aprendizaje disponibles al problema de la excitación de preferencias. Un enfoque de aprendizaje para la excitación también motiva un enfoque diferente para diseñar algoritmos de excitación que se descomponen cuidadosamente entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivos, muchos sustitutos, etc.), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de excitación. El algoritmo de excitación resultante hace un número polinomio de consultas, y hace comunicación polinomio si los algoritmos de aprendizaje originales son eficientes. No exigimos que las valoraciones de agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia sólo pueden ser, y sólo necesitan ser, simuladas hasta el punto en que se ha calculado una asignación óptima. Este es el problema de la excitación de preferencias. Teorema 1 implica que la excitación con consultas de valor y demanda no es más difícil que aprender con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las que la excitación es más fácil que el aprendizaje. Blum et al. [5] proporcionar tal ejemplo al considerar solamente consultas de membresía/valor (Teorema 4). En el trabajo futuro planeamos abordar la cuestión de los incentivos al convertir algoritmos de aprendizaje a algoritmos de excitación. En el entorno de aprendizaje, por lo general suponemos que los oráculos proporcionarán respuestas honestas a las preguntas; en el entorno de excitación, los agentes son generalmente egoístas y proporcionarán respuestas posiblemente deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para el aprendizaje de polinomios y ofertas XOR como algoritmos de excitación, y probar su rendimiento contra otros protocolos de subasta combinatoria establecidos [6, 15]. Una pregunta interesante aquí es: ¿qué precios Lindahl en el rango máximo a mínimo son los mejores para citar con el fin de minimizar la revelación de información? Suponemos que la revelación de información se reduce al pasar de precios máximos a precios mínimos de Lindahl, es decir, a medida que desplazamos las consultas de demanda más lejos de las consultas de equivalencia. Por último, sería útil determinar si el lenguaje de licitación de OR* [11] puede aprenderse (y, por lo tanto, obtenerse) de manera eficiente, dada la expresividad y sucinta de estas lenguas para una amplia variedad de clases de valoración. Agradecimientos Queremos agradecer a Debasis Mishra por sus útiles discusiones. Este trabajo está apoyado en parte por la subvención de NSF IIS0238147. 8. REFERENCIAS [1] A. Andersson, M. Tenhunen, y F. Ygge. Programación integral para la determinación del ganador de la subasta combinatoria. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprender conjuntos regulares de consultas y contraejemplos. Información e computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje conceptual. Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El modelo de asignación de paquetes. Diario de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Provocación de preferencias y aprendizaje de consultas. En Proc. 16a Conferencia Anual sobre Teoría del Aprendizaje Computacional (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. la 18a Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, e Y. Shoham. Domar la complejidad computacional de las subastas combinatoria: Enfoques óptimos y aproximados. En Proc. , 16a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), págs. 548 a 553, 1999. [8] B. Hudson y T. Sandholm. Uso de consultas de valor en subastas combinatoria. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría del aprendizaje computacional. MIT Press, 1994. [10] N. Littlestone. Aprender rápidamente cuando los atributos irrelevantes abundan: Un nuevo algoritmo de umbral lineal. Machine Learning, 2:285-318, 1988. [11] N. Nisan. Licitación y asignación en subastas combinatoria. En Proc. la Conferencia de la ACM sobre Comercio Electrónico, págs. 1 a 12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y el apoyo a los precios Lindahl. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de mínima revelación. En Padget et al., editor, Agent-Mediated Electronic Commerce IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. Diseño de subastas con costosas preferencias. En Temas Especiales de Anales de Matemáticas y AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17a Conferencia Nacional sobre Inteligencia Artificial (AAAI-00), págs. 74 a 81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. la 17a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariables escasos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de ACM sobre Teoría del Aprendizaje Computacional, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendido. Comun. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum, y T. Sandholm. Sobre la excitación de la preferencia polinomio-tiempo con las consultas de valor. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "error": [
                ""
            ]
        },
        "preference elicitation algorithm": {
            "translated_key": [
                "algoritmo de excitación de preferencia",
                "algoritmo de excitación de preferencia eficiente",
                "algoritmo de excitación de preferencia"
            ],
            "translated_annotated_text": "Aplicando algoritmos de aprendizaje a la eliminación de preferencia Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de excitación Demostramos que los algoritmos de aprendizaje pueden ser usados como base para algoritmos de excitación de preferencias. Los algoritmos de excitación resultantes realizan un número polinomio de consultas. También damos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. En particular, se obtiene un algoritmo que provoca pujas XOR con comunicación polinómica. Categorías y Descriptores sujetos F.2.0 [Análisis de algoritmos y complejidad de problemas]: General; J.4 [Ciencias Sociales y Conductuales]: Economía; I.2.6 [Inteligencia Artificial]: Términos generales de aprendizaje Algoritmos, Economía, Teoría 1. INTRODUCCIÓN En una subasta combinatoria, los agentes pueden pujar por paquetes de bienes en lugar de por cada uno de ellos. Puesto que hay un número exponencial de paquetes (en el número de bienes), comunicar los valores sobre estos paquetes puede ser problemático. Comunicar las valoraciones de una sola vez puede ser prohibitivamente costoso si el número de bienes es sólo moderadamente grande. Además, incluso podría ser difícil para los agentes determinar sus valoraciones para paquetes únicos [14]. A esos agentes les interesa disponer de protocolos de subasta que les obliguen a pujar en el menor número posible de paquetes. Incluso si los agentes pueden calcular eficientemente sus valoraciones, podrían ser reacios a revelarlas enteramente en el curso de una subasta, porque tal información puede ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información necesaria para determinar una asignación óptima de los bienes. Ha habido un trabajo reciente explorando los vínculos entre el problema de la excitación de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje computacional [5, 19]. En teoría de aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, tales como ¿Cuál es el valor de las funciones en estas entradas? En la obtención de preferencia, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Demostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia se puede convertir en un \"algoritmo de excitación de preferencia\" con consultas de valor y demanda. El algoritmo de excitación resultante garantiza la excitación en un número polinomio de consultas de valor y demanda. Aquí queremos decir polinomio en el número de bienes, agentes, y los tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Argumentamos que las garantías de complejidad para los esquemas de excitación deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar la comunicación polinómica en el peor de los casos, que normalmente no se puede lograr en el número de productos y agentes por sí solos. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. Por supuesto, una subasta combinatoria de un solo disparo donde los agentes proporcionan todas sus funciones de valoración a la vez también tendría comunicación polinómica en el tamaño de las valoraciones de los agentes, y sólo requieren una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay ninguna carga para los agentes de formular sus valoraciones en un esquema de codificación de los subastadores que elijan. Esperamos que esta sea una consideración importante en la práctica. Además, con nuestro esquema la revelación entera sólo ocurre en el peor de los casos. 180 Por ahora, dejamos a un lado la cuestión de los incentivos al derivar algoritmos de excitación. Nos centramos en el tiempo y la complejidad de la comunicación de la obtención de preferencias, independientemente de las limitaciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich y otros [19] considerar el problema del aprendizaje de clases restringidas de funciones de valoración que se pueden representar utilizando fórmulas de lectura once y Toolbox DNF. Las fórmulas Read-once pueden representar ciertas sustitutibilidades, pero no complementariedades, mientras que lo contrario se mantiene para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten depender del tamaño de la valoración objetivo como lo hacemos (aunque las valoraciones de read-once siempre se pueden representar sucintamente de todos modos). Su trabajo sólo hace uso de consultas de valor, que son bastante limitados en el poder. Debido a que nos permitimos pedir consultas, somos capaces de derivar un esquema de excitación para las funciones de valoración general. Blum et al. [5] proporcionar resultados relacionados con las complejidades del aprendizaje de la consulta y la excitación de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje de consultas, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones se pueden aprender eficientemente, pero no se pueden obtener eficientemente, y viceversa. En contraste, nuestro trabajo muestra que dada una versión más general (todavía bastante estándar) de la consulta de demanda que el tipo que consideran, la complejidad de la excitación de preferencia no es mayor que la complejidad del aprendizaje. Demostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre valoraciones para implicar una solución al problema de excitación. Nisan y Segal [12] estudian la complejidad comunicativa de la excitación de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos de la computación una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo se permite a los algoritmos hacer preguntas sobre valoraciones de agentes y recibir respuestas honestas, sin ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda la cuestión de la complejidad de la comunicación, y somos capaces de derivar algoritmos que proporcionan garantías de comunicación significativas a pesar de los resultados negativos de Nisan y Segals. Su trabajo motiva la necesidad de confiar en el tamaño de los agentes funciones de valoración para indicar los peores resultados. 2. LOS MODELOS 2.1 Aprendizaje de la consulta El modelo de aprendizaje de la consulta que consideramos aquí se llama aprendizaje exacto de la membresía y consultas de equivalencia, introducido por Angluin [2]. En este modelo el objetivo de los algoritmos de aprendizaje es identificar exactamente una función diana desconocida f : X → Y a través de consultas a un oráculo. La función de destino se extrae de una función de clase C que es conocida por el algoritmo. Típicamente el dominio X es algún subconjunto de {0, 1}m, y el rango Y es {0, 1} o algún subconjunto de los números reales. A medida que el algoritmo avanza, construye una hipótesis manifiesta?f que es su estimación actual de la función de destino. Después de la terminación, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface?f(x) = f(x) para todos x?X. Es importante especificar la representación que se utilizará para codificar funciones de C. Por ejemplo, considere la siguiente función de {0, 1}m a ♥: f(x) = 2 si x consiste en m 1s, y f(x) = 0 de otra manera. Esta función puede representarse simplemente como una lista de valores de 2m. O puede codificarse como el polinomio 2x1 · · · xm, que es mucho más sucinto. Así pues, la elección de la codificación puede tener un impacto significativo en las necesidades de tiempo y espacio del algoritmo de aprendizaje. Let size(f) ser el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes distintos de cero en el polinomio, por ejemplo. Por lo general, sólo nos referiremos a las clases de representación; las clases de funciones correspondientes serán implícitas. Por ejemplo, la clase de representación de fórmulas DNF monotonas implica la clase de función de funciones booleanas monotonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: la membresía y las consultas de equivalencia. En una consulta de membresía, el aprendiz presenta algunas x x x y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta f. El oráculo responde SÍ si?f = f, o devuelve un contraejemplo x de tal manera que?f(x) = f(x). Una consulta de equivalencia es apropiada si el tamaño( ̃f) ≤ tamaño(f) en el momento de presentar la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones se adaptan a partir de Kearns y Vazirani [9]: Definición 1. La clase de representación C es polinomialquery exactamente aprendeble de las consultas de membresía y equivalencia si hay un polinomial fijo p(·, ·) y un algoritmo L con acceso a la membresía y consultas de equivalencia de un oráculo tal que para cualquier función de destino f • C, L salidas después de a lo sumo p(size(f), m) consultas de una función?f • C tal que?f Del mismo modo, la clase de representación C se puede aprender exactamente de las consultas de membresía y equivalencia si el algoritmo L produce una hipótesis correcta en el tiempo p(size(f), m), para algunos polinomios fijos p(·, ·). Aquí m es la dimensión del dominio. Dado que la función de destino debe ser reconstruida, también permitimos necesariamente la dependencia polinómica del tamaño (f). 2.2 Eliminación de preferencias En una subasta combinatoria, un conjunto de bienes M se asignará entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Tal asignación se llama eficiente en la literatura de economía, pero nos referiremos a ella como óptima y reservar el término eficiente para referirse a la eficiencia computacional. Dejamos n = N y m = M. Una asignación es una partición de los objetos en paquetes (S1,. . . , Sn), de tal manera que Si â € ¬ Sj = â € para todos los i, j â € N. Let â € € sea el conjunto de posibles asignaciones. Cada agente i+N tiene una función de valoración vi : 2M → • sobre el espacio de los paquetes posibles. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no tienen que coincidir. Asumimos que todas las valoraciones consideradas están normalizadas, es decir, v() = 0, y que no hay externalidades, es decir, vi(S1,..., Sn) = vi(Si), para todos los agentes i  N, para cualquier asignación (S1,..., Sn)  (es decir, un agente se preocupa sólo por el paquete asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales.1 Nosotros 1 A menudo las valoraciones generales se hacen para satisfacer los 181 adicionales también asumen que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que los agentes utilidades pueden ser divididos en componentes monetarios y no monetarios. Si a un agente i se le asigna el paquete S al precio p, deriva utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más sucintas para ciertas clases de valoración, y ha habido mucha investigación en lenguajes de licitación concisos para diversos tipos de valoraciones [11]. Un ejemplo clásico al que nos referiremos más adelante es el lenguaje de licitación XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, que consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estas pujas, se busca el paquete S del valor más alto listado en las pujas atómicas de tal manera que S  S. Es entonces el caso que v(S) = v(S). Al igual que en el contexto de la teoría del aprendizaje, por lo general sólo nos referiremos a idiomas de oferta en lugar de clases de valoración, ya que las clases de valoración correspondientes serán implícitas. Por ejemplo, el lenguaje de licitación XOR implica la clase de valoraciones que satisfacen la disposición libre, que es la condición de que A  B ♥ v(A) ≤ v(B). Dejamos el tamaño(v1,. . . , vn) = Èn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de licitación). Para hacer una analogía con la teoría del aprendizaje computacional, suponemos que todas las clases de representación consideradas son polinomiamente interpretables [11], lo que significa que el valor de un paquete puede ser calculado en tiempo polinomio dada la representación de funciones de valoración. Más formalmente, una clase de representación (lenguaje de licitación) C es polinomialmente interpretable si existe un algoritmo que da como entrada algunos v • C y una instancia x • X calcula el valor v(x) en el tiempo q(size(v), m), para algún polinomio fijo q(·, ·).2 En las rondas intermedias de una subasta (terativa), el subastador habrá obtenido información sobre las funciones de Por lo tanto, habrá construido un conjunto de valoraciones manifiestas, denotadas . . Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha adquirido información sobre ciertos paquetes. El objetivo en el problema de la excitación de preferencia es construir un conjunto de valoraciones manifiestas tales que: arg max (S1,...,Sn) iÃ3n Ã3vi(Si)  arg max (S1,...,Sn) iÃ3n vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que es óptima con respecto a las valoraciones verdaderas. Tenga en cuenta que sólo se requiere una asignación óptima. condición de la libre eliminación (monotonicidad), pero no la necesitamos en este punto. 2 Esto excluye OR*, asumiendo P = NP, porque la interpretación de las ofertas de este lenguaje es NP-duro por reducción de set-embalaje ponderado, y no hay clase de representación bien estudiada en teoría de aprendizaje que es claramente análogo a OR*. 3 Esta visión de las subastas iterativas tiene por objeto paralelizar el entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente están implícitas por la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son consultas de valor y demanda. En una consulta de valor, el subastador presenta un paquete S  M y el agente responde con su valor (exacto) para el paquete v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p • • • (2m ) sobre los paquetes junto con un paquete S. El agente responde SI si es el caso de que S • arg max S M v(S ) − p(S ) ¡ o de otro modo presenta un paquete S tal que v(S ) − p(S ) > v( Tenga en cuenta también que comunicar precios no lineales no implica necesariamente citar un precio por cada paquete posible. Puede haber formas más sucintas de comunicar este vector, como se muestra en la sección 5. Hacemos las siguientes definiciones para paralelizar la configuración de aprendizaje de la consulta y para simplificar las declaraciones de resultados posteriores: Definición 2. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si hay un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes tales que para cualquier (v1,. . . , vn) V1 ×. . . × Vn, L salidas después de como máximo p(size(v1,. . . , vn), m) consulta una asignación (S1,. . . , Sn) arg max(S1,...,Sn) È vi(Si). Del mismo modo, la clase de representación C se puede obtener eficientemente de las consultas de valor y demanda si el algoritmo L produce una asignación óptima con comunicación p(size(v1, ). . . , vn), m), para algunos polinomios fijos p(·, ·). Hay algunas diferencias clave aquí con la definición de aprendizaje de la consulta. Hemos eliminado el término exactamente ya que las funciones de valoración no necesitan ser determinadas exactamente con el fin de calcular una asignación óptima. Además, un algoritmo de excitación eficiente es la comunicación polinomio, en lugar de tiempo polinomio. Esto refleja el hecho de que la comunicación en lugar del tiempo de espera es el cuello de botella en la excitación. Cálculo de una asignación óptima de bienes incluso cuando se dan las valoraciones verdaderas es NP-duro para una amplia gama de clases de valoración. Por lo tanto, no es razonable exigir tiempo polinomio en la definición de un \"algoritmo de excitación de preferencia eficiente\". Nos complace centrarnos en la complejidad comunicativa de la excitación porque se cree que este problema es más significativo en la práctica que el de la determinación del ganador [11].5 4 Esto difiere ligeramente de la definición proporcionada por Blum et al. [5] Sus consultas sobre la demanda se limitan a precios lineales sobre las mercancías, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir. un precio distinto por cada paquete posible. Es por eso que el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. 5 Aunque el problema de determinación del ganador es NP-hard para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta aproximaciones usando solucionadores IP fuera de la plataforma [1]. 182 Dado que no es necesario obtener exactamente las valoraciones, es inicialmente menos claro si la dependencia polinómica del tamaño (v1, ). . . , vn) está justificado en este contexto. Intuitivamente, este parámetro está justificado porque debemos aprender valoraciones exactamente cuando se realiza la excitación, en el peor de los casos. Nos ocupamos de esto en la siguiente sección. 3. PARALLESBETWEEN EQUIVALENCIA Y QUERIDAS DE DEMANDA Hemos descrito los ajustes de aprendizaje y excitación de preferencias de la consulta de una manera que destaca sus similitudes. Las consultas de valor y membresía son claras analógicas. Un poco menos obvio es el hecho de que las consultas de equivalencia y demanda también son analógicas. Para ver esto, necesitamos el concepto de precios Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios sobre sus bienes subyacentes. Son no anónimos en el sentido de que dos agentes pueden tener que hacer frente a precios diferentes para el mismo paquete de mercancías. Así los precios de Lindahl son de la forma pi(S), para todos S  M, para todos los precios de i  N. Lindahl se presentan a los agentes en consultas de la demanda. Cuando los agentes han normalizado las funciones de utilidad cuasi-lineal, Bikhchandani y Ostroy [4] muestran que siempre existen precios Lindahl tales que (S1,. . . , Sn) es una asignación óptima si y sólo si Si • arg max Si vi(Si) − pi(Si) • i N (1) (S1,. . . , Sn)  arg max (S1,...,Sn) iN pi(Si) (2) Condición (1) establece que cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos de los subastadores a los precios indicados. El escenario en el que se mantienen estas condiciones se llama equilibrio Lindahl, o a menudo un equilibrio competitivo. Decimos que los precios de Lindahl apoyan la asignación óptima. Por lo tanto, basta con anunciar los precios de apoyo de Lindahl para verificar una asignación óptima. Una vez que hemos encontrado una asignación con el apoyo de precios Lindahl, el problema de excitación se resuelve. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones estén garantizadas como integrales [4]. Las variables duales de este programa lineal están soportando los precios de Lindahl para la asignación resultante. La función objetiva del programa dual es: min pi(S) Por lo general, hay una gama de posibles precios Lindahl que apoyan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios válidos Lindahl, y nos referimos a ellos como precios máximos Lindahl. De todos los vectores posibles de precios Lindahl, precios máximos Lindahl maximizar la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È iÃ3N πi del objetivo (la suma de los agentes de utilidades) son precios mínimos Lindahl. Cualquier Lindahl precios hará para nuestros resultados, pero algunos pueden tener mejores propiedades de excitación que otros. Tenga en cuenta que una consulta de demanda con precios máximos de Lindahl es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para el trabajo futuro la cuestión de los precios de Lindahl para elegir minimizar la obtención de preferencias. Teniendo en cuenta ahora por qué las consultas de demanda y equivalencia son analógicas directas, primero tenga en cuenta que dado el πi en algún equilibrio Lindahl, establecer pi(S) = max{0, Estos precios dejan a cada agente indiferente en todos los paquetes con precio positivo, y satisfacen la condición (1). Así, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl típicamente serán una constante aditivo lejos de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos de consultas de equivalencia a través de consultas de demanda. Lemma 1. Supongamos que un agente responde con un paquete preferido S cuando se propone un paquete S y soporta los precios de Lindahl p(S) (soportando con respecto a la valoración manifiesta de los agentes). A continuación, o bien?v(S) = v(S) o?v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: Φv(S) − p(S) ≥ Desigualdad (6) se mantiene porque el agente de hecho prefiere S a S dados los precios, de acuerdo con su respuesta a la consulta de demanda. Si fuera el caso de que?v(S) = v(S) y Así, al menos uno de S y S es un contraejemplo de la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño(v1,. . . , vn) en problemas de excitación. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que apoyar los precios de Lindahl debe necesariamente revelarse en el curso de cualquier protocolo de obtención de preferencias que termina con una asignación óptima. Además, Nisan y Segal (Lemma 1, [12]) afirman que en el peor de los casos los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones dobles (como será el caso de las clases más interesantes). Puesto que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y puesto que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitiendo la dependencia del tamaño(v1,. . . , vn) en problemas de excitación es totalmente natural. 183 4. DE APRENDIZAJE A LA LICITACIÓN DE PREFERENCIA La clave para convertir un algoritmo de aprendizaje a un algoritmo de excitación es simular consultas de equivalencia con consultas de demanda y valor hasta que se encuentre una asignación óptima. Debido a nuestra construcción de precios Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en que un agente responde SÍ a una consulta de equivalencia cuando la función de destino se ha aprendido exactamente. De lo contrario, podemos obtener un contraejemplo a una consulta de equivalencia dada una respuesta de agentes a una consulta de demanda. Teorema 1. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si cada uno puede ser polinomio-consulta exactamente aprendido de consultas de membresía y equivalencia. Prueba. Considere el algoritmo de excitación en la Figura 1. Cada consulta de membresía en el paso 1 es simulada con una consulta de valor ya que estas son de hecho idénticas. Considere el paso 4. Si todos los agentes responden SÍ, la condición (1) se mantiene. Condición (2) se mantiene porque la asignación calculada es la maximización de ingresos para el subastador, independientemente de los agentes verdaderas valoraciones. Así pues, se ha encontrado una asignación óptima. De lo contrario, por lo menos uno de Si o Si es un contraejemplo a Vi, por Lemma 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones del agente se conocerán exactamente, en cuyo caso la asignación óptima y los precios Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinomio de consultas, desde A1,. . . , A son todos los algoritmos de aprendizaje polinomio-quería. Tenga en cuenta que el procedimiento de conversión resulta en un \"algoritmo de excitación de preferencia\", no un algoritmo de aprendizaje. Es decir, el algoritmo resultante no simplemente aprender las valoraciones exactamente, a continuación, calcular una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor, y periódicamente comprueba si se ha reunido suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio Lindahl para las valoraciones v1,. . . , vn utilizando una asignación y precios derivados de valoraciones manifiestas . . y encontrar una asignación óptima no implica que las valoraciones de los agentes se hayan aprendido exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta interrupción temprana. No obtendremos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE COMUNICACIÓN En esta sección, pasamos a la cuestión de la complejidad comunicativa de la excitación. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (tales como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos de determinar los precios de Lindahl es exponencial en el número de mercancías, m. La carga de comunicación se mide en términos del número de bits transmitidos entre agentes y subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. La conversión de algoritmos de aprendizaje eficientes a un algoritmo de excitación produce un algoritmo cuyas consultas tienen tamaños polinomios en los parámetros m y tamaño (v1, ). . . , vn). Teorema 2. Las clases de representación V1,. . . , Vn se puede obtener de forma eficiente de las consultas de valor y demanda si cada uno puede ser aprendido exactamente de las consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, basta con comunicar la función de valoración manifiesta de los agentes y el valor Nótese que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinomio, porque el tiempo de ejecución de los algoritmos también sería superpolinomio, contradiciendo la eficiencia. Por lo tanto, la comunicación de la valoración manifiesta requiere tamaño a lo sumo p(size(vi), m), para algunos polinomios p que limita superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representando el excedente πi al agente no se puede requerir espacio mayor que q(size( También debemos comunicarnos con su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es como máximo p(size(vi), m) + q(p(size(vi), m), m)+O(m). Claramente, una respuesta de agentes a una consulta de valor o demanda tiene un tamaño máximo de q(size(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, son siempre de tamaño polinomio. Un algoritmo de aprendizaje eficiente realiza un número polinomio de consultas, por lo que la comunicación total del algoritmo de excitación resultante es polinomio en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites pueden ser traducidos a límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de excitación resultante. Con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2 se determinó el tamaño de la hipótesis manifiesta. Es probable que podamos hacerlo mucho mejor que esto en la práctica. Recuerde que una consulta de equivalencia es apropiada si size( ̃f) ≤ size(f) en el momento de realizar la consulta. Si las consultas de equivalencia de algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites estrechos en los requisitos de comunicación del algoritmo de excitación resultante. El teorema 2 muestra que los algoritmos de excitación que dependen del tamaño (v1,. . . El parámetro, vn) evita los resultados negativos de Nisan y Segals [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto al tamaño de las instancias de las funciones de valoración que se enfrentan a cualquier ejecución del algoritmo. Estos algoritmos van bien si la clase de representación elegida proporciona representaciones sucintas para la más simple y común de las valoraciones, y por lo tanto el enfoque se mueve de nuevo a uno de lenguajes de licitación compactos pero expresivos. A continuación se examinan estas cuestiones. 6. APLICACIONES En esta sección, demostramos la aplicación de nuestros métodos a clases particulares de representación para valoraciones combinatorias. Hemos demostrado que el problema de excitación de preferencias para las clases de valoración V1,. . . , Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1,. . . , Una para las valoraciones de las clases V1,. . . , Vn respectivamente. Encaje hasta que haya una señal para detenerse: 1. Corre A1,. . . , Un en paralelo sobre sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se ha detenido con los agentes valoración exacta. 2. Calcular una asignación óptima (S1,. . . , Sn ) y los correspondientes precios de Lindahl con respecto a las valoraciones manifiestas . . , їvn determinado hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de consulta de demanda. 4. Si todos ellos responden SÍ, salida la asignación y parada. De lo contrario hay algún agente i que ha respondido con algún paquete preferido Si. Realizar consultas de valor en Si y Si para encontrar un contraejemplo a ‡vi, y proporcionarlo a Ai. Figura 1: Convertir algoritmos de aprendizaje a un algoritmo de excitación. al problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de función, y porque a menudo puede ser más simple resolver cada subproblema de aprendizaje por separado que atacar el problema de excitación de preferencias directamente. Podemos desarrollar un algoritmo de excitación que se adapta a cada valoración de agentes, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Demostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas de DNF monotono y funciones de umbral lineal se pueden convertir en algoritmos de excitación de preferencia para valoraciones generales, valoraciones con eliminación libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en las representaciones que son polinomialmente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la traqueabilidad computacional [18]. Al interpretar los métodos enfatizamos la expresividad y sucinta de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de licitación, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debe representar sucintamente las funciones más simples y comunes de la clase. 6.1 Las Representaciones Polinómicas Schapire y Sellie [17] dan un algoritmo de aprendizaje para polinomios multivariables escasos que pueden utilizarse como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas apropiadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados de t-sparse sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-sparse tiene como máximo t términos, donde un término es un producto de variables, por ejemplo. x1x3x4. Un polinomio sobre los números reales tiene coeficientes extraídos de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M →  se puede escribir exclusivamente como un polinomio [17]. Para tener una idea de la sucintaidad de los polinomios como lenguaje de licitación, considere las valoraciones aditivas y mono-ítem presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es el número de mercancías que contiene el paquete. En la valoración de un solo elemento, todos los paquetes tienen valor 1, excepto el valor 0 (i.e. el agente está satisfecho tan pronto como ha adquirido un único artículo). No es difícil demostrar que la valoración de un solo elemento requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Por lo tanto, los polinomios son adecuados para valoraciones que en su mayoría son aditivas, con algunas sustituibilidades y complementariedades que pueden introducirse ajustando los coeficientes. El algoritmo de aprendizaje para polinomios hace como máximo consultas de equivalencia mti +2 y como máximo (mti +1) (t2 i +3ti)/2 consultas de membresía a un agente i, donde ti es la esparcidad del polinomio que representa vi [17]. Por lo tanto, se obtiene un algoritmo que provoca valoraciones generales con un número polinomio de consultas y comunicación polinomio.6 6.2 XOR Representaciones El lenguaje de licitación XOR es estándar en la literatura de subastas combinatoria. Recordemos que una oferta XOR se caracteriza por un conjunto de paquetes B  2M y una función de valor w : B →  definida en esos paquetes, que induce la función de valoración: v(B) = max {B  B  B  B} w(B) (7) Las ofertas XOR pueden representar valoraciones que satisfacen la libre eliminación (y sólo tales valoraciones), que de nuevo es la propiedad que A  B El lenguaje de licitación XOR es ligeramente menos expresivo que los polinomios, porque los polinomios pueden representar valoraciones que no satisfacen la libre eliminación. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas de XOR pueden representar la valoración de un solo elemento con ofertas atómicas m, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario se aplica a los polinomios, estas dos lenguas son incomparables en sucintas y algo complementarias para su uso práctico. Blum et al. [5] note que las fórmulas DNF monotonas son los análogos de las pujas XOR en la literatura de teoría del aprendizaje. Una fórmula de DNF monotona es una disyunción de conjunciones en las que las variables aparecen sin negación, por ejemplo x1x2 x3 x2x4x5. Tenga en cuenta que tales fórmulas pueden ser representadas como ofertas XOR donde cada oferta atómica tiene valor 1; por lo tanto XOR ofrece generalizar fórmulas DNF monotono de Boolean a funciones de valor real. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para el DNF monotono ([3] Teorema 6 Tenga en cuenta que el Teorema 1 se aplica incluso si las valoraciones no satisfacen la eliminación libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lemma 2. Una oferta XOR que contiene ofertas t atómicas se puede aprender exactamente con consultas de equivalencia t + 1 y a lo sumo consultas de membresía tm. Prueba. El algoritmo identificará cada puja atómica en la puja XOR objetivo a su vez. Initialice la valoración manifiesta v a la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presente ‡v como consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un paquete S para el que v(S) = Crear un paquete T de la siguiente manera. Primero inicialice T = S. Para cada elemento i en T, compruebe a través de una consulta de membresía si v(T) = v(T − {i}). Si así se establece T = T − {i}. De lo contrario, deje T como está y pase al siguiente punto. Afirmamos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada ítem i en T, tenemos v(T) = v(T − {i}). Para ver esto, tenga en cuenta que en algún momento al generar T, tuvimos un ̄T tal que T  ̄T  S y v( ̄T) > v( ̄T − {i}), de modo que me mantuvo en ̄T. Tenga en cuenta que v(S) = v( ̄T) = v(T) porque el valor del paquete S se mantiene durante todo el proceso de eliminación de elementos. Ahora asume v(T) = v(T − {i}). Entonces v( ̄T) = v(T) = v(T − {i}) > v( ̄T − {i}) que contradice la libre eliminación, ya que T {i}  ̄T − {i}. Por lo tanto v(T) > v(T − {i}) para todos los ítems i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si este no fuera el caso, T tomaría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = máx itat {max T T Ahora mostramos que v(T) = ̃v(T), que implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Asumir que toda oferta atómica (R, Esta suposición se mantiene vagamente cuando se inicializa la valoración manifiesta. Usando la notación de (7), dejar ( Tenemos B  B, y Bw(B) = w(B) para B Por lo tanto,?v(S) = max {B} {B} {B} {B} {B} {B} = max {B} {B} {B} ≤ {B} {B} {B} {B} {S} w(B} = v(S) (8) Ahora asume v(T) {v(T La segunda igualdad se deriva del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad sostiene porque S es un contraejemplo de la valoración manifiesta. De la ecuación (9) y la eliminación libre, nosotros 7 El algoritmo citado también se utilizó como base para Zinkevich et al.s [19] algoritmo de excitación para Toolbox DNF. Recuerde que Toolbox DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia se puede simular con una consulta de valor en el paquete que contiene todas las mercancías. que tengan ‡v(T) < Entonces de nuevo de la ecuación (9) se deduce que v(S) < Esto contradice (8), por lo que de hecho tenemos v(T) = Por lo tanto (T, v(T)) no está actualmente en nuestra hipótesis como una oferta atómica, o tendríamos correctamente?v(T) = v(T) por la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas adicionales de equivalencia hasta que todas las ofertas atómicas hayan sido identificadas. Después de cada consulta de equivalencia, una oferta atómica se identifica con como máximo m consultas de membresía. Cada contraejemplo conduce al descubrimiento de una nueva oferta atómica. Por lo tanto, hacemos a lo sumo consultas de membresía tm y exactamente consultas de equivalencia t + 1. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR se puede obtener eficientemente de las consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al.s ([5], Teorema 2) afirmando que el DNF monotono (y por lo tanto las ofertas XOR) no se pueden obtener de manera eficiente cuando las consultas de demanda se limitan a precios lineales y anónimos sobre las mercancías. 6.3 Las representaciones lineales de umbral polinomios, las ofertas XOR y todas las lenguas basadas en el lenguaje de licitación OR (como XOR-de-OR, OR-de-XOR y OR*) no representan sucintamente la valoración mayoritaria [11]. En esta valoración, los paquetes tienen valor 1 si contienen al menos m/2 ítems, y valor 0 de lo contrario. Más generalmente, considere la familia de r-of-S de valoraciones donde los paquetes tienen valor 1 si contienen al menos r artículos de un conjunto especificado de ítems S  M, y valor 0 de otra manera. La valoración mayoritaria es un caso especial de la valoración de r-of-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar las sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede añadir valor. Dejando k = S, tales valoraciones están sucintamente representadas por funciones de umbral r-of-k. Estas funciones adoptan la forma de desigualdades lineales: xi1 +. . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se mantiene, y 0 de lo contrario. Aquí i1,. . . , ik son los elementos en S. Littlestones WINNOW 2 algoritmo puede aprender tales funciones utilizando consultas de equivalencia sólo, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de excitación que resulta de WINNOW 2 sólo utiliza consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos están implícitos cuando sólo hay dos valores posibles). Tenga en cuenta que las funciones de umbral r-of-k siempre se pueden representar sucintamente en el espacio O(m). Así se obtiene un algoritmo que puede generar tales funciones con un número polinomio de consultas y comunicación polinomio, en los parámetros n y m solos. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exactos con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de excitación de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas en el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la riqueza de algoritmos de aprendizaje disponibles al problema de la excitación de preferencias. Un enfoque de aprendizaje para la excitación también motiva un enfoque diferente para diseñar algoritmos de excitación que se descomponen cuidadosamente entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivos, muchos sustitutos, etc.), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de excitación. El algoritmo de excitación resultante hace un número polinomio de consultas, y hace comunicación polinomio si los algoritmos de aprendizaje originales son eficientes. No exigimos que las valoraciones de agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia sólo pueden ser, y sólo necesitan ser, simuladas hasta el punto en que se ha calculado una asignación óptima. Este es el problema de la excitación de preferencias. Teorema 1 implica que la excitación con consultas de valor y demanda no es más difícil que aprender con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las que la excitación es más fácil que el aprendizaje. Blum et al. [5] proporcionar tal ejemplo al considerar solamente consultas de membresía/valor (Teorema 4). En el trabajo futuro planeamos abordar la cuestión de los incentivos al convertir algoritmos de aprendizaje a algoritmos de excitación. En el entorno de aprendizaje, por lo general suponemos que los oráculos proporcionarán respuestas honestas a las preguntas; en el entorno de excitación, los agentes son generalmente egoístas y proporcionarán respuestas posiblemente deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para el aprendizaje de polinomios y ofertas XOR como algoritmos de excitación, y probar su rendimiento contra otros protocolos de subasta combinatoria establecidos [6, 15]. Una pregunta interesante aquí es: ¿qué precios Lindahl en el rango máximo a mínimo son los mejores para citar con el fin de minimizar la revelación de información? Suponemos que la revelación de información se reduce al pasar de precios máximos a precios mínimos de Lindahl, es decir, a medida que desplazamos las consultas de demanda más lejos de las consultas de equivalencia. Por último, sería útil determinar si el lenguaje de licitación de OR* [11] puede aprenderse (y, por lo tanto, obtenerse) de manera eficiente, dada la expresividad y sucinta de estas lenguas para una amplia variedad de clases de valoración. Agradecimientos Queremos agradecer a Debasis Mishra por sus útiles discusiones. Este trabajo está apoyado en parte por la subvención de NSF IIS0238147. 8. REFERENCIAS [1] A. Andersson, M. Tenhunen, y F. Ygge. Programación integral para la determinación del ganador de la subasta combinatoria. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprender conjuntos regulares de consultas y contraejemplos. Información e computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje conceptual. Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El modelo de asignación de paquetes. Diario de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Provocación de preferencias y aprendizaje de consultas. En Proc. 16a Conferencia Anual sobre Teoría del Aprendizaje Computacional (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. la 18a Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, e Y. Shoham. Domar la complejidad computacional de las subastas combinatoria: Enfoques óptimos y aproximados. En Proc. , 16a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), págs. 548 a 553, 1999. [8] B. Hudson y T. Sandholm. Uso de consultas de valor en subastas combinatoria. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría del aprendizaje computacional. MIT Press, 1994. [10] N. Littlestone. Aprender rápidamente cuando los atributos irrelevantes abundan: Un nuevo algoritmo de umbral lineal. Machine Learning, 2:285-318, 1988. [11] N. Nisan. Licitación y asignación en subastas combinatoria. En Proc. la Conferencia de la ACM sobre Comercio Electrónico, págs. 1 a 12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y el apoyo a los precios Lindahl. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de mínima revelación. En Padget et al., editor, Agent-Mediated Electronic Commerce IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. Diseño de subastas con costosas preferencias. En Temas Especiales de Anales de Matemáticas y AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17a Conferencia Nacional sobre Inteligencia Artificial (AAAI-00), págs. 74 a 81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. la 17a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariables escasos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de ACM sobre Teoría del Aprendizaje Computacional, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendido. Comun. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum, y T. Sandholm. Sobre la excitación de la preferencia polinomio-tiempo con las consultas de valor. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "error": [
                "algoritmo de excitación de preferencia",
                "algoritmo de excitación de preferencia eficiente",
                "algoritmo de excitación de preferencia"
            ]
        },
        "elicitation algorithm": {
            "translated_key": "algoritmo de eliminación",
            "translated_annotated_text": "Aplicando algoritmos de aprendizaje a la eliminación de preferencia Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de excitación Demostramos que los algoritmos de aprendizaje pueden ser usados como base para algoritmos de excitación de preferencias. Los algoritmos de excitación resultantes realizan un número polinomio de consultas. También damos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. En particular, se obtiene un algoritmo que provoca pujas XOR con comunicación polinómica. Categorías y Descriptores sujetos F.2.0 [Análisis de algoritmos y complejidad de problemas]: General; J.4 [Ciencias Sociales y Conductuales]: Economía; I.2.6 [Inteligencia Artificial]: Términos generales de aprendizaje Algoritmos, Economía, Teoría 1. INTRODUCCIÓN En una subasta combinatoria, los agentes pueden pujar por paquetes de bienes en lugar de por cada uno de ellos. Puesto que hay un número exponencial de paquetes (en el número de bienes), comunicar los valores sobre estos paquetes puede ser problemático. Comunicar las valoraciones de una sola vez puede ser prohibitivamente costoso si el número de bienes es sólo moderadamente grande. Además, incluso podría ser difícil para los agentes determinar sus valoraciones para paquetes únicos [14]. A esos agentes les interesa disponer de protocolos de subasta que les obliguen a pujar en el menor número posible de paquetes. Incluso si los agentes pueden calcular eficientemente sus valoraciones, podrían ser reacios a revelarlas enteramente en el curso de una subasta, porque tal información puede ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información necesaria para determinar una asignación óptima de los bienes. Ha habido un trabajo reciente explorando los vínculos entre el problema de la excitación de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje computacional [5, 19]. En teoría de aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, tales como ¿Cuál es el valor de las funciones en estas entradas? En la obtención de preferencia, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Demostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia se puede convertir en un \"algoritmo de eliminación\" de preferencia con consultas de valor y demanda. El \"algoritmo de eliminación\" resultante garantiza la excitación en un número polinomio de consultas de valor y demanda. Aquí queremos decir polinomio en el número de bienes, agentes, y los tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Argumentamos que las garantías de complejidad para los esquemas de excitación deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar la comunicación polinómica en el peor de los casos, que normalmente no se puede lograr en el número de productos y agentes por sí solos. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. Por supuesto, una subasta combinatoria de un solo disparo donde los agentes proporcionan todas sus funciones de valoración a la vez también tendría comunicación polinómica en el tamaño de las valoraciones de los agentes, y sólo requieren una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay ninguna carga para los agentes de formular sus valoraciones en un esquema de codificación de los subastadores que elijan. Esperamos que esta sea una consideración importante en la práctica. Además, con nuestro esquema la revelación entera sólo ocurre en el peor de los casos. 180 Por ahora, dejamos a un lado la cuestión de los incentivos al derivar algoritmos de excitación. Nos centramos en el tiempo y la complejidad de la comunicación de la obtención de preferencias, independientemente de las limitaciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich y otros [19] considerar el problema del aprendizaje de clases restringidas de funciones de valoración que se pueden representar utilizando fórmulas de lectura once y Toolbox DNF. Las fórmulas Read-once pueden representar ciertas sustitutibilidades, pero no complementariedades, mientras que lo contrario se mantiene para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten depender del tamaño de la valoración objetivo como lo hacemos (aunque las valoraciones de read-once siempre se pueden representar sucintamente de todos modos). Su trabajo sólo hace uso de consultas de valor, que son bastante limitados en el poder. Debido a que nos permitimos pedir consultas, somos capaces de derivar un esquema de excitación para las funciones de valoración general. Blum et al. [5] proporcionar resultados relacionados con las complejidades del aprendizaje de la consulta y la excitación de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje de consultas, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones se pueden aprender eficientemente, pero no se pueden obtener eficientemente, y viceversa. En contraste, nuestro trabajo muestra que dada una versión más general (todavía bastante estándar) de la consulta de demanda que el tipo que consideran, la complejidad de la excitación de preferencia no es mayor que la complejidad del aprendizaje. Demostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre valoraciones para implicar una solución al problema de excitación. Nisan y Segal [12] estudian la complejidad comunicativa de la excitación de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos de la computación una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo se permite a los algoritmos hacer preguntas sobre valoraciones de agentes y recibir respuestas honestas, sin ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda la cuestión de la complejidad de la comunicación, y somos capaces de derivar algoritmos que proporcionan garantías de comunicación significativas a pesar de los resultados negativos de Nisan y Segals. Su trabajo motiva la necesidad de confiar en el tamaño de los agentes funciones de valoración para indicar los peores resultados. 2. LOS MODELOS 2.1 Aprendizaje de la consulta El modelo de aprendizaje de la consulta que consideramos aquí se llama aprendizaje exacto de la membresía y consultas de equivalencia, introducido por Angluin [2]. En este modelo el objetivo de los algoritmos de aprendizaje es identificar exactamente una función diana desconocida f : X → Y a través de consultas a un oráculo. La función de destino se extrae de una función de clase C que es conocida por el algoritmo. Típicamente el dominio X es algún subconjunto de {0, 1}m, y el rango Y es {0, 1} o algún subconjunto de los números reales. A medida que el algoritmo avanza, construye una hipótesis manifiesta?f que es su estimación actual de la función de destino. Después de la terminación, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface?f(x) = f(x) para todos x?X. Es importante especificar la representación que se utilizará para codificar funciones de C. Por ejemplo, considere la siguiente función de {0, 1}m a ♥: f(x) = 2 si x consiste en m 1s, y f(x) = 0 de otra manera. Esta función puede representarse simplemente como una lista de valores de 2m. O puede codificarse como el polinomio 2x1 · · · xm, que es mucho más sucinto. Así pues, la elección de la codificación puede tener un impacto significativo en las necesidades de tiempo y espacio del algoritmo de aprendizaje. Let size(f) ser el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes distintos de cero en el polinomio, por ejemplo. Por lo general, sólo nos referiremos a las clases de representación; las clases de funciones correspondientes serán implícitas. Por ejemplo, la clase de representación de fórmulas DNF monotonas implica la clase de función de funciones booleanas monotonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: la membresía y las consultas de equivalencia. En una consulta de membresía, el aprendiz presenta algunas x x x y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta f. El oráculo responde SÍ si?f = f, o devuelve un contraejemplo x de tal manera que?f(x) = f(x). Una consulta de equivalencia es apropiada si el tamaño( ̃f) ≤ tamaño(f) en el momento de presentar la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones se adaptan a partir de Kearns y Vazirani [9]: Definición 1. La clase de representación C es polinomialquery exactamente aprendeble de las consultas de membresía y equivalencia si hay un polinomial fijo p(·, ·) y un algoritmo L con acceso a la membresía y consultas de equivalencia de un oráculo tal que para cualquier función de destino f • C, L salidas después de a lo sumo p(size(f), m) consultas de una función?f • C tal que?f Del mismo modo, la clase de representación C se puede aprender exactamente de las consultas de membresía y equivalencia si el algoritmo L produce una hipótesis correcta en el tiempo p(size(f), m), para algunos polinomios fijos p(·, ·). Aquí m es la dimensión del dominio. Dado que la función de destino debe ser reconstruida, también permitimos necesariamente la dependencia polinómica del tamaño (f). 2.2 Eliminación de preferencias En una subasta combinatoria, un conjunto de bienes M se asignará entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Tal asignación se llama eficiente en la literatura de economía, pero nos referiremos a ella como óptima y reservar el término eficiente para referirse a la eficiencia computacional. Dejamos n = N y m = M. Una asignación es una partición de los objetos en paquetes (S1,. . . , Sn), de tal manera que Si â € ¬ Sj = â € para todos los i, j â € N. Let â € € sea el conjunto de posibles asignaciones. Cada agente i+N tiene una función de valoración vi : 2M → • sobre el espacio de los paquetes posibles. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no tienen que coincidir. Asumimos que todas las valoraciones consideradas están normalizadas, es decir, v() = 0, y que no hay externalidades, es decir, vi(S1,..., Sn) = vi(Si), para todos los agentes i  N, para cualquier asignación (S1,..., Sn)  (es decir, un agente se preocupa sólo por el paquete asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales.1 Nosotros 1 A menudo las valoraciones generales se hacen para satisfacer los 181 adicionales también asumen que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que los agentes utilidades pueden ser divididos en componentes monetarios y no monetarios. Si a un agente i se le asigna el paquete S al precio p, deriva utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más sucintas para ciertas clases de valoración, y ha habido mucha investigación en lenguajes de licitación concisos para diversos tipos de valoraciones [11]. Un ejemplo clásico al que nos referiremos más adelante es el lenguaje de licitación XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, que consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estas pujas, se busca el paquete S del valor más alto listado en las pujas atómicas de tal manera que S  S. Es entonces el caso que v(S) = v(S). Al igual que en el contexto de la teoría del aprendizaje, por lo general sólo nos referiremos a idiomas de oferta en lugar de clases de valoración, ya que las clases de valoración correspondientes serán implícitas. Por ejemplo, el lenguaje de licitación XOR implica la clase de valoraciones que satisfacen la disposición libre, que es la condición de que A  B ♥ v(A) ≤ v(B). Dejamos el tamaño(v1,. . . , vn) = Èn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de licitación). Para hacer una analogía con la teoría del aprendizaje computacional, suponemos que todas las clases de representación consideradas son polinomiamente interpretables [11], lo que significa que el valor de un paquete puede ser calculado en tiempo polinomio dada la representación de funciones de valoración. Más formalmente, una clase de representación (lenguaje de licitación) C es polinomialmente interpretable si existe un algoritmo que da como entrada algunos v • C y una instancia x • X calcula el valor v(x) en el tiempo q(size(v), m), para algún polinomio fijo q(·, ·).2 En las rondas intermedias de una subasta (terativa), el subastador habrá obtenido información sobre las funciones de Por lo tanto, habrá construido un conjunto de valoraciones manifiestas, denotadas . . Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha adquirido información sobre ciertos paquetes. El objetivo en el problema de la excitación de preferencia es construir un conjunto de valoraciones manifiestas tales que: arg max (S1,...,Sn) iÃ3n Ã3vi(Si)  arg max (S1,...,Sn) iÃ3n vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que es óptima con respecto a las valoraciones verdaderas. Tenga en cuenta que sólo se requiere una asignación óptima. condición de la libre eliminación (monotonicidad), pero no la necesitamos en este punto. 2 Esto excluye OR*, asumiendo P = NP, porque la interpretación de las ofertas de este lenguaje es NP-duro por reducción de set-embalaje ponderado, y no hay clase de representación bien estudiada en teoría de aprendizaje que es claramente análogo a OR*. 3 Esta visión de las subastas iterativas tiene por objeto paralelizar el entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente están implícitas por la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son consultas de valor y demanda. En una consulta de valor, el subastador presenta un paquete S  M y el agente responde con su valor (exacto) para el paquete v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p • • • (2m ) sobre los paquetes junto con un paquete S. El agente responde SI si es el caso de que S • arg max S M v(S ) − p(S ) ¡ o de otro modo presenta un paquete S tal que v(S ) − p(S ) > v( Tenga en cuenta también que comunicar precios no lineales no implica necesariamente citar un precio por cada paquete posible. Puede haber formas más sucintas de comunicar este vector, como se muestra en la sección 5. Hacemos las siguientes definiciones para paralelizar la configuración de aprendizaje de la consulta y para simplificar las declaraciones de resultados posteriores: Definición 2. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si hay un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes tales que para cualquier (v1,. . . , vn) V1 ×. . . × Vn, L salidas después de como máximo p(size(v1,. . . , vn), m) consulta una asignación (S1,. . . , Sn) arg max(S1,...,Sn) È vi(Si). Del mismo modo, la clase de representación C se puede obtener eficientemente de las consultas de valor y demanda si el algoritmo L produce una asignación óptima con comunicación p(size(v1, ). . . , vn), m), para algunos polinomios fijos p(·, ·). Hay algunas diferencias clave aquí con la definición de aprendizaje de la consulta. Hemos eliminado el término exactamente ya que las funciones de valoración no necesitan ser determinadas exactamente con el fin de calcular una asignación óptima. Además, un \"algoritmo de eliminación\" eficiente es la comunicación polinómica, en lugar de tiempo polinomio. Esto refleja el hecho de que la comunicación en lugar del tiempo de espera es el cuello de botella en la excitación. Cálculo de una asignación óptima de bienes incluso cuando se dan las valoraciones verdaderas es NP-duro para una amplia gama de clases de valoración. Por lo tanto, no es razonable exigir tiempo polinomio en la definición de un \"algoritmo de eliminación\" de preferencia eficiente. Nos complace centrarnos en la complejidad comunicativa de la excitación porque se cree que este problema es más significativo en la práctica que el de la determinación del ganador [11].5 4 Esto difiere ligeramente de la definición proporcionada por Blum et al. [5] Sus consultas sobre la demanda se limitan a precios lineales sobre las mercancías, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir. un precio distinto por cada paquete posible. Es por eso que el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. 5 Aunque el problema de determinación del ganador es NP-hard para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta aproximaciones usando solucionadores IP fuera de la plataforma [1]. 182 Dado que no es necesario obtener exactamente las valoraciones, es inicialmente menos claro si la dependencia polinómica del tamaño (v1, ). . . , vn) está justificado en este contexto. Intuitivamente, este parámetro está justificado porque debemos aprender valoraciones exactamente cuando se realiza la excitación, en el peor de los casos. Nos ocupamos de esto en la siguiente sección. 3. PARALLESBETWEEN EQUIVALENCIA Y QUERIDAS DE DEMANDA Hemos descrito los ajustes de aprendizaje y excitación de preferencias de la consulta de una manera que destaca sus similitudes. Las consultas de valor y membresía son claras analógicas. Un poco menos obvio es el hecho de que las consultas de equivalencia y demanda también son analógicas. Para ver esto, necesitamos el concepto de precios Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios sobre sus bienes subyacentes. Son no anónimos en el sentido de que dos agentes pueden tener que hacer frente a precios diferentes para el mismo paquete de mercancías. Así los precios de Lindahl son de la forma pi(S), para todos S  M, para todos los precios de i  N. Lindahl se presentan a los agentes en consultas de la demanda. Cuando los agentes han normalizado las funciones de utilidad cuasi-lineal, Bikhchandani y Ostroy [4] muestran que siempre existen precios Lindahl tales que (S1,. . . , Sn) es una asignación óptima si y sólo si Si • arg max Si vi(Si) − pi(Si) • i N (1) (S1,. . . , Sn)  arg max (S1,...,Sn) iN pi(Si) (2) Condición (1) establece que cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos de los subastadores a los precios indicados. El escenario en el que se mantienen estas condiciones se llama equilibrio Lindahl, o a menudo un equilibrio competitivo. Decimos que los precios de Lindahl apoyan la asignación óptima. Por lo tanto, basta con anunciar los precios de apoyo de Lindahl para verificar una asignación óptima. Una vez que hemos encontrado una asignación con el apoyo de precios Lindahl, el problema de excitación se resuelve. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones estén garantizadas como integrales [4]. Las variables duales de este programa lineal están soportando los precios de Lindahl para la asignación resultante. La función objetiva del programa dual es: min pi(S) Por lo general, hay una gama de posibles precios Lindahl que apoyan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios válidos Lindahl, y nos referimos a ellos como precios máximos Lindahl. De todos los vectores posibles de precios Lindahl, precios máximos Lindahl maximizar la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È iÃ3N πi del objetivo (la suma de los agentes de utilidades) son precios mínimos Lindahl. Cualquier Lindahl precios hará para nuestros resultados, pero algunos pueden tener mejores propiedades de excitación que otros. Tenga en cuenta que una consulta de demanda con precios máximos de Lindahl es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para el trabajo futuro la cuestión de los precios de Lindahl para elegir minimizar la obtención de preferencias. Teniendo en cuenta ahora por qué las consultas de demanda y equivalencia son analógicas directas, primero tenga en cuenta que dado el πi en algún equilibrio Lindahl, establecer pi(S) = max{0, Estos precios dejan a cada agente indiferente en todos los paquetes con precio positivo, y satisfacen la condición (1). Así, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl típicamente serán una constante aditivo lejos de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos de consultas de equivalencia a través de consultas de demanda. Lemma 1. Supongamos que un agente responde con un paquete preferido S cuando se propone un paquete S y soporta los precios de Lindahl p(S) (soportando con respecto a la valoración manifiesta de los agentes). A continuación, o bien?v(S) = v(S) o?v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: Φv(S) − p(S) ≥ Desigualdad (6) se mantiene porque el agente de hecho prefiere S a S dados los precios, de acuerdo con su respuesta a la consulta de demanda. Si fuera el caso de que?v(S) = v(S) y Así, al menos uno de S y S es un contraejemplo de la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño(v1,. . . , vn) en problemas de excitación. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que apoyar los precios de Lindahl debe necesariamente revelarse en el curso de cualquier protocolo de obtención de preferencias que termina con una asignación óptima. Además, Nisan y Segal (Lemma 1, [12]) afirman que en el peor de los casos los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones dobles (como será el caso de las clases más interesantes). Puesto que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y puesto que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitiendo la dependencia del tamaño(v1,. . . , vn) en problemas de excitación es totalmente natural. 183 4. DE APRENDIZAR A LA ELICITACIÓN DE PREFERENCIA La clave para convertir un algoritmo de aprendizaje a un \"algoritmo de eliminación\" es simular consultas de equivalencia con consultas de demanda y valor hasta que se encuentre una asignación óptima. Debido a nuestra construcción de precios Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en que un agente responde SÍ a una consulta de equivalencia cuando la función de destino se ha aprendido exactamente. De lo contrario, podemos obtener un contraejemplo a una consulta de equivalencia dada una respuesta de agentes a una consulta de demanda. Teorema 1. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si cada uno puede ser polinomio-consulta exactamente aprendido de consultas de membresía y equivalencia. Prueba. Considere el \"algoritmo de eliminación\" en la Figura 1. Cada consulta de membresía en el paso 1 es simulada con una consulta de valor ya que estas son de hecho idénticas. Considere el paso 4. Si todos los agentes responden SÍ, la condición (1) se mantiene. Condición (2) se mantiene porque la asignación calculada es la maximización de ingresos para el subastador, independientemente de los agentes verdaderas valoraciones. Así pues, se ha encontrado una asignación óptima. De lo contrario, por lo menos uno de Si o Si es un contraejemplo a Vi, por Lemma 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones del agente se conocerán exactamente, en cuyo caso la asignación óptima y los precios Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinomio de consultas, desde A1,. . . , A son todos los algoritmos de aprendizaje polinomio-quería. Tenga en cuenta que el procedimiento de conversión resulta en una preferencia \"algoritmo de eliminación\", no un algoritmo de aprendizaje. Es decir, el algoritmo resultante no simplemente aprender las valoraciones exactamente, a continuación, calcular una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor, y periódicamente comprueba si se ha reunido suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio Lindahl para las valoraciones v1,. . . , vn utilizando una asignación y precios derivados de valoraciones manifiestas . . y encontrar una asignación óptima no implica que las valoraciones de los agentes se hayan aprendido exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta interrupción temprana. No obtendremos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE COMUNICACIÓN En esta sección, pasamos a la cuestión de la complejidad comunicativa de la excitación. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (tales como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos de determinar los precios de Lindahl es exponencial en el número de mercancías, m. La carga de comunicación se mide en términos del número de bits transmitidos entre agentes y subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. Convertir algoritmos de aprendizaje eficientes a un \"algoritmo de eliminación\" produce un algoritmo cuyas consultas tienen tamaños polinomios en los parámetros m y tamaño (v1, ). . . , vn). Teorema 2. Las clases de representación V1,. . . , Vn se puede obtener de forma eficiente de las consultas de valor y demanda si cada uno puede ser aprendido exactamente de las consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, basta con comunicar la función de valoración manifiesta de los agentes y el valor Nótese que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinomio, porque el tiempo de ejecución de los algoritmos también sería superpolinomio, contradiciendo la eficiencia. Por lo tanto, la comunicación de la valoración manifiesta requiere tamaño a lo sumo p(size(vi), m), para algunos polinomios p que limita superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representando el excedente πi al agente no se puede requerir espacio mayor que q(size( También debemos comunicarnos con su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es como máximo p(size(vi), m) + q(p(size(vi), m), m)+O(m). Claramente, una respuesta de agentes a una consulta de valor o demanda tiene un tamaño máximo de q(size(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, son siempre de tamaño polinomio. Un algoritmo de aprendizaje eficiente realiza un número polinomio de consultas, por lo que la comunicación total del \"algoritmo de eliminación\" resultante es polinomio en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites se pueden traducir a límites explícitos sobre el número de consultas de valor y demanda realizadas por el \"algoritmo de eliminación\" resultante. Con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2 se determinó el tamaño de la hipótesis manifiesta. Es probable que podamos hacerlo mucho mejor que esto en la práctica. Recuerde que una consulta de equivalencia es apropiada si size( ̃f) ≤ size(f) en el momento de realizar la consulta. Si las consultas de equivalencia de algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites estrechos en los requisitos de comunicación del \"algoritmo de eliminación\" resultante. El teorema 2 muestra que los algoritmos de excitación que dependen del tamaño (v1,. . . El parámetro, vn) evita los resultados negativos de Nisan y Segals [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto al tamaño de las instancias de las funciones de valoración que se enfrentan a cualquier ejecución del algoritmo. Estos algoritmos van bien si la clase de representación elegida proporciona representaciones sucintas para la más simple y común de las valoraciones, y por lo tanto el enfoque se mueve de nuevo a uno de lenguajes de licitación compactos pero expresivos. A continuación se examinan estas cuestiones. 6. APLICACIONES En esta sección, demostramos la aplicación de nuestros métodos a clases particulares de representación para valoraciones combinatorias. Hemos demostrado que el problema de excitación de preferencias para las clases de valoración V1,. . . , Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1,. . . , Una para las valoraciones de las clases V1,. . . , Vn respectivamente. Encaje hasta que haya una señal para detenerse: 1. Corre A1,. . . , Un en paralelo sobre sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se ha detenido con los agentes valoración exacta. 2. Calcular una asignación óptima (S1,. . . , Sn ) y los correspondientes precios de Lindahl con respecto a las valoraciones manifiestas . . , їvn determinado hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de consulta de demanda. 4. Si todos ellos responden SÍ, salida la asignación y parada. De lo contrario hay algún agente i que ha respondido con algún paquete preferido Si. Realizar consultas de valor en Si y Si para encontrar un contraejemplo a ‡vi, y proporcionarlo a Ai. Figura 1: Convertir algoritmos de aprendizaje en un \"algoritmo de eliminación\". al problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de función, y porque a menudo puede ser más simple resolver cada subproblema de aprendizaje por separado que atacar el problema de excitación de preferencias directamente. Podemos desarrollar un \"algoritmo de eliminación\" que se adapta a cada valoración de los agentes, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Demostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas de DNF monotono y funciones de umbral lineal se pueden convertir en algoritmos de excitación de preferencia para valoraciones generales, valoraciones con eliminación libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en las representaciones que son polinomialmente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la traqueabilidad computacional [18]. Al interpretar los métodos enfatizamos la expresividad y sucinta de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de licitación, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debe representar sucintamente las funciones más simples y comunes de la clase. 6.1 Las Representaciones Polinómicas Schapire y Sellie [17] dan un algoritmo de aprendizaje para polinomios multivariables escasos que pueden utilizarse como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas apropiadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados de t-sparse sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-sparse tiene como máximo t términos, donde un término es un producto de variables, por ejemplo. x1x3x4. Un polinomio sobre los números reales tiene coeficientes extraídos de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M →  se puede escribir exclusivamente como un polinomio [17]. Para tener una idea de la sucintaidad de los polinomios como lenguaje de licitación, considere las valoraciones aditivas y mono-ítem presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es el número de mercancías que contiene el paquete. En la valoración de un solo elemento, todos los paquetes tienen valor 1, excepto el valor 0 (i.e. el agente está satisfecho tan pronto como ha adquirido un único artículo). No es difícil demostrar que la valoración de un solo elemento requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Por lo tanto, los polinomios son adecuados para valoraciones que en su mayoría son aditivas, con algunas sustituibilidades y complementariedades que pueden introducirse ajustando los coeficientes. El algoritmo de aprendizaje para polinomios hace como máximo consultas de equivalencia mti +2 y como máximo (mti +1) (t2 i +3ti)/2 consultas de membresía a un agente i, donde ti es la esparcidad del polinomio que representa vi [17]. Por lo tanto, se obtiene un algoritmo que provoca valoraciones generales con un número polinomio de consultas y comunicación polinomio.6 6.2 XOR Representaciones El lenguaje de licitación XOR es estándar en la literatura de subastas combinatoria. Recordemos que una oferta XOR se caracteriza por un conjunto de paquetes B  2M y una función de valor w : B →  definida en esos paquetes, que induce la función de valoración: v(B) = max {B  B  B  B} w(B) (7) Las ofertas XOR pueden representar valoraciones que satisfacen la libre eliminación (y sólo tales valoraciones), que de nuevo es la propiedad que A  B El lenguaje de licitación XOR es ligeramente menos expresivo que los polinomios, porque los polinomios pueden representar valoraciones que no satisfacen la libre eliminación. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas de XOR pueden representar la valoración de un solo elemento con ofertas atómicas m, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario se aplica a los polinomios, estas dos lenguas son incomparables en sucintas y algo complementarias para su uso práctico. Blum et al. [5] note que las fórmulas DNF monotonas son los análogos de las pujas XOR en la literatura de teoría del aprendizaje. Una fórmula de DNF monotona es una disyunción de conjunciones en las que las variables aparecen sin negación, por ejemplo x1x2 x3 x2x4x5. Tenga en cuenta que tales fórmulas pueden ser representadas como ofertas XOR donde cada oferta atómica tiene valor 1; por lo tanto XOR ofrece generalizar fórmulas DNF monotono de Boolean a funciones de valor real. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para el DNF monotono ([3] Teorema 6 Tenga en cuenta que el Teorema 1 se aplica incluso si las valoraciones no satisfacen la eliminación libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lemma 2. Una oferta XOR que contiene ofertas t atómicas se puede aprender exactamente con consultas de equivalencia t + 1 y a lo sumo consultas de membresía tm. Prueba. El algoritmo identificará cada puja atómica en la puja XOR objetivo a su vez. Initialice la valoración manifiesta v a la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presente ‡v como consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un paquete S para el que v(S) = Crear un paquete T de la siguiente manera. Primero inicialice T = S. Para cada elemento i en T, compruebe a través de una consulta de membresía si v(T) = v(T − {i}). Si así se establece T = T − {i}. De lo contrario, deje T como está y pase al siguiente punto. Afirmamos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada ítem i en T, tenemos v(T) = v(T − {i}). Para ver esto, tenga en cuenta que en algún momento al generar T, tuvimos un ̄T tal que T  ̄T  S y v( ̄T) > v( ̄T − {i}), de modo que me mantuvo en ̄T. Tenga en cuenta que v(S) = v( ̄T) = v(T) porque el valor del paquete S se mantiene durante todo el proceso de eliminación de elementos. Ahora asume v(T) = v(T − {i}). Entonces v( ̄T) = v(T) = v(T − {i}) > v( ̄T − {i}) que contradice la libre eliminación, ya que T {i}  ̄T − {i}. Por lo tanto v(T) > v(T − {i}) para todos los ítems i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si este no fuera el caso, T tomaría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = máx itat {max T T Ahora mostramos que v(T) = ̃v(T), que implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Asumir que toda oferta atómica (R, Esta suposición se mantiene vagamente cuando se inicializa la valoración manifiesta. Usando la notación de (7), dejar ( Tenemos B  B, y Bw(B) = w(B) para B Por lo tanto,?v(S) = max {B} {B} {B} {B} {B} {B} = max {B} {B} {B} ≤ {B} {B} {B} {B} {S} w(B} = v(S) (8) Ahora asume v(T) {v(T La segunda igualdad se deriva del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad sostiene porque S es un contraejemplo de la valoración manifiesta. De la ecuación (9) y la eliminación libre, nosotros 7 El algoritmo citado también se utilizó como base para Zinkevich et al.s [19] \"algoritmo de eliminación\" para Toolbox DNF. Recuerde que Toolbox DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia se puede simular con una consulta de valor en el paquete que contiene todas las mercancías. que tengan ‡v(T) < Entonces de nuevo de la ecuación (9) se deduce que v(S) < Esto contradice (8), por lo que de hecho tenemos v(T) = Por lo tanto (T, v(T)) no está actualmente en nuestra hipótesis como una oferta atómica, o tendríamos correctamente?v(T) = v(T) por la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas adicionales de equivalencia hasta que todas las ofertas atómicas hayan sido identificadas. Después de cada consulta de equivalencia, una oferta atómica se identifica con como máximo m consultas de membresía. Cada contraejemplo conduce al descubrimiento de una nueva oferta atómica. Por lo tanto, hacemos a lo sumo consultas de membresía tm y exactamente consultas de equivalencia t + 1. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR se puede obtener eficientemente de las consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al.s ([5], Teorema 2) afirmando que el DNF monotono (y por lo tanto las ofertas XOR) no se pueden obtener de manera eficiente cuando las consultas de demanda se limitan a precios lineales y anónimos sobre las mercancías. 6.3 Las representaciones lineales de umbral polinomios, las ofertas XOR y todas las lenguas basadas en el lenguaje de licitación OR (como XOR-de-OR, OR-de-XOR y OR*) no representan sucintamente la valoración mayoritaria [11]. En esta valoración, los paquetes tienen valor 1 si contienen al menos m/2 ítems, y valor 0 de lo contrario. Más generalmente, considere la familia de r-of-S de valoraciones donde los paquetes tienen valor 1 si contienen al menos r artículos de un conjunto especificado de ítems S  M, y valor 0 de otra manera. La valoración mayoritaria es un caso especial de la valoración de r-of-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar las sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede añadir valor. Dejando k = S, tales valoraciones están sucintamente representadas por funciones de umbral r-of-k. Estas funciones adoptan la forma de desigualdades lineales: xi1 +. . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se mantiene, y 0 de lo contrario. Aquí i1,. . . , ik son los elementos en S. Littlestones WINNOW 2 algoritmo puede aprender tales funciones utilizando consultas de equivalencia sólo, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El \"algoritmo de eliminación\" que resulta de WINNOW 2 utiliza sólo consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos están implícitos cuando sólo hay dos valores posibles). Tenga en cuenta que las funciones de umbral r-of-k siempre se pueden representar sucintamente en el espacio O(m). Así se obtiene un algoritmo que puede generar tales funciones con un número polinomio de consultas y comunicación polinomio, en los parámetros n y m solos. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exactos con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de excitación de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas en el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la riqueza de algoritmos de aprendizaje disponibles al problema de la excitación de preferencias. Un enfoque de aprendizaje para la excitación también motiva un enfoque diferente para diseñar algoritmos de excitación que se descomponen cuidadosamente entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivos, muchos sustitutos, etc.), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de excitación. El \"algoritmo de eliminación\" resultante hace un número polinomio de consultas, y hace comunicación polinomio si los algoritmos de aprendizaje originales son eficientes. No exigimos que las valoraciones de agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia sólo pueden ser, y sólo necesitan ser, simuladas hasta el punto en que se ha calculado una asignación óptima. Este es el problema de la excitación de preferencias. Teorema 1 implica que la excitación con consultas de valor y demanda no es más difícil que aprender con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las que la excitación es más fácil que el aprendizaje. Blum et al. [5] proporcionar tal ejemplo al considerar solamente consultas de membresía/valor (Teorema 4). En el trabajo futuro planeamos abordar la cuestión de los incentivos al convertir algoritmos de aprendizaje a algoritmos de excitación. En el entorno de aprendizaje, por lo general suponemos que los oráculos proporcionarán respuestas honestas a las preguntas; en el entorno de excitación, los agentes son generalmente egoístas y proporcionarán respuestas posiblemente deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para el aprendizaje de polinomios y ofertas XOR como algoritmos de excitación, y probar su rendimiento contra otros protocolos de subasta combinatoria establecidos [6, 15]. Una pregunta interesante aquí es: ¿qué precios Lindahl en el rango máximo a mínimo son los mejores para citar con el fin de minimizar la revelación de información? Suponemos que la revelación de información se reduce al pasar de precios máximos a precios mínimos de Lindahl, es decir, a medida que desplazamos las consultas de demanda más lejos de las consultas de equivalencia. Por último, sería útil determinar si el lenguaje de licitación de OR* [11] puede aprenderse (y, por lo tanto, obtenerse) de manera eficiente, dada la expresividad y sucinta de estas lenguas para una amplia variedad de clases de valoración. Agradecimientos Queremos agradecer a Debasis Mishra por sus útiles discusiones. Este trabajo está apoyado en parte por la subvención de NSF IIS0238147. 8. REFERENCIAS [1] A. Andersson, M. Tenhunen, y F. Ygge. Programación integral para la determinación del ganador de la subasta combinatoria. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprender conjuntos regulares de consultas y contraejemplos. Información e computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje conceptual. Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El modelo de asignación de paquetes. Diario de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Provocación de preferencias y aprendizaje de consultas. En Proc. 16a Conferencia Anual sobre Teoría del Aprendizaje Computacional (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. la 18a Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, e Y. Shoham. Domar la complejidad computacional de las subastas combinatoria: Enfoques óptimos y aproximados. En Proc. , 16a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), págs. 548 a 553, 1999. [8] B. Hudson y T. Sandholm. Uso de consultas de valor en subastas combinatoria. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría del aprendizaje computacional. MIT Press, 1994. [10] N. Littlestone. Aprender rápidamente cuando los atributos irrelevantes abundan: Un nuevo algoritmo de umbral lineal. Machine Learning, 2:285-318, 1988. [11] N. Nisan. Licitación y asignación en subastas combinatoria. En Proc. la Conferencia de la ACM sobre Comercio Electrónico, págs. 1 a 12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y el apoyo a los precios Lindahl. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de mínima revelación. En Padget et al., editor, Agent-Mediated Electronic Commerce IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. Diseño de subastas con costosas preferencias. En Temas Especiales de Anales de Matemáticas y AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17a Conferencia Nacional sobre Inteligencia Artificial (AAAI-00), págs. 74 a 81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. la 17a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariables escasos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de ACM sobre Teoría del Aprendizaje Computacional, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendido. Comun. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum, y T. Sandholm. Sobre la excitación de la preferencia polinomio-tiempo con las consultas de valor. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "error": [
                ""
            ]
        },
        "polynomial number of query": {
            "translated_key": [],
            "translated_annotated_text": "Aplicando algoritmos de aprendizaje a la eliminación de preferencia Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de excitación Demostramos que los algoritmos de aprendizaje pueden ser usados como base para algoritmos de excitación de preferencias. Los algoritmos de excitación resultantes realizan un número polinomio de consultas. También damos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. En particular, se obtiene un algoritmo que provoca pujas XOR con comunicación polinómica. Categorías y Descriptores sujetos F.2.0 [Análisis de algoritmos y complejidad de problemas]: General; J.4 [Ciencias Sociales y Conductuales]: Economía; I.2.6 [Inteligencia Artificial]: Términos generales de aprendizaje Algoritmos, Economía, Teoría 1. INTRODUCCIÓN En una subasta combinatoria, los agentes pueden pujar por paquetes de bienes en lugar de por cada uno de ellos. Puesto que hay un número exponencial de paquetes (en el número de bienes), comunicar los valores sobre estos paquetes puede ser problemático. Comunicar las valoraciones de una sola vez puede ser prohibitivamente costoso si el número de bienes es sólo moderadamente grande. Además, incluso podría ser difícil para los agentes determinar sus valoraciones para paquetes únicos [14]. A esos agentes les interesa disponer de protocolos de subasta que les obliguen a pujar en el menor número posible de paquetes. Incluso si los agentes pueden calcular eficientemente sus valoraciones, podrían ser reacios a revelarlas enteramente en el curso de una subasta, porque tal información puede ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información necesaria para determinar una asignación óptima de los bienes. Ha habido un trabajo reciente explorando los vínculos entre el problema de la excitación de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje computacional [5, 19]. En teoría de aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, tales como ¿Cuál es el valor de las funciones en estas entradas? En la obtención de preferencia, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Demostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia se puede convertir en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de excitación resultante garantiza la excitación en un número polinomio de consultas de valor y demanda. Aquí queremos decir polinomio en el número de bienes, agentes, y los tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Argumentamos que las garantías de complejidad para los esquemas de excitación deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar la comunicación polinómica en el peor de los casos, que normalmente no se puede lograr en el número de productos y agentes por sí solos. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. Por supuesto, una subasta combinatoria de un solo disparo donde los agentes proporcionan todas sus funciones de valoración a la vez también tendría comunicación polinómica en el tamaño de las valoraciones de los agentes, y sólo requieren una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay ninguna carga para los agentes de formular sus valoraciones en un esquema de codificación de los subastadores que elijan. Esperamos que esta sea una consideración importante en la práctica. Además, con nuestro esquema la revelación entera sólo ocurre en el peor de los casos. 180 Por ahora, dejamos a un lado la cuestión de los incentivos al derivar algoritmos de excitación. Nos centramos en el tiempo y la complejidad de la comunicación de la obtención de preferencias, independientemente de las limitaciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich y otros [19] considerar el problema del aprendizaje de clases restringidas de funciones de valoración que se pueden representar utilizando fórmulas de lectura once y Toolbox DNF. Las fórmulas Read-once pueden representar ciertas sustitutibilidades, pero no complementariedades, mientras que lo contrario se mantiene para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten depender del tamaño de la valoración objetivo como lo hacemos (aunque las valoraciones de read-once siempre se pueden representar sucintamente de todos modos). Su trabajo sólo hace uso de consultas de valor, que son bastante limitados en el poder. Debido a que nos permitimos pedir consultas, somos capaces de derivar un esquema de excitación para las funciones de valoración general. Blum et al. [5] proporcionar resultados relacionados con las complejidades del aprendizaje de la consulta y la excitación de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje de consultas, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones se pueden aprender eficientemente, pero no se pueden obtener eficientemente, y viceversa. En contraste, nuestro trabajo muestra que dada una versión más general (todavía bastante estándar) de la consulta de demanda que el tipo que consideran, la complejidad de la excitación de preferencia no es mayor que la complejidad del aprendizaje. Demostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre valoraciones para implicar una solución al problema de excitación. Nisan y Segal [12] estudian la complejidad comunicativa de la excitación de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos de la computación una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo se permite a los algoritmos hacer preguntas sobre valoraciones de agentes y recibir respuestas honestas, sin ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda la cuestión de la complejidad de la comunicación, y somos capaces de derivar algoritmos que proporcionan garantías de comunicación significativas a pesar de los resultados negativos de Nisan y Segals. Su trabajo motiva la necesidad de confiar en el tamaño de los agentes funciones de valoración para indicar los peores resultados. 2. LOS MODELOS 2.1 Aprendizaje de la consulta El modelo de aprendizaje de la consulta que consideramos aquí se llama aprendizaje exacto de la membresía y consultas de equivalencia, introducido por Angluin [2]. En este modelo el objetivo de los algoritmos de aprendizaje es identificar exactamente una función diana desconocida f : X → Y a través de consultas a un oráculo. La función de destino se extrae de una función de clase C que es conocida por el algoritmo. Típicamente el dominio X es algún subconjunto de {0, 1}m, y el rango Y es {0, 1} o algún subconjunto de los números reales. A medida que el algoritmo avanza, construye una hipótesis manifiesta?f que es su estimación actual de la función de destino. Después de la terminación, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface?f(x) = f(x) para todos x?X. Es importante especificar la representación que se utilizará para codificar funciones de C. Por ejemplo, considere la siguiente función de {0, 1}m a ♥: f(x) = 2 si x consiste en m 1s, y f(x) = 0 de otra manera. Esta función puede representarse simplemente como una lista de valores de 2m. O puede codificarse como el polinomio 2x1 · · · xm, que es mucho más sucinto. Así pues, la elección de la codificación puede tener un impacto significativo en las necesidades de tiempo y espacio del algoritmo de aprendizaje. Let size(f) ser el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes distintos de cero en el polinomio, por ejemplo. Por lo general, sólo nos referiremos a las clases de representación; las clases de funciones correspondientes serán implícitas. Por ejemplo, la clase de representación de fórmulas DNF monotonas implica la clase de función de funciones booleanas monotonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: la membresía y las consultas de equivalencia. En una consulta de membresía, el aprendiz presenta algunas x x x y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta f. El oráculo responde SÍ si?f = f, o devuelve un contraejemplo x de tal manera que?f(x) = f(x). Una consulta de equivalencia es apropiada si el tamaño( ̃f) ≤ tamaño(f) en el momento de presentar la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones se adaptan a partir de Kearns y Vazirani [9]: Definición 1. La clase de representación C es polinomialquery exactamente aprendeble de las consultas de membresía y equivalencia si hay un polinomial fijo p(·, ·) y un algoritmo L con acceso a la membresía y consultas de equivalencia de un oráculo tal que para cualquier función de destino f • C, L salidas después de a lo sumo p(size(f), m) consultas de una función?f • C tal que?f Del mismo modo, la clase de representación C se puede aprender exactamente de las consultas de membresía y equivalencia si el algoritmo L produce una hipótesis correcta en el tiempo p(size(f), m), para algunos polinomios fijos p(·, ·). Aquí m es la dimensión del dominio. Dado que la función de destino debe ser reconstruida, también permitimos necesariamente la dependencia polinómica del tamaño (f). 2.2 Eliminación de preferencias En una subasta combinatoria, un conjunto de bienes M se asignará entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Tal asignación se llama eficiente en la literatura de economía, pero nos referiremos a ella como óptima y reservar el término eficiente para referirse a la eficiencia computacional. Dejamos n = N y m = M. Una asignación es una partición de los objetos en paquetes (S1,. . . , Sn), de tal manera que Si â € ¬ Sj = â € para todos los i, j â € N. Let â € € sea el conjunto de posibles asignaciones. Cada agente i+N tiene una función de valoración vi : 2M → • sobre el espacio de los paquetes posibles. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no tienen que coincidir. Asumimos que todas las valoraciones consideradas están normalizadas, es decir, v() = 0, y que no hay externalidades, es decir, vi(S1,..., Sn) = vi(Si), para todos los agentes i  N, para cualquier asignación (S1,..., Sn)  (es decir, un agente se preocupa sólo por el paquete asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales.1 Nosotros 1 A menudo las valoraciones generales se hacen para satisfacer los 181 adicionales también asumen que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que los agentes utilidades pueden ser divididos en componentes monetarios y no monetarios. Si a un agente i se le asigna el paquete S al precio p, deriva utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más sucintas para ciertas clases de valoración, y ha habido mucha investigación en lenguajes de licitación concisos para diversos tipos de valoraciones [11]. Un ejemplo clásico al que nos referiremos más adelante es el lenguaje de licitación XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, que consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estas pujas, se busca el paquete S del valor más alto listado en las pujas atómicas de tal manera que S  S. Es entonces el caso que v(S) = v(S). Al igual que en el contexto de la teoría del aprendizaje, por lo general sólo nos referiremos a idiomas de oferta en lugar de clases de valoración, ya que las clases de valoración correspondientes serán implícitas. Por ejemplo, el lenguaje de licitación XOR implica la clase de valoraciones que satisfacen la disposición libre, que es la condición de que A  B ♥ v(A) ≤ v(B). Dejamos el tamaño(v1,. . . , vn) = Èn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de licitación). Para hacer una analogía con la teoría del aprendizaje computacional, suponemos que todas las clases de representación consideradas son polinomiamente interpretables [11], lo que significa que el valor de un paquete puede ser calculado en tiempo polinomio dada la representación de funciones de valoración. Más formalmente, una clase de representación (lenguaje de licitación) C es polinomialmente interpretable si existe un algoritmo que da como entrada algunos v • C y una instancia x • X calcula el valor v(x) en el tiempo q(size(v), m), para algún polinomio fijo q(·, ·).2 En las rondas intermedias de una subasta (terativa), el subastador habrá obtenido información sobre las funciones de Por lo tanto, habrá construido un conjunto de valoraciones manifiestas, denotadas . . Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha adquirido información sobre ciertos paquetes. El objetivo en el problema de la excitación de preferencia es construir un conjunto de valoraciones manifiestas tales que: arg max (S1,...,Sn) iÃ3n Ã3vi(Si)  arg max (S1,...,Sn) iÃ3n vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que es óptima con respecto a las valoraciones verdaderas. Tenga en cuenta que sólo se requiere una asignación óptima. condición de la libre eliminación (monotonicidad), pero no la necesitamos en este punto. 2 Esto excluye OR*, asumiendo P = NP, porque la interpretación de las ofertas de este lenguaje es NP-duro por reducción de set-embalaje ponderado, y no hay clase de representación bien estudiada en teoría de aprendizaje que es claramente análogo a OR*. 3 Esta visión de las subastas iterativas tiene por objeto paralelizar el entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente están implícitas por la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son consultas de valor y demanda. En una consulta de valor, el subastador presenta un paquete S  M y el agente responde con su valor (exacto) para el paquete v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p • • • (2m ) sobre los paquetes junto con un paquete S. El agente responde SI si es el caso de que S • arg max S M v(S ) − p(S ) ¡ o de otro modo presenta un paquete S tal que v(S ) − p(S ) > v( Tenga en cuenta también que comunicar precios no lineales no implica necesariamente citar un precio por cada paquete posible. Puede haber formas más sucintas de comunicar este vector, como se muestra en la sección 5. Hacemos las siguientes definiciones para paralelizar la configuración de aprendizaje de la consulta y para simplificar las declaraciones de resultados posteriores: Definición 2. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si hay un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes tales que para cualquier (v1,. . . , vn) V1 ×. . . × Vn, L salidas después de como máximo p(size(v1,. . . , vn), m) consulta una asignación (S1,. . . , Sn) arg max(S1,...,Sn) È vi(Si). Del mismo modo, la clase de representación C se puede obtener eficientemente de las consultas de valor y demanda si el algoritmo L produce una asignación óptima con comunicación p(size(v1, ). . . , vn), m), para algunos polinomios fijos p(·, ·). Hay algunas diferencias clave aquí con la definición de aprendizaje de la consulta. Hemos eliminado el término exactamente ya que las funciones de valoración no necesitan ser determinadas exactamente con el fin de calcular una asignación óptima. Además, un algoritmo de excitación eficiente es la comunicación polinomio, en lugar de tiempo polinomio. Esto refleja el hecho de que la comunicación en lugar del tiempo de espera es el cuello de botella en la excitación. Cálculo de una asignación óptima de bienes incluso cuando se dan las valoraciones verdaderas es NP-duro para una amplia gama de clases de valoración. Por lo tanto, no es razonable exigir tiempo polinomio en la definición de un algoritmo de excitación de preferencias eficiente. Nos complace centrarnos en la complejidad comunicativa de la excitación porque se cree que este problema es más significativo en la práctica que el de la determinación del ganador [11].5 4 Esto difiere ligeramente de la definición proporcionada por Blum et al. [5] Sus consultas sobre la demanda se limitan a precios lineales sobre las mercancías, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir. un precio distinto por cada paquete posible. Es por eso que el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. 5 Aunque el problema de determinación del ganador es NP-hard para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta aproximaciones usando solucionadores IP fuera de la plataforma [1]. 182 Dado que no es necesario obtener exactamente las valoraciones, es inicialmente menos claro si la dependencia polinómica del tamaño (v1, ). . . , vn) está justificado en este contexto. Intuitivamente, este parámetro está justificado porque debemos aprender valoraciones exactamente cuando se realiza la excitación, en el peor de los casos. Nos ocupamos de esto en la siguiente sección. 3. PARALLESBETWEEN EQUIVALENCIA Y QUERIDAS DE DEMANDA Hemos descrito los ajustes de aprendizaje y excitación de preferencias de la consulta de una manera que destaca sus similitudes. Las consultas de valor y membresía son claras analógicas. Un poco menos obvio es el hecho de que las consultas de equivalencia y demanda también son analógicas. Para ver esto, necesitamos el concepto de precios Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios sobre sus bienes subyacentes. Son no anónimos en el sentido de que dos agentes pueden tener que hacer frente a precios diferentes para el mismo paquete de mercancías. Así los precios de Lindahl son de la forma pi(S), para todos S  M, para todos los precios de i  N. Lindahl se presentan a los agentes en consultas de la demanda. Cuando los agentes han normalizado las funciones de utilidad cuasi-lineal, Bikhchandani y Ostroy [4] muestran que siempre existen precios Lindahl tales que (S1,. . . , Sn) es una asignación óptima si y sólo si Si • arg max Si vi(Si) − pi(Si) • i N (1) (S1,. . . , Sn)  arg max (S1,...,Sn) iN pi(Si) (2) Condición (1) establece que cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos de los subastadores a los precios indicados. El escenario en el que se mantienen estas condiciones se llama equilibrio Lindahl, o a menudo un equilibrio competitivo. Decimos que los precios de Lindahl apoyan la asignación óptima. Por lo tanto, basta con anunciar los precios de apoyo de Lindahl para verificar una asignación óptima. Una vez que hemos encontrado una asignación con el apoyo de precios Lindahl, el problema de excitación se resuelve. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones estén garantizadas como integrales [4]. Las variables duales de este programa lineal están soportando los precios de Lindahl para la asignación resultante. La función objetiva del programa dual es: min pi(S) Por lo general, hay una gama de posibles precios Lindahl que apoyan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios válidos Lindahl, y nos referimos a ellos como precios máximos Lindahl. De todos los vectores posibles de precios Lindahl, precios máximos Lindahl maximizar la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È iÃ3N πi del objetivo (la suma de los agentes de utilidades) son precios mínimos Lindahl. Cualquier Lindahl precios hará para nuestros resultados, pero algunos pueden tener mejores propiedades de excitación que otros. Tenga en cuenta que una consulta de demanda con precios máximos de Lindahl es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para el trabajo futuro la cuestión de los precios de Lindahl para elegir minimizar la obtención de preferencias. Teniendo en cuenta ahora por qué las consultas de demanda y equivalencia son analógicas directas, primero tenga en cuenta que dado el πi en algún equilibrio Lindahl, establecer pi(S) = max{0, Estos precios dejan a cada agente indiferente en todos los paquetes con precio positivo, y satisfacen la condición (1). Así, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl típicamente serán una constante aditivo lejos de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos de consultas de equivalencia a través de consultas de demanda. Lemma 1. Supongamos que un agente responde con un paquete preferido S cuando se propone un paquete S y soporta los precios de Lindahl p(S) (soportando con respecto a la valoración manifiesta de los agentes). A continuación, o bien?v(S) = v(S) o?v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: Φv(S) − p(S) ≥ Desigualdad (6) se mantiene porque el agente de hecho prefiere S a S dados los precios, de acuerdo con su respuesta a la consulta de demanda. Si fuera el caso de que?v(S) = v(S) y Así, al menos uno de S y S es un contraejemplo de la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño(v1,. . . , vn) en problemas de excitación. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que apoyar los precios de Lindahl debe necesariamente revelarse en el curso de cualquier protocolo de obtención de preferencias que termina con una asignación óptima. Además, Nisan y Segal (Lemma 1, [12]) afirman que en el peor de los casos los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones dobles (como será el caso de las clases más interesantes). Puesto que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y puesto que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitiendo la dependencia del tamaño(v1,. . . , vn) en problemas de excitación es totalmente natural. 183 4. DE APRENDIZAJE A LA LICITACIÓN DE PREFERENCIA La clave para convertir un algoritmo de aprendizaje a un algoritmo de excitación es simular consultas de equivalencia con consultas de demanda y valor hasta que se encuentre una asignación óptima. Debido a nuestra construcción de precios Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en que un agente responde SÍ a una consulta de equivalencia cuando la función de destino se ha aprendido exactamente. De lo contrario, podemos obtener un contraejemplo a una consulta de equivalencia dada una respuesta de agentes a una consulta de demanda. Teorema 1. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si cada uno puede ser polinomio-consulta exactamente aprendido de consultas de membresía y equivalencia. Prueba. Considere el algoritmo de excitación en la Figura 1. Cada consulta de membresía en el paso 1 es simulada con una consulta de valor ya que estas son de hecho idénticas. Considere el paso 4. Si todos los agentes responden SÍ, la condición (1) se mantiene. Condición (2) se mantiene porque la asignación calculada es la maximización de ingresos para el subastador, independientemente de los agentes verdaderas valoraciones. Así pues, se ha encontrado una asignación óptima. De lo contrario, por lo menos uno de Si o Si es un contraejemplo a Vi, por Lemma 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones del agente se conocerán exactamente, en cuyo caso la asignación óptima y los precios Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinomio de consultas, desde A1,. . . , A son todos los algoritmos de aprendizaje polinomio-quería. Tenga en cuenta que el procedimiento de conversión resulta en un algoritmo de excitación de preferencias, no un algoritmo de aprendizaje. Es decir, el algoritmo resultante no simplemente aprender las valoraciones exactamente, a continuación, calcular una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor, y periódicamente comprueba si se ha reunido suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio Lindahl para las valoraciones v1,. . . , vn utilizando una asignación y precios derivados de valoraciones manifiestas . . y encontrar una asignación óptima no implica que las valoraciones de los agentes se hayan aprendido exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta interrupción temprana. No obtendremos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE COMUNICACIÓN En esta sección, pasamos a la cuestión de la complejidad comunicativa de la excitación. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (tales como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos de determinar los precios de Lindahl es exponencial en el número de mercancías, m. La carga de comunicación se mide en términos del número de bits transmitidos entre agentes y subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. La conversión de algoritmos de aprendizaje eficientes a un algoritmo de excitación produce un algoritmo cuyas consultas tienen tamaños polinomios en los parámetros m y tamaño (v1, ). . . , vn). Teorema 2. Las clases de representación V1,. . . , Vn se puede obtener de forma eficiente de las consultas de valor y demanda si cada uno puede ser aprendido exactamente de las consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, basta con comunicar la función de valoración manifiesta de los agentes y el valor Nótese que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinomio, porque el tiempo de ejecución de los algoritmos también sería superpolinomio, contradiciendo la eficiencia. Por lo tanto, la comunicación de la valoración manifiesta requiere tamaño a lo sumo p(size(vi), m), para algunos polinomios p que limita superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representando el excedente πi al agente no se puede requerir espacio mayor que q(size( También debemos comunicarnos con su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es como máximo p(size(vi), m) + q(p(size(vi), m), m)+O(m). Claramente, una respuesta de agentes a una consulta de valor o demanda tiene un tamaño máximo de q(size(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, son siempre de tamaño polinomio. Un algoritmo de aprendizaje eficiente realiza un número polinomio de consultas, por lo que la comunicación total del algoritmo de excitación resultante es polinomio en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites pueden ser traducidos a límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de excitación resultante. Con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2 se determinó el tamaño de la hipótesis manifiesta. Es probable que podamos hacerlo mucho mejor que esto en la práctica. Recuerde que una consulta de equivalencia es apropiada si size( ̃f) ≤ size(f) en el momento de realizar la consulta. Si las consultas de equivalencia de algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites estrechos en los requisitos de comunicación del algoritmo de excitación resultante. El teorema 2 muestra que los algoritmos de excitación que dependen del tamaño (v1,. . . El parámetro, vn) evita los resultados negativos de Nisan y Segals [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto al tamaño de las instancias de las funciones de valoración que se enfrentan a cualquier ejecución del algoritmo. Estos algoritmos van bien si la clase de representación elegida proporciona representaciones sucintas para la más simple y común de las valoraciones, y por lo tanto el enfoque se mueve de nuevo a uno de lenguajes de licitación compactos pero expresivos. A continuación se examinan estas cuestiones. 6. APLICACIONES En esta sección, demostramos la aplicación de nuestros métodos a clases particulares de representación para valoraciones combinatorias. Hemos demostrado que el problema de excitación de preferencias para las clases de valoración V1,. . . , Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1,. . . , Una para las valoraciones de las clases V1,. . . , Vn respectivamente. Encaje hasta que haya una señal para detenerse: 1. Corre A1,. . . , Un en paralelo sobre sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se ha detenido con los agentes valoración exacta. 2. Calcular una asignación óptima (S1,. . . , Sn ) y los correspondientes precios de Lindahl con respecto a las valoraciones manifiestas . . , їvn determinado hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de consulta de demanda. 4. Si todos ellos responden SÍ, salida la asignación y parada. De lo contrario hay algún agente i que ha respondido con algún paquete preferido Si. Realizar consultas de valor en Si y Si para encontrar un contraejemplo a ‡vi, y proporcionarlo a Ai. Figura 1: Convertir algoritmos de aprendizaje a un algoritmo de excitación. al problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de función, y porque a menudo puede ser más simple resolver cada subproblema de aprendizaje por separado que atacar el problema de excitación de preferencias directamente. Podemos desarrollar un algoritmo de excitación que se adapta a cada valoración de agentes, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Demostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas de DNF monotono y funciones de umbral lineal se pueden convertir en algoritmos de excitación de preferencia para valoraciones generales, valoraciones con eliminación libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en las representaciones que son polinomialmente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la traqueabilidad computacional [18]. Al interpretar los métodos enfatizamos la expresividad y sucinta de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de licitación, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debe representar sucintamente las funciones más simples y comunes de la clase. 6.1 Las Representaciones Polinómicas Schapire y Sellie [17] dan un algoritmo de aprendizaje para polinomios multivariables escasos que pueden utilizarse como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas apropiadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados de t-sparse sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-sparse tiene como máximo t términos, donde un término es un producto de variables, por ejemplo. x1x3x4. Un polinomio sobre los números reales tiene coeficientes extraídos de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M →  se puede escribir exclusivamente como un polinomio [17]. Para tener una idea de la sucintaidad de los polinomios como lenguaje de licitación, considere las valoraciones aditivas y mono-ítem presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es el número de mercancías que contiene el paquete. En la valoración de un solo elemento, todos los paquetes tienen valor 1, excepto el valor 0 (i.e. el agente está satisfecho tan pronto como ha adquirido un único artículo). No es difícil demostrar que la valoración de un solo elemento requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Por lo tanto, los polinomios son adecuados para valoraciones que en su mayoría son aditivas, con algunas sustituibilidades y complementariedades que pueden introducirse ajustando los coeficientes. El algoritmo de aprendizaje para polinomios hace como máximo consultas de equivalencia mti +2 y como máximo (mti +1) (t2 i +3ti)/2 consultas de membresía a un agente i, donde ti es la esparcidad del polinomio que representa vi [17]. Por lo tanto, se obtiene un algoritmo que provoca valoraciones generales con un número polinomio de consultas y comunicación polinomio.6 6.2 XOR Representaciones El lenguaje de licitación XOR es estándar en la literatura de subastas combinatoria. Recordemos que una oferta XOR se caracteriza por un conjunto de paquetes B  2M y una función de valor w : B →  definida en esos paquetes, que induce la función de valoración: v(B) = max {B  B  B  B} w(B) (7) Las ofertas XOR pueden representar valoraciones que satisfacen la libre eliminación (y sólo tales valoraciones), que de nuevo es la propiedad que A  B El lenguaje de licitación XOR es ligeramente menos expresivo que los polinomios, porque los polinomios pueden representar valoraciones que no satisfacen la libre eliminación. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas de XOR pueden representar la valoración de un solo elemento con ofertas atómicas m, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario se aplica a los polinomios, estas dos lenguas son incomparables en sucintas y algo complementarias para su uso práctico. Blum et al. [5] note que las fórmulas DNF monotonas son los análogos de las pujas XOR en la literatura de teoría del aprendizaje. Una fórmula de DNF monotona es una disyunción de conjunciones en las que las variables aparecen sin negación, por ejemplo x1x2 x3 x2x4x5. Tenga en cuenta que tales fórmulas pueden ser representadas como ofertas XOR donde cada oferta atómica tiene valor 1; por lo tanto XOR ofrece generalizar fórmulas DNF monotono de Boolean a funciones de valor real. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para el DNF monotono ([3] Teorema 6 Tenga en cuenta que el Teorema 1 se aplica incluso si las valoraciones no satisfacen la eliminación libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lemma 2. Una oferta XOR que contiene ofertas t atómicas se puede aprender exactamente con consultas de equivalencia t + 1 y a lo sumo consultas de membresía tm. Prueba. El algoritmo identificará cada puja atómica en la puja XOR objetivo a su vez. Initialice la valoración manifiesta v a la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presente ‡v como consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un paquete S para el que v(S) = Crear un paquete T de la siguiente manera. Primero inicialice T = S. Para cada elemento i en T, compruebe a través de una consulta de membresía si v(T) = v(T − {i}). Si así se establece T = T − {i}. De lo contrario, deje T como está y pase al siguiente punto. Afirmamos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada ítem i en T, tenemos v(T) = v(T − {i}). Para ver esto, tenga en cuenta que en algún momento al generar T, tuvimos un ̄T tal que T  ̄T  S y v( ̄T) > v( ̄T − {i}), de modo que me mantuvo en ̄T. Tenga en cuenta que v(S) = v( ̄T) = v(T) porque el valor del paquete S se mantiene durante todo el proceso de eliminación de elementos. Ahora asume v(T) = v(T − {i}). Entonces v( ̄T) = v(T) = v(T − {i}) > v( ̄T − {i}) que contradice la libre eliminación, ya que T {i}  ̄T − {i}. Por lo tanto v(T) > v(T − {i}) para todos los ítems i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si este no fuera el caso, T tomaría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = máx itat {max T T Ahora mostramos que v(T) = ̃v(T), que implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Asumir que toda oferta atómica (R, Esta suposición se mantiene vagamente cuando se inicializa la valoración manifiesta. Usando la notación de (7), dejar ( Tenemos B  B, y Bw(B) = w(B) para B Por lo tanto,?v(S) = max {B} {B} {B} {B} {B} {B} = max {B} {B} {B} ≤ {B} {B} {B} {B} {S} w(B} = v(S) (8) Ahora asume v(T) {v(T La segunda igualdad se deriva del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad sostiene porque S es un contraejemplo de la valoración manifiesta. De la ecuación (9) y la eliminación libre, nosotros 7 El algoritmo citado también se utilizó como base para Zinkevich et al.s [19] algoritmo de excitación para Toolbox DNF. Recuerde que Toolbox DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia se puede simular con una consulta de valor en el paquete que contiene todas las mercancías. que tengan ‡v(T) < Entonces de nuevo de la ecuación (9) se deduce que v(S) < Esto contradice (8), por lo que de hecho tenemos v(T) = Por lo tanto (T, v(T)) no está actualmente en nuestra hipótesis como una oferta atómica, o tendríamos correctamente?v(T) = v(T) por la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas adicionales de equivalencia hasta que todas las ofertas atómicas hayan sido identificadas. Después de cada consulta de equivalencia, una oferta atómica se identifica con como máximo m consultas de membresía. Cada contraejemplo conduce al descubrimiento de una nueva oferta atómica. Por lo tanto, hacemos a lo sumo consultas de membresía tm y exactamente consultas de equivalencia t + 1. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR se puede obtener eficientemente de las consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al.s ([5], Teorema 2) afirmando que el DNF monotono (y por lo tanto las ofertas XOR) no se pueden obtener de manera eficiente cuando las consultas de demanda se limitan a precios lineales y anónimos sobre las mercancías. 6.3 Las representaciones lineales de umbral polinomios, las ofertas XOR y todas las lenguas basadas en el lenguaje de licitación OR (como XOR-de-OR, OR-de-XOR y OR*) no representan sucintamente la valoración mayoritaria [11]. En esta valoración, los paquetes tienen valor 1 si contienen al menos m/2 ítems, y valor 0 de lo contrario. Más generalmente, considere la familia de r-of-S de valoraciones donde los paquetes tienen valor 1 si contienen al menos r artículos de un conjunto especificado de ítems S  M, y valor 0 de otra manera. La valoración mayoritaria es un caso especial de la valoración de r-of-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar las sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede añadir valor. Dejando k = S, tales valoraciones están sucintamente representadas por funciones de umbral r-of-k. Estas funciones adoptan la forma de desigualdades lineales: xi1 +. . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se mantiene, y 0 de lo contrario. Aquí i1,. . . , ik son los elementos en S. Littlestones WINNOW 2 algoritmo puede aprender tales funciones utilizando consultas de equivalencia sólo, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de excitación que resulta de WINNOW 2 sólo utiliza consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos están implícitos cuando sólo hay dos valores posibles). Tenga en cuenta que las funciones de umbral r-of-k siempre se pueden representar sucintamente en el espacio O(m). Así se obtiene un algoritmo que puede generar tales funciones con un número polinomio de consultas y comunicación polinomio, en los parámetros n y m solos. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exactos con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de excitación de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas en el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la riqueza de algoritmos de aprendizaje disponibles al problema de la excitación de preferencias. Un enfoque de aprendizaje para la excitación también motiva un enfoque diferente para diseñar algoritmos de excitación que se descomponen cuidadosamente entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivos, muchos sustitutos, etc.), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de excitación. El algoritmo de excitación resultante hace un número polinomio de consultas, y hace comunicación polinomio si los algoritmos de aprendizaje originales son eficientes. No exigimos que las valoraciones de agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia sólo pueden ser, y sólo necesitan ser, simuladas hasta el punto en que se ha calculado una asignación óptima. Este es el problema de la excitación de preferencias. Teorema 1 implica que la excitación con consultas de valor y demanda no es más difícil que aprender con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las que la excitación es más fácil que el aprendizaje. Blum et al. [5] proporcionar tal ejemplo al considerar solamente consultas de membresía/valor (Teorema 4). En el trabajo futuro planeamos abordar la cuestión de los incentivos al convertir algoritmos de aprendizaje a algoritmos de excitación. En el entorno de aprendizaje, por lo general suponemos que los oráculos proporcionarán respuestas honestas a las preguntas; en el entorno de excitación, los agentes son generalmente egoístas y proporcionarán respuestas posiblemente deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para el aprendizaje de polinomios y ofertas XOR como algoritmos de excitación, y probar su rendimiento contra otros protocolos de subasta combinatoria establecidos [6, 15]. Una pregunta interesante aquí es: ¿qué precios Lindahl en el rango máximo a mínimo son los mejores para citar con el fin de minimizar la revelación de información? Suponemos que la revelación de información se reduce al pasar de precios máximos a precios mínimos de Lindahl, es decir, a medida que desplazamos las consultas de demanda más lejos de las consultas de equivalencia. Por último, sería útil determinar si el lenguaje de licitación de OR* [11] puede aprenderse (y, por lo tanto, obtenerse) de manera eficiente, dada la expresividad y sucinta de estas lenguas para una amplia variedad de clases de valoración. Agradecimientos Queremos agradecer a Debasis Mishra por sus útiles discusiones. Este trabajo está apoyado en parte por la subvención de NSF IIS0238147. 8. REFERENCIAS [1] A. Andersson, M. Tenhunen, y F. Ygge. Programación integral para la determinación del ganador de la subasta combinatoria. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprender conjuntos regulares de consultas y contraejemplos. Información e computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje conceptual. Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El modelo de asignación de paquetes. Diario de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Provocación de preferencias y aprendizaje de consultas. En Proc. 16a Conferencia Anual sobre Teoría del Aprendizaje Computacional (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. la 18a Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, e Y. Shoham. Domar la complejidad computacional de las subastas combinatoria: Enfoques óptimos y aproximados. En Proc. , 16a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), págs. 548 a 553, 1999. [8] B. Hudson y T. Sandholm. Uso de consultas de valor en subastas combinatoria. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría del aprendizaje computacional. MIT Press, 1994. [10] N. Littlestone. Aprender rápidamente cuando los atributos irrelevantes abundan: Un nuevo algoritmo de umbral lineal. Machine Learning, 2:285-318, 1988. [11] N. Nisan. Licitación y asignación en subastas combinatoria. En Proc. la Conferencia de la ACM sobre Comercio Electrónico, págs. 1 a 12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y el apoyo a los precios Lindahl. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de mínima revelación. En Padget et al., editor, Agent-Mediated Electronic Commerce IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. Diseño de subastas con costosas preferencias. En Temas Especiales de Anales de Matemáticas y AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17a Conferencia Nacional sobre Inteligencia Artificial (AAAI-00), págs. 74 a 81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. la 17a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariables escasos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de ACM sobre Teoría del Aprendizaje Computacional, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendido. Comun. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum, y T. Sandholm. Sobre la excitación de la preferencia polinomio-tiempo con las consultas de valor. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "error": []
        },
        "query polynomial number": {
            "translated_key": [],
            "translated_annotated_text": "Aplicando algoritmos de aprendizaje a la eliminación de preferencia Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de excitación Demostramos que los algoritmos de aprendizaje pueden ser usados como base para algoritmos de excitación de preferencias. Los algoritmos de excitación resultantes realizan un número polinomio de consultas. También damos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. En particular, se obtiene un algoritmo que provoca pujas XOR con comunicación polinómica. Categorías y Descriptores sujetos F.2.0 [Análisis de algoritmos y complejidad de problemas]: General; J.4 [Ciencias Sociales y Conductuales]: Economía; I.2.6 [Inteligencia Artificial]: Términos generales de aprendizaje Algoritmos, Economía, Teoría 1. INTRODUCCIÓN En una subasta combinatoria, los agentes pueden pujar por paquetes de bienes en lugar de por cada uno de ellos. Puesto que hay un número exponencial de paquetes (en el número de bienes), comunicar los valores sobre estos paquetes puede ser problemático. Comunicar las valoraciones de una sola vez puede ser prohibitivamente costoso si el número de bienes es sólo moderadamente grande. Además, incluso podría ser difícil para los agentes determinar sus valoraciones para paquetes únicos [14]. A esos agentes les interesa disponer de protocolos de subasta que les obliguen a pujar en el menor número posible de paquetes. Incluso si los agentes pueden calcular eficientemente sus valoraciones, podrían ser reacios a revelarlas enteramente en el curso de una subasta, porque tal información puede ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información necesaria para determinar una asignación óptima de los bienes. Ha habido un trabajo reciente explorando los vínculos entre el problema de la excitación de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje computacional [5, 19]. En teoría de aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, tales como ¿Cuál es el valor de las funciones en estas entradas? En la obtención de preferencia, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Demostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia se puede convertir en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de excitación resultante garantiza la excitación en un número polinomio de consultas de valor y demanda. Aquí queremos decir polinomio en el número de bienes, agentes, y los tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Argumentamos que las garantías de complejidad para los esquemas de excitación deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar la comunicación polinómica en el peor de los casos, que normalmente no se puede lograr en el número de productos y agentes por sí solos. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. Por supuesto, una subasta combinatoria de un solo disparo donde los agentes proporcionan todas sus funciones de valoración a la vez también tendría comunicación polinómica en el tamaño de las valoraciones de los agentes, y sólo requieren una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay ninguna carga para los agentes de formular sus valoraciones en un esquema de codificación de los subastadores que elijan. Esperamos que esta sea una consideración importante en la práctica. Además, con nuestro esquema la revelación entera sólo ocurre en el peor de los casos. 180 Por ahora, dejamos a un lado la cuestión de los incentivos al derivar algoritmos de excitación. Nos centramos en el tiempo y la complejidad de la comunicación de la obtención de preferencias, independientemente de las limitaciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich y otros [19] considerar el problema del aprendizaje de clases restringidas de funciones de valoración que se pueden representar utilizando fórmulas de lectura once y Toolbox DNF. Las fórmulas Read-once pueden representar ciertas sustitutibilidades, pero no complementariedades, mientras que lo contrario se mantiene para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten depender del tamaño de la valoración objetivo como lo hacemos (aunque las valoraciones de read-once siempre se pueden representar sucintamente de todos modos). Su trabajo sólo hace uso de consultas de valor, que son bastante limitados en el poder. Debido a que nos permitimos pedir consultas, somos capaces de derivar un esquema de excitación para las funciones de valoración general. Blum et al. [5] proporcionar resultados relacionados con las complejidades del aprendizaje de la consulta y la excitación de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje de consultas, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones se pueden aprender eficientemente, pero no se pueden obtener eficientemente, y viceversa. En contraste, nuestro trabajo muestra que dada una versión más general (todavía bastante estándar) de la consulta de demanda que el tipo que consideran, la complejidad de la excitación de preferencia no es mayor que la complejidad del aprendizaje. Demostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre valoraciones para implicar una solución al problema de excitación. Nisan y Segal [12] estudian la complejidad comunicativa de la excitación de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos de la computación una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo se permite a los algoritmos hacer preguntas sobre valoraciones de agentes y recibir respuestas honestas, sin ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda la cuestión de la complejidad de la comunicación, y somos capaces de derivar algoritmos que proporcionan garantías de comunicación significativas a pesar de los resultados negativos de Nisan y Segals. Su trabajo motiva la necesidad de confiar en el tamaño de los agentes funciones de valoración para indicar los peores resultados. 2. LOS MODELOS 2.1 Aprendizaje de la consulta El modelo de aprendizaje de la consulta que consideramos aquí se llama aprendizaje exacto de la membresía y consultas de equivalencia, introducido por Angluin [2]. En este modelo el objetivo de los algoritmos de aprendizaje es identificar exactamente una función diana desconocida f : X → Y a través de consultas a un oráculo. La función de destino se extrae de una función de clase C que es conocida por el algoritmo. Típicamente el dominio X es algún subconjunto de {0, 1}m, y el rango Y es {0, 1} o algún subconjunto de los números reales. A medida que el algoritmo avanza, construye una hipótesis manifiesta?f que es su estimación actual de la función de destino. Después de la terminación, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface?f(x) = f(x) para todos x?X. Es importante especificar la representación que se utilizará para codificar funciones de C. Por ejemplo, considere la siguiente función de {0, 1}m a ♥: f(x) = 2 si x consiste en m 1s, y f(x) = 0 de otra manera. Esta función puede representarse simplemente como una lista de valores de 2m. O puede codificarse como el polinomio 2x1 · · · xm, que es mucho más sucinto. Así pues, la elección de la codificación puede tener un impacto significativo en las necesidades de tiempo y espacio del algoritmo de aprendizaje. Let size(f) ser el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes distintos de cero en el polinomio, por ejemplo. Por lo general, sólo nos referiremos a las clases de representación; las clases de funciones correspondientes serán implícitas. Por ejemplo, la clase de representación de fórmulas DNF monotonas implica la clase de función de funciones booleanas monotonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: la membresía y las consultas de equivalencia. En una consulta de membresía, el aprendiz presenta algunas x x x y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta f. El oráculo responde SÍ si?f = f, o devuelve un contraejemplo x de tal manera que?f(x) = f(x). Una consulta de equivalencia es apropiada si el tamaño( ̃f) ≤ tamaño(f) en el momento de presentar la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones se adaptan a partir de Kearns y Vazirani [9]: Definición 1. La clase de representación C es polinomialquery exactamente aprendeble de las consultas de membresía y equivalencia si hay un polinomial fijo p(·, ·) y un algoritmo L con acceso a la membresía y consultas de equivalencia de un oráculo tal que para cualquier función de destino f • C, L salidas después de a lo sumo p(size(f), m) consultas de una función?f • C tal que?f Del mismo modo, la clase de representación C se puede aprender exactamente de las consultas de membresía y equivalencia si el algoritmo L produce una hipótesis correcta en el tiempo p(size(f), m), para algunos polinomios fijos p(·, ·). Aquí m es la dimensión del dominio. Dado que la función de destino debe ser reconstruida, también permitimos necesariamente la dependencia polinómica del tamaño (f). 2.2 Eliminación de preferencias En una subasta combinatoria, un conjunto de bienes M se asignará entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Tal asignación se llama eficiente en la literatura de economía, pero nos referiremos a ella como óptima y reservar el término eficiente para referirse a la eficiencia computacional. Dejamos n = N y m = M. Una asignación es una partición de los objetos en paquetes (S1,. . . , Sn), de tal manera que Si â € ¬ Sj = â € para todos los i, j â € N. Let â € € sea el conjunto de posibles asignaciones. Cada agente i+N tiene una función de valoración vi : 2M → • sobre el espacio de los paquetes posibles. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no tienen que coincidir. Asumimos que todas las valoraciones consideradas están normalizadas, es decir, v() = 0, y que no hay externalidades, es decir, vi(S1,..., Sn) = vi(Si), para todos los agentes i  N, para cualquier asignación (S1,..., Sn)  (es decir, un agente se preocupa sólo por el paquete asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales.1 Nosotros 1 A menudo las valoraciones generales se hacen para satisfacer los 181 adicionales también asumen que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que los agentes utilidades pueden ser divididos en componentes monetarios y no monetarios. Si a un agente i se le asigna el paquete S al precio p, deriva utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más sucintas para ciertas clases de valoración, y ha habido mucha investigación en lenguajes de licitación concisos para diversos tipos de valoraciones [11]. Un ejemplo clásico al que nos referiremos más adelante es el lenguaje de licitación XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, que consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estas pujas, se busca el paquete S del valor más alto listado en las pujas atómicas de tal manera que S  S. Es entonces el caso que v(S) = v(S). Al igual que en el contexto de la teoría del aprendizaje, por lo general sólo nos referiremos a idiomas de oferta en lugar de clases de valoración, ya que las clases de valoración correspondientes serán implícitas. Por ejemplo, el lenguaje de licitación XOR implica la clase de valoraciones que satisfacen la disposición libre, que es la condición de que A  B ♥ v(A) ≤ v(B). Dejamos el tamaño(v1,. . . , vn) = Èn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de licitación). Para hacer una analogía con la teoría del aprendizaje computacional, suponemos que todas las clases de representación consideradas son polinomiamente interpretables [11], lo que significa que el valor de un paquete puede ser calculado en tiempo polinomio dada la representación de funciones de valoración. Más formalmente, una clase de representación (lenguaje de licitación) C es polinomialmente interpretable si existe un algoritmo que da como entrada algunos v • C y una instancia x • X calcula el valor v(x) en el tiempo q(size(v), m), para algún polinomio fijo q(·, ·).2 En las rondas intermedias de una subasta (terativa), el subastador habrá obtenido información sobre las funciones de Por lo tanto, habrá construido un conjunto de valoraciones manifiestas, denotadas . . Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha adquirido información sobre ciertos paquetes. El objetivo en el problema de la excitación de preferencia es construir un conjunto de valoraciones manifiestas tales que: arg max (S1,...,Sn) iÃ3n Ã3vi(Si)  arg max (S1,...,Sn) iÃ3n vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que es óptima con respecto a las valoraciones verdaderas. Tenga en cuenta que sólo se requiere una asignación óptima. condición de la libre eliminación (monotonicidad), pero no la necesitamos en este punto. 2 Esto excluye OR*, asumiendo P = NP, porque la interpretación de las ofertas de este lenguaje es NP-duro por reducción de set-embalaje ponderado, y no hay clase de representación bien estudiada en teoría de aprendizaje que es claramente análogo a OR*. 3 Esta visión de las subastas iterativas tiene por objeto paralelizar el entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente están implícitas por la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son consultas de valor y demanda. En una consulta de valor, el subastador presenta un paquete S  M y el agente responde con su valor (exacto) para el paquete v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p • • • (2m ) sobre los paquetes junto con un paquete S. El agente responde SI si es el caso de que S • arg max S M v(S ) − p(S ) ¡ o de otro modo presenta un paquete S tal que v(S ) − p(S ) > v( Tenga en cuenta también que comunicar precios no lineales no implica necesariamente citar un precio por cada paquete posible. Puede haber formas más sucintas de comunicar este vector, como se muestra en la sección 5. Hacemos las siguientes definiciones para paralelizar la configuración de aprendizaje de la consulta y para simplificar las declaraciones de resultados posteriores: Definición 2. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si hay un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes tales que para cualquier (v1,. . . , vn) V1 ×. . . × Vn, L salidas después de como máximo p(size(v1,. . . , vn), m) consulta una asignación (S1,. . . , Sn) arg max(S1,...,Sn) È vi(Si). Del mismo modo, la clase de representación C se puede obtener eficientemente de las consultas de valor y demanda si el algoritmo L produce una asignación óptima con comunicación p(size(v1, ). . . , vn), m), para algunos polinomios fijos p(·, ·). Hay algunas diferencias clave aquí con la definición de aprendizaje de la consulta. Hemos eliminado el término exactamente ya que las funciones de valoración no necesitan ser determinadas exactamente con el fin de calcular una asignación óptima. Además, un algoritmo de excitación eficiente es la comunicación polinomio, en lugar de tiempo polinomio. Esto refleja el hecho de que la comunicación en lugar del tiempo de espera es el cuello de botella en la excitación. Cálculo de una asignación óptima de bienes incluso cuando se dan las valoraciones verdaderas es NP-duro para una amplia gama de clases de valoración. Por lo tanto, no es razonable exigir tiempo polinomio en la definición de un algoritmo de excitación de preferencias eficiente. Nos complace centrarnos en la complejidad comunicativa de la excitación porque se cree que este problema es más significativo en la práctica que el de la determinación del ganador [11].5 4 Esto difiere ligeramente de la definición proporcionada por Blum et al. [5] Sus consultas sobre la demanda se limitan a precios lineales sobre las mercancías, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir. un precio distinto por cada paquete posible. Es por eso que el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. 5 Aunque el problema de determinación del ganador es NP-hard para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta aproximaciones usando solucionadores IP fuera de la plataforma [1]. 182 Dado que no es necesario obtener exactamente las valoraciones, es inicialmente menos claro si la dependencia polinómica del tamaño (v1, ). . . , vn) está justificado en este contexto. Intuitivamente, este parámetro está justificado porque debemos aprender valoraciones exactamente cuando se realiza la excitación, en el peor de los casos. Nos ocupamos de esto en la siguiente sección. 3. PARALLESBETWEEN EQUIVALENCIA Y QUERIDAS DE DEMANDA Hemos descrito los ajustes de aprendizaje y excitación de preferencias de la consulta de una manera que destaca sus similitudes. Las consultas de valor y membresía son claras analógicas. Un poco menos obvio es el hecho de que las consultas de equivalencia y demanda también son analógicas. Para ver esto, necesitamos el concepto de precios Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios sobre sus bienes subyacentes. Son no anónimos en el sentido de que dos agentes pueden tener que hacer frente a precios diferentes para el mismo paquete de mercancías. Así los precios de Lindahl son de la forma pi(S), para todos S  M, para todos los precios de i  N. Lindahl se presentan a los agentes en consultas de la demanda. Cuando los agentes han normalizado las funciones de utilidad cuasi-lineal, Bikhchandani y Ostroy [4] muestran que siempre existen precios Lindahl tales que (S1,. . . , Sn) es una asignación óptima si y sólo si Si • arg max Si vi(Si) − pi(Si) • i N (1) (S1,. . . , Sn)  arg max (S1,...,Sn) iN pi(Si) (2) Condición (1) establece que cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos de los subastadores a los precios indicados. El escenario en el que se mantienen estas condiciones se llama equilibrio Lindahl, o a menudo un equilibrio competitivo. Decimos que los precios de Lindahl apoyan la asignación óptima. Por lo tanto, basta con anunciar los precios de apoyo de Lindahl para verificar una asignación óptima. Una vez que hemos encontrado una asignación con el apoyo de precios Lindahl, el problema de excitación se resuelve. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones estén garantizadas como integrales [4]. Las variables duales de este programa lineal están soportando los precios de Lindahl para la asignación resultante. La función objetiva del programa dual es: min pi(S) Por lo general, hay una gama de posibles precios Lindahl que apoyan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios válidos Lindahl, y nos referimos a ellos como precios máximos Lindahl. De todos los vectores posibles de precios Lindahl, precios máximos Lindahl maximizar la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È iÃ3N πi del objetivo (la suma de los agentes de utilidades) son precios mínimos Lindahl. Cualquier Lindahl precios hará para nuestros resultados, pero algunos pueden tener mejores propiedades de excitación que otros. Tenga en cuenta que una consulta de demanda con precios máximos de Lindahl es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para el trabajo futuro la cuestión de los precios de Lindahl para elegir minimizar la obtención de preferencias. Teniendo en cuenta ahora por qué las consultas de demanda y equivalencia son analógicas directas, primero tenga en cuenta que dado el πi en algún equilibrio Lindahl, establecer pi(S) = max{0, Estos precios dejan a cada agente indiferente en todos los paquetes con precio positivo, y satisfacen la condición (1). Así, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl típicamente serán una constante aditivo lejos de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos de consultas de equivalencia a través de consultas de demanda. Lemma 1. Supongamos que un agente responde con un paquete preferido S cuando se propone un paquete S y soporta los precios de Lindahl p(S) (soportando con respecto a la valoración manifiesta de los agentes). A continuación, o bien?v(S) = v(S) o?v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: Φv(S) − p(S) ≥ Desigualdad (6) se mantiene porque el agente de hecho prefiere S a S dados los precios, de acuerdo con su respuesta a la consulta de demanda. Si fuera el caso de que?v(S) = v(S) y Así, al menos uno de S y S es un contraejemplo de la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño(v1,. . . , vn) en problemas de excitación. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que apoyar los precios de Lindahl debe necesariamente revelarse en el curso de cualquier protocolo de obtención de preferencias que termina con una asignación óptima. Además, Nisan y Segal (Lemma 1, [12]) afirman que en el peor de los casos los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones dobles (como será el caso de las clases más interesantes). Puesto que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y puesto que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitiendo la dependencia del tamaño(v1,. . . , vn) en problemas de excitación es totalmente natural. 183 4. DE APRENDIZAJE A LA LICITACIÓN DE PREFERENCIA La clave para convertir un algoritmo de aprendizaje a un algoritmo de excitación es simular consultas de equivalencia con consultas de demanda y valor hasta que se encuentre una asignación óptima. Debido a nuestra construcción de precios Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en que un agente responde SÍ a una consulta de equivalencia cuando la función de destino se ha aprendido exactamente. De lo contrario, podemos obtener un contraejemplo a una consulta de equivalencia dada una respuesta de agentes a una consulta de demanda. Teorema 1. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si cada uno puede ser polinomio-consulta exactamente aprendido de consultas de membresía y equivalencia. Prueba. Considere el algoritmo de excitación en la Figura 1. Cada consulta de membresía en el paso 1 es simulada con una consulta de valor ya que estas son de hecho idénticas. Considere el paso 4. Si todos los agentes responden SÍ, la condición (1) se mantiene. Condición (2) se mantiene porque la asignación calculada es la maximización de ingresos para el subastador, independientemente de los agentes verdaderas valoraciones. Así pues, se ha encontrado una asignación óptima. De lo contrario, por lo menos uno de Si o Si es un contraejemplo a Vi, por Lemma 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones del agente se conocerán exactamente, en cuyo caso la asignación óptima y los precios Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinomio de consultas, desde A1,. . . , A son todos los algoritmos de aprendizaje polinomio-quería. Tenga en cuenta que el procedimiento de conversión resulta en un algoritmo de excitación de preferencias, no un algoritmo de aprendizaje. Es decir, el algoritmo resultante no simplemente aprender las valoraciones exactamente, a continuación, calcular una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor, y periódicamente comprueba si se ha reunido suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio Lindahl para las valoraciones v1,. . . , vn utilizando una asignación y precios derivados de valoraciones manifiestas . . y encontrar una asignación óptima no implica que las valoraciones de los agentes se hayan aprendido exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta interrupción temprana. No obtendremos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE COMUNICACIÓN En esta sección, pasamos a la cuestión de la complejidad comunicativa de la excitación. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (tales como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos de determinar los precios de Lindahl es exponencial en el número de mercancías, m. La carga de comunicación se mide en términos del número de bits transmitidos entre agentes y subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. La conversión de algoritmos de aprendizaje eficientes a un algoritmo de excitación produce un algoritmo cuyas consultas tienen tamaños polinomios en los parámetros m y tamaño (v1, ). . . , vn). Teorema 2. Las clases de representación V1,. . . , Vn se puede obtener de forma eficiente de las consultas de valor y demanda si cada uno puede ser aprendido exactamente de las consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, basta con comunicar la función de valoración manifiesta de los agentes y el valor Nótese que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinomio, porque el tiempo de ejecución de los algoritmos también sería superpolinomio, contradiciendo la eficiencia. Por lo tanto, la comunicación de la valoración manifiesta requiere tamaño a lo sumo p(size(vi), m), para algunos polinomios p que limita superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representando el excedente πi al agente no se puede requerir espacio mayor que q(size( También debemos comunicarnos con su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es como máximo p(size(vi), m) + q(p(size(vi), m), m)+O(m). Claramente, una respuesta de agentes a una consulta de valor o demanda tiene un tamaño máximo de q(size(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, son siempre de tamaño polinomio. Un algoritmo de aprendizaje eficiente realiza un número polinomio de consultas, por lo que la comunicación total del algoritmo de excitación resultante es polinomio en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites pueden ser traducidos a límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de excitación resultante. Con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2 se determinó el tamaño de la hipótesis manifiesta. Es probable que podamos hacerlo mucho mejor que esto en la práctica. Recuerde que una consulta de equivalencia es apropiada si size( ̃f) ≤ size(f) en el momento de realizar la consulta. Si las consultas de equivalencia de algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites estrechos en los requisitos de comunicación del algoritmo de excitación resultante. El teorema 2 muestra que los algoritmos de excitación que dependen del tamaño (v1,. . . El parámetro, vn) evita los resultados negativos de Nisan y Segals [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto al tamaño de las instancias de las funciones de valoración que se enfrentan a cualquier ejecución del algoritmo. Estos algoritmos van bien si la clase de representación elegida proporciona representaciones sucintas para la más simple y común de las valoraciones, y por lo tanto el enfoque se mueve de nuevo a uno de lenguajes de licitación compactos pero expresivos. A continuación se examinan estas cuestiones. 6. APLICACIONES En esta sección, demostramos la aplicación de nuestros métodos a clases particulares de representación para valoraciones combinatorias. Hemos demostrado que el problema de excitación de preferencias para las clases de valoración V1,. . . , Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1,. . . , Una para las valoraciones de las clases V1,. . . , Vn respectivamente. Encaje hasta que haya una señal para detenerse: 1. Corre A1,. . . , Un en paralelo sobre sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se ha detenido con los agentes valoración exacta. 2. Calcular una asignación óptima (S1,. . . , Sn ) y los correspondientes precios de Lindahl con respecto a las valoraciones manifiestas . . , їvn determinado hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de consulta de demanda. 4. Si todos ellos responden SÍ, salida la asignación y parada. De lo contrario hay algún agente i que ha respondido con algún paquete preferido Si. Realizar consultas de valor en Si y Si para encontrar un contraejemplo a ‡vi, y proporcionarlo a Ai. Figura 1: Convertir algoritmos de aprendizaje a un algoritmo de excitación. al problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de función, y porque a menudo puede ser más simple resolver cada subproblema de aprendizaje por separado que atacar el problema de excitación de preferencias directamente. Podemos desarrollar un algoritmo de excitación que se adapta a cada valoración de agentes, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Demostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas de DNF monotono y funciones de umbral lineal se pueden convertir en algoritmos de excitación de preferencia para valoraciones generales, valoraciones con eliminación libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en las representaciones que son polinomialmente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la traqueabilidad computacional [18]. Al interpretar los métodos enfatizamos la expresividad y sucinta de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de licitación, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debe representar sucintamente las funciones más simples y comunes de la clase. 6.1 Las Representaciones Polinómicas Schapire y Sellie [17] dan un algoritmo de aprendizaje para polinomios multivariables escasos que pueden utilizarse como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas apropiadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados de t-sparse sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-sparse tiene como máximo t términos, donde un término es un producto de variables, por ejemplo. x1x3x4. Un polinomio sobre los números reales tiene coeficientes extraídos de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M →  se puede escribir exclusivamente como un polinomio [17]. Para tener una idea de la sucintaidad de los polinomios como lenguaje de licitación, considere las valoraciones aditivas y mono-ítem presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es el número de mercancías que contiene el paquete. En la valoración de un solo elemento, todos los paquetes tienen valor 1, excepto el valor 0 (i.e. el agente está satisfecho tan pronto como ha adquirido un único artículo). No es difícil demostrar que la valoración de un solo elemento requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Por lo tanto, los polinomios son adecuados para valoraciones que en su mayoría son aditivas, con algunas sustituibilidades y complementariedades que pueden introducirse ajustando los coeficientes. El algoritmo de aprendizaje para polinomios hace como máximo consultas de equivalencia mti +2 y como máximo (mti +1) (t2 i +3ti)/2 consultas de membresía a un agente i, donde ti es la esparcidad del polinomio que representa vi [17]. Por lo tanto, se obtiene un algoritmo que provoca valoraciones generales con un número polinomio de consultas y comunicación polinomio.6 6.2 XOR Representaciones El lenguaje de licitación XOR es estándar en la literatura de subastas combinatoria. Recordemos que una oferta XOR se caracteriza por un conjunto de paquetes B  2M y una función de valor w : B →  definida en esos paquetes, que induce la función de valoración: v(B) = max {B  B  B  B} w(B) (7) Las ofertas XOR pueden representar valoraciones que satisfacen la libre eliminación (y sólo tales valoraciones), que de nuevo es la propiedad que A  B El lenguaje de licitación XOR es ligeramente menos expresivo que los polinomios, porque los polinomios pueden representar valoraciones que no satisfacen la libre eliminación. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas de XOR pueden representar la valoración de un solo elemento con ofertas atómicas m, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario se aplica a los polinomios, estas dos lenguas son incomparables en sucintas y algo complementarias para su uso práctico. Blum et al. [5] note que las fórmulas DNF monotonas son los análogos de las pujas XOR en la literatura de teoría del aprendizaje. Una fórmula de DNF monotona es una disyunción de conjunciones en las que las variables aparecen sin negación, por ejemplo x1x2 x3 x2x4x5. Tenga en cuenta que tales fórmulas pueden ser representadas como ofertas XOR donde cada oferta atómica tiene valor 1; por lo tanto XOR ofrece generalizar fórmulas DNF monotono de Boolean a funciones de valor real. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para el DNF monotono ([3] Teorema 6 Tenga en cuenta que el Teorema 1 se aplica incluso si las valoraciones no satisfacen la eliminación libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lemma 2. Una oferta XOR que contiene ofertas t atómicas se puede aprender exactamente con consultas de equivalencia t + 1 y a lo sumo consultas de membresía tm. Prueba. El algoritmo identificará cada puja atómica en la puja XOR objetivo a su vez. Initialice la valoración manifiesta v a la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presente ‡v como consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un paquete S para el que v(S) = Crear un paquete T de la siguiente manera. Primero inicialice T = S. Para cada elemento i en T, compruebe a través de una consulta de membresía si v(T) = v(T − {i}). Si así se establece T = T − {i}. De lo contrario, deje T como está y pase al siguiente punto. Afirmamos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada ítem i en T, tenemos v(T) = v(T − {i}). Para ver esto, tenga en cuenta que en algún momento al generar T, tuvimos un ̄T tal que T  ̄T  S y v( ̄T) > v( ̄T − {i}), de modo que me mantuvo en ̄T. Tenga en cuenta que v(S) = v( ̄T) = v(T) porque el valor del paquete S se mantiene durante todo el proceso de eliminación de elementos. Ahora asume v(T) = v(T − {i}). Entonces v( ̄T) = v(T) = v(T − {i}) > v( ̄T − {i}) que contradice la libre eliminación, ya que T {i}  ̄T − {i}. Por lo tanto v(T) > v(T − {i}) para todos los ítems i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si este no fuera el caso, T tomaría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = máx itat {max T T Ahora mostramos que v(T) = ̃v(T), que implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Asumir que toda oferta atómica (R, Esta suposición se mantiene vagamente cuando se inicializa la valoración manifiesta. Usando la notación de (7), dejar ( Tenemos B  B, y Bw(B) = w(B) para B Por lo tanto,?v(S) = max {B} {B} {B} {B} {B} {B} = max {B} {B} {B} ≤ {B} {B} {B} {B} {S} w(B} = v(S) (8) Ahora asume v(T) {v(T La segunda igualdad se deriva del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad sostiene porque S es un contraejemplo de la valoración manifiesta. De la ecuación (9) y la eliminación libre, nosotros 7 El algoritmo citado también se utilizó como base para Zinkevich et al.s [19] algoritmo de excitación para Toolbox DNF. Recuerde que Toolbox DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia se puede simular con una consulta de valor en el paquete que contiene todas las mercancías. que tengan ‡v(T) < Entonces de nuevo de la ecuación (9) se deduce que v(S) < Esto contradice (8), por lo que de hecho tenemos v(T) = Por lo tanto (T, v(T)) no está actualmente en nuestra hipótesis como una oferta atómica, o tendríamos correctamente?v(T) = v(T) por la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas adicionales de equivalencia hasta que todas las ofertas atómicas hayan sido identificadas. Después de cada consulta de equivalencia, una oferta atómica se identifica con como máximo m consultas de membresía. Cada contraejemplo conduce al descubrimiento de una nueva oferta atómica. Por lo tanto, hacemos a lo sumo consultas de membresía tm y exactamente consultas de equivalencia t + 1. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR se puede obtener eficientemente de las consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al.s ([5], Teorema 2) afirmando que el DNF monotono (y por lo tanto las ofertas XOR) no se pueden obtener de manera eficiente cuando las consultas de demanda se limitan a precios lineales y anónimos sobre las mercancías. 6.3 Las representaciones lineales de umbral polinomios, las ofertas XOR y todas las lenguas basadas en el lenguaje de licitación OR (como XOR-de-OR, OR-de-XOR y OR*) no representan sucintamente la valoración mayoritaria [11]. En esta valoración, los paquetes tienen valor 1 si contienen al menos m/2 ítems, y valor 0 de lo contrario. Más generalmente, considere la familia de r-of-S de valoraciones donde los paquetes tienen valor 1 si contienen al menos r artículos de un conjunto especificado de ítems S  M, y valor 0 de otra manera. La valoración mayoritaria es un caso especial de la valoración de r-of-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar las sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede añadir valor. Dejando k = S, tales valoraciones están sucintamente representadas por funciones de umbral r-of-k. Estas funciones adoptan la forma de desigualdades lineales: xi1 +. . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se mantiene, y 0 de lo contrario. Aquí i1,. . . , ik son los elementos en S. Littlestones WINNOW 2 algoritmo puede aprender tales funciones utilizando consultas de equivalencia sólo, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de excitación que resulta de WINNOW 2 sólo utiliza consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos están implícitos cuando sólo hay dos valores posibles). Tenga en cuenta que las funciones de umbral r-of-k siempre se pueden representar sucintamente en el espacio O(m). Así se obtiene un algoritmo que puede generar tales funciones con un número polinomio de consultas y comunicación polinomio, en los parámetros n y m solos. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exactos con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de excitación de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas en el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la riqueza de algoritmos de aprendizaje disponibles al problema de la excitación de preferencias. Un enfoque de aprendizaje para la excitación también motiva un enfoque diferente para diseñar algoritmos de excitación que se descomponen cuidadosamente entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivos, muchos sustitutos, etc.), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de excitación. El algoritmo de excitación resultante hace un número polinomio de consultas, y hace comunicación polinomio si los algoritmos de aprendizaje originales son eficientes. No exigimos que las valoraciones de agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia sólo pueden ser, y sólo necesitan ser, simuladas hasta el punto en que se ha calculado una asignación óptima. Este es el problema de la excitación de preferencias. Teorema 1 implica que la excitación con consultas de valor y demanda no es más difícil que aprender con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las que la excitación es más fácil que el aprendizaje. Blum et al. [5] proporcionar tal ejemplo al considerar solamente consultas de membresía/valor (Teorema 4). En el trabajo futuro planeamos abordar la cuestión de los incentivos al convertir algoritmos de aprendizaje a algoritmos de excitación. En el entorno de aprendizaje, por lo general suponemos que los oráculos proporcionarán respuestas honestas a las preguntas; en el entorno de excitación, los agentes son generalmente egoístas y proporcionarán respuestas posiblemente deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para el aprendizaje de polinomios y ofertas XOR como algoritmos de excitación, y probar su rendimiento contra otros protocolos de subasta combinatoria establecidos [6, 15]. Una pregunta interesante aquí es: ¿qué precios Lindahl en el rango máximo a mínimo son los mejores para citar con el fin de minimizar la revelación de información? Suponemos que la revelación de información se reduce al pasar de precios máximos a precios mínimos de Lindahl, es decir, a medida que desplazamos las consultas de demanda más lejos de las consultas de equivalencia. Por último, sería útil determinar si el lenguaje de licitación de OR* [11] puede aprenderse (y, por lo tanto, obtenerse) de manera eficiente, dada la expresividad y sucinta de estas lenguas para una amplia variedad de clases de valoración. Agradecimientos Queremos agradecer a Debasis Mishra por sus útiles discusiones. Este trabajo está apoyado en parte por la subvención de NSF IIS0238147. 8. REFERENCIAS [1] A. Andersson, M. Tenhunen, y F. Ygge. Programación integral para la determinación del ganador de la subasta combinatoria. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprender conjuntos regulares de consultas y contraejemplos. Información e computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje conceptual. Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El modelo de asignación de paquetes. Diario de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Provocación de preferencias y aprendizaje de consultas. En Proc. 16a Conferencia Anual sobre Teoría del Aprendizaje Computacional (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. la 18a Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, e Y. Shoham. Domar la complejidad computacional de las subastas combinatoria: Enfoques óptimos y aproximados. En Proc. , 16a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), págs. 548 a 553, 1999. [8] B. Hudson y T. Sandholm. Uso de consultas de valor en subastas combinatoria. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría del aprendizaje computacional. MIT Press, 1994. [10] N. Littlestone. Aprender rápidamente cuando los atributos irrelevantes abundan: Un nuevo algoritmo de umbral lineal. Machine Learning, 2:285-318, 1988. [11] N. Nisan. Licitación y asignación en subastas combinatoria. En Proc. la Conferencia de la ACM sobre Comercio Electrónico, págs. 1 a 12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y el apoyo a los precios Lindahl. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de mínima revelación. En Padget et al., editor, Agent-Mediated Electronic Commerce IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. Diseño de subastas con costosas preferencias. En Temas Especiales de Anales de Matemáticas y AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17a Conferencia Nacional sobre Inteligencia Artificial (AAAI-00), págs. 74 a 81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. la 17a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariables escasos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de ACM sobre Teoría del Aprendizaje Computacional, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendido. Comun. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum, y T. Sandholm. Sobre la excitación de la preferencia polinomio-tiempo con las consultas de valor. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "error": []
        },
        "polynomial communication": {
            "translated_key": [
                "comunicación polinómica",
                "comunicación polinómica",
                "comunicación polinómica",
                "comunicación polinómica",
                "comunicación polinomio",
                "comunicación polinomio",
                "comunicación polinomio"
            ],
            "translated_annotated_text": "Aplicando algoritmos de aprendizaje a la eliminación de preferencia Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de excitación Demostramos que los algoritmos de aprendizaje pueden ser usados como base para algoritmos de excitación de preferencias. Los algoritmos de excitación resultantes realizan un número polinomio de consultas. También damos condiciones bajo las cuales los algoritmos resultantes tienen \"comunicación polinómica\". Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. En particular, obtenemos un algoritmo que provoca ofertas XOR con \"comunicación polinómica\". Categorías y Descriptores sujetos F.2.0 [Análisis de algoritmos y complejidad de problemas]: General; J.4 [Ciencias Sociales y Conductuales]: Economía; I.2.6 [Inteligencia Artificial]: Términos generales de aprendizaje Algoritmos, Economía, Teoría 1. INTRODUCCIÓN En una subasta combinatoria, los agentes pueden pujar por paquetes de bienes en lugar de por cada uno de ellos. Puesto que hay un número exponencial de paquetes (en el número de bienes), comunicar los valores sobre estos paquetes puede ser problemático. Comunicar las valoraciones de una sola vez puede ser prohibitivamente costoso si el número de bienes es sólo moderadamente grande. Además, incluso podría ser difícil para los agentes determinar sus valoraciones para paquetes únicos [14]. A esos agentes les interesa disponer de protocolos de subasta que les obliguen a pujar en el menor número posible de paquetes. Incluso si los agentes pueden calcular eficientemente sus valoraciones, podrían ser reacios a revelarlas enteramente en el curso de una subasta, porque tal información puede ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información necesaria para determinar una asignación óptima de los bienes. Ha habido un trabajo reciente explorando los vínculos entre el problema de la excitación de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje computacional [5, 19]. En teoría de aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, tales como ¿Cuál es el valor de las funciones en estas entradas? En la obtención de preferencia, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Demostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia se puede convertir en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de excitación resultante garantiza la excitación en un número polinomio de consultas de valor y demanda. Aquí queremos decir polinomio en el número de bienes, agentes, y los tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Argumentamos que las garantías de complejidad para los esquemas de excitación deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar la comunicación polinómica en el peor de los casos, que normalmente no se puede lograr en el número de productos y agentes por sí solos. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. Por supuesto, una subasta combinatoria de un solo disparo donde los agentes proporcionan todas sus funciones de valoración a la vez también tendría \"comunicación polinómica\" en el tamaño de las valoraciones de los agentes, y sólo requieren una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay ninguna carga para los agentes de formular sus valoraciones en un esquema de codificación de los subastadores que elijan. Esperamos que esta sea una consideración importante en la práctica. Además, con nuestro esquema la revelación entera sólo ocurre en el peor de los casos. 180 Por ahora, dejamos a un lado la cuestión de los incentivos al derivar algoritmos de excitación. Nos centramos en el tiempo y la complejidad de la comunicación de la obtención de preferencias, independientemente de las limitaciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich y otros [19] considerar el problema del aprendizaje de clases restringidas de funciones de valoración que se pueden representar utilizando fórmulas de lectura once y Toolbox DNF. Las fórmulas Read-once pueden representar ciertas sustitutibilidades, pero no complementariedades, mientras que lo contrario se mantiene para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten depender del tamaño de la valoración objetivo como lo hacemos (aunque las valoraciones de read-once siempre se pueden representar sucintamente de todos modos). Su trabajo sólo hace uso de consultas de valor, que son bastante limitados en el poder. Debido a que nos permitimos pedir consultas, somos capaces de derivar un esquema de excitación para las funciones de valoración general. Blum et al. [5] proporcionar resultados relacionados con las complejidades del aprendizaje de la consulta y la excitación de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje de consultas, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones se pueden aprender eficientemente, pero no se pueden obtener eficientemente, y viceversa. En contraste, nuestro trabajo muestra que dada una versión más general (todavía bastante estándar) de la consulta de demanda que el tipo que consideran, la complejidad de la excitación de preferencia no es mayor que la complejidad del aprendizaje. Demostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre valoraciones para implicar una solución al problema de excitación. Nisan y Segal [12] estudian la complejidad comunicativa de la excitación de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos de la computación una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo se permite a los algoritmos hacer preguntas sobre valoraciones de agentes y recibir respuestas honestas, sin ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda la cuestión de la complejidad de la comunicación, y somos capaces de derivar algoritmos que proporcionan garantías de comunicación significativas a pesar de los resultados negativos de Nisan y Segals. Su trabajo motiva la necesidad de confiar en el tamaño de los agentes funciones de valoración para indicar los peores resultados. 2. LOS MODELOS 2.1 Aprendizaje de la consulta El modelo de aprendizaje de la consulta que consideramos aquí se llama aprendizaje exacto de la membresía y consultas de equivalencia, introducido por Angluin [2]. En este modelo el objetivo de los algoritmos de aprendizaje es identificar exactamente una función diana desconocida f : X → Y a través de consultas a un oráculo. La función de destino se extrae de una función de clase C que es conocida por el algoritmo. Típicamente el dominio X es algún subconjunto de {0, 1}m, y el rango Y es {0, 1} o algún subconjunto de los números reales. A medida que el algoritmo avanza, construye una hipótesis manifiesta?f que es su estimación actual de la función de destino. Después de la terminación, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface?f(x) = f(x) para todos x?X. Es importante especificar la representación que se utilizará para codificar funciones de C. Por ejemplo, considere la siguiente función de {0, 1}m a ♥: f(x) = 2 si x consiste en m 1s, y f(x) = 0 de otra manera. Esta función puede representarse simplemente como una lista de valores de 2m. O puede codificarse como el polinomio 2x1 · · · xm, que es mucho más sucinto. Así pues, la elección de la codificación puede tener un impacto significativo en las necesidades de tiempo y espacio del algoritmo de aprendizaje. Let size(f) ser el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes distintos de cero en el polinomio, por ejemplo. Por lo general, sólo nos referiremos a las clases de representación; las clases de funciones correspondientes serán implícitas. Por ejemplo, la clase de representación de fórmulas DNF monotonas implica la clase de función de funciones booleanas monotonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: la membresía y las consultas de equivalencia. En una consulta de membresía, el aprendiz presenta algunas x x x y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta f. El oráculo responde SÍ si?f = f, o devuelve un contraejemplo x de tal manera que?f(x) = f(x). Una consulta de equivalencia es apropiada si el tamaño( ̃f) ≤ tamaño(f) en el momento de presentar la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones se adaptan a partir de Kearns y Vazirani [9]: Definición 1. La clase de representación C es polinomialquery exactamente aprendeble de las consultas de membresía y equivalencia si hay un polinomial fijo p(·, ·) y un algoritmo L con acceso a la membresía y consultas de equivalencia de un oráculo tal que para cualquier función de destino f • C, L salidas después de a lo sumo p(size(f), m) consultas de una función?f • C tal que?f Del mismo modo, la clase de representación C se puede aprender exactamente de las consultas de membresía y equivalencia si el algoritmo L produce una hipótesis correcta en el tiempo p(size(f), m), para algunos polinomios fijos p(·, ·). Aquí m es la dimensión del dominio. Dado que la función de destino debe ser reconstruida, también permitimos necesariamente la dependencia polinómica del tamaño (f). 2.2 Eliminación de preferencias En una subasta combinatoria, un conjunto de bienes M se asignará entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Tal asignación se llama eficiente en la literatura de economía, pero nos referiremos a ella como óptima y reservar el término eficiente para referirse a la eficiencia computacional. Dejamos n = N y m = M. Una asignación es una partición de los objetos en paquetes (S1,. . . , Sn), de tal manera que Si â € ¬ Sj = â € para todos los i, j â € N. Let â € € sea el conjunto de posibles asignaciones. Cada agente i+N tiene una función de valoración vi : 2M → • sobre el espacio de los paquetes posibles. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no tienen que coincidir. Asumimos que todas las valoraciones consideradas están normalizadas, es decir, v() = 0, y que no hay externalidades, es decir, vi(S1,..., Sn) = vi(Si), para todos los agentes i  N, para cualquier asignación (S1,..., Sn)  (es decir, un agente se preocupa sólo por el paquete asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales.1 Nosotros 1 A menudo las valoraciones generales se hacen para satisfacer los 181 adicionales también asumen que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que los agentes utilidades pueden ser divididos en componentes monetarios y no monetarios. Si a un agente i se le asigna el paquete S al precio p, deriva utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más sucintas para ciertas clases de valoración, y ha habido mucha investigación en lenguajes de licitación concisos para diversos tipos de valoraciones [11]. Un ejemplo clásico al que nos referiremos más adelante es el lenguaje de licitación XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, que consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estas pujas, se busca el paquete S del valor más alto listado en las pujas atómicas de tal manera que S  S. Es entonces el caso que v(S) = v(S). Al igual que en el contexto de la teoría del aprendizaje, por lo general sólo nos referiremos a idiomas de oferta en lugar de clases de valoración, ya que las clases de valoración correspondientes serán implícitas. Por ejemplo, el lenguaje de licitación XOR implica la clase de valoraciones que satisfacen la disposición libre, que es la condición de que A  B ♥ v(A) ≤ v(B). Dejamos el tamaño(v1,. . . , vn) = Èn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de licitación). Para hacer una analogía con la teoría del aprendizaje computacional, suponemos que todas las clases de representación consideradas son polinomiamente interpretables [11], lo que significa que el valor de un paquete puede ser calculado en tiempo polinomio dada la representación de funciones de valoración. Más formalmente, una clase de representación (lenguaje de licitación) C es polinomialmente interpretable si existe un algoritmo que da como entrada algunos v • C y una instancia x • X calcula el valor v(x) en el tiempo q(size(v), m), para algún polinomio fijo q(·, ·).2 En las rondas intermedias de una subasta (terativa), el subastador habrá obtenido información sobre las funciones de Por lo tanto, habrá construido un conjunto de valoraciones manifiestas, denotadas . . Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha adquirido información sobre ciertos paquetes. El objetivo en el problema de la excitación de preferencia es construir un conjunto de valoraciones manifiestas tales que: arg max (S1,...,Sn) iÃ3n Ã3vi(Si)  arg max (S1,...,Sn) iÃ3n vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que es óptima con respecto a las valoraciones verdaderas. Tenga en cuenta que sólo se requiere una asignación óptima. condición de la libre eliminación (monotonicidad), pero no la necesitamos en este punto. 2 Esto excluye OR*, asumiendo P = NP, porque la interpretación de las ofertas de este lenguaje es NP-duro por reducción de set-embalaje ponderado, y no hay clase de representación bien estudiada en teoría de aprendizaje que es claramente análogo a OR*. 3 Esta visión de las subastas iterativas tiene por objeto paralelizar el entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente están implícitas por la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son consultas de valor y demanda. En una consulta de valor, el subastador presenta un paquete S  M y el agente responde con su valor (exacto) para el paquete v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p • • • (2m ) sobre los paquetes junto con un paquete S. El agente responde SI si es el caso de que S • arg max S M v(S ) − p(S ) ¡ o de otro modo presenta un paquete S tal que v(S ) − p(S ) > v( Tenga en cuenta también que comunicar precios no lineales no implica necesariamente citar un precio por cada paquete posible. Puede haber formas más sucintas de comunicar este vector, como se muestra en la sección 5. Hacemos las siguientes definiciones para paralelizar la configuración de aprendizaje de la consulta y para simplificar las declaraciones de resultados posteriores: Definición 2. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si hay un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes tales que para cualquier (v1,. . . , vn) V1 ×. . . × Vn, L salidas después de como máximo p(size(v1,. . . , vn), m) consulta una asignación (S1,. . . , Sn) arg max(S1,...,Sn) È vi(Si). Del mismo modo, la clase de representación C se puede obtener eficientemente de las consultas de valor y demanda si el algoritmo L produce una asignación óptima con comunicación p(size(v1, ). . . , vn), m), para algunos polinomios fijos p(·, ·). Hay algunas diferencias clave aquí con la definición de aprendizaje de la consulta. Hemos eliminado el término exactamente ya que las funciones de valoración no necesitan ser determinadas exactamente con el fin de calcular una asignación óptima. Además, un algoritmo de excitación eficiente es \"comunicación polinómica\", en lugar de tiempo polinomio. Esto refleja el hecho de que la comunicación en lugar del tiempo de espera es el cuello de botella en la excitación. Cálculo de una asignación óptima de bienes incluso cuando se dan las valoraciones verdaderas es NP-duro para una amplia gama de clases de valoración. Por lo tanto, no es razonable exigir tiempo polinomio en la definición de un algoritmo de excitación de preferencias eficiente. Nos complace centrarnos en la complejidad comunicativa de la excitación porque se cree que este problema es más significativo en la práctica que el de la determinación del ganador [11].5 4 Esto difiere ligeramente de la definición proporcionada por Blum et al. [5] Sus consultas sobre la demanda se limitan a precios lineales sobre las mercancías, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir. un precio distinto por cada paquete posible. Es por eso que el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. 5 Aunque el problema de determinación del ganador es NP-hard para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta aproximaciones usando solucionadores IP fuera de la plataforma [1]. 182 Dado que no es necesario obtener exactamente las valoraciones, es inicialmente menos claro si la dependencia polinómica del tamaño (v1, ). . . , vn) está justificado en este contexto. Intuitivamente, este parámetro está justificado porque debemos aprender valoraciones exactamente cuando se realiza la excitación, en el peor de los casos. Nos ocupamos de esto en la siguiente sección. 3. PARALLESBETWEEN EQUIVALENCIA Y QUERIDAS DE DEMANDA Hemos descrito los ajustes de aprendizaje y excitación de preferencias de la consulta de una manera que destaca sus similitudes. Las consultas de valor y membresía son claras analógicas. Un poco menos obvio es el hecho de que las consultas de equivalencia y demanda también son analógicas. Para ver esto, necesitamos el concepto de precios Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios sobre sus bienes subyacentes. Son no anónimos en el sentido de que dos agentes pueden tener que hacer frente a precios diferentes para el mismo paquete de mercancías. Así los precios de Lindahl son de la forma pi(S), para todos S  M, para todos los precios de i  N. Lindahl se presentan a los agentes en consultas de la demanda. Cuando los agentes han normalizado las funciones de utilidad cuasi-lineal, Bikhchandani y Ostroy [4] muestran que siempre existen precios Lindahl tales que (S1,. . . , Sn) es una asignación óptima si y sólo si Si • arg max Si vi(Si) − pi(Si) • i N (1) (S1,. . . , Sn)  arg max (S1,...,Sn) iN pi(Si) (2) Condición (1) establece que cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos de los subastadores a los precios indicados. El escenario en el que se mantienen estas condiciones se llama equilibrio Lindahl, o a menudo un equilibrio competitivo. Decimos que los precios de Lindahl apoyan la asignación óptima. Por lo tanto, basta con anunciar los precios de apoyo de Lindahl para verificar una asignación óptima. Una vez que hemos encontrado una asignación con el apoyo de precios Lindahl, el problema de excitación se resuelve. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones estén garantizadas como integrales [4]. Las variables duales de este programa lineal están soportando los precios de Lindahl para la asignación resultante. La función objetiva del programa dual es: min pi(S) Por lo general, hay una gama de posibles precios Lindahl que apoyan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios válidos Lindahl, y nos referimos a ellos como precios máximos Lindahl. De todos los vectores posibles de precios Lindahl, precios máximos Lindahl maximizar la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È iÃ3N πi del objetivo (la suma de los agentes de utilidades) son precios mínimos Lindahl. Cualquier Lindahl precios hará para nuestros resultados, pero algunos pueden tener mejores propiedades de excitación que otros. Tenga en cuenta que una consulta de demanda con precios máximos de Lindahl es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para el trabajo futuro la cuestión de los precios de Lindahl para elegir minimizar la obtención de preferencias. Teniendo en cuenta ahora por qué las consultas de demanda y equivalencia son analógicas directas, primero tenga en cuenta que dado el πi en algún equilibrio Lindahl, establecer pi(S) = max{0, Estos precios dejan a cada agente indiferente en todos los paquetes con precio positivo, y satisfacen la condición (1). Así, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl típicamente serán una constante aditivo lejos de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos de consultas de equivalencia a través de consultas de demanda. Lemma 1. Supongamos que un agente responde con un paquete preferido S cuando se propone un paquete S y soporta los precios de Lindahl p(S) (soportando con respecto a la valoración manifiesta de los agentes). A continuación, o bien?v(S) = v(S) o?v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: Φv(S) − p(S) ≥ Desigualdad (6) se mantiene porque el agente de hecho prefiere S a S dados los precios, de acuerdo con su respuesta a la consulta de demanda. Si fuera el caso de que?v(S) = v(S) y Así, al menos uno de S y S es un contraejemplo de la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño(v1,. . . , vn) en problemas de excitación. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que apoyar los precios de Lindahl debe necesariamente revelarse en el curso de cualquier protocolo de obtención de preferencias que termina con una asignación óptima. Además, Nisan y Segal (Lemma 1, [12]) afirman que en el peor de los casos los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones dobles (como será el caso de las clases más interesantes). Puesto que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y puesto que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitiendo la dependencia del tamaño(v1,. . . , vn) en problemas de excitación es totalmente natural. 183 4. DE APRENDIZAJE A LA LICITACIÓN DE PREFERENCIA La clave para convertir un algoritmo de aprendizaje a un algoritmo de excitación es simular consultas de equivalencia con consultas de demanda y valor hasta que se encuentre una asignación óptima. Debido a nuestra construcción de precios Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en que un agente responde SÍ a una consulta de equivalencia cuando la función de destino se ha aprendido exactamente. De lo contrario, podemos obtener un contraejemplo a una consulta de equivalencia dada una respuesta de agentes a una consulta de demanda. Teorema 1. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si cada uno puede ser polinomio-consulta exactamente aprendido de consultas de membresía y equivalencia. Prueba. Considere el algoritmo de excitación en la Figura 1. Cada consulta de membresía en el paso 1 es simulada con una consulta de valor ya que estas son de hecho idénticas. Considere el paso 4. Si todos los agentes responden SÍ, la condición (1) se mantiene. Condición (2) se mantiene porque la asignación calculada es la maximización de ingresos para el subastador, independientemente de los agentes verdaderas valoraciones. Así pues, se ha encontrado una asignación óptima. De lo contrario, por lo menos uno de Si o Si es un contraejemplo a Vi, por Lemma 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones del agente se conocerán exactamente, en cuyo caso la asignación óptima y los precios Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinomio de consultas, desde A1,. . . , A son todos los algoritmos de aprendizaje polinomio-quería. Tenga en cuenta que el procedimiento de conversión resulta en un algoritmo de excitación de preferencias, no un algoritmo de aprendizaje. Es decir, el algoritmo resultante no simplemente aprender las valoraciones exactamente, a continuación, calcular una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor, y periódicamente comprueba si se ha reunido suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio Lindahl para las valoraciones v1,. . . , vn utilizando una asignación y precios derivados de valoraciones manifiestas . . y encontrar una asignación óptima no implica que las valoraciones de los agentes se hayan aprendido exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta interrupción temprana. No obtendremos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE COMUNICACIÓN En esta sección, pasamos a la cuestión de la complejidad comunicativa de la excitación. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (tales como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos de determinar los precios de Lindahl es exponencial en el número de mercancías, m. La carga de comunicación se mide en términos del número de bits transmitidos entre agentes y subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. La conversión de algoritmos de aprendizaje eficientes a un algoritmo de excitación produce un algoritmo cuyas consultas tienen tamaños polinomios en los parámetros m y tamaño (v1, ). . . , vn). Teorema 2. Las clases de representación V1,. . . , Vn se puede obtener de forma eficiente de las consultas de valor y demanda si cada uno puede ser aprendido exactamente de las consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, basta con comunicar la función de valoración manifiesta de los agentes y el valor Nótese que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinomio, porque el tiempo de ejecución de los algoritmos también sería superpolinomio, contradiciendo la eficiencia. Por lo tanto, la comunicación de la valoración manifiesta requiere tamaño a lo sumo p(size(vi), m), para algunos polinomios p que limita superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representando el excedente πi al agente no se puede requerir espacio mayor que q(size( También debemos comunicarnos con su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es como máximo p(size(vi), m) + q(p(size(vi), m), m)+O(m). Claramente, una respuesta de agentes a una consulta de valor o demanda tiene un tamaño máximo de q(size(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, son siempre de tamaño polinomio. Un algoritmo de aprendizaje eficiente realiza un número polinomio de consultas, por lo que la comunicación total del algoritmo de excitación resultante es polinomio en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites pueden ser traducidos a límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de excitación resultante. Con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2 se determinó el tamaño de la hipótesis manifiesta. Es probable que podamos hacerlo mucho mejor que esto en la práctica. Recuerde que una consulta de equivalencia es apropiada si size( ̃f) ≤ size(f) en el momento de realizar la consulta. Si las consultas de equivalencia de algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites estrechos en los requisitos de comunicación del algoritmo de excitación resultante. El teorema 2 muestra que los algoritmos de excitación que dependen del tamaño (v1,. . . El parámetro, vn) evita los resultados negativos de Nisan y Segals [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto al tamaño de las instancias de las funciones de valoración que se enfrentan a cualquier ejecución del algoritmo. Estos algoritmos van bien si la clase de representación elegida proporciona representaciones sucintas para la más simple y común de las valoraciones, y por lo tanto el enfoque se mueve de nuevo a uno de lenguajes de licitación compactos pero expresivos. A continuación se examinan estas cuestiones. 6. APLICACIONES En esta sección, demostramos la aplicación de nuestros métodos a clases particulares de representación para valoraciones combinatorias. Hemos demostrado que el problema de excitación de preferencias para las clases de valoración V1,. . . , Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1,. . . , Una para las valoraciones de las clases V1,. . . , Vn respectivamente. Encaje hasta que haya una señal para detenerse: 1. Corre A1,. . . , Un en paralelo sobre sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se ha detenido con los agentes valoración exacta. 2. Calcular una asignación óptima (S1,. . . , Sn ) y los correspondientes precios de Lindahl con respecto a las valoraciones manifiestas . . , їvn determinado hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de consulta de demanda. 4. Si todos ellos responden SÍ, salida la asignación y parada. De lo contrario hay algún agente i que ha respondido con algún paquete preferido Si. Realizar consultas de valor en Si y Si para encontrar un contraejemplo a ‡vi, y proporcionarlo a Ai. Figura 1: Convertir algoritmos de aprendizaje a un algoritmo de excitación. al problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de función, y porque a menudo puede ser más simple resolver cada subproblema de aprendizaje por separado que atacar el problema de excitación de preferencias directamente. Podemos desarrollar un algoritmo de excitación que se adapta a cada valoración de agentes, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Demostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas de DNF monotono y funciones de umbral lineal se pueden convertir en algoritmos de excitación de preferencia para valoraciones generales, valoraciones con eliminación libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en las representaciones que son polinomialmente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la traqueabilidad computacional [18]. Al interpretar los métodos enfatizamos la expresividad y sucinta de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de licitación, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debe representar sucintamente las funciones más simples y comunes de la clase. 6.1 Las Representaciones Polinómicas Schapire y Sellie [17] dan un algoritmo de aprendizaje para polinomios multivariables escasos que pueden utilizarse como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas apropiadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados de t-sparse sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-sparse tiene como máximo t términos, donde un término es un producto de variables, por ejemplo. x1x3x4. Un polinomio sobre los números reales tiene coeficientes extraídos de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M →  se puede escribir exclusivamente como un polinomio [17]. Para tener una idea de la sucintaidad de los polinomios como lenguaje de licitación, considere las valoraciones aditivas y mono-ítem presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es el número de mercancías que contiene el paquete. En la valoración de un solo elemento, todos los paquetes tienen valor 1, excepto el valor 0 (i.e. el agente está satisfecho tan pronto como ha adquirido un único artículo). No es difícil demostrar que la valoración de un solo elemento requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Por lo tanto, los polinomios son adecuados para valoraciones que en su mayoría son aditivas, con algunas sustituibilidades y complementariedades que pueden introducirse ajustando los coeficientes. El algoritmo de aprendizaje para polinomios hace como máximo consultas de equivalencia mti +2 y como máximo (mti +1) (t2 i +3ti)/2 consultas de membresía a un agente i, donde ti es la esparcidad del polinomio que representa vi [17]. Por lo tanto, se obtiene un algoritmo que provoca valoraciones generales con un número polinomio de consultas y \"comunicación polinomio\".6 6.2 XOR Representaciones El lenguaje de licitación XOR es estándar en la literatura de subastas combinatoria. Recordemos que una oferta XOR se caracteriza por un conjunto de paquetes B  2M y una función de valor w : B →  definida en esos paquetes, que induce la función de valoración: v(B) = max {B  B  B  B} w(B) (7) Las ofertas XOR pueden representar valoraciones que satisfacen la libre eliminación (y sólo tales valoraciones), que de nuevo es la propiedad que A  B El lenguaje de licitación XOR es ligeramente menos expresivo que los polinomios, porque los polinomios pueden representar valoraciones que no satisfacen la libre eliminación. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas de XOR pueden representar la valoración de un solo elemento con ofertas atómicas m, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario se aplica a los polinomios, estas dos lenguas son incomparables en sucintas y algo complementarias para su uso práctico. Blum et al. [5] note que las fórmulas DNF monotonas son los análogos de las pujas XOR en la literatura de teoría del aprendizaje. Una fórmula de DNF monotona es una disyunción de conjunciones en las que las variables aparecen sin negación, por ejemplo x1x2 x3 x2x4x5. Tenga en cuenta que tales fórmulas pueden ser representadas como ofertas XOR donde cada oferta atómica tiene valor 1; por lo tanto XOR ofrece generalizar fórmulas DNF monotono de Boolean a funciones de valor real. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para el DNF monotono ([3] Teorema 6 Tenga en cuenta que el Teorema 1 se aplica incluso si las valoraciones no satisfacen la eliminación libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lemma 2. Una oferta XOR que contiene ofertas t atómicas se puede aprender exactamente con consultas de equivalencia t + 1 y a lo sumo consultas de membresía tm. Prueba. El algoritmo identificará cada puja atómica en la puja XOR objetivo a su vez. Initialice la valoración manifiesta v a la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presente ‡v como consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un paquete S para el que v(S) = Crear un paquete T de la siguiente manera. Primero inicialice T = S. Para cada elemento i en T, compruebe a través de una consulta de membresía si v(T) = v(T − {i}). Si así se establece T = T − {i}. De lo contrario, deje T como está y pase al siguiente punto. Afirmamos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada ítem i en T, tenemos v(T) = v(T − {i}). Para ver esto, tenga en cuenta que en algún momento al generar T, tuvimos un ̄T tal que T  ̄T  S y v( ̄T) > v( ̄T − {i}), de modo que me mantuvo en ̄T. Tenga en cuenta que v(S) = v( ̄T) = v(T) porque el valor del paquete S se mantiene durante todo el proceso de eliminación de elementos. Ahora asume v(T) = v(T − {i}). Entonces v( ̄T) = v(T) = v(T − {i}) > v( ̄T − {i}) que contradice la libre eliminación, ya que T {i}  ̄T − {i}. Por lo tanto v(T) > v(T − {i}) para todos los ítems i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si este no fuera el caso, T tomaría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = máx itat {max T T Ahora mostramos que v(T) = ̃v(T), que implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Asumir que toda oferta atómica (R, Esta suposición se mantiene vagamente cuando se inicializa la valoración manifiesta. Usando la notación de (7), dejar ( Tenemos B  B, y Bw(B) = w(B) para B Por lo tanto,?v(S) = max {B} {B} {B} {B} {B} {B} = max {B} {B} {B} ≤ {B} {B} {B} {B} {S} w(B} = v(S) (8) Ahora asume v(T) {v(T La segunda igualdad se deriva del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad sostiene porque S es un contraejemplo de la valoración manifiesta. De la ecuación (9) y la eliminación libre, nosotros 7 El algoritmo citado también se utilizó como base para Zinkevich et al.s [19] algoritmo de excitación para Toolbox DNF. Recuerde que Toolbox DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia se puede simular con una consulta de valor en el paquete que contiene todas las mercancías. que tengan ‡v(T) < Entonces de nuevo de la ecuación (9) se deduce que v(S) < Esto contradice (8), por lo que de hecho tenemos v(T) = Por lo tanto (T, v(T)) no está actualmente en nuestra hipótesis como una oferta atómica, o tendríamos correctamente?v(T) = v(T) por la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas adicionales de equivalencia hasta que todas las ofertas atómicas hayan sido identificadas. Después de cada consulta de equivalencia, una oferta atómica se identifica con como máximo m consultas de membresía. Cada contraejemplo conduce al descubrimiento de una nueva oferta atómica. Por lo tanto, hacemos a lo sumo consultas de membresía tm y exactamente consultas de equivalencia t + 1. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR se puede obtener eficientemente de las consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al.s ([5], Teorema 2) afirmando que el DNF monotono (y por lo tanto las ofertas XOR) no se pueden obtener de manera eficiente cuando las consultas de demanda se limitan a precios lineales y anónimos sobre las mercancías. 6.3 Las representaciones lineales de umbral polinomios, las ofertas XOR y todas las lenguas basadas en el lenguaje de licitación OR (como XOR-de-OR, OR-de-XOR y OR*) no representan sucintamente la valoración mayoritaria [11]. En esta valoración, los paquetes tienen valor 1 si contienen al menos m/2 ítems, y valor 0 de lo contrario. Más generalmente, considere la familia de r-of-S de valoraciones donde los paquetes tienen valor 1 si contienen al menos r artículos de un conjunto especificado de ítems S  M, y valor 0 de otra manera. La valoración mayoritaria es un caso especial de la valoración de r-of-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar las sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede añadir valor. Dejando k = S, tales valoraciones están sucintamente representadas por funciones de umbral r-of-k. Estas funciones adoptan la forma de desigualdades lineales: xi1 +. . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se mantiene, y 0 de lo contrario. Aquí i1,. . . , ik son los elementos en S. Littlestones WINNOW 2 algoritmo puede aprender tales funciones utilizando consultas de equivalencia sólo, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de excitación que resulta de WINNOW 2 sólo utiliza consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos están implícitos cuando sólo hay dos valores posibles). Tenga en cuenta que las funciones de umbral r-of-k siempre se pueden representar sucintamente en el espacio O(m). Así se obtiene un algoritmo que puede generar tales funciones con un número polinomio de consultas y \"comunicación polinomio\", en los parámetros n y m solos. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exactos con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de excitación de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas en el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la riqueza de algoritmos de aprendizaje disponibles al problema de la excitación de preferencias. Un enfoque de aprendizaje para la excitación también motiva un enfoque diferente para diseñar algoritmos de excitación que se descomponen cuidadosamente entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivos, muchos sustitutos, etc.), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de excitación. El algoritmo de excitación resultante hace un número polinomio de consultas, y hace \"comunicación polinomio\" si los algoritmos de aprendizaje originales son eficientes. No exigimos que las valoraciones de agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia sólo pueden ser, y sólo necesitan ser, simuladas hasta el punto en que se ha calculado una asignación óptima. Este es el problema de la excitación de preferencias. Teorema 1 implica que la excitación con consultas de valor y demanda no es más difícil que aprender con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las que la excitación es más fácil que el aprendizaje. Blum et al. [5] proporcionar tal ejemplo al considerar solamente consultas de membresía/valor (Teorema 4). En el trabajo futuro planeamos abordar la cuestión de los incentivos al convertir algoritmos de aprendizaje a algoritmos de excitación. En el entorno de aprendizaje, por lo general suponemos que los oráculos proporcionarán respuestas honestas a las preguntas; en el entorno de excitación, los agentes son generalmente egoístas y proporcionarán respuestas posiblemente deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para el aprendizaje de polinomios y ofertas XOR como algoritmos de excitación, y probar su rendimiento contra otros protocolos de subasta combinatoria establecidos [6, 15]. Una pregunta interesante aquí es: ¿qué precios Lindahl en el rango máximo a mínimo son los mejores para citar con el fin de minimizar la revelación de información? Suponemos que la revelación de información se reduce al pasar de precios máximos a precios mínimos de Lindahl, es decir, a medida que desplazamos las consultas de demanda más lejos de las consultas de equivalencia. Por último, sería útil determinar si el lenguaje de licitación de OR* [11] puede aprenderse (y, por lo tanto, obtenerse) de manera eficiente, dada la expresividad y sucinta de estas lenguas para una amplia variedad de clases de valoración. Agradecimientos Queremos agradecer a Debasis Mishra por sus útiles discusiones. Este trabajo está apoyado en parte por la subvención de NSF IIS0238147. 8. REFERENCIAS [1] A. Andersson, M. Tenhunen, y F. Ygge. Programación integral para la determinación del ganador de la subasta combinatoria. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprender conjuntos regulares de consultas y contraejemplos. Información e computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje conceptual. Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El modelo de asignación de paquetes. Diario de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Provocación de preferencias y aprendizaje de consultas. En Proc. 16a Conferencia Anual sobre Teoría del Aprendizaje Computacional (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. la 18a Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, e Y. Shoham. Domar la complejidad computacional de las subastas combinatoria: Enfoques óptimos y aproximados. En Proc. , 16a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), págs. 548 a 553, 1999. [8] B. Hudson y T. Sandholm. Uso de consultas de valor en subastas combinatoria. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría del aprendizaje computacional. MIT Press, 1994. [10] N. Littlestone. Aprender rápidamente cuando los atributos irrelevantes abundan: Un nuevo algoritmo de umbral lineal. Machine Learning, 2:285-318, 1988. [11] N. Nisan. Licitación y asignación en subastas combinatoria. En Proc. la Conferencia de la ACM sobre Comercio Electrónico, págs. 1 a 12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y el apoyo a los precios Lindahl. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de mínima revelación. En Padget et al., editor, Agent-Mediated Electronic Commerce IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. Diseño de subastas con costosas preferencias. En Temas Especiales de Anales de Matemáticas y AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17a Conferencia Nacional sobre Inteligencia Artificial (AAAI-00), págs. 74 a 81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. la 17a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariables escasos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de ACM sobre Teoría del Aprendizaje Computacional, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendido. Comun. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum, y T. Sandholm. Sobre la excitación de la preferencia polinomio-tiempo con las consultas de valor. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "error": [
                "comunicación polinómica",
                "comunicación polinómica",
                "comunicación polinómica",
                "comunicación polinómica",
                "comunicación polinomio",
                "comunicación polinomio",
                "comunicación polinomio"
            ]
        },
        "resulting algorithm": {
            "translated_key": "algoritmo resultante",
            "translated_annotated_text": "Aplicando algoritmos de aprendizaje a la eliminación de preferencia Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de excitación Demostramos que los algoritmos de aprendizaje pueden ser usados como base para algoritmos de excitación de preferencias. Los algoritmos de excitación resultantes realizan un número polinomio de consultas. También damos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. En particular, se obtiene un algoritmo que provoca pujas XOR con comunicación polinómica. Categorías y Descriptores sujetos F.2.0 [Análisis de algoritmos y complejidad de problemas]: General; J.4 [Ciencias Sociales y Conductuales]: Economía; I.2.6 [Inteligencia Artificial]: Términos generales de aprendizaje Algoritmos, Economía, Teoría 1. INTRODUCCIÓN En una subasta combinatoria, los agentes pueden pujar por paquetes de bienes en lugar de por cada uno de ellos. Puesto que hay un número exponencial de paquetes (en el número de bienes), comunicar los valores sobre estos paquetes puede ser problemático. Comunicar las valoraciones de una sola vez puede ser prohibitivamente costoso si el número de bienes es sólo moderadamente grande. Además, incluso podría ser difícil para los agentes determinar sus valoraciones para paquetes únicos [14]. A esos agentes les interesa disponer de protocolos de subasta que les obliguen a pujar en el menor número posible de paquetes. Incluso si los agentes pueden calcular eficientemente sus valoraciones, podrían ser reacios a revelarlas enteramente en el curso de una subasta, porque tal información puede ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información necesaria para determinar una asignación óptima de los bienes. Ha habido un trabajo reciente explorando los vínculos entre el problema de la excitación de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje computacional [5, 19]. En teoría de aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, tales como ¿Cuál es el valor de las funciones en estas entradas? En la obtención de preferencia, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Demostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia se puede convertir en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de excitación resultante garantiza la excitación en un número polinomio de consultas de valor y demanda. Aquí queremos decir polinomio en el número de bienes, agentes, y los tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Argumentamos que las garantías de complejidad para los esquemas de excitación deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar la comunicación polinómica en el peor de los casos, que normalmente no se puede lograr en el número de productos y agentes por sí solos. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. Por supuesto, una subasta combinatoria de un solo disparo donde los agentes proporcionan todas sus funciones de valoración a la vez también tendría comunicación polinómica en el tamaño de las valoraciones de los agentes, y sólo requieren una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay ninguna carga para los agentes de formular sus valoraciones en un esquema de codificación de los subastadores que elijan. Esperamos que esta sea una consideración importante en la práctica. Además, con nuestro esquema la revelación entera sólo ocurre en el peor de los casos. 180 Por ahora, dejamos a un lado la cuestión de los incentivos al derivar algoritmos de excitación. Nos centramos en el tiempo y la complejidad de la comunicación de la obtención de preferencias, independientemente de las limitaciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich y otros [19] considerar el problema del aprendizaje de clases restringidas de funciones de valoración que se pueden representar utilizando fórmulas de lectura once y Toolbox DNF. Las fórmulas Read-once pueden representar ciertas sustitutibilidades, pero no complementariedades, mientras que lo contrario se mantiene para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten depender del tamaño de la valoración objetivo como lo hacemos (aunque las valoraciones de read-once siempre se pueden representar sucintamente de todos modos). Su trabajo sólo hace uso de consultas de valor, que son bastante limitados en el poder. Debido a que nos permitimos pedir consultas, somos capaces de derivar un esquema de excitación para las funciones de valoración general. Blum et al. [5] proporcionar resultados relacionados con las complejidades del aprendizaje de la consulta y la excitación de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje de consultas, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones se pueden aprender eficientemente, pero no se pueden obtener eficientemente, y viceversa. En contraste, nuestro trabajo muestra que dada una versión más general (todavía bastante estándar) de la consulta de demanda que el tipo que consideran, la complejidad de la excitación de preferencia no es mayor que la complejidad del aprendizaje. Demostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre valoraciones para implicar una solución al problema de excitación. Nisan y Segal [12] estudian la complejidad comunicativa de la excitación de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos de la computación una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo se permite a los algoritmos hacer preguntas sobre valoraciones de agentes y recibir respuestas honestas, sin ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda la cuestión de la complejidad de la comunicación, y somos capaces de derivar algoritmos que proporcionan garantías de comunicación significativas a pesar de los resultados negativos de Nisan y Segals. Su trabajo motiva la necesidad de confiar en el tamaño de los agentes funciones de valoración para indicar los peores resultados. 2. LOS MODELOS 2.1 Aprendizaje de la consulta El modelo de aprendizaje de la consulta que consideramos aquí se llama aprendizaje exacto de la membresía y consultas de equivalencia, introducido por Angluin [2]. En este modelo el objetivo de los algoritmos de aprendizaje es identificar exactamente una función diana desconocida f : X → Y a través de consultas a un oráculo. La función de destino se extrae de una función de clase C que es conocida por el algoritmo. Típicamente el dominio X es algún subconjunto de {0, 1}m, y el rango Y es {0, 1} o algún subconjunto de los números reales. A medida que el algoritmo avanza, construye una hipótesis manifiesta?f que es su estimación actual de la función de destino. Después de la terminación, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface?f(x) = f(x) para todos x?X. Es importante especificar la representación que se utilizará para codificar funciones de C. Por ejemplo, considere la siguiente función de {0, 1}m a ♥: f(x) = 2 si x consiste en m 1s, y f(x) = 0 de otra manera. Esta función puede representarse simplemente como una lista de valores de 2m. O puede codificarse como el polinomio 2x1 · · · xm, que es mucho más sucinto. Así pues, la elección de la codificación puede tener un impacto significativo en las necesidades de tiempo y espacio del algoritmo de aprendizaje. Let size(f) ser el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes distintos de cero en el polinomio, por ejemplo. Por lo general, sólo nos referiremos a las clases de representación; las clases de funciones correspondientes serán implícitas. Por ejemplo, la clase de representación de fórmulas DNF monotonas implica la clase de función de funciones booleanas monotonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: la membresía y las consultas de equivalencia. En una consulta de membresía, el aprendiz presenta algunas x x x y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta f. El oráculo responde SÍ si?f = f, o devuelve un contraejemplo x de tal manera que?f(x) = f(x). Una consulta de equivalencia es apropiada si el tamaño( ̃f) ≤ tamaño(f) en el momento de presentar la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones se adaptan a partir de Kearns y Vazirani [9]: Definición 1. La clase de representación C es polinomialquery exactamente aprendeble de las consultas de membresía y equivalencia si hay un polinomial fijo p(·, ·) y un algoritmo L con acceso a la membresía y consultas de equivalencia de un oráculo tal que para cualquier función de destino f • C, L salidas después de a lo sumo p(size(f), m) consultas de una función?f • C tal que?f Del mismo modo, la clase de representación C se puede aprender exactamente de las consultas de membresía y equivalencia si el algoritmo L produce una hipótesis correcta en el tiempo p(size(f), m), para algunos polinomios fijos p(·, ·). Aquí m es la dimensión del dominio. Dado que la función de destino debe ser reconstruida, también permitimos necesariamente la dependencia polinómica del tamaño (f). 2.2 Eliminación de preferencias En una subasta combinatoria, un conjunto de bienes M se asignará entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Tal asignación se llama eficiente en la literatura de economía, pero nos referiremos a ella como óptima y reservar el término eficiente para referirse a la eficiencia computacional. Dejamos n = N y m = M. Una asignación es una partición de los objetos en paquetes (S1,. . . , Sn), de tal manera que Si â € ¬ Sj = â € para todos los i, j â € N. Let â € € sea el conjunto de posibles asignaciones. Cada agente i+N tiene una función de valoración vi : 2M → • sobre el espacio de los paquetes posibles. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no tienen que coincidir. Asumimos que todas las valoraciones consideradas están normalizadas, es decir, v() = 0, y que no hay externalidades, es decir, vi(S1,..., Sn) = vi(Si), para todos los agentes i  N, para cualquier asignación (S1,..., Sn)  (es decir, un agente se preocupa sólo por el paquete asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales.1 Nosotros 1 A menudo las valoraciones generales se hacen para satisfacer los 181 adicionales también asumen que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que los agentes utilidades pueden ser divididos en componentes monetarios y no monetarios. Si a un agente i se le asigna el paquete S al precio p, deriva utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más sucintas para ciertas clases de valoración, y ha habido mucha investigación en lenguajes de licitación concisos para diversos tipos de valoraciones [11]. Un ejemplo clásico al que nos referiremos más adelante es el lenguaje de licitación XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, que consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estas pujas, se busca el paquete S del valor más alto listado en las pujas atómicas de tal manera que S  S. Es entonces el caso que v(S) = v(S). Al igual que en el contexto de la teoría del aprendizaje, por lo general sólo nos referiremos a idiomas de oferta en lugar de clases de valoración, ya que las clases de valoración correspondientes serán implícitas. Por ejemplo, el lenguaje de licitación XOR implica la clase de valoraciones que satisfacen la disposición libre, que es la condición de que A  B ♥ v(A) ≤ v(B). Dejamos el tamaño(v1,. . . , vn) = Èn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de licitación). Para hacer una analogía con la teoría del aprendizaje computacional, suponemos que todas las clases de representación consideradas son polinomiamente interpretables [11], lo que significa que el valor de un paquete puede ser calculado en tiempo polinomio dada la representación de funciones de valoración. Más formalmente, una clase de representación (lenguaje de licitación) C es polinomialmente interpretable si existe un algoritmo que da como entrada algunos v • C y una instancia x • X calcula el valor v(x) en el tiempo q(size(v), m), para algún polinomio fijo q(·, ·).2 En las rondas intermedias de una subasta (terativa), el subastador habrá obtenido información sobre las funciones de Por lo tanto, habrá construido un conjunto de valoraciones manifiestas, denotadas . . Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha adquirido información sobre ciertos paquetes. El objetivo en el problema de la excitación de preferencia es construir un conjunto de valoraciones manifiestas tales que: arg max (S1,...,Sn) iÃ3n Ã3vi(Si)  arg max (S1,...,Sn) iÃ3n vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que es óptima con respecto a las valoraciones verdaderas. Tenga en cuenta que sólo se requiere una asignación óptima. condición de la libre eliminación (monotonicidad), pero no la necesitamos en este punto. 2 Esto excluye OR*, asumiendo P = NP, porque la interpretación de las ofertas de este lenguaje es NP-duro por reducción de set-embalaje ponderado, y no hay clase de representación bien estudiada en teoría de aprendizaje que es claramente análogo a OR*. 3 Esta visión de las subastas iterativas tiene por objeto paralelizar el entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente están implícitas por la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son consultas de valor y demanda. En una consulta de valor, el subastador presenta un paquete S  M y el agente responde con su valor (exacto) para el paquete v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p • • • (2m ) sobre los paquetes junto con un paquete S. El agente responde SI si es el caso de que S • arg max S M v(S ) − p(S ) ¡ o de otro modo presenta un paquete S tal que v(S ) − p(S ) > v( Tenga en cuenta también que comunicar precios no lineales no implica necesariamente citar un precio por cada paquete posible. Puede haber formas más sucintas de comunicar este vector, como se muestra en la sección 5. Hacemos las siguientes definiciones para paralelizar la configuración de aprendizaje de la consulta y para simplificar las declaraciones de resultados posteriores: Definición 2. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si hay un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes tales que para cualquier (v1,. . . , vn) V1 ×. . . × Vn, L salidas después de como máximo p(size(v1,. . . , vn), m) consulta una asignación (S1,. . . , Sn) arg max(S1,...,Sn) È vi(Si). Del mismo modo, la clase de representación C se puede obtener eficientemente de las consultas de valor y demanda si el algoritmo L produce una asignación óptima con comunicación p(size(v1, ). . . , vn), m), para algunos polinomios fijos p(·, ·). Hay algunas diferencias clave aquí con la definición de aprendizaje de la consulta. Hemos eliminado el término exactamente ya que las funciones de valoración no necesitan ser determinadas exactamente con el fin de calcular una asignación óptima. Además, un algoritmo de excitación eficiente es la comunicación polinomio, en lugar de tiempo polinomio. Esto refleja el hecho de que la comunicación en lugar del tiempo de espera es el cuello de botella en la excitación. Cálculo de una asignación óptima de bienes incluso cuando se dan las valoraciones verdaderas es NP-duro para una amplia gama de clases de valoración. Por lo tanto, no es razonable exigir tiempo polinomio en la definición de un algoritmo de excitación de preferencias eficiente. Nos complace centrarnos en la complejidad comunicativa de la excitación porque se cree que este problema es más significativo en la práctica que el de la determinación del ganador [11].5 4 Esto difiere ligeramente de la definición proporcionada por Blum et al. [5] Sus consultas sobre la demanda se limitan a precios lineales sobre las mercancías, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir. un precio distinto por cada paquete posible. Es por eso que el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. 5 Aunque el problema de determinación del ganador es NP-hard para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta aproximaciones usando solucionadores IP fuera de la plataforma [1]. 182 Dado que no es necesario obtener exactamente las valoraciones, es inicialmente menos claro si la dependencia polinómica del tamaño (v1, ). . . , vn) está justificado en este contexto. Intuitivamente, este parámetro está justificado porque debemos aprender valoraciones exactamente cuando se realiza la excitación, en el peor de los casos. Nos ocupamos de esto en la siguiente sección. 3. PARALLESBETWEEN EQUIVALENCIA Y QUERIDAS DE DEMANDA Hemos descrito los ajustes de aprendizaje y excitación de preferencias de la consulta de una manera que destaca sus similitudes. Las consultas de valor y membresía son claras analógicas. Un poco menos obvio es el hecho de que las consultas de equivalencia y demanda también son analógicas. Para ver esto, necesitamos el concepto de precios Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios sobre sus bienes subyacentes. Son no anónimos en el sentido de que dos agentes pueden tener que hacer frente a precios diferentes para el mismo paquete de mercancías. Así los precios de Lindahl son de la forma pi(S), para todos S  M, para todos los precios de i  N. Lindahl se presentan a los agentes en consultas de la demanda. Cuando los agentes han normalizado las funciones de utilidad cuasi-lineal, Bikhchandani y Ostroy [4] muestran que siempre existen precios Lindahl tales que (S1,. . . , Sn) es una asignación óptima si y sólo si Si • arg max Si vi(Si) − pi(Si) • i N (1) (S1,. . . , Sn)  arg max (S1,...,Sn) iN pi(Si) (2) Condición (1) establece que cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos de los subastadores a los precios indicados. El escenario en el que se mantienen estas condiciones se llama equilibrio Lindahl, o a menudo un equilibrio competitivo. Decimos que los precios de Lindahl apoyan la asignación óptima. Por lo tanto, basta con anunciar los precios de apoyo de Lindahl para verificar una asignación óptima. Una vez que hemos encontrado una asignación con el apoyo de precios Lindahl, el problema de excitación se resuelve. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones estén garantizadas como integrales [4]. Las variables duales de este programa lineal están soportando los precios de Lindahl para la asignación resultante. La función objetiva del programa dual es: min pi(S) Por lo general, hay una gama de posibles precios Lindahl que apoyan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios válidos Lindahl, y nos referimos a ellos como precios máximos Lindahl. De todos los vectores posibles de precios Lindahl, precios máximos Lindahl maximizar la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È iÃ3N πi del objetivo (la suma de los agentes de utilidades) son precios mínimos Lindahl. Cualquier Lindahl precios hará para nuestros resultados, pero algunos pueden tener mejores propiedades de excitación que otros. Tenga en cuenta que una consulta de demanda con precios máximos de Lindahl es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para el trabajo futuro la cuestión de los precios de Lindahl para elegir minimizar la obtención de preferencias. Teniendo en cuenta ahora por qué las consultas de demanda y equivalencia son analógicas directas, primero tenga en cuenta que dado el πi en algún equilibrio Lindahl, establecer pi(S) = max{0, Estos precios dejan a cada agente indiferente en todos los paquetes con precio positivo, y satisfacen la condición (1). Así, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl típicamente serán una constante aditivo lejos de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos de consultas de equivalencia a través de consultas de demanda. Lemma 1. Supongamos que un agente responde con un paquete preferido S cuando se propone un paquete S y soporta los precios de Lindahl p(S) (soportando con respecto a la valoración manifiesta de los agentes). A continuación, o bien?v(S) = v(S) o?v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: Φv(S) − p(S) ≥ Desigualdad (6) se mantiene porque el agente de hecho prefiere S a S dados los precios, de acuerdo con su respuesta a la consulta de demanda. Si fuera el caso de que?v(S) = v(S) y Así, al menos uno de S y S es un contraejemplo de la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño(v1,. . . , vn) en problemas de excitación. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que apoyar los precios de Lindahl debe necesariamente revelarse en el curso de cualquier protocolo de obtención de preferencias que termina con una asignación óptima. Además, Nisan y Segal (Lemma 1, [12]) afirman que en el peor de los casos los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones dobles (como será el caso de las clases más interesantes). Puesto que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y puesto que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitiendo la dependencia del tamaño(v1,. . . , vn) en problemas de excitación es totalmente natural. 183 4. DE APRENDIZAJE A LA LICITACIÓN DE PREFERENCIA La clave para convertir un algoritmo de aprendizaje a un algoritmo de excitación es simular consultas de equivalencia con consultas de demanda y valor hasta que se encuentre una asignación óptima. Debido a nuestra construcción de precios Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en que un agente responde SÍ a una consulta de equivalencia cuando la función de destino se ha aprendido exactamente. De lo contrario, podemos obtener un contraejemplo a una consulta de equivalencia dada una respuesta de agentes a una consulta de demanda. Teorema 1. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si cada uno puede ser polinomio-consulta exactamente aprendido de consultas de membresía y equivalencia. Prueba. Considere el algoritmo de excitación en la Figura 1. Cada consulta de membresía en el paso 1 es simulada con una consulta de valor ya que estas son de hecho idénticas. Considere el paso 4. Si todos los agentes responden SÍ, la condición (1) se mantiene. Condición (2) se mantiene porque la asignación calculada es la maximización de ingresos para el subastador, independientemente de los agentes verdaderas valoraciones. Así pues, se ha encontrado una asignación óptima. De lo contrario, por lo menos uno de Si o Si es un contraejemplo a Vi, por Lemma 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones del agente se conocerán exactamente, en cuyo caso la asignación óptima y los precios Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinomio de consultas, desde A1,. . . , A son todos los algoritmos de aprendizaje polinomio-quería. Tenga en cuenta que el procedimiento de conversión resulta en un algoritmo de excitación de preferencias, no un algoritmo de aprendizaje. Es decir, el \"algoritmo resultante\" no simplemente aprender las valoraciones exactamente, a continuación, calcular una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor, y periódicamente comprueba si se ha reunido suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio Lindahl para las valoraciones v1,. . . , vn utilizando una asignación y precios derivados de valoraciones manifiestas . . y encontrar una asignación óptima no implica que las valoraciones de los agentes se hayan aprendido exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta interrupción temprana. No obtendremos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE COMUNICACIÓN En esta sección, pasamos a la cuestión de la complejidad comunicativa de la excitación. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (tales como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos de determinar los precios de Lindahl es exponencial en el número de mercancías, m. La carga de comunicación se mide en términos del número de bits transmitidos entre agentes y subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. La conversión de algoritmos de aprendizaje eficientes a un algoritmo de excitación produce un algoritmo cuyas consultas tienen tamaños polinomios en los parámetros m y tamaño (v1, ). . . , vn). Teorema 2. Las clases de representación V1,. . . , Vn se puede obtener de forma eficiente de las consultas de valor y demanda si cada uno puede ser aprendido exactamente de las consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, basta con comunicar la función de valoración manifiesta de los agentes y el valor Nótese que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinomio, porque el tiempo de ejecución de los algoritmos también sería superpolinomio, contradiciendo la eficiencia. Por lo tanto, la comunicación de la valoración manifiesta requiere tamaño a lo sumo p(size(vi), m), para algunos polinomios p que limita superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representando el excedente πi al agente no se puede requerir espacio mayor que q(size( También debemos comunicarnos con su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es como máximo p(size(vi), m) + q(p(size(vi), m), m)+O(m). Claramente, una respuesta de agentes a una consulta de valor o demanda tiene un tamaño máximo de q(size(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, son siempre de tamaño polinomio. Un algoritmo de aprendizaje eficiente realiza un número polinomio de consultas, por lo que la comunicación total del algoritmo de excitación resultante es polinomio en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites pueden ser traducidos a límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de excitación resultante. Con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2 se determinó el tamaño de la hipótesis manifiesta. Es probable que podamos hacerlo mucho mejor que esto en la práctica. Recuerde que una consulta de equivalencia es apropiada si size( ̃f) ≤ size(f) en el momento de realizar la consulta. Si las consultas de equivalencia de algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites estrechos en los requisitos de comunicación del algoritmo de excitación resultante. El teorema 2 muestra que los algoritmos de excitación que dependen del tamaño (v1,. . . El parámetro, vn) evita los resultados negativos de Nisan y Segals [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto al tamaño de las instancias de las funciones de valoración que se enfrentan a cualquier ejecución del algoritmo. Estos algoritmos van bien si la clase de representación elegida proporciona representaciones sucintas para la más simple y común de las valoraciones, y por lo tanto el enfoque se mueve de nuevo a uno de lenguajes de licitación compactos pero expresivos. A continuación se examinan estas cuestiones. 6. APLICACIONES En esta sección, demostramos la aplicación de nuestros métodos a clases particulares de representación para valoraciones combinatorias. Hemos demostrado que el problema de excitación de preferencias para las clases de valoración V1,. . . , Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1,. . . , Una para las valoraciones de las clases V1,. . . , Vn respectivamente. Encaje hasta que haya una señal para detenerse: 1. Corre A1,. . . , Un en paralelo sobre sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se ha detenido con los agentes valoración exacta. 2. Calcular una asignación óptima (S1,. . . , Sn ) y los correspondientes precios de Lindahl con respecto a las valoraciones manifiestas . . , їvn determinado hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de consulta de demanda. 4. Si todos ellos responden SÍ, salida la asignación y parada. De lo contrario hay algún agente i que ha respondido con algún paquete preferido Si. Realizar consultas de valor en Si y Si para encontrar un contraejemplo a ‡vi, y proporcionarlo a Ai. Figura 1: Convertir algoritmos de aprendizaje a un algoritmo de excitación. al problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de función, y porque a menudo puede ser más simple resolver cada subproblema de aprendizaje por separado que atacar el problema de excitación de preferencias directamente. Podemos desarrollar un algoritmo de excitación que se adapta a cada valoración de agentes, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Demostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas de DNF monotono y funciones de umbral lineal se pueden convertir en algoritmos de excitación de preferencia para valoraciones generales, valoraciones con eliminación libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en las representaciones que son polinomialmente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la traqueabilidad computacional [18]. Al interpretar los métodos enfatizamos la expresividad y sucinta de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de licitación, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debe representar sucintamente las funciones más simples y comunes de la clase. 6.1 Las Representaciones Polinómicas Schapire y Sellie [17] dan un algoritmo de aprendizaje para polinomios multivariables escasos que pueden utilizarse como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas apropiadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados de t-sparse sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-sparse tiene como máximo t términos, donde un término es un producto de variables, por ejemplo. x1x3x4. Un polinomio sobre los números reales tiene coeficientes extraídos de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M →  se puede escribir exclusivamente como un polinomio [17]. Para tener una idea de la sucintaidad de los polinomios como lenguaje de licitación, considere las valoraciones aditivas y mono-ítem presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es el número de mercancías que contiene el paquete. En la valoración de un solo elemento, todos los paquetes tienen valor 1, excepto el valor 0 (i.e. el agente está satisfecho tan pronto como ha adquirido un único artículo). No es difícil demostrar que la valoración de un solo elemento requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Por lo tanto, los polinomios son adecuados para valoraciones que en su mayoría son aditivas, con algunas sustituibilidades y complementariedades que pueden introducirse ajustando los coeficientes. El algoritmo de aprendizaje para polinomios hace como máximo consultas de equivalencia mti +2 y como máximo (mti +1) (t2 i +3ti)/2 consultas de membresía a un agente i, donde ti es la esparcidad del polinomio que representa vi [17]. Por lo tanto, se obtiene un algoritmo que provoca valoraciones generales con un número polinomio de consultas y comunicación polinomio.6 6.2 XOR Representaciones El lenguaje de licitación XOR es estándar en la literatura de subastas combinatoria. Recordemos que una oferta XOR se caracteriza por un conjunto de paquetes B  2M y una función de valor w : B →  definida en esos paquetes, que induce la función de valoración: v(B) = max {B  B  B  B} w(B) (7) Las ofertas XOR pueden representar valoraciones que satisfacen la libre eliminación (y sólo tales valoraciones), que de nuevo es la propiedad que A  B El lenguaje de licitación XOR es ligeramente menos expresivo que los polinomios, porque los polinomios pueden representar valoraciones que no satisfacen la libre eliminación. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas de XOR pueden representar la valoración de un solo elemento con ofertas atómicas m, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario se aplica a los polinomios, estas dos lenguas son incomparables en sucintas y algo complementarias para su uso práctico. Blum et al. [5] note que las fórmulas DNF monotonas son los análogos de las pujas XOR en la literatura de teoría del aprendizaje. Una fórmula de DNF monotona es una disyunción de conjunciones en las que las variables aparecen sin negación, por ejemplo x1x2 x3 x2x4x5. Tenga en cuenta que tales fórmulas pueden ser representadas como ofertas XOR donde cada oferta atómica tiene valor 1; por lo tanto XOR ofrece generalizar fórmulas DNF monotono de Boolean a funciones de valor real. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para el DNF monotono ([3] Teorema 6 Tenga en cuenta que el Teorema 1 se aplica incluso si las valoraciones no satisfacen la eliminación libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lemma 2. Una oferta XOR que contiene ofertas t atómicas se puede aprender exactamente con consultas de equivalencia t + 1 y a lo sumo consultas de membresía tm. Prueba. El algoritmo identificará cada puja atómica en la puja XOR objetivo a su vez. Initialice la valoración manifiesta v a la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presente ‡v como consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un paquete S para el que v(S) = Crear un paquete T de la siguiente manera. Primero inicialice T = S. Para cada elemento i en T, compruebe a través de una consulta de membresía si v(T) = v(T − {i}). Si así se establece T = T − {i}. De lo contrario, deje T como está y pase al siguiente punto. Afirmamos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada ítem i en T, tenemos v(T) = v(T − {i}). Para ver esto, tenga en cuenta que en algún momento al generar T, tuvimos un ̄T tal que T  ̄T  S y v( ̄T) > v( ̄T − {i}), de modo que me mantuvo en ̄T. Tenga en cuenta que v(S) = v( ̄T) = v(T) porque el valor del paquete S se mantiene durante todo el proceso de eliminación de elementos. Ahora asume v(T) = v(T − {i}). Entonces v( ̄T) = v(T) = v(T − {i}) > v( ̄T − {i}) que contradice la libre eliminación, ya que T {i}  ̄T − {i}. Por lo tanto v(T) > v(T − {i}) para todos los ítems i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si este no fuera el caso, T tomaría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = máx itat {max T T Ahora mostramos que v(T) = ̃v(T), que implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Asumir que toda oferta atómica (R, Esta suposición se mantiene vagamente cuando se inicializa la valoración manifiesta. Usando la notación de (7), dejar ( Tenemos B  B, y Bw(B) = w(B) para B Por lo tanto,?v(S) = max {B} {B} {B} {B} {B} {B} = max {B} {B} {B} ≤ {B} {B} {B} {B} {S} w(B} = v(S) (8) Ahora asume v(T) {v(T La segunda igualdad se deriva del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad sostiene porque S es un contraejemplo de la valoración manifiesta. De la ecuación (9) y la eliminación libre, nosotros 7 El algoritmo citado también se utilizó como base para Zinkevich et al.s [19] algoritmo de excitación para Toolbox DNF. Recuerde que Toolbox DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia se puede simular con una consulta de valor en el paquete que contiene todas las mercancías. que tengan ‡v(T) < Entonces de nuevo de la ecuación (9) se deduce que v(S) < Esto contradice (8), por lo que de hecho tenemos v(T) = Por lo tanto (T, v(T)) no está actualmente en nuestra hipótesis como una oferta atómica, o tendríamos correctamente?v(T) = v(T) por la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas adicionales de equivalencia hasta que todas las ofertas atómicas hayan sido identificadas. Después de cada consulta de equivalencia, una oferta atómica se identifica con como máximo m consultas de membresía. Cada contraejemplo conduce al descubrimiento de una nueva oferta atómica. Por lo tanto, hacemos a lo sumo consultas de membresía tm y exactamente consultas de equivalencia t + 1. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR se puede obtener eficientemente de las consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al.s ([5], Teorema 2) afirmando que el DNF monotono (y por lo tanto las ofertas XOR) no se pueden obtener de manera eficiente cuando las consultas de demanda se limitan a precios lineales y anónimos sobre las mercancías. 6.3 Las representaciones lineales de umbral polinomios, las ofertas XOR y todas las lenguas basadas en el lenguaje de licitación OR (como XOR-de-OR, OR-de-XOR y OR*) no representan sucintamente la valoración mayoritaria [11]. En esta valoración, los paquetes tienen valor 1 si contienen al menos m/2 ítems, y valor 0 de lo contrario. Más generalmente, considere la familia de r-of-S de valoraciones donde los paquetes tienen valor 1 si contienen al menos r artículos de un conjunto especificado de ítems S  M, y valor 0 de otra manera. La valoración mayoritaria es un caso especial de la valoración de r-of-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar las sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede añadir valor. Dejando k = S, tales valoraciones están sucintamente representadas por funciones de umbral r-of-k. Estas funciones adoptan la forma de desigualdades lineales: xi1 +. . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se mantiene, y 0 de lo contrario. Aquí i1,. . . , ik son los elementos en S. Littlestones WINNOW 2 algoritmo puede aprender tales funciones utilizando consultas de equivalencia sólo, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de excitación que resulta de WINNOW 2 sólo utiliza consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos están implícitos cuando sólo hay dos valores posibles). Tenga en cuenta que las funciones de umbral r-of-k siempre se pueden representar sucintamente en el espacio O(m). Así se obtiene un algoritmo que puede generar tales funciones con un número polinomio de consultas y comunicación polinomio, en los parámetros n y m solos. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exactos con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de excitación de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas en el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la riqueza de algoritmos de aprendizaje disponibles al problema de la excitación de preferencias. Un enfoque de aprendizaje para la excitación también motiva un enfoque diferente para diseñar algoritmos de excitación que se descomponen cuidadosamente entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivos, muchos sustitutos, etc.), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de excitación. El algoritmo de excitación resultante hace un número polinomio de consultas, y hace comunicación polinomio si los algoritmos de aprendizaje originales son eficientes. No exigimos que las valoraciones de agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia sólo pueden ser, y sólo necesitan ser, simuladas hasta el punto en que se ha calculado una asignación óptima. Este es el problema de la excitación de preferencias. Teorema 1 implica que la excitación con consultas de valor y demanda no es más difícil que aprender con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las que la excitación es más fácil que el aprendizaje. Blum et al. [5] proporcionar tal ejemplo al considerar solamente consultas de membresía/valor (Teorema 4). En el trabajo futuro planeamos abordar la cuestión de los incentivos al convertir algoritmos de aprendizaje a algoritmos de excitación. En el entorno de aprendizaje, por lo general suponemos que los oráculos proporcionarán respuestas honestas a las preguntas; en el entorno de excitación, los agentes son generalmente egoístas y proporcionarán respuestas posiblemente deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para el aprendizaje de polinomios y ofertas XOR como algoritmos de excitación, y probar su rendimiento contra otros protocolos de subasta combinatoria establecidos [6, 15]. Una pregunta interesante aquí es: ¿qué precios Lindahl en el rango máximo a mínimo son los mejores para citar con el fin de minimizar la revelación de información? Suponemos que la revelación de información se reduce al pasar de precios máximos a precios mínimos de Lindahl, es decir, a medida que desplazamos las consultas de demanda más lejos de las consultas de equivalencia. Por último, sería útil determinar si el lenguaje de licitación de OR* [11] puede aprenderse (y, por lo tanto, obtenerse) de manera eficiente, dada la expresividad y sucinta de estas lenguas para una amplia variedad de clases de valoración. Agradecimientos Queremos agradecer a Debasis Mishra por sus útiles discusiones. Este trabajo está apoyado en parte por la subvención de NSF IIS0238147. 8. REFERENCIAS [1] A. Andersson, M. Tenhunen, y F. Ygge. Programación integral para la determinación del ganador de la subasta combinatoria. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprender conjuntos regulares de consultas y contraejemplos. Información e computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje conceptual. Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El modelo de asignación de paquetes. Diario de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Provocación de preferencias y aprendizaje de consultas. En Proc. 16a Conferencia Anual sobre Teoría del Aprendizaje Computacional (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. la 18a Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, e Y. Shoham. Domar la complejidad computacional de las subastas combinatoria: Enfoques óptimos y aproximados. En Proc. , 16a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), págs. 548 a 553, 1999. [8] B. Hudson y T. Sandholm. Uso de consultas de valor en subastas combinatoria. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría del aprendizaje computacional. MIT Press, 1994. [10] N. Littlestone. Aprender rápidamente cuando los atributos irrelevantes abundan: Un nuevo algoritmo de umbral lineal. Machine Learning, 2:285-318, 1988. [11] N. Nisan. Licitación y asignación en subastas combinatoria. En Proc. la Conferencia de la ACM sobre Comercio Electrónico, págs. 1 a 12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y el apoyo a los precios Lindahl. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de mínima revelación. En Padget et al., editor, Agent-Mediated Electronic Commerce IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. Diseño de subastas con costosas preferencias. En Temas Especiales de Anales de Matemáticas y AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17a Conferencia Nacional sobre Inteligencia Artificial (AAAI-00), págs. 74 a 81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. la 17a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariables escasos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de ACM sobre Teoría del Aprendizaje Computacional, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendido. Comun. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum, y T. Sandholm. Sobre la excitación de la preferencia polinomio-tiempo con las consultas de valor. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "error": [
                ""
            ]
        },
        "conversion procedure": {
            "translated_key": "procedimiento de conversión",
            "translated_annotated_text": "Aplicando algoritmos de aprendizaje a la eliminación de preferencia Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de excitación Demostramos que los algoritmos de aprendizaje pueden ser usados como base para algoritmos de excitación de preferencias. Los algoritmos de excitación resultantes realizan un número polinomio de consultas. También damos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro \"procedimiento de conversión\" nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. En particular, se obtiene un algoritmo que provoca pujas XOR con comunicación polinómica. Categorías y Descriptores sujetos F.2.0 [Análisis de algoritmos y complejidad de problemas]: General; J.4 [Ciencias Sociales y Conductuales]: Economía; I.2.6 [Inteligencia Artificial]: Términos generales de aprendizaje Algoritmos, Economía, Teoría 1. INTRODUCCIÓN En una subasta combinatoria, los agentes pueden pujar por paquetes de bienes en lugar de por cada uno de ellos. Puesto que hay un número exponencial de paquetes (en el número de bienes), comunicar los valores sobre estos paquetes puede ser problemático. Comunicar las valoraciones de una sola vez puede ser prohibitivamente costoso si el número de bienes es sólo moderadamente grande. Además, incluso podría ser difícil para los agentes determinar sus valoraciones para paquetes únicos [14]. A esos agentes les interesa disponer de protocolos de subasta que les obliguen a pujar en el menor número posible de paquetes. Incluso si los agentes pueden calcular eficientemente sus valoraciones, podrían ser reacios a revelarlas enteramente en el curso de una subasta, porque tal información puede ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información necesaria para determinar una asignación óptima de los bienes. Ha habido un trabajo reciente explorando los vínculos entre el problema de la excitación de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje computacional [5, 19]. En teoría de aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, tales como ¿Cuál es el valor de las funciones en estas entradas? En la obtención de preferencia, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Demostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia se puede convertir en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de excitación resultante garantiza la excitación en un número polinomio de consultas de valor y demanda. Aquí queremos decir polinomio en el número de bienes, agentes, y los tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Argumentamos que las garantías de complejidad para los esquemas de excitación deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar la comunicación polinómica en el peor de los casos, que normalmente no se puede lograr en el número de productos y agentes por sí solos. Finalmente, utilizamos nuestro \"procedimiento de conversión\" para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. Por supuesto, una subasta combinatoria de un solo disparo donde los agentes proporcionan todas sus funciones de valoración a la vez también tendría comunicación polinómica en el tamaño de las valoraciones de los agentes, y sólo requieren una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay ninguna carga para los agentes de formular sus valoraciones en un esquema de codificación de los subastadores que elijan. Esperamos que esta sea una consideración importante en la práctica. Además, con nuestro esquema la revelación entera sólo ocurre en el peor de los casos. 180 Por ahora, dejamos a un lado la cuestión de los incentivos al derivar algoritmos de excitación. Nos centramos en el tiempo y la complejidad de la comunicación de la obtención de preferencias, independientemente de las limitaciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich y otros [19] considerar el problema del aprendizaje de clases restringidas de funciones de valoración que se pueden representar utilizando fórmulas de lectura once y Toolbox DNF. Las fórmulas Read-once pueden representar ciertas sustitutibilidades, pero no complementariedades, mientras que lo contrario se mantiene para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten depender del tamaño de la valoración objetivo como lo hacemos (aunque las valoraciones de read-once siempre se pueden representar sucintamente de todos modos). Su trabajo sólo hace uso de consultas de valor, que son bastante limitados en el poder. Debido a que nos permitimos pedir consultas, somos capaces de derivar un esquema de excitación para las funciones de valoración general. Blum et al. [5] proporcionar resultados relacionados con las complejidades del aprendizaje de la consulta y la excitación de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje de consultas, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones se pueden aprender eficientemente, pero no se pueden obtener eficientemente, y viceversa. En contraste, nuestro trabajo muestra que dada una versión más general (todavía bastante estándar) de la consulta de demanda que el tipo que consideran, la complejidad de la excitación de preferencia no es mayor que la complejidad del aprendizaje. Demostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre valoraciones para implicar una solución al problema de excitación. Nisan y Segal [12] estudian la complejidad comunicativa de la excitación de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos de la computación una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo se permite a los algoritmos hacer preguntas sobre valoraciones de agentes y recibir respuestas honestas, sin ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda la cuestión de la complejidad de la comunicación, y somos capaces de derivar algoritmos que proporcionan garantías de comunicación significativas a pesar de los resultados negativos de Nisan y Segals. Su trabajo motiva la necesidad de confiar en el tamaño de los agentes funciones de valoración para indicar los peores resultados. 2. LOS MODELOS 2.1 Aprendizaje de la consulta El modelo de aprendizaje de la consulta que consideramos aquí se llama aprendizaje exacto de la membresía y consultas de equivalencia, introducido por Angluin [2]. En este modelo el objetivo de los algoritmos de aprendizaje es identificar exactamente una función diana desconocida f : X → Y a través de consultas a un oráculo. La función de destino se extrae de una función de clase C que es conocida por el algoritmo. Típicamente el dominio X es algún subconjunto de {0, 1}m, y el rango Y es {0, 1} o algún subconjunto de los números reales. A medida que el algoritmo avanza, construye una hipótesis manifiesta?f que es su estimación actual de la función de destino. Después de la terminación, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface?f(x) = f(x) para todos x?X. Es importante especificar la representación que se utilizará para codificar funciones de C. Por ejemplo, considere la siguiente función de {0, 1}m a ♥: f(x) = 2 si x consiste en m 1s, y f(x) = 0 de otra manera. Esta función puede representarse simplemente como una lista de valores de 2m. O puede codificarse como el polinomio 2x1 · · · xm, que es mucho más sucinto. Así pues, la elección de la codificación puede tener un impacto significativo en las necesidades de tiempo y espacio del algoritmo de aprendizaje. Let size(f) ser el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes distintos de cero en el polinomio, por ejemplo. Por lo general, sólo nos referiremos a las clases de representación; las clases de funciones correspondientes serán implícitas. Por ejemplo, la clase de representación de fórmulas DNF monotonas implica la clase de función de funciones booleanas monotonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: la membresía y las consultas de equivalencia. En una consulta de membresía, el aprendiz presenta algunas x x x y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta f. El oráculo responde SÍ si?f = f, o devuelve un contraejemplo x de tal manera que?f(x) = f(x). Una consulta de equivalencia es apropiada si el tamaño( ̃f) ≤ tamaño(f) en el momento de presentar la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones se adaptan a partir de Kearns y Vazirani [9]: Definición 1. La clase de representación C es polinomialquery exactamente aprendeble de las consultas de membresía y equivalencia si hay un polinomial fijo p(·, ·) y un algoritmo L con acceso a la membresía y consultas de equivalencia de un oráculo tal que para cualquier función de destino f • C, L salidas después de a lo sumo p(size(f), m) consultas de una función?f • C tal que?f Del mismo modo, la clase de representación C se puede aprender exactamente de las consultas de membresía y equivalencia si el algoritmo L produce una hipótesis correcta en el tiempo p(size(f), m), para algunos polinomios fijos p(·, ·). Aquí m es la dimensión del dominio. Dado que la función de destino debe ser reconstruida, también permitimos necesariamente la dependencia polinómica del tamaño (f). 2.2 Eliminación de preferencias En una subasta combinatoria, un conjunto de bienes M se asignará entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Tal asignación se llama eficiente en la literatura de economía, pero nos referiremos a ella como óptima y reservar el término eficiente para referirse a la eficiencia computacional. Dejamos n = N y m = M. Una asignación es una partición de los objetos en paquetes (S1,. . . , Sn), de tal manera que Si â € ¬ Sj = â € para todos los i, j â € N. Let â € € sea el conjunto de posibles asignaciones. Cada agente i+N tiene una función de valoración vi : 2M → • sobre el espacio de los paquetes posibles. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no tienen que coincidir. Asumimos que todas las valoraciones consideradas están normalizadas, es decir, v() = 0, y que no hay externalidades, es decir, vi(S1,..., Sn) = vi(Si), para todos los agentes i  N, para cualquier asignación (S1,..., Sn)  (es decir, un agente se preocupa sólo por el paquete asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales.1 Nosotros 1 A menudo las valoraciones generales se hacen para satisfacer los 181 adicionales también asumen que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que los agentes utilidades pueden ser divididos en componentes monetarios y no monetarios. Si a un agente i se le asigna el paquete S al precio p, deriva utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más sucintas para ciertas clases de valoración, y ha habido mucha investigación en lenguajes de licitación concisos para diversos tipos de valoraciones [11]. Un ejemplo clásico al que nos referiremos más adelante es el lenguaje de licitación XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, que consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estas pujas, se busca el paquete S del valor más alto listado en las pujas atómicas de tal manera que S  S. Es entonces el caso que v(S) = v(S). Al igual que en el contexto de la teoría del aprendizaje, por lo general sólo nos referiremos a idiomas de oferta en lugar de clases de valoración, ya que las clases de valoración correspondientes serán implícitas. Por ejemplo, el lenguaje de licitación XOR implica la clase de valoraciones que satisfacen la disposición libre, que es la condición de que A  B ♥ v(A) ≤ v(B). Dejamos el tamaño(v1,. . . , vn) = Èn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de licitación). Para hacer una analogía con la teoría del aprendizaje computacional, suponemos que todas las clases de representación consideradas son polinomiamente interpretables [11], lo que significa que el valor de un paquete puede ser calculado en tiempo polinomio dada la representación de funciones de valoración. Más formalmente, una clase de representación (lenguaje de licitación) C es polinomialmente interpretable si existe un algoritmo que da como entrada algunos v • C y una instancia x • X calcula el valor v(x) en el tiempo q(size(v), m), para algún polinomio fijo q(·, ·).2 En las rondas intermedias de una subasta (terativa), el subastador habrá obtenido información sobre las funciones de Por lo tanto, habrá construido un conjunto de valoraciones manifiestas, denotadas . . Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha adquirido información sobre ciertos paquetes. El objetivo en el problema de la excitación de preferencia es construir un conjunto de valoraciones manifiestas tales que: arg max (S1,...,Sn) iÃ3n Ã3vi(Si)  arg max (S1,...,Sn) iÃ3n vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que es óptima con respecto a las valoraciones verdaderas. Tenga en cuenta que sólo se requiere una asignación óptima. condición de la libre eliminación (monotonicidad), pero no la necesitamos en este punto. 2 Esto excluye OR*, asumiendo P = NP, porque la interpretación de las ofertas de este lenguaje es NP-duro por reducción de set-embalaje ponderado, y no hay clase de representación bien estudiada en teoría de aprendizaje que es claramente análogo a OR*. 3 Esta visión de las subastas iterativas tiene por objeto paralelizar el entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente están implícitas por la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son consultas de valor y demanda. En una consulta de valor, el subastador presenta un paquete S  M y el agente responde con su valor (exacto) para el paquete v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p • • • (2m ) sobre los paquetes junto con un paquete S. El agente responde SI si es el caso de que S • arg max S M v(S ) − p(S ) ¡ o de otro modo presenta un paquete S tal que v(S ) − p(S ) > v( Tenga en cuenta también que comunicar precios no lineales no implica necesariamente citar un precio por cada paquete posible. Puede haber formas más sucintas de comunicar este vector, como se muestra en la sección 5. Hacemos las siguientes definiciones para paralelizar la configuración de aprendizaje de la consulta y para simplificar las declaraciones de resultados posteriores: Definición 2. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si hay un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes tales que para cualquier (v1,. . . , vn) V1 ×. . . × Vn, L salidas después de como máximo p(size(v1,. . . , vn), m) consulta una asignación (S1,. . . , Sn) arg max(S1,...,Sn) È vi(Si). Del mismo modo, la clase de representación C se puede obtener eficientemente de las consultas de valor y demanda si el algoritmo L produce una asignación óptima con comunicación p(size(v1, ). . . , vn), m), para algunos polinomios fijos p(·, ·). Hay algunas diferencias clave aquí con la definición de aprendizaje de la consulta. Hemos eliminado el término exactamente ya que las funciones de valoración no necesitan ser determinadas exactamente con el fin de calcular una asignación óptima. Además, un algoritmo de excitación eficiente es la comunicación polinomio, en lugar de tiempo polinomio. Esto refleja el hecho de que la comunicación en lugar del tiempo de espera es el cuello de botella en la excitación. Cálculo de una asignación óptima de bienes incluso cuando se dan las valoraciones verdaderas es NP-duro para una amplia gama de clases de valoración. Por lo tanto, no es razonable exigir tiempo polinomio en la definición de un algoritmo de excitación de preferencias eficiente. Nos complace centrarnos en la complejidad comunicativa de la excitación porque se cree que este problema es más significativo en la práctica que el de la determinación del ganador [11].5 4 Esto difiere ligeramente de la definición proporcionada por Blum et al. [5] Sus consultas sobre la demanda se limitan a precios lineales sobre las mercancías, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir. un precio distinto por cada paquete posible. Es por eso que el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. 5 Aunque el problema de determinación del ganador es NP-hard para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta aproximaciones usando solucionadores IP fuera de la plataforma [1]. 182 Dado que no es necesario obtener exactamente las valoraciones, es inicialmente menos claro si la dependencia polinómica del tamaño (v1, ). . . , vn) está justificado en este contexto. Intuitivamente, este parámetro está justificado porque debemos aprender valoraciones exactamente cuando se realiza la excitación, en el peor de los casos. Nos ocupamos de esto en la siguiente sección. 3. PARALLESBETWEEN EQUIVALENCIA Y QUERIDAS DE DEMANDA Hemos descrito los ajustes de aprendizaje y excitación de preferencias de la consulta de una manera que destaca sus similitudes. Las consultas de valor y membresía son claras analógicas. Un poco menos obvio es el hecho de que las consultas de equivalencia y demanda también son analógicas. Para ver esto, necesitamos el concepto de precios Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios sobre sus bienes subyacentes. Son no anónimos en el sentido de que dos agentes pueden tener que hacer frente a precios diferentes para el mismo paquete de mercancías. Así los precios de Lindahl son de la forma pi(S), para todos S  M, para todos los precios de i  N. Lindahl se presentan a los agentes en consultas de la demanda. Cuando los agentes han normalizado las funciones de utilidad cuasi-lineal, Bikhchandani y Ostroy [4] muestran que siempre existen precios Lindahl tales que (S1,. . . , Sn) es una asignación óptima si y sólo si Si • arg max Si vi(Si) − pi(Si) • i N (1) (S1,. . . , Sn)  arg max (S1,...,Sn) iN pi(Si) (2) Condición (1) establece que cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos de los subastadores a los precios indicados. El escenario en el que se mantienen estas condiciones se llama equilibrio Lindahl, o a menudo un equilibrio competitivo. Decimos que los precios de Lindahl apoyan la asignación óptima. Por lo tanto, basta con anunciar los precios de apoyo de Lindahl para verificar una asignación óptima. Una vez que hemos encontrado una asignación con el apoyo de precios Lindahl, el problema de excitación se resuelve. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones estén garantizadas como integrales [4]. Las variables duales de este programa lineal están soportando los precios de Lindahl para la asignación resultante. La función objetiva del programa dual es: min pi(S) Por lo general, hay una gama de posibles precios Lindahl que apoyan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios válidos Lindahl, y nos referimos a ellos como precios máximos Lindahl. De todos los vectores posibles de precios Lindahl, precios máximos Lindahl maximizar la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È iÃ3N πi del objetivo (la suma de los agentes de utilidades) son precios mínimos Lindahl. Cualquier Lindahl precios hará para nuestros resultados, pero algunos pueden tener mejores propiedades de excitación que otros. Tenga en cuenta que una consulta de demanda con precios máximos de Lindahl es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para el trabajo futuro la cuestión de los precios de Lindahl para elegir minimizar la obtención de preferencias. Teniendo en cuenta ahora por qué las consultas de demanda y equivalencia son analógicas directas, primero tenga en cuenta que dado el πi en algún equilibrio Lindahl, establecer pi(S) = max{0, Estos precios dejan a cada agente indiferente en todos los paquetes con precio positivo, y satisfacen la condición (1). Así, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl típicamente serán una constante aditivo lejos de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos de consultas de equivalencia a través de consultas de demanda. Lemma 1. Supongamos que un agente responde con un paquete preferido S cuando se propone un paquete S y soporta los precios de Lindahl p(S) (soportando con respecto a la valoración manifiesta de los agentes). A continuación, o bien?v(S) = v(S) o?v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: Φv(S) − p(S) ≥ Desigualdad (6) se mantiene porque el agente de hecho prefiere S a S dados los precios, de acuerdo con su respuesta a la consulta de demanda. Si fuera el caso de que?v(S) = v(S) y Así, al menos uno de S y S es un contraejemplo de la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño(v1,. . . , vn) en problemas de excitación. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que apoyar los precios de Lindahl debe necesariamente revelarse en el curso de cualquier protocolo de obtención de preferencias que termina con una asignación óptima. Además, Nisan y Segal (Lemma 1, [12]) afirman que en el peor de los casos los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones dobles (como será el caso de las clases más interesantes). Puesto que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y puesto que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitiendo la dependencia del tamaño(v1,. . . , vn) en problemas de excitación es totalmente natural. 183 4. DE APRENDIZAJE A LA LICITACIÓN DE PREFERENCIA La clave para convertir un algoritmo de aprendizaje a un algoritmo de excitación es simular consultas de equivalencia con consultas de demanda y valor hasta que se encuentre una asignación óptima. Debido a nuestra construcción de precios Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en que un agente responde SÍ a una consulta de equivalencia cuando la función de destino se ha aprendido exactamente. De lo contrario, podemos obtener un contraejemplo a una consulta de equivalencia dada una respuesta de agentes a una consulta de demanda. Teorema 1. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si cada uno puede ser polinomio-consulta exactamente aprendido de consultas de membresía y equivalencia. Prueba. Considere el algoritmo de excitación en la Figura 1. Cada consulta de membresía en el paso 1 es simulada con una consulta de valor ya que estas son de hecho idénticas. Considere el paso 4. Si todos los agentes responden SÍ, la condición (1) se mantiene. Condición (2) se mantiene porque la asignación calculada es la maximización de ingresos para el subastador, independientemente de los agentes verdaderas valoraciones. Así pues, se ha encontrado una asignación óptima. De lo contrario, por lo menos uno de Si o Si es un contraejemplo a Vi, por Lemma 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones del agente se conocerán exactamente, en cuyo caso la asignación óptima y los precios Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinomio de consultas, desde A1,. . . , A son todos los algoritmos de aprendizaje polinomio-quería. Tenga en cuenta que el \"procedimiento de conversión\" resulta en un algoritmo de excitación de preferencias, no un algoritmo de aprendizaje. Es decir, el algoritmo resultante no simplemente aprender las valoraciones exactamente, a continuación, calcular una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor, y periódicamente comprueba si se ha reunido suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio Lindahl para las valoraciones v1,. . . , vn utilizando una asignación y precios derivados de valoraciones manifiestas . . y encontrar una asignación óptima no implica que las valoraciones de los agentes se hayan aprendido exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta interrupción temprana. No obtendremos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE COMUNICACIÓN En esta sección, pasamos a la cuestión de la complejidad comunicativa de la excitación. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (tales como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos de determinar los precios de Lindahl es exponencial en el número de mercancías, m. La carga de comunicación se mide en términos del número de bits transmitidos entre agentes y subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. La conversión de algoritmos de aprendizaje eficientes a un algoritmo de excitación produce un algoritmo cuyas consultas tienen tamaños polinomios en los parámetros m y tamaño (v1, ). . . , vn). Teorema 2. Las clases de representación V1,. . . , Vn se puede obtener de forma eficiente de las consultas de valor y demanda si cada uno puede ser aprendido exactamente de las consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, basta con comunicar la función de valoración manifiesta de los agentes y el valor Nótese que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinomio, porque el tiempo de ejecución de los algoritmos también sería superpolinomio, contradiciendo la eficiencia. Por lo tanto, la comunicación de la valoración manifiesta requiere tamaño a lo sumo p(size(vi), m), para algunos polinomios p que limita superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representando el excedente πi al agente no se puede requerir espacio mayor que q(size( También debemos comunicarnos con su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es como máximo p(size(vi), m) + q(p(size(vi), m), m)+O(m). Claramente, una respuesta de agentes a una consulta de valor o demanda tiene un tamaño máximo de q(size(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, son siempre de tamaño polinomio. Un algoritmo de aprendizaje eficiente realiza un número polinomio de consultas, por lo que la comunicación total del algoritmo de excitación resultante es polinomio en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites pueden ser traducidos a límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de excitación resultante. Con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2 se determinó el tamaño de la hipótesis manifiesta. Es probable que podamos hacerlo mucho mejor que esto en la práctica. Recuerde que una consulta de equivalencia es apropiada si size( ̃f) ≤ size(f) en el momento de realizar la consulta. Si las consultas de equivalencia de algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites estrechos en los requisitos de comunicación del algoritmo de excitación resultante. El teorema 2 muestra que los algoritmos de excitación que dependen del tamaño (v1,. . . El parámetro, vn) evita los resultados negativos de Nisan y Segals [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto al tamaño de las instancias de las funciones de valoración que se enfrentan a cualquier ejecución del algoritmo. Estos algoritmos van bien si la clase de representación elegida proporciona representaciones sucintas para la más simple y común de las valoraciones, y por lo tanto el enfoque se mueve de nuevo a uno de lenguajes de licitación compactos pero expresivos. A continuación se examinan estas cuestiones. 6. APLICACIONES En esta sección, demostramos la aplicación de nuestros métodos a clases particulares de representación para valoraciones combinatorias. Hemos demostrado que el problema de excitación de preferencias para las clases de valoración V1,. . . , Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1,. . . , Una para las valoraciones de las clases V1,. . . , Vn respectivamente. Encaje hasta que haya una señal para detenerse: 1. Corre A1,. . . , Un en paralelo sobre sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se ha detenido con los agentes valoración exacta. 2. Calcular una asignación óptima (S1,. . . , Sn ) y los correspondientes precios de Lindahl con respecto a las valoraciones manifiestas . . , їvn determinado hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de consulta de demanda. 4. Si todos ellos responden SÍ, salida la asignación y parada. De lo contrario hay algún agente i que ha respondido con algún paquete preferido Si. Realizar consultas de valor en Si y Si para encontrar un contraejemplo a ‡vi, y proporcionarlo a Ai. Figura 1: Convertir algoritmos de aprendizaje a un algoritmo de excitación. al problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de función, y porque a menudo puede ser más simple resolver cada subproblema de aprendizaje por separado que atacar el problema de excitación de preferencias directamente. Podemos desarrollar un algoritmo de excitación que se adapta a cada valoración de agentes, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Demostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas de DNF monotono y funciones de umbral lineal se pueden convertir en algoritmos de excitación de preferencia para valoraciones generales, valoraciones con eliminación libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en las representaciones que son polinomialmente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la traqueabilidad computacional [18]. Al interpretar los métodos enfatizamos la expresividad y sucinta de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de licitación, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debe representar sucintamente las funciones más simples y comunes de la clase. 6.1 Las Representaciones Polinómicas Schapire y Sellie [17] dan un algoritmo de aprendizaje para polinomios multivariables escasos que pueden utilizarse como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas apropiadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados de t-sparse sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-sparse tiene como máximo t términos, donde un término es un producto de variables, por ejemplo. x1x3x4. Un polinomio sobre los números reales tiene coeficientes extraídos de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M →  se puede escribir exclusivamente como un polinomio [17]. Para tener una idea de la sucintaidad de los polinomios como lenguaje de licitación, considere las valoraciones aditivas y mono-ítem presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es el número de mercancías que contiene el paquete. En la valoración de un solo elemento, todos los paquetes tienen valor 1, excepto el valor 0 (i.e. el agente está satisfecho tan pronto como ha adquirido un único artículo). No es difícil demostrar que la valoración de un solo elemento requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Por lo tanto, los polinomios son adecuados para valoraciones que en su mayoría son aditivas, con algunas sustituibilidades y complementariedades que pueden introducirse ajustando los coeficientes. El algoritmo de aprendizaje para polinomios hace como máximo consultas de equivalencia mti +2 y como máximo (mti +1) (t2 i +3ti)/2 consultas de membresía a un agente i, donde ti es la esparcidad del polinomio que representa vi [17]. Por lo tanto, se obtiene un algoritmo que provoca valoraciones generales con un número polinomio de consultas y comunicación polinomio.6 6.2 XOR Representaciones El lenguaje de licitación XOR es estándar en la literatura de subastas combinatoria. Recordemos que una oferta XOR se caracteriza por un conjunto de paquetes B  2M y una función de valor w : B →  definida en esos paquetes, que induce la función de valoración: v(B) = max {B  B  B  B} w(B) (7) Las ofertas XOR pueden representar valoraciones que satisfacen la libre eliminación (y sólo tales valoraciones), que de nuevo es la propiedad que A  B El lenguaje de licitación XOR es ligeramente menos expresivo que los polinomios, porque los polinomios pueden representar valoraciones que no satisfacen la libre eliminación. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas de XOR pueden representar la valoración de un solo elemento con ofertas atómicas m, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario se aplica a los polinomios, estas dos lenguas son incomparables en sucintas y algo complementarias para su uso práctico. Blum et al. [5] note que las fórmulas DNF monotonas son los análogos de las pujas XOR en la literatura de teoría del aprendizaje. Una fórmula de DNF monotona es una disyunción de conjunciones en las que las variables aparecen sin negación, por ejemplo x1x2 x3 x2x4x5. Tenga en cuenta que tales fórmulas pueden ser representadas como ofertas XOR donde cada oferta atómica tiene valor 1; por lo tanto XOR ofrece generalizar fórmulas DNF monotono de Boolean a funciones de valor real. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para el DNF monotono ([3] Teorema 6 Tenga en cuenta que el Teorema 1 se aplica incluso si las valoraciones no satisfacen la eliminación libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lemma 2. Una oferta XOR que contiene ofertas t atómicas se puede aprender exactamente con consultas de equivalencia t + 1 y a lo sumo consultas de membresía tm. Prueba. El algoritmo identificará cada puja atómica en la puja XOR objetivo a su vez. Initialice la valoración manifiesta v a la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presente ‡v como consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un paquete S para el que v(S) = Crear un paquete T de la siguiente manera. Primero inicialice T = S. Para cada elemento i en T, compruebe a través de una consulta de membresía si v(T) = v(T − {i}). Si así se establece T = T − {i}. De lo contrario, deje T como está y pase al siguiente punto. Afirmamos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada ítem i en T, tenemos v(T) = v(T − {i}). Para ver esto, tenga en cuenta que en algún momento al generar T, tuvimos un ̄T tal que T  ̄T  S y v( ̄T) > v( ̄T − {i}), de modo que me mantuvo en ̄T. Tenga en cuenta que v(S) = v( ̄T) = v(T) porque el valor del paquete S se mantiene durante todo el proceso de eliminación de elementos. Ahora asume v(T) = v(T − {i}). Entonces v( ̄T) = v(T) = v(T − {i}) > v( ̄T − {i}) que contradice la libre eliminación, ya que T {i}  ̄T − {i}. Por lo tanto v(T) > v(T − {i}) para todos los ítems i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si este no fuera el caso, T tomaría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = máx itat {max T T Ahora mostramos que v(T) = ̃v(T), que implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Asumir que toda oferta atómica (R, Esta suposición se mantiene vagamente cuando se inicializa la valoración manifiesta. Usando la notación de (7), dejar ( Tenemos B  B, y Bw(B) = w(B) para B Por lo tanto,?v(S) = max {B} {B} {B} {B} {B} {B} = max {B} {B} {B} ≤ {B} {B} {B} {B} {S} w(B} = v(S) (8) Ahora asume v(T) {v(T La segunda igualdad se deriva del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad sostiene porque S es un contraejemplo de la valoración manifiesta. De la ecuación (9) y la eliminación libre, nosotros 7 El algoritmo citado también se utilizó como base para Zinkevich et al.s [19] algoritmo de excitación para Toolbox DNF. Recuerde que Toolbox DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia se puede simular con una consulta de valor en el paquete que contiene todas las mercancías. que tengan ‡v(T) < Entonces de nuevo de la ecuación (9) se deduce que v(S) < Esto contradice (8), por lo que de hecho tenemos v(T) = Por lo tanto (T, v(T)) no está actualmente en nuestra hipótesis como una oferta atómica, o tendríamos correctamente?v(T) = v(T) por la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas adicionales de equivalencia hasta que todas las ofertas atómicas hayan sido identificadas. Después de cada consulta de equivalencia, una oferta atómica se identifica con como máximo m consultas de membresía. Cada contraejemplo conduce al descubrimiento de una nueva oferta atómica. Por lo tanto, hacemos a lo sumo consultas de membresía tm y exactamente consultas de equivalencia t + 1. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR se puede obtener eficientemente de las consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al.s ([5], Teorema 2) afirmando que el DNF monotono (y por lo tanto las ofertas XOR) no se pueden obtener de manera eficiente cuando las consultas de demanda se limitan a precios lineales y anónimos sobre las mercancías. 6.3 Las representaciones lineales de umbral polinomios, las ofertas XOR y todas las lenguas basadas en el lenguaje de licitación OR (como XOR-de-OR, OR-de-XOR y OR*) no representan sucintamente la valoración mayoritaria [11]. En esta valoración, los paquetes tienen valor 1 si contienen al menos m/2 ítems, y valor 0 de lo contrario. Más generalmente, considere la familia de r-of-S de valoraciones donde los paquetes tienen valor 1 si contienen al menos r artículos de un conjunto especificado de ítems S  M, y valor 0 de otra manera. La valoración mayoritaria es un caso especial de la valoración de r-of-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar las sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede añadir valor. Dejando k = S, tales valoraciones están sucintamente representadas por funciones de umbral r-of-k. Estas funciones adoptan la forma de desigualdades lineales: xi1 +. . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se mantiene, y 0 de lo contrario. Aquí i1,. . . , ik son los elementos en S. Littlestones WINNOW 2 algoritmo puede aprender tales funciones utilizando consultas de equivalencia sólo, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de excitación que resulta de WINNOW 2 sólo utiliza consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos están implícitos cuando sólo hay dos valores posibles). Tenga en cuenta que las funciones de umbral r-of-k siempre se pueden representar sucintamente en el espacio O(m). Así se obtiene un algoritmo que puede generar tales funciones con un número polinomio de consultas y comunicación polinomio, en los parámetros n y m solos. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exactos con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de excitación de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas en el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la riqueza de algoritmos de aprendizaje disponibles al problema de la excitación de preferencias. Un enfoque de aprendizaje para la excitación también motiva un enfoque diferente para diseñar algoritmos de excitación que se descomponen cuidadosamente entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivos, muchos sustitutos, etc.), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de excitación. El algoritmo de excitación resultante hace un número polinomio de consultas, y hace comunicación polinomio si los algoritmos de aprendizaje originales son eficientes. No exigimos que las valoraciones de agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia sólo pueden ser, y sólo necesitan ser, simuladas hasta el punto en que se ha calculado una asignación óptima. Este es el problema de la excitación de preferencias. Teorema 1 implica que la excitación con consultas de valor y demanda no es más difícil que aprender con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las que la excitación es más fácil que el aprendizaje. Blum et al. [5] proporcionar tal ejemplo al considerar solamente consultas de membresía/valor (Teorema 4). En el trabajo futuro planeamos abordar la cuestión de los incentivos al convertir algoritmos de aprendizaje a algoritmos de excitación. En el entorno de aprendizaje, por lo general suponemos que los oráculos proporcionarán respuestas honestas a las preguntas; en el entorno de excitación, los agentes son generalmente egoístas y proporcionarán respuestas posiblemente deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para el aprendizaje de polinomios y ofertas XOR como algoritmos de excitación, y probar su rendimiento contra otros protocolos de subasta combinatoria establecidos [6, 15]. Una pregunta interesante aquí es: ¿qué precios Lindahl en el rango máximo a mínimo son los mejores para citar con el fin de minimizar la revelación de información? Suponemos que la revelación de información se reduce al pasar de precios máximos a precios mínimos de Lindahl, es decir, a medida que desplazamos las consultas de demanda más lejos de las consultas de equivalencia. Por último, sería útil determinar si el lenguaje de licitación de OR* [11] puede aprenderse (y, por lo tanto, obtenerse) de manera eficiente, dada la expresividad y sucinta de estas lenguas para una amplia variedad de clases de valoración. Agradecimientos Queremos agradecer a Debasis Mishra por sus útiles discusiones. Este trabajo está apoyado en parte por la subvención de NSF IIS0238147. 8. REFERENCIAS [1] A. Andersson, M. Tenhunen, y F. Ygge. Programación integral para la determinación del ganador de la subasta combinatoria. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprender conjuntos regulares de consultas y contraejemplos. Información e computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje conceptual. Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El modelo de asignación de paquetes. Diario de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Provocación de preferencias y aprendizaje de consultas. En Proc. 16a Conferencia Anual sobre Teoría del Aprendizaje Computacional (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. la 18a Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, e Y. Shoham. Domar la complejidad computacional de las subastas combinatoria: Enfoques óptimos y aproximados. En Proc. , 16a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), págs. 548 a 553, 1999. [8] B. Hudson y T. Sandholm. Uso de consultas de valor en subastas combinatoria. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría del aprendizaje computacional. MIT Press, 1994. [10] N. Littlestone. Aprender rápidamente cuando los atributos irrelevantes abundan: Un nuevo algoritmo de umbral lineal. Machine Learning, 2:285-318, 1988. [11] N. Nisan. Licitación y asignación en subastas combinatoria. En Proc. la Conferencia de la ACM sobre Comercio Electrónico, págs. 1 a 12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y el apoyo a los precios Lindahl. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de mínima revelación. En Padget et al., editor, Agent-Mediated Electronic Commerce IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. Diseño de subastas con costosas preferencias. En Temas Especiales de Anales de Matemáticas y AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17a Conferencia Nacional sobre Inteligencia Artificial (AAAI-00), págs. 74 a 81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. la 17a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariables escasos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de ACM sobre Teoría del Aprendizaje Computacional, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendido. Comun. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum, y T. Sandholm. Sobre la excitación de la preferencia polinomio-tiempo con las consultas de valor. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "error": [
                ""
            ]
        },
        "combinatorial auction protocol": {
            "translated_key": "protocolo de subastas combinatoria",
            "translated_annotated_text": "Aplicando algoritmos de aprendizaje a la eliminación de preferencia Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de excitación Demostramos que los algoritmos de aprendizaje pueden ser usados como base para algoritmos de excitación de preferencias. Los algoritmos de excitación resultantes realizan un número polinomio de consultas. También damos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. En particular, se obtiene un algoritmo que provoca pujas XOR con comunicación polinómica. Categorías y Descriptores sujetos F.2.0 [Análisis de algoritmos y complejidad de problemas]: General; J.4 [Ciencias Sociales y Conductuales]: Economía; I.2.6 [Inteligencia Artificial]: Términos generales de aprendizaje Algoritmos, Economía, Teoría 1. INTRODUCCIÓN En una subasta combinatoria, los agentes pueden pujar por paquetes de bienes en lugar de por cada uno de ellos. Puesto que hay un número exponencial de paquetes (en el número de bienes), comunicar los valores sobre estos paquetes puede ser problemático. Comunicar las valoraciones de una sola vez puede ser prohibitivamente costoso si el número de bienes es sólo moderadamente grande. Además, incluso podría ser difícil para los agentes determinar sus valoraciones para paquetes únicos [14]. A esos agentes les interesa disponer de protocolos de subasta que les obliguen a pujar en el menor número posible de paquetes. Incluso si los agentes pueden calcular eficientemente sus valoraciones, podrían ser reacios a revelarlas enteramente en el curso de una subasta, porque tal información puede ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información necesaria para determinar una asignación óptima de los bienes. Ha habido un trabajo reciente explorando los vínculos entre el problema de la excitación de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje computacional [5, 19]. En teoría de aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, tales como ¿Cuál es el valor de las funciones en estas entradas? En la obtención de preferencia, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Demostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia se puede convertir en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de excitación resultante garantiza la excitación en un número polinomio de consultas de valor y demanda. Aquí queremos decir polinomio en el número de bienes, agentes, y los tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Argumentamos que las garantías de complejidad para los esquemas de excitación deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar la comunicación polinómica en el peor de los casos, que normalmente no se puede lograr en el número de productos y agentes por sí solos. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. Por supuesto, una subasta combinatoria de un solo disparo donde los agentes proporcionan todas sus funciones de valoración a la vez también tendría comunicación polinómica en el tamaño de las valoraciones de los agentes, y sólo requieren una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay ninguna carga para los agentes de formular sus valoraciones en un esquema de codificación de los subastadores que elijan. Esperamos que esta sea una consideración importante en la práctica. Además, con nuestro esquema la revelación entera sólo ocurre en el peor de los casos. 180 Por ahora, dejamos a un lado la cuestión de los incentivos al derivar algoritmos de excitación. Nos centramos en el tiempo y la complejidad de la comunicación de la obtención de preferencias, independientemente de las limitaciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich y otros [19] considerar el problema del aprendizaje de clases restringidas de funciones de valoración que se pueden representar utilizando fórmulas de lectura once y Toolbox DNF. Las fórmulas Read-once pueden representar ciertas sustitutibilidades, pero no complementariedades, mientras que lo contrario se mantiene para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten depender del tamaño de la valoración objetivo como lo hacemos (aunque las valoraciones de read-once siempre se pueden representar sucintamente de todos modos). Su trabajo sólo hace uso de consultas de valor, que son bastante limitados en el poder. Debido a que nos permitimos pedir consultas, somos capaces de derivar un esquema de excitación para las funciones de valoración general. Blum et al. [5] proporcionar resultados relacionados con las complejidades del aprendizaje de la consulta y la excitación de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje de consultas, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones se pueden aprender eficientemente, pero no se pueden obtener eficientemente, y viceversa. En contraste, nuestro trabajo muestra que dada una versión más general (todavía bastante estándar) de la consulta de demanda que el tipo que consideran, la complejidad de la excitación de preferencia no es mayor que la complejidad del aprendizaje. Demostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre valoraciones para implicar una solución al problema de excitación. Nisan y Segal [12] estudian la complejidad comunicativa de la excitación de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos de la computación una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo se permite a los algoritmos hacer preguntas sobre valoraciones de agentes y recibir respuestas honestas, sin ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda la cuestión de la complejidad de la comunicación, y somos capaces de derivar algoritmos que proporcionan garantías de comunicación significativas a pesar de los resultados negativos de Nisan y Segals. Su trabajo motiva la necesidad de confiar en el tamaño de los agentes funciones de valoración para indicar los peores resultados. 2. LOS MODELOS 2.1 Aprendizaje de la consulta El modelo de aprendizaje de la consulta que consideramos aquí se llama aprendizaje exacto de la membresía y consultas de equivalencia, introducido por Angluin [2]. En este modelo el objetivo de los algoritmos de aprendizaje es identificar exactamente una función diana desconocida f : X → Y a través de consultas a un oráculo. La función de destino se extrae de una función de clase C que es conocida por el algoritmo. Típicamente el dominio X es algún subconjunto de {0, 1}m, y el rango Y es {0, 1} o algún subconjunto de los números reales. A medida que el algoritmo avanza, construye una hipótesis manifiesta?f que es su estimación actual de la función de destino. Después de la terminación, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface?f(x) = f(x) para todos x?X. Es importante especificar la representación que se utilizará para codificar funciones de C. Por ejemplo, considere la siguiente función de {0, 1}m a ♥: f(x) = 2 si x consiste en m 1s, y f(x) = 0 de otra manera. Esta función puede representarse simplemente como una lista de valores de 2m. O puede codificarse como el polinomio 2x1 · · · xm, que es mucho más sucinto. Así pues, la elección de la codificación puede tener un impacto significativo en las necesidades de tiempo y espacio del algoritmo de aprendizaje. Let size(f) ser el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes distintos de cero en el polinomio, por ejemplo. Por lo general, sólo nos referiremos a las clases de representación; las clases de funciones correspondientes serán implícitas. Por ejemplo, la clase de representación de fórmulas DNF monotonas implica la clase de función de funciones booleanas monotonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: la membresía y las consultas de equivalencia. En una consulta de membresía, el aprendiz presenta algunas x x x y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta f. El oráculo responde SÍ si?f = f, o devuelve un contraejemplo x de tal manera que?f(x) = f(x). Una consulta de equivalencia es apropiada si el tamaño( ̃f) ≤ tamaño(f) en el momento de presentar la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones se adaptan a partir de Kearns y Vazirani [9]: Definición 1. La clase de representación C es polinomialquery exactamente aprendeble de las consultas de membresía y equivalencia si hay un polinomial fijo p(·, ·) y un algoritmo L con acceso a la membresía y consultas de equivalencia de un oráculo tal que para cualquier función de destino f • C, L salidas después de a lo sumo p(size(f), m) consultas de una función?f • C tal que?f Del mismo modo, la clase de representación C se puede aprender exactamente de las consultas de membresía y equivalencia si el algoritmo L produce una hipótesis correcta en el tiempo p(size(f), m), para algunos polinomios fijos p(·, ·). Aquí m es la dimensión del dominio. Dado que la función de destino debe ser reconstruida, también permitimos necesariamente la dependencia polinómica del tamaño (f). 2.2 Eliminación de preferencias En una subasta combinatoria, un conjunto de bienes M se asignará entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Tal asignación se llama eficiente en la literatura de economía, pero nos referiremos a ella como óptima y reservar el término eficiente para referirse a la eficiencia computacional. Dejamos n = N y m = M. Una asignación es una partición de los objetos en paquetes (S1,. . . , Sn), de tal manera que Si â € ¬ Sj = â € para todos los i, j â € N. Let â € € sea el conjunto de posibles asignaciones. Cada agente i+N tiene una función de valoración vi : 2M → • sobre el espacio de los paquetes posibles. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no tienen que coincidir. Asumimos que todas las valoraciones consideradas están normalizadas, es decir, v() = 0, y que no hay externalidades, es decir, vi(S1,..., Sn) = vi(Si), para todos los agentes i  N, para cualquier asignación (S1,..., Sn)  (es decir, un agente se preocupa sólo por el paquete asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales.1 Nosotros 1 A menudo las valoraciones generales se hacen para satisfacer los 181 adicionales también asumen que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que los agentes utilidades pueden ser divididos en componentes monetarios y no monetarios. Si a un agente i se le asigna el paquete S al precio p, deriva utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más sucintas para ciertas clases de valoración, y ha habido mucha investigación en lenguajes de licitación concisos para diversos tipos de valoraciones [11]. Un ejemplo clásico al que nos referiremos más adelante es el lenguaje de licitación XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, que consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estas pujas, se busca el paquete S del valor más alto listado en las pujas atómicas de tal manera que S  S. Es entonces el caso que v(S) = v(S). Al igual que en el contexto de la teoría del aprendizaje, por lo general sólo nos referiremos a idiomas de oferta en lugar de clases de valoración, ya que las clases de valoración correspondientes serán implícitas. Por ejemplo, el lenguaje de licitación XOR implica la clase de valoraciones que satisfacen la disposición libre, que es la condición de que A  B ♥ v(A) ≤ v(B). Dejamos el tamaño(v1,. . . , vn) = Èn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de licitación). Para hacer una analogía con la teoría del aprendizaje computacional, suponemos que todas las clases de representación consideradas son polinomiamente interpretables [11], lo que significa que el valor de un paquete puede ser calculado en tiempo polinomio dada la representación de funciones de valoración. Más formalmente, una clase de representación (lenguaje de licitación) C es polinomialmente interpretable si existe un algoritmo que da como entrada algunos v • C y una instancia x • X calcula el valor v(x) en el tiempo q(size(v), m), para algún polinomio fijo q(·, ·).2 En las rondas intermedias de una subasta (terativa), el subastador habrá obtenido información sobre las funciones de Por lo tanto, habrá construido un conjunto de valoraciones manifiestas, denotadas . . Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha adquirido información sobre ciertos paquetes. El objetivo en el problema de la excitación de preferencia es construir un conjunto de valoraciones manifiestas tales que: arg max (S1,...,Sn) iÃ3n Ã3vi(Si)  arg max (S1,...,Sn) iÃ3n vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que es óptima con respecto a las valoraciones verdaderas. Tenga en cuenta que sólo se requiere una asignación óptima. condición de la libre eliminación (monotonicidad), pero no la necesitamos en este punto. 2 Esto excluye OR*, asumiendo P = NP, porque la interpretación de las ofertas de este lenguaje es NP-duro por reducción de set-embalaje ponderado, y no hay clase de representación bien estudiada en teoría de aprendizaje que es claramente análogo a OR*. 3 Esta visión de las subastas iterativas tiene por objeto paralelizar el entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente están implícitas por la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son consultas de valor y demanda. En una consulta de valor, el subastador presenta un paquete S  M y el agente responde con su valor (exacto) para el paquete v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p • • • (2m ) sobre los paquetes junto con un paquete S. El agente responde SI si es el caso de que S • arg max S M v(S ) − p(S ) ¡ o de otro modo presenta un paquete S tal que v(S ) − p(S ) > v( Tenga en cuenta también que comunicar precios no lineales no implica necesariamente citar un precio por cada paquete posible. Puede haber formas más sucintas de comunicar este vector, como se muestra en la sección 5. Hacemos las siguientes definiciones para paralelizar la configuración de aprendizaje de la consulta y para simplificar las declaraciones de resultados posteriores: Definición 2. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si hay un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes tales que para cualquier (v1,. . . , vn) V1 ×. . . × Vn, L salidas después de como máximo p(size(v1,. . . , vn), m) consulta una asignación (S1,. . . , Sn) arg max(S1,...,Sn) È vi(Si). Del mismo modo, la clase de representación C se puede obtener eficientemente de las consultas de valor y demanda si el algoritmo L produce una asignación óptima con comunicación p(size(v1, ). . . , vn), m), para algunos polinomios fijos p(·, ·). Hay algunas diferencias clave aquí con la definición de aprendizaje de la consulta. Hemos eliminado el término exactamente ya que las funciones de valoración no necesitan ser determinadas exactamente con el fin de calcular una asignación óptima. Además, un algoritmo de excitación eficiente es la comunicación polinomio, en lugar de tiempo polinomio. Esto refleja el hecho de que la comunicación en lugar del tiempo de espera es el cuello de botella en la excitación. Cálculo de una asignación óptima de bienes incluso cuando se dan las valoraciones verdaderas es NP-duro para una amplia gama de clases de valoración. Por lo tanto, no es razonable exigir tiempo polinomio en la definición de un algoritmo de excitación de preferencias eficiente. Nos complace centrarnos en la complejidad comunicativa de la excitación porque se cree que este problema es más significativo en la práctica que el de la determinación del ganador [11].5 4 Esto difiere ligeramente de la definición proporcionada por Blum et al. [5] Sus consultas sobre la demanda se limitan a precios lineales sobre las mercancías, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir. un precio distinto por cada paquete posible. Es por eso que el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. 5 Aunque el problema de determinación del ganador es NP-hard para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta aproximaciones usando solucionadores IP fuera de la plataforma [1]. 182 Dado que no es necesario obtener exactamente las valoraciones, es inicialmente menos claro si la dependencia polinómica del tamaño (v1, ). . . , vn) está justificado en este contexto. Intuitivamente, este parámetro está justificado porque debemos aprender valoraciones exactamente cuando se realiza la excitación, en el peor de los casos. Nos ocupamos de esto en la siguiente sección. 3. PARALLESBETWEEN EQUIVALENCIA Y QUERIDAS DE DEMANDA Hemos descrito los ajustes de aprendizaje y excitación de preferencias de la consulta de una manera que destaca sus similitudes. Las consultas de valor y membresía son claras analógicas. Un poco menos obvio es el hecho de que las consultas de equivalencia y demanda también son analógicas. Para ver esto, necesitamos el concepto de precios Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios sobre sus bienes subyacentes. Son no anónimos en el sentido de que dos agentes pueden tener que hacer frente a precios diferentes para el mismo paquete de mercancías. Así los precios de Lindahl son de la forma pi(S), para todos S  M, para todos los precios de i  N. Lindahl se presentan a los agentes en consultas de la demanda. Cuando los agentes han normalizado las funciones de utilidad cuasi-lineal, Bikhchandani y Ostroy [4] muestran que siempre existen precios Lindahl tales que (S1,. . . , Sn) es una asignación óptima si y sólo si Si • arg max Si vi(Si) − pi(Si) • i N (1) (S1,. . . , Sn)  arg max (S1,...,Sn) iN pi(Si) (2) Condición (1) establece que cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos de los subastadores a los precios indicados. El escenario en el que se mantienen estas condiciones se llama equilibrio Lindahl, o a menudo un equilibrio competitivo. Decimos que los precios de Lindahl apoyan la asignación óptima. Por lo tanto, basta con anunciar los precios de apoyo de Lindahl para verificar una asignación óptima. Una vez que hemos encontrado una asignación con el apoyo de precios Lindahl, el problema de excitación se resuelve. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones estén garantizadas como integrales [4]. Las variables duales de este programa lineal están soportando los precios de Lindahl para la asignación resultante. La función objetiva del programa dual es: min pi(S) Por lo general, hay una gama de posibles precios Lindahl que apoyan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios válidos Lindahl, y nos referimos a ellos como precios máximos Lindahl. De todos los vectores posibles de precios Lindahl, precios máximos Lindahl maximizar la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È iÃ3N πi del objetivo (la suma de los agentes de utilidades) son precios mínimos Lindahl. Cualquier Lindahl precios hará para nuestros resultados, pero algunos pueden tener mejores propiedades de excitación que otros. Tenga en cuenta que una consulta de demanda con precios máximos de Lindahl es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para el trabajo futuro la cuestión de los precios de Lindahl para elegir minimizar la obtención de preferencias. Teniendo en cuenta ahora por qué las consultas de demanda y equivalencia son analógicas directas, primero tenga en cuenta que dado el πi en algún equilibrio Lindahl, establecer pi(S) = max{0, Estos precios dejan a cada agente indiferente en todos los paquetes con precio positivo, y satisfacen la condición (1). Así, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl típicamente serán una constante aditivo lejos de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos de consultas de equivalencia a través de consultas de demanda. Lemma 1. Supongamos que un agente responde con un paquete preferido S cuando se propone un paquete S y soporta los precios de Lindahl p(S) (soportando con respecto a la valoración manifiesta de los agentes). A continuación, o bien?v(S) = v(S) o?v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: Φv(S) − p(S) ≥ Desigualdad (6) se mantiene porque el agente de hecho prefiere S a S dados los precios, de acuerdo con su respuesta a la consulta de demanda. Si fuera el caso de que?v(S) = v(S) y Así, al menos uno de S y S es un contraejemplo de la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño(v1,. . . , vn) en problemas de excitación. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que apoyar los precios de Lindahl debe necesariamente revelarse en el curso de cualquier protocolo de obtención de preferencias que termina con una asignación óptima. Además, Nisan y Segal (Lemma 1, [12]) afirman que en el peor de los casos los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones dobles (como será el caso de las clases más interesantes). Puesto que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y puesto que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitiendo la dependencia del tamaño(v1,. . . , vn) en problemas de excitación es totalmente natural. 183 4. DE APRENDIZAJE A LA LICITACIÓN DE PREFERENCIA La clave para convertir un algoritmo de aprendizaje a un algoritmo de excitación es simular consultas de equivalencia con consultas de demanda y valor hasta que se encuentre una asignación óptima. Debido a nuestra construcción de precios Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en que un agente responde SÍ a una consulta de equivalencia cuando la función de destino se ha aprendido exactamente. De lo contrario, podemos obtener un contraejemplo a una consulta de equivalencia dada una respuesta de agentes a una consulta de demanda. Teorema 1. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si cada uno puede ser polinomio-consulta exactamente aprendido de consultas de membresía y equivalencia. Prueba. Considere el algoritmo de excitación en la Figura 1. Cada consulta de membresía en el paso 1 es simulada con una consulta de valor ya que estas son de hecho idénticas. Considere el paso 4. Si todos los agentes responden SÍ, la condición (1) se mantiene. Condición (2) se mantiene porque la asignación calculada es la maximización de ingresos para el subastador, independientemente de los agentes verdaderas valoraciones. Así pues, se ha encontrado una asignación óptima. De lo contrario, por lo menos uno de Si o Si es un contraejemplo a Vi, por Lemma 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones del agente se conocerán exactamente, en cuyo caso la asignación óptima y los precios Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinomio de consultas, desde A1,. . . , A son todos los algoritmos de aprendizaje polinomio-quería. Tenga en cuenta que el procedimiento de conversión resulta en un algoritmo de excitación de preferencias, no un algoritmo de aprendizaje. Es decir, el algoritmo resultante no simplemente aprender las valoraciones exactamente, a continuación, calcular una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor, y periódicamente comprueba si se ha reunido suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio Lindahl para las valoraciones v1,. . . , vn utilizando una asignación y precios derivados de valoraciones manifiestas . . y encontrar una asignación óptima no implica que las valoraciones de los agentes se hayan aprendido exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta interrupción temprana. No obtendremos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE COMUNICACIÓN En esta sección, pasamos a la cuestión de la complejidad comunicativa de la excitación. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (tales como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos de determinar los precios de Lindahl es exponencial en el número de mercancías, m. La carga de comunicación se mide en términos del número de bits transmitidos entre agentes y subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. La conversión de algoritmos de aprendizaje eficientes a un algoritmo de excitación produce un algoritmo cuyas consultas tienen tamaños polinomios en los parámetros m y tamaño (v1, ). . . , vn). Teorema 2. Las clases de representación V1,. . . , Vn se puede obtener de forma eficiente de las consultas de valor y demanda si cada uno puede ser aprendido exactamente de las consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, basta con comunicar la función de valoración manifiesta de los agentes y el valor Nótese que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinomio, porque el tiempo de ejecución de los algoritmos también sería superpolinomio, contradiciendo la eficiencia. Por lo tanto, la comunicación de la valoración manifiesta requiere tamaño a lo sumo p(size(vi), m), para algunos polinomios p que limita superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representando el excedente πi al agente no se puede requerir espacio mayor que q(size( También debemos comunicarnos con su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es como máximo p(size(vi), m) + q(p(size(vi), m), m)+O(m). Claramente, una respuesta de agentes a una consulta de valor o demanda tiene un tamaño máximo de q(size(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, son siempre de tamaño polinomio. Un algoritmo de aprendizaje eficiente realiza un número polinomio de consultas, por lo que la comunicación total del algoritmo de excitación resultante es polinomio en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites pueden ser traducidos a límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de excitación resultante. Con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2 se determinó el tamaño de la hipótesis manifiesta. Es probable que podamos hacerlo mucho mejor que esto en la práctica. Recuerde que una consulta de equivalencia es apropiada si size( ̃f) ≤ size(f) en el momento de realizar la consulta. Si las consultas de equivalencia de algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites estrechos en los requisitos de comunicación del algoritmo de excitación resultante. El teorema 2 muestra que los algoritmos de excitación que dependen del tamaño (v1,. . . El parámetro, vn) evita los resultados negativos de Nisan y Segals [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto al tamaño de las instancias de las funciones de valoración que se enfrentan a cualquier ejecución del algoritmo. Estos algoritmos van bien si la clase de representación elegida proporciona representaciones sucintas para la más simple y común de las valoraciones, y por lo tanto el enfoque se mueve de nuevo a uno de lenguajes de licitación compactos pero expresivos. A continuación se examinan estas cuestiones. 6. APLICACIONES En esta sección, demostramos la aplicación de nuestros métodos a clases particulares de representación para valoraciones combinatorias. Hemos demostrado que el problema de excitación de preferencias para las clases de valoración V1,. . . , Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1,. . . , Una para las valoraciones de las clases V1,. . . , Vn respectivamente. Encaje hasta que haya una señal para detenerse: 1. Corre A1,. . . , Un en paralelo sobre sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se ha detenido con los agentes valoración exacta. 2. Calcular una asignación óptima (S1,. . . , Sn ) y los correspondientes precios de Lindahl con respecto a las valoraciones manifiestas . . , їvn determinado hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de consulta de demanda. 4. Si todos ellos responden SÍ, salida la asignación y parada. De lo contrario hay algún agente i que ha respondido con algún paquete preferido Si. Realizar consultas de valor en Si y Si para encontrar un contraejemplo a ‡vi, y proporcionarlo a Ai. Figura 1: Convertir algoritmos de aprendizaje a un algoritmo de excitación. al problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de función, y porque a menudo puede ser más simple resolver cada subproblema de aprendizaje por separado que atacar el problema de excitación de preferencias directamente. Podemos desarrollar un algoritmo de excitación que se adapta a cada valoración de agentes, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Demostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas de DNF monotono y funciones de umbral lineal se pueden convertir en algoritmos de excitación de preferencia para valoraciones generales, valoraciones con eliminación libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en las representaciones que son polinomialmente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la traqueabilidad computacional [18]. Al interpretar los métodos enfatizamos la expresividad y sucinta de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de licitación, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debe representar sucintamente las funciones más simples y comunes de la clase. 6.1 Representaciones polinómicas Schapire y Sellie [17] dan un algoritmo de aprendizaje para polinomios multivariables escasos que pueden ser utilizados como base para un \"protocolo de subastas combinatoria\". Las consultas de equivalencia realizadas por este algoritmo son todas apropiadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados de t-sparse sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-sparse tiene como máximo t términos, donde un término es un producto de variables, por ejemplo. x1x3x4. Un polinomio sobre los números reales tiene coeficientes extraídos de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M →  se puede escribir exclusivamente como un polinomio [17]. Para tener una idea de la sucintaidad de los polinomios como lenguaje de licitación, considere las valoraciones aditivas y mono-ítem presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es el número de mercancías que contiene el paquete. En la valoración de un solo elemento, todos los paquetes tienen valor 1, excepto el valor 0 (i.e. el agente está satisfecho tan pronto como ha adquirido un único artículo). No es difícil demostrar que la valoración de un solo elemento requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Por lo tanto, los polinomios son adecuados para valoraciones que en su mayoría son aditivas, con algunas sustituibilidades y complementariedades que pueden introducirse ajustando los coeficientes. El algoritmo de aprendizaje para polinomios hace como máximo consultas de equivalencia mti +2 y como máximo (mti +1) (t2 i +3ti)/2 consultas de membresía a un agente i, donde ti es la esparcidad del polinomio que representa vi [17]. Por lo tanto, se obtiene un algoritmo que provoca valoraciones generales con un número polinomio de consultas y comunicación polinomio.6 6.2 XOR Representaciones El lenguaje de licitación XOR es estándar en la literatura de subastas combinatoria. Recordemos que una oferta XOR se caracteriza por un conjunto de paquetes B  2M y una función de valor w : B →  definida en esos paquetes, que induce la función de valoración: v(B) = max {B  B  B  B} w(B) (7) Las ofertas XOR pueden representar valoraciones que satisfacen la libre eliminación (y sólo tales valoraciones), que de nuevo es la propiedad que A  B El lenguaje de licitación XOR es ligeramente menos expresivo que los polinomios, porque los polinomios pueden representar valoraciones que no satisfacen la libre eliminación. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas de XOR pueden representar la valoración de un solo elemento con ofertas atómicas m, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario se aplica a los polinomios, estas dos lenguas son incomparables en sucintas y algo complementarias para su uso práctico. Blum et al. [5] note que las fórmulas DNF monotonas son los análogos de las pujas XOR en la literatura de teoría del aprendizaje. Una fórmula de DNF monotona es una disyunción de conjunciones en las que las variables aparecen sin negación, por ejemplo x1x2 x3 x2x4x5. Tenga en cuenta que tales fórmulas pueden ser representadas como ofertas XOR donde cada oferta atómica tiene valor 1; por lo tanto XOR ofrece generalizar fórmulas DNF monotono de Boolean a funciones de valor real. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para el DNF monotono ([3] Teorema 6 Tenga en cuenta que el Teorema 1 se aplica incluso si las valoraciones no satisfacen la eliminación libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lemma 2. Una oferta XOR que contiene ofertas t atómicas se puede aprender exactamente con consultas de equivalencia t + 1 y a lo sumo consultas de membresía tm. Prueba. El algoritmo identificará cada puja atómica en la puja XOR objetivo a su vez. Initialice la valoración manifiesta v a la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presente ‡v como consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un paquete S para el que v(S) = Crear un paquete T de la siguiente manera. Primero inicialice T = S. Para cada elemento i en T, compruebe a través de una consulta de membresía si v(T) = v(T − {i}). Si así se establece T = T − {i}. De lo contrario, deje T como está y pase al siguiente punto. Afirmamos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada ítem i en T, tenemos v(T) = v(T − {i}). Para ver esto, tenga en cuenta que en algún momento al generar T, tuvimos un ̄T tal que T  ̄T  S y v( ̄T) > v( ̄T − {i}), de modo que me mantuvo en ̄T. Tenga en cuenta que v(S) = v( ̄T) = v(T) porque el valor del paquete S se mantiene durante todo el proceso de eliminación de elementos. Ahora asume v(T) = v(T − {i}). Entonces v( ̄T) = v(T) = v(T − {i}) > v( ̄T − {i}) que contradice la libre eliminación, ya que T {i}  ̄T − {i}. Por lo tanto v(T) > v(T − {i}) para todos los ítems i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si este no fuera el caso, T tomaría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = máx itat {max T T Ahora mostramos que v(T) = ̃v(T), que implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Asumir que toda oferta atómica (R, Esta suposición se mantiene vagamente cuando se inicializa la valoración manifiesta. Usando la notación de (7), dejar ( Tenemos B  B, y Bw(B) = w(B) para B Por lo tanto,?v(S) = max {B} {B} {B} {B} {B} {B} = max {B} {B} {B} ≤ {B} {B} {B} {B} {S} w(B} = v(S) (8) Ahora asume v(T) {v(T La segunda igualdad se deriva del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad sostiene porque S es un contraejemplo de la valoración manifiesta. De la ecuación (9) y la eliminación libre, nosotros 7 El algoritmo citado también se utilizó como base para Zinkevich et al.s [19] algoritmo de excitación para Toolbox DNF. Recuerde que Toolbox DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia se puede simular con una consulta de valor en el paquete que contiene todas las mercancías. que tengan ‡v(T) < Entonces de nuevo de la ecuación (9) se deduce que v(S) < Esto contradice (8), por lo que de hecho tenemos v(T) = Por lo tanto (T, v(T)) no está actualmente en nuestra hipótesis como una oferta atómica, o tendríamos correctamente?v(T) = v(T) por la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas adicionales de equivalencia hasta que todas las ofertas atómicas hayan sido identificadas. Después de cada consulta de equivalencia, una oferta atómica se identifica con como máximo m consultas de membresía. Cada contraejemplo conduce al descubrimiento de una nueva oferta atómica. Por lo tanto, hacemos a lo sumo consultas de membresía tm y exactamente consultas de equivalencia t + 1. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR se puede obtener eficientemente de las consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al.s ([5], Teorema 2) afirmando que el DNF monotono (y por lo tanto las ofertas XOR) no se pueden obtener de manera eficiente cuando las consultas de demanda se limitan a precios lineales y anónimos sobre las mercancías. 6.3 Las representaciones lineales de umbral polinomios, las ofertas XOR y todas las lenguas basadas en el lenguaje de licitación OR (como XOR-de-OR, OR-de-XOR y OR*) no representan sucintamente la valoración mayoritaria [11]. En esta valoración, los paquetes tienen valor 1 si contienen al menos m/2 ítems, y valor 0 de lo contrario. Más generalmente, considere la familia de r-of-S de valoraciones donde los paquetes tienen valor 1 si contienen al menos r artículos de un conjunto especificado de ítems S  M, y valor 0 de otra manera. La valoración mayoritaria es un caso especial de la valoración de r-of-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar las sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede añadir valor. Dejando k = S, tales valoraciones están sucintamente representadas por funciones de umbral r-of-k. Estas funciones adoptan la forma de desigualdades lineales: xi1 +. . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se mantiene, y 0 de lo contrario. Aquí i1,. . . , ik son los elementos en S. Littlestones WINNOW 2 algoritmo puede aprender tales funciones utilizando consultas de equivalencia sólo, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de excitación que resulta de WINNOW 2 sólo utiliza consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos están implícitos cuando sólo hay dos valores posibles). Tenga en cuenta que las funciones de umbral r-of-k siempre se pueden representar sucintamente en el espacio O(m). Así se obtiene un algoritmo que puede generar tales funciones con un número polinomio de consultas y comunicación polinomio, en los parámetros n y m solos. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exactos con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de excitación de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas en el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la riqueza de algoritmos de aprendizaje disponibles al problema de la excitación de preferencias. Un enfoque de aprendizaje para la excitación también motiva un enfoque diferente para diseñar algoritmos de excitación que se descomponen cuidadosamente entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivos, muchos sustitutos, etc.), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de excitación. El algoritmo de excitación resultante hace un número polinomio de consultas, y hace comunicación polinomio si los algoritmos de aprendizaje originales son eficientes. No exigimos que las valoraciones de agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia sólo pueden ser, y sólo necesitan ser, simuladas hasta el punto en que se ha calculado una asignación óptima. Este es el problema de la excitación de preferencias. Teorema 1 implica que la excitación con consultas de valor y demanda no es más difícil que aprender con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las que la excitación es más fácil que el aprendizaje. Blum et al. [5] proporcionar tal ejemplo al considerar solamente consultas de membresía/valor (Teorema 4). En el trabajo futuro planeamos abordar la cuestión de los incentivos al convertir algoritmos de aprendizaje a algoritmos de excitación. En el entorno de aprendizaje, por lo general suponemos que los oráculos proporcionarán respuestas honestas a las preguntas; en el entorno de excitación, los agentes son generalmente egoístas y proporcionarán respuestas posiblemente deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para el aprendizaje de polinomios y ofertas XOR como algoritmos de excitación, y probar su rendimiento contra otros protocolos de subasta combinatoria establecidos [6, 15]. Una pregunta interesante aquí es: ¿qué precios Lindahl en el rango máximo a mínimo son los mejores para citar con el fin de minimizar la revelación de información? Suponemos que la revelación de información se reduce al pasar de precios máximos a precios mínimos de Lindahl, es decir, a medida que desplazamos las consultas de demanda más lejos de las consultas de equivalencia. Por último, sería útil determinar si el lenguaje de licitación de OR* [11] puede aprenderse (y, por lo tanto, obtenerse) de manera eficiente, dada la expresividad y sucinta de estas lenguas para una amplia variedad de clases de valoración. Agradecimientos Queremos agradecer a Debasis Mishra por sus útiles discusiones. Este trabajo está apoyado en parte por la subvención de NSF IIS0238147. 8. REFERENCIAS [1] A. Andersson, M. Tenhunen, y F. Ygge. Programación integral para la determinación del ganador de la subasta combinatoria. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprender conjuntos regulares de consultas y contraejemplos. Información e computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje conceptual. Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El modelo de asignación de paquetes. Diario de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Provocación de preferencias y aprendizaje de consultas. En Proc. 16a Conferencia Anual sobre Teoría del Aprendizaje Computacional (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. la 18a Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, e Y. Shoham. Domar la complejidad computacional de las subastas combinatoria: Enfoques óptimos y aproximados. En Proc. , 16a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), págs. 548 a 553, 1999. [8] B. Hudson y T. Sandholm. Uso de consultas de valor en subastas combinatoria. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría del aprendizaje computacional. MIT Press, 1994. [10] N. Littlestone. Aprender rápidamente cuando los atributos irrelevantes abundan: Un nuevo algoritmo de umbral lineal. Machine Learning, 2:285-318, 1988. [11] N. Nisan. Licitación y asignación en subastas combinatoria. En Proc. la Conferencia de la ACM sobre Comercio Electrónico, págs. 1 a 12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y el apoyo a los precios Lindahl. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de mínima revelación. En Padget et al., editor, Agent-Mediated Electronic Commerce IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. Diseño de subastas con costosas preferencias. En Temas Especiales de Anales de Matemáticas y AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17a Conferencia Nacional sobre Inteligencia Artificial (AAAI-00), págs. 74 a 81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. la 17a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariables escasos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de ACM sobre Teoría del Aprendizaje Computacional, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendido. Comun. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum, y T. Sandholm. Sobre la excitación de la preferencia polinomio-tiempo con las consultas de valor. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "error": [
                ""
            ]
        },
        "polynomial": {
            "translated_key": [
                "polinomio",
                "polinómica",
                "polinómica",
                "polinomio",
                "polinomio",
                "polinómica",
                "polinómica",
                "polinomio",
                "polinomio",
                "polinomio",
                "polinomial",
                "polinomios",
                "polinómica",
                "polinomio",
                "polinomio",
                "polynomial",
                "polinomial",
                "polinomios",
                "polinómica",
                "polinomio",
                "polinomio",
                "polinómica",
                "polynomial",
                "polinomial",
                "polinomio",
                "polinomio",
                "polinomios",
                "polinomios",
                "polinomio",
                "polinomio",
                "polinomio",
                "polinomio",
                "polinomio",
                "polinomio",
                "polinomio",
                "polinomio",
                "polinomio",
                "polinomio",
                "polinomio",
                "polinomio",
                "polinomio",
                "polinómica"
            ],
            "translated_annotated_text": "Aplicando algoritmos de aprendizaje a la eliminación de preferencia Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de excitación Demostramos que los algoritmos de aprendizaje pueden ser usados como base para algoritmos de excitación de preferencias. Los algoritmos de excitación resultantes realizan un número \"polinomio\" de consultas. También damos condiciones bajo las cuales los algoritmos resultantes tienen comunicación \"polinómica\". Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. En particular, obtenemos un algoritmo que provoca ofertas XOR con comunicación \"polinómica\". Categorías y Descriptores sujetos F.2.0 [Análisis de algoritmos y complejidad de problemas]: General; J.4 [Ciencias Sociales y Conductuales]: Economía; I.2.6 [Inteligencia Artificial]: Términos generales de aprendizaje Algoritmos, Economía, Teoría 1. INTRODUCCIÓN En una subasta combinatoria, los agentes pueden pujar por paquetes de bienes en lugar de por cada uno de ellos. Puesto que hay un número exponencial de paquetes (en el número de bienes), comunicar los valores sobre estos paquetes puede ser problemático. Comunicar las valoraciones de una sola vez puede ser prohibitivamente costoso si el número de bienes es sólo moderadamente grande. Además, incluso podría ser difícil para los agentes determinar sus valoraciones para paquetes únicos [14]. A esos agentes les interesa disponer de protocolos de subasta que les obliguen a pujar en el menor número posible de paquetes. Incluso si los agentes pueden calcular eficientemente sus valoraciones, podrían ser reacios a revelarlas enteramente en el curso de una subasta, porque tal información puede ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información necesaria para determinar una asignación óptima de los bienes. Ha habido un trabajo reciente explorando los vínculos entre el problema de la excitación de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje computacional [5, 19]. En teoría de aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, tales como ¿Cuál es el valor de las funciones en estas entradas? En la obtención de preferencia, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Demostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia se puede convertir en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de excitación resultante garantiza la excitación en un número \"polinomio\" de consultas de valor y demanda. Aquí queremos decir \"polinomio\" en el número de bienes, agentes, y los tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Argumentamos que las garantías de complejidad para los esquemas de excitación deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar la comunicación \"polinómica\" en el peor de los casos, que normalmente no se puede lograr en el número de bienes y agentes por sí solos. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. Por supuesto, una subasta combinatoria de un solo disparo donde los agentes proporcionan todas sus funciones de valoración a la vez también tendría comunicación \"polinómica\" en el tamaño de las valoraciones de los agentes, y sólo requieren una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay ninguna carga para los agentes de formular sus valoraciones en un esquema de codificación de los subastadores que elijan. Esperamos que esta sea una consideración importante en la práctica. Además, con nuestro esquema la revelación entera sólo ocurre en el peor de los casos. 180 Por ahora, dejamos a un lado la cuestión de los incentivos al derivar algoritmos de excitación. Nos centramos en el tiempo y la complejidad de la comunicación de la obtención de preferencias, independientemente de las limitaciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich y otros [19] considerar el problema del aprendizaje de clases restringidas de funciones de valoración que se pueden representar utilizando fórmulas de lectura once y Toolbox DNF. Las fórmulas Read-once pueden representar ciertas sustitutibilidades, pero no complementariedades, mientras que lo contrario se mantiene para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten depender del tamaño de la valoración objetivo como lo hacemos (aunque las valoraciones de read-once siempre se pueden representar sucintamente de todos modos). Su trabajo sólo hace uso de consultas de valor, que son bastante limitados en el poder. Debido a que nos permitimos pedir consultas, somos capaces de derivar un esquema de excitación para las funciones de valoración general. Blum et al. [5] proporcionar resultados relacionados con las complejidades del aprendizaje de la consulta y la excitación de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje de consultas, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones se pueden aprender eficientemente, pero no se pueden obtener eficientemente, y viceversa. En contraste, nuestro trabajo muestra que dada una versión más general (todavía bastante estándar) de la consulta de demanda que el tipo que consideran, la complejidad de la excitación de preferencia no es mayor que la complejidad del aprendizaje. Demostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre valoraciones para implicar una solución al problema de excitación. Nisan y Segal [12] estudian la complejidad comunicativa de la excitación de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos de la computación una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo se permite a los algoritmos hacer preguntas sobre valoraciones de agentes y recibir respuestas honestas, sin ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda la cuestión de la complejidad de la comunicación, y somos capaces de derivar algoritmos que proporcionan garantías de comunicación significativas a pesar de los resultados negativos de Nisan y Segals. Su trabajo motiva la necesidad de confiar en el tamaño de los agentes funciones de valoración para indicar los peores resultados. 2. LOS MODELOS 2.1 Aprendizaje de la consulta El modelo de aprendizaje de la consulta que consideramos aquí se llama aprendizaje exacto de la membresía y consultas de equivalencia, introducido por Angluin [2]. En este modelo el objetivo de los algoritmos de aprendizaje es identificar exactamente una función diana desconocida f : X → Y a través de consultas a un oráculo. La función de destino se extrae de una función de clase C que es conocida por el algoritmo. Típicamente el dominio X es algún subconjunto de {0, 1}m, y el rango Y es {0, 1} o algún subconjunto de los números reales. A medida que el algoritmo avanza, construye una hipótesis manifiesta?f que es su estimación actual de la función de destino. Después de la terminación, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface?f(x) = f(x) para todos x?X. Es importante especificar la representación que se utilizará para codificar funciones de C. Por ejemplo, considere la siguiente función de {0, 1}m a ♥: f(x) = 2 si x consiste en m 1s, y f(x) = 0 de otra manera. Esta función puede representarse simplemente como una lista de valores de 2m. O puede codificarse como el \"polinomio\" 2x1 · · · xm, que es mucho más sucinto. Así pues, la elección de la codificación puede tener un impacto significativo en las necesidades de tiempo y espacio del algoritmo de aprendizaje. Let size(f) ser el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un \"polinomio\" puede definirse como el número de coeficientes distintos de cero en el \"polinomio\", por ejemplo. Por lo general, sólo nos referiremos a las clases de representación; las clases de funciones correspondientes serán implícitas. Por ejemplo, la clase de representación de fórmulas DNF monotonas implica la clase de función de funciones booleanas monotonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: la membresía y las consultas de equivalencia. En una consulta de membresía, el aprendiz presenta algunas x x x y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta f. El oráculo responde SÍ si?f = f, o devuelve un contraejemplo x de tal manera que?f(x) = f(x). Una consulta de equivalencia es apropiada si el tamaño( ̃f) ≤ tamaño(f) en el momento de presentar la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones se adaptan a partir de Kearns y Vazirani [9]: Definición 1. La clase de representación C es polinomialquery exactamente aprendible de las consultas de membresía y equivalencia si hay un \"polinomial\" fijo p(·, ·) y un algoritmo L con acceso a la membresía y consultas de equivalencia de un oráculo tal que para cualquier función de destino f • C, salidas L después de a lo sumo p(size(f), m) consultas una función Del mismo modo, la clase de representación C se puede aprender exactamente de las consultas de membresía y equivalencia si el algoritmo L produce una hipótesis correcta en el tiempo p(size(f), m), para algunos \"polinomios\" fijos p(·, ·). Aquí m es la dimensión del dominio. Dado que la función diana debe ser reconstruida, también permitimos necesariamente la dependencia \"polinómica\" del tamaño (f). 2.2 Eliminación de preferencias En una subasta combinatoria, un conjunto de bienes M se asignará entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Tal asignación se llama eficiente en la literatura de economía, pero nos referiremos a ella como óptima y reservar el término eficiente para referirse a la eficiencia computacional. Dejamos n = N y m = M. Una asignación es una partición de los objetos en paquetes (S1,. . . , Sn), de tal manera que Si â € ¬ Sj = â € para todos los i, j â € N. Let â € € sea el conjunto de posibles asignaciones. Cada agente i+N tiene una función de valoración vi : 2M → • sobre el espacio de los paquetes posibles. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no tienen que coincidir. Asumimos que todas las valoraciones consideradas están normalizadas, es decir, v() = 0, y que no hay externalidades, es decir, vi(S1,..., Sn) = vi(Si), para todos los agentes i  N, para cualquier asignación (S1,..., Sn)  (es decir, un agente se preocupa sólo por el paquete asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales.1 Nosotros 1 A menudo las valoraciones generales se hacen para satisfacer los 181 adicionales también asumen que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que los agentes utilidades pueden ser divididos en componentes monetarios y no monetarios. Si a un agente i se le asigna el paquete S al precio p, deriva utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más sucintas para ciertas clases de valoración, y ha habido mucha investigación en lenguajes de licitación concisos para diversos tipos de valoraciones [11]. Un ejemplo clásico al que nos referiremos más adelante es el lenguaje de licitación XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, que consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estas pujas, se busca el paquete S del valor más alto listado en las pujas atómicas de tal manera que S  S. Es entonces el caso que v(S) = v(S). Al igual que en el contexto de la teoría del aprendizaje, por lo general sólo nos referiremos a idiomas de oferta en lugar de clases de valoración, ya que las clases de valoración correspondientes serán implícitas. Por ejemplo, el lenguaje de licitación XOR implica la clase de valoraciones que satisfacen la disposición libre, que es la condición de que A  B ♥ v(A) ≤ v(B). Dejamos el tamaño(v1,. . . , vn) = Èn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de licitación). Para hacer una analogía con la teoría del aprendizaje computacional, suponemos que todas las clases de representación consideradas son polinomiamente interpretables [11], lo que significa que el valor de un paquete puede ser calculado en tiempo \"polinomio\" dada la representación de funciones de valoración. Más formalmente, una clase de representación (lenguaje de licitación) C es polinomialmente interpretable si existe un algoritmo que da como entrada algunos v • C y una instancia x • X calcula el valor v(x) en el tiempo q(size(v), m), para algunos \"polinomio\" fijo q(·, ·).2 En las rondas intermedias de una subasta (terativa), el subastador habrá obtenido información sobre las Por lo tanto, habrá construido un conjunto de valoraciones manifiestas, denotadas . . Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha adquirido información sobre ciertos paquetes. El objetivo en el problema de la excitación de preferencia es construir un conjunto de valoraciones manifiestas tales que: arg max (S1,...,Sn) iÃ3n Ã3vi(Si)  arg max (S1,...,Sn) iÃ3n vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que es óptima con respecto a las valoraciones verdaderas. Tenga en cuenta que sólo se requiere una asignación óptima. condición de la libre eliminación (monotonicidad), pero no la necesitamos en este punto. 2 Esto excluye OR*, asumiendo P = NP, porque la interpretación de las ofertas de este lenguaje es NP-duro por reducción de set-embalaje ponderado, y no hay clase de representación bien estudiada en teoría de aprendizaje que es claramente análogo a OR*. 3 Esta visión de las subastas iterativas tiene por objeto paralelizar el entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente están implícitas por la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son consultas de valor y demanda. En una consulta de valor, el subastador presenta un paquete S  M y el agente responde con su valor (exacto) para el paquete v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p • • • (2m ) sobre los paquetes junto con un paquete S. El agente responde SI si es el caso de que S • arg max S M v(S ) − p(S ) ¡ o de otro modo presenta un paquete S tal que v(S ) − p(S ) > v( Tenga en cuenta también que comunicar precios no lineales no implica necesariamente citar un precio por cada paquete posible. Puede haber formas más sucintas de comunicar este vector, como se muestra en la sección 5. Hacemos las siguientes definiciones para paralelizar la configuración de aprendizaje de la consulta y para simplificar las declaraciones de resultados posteriores: Definición 2. Las clases de representación V1,. . . , Vn puede ser \"polynomial\"-query obtenido de consultas de valor y demanda si hay un fijo \"polinomial\" p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes tales que para cualquier (v1,. . . , vn) V1 ×. . . × Vn, L salidas después de como máximo p(size(v1,. . . , vn), m) consulta una asignación (S1,. . . , Sn) arg max(S1,...,Sn) È vi(Si). Del mismo modo, la clase de representación C se puede obtener eficientemente de las consultas de valor y demanda si el algoritmo L produce una asignación óptima con comunicación p(size(v1, ). . . , vn), m), para algunos \"polinomios\" fijos p(·, ·). Hay algunas diferencias clave aquí con la definición de aprendizaje de la consulta. Hemos eliminado el término exactamente ya que las funciones de valoración no necesitan ser determinadas exactamente con el fin de calcular una asignación óptima. Además, un algoritmo de excitación eficiente es comunicación \"polinómica\", en lugar de tiempo \"polinomio\". Esto refleja el hecho de que la comunicación en lugar del tiempo de espera es el cuello de botella en la excitación. Cálculo de una asignación óptima de bienes incluso cuando se dan las valoraciones verdaderas es NP-duro para una amplia gama de clases de valoración. Por lo tanto, no es razonable exigir tiempo \"polinomio\" en la definición de un algoritmo de excitación de preferencias eficiente. Nos complace centrarnos en la complejidad comunicativa de la excitación porque se cree que este problema es más significativo en la práctica que el de la determinación del ganador [11].5 4 Esto difiere ligeramente de la definición proporcionada por Blum et al. [5] Sus consultas sobre la demanda se limitan a precios lineales sobre las mercancías, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir. un precio distinto por cada paquete posible. Es por eso que el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. 5 Aunque el problema de determinación del ganador es NP-hard para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta aproximaciones usando solucionadores IP fuera de la plataforma [1]. 182 Dado que las valoraciones no es necesario obtener exactamente es inicialmente menos claro si la dependencia \"polinómica\" del tamaño (v1,. . . , vn) está justificado en este contexto. Intuitivamente, este parámetro está justificado porque debemos aprender valoraciones exactamente cuando se realiza la excitación, en el peor de los casos. Nos ocupamos de esto en la siguiente sección. 3. PARALLESBETWEEN EQUIVALENCIA Y QUERIDAS DE DEMANDA Hemos descrito los ajustes de aprendizaje y excitación de preferencias de la consulta de una manera que destaca sus similitudes. Las consultas de valor y membresía son claras analógicas. Un poco menos obvio es el hecho de que las consultas de equivalencia y demanda también son analógicas. Para ver esto, necesitamos el concepto de precios Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios sobre sus bienes subyacentes. Son no anónimos en el sentido de que dos agentes pueden tener que hacer frente a precios diferentes para el mismo paquete de mercancías. Así los precios de Lindahl son de la forma pi(S), para todos S  M, para todos los precios de i  N. Lindahl se presentan a los agentes en consultas de la demanda. Cuando los agentes han normalizado las funciones de utilidad cuasi-lineal, Bikhchandani y Ostroy [4] muestran que siempre existen precios Lindahl tales que (S1,. . . , Sn) es una asignación óptima si y sólo si Si • arg max Si vi(Si) − pi(Si) • i N (1) (S1,. . . , Sn)  arg max (S1,...,Sn) iN pi(Si) (2) Condición (1) establece que cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos de los subastadores a los precios indicados. El escenario en el que se mantienen estas condiciones se llama equilibrio Lindahl, o a menudo un equilibrio competitivo. Decimos que los precios de Lindahl apoyan la asignación óptima. Por lo tanto, basta con anunciar los precios de apoyo de Lindahl para verificar una asignación óptima. Una vez que hemos encontrado una asignación con el apoyo de precios Lindahl, el problema de excitación se resuelve. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones estén garantizadas como integrales [4]. Las variables duales de este programa lineal están soportando los precios de Lindahl para la asignación resultante. La función objetiva del programa dual es: min pi(S) Por lo general, hay una gama de posibles precios Lindahl que apoyan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios válidos Lindahl, y nos referimos a ellos como precios máximos Lindahl. De todos los vectores posibles de precios Lindahl, precios máximos Lindahl maximizar la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È iÃ3N πi del objetivo (la suma de los agentes de utilidades) son precios mínimos Lindahl. Cualquier Lindahl precios hará para nuestros resultados, pero algunos pueden tener mejores propiedades de excitación que otros. Tenga en cuenta que una consulta de demanda con precios máximos de Lindahl es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para el trabajo futuro la cuestión de los precios de Lindahl para elegir minimizar la obtención de preferencias. Teniendo en cuenta ahora por qué las consultas de demanda y equivalencia son analógicas directas, primero tenga en cuenta que dado el πi en algún equilibrio Lindahl, establecer pi(S) = max{0, Estos precios dejan a cada agente indiferente en todos los paquetes con precio positivo, y satisfacen la condición (1). Así, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl típicamente serán una constante aditivo lejos de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos de consultas de equivalencia a través de consultas de demanda. Lemma 1. Supongamos que un agente responde con un paquete preferido S cuando se propone un paquete S y soporta los precios de Lindahl p(S) (soportando con respecto a la valoración manifiesta de los agentes). A continuación, o bien?v(S) = v(S) o?v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: Φv(S) − p(S) ≥ Desigualdad (6) se mantiene porque el agente de hecho prefiere S a S dados los precios, de acuerdo con su respuesta a la consulta de demanda. Si fuera el caso de que?v(S) = v(S) y Así, al menos uno de S y S es un contraejemplo de la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño(v1,. . . , vn) en problemas de excitación. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que apoyar los precios de Lindahl debe necesariamente revelarse en el curso de cualquier protocolo de obtención de preferencias que termina con una asignación óptima. Además, Nisan y Segal (Lemma 1, [12]) afirman que en el peor de los casos los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones dobles (como será el caso de las clases más interesantes). Puesto que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y puesto que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitiendo la dependencia del tamaño(v1,. . . , vn) en problemas de excitación es totalmente natural. 183 4. DE APRENDIZAJE A LA LICITACIÓN DE PREFERENCIA La clave para convertir un algoritmo de aprendizaje a un algoritmo de excitación es simular consultas de equivalencia con consultas de demanda y valor hasta que se encuentre una asignación óptima. Debido a nuestra construcción de precios Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en que un agente responde SÍ a una consulta de equivalencia cuando la función de destino se ha aprendido exactamente. De lo contrario, podemos obtener un contraejemplo a una consulta de equivalencia dada una respuesta de agentes a una consulta de demanda. Teorema 1. Las clases de representación V1,. . . , Vn puede ser \"polynomial\"-query obtenido de las consultas de valor y demanda si cada uno puede ser \"polinomial\"-query exactamente aprendido de las consultas de membresía y equivalencia. Prueba. Considere el algoritmo de excitación en la Figura 1. Cada consulta de membresía en el paso 1 es simulada con una consulta de valor ya que estas son de hecho idénticas. Considere el paso 4. Si todos los agentes responden SÍ, la condición (1) se mantiene. Condición (2) se mantiene porque la asignación calculada es la maximización de ingresos para el subastador, independientemente de los agentes verdaderas valoraciones. Así pues, se ha encontrado una asignación óptima. De lo contrario, por lo menos uno de Si o Si es un contraejemplo a Vi, por Lemma 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones del agente se conocerán exactamente, en cuyo caso la asignación óptima y los precios Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número \"polinomio\" de consultas, desde A1,. . . , A son todos algoritmos de aprendizaje \"polinomio\"-query. Tenga en cuenta que el procedimiento de conversión resulta en un algoritmo de excitación de preferencias, no un algoritmo de aprendizaje. Es decir, el algoritmo resultante no simplemente aprender las valoraciones exactamente, a continuación, calcular una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor, y periódicamente comprueba si se ha reunido suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio Lindahl para las valoraciones v1,. . . , vn utilizando una asignación y precios derivados de valoraciones manifiestas . . y encontrar una asignación óptima no implica que las valoraciones de los agentes se hayan aprendido exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta interrupción temprana. No obtendremos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE COMUNICACIÓN En esta sección, pasamos a la cuestión de la complejidad comunicativa de la excitación. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (tales como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos de determinar los precios de Lindahl es exponencial en el número de mercancías, m. La carga de comunicación se mide en términos del número de bits transmitidos entre agentes y subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. La conversión de algoritmos de aprendizaje eficientes a un algoritmo de excitación produce un algoritmo cuyas consultas tienen tamaños \"polinomios\" en los parámetros m y tamaño (v1, ). . . , vn). Teorema 2. Las clases de representación V1,. . . , Vn se puede obtener de forma eficiente de las consultas de valor y demanda si cada uno puede ser aprendido exactamente de las consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, basta con comunicar la función de valoración manifiesta de los agentes y el valor Nótese que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinomio, porque el tiempo de ejecución de los algoritmos también sería superpolinomio, contradiciendo la eficiencia. Por lo tanto, la comunicación de la valoración manifiesta requiere tamaño a lo sumo p(size(vi), m), para algunos \"polinomios\" p que limita superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representando el excedente πi al agente no se puede requerir espacio mayor que q(size( También debemos comunicarnos con su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es como máximo p(size(vi), m) + q(p(size(vi), m), m)+O(m). Claramente, una respuesta de agentes a una consulta de valor o demanda tiene un tamaño máximo de q(size(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, son siempre de tamaño \"polinomio\". Un algoritmo de aprendizaje eficiente realiza un número \"polinomio\" de consultas, por lo que la comunicación total del algoritmo de excitación resultante es \"polinomio\" en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites pueden ser traducidos a límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de excitación resultante. Con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2 se determinó el tamaño de la hipótesis manifiesta. Es probable que podamos hacerlo mucho mejor que esto en la práctica. Recuerde que una consulta de equivalencia es apropiada si size( ̃f) ≤ size(f) en el momento de realizar la consulta. Si las consultas de equivalencia de algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites estrechos en los requisitos de comunicación del algoritmo de excitación resultante. El teorema 2 muestra que los algoritmos de excitación que dependen del tamaño (v1,. . . El parámetro, vn) evita los resultados negativos de Nisan y Segals [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto al tamaño de las instancias de las funciones de valoración que se enfrentan a cualquier ejecución del algoritmo. Estos algoritmos van bien si la clase de representación elegida proporciona representaciones sucintas para la más simple y común de las valoraciones, y por lo tanto el enfoque se mueve de nuevo a uno de lenguajes de licitación compactos pero expresivos. A continuación se examinan estas cuestiones. 6. APLICACIONES En esta sección, demostramos la aplicación de nuestros métodos a clases particulares de representación para valoraciones combinatorias. Hemos demostrado que el problema de excitación de preferencias para las clases de valoración V1,. . . , Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1,. . . , Una para las valoraciones de las clases V1,. . . , Vn respectivamente. Encaje hasta que haya una señal para detenerse: 1. Corre A1,. . . , Un en paralelo sobre sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se ha detenido con los agentes valoración exacta. 2. Calcular una asignación óptima (S1,. . . , Sn ) y los correspondientes precios de Lindahl con respecto a las valoraciones manifiestas . . , їvn determinado hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de consulta de demanda. 4. Si todos ellos responden SÍ, salida la asignación y parada. De lo contrario hay algún agente i que ha respondido con algún paquete preferido Si. Realizar consultas de valor en Si y Si para encontrar un contraejemplo a ‡vi, y proporcionarlo a Ai. Figura 1: Convertir algoritmos de aprendizaje a un algoritmo de excitación. al problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de función, y porque a menudo puede ser más simple resolver cada subproblema de aprendizaje por separado que atacar el problema de excitación de preferencias directamente. Podemos desarrollar un algoritmo de excitación que se adapta a cada valoración de agentes, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Demostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas de DNF monotono y funciones de umbral lineal se pueden convertir en algoritmos de excitación de preferencia para valoraciones generales, valoraciones con eliminación libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en las representaciones que son polinomialmente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la traqueabilidad computacional [18]. Al interpretar los métodos enfatizamos la expresividad y sucinta de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de licitación, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debe representar sucintamente las funciones más simples y comunes de la clase. 6.1 Las Representaciones Polinómicas Schapire y Sellie [17] dan un algoritmo de aprendizaje para polinomios multivariables escasos que pueden utilizarse como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas apropiadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados de t-sparse sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un t-sparse \"polinomio\" tiene como máximo t términos, donde un término es un producto de variables, por ejemplo. x1x3x4. Un \"polinomio\" sobre los números reales tiene coeficientes extraídos de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M →  se puede escribir como un \"polinomio\" [17]. Para tener una idea de la sucintaidad de los polinomios como lenguaje de licitación, considere las valoraciones aditivas y mono-ítem presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es el número de mercancías que contiene el paquete. En la valoración de un solo elemento, todos los paquetes tienen valor 1, excepto el valor 0 (i.e. el agente está satisfecho tan pronto como ha adquirido un único artículo). No es difícil demostrar que la valoración de un solo elemento requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Por lo tanto, los polinomios son adecuados para valoraciones que en su mayoría son aditivas, con algunas sustituibilidades y complementariedades que pueden introducirse ajustando los coeficientes. El algoritmo de aprendizaje para polinomios hace como máximo consultas de equivalencia mti +2 y como máximo (mti +1)(t2 i +3ti)/2 consultas de membresía a un agente i, donde ti es la esparcidad del \"polinomio\" que representa vi [17]. Por lo tanto, obtenemos un algoritmo que provoca valoraciones generales con un número \"polinomio\" de consultas y comunicación \"polinomio\".6 6.2 Representaciones XOR El lenguaje de licitación XOR es estándar en la literatura de subastas combinatoria. Recordemos que una oferta XOR se caracteriza por un conjunto de paquetes B  2M y una función de valor w : B →  definida en esos paquetes, que induce la función de valoración: v(B) = max {B  B  B  B} w(B) (7) Las ofertas XOR pueden representar valoraciones que satisfacen la libre eliminación (y sólo tales valoraciones), que de nuevo es la propiedad que A  B El lenguaje de licitación XOR es ligeramente menos expresivo que los polinomios, porque los polinomios pueden representar valoraciones que no satisfacen la libre eliminación. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas de XOR pueden representar la valoración de un solo elemento con ofertas atómicas m, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario se aplica a los polinomios, estas dos lenguas son incomparables en sucintas y algo complementarias para su uso práctico. Blum et al. [5] note que las fórmulas DNF monotonas son los análogos de las pujas XOR en la literatura de teoría del aprendizaje. Una fórmula de DNF monotona es una disyunción de conjunciones en las que las variables aparecen sin negación, por ejemplo x1x2 x3 x2x4x5. Tenga en cuenta que tales fórmulas pueden ser representadas como ofertas XOR donde cada oferta atómica tiene valor 1; por lo tanto XOR ofrece generalizar fórmulas DNF monotono de Boolean a funciones de valor real. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para el DNF monotono ([3] Teorema 6 Tenga en cuenta que el Teorema 1 se aplica incluso si las valoraciones no satisfacen la eliminación libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lemma 2. Una oferta XOR que contiene ofertas t atómicas se puede aprender exactamente con consultas de equivalencia t + 1 y a lo sumo consultas de membresía tm. Prueba. El algoritmo identificará cada puja atómica en la puja XOR objetivo a su vez. Initialice la valoración manifiesta v a la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presente ‡v como consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un paquete S para el que v(S) = Crear un paquete T de la siguiente manera. Primero inicialice T = S. Para cada elemento i en T, compruebe a través de una consulta de membresía si v(T) = v(T − {i}). Si así se establece T = T − {i}. De lo contrario, deje T como está y pase al siguiente punto. Afirmamos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada ítem i en T, tenemos v(T) = v(T − {i}). Para ver esto, tenga en cuenta que en algún momento al generar T, tuvimos un ̄T tal que T  ̄T  S y v( ̄T) > v( ̄T − {i}), de modo que me mantuvo en ̄T. Tenga en cuenta que v(S) = v( ̄T) = v(T) porque el valor del paquete S se mantiene durante todo el proceso de eliminación de elementos. Ahora asume v(T) = v(T − {i}). Entonces v( ̄T) = v(T) = v(T − {i}) > v( ̄T − {i}) que contradice la libre eliminación, ya que T {i}  ̄T − {i}. Por lo tanto v(T) > v(T − {i}) para todos los ítems i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si este no fuera el caso, T tomaría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = máx itat {max T T Ahora mostramos que v(T) = ̃v(T), que implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Asumir que toda oferta atómica (R, Esta suposición se mantiene vagamente cuando se inicializa la valoración manifiesta. Usando la notación de (7), dejar ( Tenemos B  B, y Bw(B) = w(B) para B Por lo tanto,?v(S) = max {B} {B} {B} {B} {B} {B} = max {B} {B} {B} ≤ {B} {B} {B} {B} {S} w(B} = v(S) (8) Ahora asume v(T) {v(T La segunda igualdad se deriva del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad sostiene porque S es un contraejemplo de la valoración manifiesta. De la ecuación (9) y la eliminación libre, nosotros 7 El algoritmo citado también se utilizó como base para Zinkevich et al.s [19] algoritmo de excitación para Toolbox DNF. Recuerde que Toolbox DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia se puede simular con una consulta de valor en el paquete que contiene todas las mercancías. que tengan ‡v(T) < Entonces de nuevo de la ecuación (9) se deduce que v(S) < Esto contradice (8), por lo que de hecho tenemos v(T) = Por lo tanto (T, v(T)) no está actualmente en nuestra hipótesis como una oferta atómica, o tendríamos correctamente?v(T) = v(T) por la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas adicionales de equivalencia hasta que todas las ofertas atómicas hayan sido identificadas. Después de cada consulta de equivalencia, una oferta atómica se identifica con como máximo m consultas de membresía. Cada contraejemplo conduce al descubrimiento de una nueva oferta atómica. Por lo tanto, hacemos a lo sumo consultas de membresía tm y exactamente consultas de equivalencia t + 1. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR se puede obtener eficientemente de las consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al.s ([5], Teorema 2) afirmando que el DNF monotono (y por lo tanto las ofertas XOR) no se pueden obtener de manera eficiente cuando las consultas de demanda se limitan a precios lineales y anónimos sobre las mercancías. 6.3 Las representaciones lineales de umbral polinomios, las ofertas XOR y todas las lenguas basadas en el lenguaje de licitación OR (como XOR-de-OR, OR-de-XOR y OR*) no representan sucintamente la valoración mayoritaria [11]. En esta valoración, los paquetes tienen valor 1 si contienen al menos m/2 ítems, y valor 0 de lo contrario. Más generalmente, considere la familia de r-of-S de valoraciones donde los paquetes tienen valor 1 si contienen al menos r artículos de un conjunto especificado de ítems S  M, y valor 0 de otra manera. La valoración mayoritaria es un caso especial de la valoración de r-of-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar las sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede añadir valor. Dejando k = S, tales valoraciones están sucintamente representadas por funciones de umbral r-of-k. Estas funciones adoptan la forma de desigualdades lineales: xi1 +. . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se mantiene, y 0 de lo contrario. Aquí i1,. . . , ik son los elementos en S. Littlestones WINNOW 2 algoritmo puede aprender tales funciones utilizando consultas de equivalencia sólo, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de excitación que resulta de WINNOW 2 sólo utiliza consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos están implícitos cuando sólo hay dos valores posibles). Tenga en cuenta que las funciones de umbral r-of-k siempre se pueden representar sucintamente en el espacio O(m). Así obtenemos un algoritmo que puede provocar tales funciones con un número \"polinomio\" de consultas y comunicación \"polinomio\", sólo en los parámetros n y m. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exactos con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de excitación de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas en el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la riqueza de algoritmos de aprendizaje disponibles al problema de la excitación de preferencias. Un enfoque de aprendizaje para la excitación también motiva un enfoque diferente para diseñar algoritmos de excitación que se descomponen cuidadosamente entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivos, muchos sustitutos, etc.), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de excitación. El algoritmo de excitación resultante hace un número \"polinomio\" de consultas, y hace comunicación \"polinomio\" si los algoritmos de aprendizaje originales son eficientes. No exigimos que las valoraciones de agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia sólo pueden ser, y sólo necesitan ser, simuladas hasta el punto en que se ha calculado una asignación óptima. Este es el problema de la excitación de preferencias. Teorema 1 implica que la excitación con consultas de valor y demanda no es más difícil que aprender con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las que la excitación es más fácil que el aprendizaje. Blum et al. [5] proporcionar tal ejemplo al considerar solamente consultas de membresía/valor (Teorema 4). En el trabajo futuro planeamos abordar la cuestión de los incentivos al convertir algoritmos de aprendizaje a algoritmos de excitación. En el entorno de aprendizaje, por lo general suponemos que los oráculos proporcionarán respuestas honestas a las preguntas; en el entorno de excitación, los agentes son generalmente egoístas y proporcionarán respuestas posiblemente deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para el aprendizaje de polinomios y ofertas XOR como algoritmos de excitación, y probar su rendimiento contra otros protocolos de subasta combinatoria establecidos [6, 15]. Una pregunta interesante aquí es: ¿qué precios Lindahl en el rango máximo a mínimo son los mejores para citar con el fin de minimizar la revelación de información? Suponemos que la revelación de información se reduce al pasar de precios máximos a precios mínimos de Lindahl, es decir, a medida que desplazamos las consultas de demanda más lejos de las consultas de equivalencia. Por último, sería útil determinar si el lenguaje de licitación de OR* [11] puede aprenderse (y, por lo tanto, obtenerse) de manera eficiente, dada la expresividad y sucinta de estas lenguas para una amplia variedad de clases de valoración. Agradecimientos Queremos agradecer a Debasis Mishra por sus útiles discusiones. Este trabajo está apoyado en parte por la subvención de NSF IIS0238147. 8. REFERENCIAS [1] A. Andersson, M. Tenhunen, y F. Ygge. Programación integral para la determinación del ganador de la subasta combinatoria. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprender conjuntos regulares de consultas y contraejemplos. Información e computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje conceptual. Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El modelo de asignación de paquetes. Diario de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Provocación de preferencias y aprendizaje de consultas. En Proc. 16a Conferencia Anual sobre Teoría del Aprendizaje Computacional (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. la 18a Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, e Y. Shoham. Domar la complejidad computacional de las subastas combinatoria: Enfoques óptimos y aproximados. En Proc. , 16a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), págs. 548 a 553, 1999. [8] B. Hudson y T. Sandholm. Uso de consultas de valor en subastas combinatoria. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría del aprendizaje computacional. MIT Press, 1994. [10] N. Littlestone. Aprender rápidamente cuando los atributos irrelevantes abundan: Un nuevo algoritmo de umbral lineal. Machine Learning, 2:285-318, 1988. [11] N. Nisan. Licitación y asignación en subastas combinatoria. En Proc. la Conferencia de la ACM sobre Comercio Electrónico, págs. 1 a 12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y el apoyo a los precios Lindahl. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de mínima revelación. En Padget et al., editor, Agent-Mediated Electronic Commerce IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. Diseño de subastas con costosas preferencias. En Temas Especiales de Anales de Matemáticas y AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17a Conferencia Nacional sobre Inteligencia Artificial (AAAI-00), págs. 74 a 81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. la 17a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariables escasos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de ACM sobre Teoría del Aprendizaje Computacional, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendido. Comun. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum, y T. Sandholm. Sobre la excitación de la preferencia \"polinómica\" del tiempo con las consultas de valor. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "error": [
                "polinomio",
                "polinómica",
                "polinómica",
                "polinomio",
                "polinomio",
                "polinómica",
                "polinómica",
                "polinomio",
                "polinomio",
                "polinomio",
                "polinomial",
                "polinomios",
                "polinómica",
                "polinomio",
                "polinomio",
                "polynomial",
                "polinomial",
                "polinomios",
                "polinómica",
                "polinomio",
                "polinomio",
                "polinómica",
                "polynomial",
                "polinomial",
                "polinomio",
                "polinomio",
                "polinomios",
                "polinomios",
                "polinomio",
                "polinomio",
                "polinomio",
                "polinomio",
                "polinomio",
                "polinomio",
                "polinomio",
                "polinomio",
                "polinomio",
                "polinomio",
                "polinomio",
                "polinomio",
                "polinomio",
                "polinómica"
            ]
        },
        "monotone dnf": {
            "translated_key": [],
            "translated_annotated_text": "Aplicando algoritmos de aprendizaje a la eliminación de preferencia Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de excitación Demostramos que los algoritmos de aprendizaje pueden ser usados como base para algoritmos de excitación de preferencias. Los algoritmos de excitación resultantes realizan un número polinomio de consultas. También damos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. En particular, se obtiene un algoritmo que provoca pujas XOR con comunicación polinómica. Categorías y Descriptores sujetos F.2.0 [Análisis de algoritmos y complejidad de problemas]: General; J.4 [Ciencias Sociales y Conductuales]: Economía; I.2.6 [Inteligencia Artificial]: Términos generales de aprendizaje Algoritmos, Economía, Teoría 1. INTRODUCCIÓN En una subasta combinatoria, los agentes pueden pujar por paquetes de bienes en lugar de por cada uno de ellos. Puesto que hay un número exponencial de paquetes (en el número de bienes), comunicar los valores sobre estos paquetes puede ser problemático. Comunicar las valoraciones de una sola vez puede ser prohibitivamente costoso si el número de bienes es sólo moderadamente grande. Además, incluso podría ser difícil para los agentes determinar sus valoraciones para paquetes únicos [14]. A esos agentes les interesa disponer de protocolos de subasta que les obliguen a pujar en el menor número posible de paquetes. Incluso si los agentes pueden calcular eficientemente sus valoraciones, podrían ser reacios a revelarlas enteramente en el curso de una subasta, porque tal información puede ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información necesaria para determinar una asignación óptima de los bienes. Ha habido un trabajo reciente explorando los vínculos entre el problema de la excitación de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje computacional [5, 19]. En teoría de aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, tales como ¿Cuál es el valor de las funciones en estas entradas? En la obtención de preferencia, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Demostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia se puede convertir en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de excitación resultante garantiza la excitación en un número polinomio de consultas de valor y demanda. Aquí queremos decir polinomio en el número de bienes, agentes, y los tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Argumentamos que las garantías de complejidad para los esquemas de excitación deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar la comunicación polinómica en el peor de los casos, que normalmente no se puede lograr en el número de productos y agentes por sí solos. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. Por supuesto, una subasta combinatoria de un solo disparo donde los agentes proporcionan todas sus funciones de valoración a la vez también tendría comunicación polinómica en el tamaño de las valoraciones de los agentes, y sólo requieren una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay ninguna carga para los agentes de formular sus valoraciones en un esquema de codificación de los subastadores que elijan. Esperamos que esta sea una consideración importante en la práctica. Además, con nuestro esquema la revelación entera sólo ocurre en el peor de los casos. 180 Por ahora, dejamos a un lado la cuestión de los incentivos al derivar algoritmos de excitación. Nos centramos en el tiempo y la complejidad de la comunicación de la obtención de preferencias, independientemente de las limitaciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich y otros [19] considerar el problema del aprendizaje de clases restringidas de funciones de valoración que se pueden representar utilizando fórmulas de lectura once y Toolbox DNF. Las fórmulas Read-once pueden representar ciertas sustitutibilidades, pero no complementariedades, mientras que lo contrario se mantiene para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten depender del tamaño de la valoración objetivo como lo hacemos (aunque las valoraciones de read-once siempre se pueden representar sucintamente de todos modos). Su trabajo sólo hace uso de consultas de valor, que son bastante limitados en el poder. Debido a que nos permitimos pedir consultas, somos capaces de derivar un esquema de excitación para las funciones de valoración general. Blum et al. [5] proporcionar resultados relacionados con las complejidades del aprendizaje de la consulta y la excitación de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje de consultas, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones se pueden aprender eficientemente, pero no se pueden obtener eficientemente, y viceversa. En contraste, nuestro trabajo muestra que dada una versión más general (todavía bastante estándar) de la consulta de demanda que el tipo que consideran, la complejidad de la excitación de preferencia no es mayor que la complejidad del aprendizaje. Demostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre valoraciones para implicar una solución al problema de excitación. Nisan y Segal [12] estudian la complejidad comunicativa de la excitación de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos de la computación una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo se permite a los algoritmos hacer preguntas sobre valoraciones de agentes y recibir respuestas honestas, sin ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda la cuestión de la complejidad de la comunicación, y somos capaces de derivar algoritmos que proporcionan garantías de comunicación significativas a pesar de los resultados negativos de Nisan y Segals. Su trabajo motiva la necesidad de confiar en el tamaño de los agentes funciones de valoración para indicar los peores resultados. 2. LOS MODELOS 2.1 Aprendizaje de la consulta El modelo de aprendizaje de la consulta que consideramos aquí se llama aprendizaje exacto de la membresía y consultas de equivalencia, introducido por Angluin [2]. En este modelo el objetivo de los algoritmos de aprendizaje es identificar exactamente una función diana desconocida f : X → Y a través de consultas a un oráculo. La función de destino se extrae de una función de clase C que es conocida por el algoritmo. Típicamente el dominio X es algún subconjunto de {0, 1}m, y el rango Y es {0, 1} o algún subconjunto de los números reales. A medida que el algoritmo avanza, construye una hipótesis manifiesta?f que es su estimación actual de la función de destino. Después de la terminación, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface?f(x) = f(x) para todos x?X. Es importante especificar la representación que se utilizará para codificar funciones de C. Por ejemplo, considere la siguiente función de {0, 1}m a ♥: f(x) = 2 si x consiste en m 1s, y f(x) = 0 de otra manera. Esta función puede representarse simplemente como una lista de valores de 2m. O puede codificarse como el polinomio 2x1 · · · xm, que es mucho más sucinto. Así pues, la elección de la codificación puede tener un impacto significativo en las necesidades de tiempo y espacio del algoritmo de aprendizaje. Let size(f) ser el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes distintos de cero en el polinomio, por ejemplo. Por lo general, sólo nos referiremos a las clases de representación; las clases de funciones correspondientes serán implícitas. Por ejemplo, la clase de representación de fórmulas DNF monotonas implica la clase de función de funciones booleanas monotonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: la membresía y las consultas de equivalencia. En una consulta de membresía, el aprendiz presenta algunas x x x y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta f. El oráculo responde SÍ si?f = f, o devuelve un contraejemplo x de tal manera que?f(x) = f(x). Una consulta de equivalencia es apropiada si el tamaño( ̃f) ≤ tamaño(f) en el momento de presentar la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones se adaptan a partir de Kearns y Vazirani [9]: Definición 1. La clase de representación C es polinomialquery exactamente aprendeble de las consultas de membresía y equivalencia si hay un polinomial fijo p(·, ·) y un algoritmo L con acceso a la membresía y consultas de equivalencia de un oráculo tal que para cualquier función de destino f • C, L salidas después de a lo sumo p(size(f), m) consultas de una función?f • C tal que?f Del mismo modo, la clase de representación C se puede aprender exactamente de las consultas de membresía y equivalencia si el algoritmo L produce una hipótesis correcta en el tiempo p(size(f), m), para algunos polinomios fijos p(·, ·). Aquí m es la dimensión del dominio. Dado que la función de destino debe ser reconstruida, también permitimos necesariamente la dependencia polinómica del tamaño (f). 2.2 Eliminación de preferencias En una subasta combinatoria, un conjunto de bienes M se asignará entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Tal asignación se llama eficiente en la literatura de economía, pero nos referiremos a ella como óptima y reservar el término eficiente para referirse a la eficiencia computacional. Dejamos n = N y m = M. Una asignación es una partición de los objetos en paquetes (S1,. . . , Sn), de tal manera que Si â € ¬ Sj = â € para todos los i, j â € N. Let â € € sea el conjunto de posibles asignaciones. Cada agente i+N tiene una función de valoración vi : 2M → • sobre el espacio de los paquetes posibles. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no tienen que coincidir. Asumimos que todas las valoraciones consideradas están normalizadas, es decir, v() = 0, y que no hay externalidades, es decir, vi(S1,..., Sn) = vi(Si), para todos los agentes i  N, para cualquier asignación (S1,..., Sn)  (es decir, un agente se preocupa sólo por el paquete asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales.1 Nosotros 1 A menudo las valoraciones generales se hacen para satisfacer los 181 adicionales también asumen que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que los agentes utilidades pueden ser divididos en componentes monetarios y no monetarios. Si a un agente i se le asigna el paquete S al precio p, deriva utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más sucintas para ciertas clases de valoración, y ha habido mucha investigación en lenguajes de licitación concisos para diversos tipos de valoraciones [11]. Un ejemplo clásico al que nos referiremos más adelante es el lenguaje de licitación XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, que consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estas pujas, se busca el paquete S del valor más alto listado en las pujas atómicas de tal manera que S  S. Es entonces el caso que v(S) = v(S). Al igual que en el contexto de la teoría del aprendizaje, por lo general sólo nos referiremos a idiomas de oferta en lugar de clases de valoración, ya que las clases de valoración correspondientes serán implícitas. Por ejemplo, el lenguaje de licitación XOR implica la clase de valoraciones que satisfacen la disposición libre, que es la condición de que A  B ♥ v(A) ≤ v(B). Dejamos el tamaño(v1,. . . , vn) = Èn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de licitación). Para hacer una analogía con la teoría del aprendizaje computacional, suponemos que todas las clases de representación consideradas son polinomiamente interpretables [11], lo que significa que el valor de un paquete puede ser calculado en tiempo polinomio dada la representación de funciones de valoración. Más formalmente, una clase de representación (lenguaje de licitación) C es polinomialmente interpretable si existe un algoritmo que da como entrada algunos v • C y una instancia x • X calcula el valor v(x) en el tiempo q(size(v), m), para algún polinomio fijo q(·, ·).2 En las rondas intermedias de una subasta (terativa), el subastador habrá obtenido información sobre las funciones de Por lo tanto, habrá construido un conjunto de valoraciones manifiestas, denotadas . . Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha adquirido información sobre ciertos paquetes. El objetivo en el problema de la excitación de preferencia es construir un conjunto de valoraciones manifiestas tales que: arg max (S1,...,Sn) iÃ3n Ã3vi(Si)  arg max (S1,...,Sn) iÃ3n vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que es óptima con respecto a las valoraciones verdaderas. Tenga en cuenta que sólo se requiere una asignación óptima. condición de la libre eliminación (monotonicidad), pero no la necesitamos en este punto. 2 Esto excluye OR*, asumiendo P = NP, porque la interpretación de las ofertas de este lenguaje es NP-duro por reducción de set-embalaje ponderado, y no hay clase de representación bien estudiada en teoría de aprendizaje que es claramente análogo a OR*. 3 Esta visión de las subastas iterativas tiene por objeto paralelizar el entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente están implícitas por la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son consultas de valor y demanda. En una consulta de valor, el subastador presenta un paquete S  M y el agente responde con su valor (exacto) para el paquete v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p • • • (2m ) sobre los paquetes junto con un paquete S. El agente responde SI si es el caso de que S • arg max S M v(S ) − p(S ) ¡ o de otro modo presenta un paquete S tal que v(S ) − p(S ) > v( Tenga en cuenta también que comunicar precios no lineales no implica necesariamente citar un precio por cada paquete posible. Puede haber formas más sucintas de comunicar este vector, como se muestra en la sección 5. Hacemos las siguientes definiciones para paralelizar la configuración de aprendizaje de la consulta y para simplificar las declaraciones de resultados posteriores: Definición 2. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si hay un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes tales que para cualquier (v1,. . . , vn) V1 ×. . . × Vn, L salidas después de como máximo p(size(v1,. . . , vn), m) consulta una asignación (S1,. . . , Sn) arg max(S1,...,Sn) È vi(Si). Del mismo modo, la clase de representación C se puede obtener eficientemente de las consultas de valor y demanda si el algoritmo L produce una asignación óptima con comunicación p(size(v1, ). . . , vn), m), para algunos polinomios fijos p(·, ·). Hay algunas diferencias clave aquí con la definición de aprendizaje de la consulta. Hemos eliminado el término exactamente ya que las funciones de valoración no necesitan ser determinadas exactamente con el fin de calcular una asignación óptima. Además, un algoritmo de excitación eficiente es la comunicación polinomio, en lugar de tiempo polinomio. Esto refleja el hecho de que la comunicación en lugar del tiempo de espera es el cuello de botella en la excitación. Cálculo de una asignación óptima de bienes incluso cuando se dan las valoraciones verdaderas es NP-duro para una amplia gama de clases de valoración. Por lo tanto, no es razonable exigir tiempo polinomio en la definición de un algoritmo de excitación de preferencias eficiente. Nos complace centrarnos en la complejidad comunicativa de la excitación porque se cree que este problema es más significativo en la práctica que el de la determinación del ganador [11].5 4 Esto difiere ligeramente de la definición proporcionada por Blum et al. [5] Sus consultas sobre la demanda se limitan a precios lineales sobre las mercancías, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir. un precio distinto por cada paquete posible. Es por eso que el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. 5 Aunque el problema de determinación del ganador es NP-hard para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta aproximaciones usando solucionadores IP fuera de la plataforma [1]. 182 Dado que no es necesario obtener exactamente las valoraciones, es inicialmente menos claro si la dependencia polinómica del tamaño (v1, ). . . , vn) está justificado en este contexto. Intuitivamente, este parámetro está justificado porque debemos aprender valoraciones exactamente cuando se realiza la excitación, en el peor de los casos. Nos ocupamos de esto en la siguiente sección. 3. PARALLESBETWEEN EQUIVALENCIA Y QUERIDAS DE DEMANDA Hemos descrito los ajustes de aprendizaje y excitación de preferencias de la consulta de una manera que destaca sus similitudes. Las consultas de valor y membresía son claras analógicas. Un poco menos obvio es el hecho de que las consultas de equivalencia y demanda también son analógicas. Para ver esto, necesitamos el concepto de precios Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios sobre sus bienes subyacentes. Son no anónimos en el sentido de que dos agentes pueden tener que hacer frente a precios diferentes para el mismo paquete de mercancías. Así los precios de Lindahl son de la forma pi(S), para todos S  M, para todos los precios de i  N. Lindahl se presentan a los agentes en consultas de la demanda. Cuando los agentes han normalizado las funciones de utilidad cuasi-lineal, Bikhchandani y Ostroy [4] muestran que siempre existen precios Lindahl tales que (S1,. . . , Sn) es una asignación óptima si y sólo si Si • arg max Si vi(Si) − pi(Si) • i N (1) (S1,. . . , Sn)  arg max (S1,...,Sn) iN pi(Si) (2) Condición (1) establece que cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos de los subastadores a los precios indicados. El escenario en el que se mantienen estas condiciones se llama equilibrio Lindahl, o a menudo un equilibrio competitivo. Decimos que los precios de Lindahl apoyan la asignación óptima. Por lo tanto, basta con anunciar los precios de apoyo de Lindahl para verificar una asignación óptima. Una vez que hemos encontrado una asignación con el apoyo de precios Lindahl, el problema de excitación se resuelve. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones estén garantizadas como integrales [4]. Las variables duales de este programa lineal están soportando los precios de Lindahl para la asignación resultante. La función objetiva del programa dual es: min pi(S) Por lo general, hay una gama de posibles precios Lindahl que apoyan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios válidos Lindahl, y nos referimos a ellos como precios máximos Lindahl. De todos los vectores posibles de precios Lindahl, precios máximos Lindahl maximizar la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È iÃ3N πi del objetivo (la suma de los agentes de utilidades) son precios mínimos Lindahl. Cualquier Lindahl precios hará para nuestros resultados, pero algunos pueden tener mejores propiedades de excitación que otros. Tenga en cuenta que una consulta de demanda con precios máximos de Lindahl es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para el trabajo futuro la cuestión de los precios de Lindahl para elegir minimizar la obtención de preferencias. Teniendo en cuenta ahora por qué las consultas de demanda y equivalencia son analógicas directas, primero tenga en cuenta que dado el πi en algún equilibrio Lindahl, establecer pi(S) = max{0, Estos precios dejan a cada agente indiferente en todos los paquetes con precio positivo, y satisfacen la condición (1). Así, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl típicamente serán una constante aditivo lejos de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos de consultas de equivalencia a través de consultas de demanda. Lemma 1. Supongamos que un agente responde con un paquete preferido S cuando se propone un paquete S y soporta los precios de Lindahl p(S) (soportando con respecto a la valoración manifiesta de los agentes). A continuación, o bien?v(S) = v(S) o?v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: Φv(S) − p(S) ≥ Desigualdad (6) se mantiene porque el agente de hecho prefiere S a S dados los precios, de acuerdo con su respuesta a la consulta de demanda. Si fuera el caso de que?v(S) = v(S) y Así, al menos uno de S y S es un contraejemplo de la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño(v1,. . . , vn) en problemas de excitación. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que apoyar los precios de Lindahl debe necesariamente revelarse en el curso de cualquier protocolo de obtención de preferencias que termina con una asignación óptima. Además, Nisan y Segal (Lemma 1, [12]) afirman que en el peor de los casos los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones dobles (como será el caso de las clases más interesantes). Puesto que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y puesto que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitiendo la dependencia del tamaño(v1,. . . , vn) en problemas de excitación es totalmente natural. 183 4. DE APRENDIZAJE A LA LICITACIÓN DE PREFERENCIA La clave para convertir un algoritmo de aprendizaje a un algoritmo de excitación es simular consultas de equivalencia con consultas de demanda y valor hasta que se encuentre una asignación óptima. Debido a nuestra construcción de precios Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en que un agente responde SÍ a una consulta de equivalencia cuando la función de destino se ha aprendido exactamente. De lo contrario, podemos obtener un contraejemplo a una consulta de equivalencia dada una respuesta de agentes a una consulta de demanda. Teorema 1. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si cada uno puede ser polinomio-consulta exactamente aprendido de consultas de membresía y equivalencia. Prueba. Considere el algoritmo de excitación en la Figura 1. Cada consulta de membresía en el paso 1 es simulada con una consulta de valor ya que estas son de hecho idénticas. Considere el paso 4. Si todos los agentes responden SÍ, la condición (1) se mantiene. Condición (2) se mantiene porque la asignación calculada es la maximización de ingresos para el subastador, independientemente de los agentes verdaderas valoraciones. Así pues, se ha encontrado una asignación óptima. De lo contrario, por lo menos uno de Si o Si es un contraejemplo a Vi, por Lemma 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones del agente se conocerán exactamente, en cuyo caso la asignación óptima y los precios Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinomio de consultas, desde A1,. . . , A son todos los algoritmos de aprendizaje polinomio-quería. Tenga en cuenta que el procedimiento de conversión resulta en un algoritmo de excitación de preferencias, no un algoritmo de aprendizaje. Es decir, el algoritmo resultante no simplemente aprender las valoraciones exactamente, a continuación, calcular una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor, y periódicamente comprueba si se ha reunido suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio Lindahl para las valoraciones v1,. . . , vn utilizando una asignación y precios derivados de valoraciones manifiestas . . y encontrar una asignación óptima no implica que las valoraciones de los agentes se hayan aprendido exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta interrupción temprana. No obtendremos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE COMUNICACIÓN En esta sección, pasamos a la cuestión de la complejidad comunicativa de la excitación. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (tales como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos de determinar los precios de Lindahl es exponencial en el número de mercancías, m. La carga de comunicación se mide en términos del número de bits transmitidos entre agentes y subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. La conversión de algoritmos de aprendizaje eficientes a un algoritmo de excitación produce un algoritmo cuyas consultas tienen tamaños polinomios en los parámetros m y tamaño (v1, ). . . , vn). Teorema 2. Las clases de representación V1,. . . , Vn se puede obtener de forma eficiente de las consultas de valor y demanda si cada uno puede ser aprendido exactamente de las consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, basta con comunicar la función de valoración manifiesta de los agentes y el valor Nótese que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinomio, porque el tiempo de ejecución de los algoritmos también sería superpolinomio, contradiciendo la eficiencia. Por lo tanto, la comunicación de la valoración manifiesta requiere tamaño a lo sumo p(size(vi), m), para algunos polinomios p que limita superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representando el excedente πi al agente no se puede requerir espacio mayor que q(size( También debemos comunicarnos con su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es como máximo p(size(vi), m) + q(p(size(vi), m), m)+O(m). Claramente, una respuesta de agentes a una consulta de valor o demanda tiene un tamaño máximo de q(size(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, son siempre de tamaño polinomio. Un algoritmo de aprendizaje eficiente realiza un número polinomio de consultas, por lo que la comunicación total del algoritmo de excitación resultante es polinomio en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites pueden ser traducidos a límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de excitación resultante. Con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2 se determinó el tamaño de la hipótesis manifiesta. Es probable que podamos hacerlo mucho mejor que esto en la práctica. Recuerde que una consulta de equivalencia es apropiada si size( ̃f) ≤ size(f) en el momento de realizar la consulta. Si las consultas de equivalencia de algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites estrechos en los requisitos de comunicación del algoritmo de excitación resultante. El teorema 2 muestra que los algoritmos de excitación que dependen del tamaño (v1,. . . El parámetro, vn) evita los resultados negativos de Nisan y Segals [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto al tamaño de las instancias de las funciones de valoración que se enfrentan a cualquier ejecución del algoritmo. Estos algoritmos van bien si la clase de representación elegida proporciona representaciones sucintas para la más simple y común de las valoraciones, y por lo tanto el enfoque se mueve de nuevo a uno de lenguajes de licitación compactos pero expresivos. A continuación se examinan estas cuestiones. 6. APLICACIONES En esta sección, demostramos la aplicación de nuestros métodos a clases particulares de representación para valoraciones combinatorias. Hemos demostrado que el problema de excitación de preferencias para las clases de valoración V1,. . . , Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1,. . . , Una para las valoraciones de las clases V1,. . . , Vn respectivamente. Encaje hasta que haya una señal para detenerse: 1. Corre A1,. . . , Un en paralelo sobre sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se ha detenido con los agentes valoración exacta. 2. Calcular una asignación óptima (S1,. . . , Sn ) y los correspondientes precios de Lindahl con respecto a las valoraciones manifiestas . . , їvn determinado hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de consulta de demanda. 4. Si todos ellos responden SÍ, salida la asignación y parada. De lo contrario hay algún agente i que ha respondido con algún paquete preferido Si. Realizar consultas de valor en Si y Si para encontrar un contraejemplo a ‡vi, y proporcionarlo a Ai. Figura 1: Convertir algoritmos de aprendizaje a un algoritmo de excitación. al problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de función, y porque a menudo puede ser más simple resolver cada subproblema de aprendizaje por separado que atacar el problema de excitación de preferencias directamente. Podemos desarrollar un algoritmo de excitación que se adapta a cada valoración de agentes, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Demostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas de DNF monotono y funciones de umbral lineal se pueden convertir en algoritmos de excitación de preferencia para valoraciones generales, valoraciones con eliminación libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en las representaciones que son polinomialmente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la traqueabilidad computacional [18]. Al interpretar los métodos enfatizamos la expresividad y sucinta de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de licitación, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debe representar sucintamente las funciones más simples y comunes de la clase. 6.1 Las Representaciones Polinómicas Schapire y Sellie [17] dan un algoritmo de aprendizaje para polinomios multivariables escasos que pueden utilizarse como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas apropiadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados de t-sparse sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-sparse tiene como máximo t términos, donde un término es un producto de variables, por ejemplo. x1x3x4. Un polinomio sobre los números reales tiene coeficientes extraídos de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M →  se puede escribir exclusivamente como un polinomio [17]. Para tener una idea de la sucintaidad de los polinomios como lenguaje de licitación, considere las valoraciones aditivas y mono-ítem presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es el número de mercancías que contiene el paquete. En la valoración de un solo elemento, todos los paquetes tienen valor 1, excepto el valor 0 (i.e. el agente está satisfecho tan pronto como ha adquirido un único artículo). No es difícil demostrar que la valoración de un solo elemento requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Por lo tanto, los polinomios son adecuados para valoraciones que en su mayoría son aditivas, con algunas sustituibilidades y complementariedades que pueden introducirse ajustando los coeficientes. El algoritmo de aprendizaje para polinomios hace como máximo consultas de equivalencia mti +2 y como máximo (mti +1) (t2 i +3ti)/2 consultas de membresía a un agente i, donde ti es la esparcidad del polinomio que representa vi [17]. Por lo tanto, se obtiene un algoritmo que provoca valoraciones generales con un número polinomio de consultas y comunicación polinomio.6 6.2 XOR Representaciones El lenguaje de licitación XOR es estándar en la literatura de subastas combinatoria. Recordemos que una oferta XOR se caracteriza por un conjunto de paquetes B  2M y una función de valor w : B →  definida en esos paquetes, que induce la función de valoración: v(B) = max {B  B  B  B} w(B) (7) Las ofertas XOR pueden representar valoraciones que satisfacen la libre eliminación (y sólo tales valoraciones), que de nuevo es la propiedad que A  B El lenguaje de licitación XOR es ligeramente menos expresivo que los polinomios, porque los polinomios pueden representar valoraciones que no satisfacen la libre eliminación. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas de XOR pueden representar la valoración de un solo elemento con ofertas atómicas m, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario se aplica a los polinomios, estas dos lenguas son incomparables en sucintas y algo complementarias para su uso práctico. Blum et al. [5] note que las fórmulas DNF monotonas son los análogos de las pujas XOR en la literatura de teoría del aprendizaje. Una fórmula de DNF monotona es una disyunción de conjunciones en las que las variables aparecen sin negación, por ejemplo x1x2 x3 x2x4x5. Tenga en cuenta que tales fórmulas pueden ser representadas como ofertas XOR donde cada oferta atómica tiene valor 1; por lo tanto XOR ofrece generalizar fórmulas DNF monotono de Boolean a funciones de valor real. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para el DNF monotono ([3] Teorema 6 Tenga en cuenta que el Teorema 1 se aplica incluso si las valoraciones no satisfacen la eliminación libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lemma 2. Una oferta XOR que contiene ofertas t atómicas se puede aprender exactamente con consultas de equivalencia t + 1 y a lo sumo consultas de membresía tm. Prueba. El algoritmo identificará cada puja atómica en la puja XOR objetivo a su vez. Initialice la valoración manifiesta v a la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presente ‡v como consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un paquete S para el que v(S) = Crear un paquete T de la siguiente manera. Primero inicialice T = S. Para cada elemento i en T, compruebe a través de una consulta de membresía si v(T) = v(T − {i}). Si así se establece T = T − {i}. De lo contrario, deje T como está y pase al siguiente punto. Afirmamos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada ítem i en T, tenemos v(T) = v(T − {i}). Para ver esto, tenga en cuenta que en algún momento al generar T, tuvimos un ̄T tal que T  ̄T  S y v( ̄T) > v( ̄T − {i}), de modo que me mantuvo en ̄T. Tenga en cuenta que v(S) = v( ̄T) = v(T) porque el valor del paquete S se mantiene durante todo el proceso de eliminación de elementos. Ahora asume v(T) = v(T − {i}). Entonces v( ̄T) = v(T) = v(T − {i}) > v( ̄T − {i}) que contradice la libre eliminación, ya que T {i}  ̄T − {i}. Por lo tanto v(T) > v(T − {i}) para todos los ítems i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si este no fuera el caso, T tomaría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = máx itat {max T T Ahora mostramos que v(T) = ̃v(T), que implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Asumir que toda oferta atómica (R, Esta suposición se mantiene vagamente cuando se inicializa la valoración manifiesta. Usando la notación de (7), dejar ( Tenemos B  B, y Bw(B) = w(B) para B Por lo tanto,?v(S) = max {B} {B} {B} {B} {B} {B} = max {B} {B} {B} ≤ {B} {B} {B} {B} {S} w(B} = v(S) (8) Ahora asume v(T) {v(T La segunda igualdad se deriva del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad sostiene porque S es un contraejemplo de la valoración manifiesta. De la ecuación (9) y la eliminación libre, nosotros 7 El algoritmo citado también se utilizó como base para Zinkevich et al.s [19] algoritmo de excitación para Toolbox DNF. Recuerde que Toolbox DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia se puede simular con una consulta de valor en el paquete que contiene todas las mercancías. que tengan ‡v(T) < Entonces de nuevo de la ecuación (9) se deduce que v(S) < Esto contradice (8), por lo que de hecho tenemos v(T) = Por lo tanto (T, v(T)) no está actualmente en nuestra hipótesis como una oferta atómica, o tendríamos correctamente?v(T) = v(T) por la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas adicionales de equivalencia hasta que todas las ofertas atómicas hayan sido identificadas. Después de cada consulta de equivalencia, una oferta atómica se identifica con como máximo m consultas de membresía. Cada contraejemplo conduce al descubrimiento de una nueva oferta atómica. Por lo tanto, hacemos a lo sumo consultas de membresía tm y exactamente consultas de equivalencia t + 1. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR se puede obtener eficientemente de las consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al.s ([5], Teorema 2) afirmando que el DNF monotono (y por lo tanto las ofertas XOR) no se pueden obtener de manera eficiente cuando las consultas de demanda se limitan a precios lineales y anónimos sobre las mercancías. 6.3 Las representaciones lineales de umbral polinomios, las ofertas XOR y todas las lenguas basadas en el lenguaje de licitación OR (como XOR-de-OR, OR-de-XOR y OR*) no representan sucintamente la valoración mayoritaria [11]. En esta valoración, los paquetes tienen valor 1 si contienen al menos m/2 ítems, y valor 0 de lo contrario. Más generalmente, considere la familia de r-of-S de valoraciones donde los paquetes tienen valor 1 si contienen al menos r artículos de un conjunto especificado de ítems S  M, y valor 0 de otra manera. La valoración mayoritaria es un caso especial de la valoración de r-of-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar las sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede añadir valor. Dejando k = S, tales valoraciones están sucintamente representadas por funciones de umbral r-of-k. Estas funciones adoptan la forma de desigualdades lineales: xi1 +. . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se mantiene, y 0 de lo contrario. Aquí i1,. . . , ik son los elementos en S. Littlestones WINNOW 2 algoritmo puede aprender tales funciones utilizando consultas de equivalencia sólo, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de excitación que resulta de WINNOW 2 sólo utiliza consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos están implícitos cuando sólo hay dos valores posibles). Tenga en cuenta que las funciones de umbral r-of-k siempre se pueden representar sucintamente en el espacio O(m). Así se obtiene un algoritmo que puede generar tales funciones con un número polinomio de consultas y comunicación polinomio, en los parámetros n y m solos. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exactos con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de excitación de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas en el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la riqueza de algoritmos de aprendizaje disponibles al problema de la excitación de preferencias. Un enfoque de aprendizaje para la excitación también motiva un enfoque diferente para diseñar algoritmos de excitación que se descomponen cuidadosamente entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivos, muchos sustitutos, etc.), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de excitación. El algoritmo de excitación resultante hace un número polinomio de consultas, y hace comunicación polinomio si los algoritmos de aprendizaje originales son eficientes. No exigimos que las valoraciones de agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia sólo pueden ser, y sólo necesitan ser, simuladas hasta el punto en que se ha calculado una asignación óptima. Este es el problema de la excitación de preferencias. Teorema 1 implica que la excitación con consultas de valor y demanda no es más difícil que aprender con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las que la excitación es más fácil que el aprendizaje. Blum et al. [5] proporcionar tal ejemplo al considerar solamente consultas de membresía/valor (Teorema 4). En el trabajo futuro planeamos abordar la cuestión de los incentivos al convertir algoritmos de aprendizaje a algoritmos de excitación. En el entorno de aprendizaje, por lo general suponemos que los oráculos proporcionarán respuestas honestas a las preguntas; en el entorno de excitación, los agentes son generalmente egoístas y proporcionarán respuestas posiblemente deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para el aprendizaje de polinomios y ofertas XOR como algoritmos de excitación, y probar su rendimiento contra otros protocolos de subasta combinatoria establecidos [6, 15]. Una pregunta interesante aquí es: ¿qué precios Lindahl en el rango máximo a mínimo son los mejores para citar con el fin de minimizar la revelación de información? Suponemos que la revelación de información se reduce al pasar de precios máximos a precios mínimos de Lindahl, es decir, a medida que desplazamos las consultas de demanda más lejos de las consultas de equivalencia. Por último, sería útil determinar si el lenguaje de licitación de OR* [11] puede aprenderse (y, por lo tanto, obtenerse) de manera eficiente, dada la expresividad y sucinta de estas lenguas para una amplia variedad de clases de valoración. Agradecimientos Queremos agradecer a Debasis Mishra por sus útiles discusiones. Este trabajo está apoyado en parte por la subvención de NSF IIS0238147. 8. REFERENCIAS [1] A. Andersson, M. Tenhunen, y F. Ygge. Programación integral para la determinación del ganador de la subasta combinatoria. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprender conjuntos regulares de consultas y contraejemplos. Información e computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje conceptual. Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El modelo de asignación de paquetes. Diario de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Provocación de preferencias y aprendizaje de consultas. En Proc. 16a Conferencia Anual sobre Teoría del Aprendizaje Computacional (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. la 18a Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, e Y. Shoham. Domar la complejidad computacional de las subastas combinatoria: Enfoques óptimos y aproximados. En Proc. , 16a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), págs. 548 a 553, 1999. [8] B. Hudson y T. Sandholm. Uso de consultas de valor en subastas combinatoria. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría del aprendizaje computacional. MIT Press, 1994. [10] N. Littlestone. Aprender rápidamente cuando los atributos irrelevantes abundan: Un nuevo algoritmo de umbral lineal. Machine Learning, 2:285-318, 1988. [11] N. Nisan. Licitación y asignación en subastas combinatoria. En Proc. la Conferencia de la ACM sobre Comercio Electrónico, págs. 1 a 12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y el apoyo a los precios Lindahl. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de mínima revelación. En Padget et al., editor, Agent-Mediated Electronic Commerce IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. Diseño de subastas con costosas preferencias. En Temas Especiales de Anales de Matemáticas y AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17a Conferencia Nacional sobre Inteligencia Artificial (AAAI-00), págs. 74 a 81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. la 17a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariables escasos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de ACM sobre Teoría del Aprendizaje Computacional, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendido. Comun. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum, y T. Sandholm. Sobre la excitación de la preferencia polinomio-tiempo con las consultas de valor. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "error": []
        },
        "linear-threshold function": {
            "translated_key": [],
            "translated_annotated_text": "Aplicando algoritmos de aprendizaje a la eliminación de preferencia Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de excitación Demostramos que los algoritmos de aprendizaje pueden ser usados como base para algoritmos de excitación de preferencias. Los algoritmos de excitación resultantes realizan un número polinomio de consultas. También damos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. En particular, se obtiene un algoritmo que provoca pujas XOR con comunicación polinómica. Categorías y Descriptores sujetos F.2.0 [Análisis de algoritmos y complejidad de problemas]: General; J.4 [Ciencias Sociales y Conductuales]: Economía; I.2.6 [Inteligencia Artificial]: Términos generales de aprendizaje Algoritmos, Economía, Teoría 1. INTRODUCCIÓN En una subasta combinatoria, los agentes pueden pujar por paquetes de bienes en lugar de por cada uno de ellos. Puesto que hay un número exponencial de paquetes (en el número de bienes), comunicar los valores sobre estos paquetes puede ser problemático. Comunicar las valoraciones de una sola vez puede ser prohibitivamente costoso si el número de bienes es sólo moderadamente grande. Además, incluso podría ser difícil para los agentes determinar sus valoraciones para paquetes únicos [14]. A esos agentes les interesa disponer de protocolos de subasta que les obliguen a pujar en el menor número posible de paquetes. Incluso si los agentes pueden calcular eficientemente sus valoraciones, podrían ser reacios a revelarlas enteramente en el curso de una subasta, porque tal información puede ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información necesaria para determinar una asignación óptima de los bienes. Ha habido un trabajo reciente explorando los vínculos entre el problema de la excitación de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje computacional [5, 19]. En teoría de aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, tales como ¿Cuál es el valor de las funciones en estas entradas? En la obtención de preferencia, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Demostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia se puede convertir en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de excitación resultante garantiza la excitación en un número polinomio de consultas de valor y demanda. Aquí queremos decir polinomio en el número de bienes, agentes, y los tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Argumentamos que las garantías de complejidad para los esquemas de excitación deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar la comunicación polinómica en el peor de los casos, que normalmente no se puede lograr en el número de productos y agentes por sí solos. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. Por supuesto, una subasta combinatoria de un solo disparo donde los agentes proporcionan todas sus funciones de valoración a la vez también tendría comunicación polinómica en el tamaño de las valoraciones de los agentes, y sólo requieren una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay ninguna carga para los agentes de formular sus valoraciones en un esquema de codificación de los subastadores que elijan. Esperamos que esta sea una consideración importante en la práctica. Además, con nuestro esquema la revelación entera sólo ocurre en el peor de los casos. 180 Por ahora, dejamos a un lado la cuestión de los incentivos al derivar algoritmos de excitación. Nos centramos en el tiempo y la complejidad de la comunicación de la obtención de preferencias, independientemente de las limitaciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich y otros [19] considerar el problema del aprendizaje de clases restringidas de funciones de valoración que se pueden representar utilizando fórmulas de lectura once y Toolbox DNF. Las fórmulas Read-once pueden representar ciertas sustitutibilidades, pero no complementariedades, mientras que lo contrario se mantiene para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten depender del tamaño de la valoración objetivo como lo hacemos (aunque las valoraciones de read-once siempre se pueden representar sucintamente de todos modos). Su trabajo sólo hace uso de consultas de valor, que son bastante limitados en el poder. Debido a que nos permitimos pedir consultas, somos capaces de derivar un esquema de excitación para las funciones de valoración general. Blum et al. [5] proporcionar resultados relacionados con las complejidades del aprendizaje de la consulta y la excitación de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje de consultas, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones se pueden aprender eficientemente, pero no se pueden obtener eficientemente, y viceversa. En contraste, nuestro trabajo muestra que dada una versión más general (todavía bastante estándar) de la consulta de demanda que el tipo que consideran, la complejidad de la excitación de preferencia no es mayor que la complejidad del aprendizaje. Demostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre valoraciones para implicar una solución al problema de excitación. Nisan y Segal [12] estudian la complejidad comunicativa de la excitación de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos de la computación una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo se permite a los algoritmos hacer preguntas sobre valoraciones de agentes y recibir respuestas honestas, sin ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda la cuestión de la complejidad de la comunicación, y somos capaces de derivar algoritmos que proporcionan garantías de comunicación significativas a pesar de los resultados negativos de Nisan y Segals. Su trabajo motiva la necesidad de confiar en el tamaño de los agentes funciones de valoración para indicar los peores resultados. 2. LOS MODELOS 2.1 Aprendizaje de la consulta El modelo de aprendizaje de la consulta que consideramos aquí se llama aprendizaje exacto de la membresía y consultas de equivalencia, introducido por Angluin [2]. En este modelo el objetivo de los algoritmos de aprendizaje es identificar exactamente una función diana desconocida f : X → Y a través de consultas a un oráculo. La función de destino se extrae de una función de clase C que es conocida por el algoritmo. Típicamente el dominio X es algún subconjunto de {0, 1}m, y el rango Y es {0, 1} o algún subconjunto de los números reales. A medida que el algoritmo avanza, construye una hipótesis manifiesta?f que es su estimación actual de la función de destino. Después de la terminación, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface?f(x) = f(x) para todos x?X. Es importante especificar la representación que se utilizará para codificar funciones de C. Por ejemplo, considere la siguiente función de {0, 1}m a ♥: f(x) = 2 si x consiste en m 1s, y f(x) = 0 de otra manera. Esta función puede representarse simplemente como una lista de valores de 2m. O puede codificarse como el polinomio 2x1 · · · xm, que es mucho más sucinto. Así pues, la elección de la codificación puede tener un impacto significativo en las necesidades de tiempo y espacio del algoritmo de aprendizaje. Let size(f) ser el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes distintos de cero en el polinomio, por ejemplo. Por lo general, sólo nos referiremos a las clases de representación; las clases de funciones correspondientes serán implícitas. Por ejemplo, la clase de representación de fórmulas DNF monotonas implica la clase de función de funciones booleanas monotonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: la membresía y las consultas de equivalencia. En una consulta de membresía, el aprendiz presenta algunas x x x y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta f. El oráculo responde SÍ si?f = f, o devuelve un contraejemplo x de tal manera que?f(x) = f(x). Una consulta de equivalencia es apropiada si el tamaño( ̃f) ≤ tamaño(f) en el momento de presentar la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones se adaptan a partir de Kearns y Vazirani [9]: Definición 1. La clase de representación C es polinomialquery exactamente aprendeble de las consultas de membresía y equivalencia si hay un polinomial fijo p(·, ·) y un algoritmo L con acceso a la membresía y consultas de equivalencia de un oráculo tal que para cualquier función de destino f • C, L salidas después de a lo sumo p(size(f), m) consultas de una función?f • C tal que?f Del mismo modo, la clase de representación C se puede aprender exactamente de las consultas de membresía y equivalencia si el algoritmo L produce una hipótesis correcta en el tiempo p(size(f), m), para algunos polinomios fijos p(·, ·). Aquí m es la dimensión del dominio. Dado que la función de destino debe ser reconstruida, también permitimos necesariamente la dependencia polinómica del tamaño (f). 2.2 Eliminación de preferencias En una subasta combinatoria, un conjunto de bienes M se asignará entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Tal asignación se llama eficiente en la literatura de economía, pero nos referiremos a ella como óptima y reservar el término eficiente para referirse a la eficiencia computacional. Dejamos n = N y m = M. Una asignación es una partición de los objetos en paquetes (S1,. . . , Sn), de tal manera que Si â € ¬ Sj = â € para todos los i, j â € N. Let â € € sea el conjunto de posibles asignaciones. Cada agente i+N tiene una función de valoración vi : 2M → • sobre el espacio de los paquetes posibles. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no tienen que coincidir. Asumimos que todas las valoraciones consideradas están normalizadas, es decir, v() = 0, y que no hay externalidades, es decir, vi(S1,..., Sn) = vi(Si), para todos los agentes i  N, para cualquier asignación (S1,..., Sn)  (es decir, un agente se preocupa sólo por el paquete asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales.1 Nosotros 1 A menudo las valoraciones generales se hacen para satisfacer los 181 adicionales también asumen que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que los agentes utilidades pueden ser divididos en componentes monetarios y no monetarios. Si a un agente i se le asigna el paquete S al precio p, deriva utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más sucintas para ciertas clases de valoración, y ha habido mucha investigación en lenguajes de licitación concisos para diversos tipos de valoraciones [11]. Un ejemplo clásico al que nos referiremos más adelante es el lenguaje de licitación XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, que consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estas pujas, se busca el paquete S del valor más alto listado en las pujas atómicas de tal manera que S  S. Es entonces el caso que v(S) = v(S). Al igual que en el contexto de la teoría del aprendizaje, por lo general sólo nos referiremos a idiomas de oferta en lugar de clases de valoración, ya que las clases de valoración correspondientes serán implícitas. Por ejemplo, el lenguaje de licitación XOR implica la clase de valoraciones que satisfacen la disposición libre, que es la condición de que A  B ♥ v(A) ≤ v(B). Dejamos el tamaño(v1,. . . , vn) = Èn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de licitación). Para hacer una analogía con la teoría del aprendizaje computacional, suponemos que todas las clases de representación consideradas son polinomiamente interpretables [11], lo que significa que el valor de un paquete puede ser calculado en tiempo polinomio dada la representación de funciones de valoración. Más formalmente, una clase de representación (lenguaje de licitación) C es polinomialmente interpretable si existe un algoritmo que da como entrada algunos v • C y una instancia x • X calcula el valor v(x) en el tiempo q(size(v), m), para algún polinomio fijo q(·, ·).2 En las rondas intermedias de una subasta (terativa), el subastador habrá obtenido información sobre las funciones de Por lo tanto, habrá construido un conjunto de valoraciones manifiestas, denotadas . . Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha adquirido información sobre ciertos paquetes. El objetivo en el problema de la excitación de preferencia es construir un conjunto de valoraciones manifiestas tales que: arg max (S1,...,Sn) iÃ3n Ã3vi(Si)  arg max (S1,...,Sn) iÃ3n vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que es óptima con respecto a las valoraciones verdaderas. Tenga en cuenta que sólo se requiere una asignación óptima. condición de la libre eliminación (monotonicidad), pero no la necesitamos en este punto. 2 Esto excluye OR*, asumiendo P = NP, porque la interpretación de las ofertas de este lenguaje es NP-duro por reducción de set-embalaje ponderado, y no hay clase de representación bien estudiada en teoría de aprendizaje que es claramente análogo a OR*. 3 Esta visión de las subastas iterativas tiene por objeto paralelizar el entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente están implícitas por la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son consultas de valor y demanda. En una consulta de valor, el subastador presenta un paquete S  M y el agente responde con su valor (exacto) para el paquete v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p • • • (2m ) sobre los paquetes junto con un paquete S. El agente responde SI si es el caso de que S • arg max S M v(S ) − p(S ) ¡ o de otro modo presenta un paquete S tal que v(S ) − p(S ) > v( Tenga en cuenta también que comunicar precios no lineales no implica necesariamente citar un precio por cada paquete posible. Puede haber formas más sucintas de comunicar este vector, como se muestra en la sección 5. Hacemos las siguientes definiciones para paralelizar la configuración de aprendizaje de la consulta y para simplificar las declaraciones de resultados posteriores: Definición 2. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si hay un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes tales que para cualquier (v1,. . . , vn) V1 ×. . . × Vn, L salidas después de como máximo p(size(v1,. . . , vn), m) consulta una asignación (S1,. . . , Sn) arg max(S1,...,Sn) È vi(Si). Del mismo modo, la clase de representación C se puede obtener eficientemente de las consultas de valor y demanda si el algoritmo L produce una asignación óptima con comunicación p(size(v1, ). . . , vn), m), para algunos polinomios fijos p(·, ·). Hay algunas diferencias clave aquí con la definición de aprendizaje de la consulta. Hemos eliminado el término exactamente ya que las funciones de valoración no necesitan ser determinadas exactamente con el fin de calcular una asignación óptima. Además, un algoritmo de excitación eficiente es la comunicación polinomio, en lugar de tiempo polinomio. Esto refleja el hecho de que la comunicación en lugar del tiempo de espera es el cuello de botella en la excitación. Cálculo de una asignación óptima de bienes incluso cuando se dan las valoraciones verdaderas es NP-duro para una amplia gama de clases de valoración. Por lo tanto, no es razonable exigir tiempo polinomio en la definición de un algoritmo de excitación de preferencias eficiente. Nos complace centrarnos en la complejidad comunicativa de la excitación porque se cree que este problema es más significativo en la práctica que el de la determinación del ganador [11].5 4 Esto difiere ligeramente de la definición proporcionada por Blum et al. [5] Sus consultas sobre la demanda se limitan a precios lineales sobre las mercancías, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir. un precio distinto por cada paquete posible. Es por eso que el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. 5 Aunque el problema de determinación del ganador es NP-hard para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta aproximaciones usando solucionadores IP fuera de la plataforma [1]. 182 Dado que no es necesario obtener exactamente las valoraciones, es inicialmente menos claro si la dependencia polinómica del tamaño (v1, ). . . , vn) está justificado en este contexto. Intuitivamente, este parámetro está justificado porque debemos aprender valoraciones exactamente cuando se realiza la excitación, en el peor de los casos. Nos ocupamos de esto en la siguiente sección. 3. PARALLESBETWEEN EQUIVALENCIA Y QUERIDAS DE DEMANDA Hemos descrito los ajustes de aprendizaje y excitación de preferencias de la consulta de una manera que destaca sus similitudes. Las consultas de valor y membresía son claras analógicas. Un poco menos obvio es el hecho de que las consultas de equivalencia y demanda también son analógicas. Para ver esto, necesitamos el concepto de precios Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios sobre sus bienes subyacentes. Son no anónimos en el sentido de que dos agentes pueden tener que hacer frente a precios diferentes para el mismo paquete de mercancías. Así los precios de Lindahl son de la forma pi(S), para todos S  M, para todos los precios de i  N. Lindahl se presentan a los agentes en consultas de la demanda. Cuando los agentes han normalizado las funciones de utilidad cuasi-lineal, Bikhchandani y Ostroy [4] muestran que siempre existen precios Lindahl tales que (S1,. . . , Sn) es una asignación óptima si y sólo si Si • arg max Si vi(Si) − pi(Si) • i N (1) (S1,. . . , Sn)  arg max (S1,...,Sn) iN pi(Si) (2) Condición (1) establece que cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos de los subastadores a los precios indicados. El escenario en el que se mantienen estas condiciones se llama equilibrio Lindahl, o a menudo un equilibrio competitivo. Decimos que los precios de Lindahl apoyan la asignación óptima. Por lo tanto, basta con anunciar los precios de apoyo de Lindahl para verificar una asignación óptima. Una vez que hemos encontrado una asignación con el apoyo de precios Lindahl, el problema de excitación se resuelve. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones estén garantizadas como integrales [4]. Las variables duales de este programa lineal están soportando los precios de Lindahl para la asignación resultante. La función objetiva del programa dual es: min pi(S) Por lo general, hay una gama de posibles precios Lindahl que apoyan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios válidos Lindahl, y nos referimos a ellos como precios máximos Lindahl. De todos los vectores posibles de precios Lindahl, precios máximos Lindahl maximizar la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È iÃ3N πi del objetivo (la suma de los agentes de utilidades) son precios mínimos Lindahl. Cualquier Lindahl precios hará para nuestros resultados, pero algunos pueden tener mejores propiedades de excitación que otros. Tenga en cuenta que una consulta de demanda con precios máximos de Lindahl es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para el trabajo futuro la cuestión de los precios de Lindahl para elegir minimizar la obtención de preferencias. Teniendo en cuenta ahora por qué las consultas de demanda y equivalencia son analógicas directas, primero tenga en cuenta que dado el πi en algún equilibrio Lindahl, establecer pi(S) = max{0, Estos precios dejan a cada agente indiferente en todos los paquetes con precio positivo, y satisfacen la condición (1). Así, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl típicamente serán una constante aditivo lejos de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos de consultas de equivalencia a través de consultas de demanda. Lemma 1. Supongamos que un agente responde con un paquete preferido S cuando se propone un paquete S y soporta los precios de Lindahl p(S) (soportando con respecto a la valoración manifiesta de los agentes). A continuación, o bien?v(S) = v(S) o?v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: Φv(S) − p(S) ≥ Desigualdad (6) se mantiene porque el agente de hecho prefiere S a S dados los precios, de acuerdo con su respuesta a la consulta de demanda. Si fuera el caso de que?v(S) = v(S) y Así, al menos uno de S y S es un contraejemplo de la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño(v1,. . . , vn) en problemas de excitación. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que apoyar los precios de Lindahl debe necesariamente revelarse en el curso de cualquier protocolo de obtención de preferencias que termina con una asignación óptima. Además, Nisan y Segal (Lemma 1, [12]) afirman que en el peor de los casos los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones dobles (como será el caso de las clases más interesantes). Puesto que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y puesto que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitiendo la dependencia del tamaño(v1,. . . , vn) en problemas de excitación es totalmente natural. 183 4. DE APRENDIZAJE A LA LICITACIÓN DE PREFERENCIA La clave para convertir un algoritmo de aprendizaje a un algoritmo de excitación es simular consultas de equivalencia con consultas de demanda y valor hasta que se encuentre una asignación óptima. Debido a nuestra construcción de precios Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en que un agente responde SÍ a una consulta de equivalencia cuando la función de destino se ha aprendido exactamente. De lo contrario, podemos obtener un contraejemplo a una consulta de equivalencia dada una respuesta de agentes a una consulta de demanda. Teorema 1. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si cada uno puede ser polinomio-consulta exactamente aprendido de consultas de membresía y equivalencia. Prueba. Considere el algoritmo de excitación en la Figura 1. Cada consulta de membresía en el paso 1 es simulada con una consulta de valor ya que estas son de hecho idénticas. Considere el paso 4. Si todos los agentes responden SÍ, la condición (1) se mantiene. Condición (2) se mantiene porque la asignación calculada es la maximización de ingresos para el subastador, independientemente de los agentes verdaderas valoraciones. Así pues, se ha encontrado una asignación óptima. De lo contrario, por lo menos uno de Si o Si es un contraejemplo a Vi, por Lemma 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones del agente se conocerán exactamente, en cuyo caso la asignación óptima y los precios Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinomio de consultas, desde A1,. . . , A son todos los algoritmos de aprendizaje polinomio-quería. Tenga en cuenta que el procedimiento de conversión resulta en un algoritmo de excitación de preferencias, no un algoritmo de aprendizaje. Es decir, el algoritmo resultante no simplemente aprender las valoraciones exactamente, a continuación, calcular una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor, y periódicamente comprueba si se ha reunido suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio Lindahl para las valoraciones v1,. . . , vn utilizando una asignación y precios derivados de valoraciones manifiestas . . y encontrar una asignación óptima no implica que las valoraciones de los agentes se hayan aprendido exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta interrupción temprana. No obtendremos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE COMUNICACIÓN En esta sección, pasamos a la cuestión de la complejidad comunicativa de la excitación. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (tales como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos de determinar los precios de Lindahl es exponencial en el número de mercancías, m. La carga de comunicación se mide en términos del número de bits transmitidos entre agentes y subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. La conversión de algoritmos de aprendizaje eficientes a un algoritmo de excitación produce un algoritmo cuyas consultas tienen tamaños polinomios en los parámetros m y tamaño (v1, ). . . , vn). Teorema 2. Las clases de representación V1,. . . , Vn se puede obtener de forma eficiente de las consultas de valor y demanda si cada uno puede ser aprendido exactamente de las consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, basta con comunicar la función de valoración manifiesta de los agentes y el valor Nótese que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinomio, porque el tiempo de ejecución de los algoritmos también sería superpolinomio, contradiciendo la eficiencia. Por lo tanto, la comunicación de la valoración manifiesta requiere tamaño a lo sumo p(size(vi), m), para algunos polinomios p que limita superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representando el excedente πi al agente no se puede requerir espacio mayor que q(size( También debemos comunicarnos con su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es como máximo p(size(vi), m) + q(p(size(vi), m), m)+O(m). Claramente, una respuesta de agentes a una consulta de valor o demanda tiene un tamaño máximo de q(size(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, son siempre de tamaño polinomio. Un algoritmo de aprendizaje eficiente realiza un número polinomio de consultas, por lo que la comunicación total del algoritmo de excitación resultante es polinomio en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites pueden ser traducidos a límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de excitación resultante. Con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2 se determinó el tamaño de la hipótesis manifiesta. Es probable que podamos hacerlo mucho mejor que esto en la práctica. Recuerde que una consulta de equivalencia es apropiada si size( ̃f) ≤ size(f) en el momento de realizar la consulta. Si las consultas de equivalencia de algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites estrechos en los requisitos de comunicación del algoritmo de excitación resultante. El teorema 2 muestra que los algoritmos de excitación que dependen del tamaño (v1,. . . El parámetro, vn) evita los resultados negativos de Nisan y Segals [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto al tamaño de las instancias de las funciones de valoración que se enfrentan a cualquier ejecución del algoritmo. Estos algoritmos van bien si la clase de representación elegida proporciona representaciones sucintas para la más simple y común de las valoraciones, y por lo tanto el enfoque se mueve de nuevo a uno de lenguajes de licitación compactos pero expresivos. A continuación se examinan estas cuestiones. 6. APLICACIONES En esta sección, demostramos la aplicación de nuestros métodos a clases particulares de representación para valoraciones combinatorias. Hemos demostrado que el problema de excitación de preferencias para las clases de valoración V1,. . . , Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1,. . . , Una para las valoraciones de las clases V1,. . . , Vn respectivamente. Encaje hasta que haya una señal para detenerse: 1. Corre A1,. . . , Un en paralelo sobre sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se ha detenido con los agentes valoración exacta. 2. Calcular una asignación óptima (S1,. . . , Sn ) y los correspondientes precios de Lindahl con respecto a las valoraciones manifiestas . . , їvn determinado hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de consulta de demanda. 4. Si todos ellos responden SÍ, salida la asignación y parada. De lo contrario hay algún agente i que ha respondido con algún paquete preferido Si. Realizar consultas de valor en Si y Si para encontrar un contraejemplo a ‡vi, y proporcionarlo a Ai. Figura 1: Convertir algoritmos de aprendizaje a un algoritmo de excitación. al problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de función, y porque a menudo puede ser más simple resolver cada subproblema de aprendizaje por separado que atacar el problema de excitación de preferencias directamente. Podemos desarrollar un algoritmo de excitación que se adapta a cada valoración de agentes, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Demostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas de DNF monotono y funciones de umbral lineal se pueden convertir en algoritmos de excitación de preferencia para valoraciones generales, valoraciones con eliminación libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en las representaciones que son polinomialmente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la traqueabilidad computacional [18]. Al interpretar los métodos enfatizamos la expresividad y sucinta de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de licitación, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debe representar sucintamente las funciones más simples y comunes de la clase. 6.1 Las Representaciones Polinómicas Schapire y Sellie [17] dan un algoritmo de aprendizaje para polinomios multivariables escasos que pueden utilizarse como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas apropiadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados de t-sparse sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-sparse tiene como máximo t términos, donde un término es un producto de variables, por ejemplo. x1x3x4. Un polinomio sobre los números reales tiene coeficientes extraídos de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M →  se puede escribir exclusivamente como un polinomio [17]. Para tener una idea de la sucintaidad de los polinomios como lenguaje de licitación, considere las valoraciones aditivas y mono-ítem presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es el número de mercancías que contiene el paquete. En la valoración de un solo elemento, todos los paquetes tienen valor 1, excepto el valor 0 (i.e. el agente está satisfecho tan pronto como ha adquirido un único artículo). No es difícil demostrar que la valoración de un solo elemento requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Por lo tanto, los polinomios son adecuados para valoraciones que en su mayoría son aditivas, con algunas sustituibilidades y complementariedades que pueden introducirse ajustando los coeficientes. El algoritmo de aprendizaje para polinomios hace como máximo consultas de equivalencia mti +2 y como máximo (mti +1) (t2 i +3ti)/2 consultas de membresía a un agente i, donde ti es la esparcidad del polinomio que representa vi [17]. Por lo tanto, se obtiene un algoritmo que provoca valoraciones generales con un número polinomio de consultas y comunicación polinomio.6 6.2 XOR Representaciones El lenguaje de licitación XOR es estándar en la literatura de subastas combinatoria. Recordemos que una oferta XOR se caracteriza por un conjunto de paquetes B  2M y una función de valor w : B →  definida en esos paquetes, que induce la función de valoración: v(B) = max {B  B  B  B} w(B) (7) Las ofertas XOR pueden representar valoraciones que satisfacen la libre eliminación (y sólo tales valoraciones), que de nuevo es la propiedad que A  B El lenguaje de licitación XOR es ligeramente menos expresivo que los polinomios, porque los polinomios pueden representar valoraciones que no satisfacen la libre eliminación. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas de XOR pueden representar la valoración de un solo elemento con ofertas atómicas m, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario se aplica a los polinomios, estas dos lenguas son incomparables en sucintas y algo complementarias para su uso práctico. Blum et al. [5] note que las fórmulas DNF monotonas son los análogos de las pujas XOR en la literatura de teoría del aprendizaje. Una fórmula de DNF monotona es una disyunción de conjunciones en las que las variables aparecen sin negación, por ejemplo x1x2 x3 x2x4x5. Tenga en cuenta que tales fórmulas pueden ser representadas como ofertas XOR donde cada oferta atómica tiene valor 1; por lo tanto XOR ofrece generalizar fórmulas DNF monotono de Boolean a funciones de valor real. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para el DNF monotono ([3] Teorema 6 Tenga en cuenta que el Teorema 1 se aplica incluso si las valoraciones no satisfacen la eliminación libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lemma 2. Una oferta XOR que contiene ofertas t atómicas se puede aprender exactamente con consultas de equivalencia t + 1 y a lo sumo consultas de membresía tm. Prueba. El algoritmo identificará cada puja atómica en la puja XOR objetivo a su vez. Initialice la valoración manifiesta v a la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presente ‡v como consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un paquete S para el que v(S) = Crear un paquete T de la siguiente manera. Primero inicialice T = S. Para cada elemento i en T, compruebe a través de una consulta de membresía si v(T) = v(T − {i}). Si así se establece T = T − {i}. De lo contrario, deje T como está y pase al siguiente punto. Afirmamos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada ítem i en T, tenemos v(T) = v(T − {i}). Para ver esto, tenga en cuenta que en algún momento al generar T, tuvimos un ̄T tal que T  ̄T  S y v( ̄T) > v( ̄T − {i}), de modo que me mantuvo en ̄T. Tenga en cuenta que v(S) = v( ̄T) = v(T) porque el valor del paquete S se mantiene durante todo el proceso de eliminación de elementos. Ahora asume v(T) = v(T − {i}). Entonces v( ̄T) = v(T) = v(T − {i}) > v( ̄T − {i}) que contradice la libre eliminación, ya que T {i}  ̄T − {i}. Por lo tanto v(T) > v(T − {i}) para todos los ítems i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si este no fuera el caso, T tomaría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = máx itat {max T T Ahora mostramos que v(T) = ̃v(T), que implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Asumir que toda oferta atómica (R, Esta suposición se mantiene vagamente cuando se inicializa la valoración manifiesta. Usando la notación de (7), dejar ( Tenemos B  B, y Bw(B) = w(B) para B Por lo tanto,?v(S) = max {B} {B} {B} {B} {B} {B} = max {B} {B} {B} ≤ {B} {B} {B} {B} {S} w(B} = v(S) (8) Ahora asume v(T) {v(T La segunda igualdad se deriva del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad sostiene porque S es un contraejemplo de la valoración manifiesta. De la ecuación (9) y la eliminación libre, nosotros 7 El algoritmo citado también se utilizó como base para Zinkevich et al.s [19] algoritmo de excitación para Toolbox DNF. Recuerde que Toolbox DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia se puede simular con una consulta de valor en el paquete que contiene todas las mercancías. que tengan ‡v(T) < Entonces de nuevo de la ecuación (9) se deduce que v(S) < Esto contradice (8), por lo que de hecho tenemos v(T) = Por lo tanto (T, v(T)) no está actualmente en nuestra hipótesis como una oferta atómica, o tendríamos correctamente?v(T) = v(T) por la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas adicionales de equivalencia hasta que todas las ofertas atómicas hayan sido identificadas. Después de cada consulta de equivalencia, una oferta atómica se identifica con como máximo m consultas de membresía. Cada contraejemplo conduce al descubrimiento de una nueva oferta atómica. Por lo tanto, hacemos a lo sumo consultas de membresía tm y exactamente consultas de equivalencia t + 1. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR se puede obtener eficientemente de las consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al.s ([5], Teorema 2) afirmando que el DNF monotono (y por lo tanto las ofertas XOR) no se pueden obtener de manera eficiente cuando las consultas de demanda se limitan a precios lineales y anónimos sobre las mercancías. 6.3 Las representaciones lineales de umbral polinomios, las ofertas XOR y todas las lenguas basadas en el lenguaje de licitación OR (como XOR-de-OR, OR-de-XOR y OR*) no representan sucintamente la valoración mayoritaria [11]. En esta valoración, los paquetes tienen valor 1 si contienen al menos m/2 ítems, y valor 0 de lo contrario. Más generalmente, considere la familia de r-of-S de valoraciones donde los paquetes tienen valor 1 si contienen al menos r artículos de un conjunto especificado de ítems S  M, y valor 0 de otra manera. La valoración mayoritaria es un caso especial de la valoración de r-of-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar las sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede añadir valor. Dejando k = S, tales valoraciones están sucintamente representadas por funciones de umbral r-of-k. Estas funciones adoptan la forma de desigualdades lineales: xi1 +. . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se mantiene, y 0 de lo contrario. Aquí i1,. . . , ik son los elementos en S. Littlestones WINNOW 2 algoritmo puede aprender tales funciones utilizando consultas de equivalencia sólo, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de excitación que resulta de WINNOW 2 sólo utiliza consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos están implícitos cuando sólo hay dos valores posibles). Tenga en cuenta que las funciones de umbral r-of-k siempre se pueden representar sucintamente en el espacio O(m). Así se obtiene un algoritmo que puede generar tales funciones con un número polinomio de consultas y comunicación polinomio, en los parámetros n y m solos. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exactos con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de excitación de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas en el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la riqueza de algoritmos de aprendizaje disponibles al problema de la excitación de preferencias. Un enfoque de aprendizaje para la excitación también motiva un enfoque diferente para diseñar algoritmos de excitación que se descomponen cuidadosamente entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivos, muchos sustitutos, etc.), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de excitación. El algoritmo de excitación resultante hace un número polinomio de consultas, y hace comunicación polinomio si los algoritmos de aprendizaje originales son eficientes. No exigimos que las valoraciones de agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia sólo pueden ser, y sólo necesitan ser, simuladas hasta el punto en que se ha calculado una asignación óptima. Este es el problema de la excitación de preferencias. Teorema 1 implica que la excitación con consultas de valor y demanda no es más difícil que aprender con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las que la excitación es más fácil que el aprendizaje. Blum et al. [5] proporcionar tal ejemplo al considerar solamente consultas de membresía/valor (Teorema 4). En el trabajo futuro planeamos abordar la cuestión de los incentivos al convertir algoritmos de aprendizaje a algoritmos de excitación. En el entorno de aprendizaje, por lo general suponemos que los oráculos proporcionarán respuestas honestas a las preguntas; en el entorno de excitación, los agentes son generalmente egoístas y proporcionarán respuestas posiblemente deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para el aprendizaje de polinomios y ofertas XOR como algoritmos de excitación, y probar su rendimiento contra otros protocolos de subasta combinatoria establecidos [6, 15]. Una pregunta interesante aquí es: ¿qué precios Lindahl en el rango máximo a mínimo son los mejores para citar con el fin de minimizar la revelación de información? Suponemos que la revelación de información se reduce al pasar de precios máximos a precios mínimos de Lindahl, es decir, a medida que desplazamos las consultas de demanda más lejos de las consultas de equivalencia. Por último, sería útil determinar si el lenguaje de licitación de OR* [11] puede aprenderse (y, por lo tanto, obtenerse) de manera eficiente, dada la expresividad y sucinta de estas lenguas para una amplia variedad de clases de valoración. Agradecimientos Queremos agradecer a Debasis Mishra por sus útiles discusiones. Este trabajo está apoyado en parte por la subvención de NSF IIS0238147. 8. REFERENCIAS [1] A. Andersson, M. Tenhunen, y F. Ygge. Programación integral para la determinación del ganador de la subasta combinatoria. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprender conjuntos regulares de consultas y contraejemplos. Información e computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje conceptual. Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El modelo de asignación de paquetes. Diario de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Provocación de preferencias y aprendizaje de consultas. En Proc. 16a Conferencia Anual sobre Teoría del Aprendizaje Computacional (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. la 18a Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, e Y. Shoham. Domar la complejidad computacional de las subastas combinatoria: Enfoques óptimos y aproximados. En Proc. , 16a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), págs. 548 a 553, 1999. [8] B. Hudson y T. Sandholm. Uso de consultas de valor en subastas combinatoria. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría del aprendizaje computacional. MIT Press, 1994. [10] N. Littlestone. Aprender rápidamente cuando los atributos irrelevantes abundan: Un nuevo algoritmo de umbral lineal. Machine Learning, 2:285-318, 1988. [11] N. Nisan. Licitación y asignación en subastas combinatoria. En Proc. la Conferencia de la ACM sobre Comercio Electrónico, págs. 1 a 12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y el apoyo a los precios Lindahl. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de mínima revelación. En Padget et al., editor, Agent-Mediated Electronic Commerce IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. Diseño de subastas con costosas preferencias. En Temas Especiales de Anales de Matemáticas y AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17a Conferencia Nacional sobre Inteligencia Artificial (AAAI-00), págs. 74 a 81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. la 17a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariables escasos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de ACM sobre Teoría del Aprendizaje Computacional, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendido. Comun. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum, y T. Sandholm. Sobre la excitación de la preferencia polinomio-tiempo con las consultas de valor. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "error": []
        },
        "xor bid": {
            "translated_key": [],
            "translated_annotated_text": "Aplicando algoritmos de aprendizaje a la eliminación de preferencia Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de excitación Demostramos que los algoritmos de aprendizaje pueden ser usados como base para algoritmos de excitación de preferencias. Los algoritmos de excitación resultantes realizan un número polinomio de consultas. También damos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. En particular, se obtiene un algoritmo que provoca pujas XOR con comunicación polinómica. Categorías y Descriptores sujetos F.2.0 [Análisis de algoritmos y complejidad de problemas]: General; J.4 [Ciencias Sociales y Conductuales]: Economía; I.2.6 [Inteligencia Artificial]: Términos generales de aprendizaje Algoritmos, Economía, Teoría 1. INTRODUCCIÓN En una subasta combinatoria, los agentes pueden pujar por paquetes de bienes en lugar de por cada uno de ellos. Puesto que hay un número exponencial de paquetes (en el número de bienes), comunicar los valores sobre estos paquetes puede ser problemático. Comunicar las valoraciones de una sola vez puede ser prohibitivamente costoso si el número de bienes es sólo moderadamente grande. Además, incluso podría ser difícil para los agentes determinar sus valoraciones para paquetes únicos [14]. A esos agentes les interesa disponer de protocolos de subasta que les obliguen a pujar en el menor número posible de paquetes. Incluso si los agentes pueden calcular eficientemente sus valoraciones, podrían ser reacios a revelarlas enteramente en el curso de una subasta, porque tal información puede ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información necesaria para determinar una asignación óptima de los bienes. Ha habido un trabajo reciente explorando los vínculos entre el problema de la excitación de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje computacional [5, 19]. En teoría de aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, tales como ¿Cuál es el valor de las funciones en estas entradas? En la obtención de preferencia, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Demostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia se puede convertir en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de excitación resultante garantiza la excitación en un número polinomio de consultas de valor y demanda. Aquí queremos decir polinomio en el número de bienes, agentes, y los tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Argumentamos que las garantías de complejidad para los esquemas de excitación deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar la comunicación polinómica en el peor de los casos, que normalmente no se puede lograr en el número de productos y agentes por sí solos. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. Por supuesto, una subasta combinatoria de un solo disparo donde los agentes proporcionan todas sus funciones de valoración a la vez también tendría comunicación polinómica en el tamaño de las valoraciones de los agentes, y sólo requieren una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay ninguna carga para los agentes de formular sus valoraciones en un esquema de codificación de los subastadores que elijan. Esperamos que esta sea una consideración importante en la práctica. Además, con nuestro esquema la revelación entera sólo ocurre en el peor de los casos. 180 Por ahora, dejamos a un lado la cuestión de los incentivos al derivar algoritmos de excitación. Nos centramos en el tiempo y la complejidad de la comunicación de la obtención de preferencias, independientemente de las limitaciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich y otros [19] considerar el problema del aprendizaje de clases restringidas de funciones de valoración que se pueden representar utilizando fórmulas de lectura once y Toolbox DNF. Las fórmulas Read-once pueden representar ciertas sustitutibilidades, pero no complementariedades, mientras que lo contrario se mantiene para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten depender del tamaño de la valoración objetivo como lo hacemos (aunque las valoraciones de read-once siempre se pueden representar sucintamente de todos modos). Su trabajo sólo hace uso de consultas de valor, que son bastante limitados en el poder. Debido a que nos permitimos pedir consultas, somos capaces de derivar un esquema de excitación para las funciones de valoración general. Blum et al. [5] proporcionar resultados relacionados con las complejidades del aprendizaje de la consulta y la excitación de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje de consultas, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones se pueden aprender eficientemente, pero no se pueden obtener eficientemente, y viceversa. En contraste, nuestro trabajo muestra que dada una versión más general (todavía bastante estándar) de la consulta de demanda que el tipo que consideran, la complejidad de la excitación de preferencia no es mayor que la complejidad del aprendizaje. Demostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre valoraciones para implicar una solución al problema de excitación. Nisan y Segal [12] estudian la complejidad comunicativa de la excitación de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos de la computación una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo se permite a los algoritmos hacer preguntas sobre valoraciones de agentes y recibir respuestas honestas, sin ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda la cuestión de la complejidad de la comunicación, y somos capaces de derivar algoritmos que proporcionan garantías de comunicación significativas a pesar de los resultados negativos de Nisan y Segals. Su trabajo motiva la necesidad de confiar en el tamaño de los agentes funciones de valoración para indicar los peores resultados. 2. LOS MODELOS 2.1 Aprendizaje de la consulta El modelo de aprendizaje de la consulta que consideramos aquí se llama aprendizaje exacto de la membresía y consultas de equivalencia, introducido por Angluin [2]. En este modelo el objetivo de los algoritmos de aprendizaje es identificar exactamente una función diana desconocida f : X → Y a través de consultas a un oráculo. La función de destino se extrae de una función de clase C que es conocida por el algoritmo. Típicamente el dominio X es algún subconjunto de {0, 1}m, y el rango Y es {0, 1} o algún subconjunto de los números reales. A medida que el algoritmo avanza, construye una hipótesis manifiesta?f que es su estimación actual de la función de destino. Después de la terminación, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface?f(x) = f(x) para todos x?X. Es importante especificar la representación que se utilizará para codificar funciones de C. Por ejemplo, considere la siguiente función de {0, 1}m a ♥: f(x) = 2 si x consiste en m 1s, y f(x) = 0 de otra manera. Esta función puede representarse simplemente como una lista de valores de 2m. O puede codificarse como el polinomio 2x1 · · · xm, que es mucho más sucinto. Así pues, la elección de la codificación puede tener un impacto significativo en las necesidades de tiempo y espacio del algoritmo de aprendizaje. Let size(f) ser el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes distintos de cero en el polinomio, por ejemplo. Por lo general, sólo nos referiremos a las clases de representación; las clases de funciones correspondientes serán implícitas. Por ejemplo, la clase de representación de fórmulas DNF monotonas implica la clase de función de funciones booleanas monotonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: la membresía y las consultas de equivalencia. En una consulta de membresía, el aprendiz presenta algunas x x x y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta f. El oráculo responde SÍ si?f = f, o devuelve un contraejemplo x de tal manera que?f(x) = f(x). Una consulta de equivalencia es apropiada si el tamaño( ̃f) ≤ tamaño(f) en el momento de presentar la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones se adaptan a partir de Kearns y Vazirani [9]: Definición 1. La clase de representación C es polinomialquery exactamente aprendeble de las consultas de membresía y equivalencia si hay un polinomial fijo p(·, ·) y un algoritmo L con acceso a la membresía y consultas de equivalencia de un oráculo tal que para cualquier función de destino f • C, L salidas después de a lo sumo p(size(f), m) consultas de una función?f • C tal que?f Del mismo modo, la clase de representación C se puede aprender exactamente de las consultas de membresía y equivalencia si el algoritmo L produce una hipótesis correcta en el tiempo p(size(f), m), para algunos polinomios fijos p(·, ·). Aquí m es la dimensión del dominio. Dado que la función de destino debe ser reconstruida, también permitimos necesariamente la dependencia polinómica del tamaño (f). 2.2 Eliminación de preferencias En una subasta combinatoria, un conjunto de bienes M se asignará entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Tal asignación se llama eficiente en la literatura de economía, pero nos referiremos a ella como óptima y reservar el término eficiente para referirse a la eficiencia computacional. Dejamos n = N y m = M. Una asignación es una partición de los objetos en paquetes (S1,. . . , Sn), de tal manera que Si â € ¬ Sj = â € para todos los i, j â € N. Let â € € sea el conjunto de posibles asignaciones. Cada agente i+N tiene una función de valoración vi : 2M → • sobre el espacio de los paquetes posibles. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no tienen que coincidir. Asumimos que todas las valoraciones consideradas están normalizadas, es decir, v() = 0, y que no hay externalidades, es decir, vi(S1,..., Sn) = vi(Si), para todos los agentes i  N, para cualquier asignación (S1,..., Sn)  (es decir, un agente se preocupa sólo por el paquete asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales.1 Nosotros 1 A menudo las valoraciones generales se hacen para satisfacer los 181 adicionales también asumen que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que los agentes utilidades pueden ser divididos en componentes monetarios y no monetarios. Si a un agente i se le asigna el paquete S al precio p, deriva utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más sucintas para ciertas clases de valoración, y ha habido mucha investigación en lenguajes de licitación concisos para diversos tipos de valoraciones [11]. Un ejemplo clásico al que nos referiremos más adelante es el lenguaje de licitación XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, que consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estas pujas, se busca el paquete S del valor más alto listado en las pujas atómicas de tal manera que S  S. Es entonces el caso que v(S) = v(S). Al igual que en el contexto de la teoría del aprendizaje, por lo general sólo nos referiremos a idiomas de oferta en lugar de clases de valoración, ya que las clases de valoración correspondientes serán implícitas. Por ejemplo, el lenguaje de licitación XOR implica la clase de valoraciones que satisfacen la disposición libre, que es la condición de que A  B ♥ v(A) ≤ v(B). Dejamos el tamaño(v1,. . . , vn) = Èn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de licitación). Para hacer una analogía con la teoría del aprendizaje computacional, suponemos que todas las clases de representación consideradas son polinomiamente interpretables [11], lo que significa que el valor de un paquete puede ser calculado en tiempo polinomio dada la representación de funciones de valoración. Más formalmente, una clase de representación (lenguaje de licitación) C es polinomialmente interpretable si existe un algoritmo que da como entrada algunos v • C y una instancia x • X calcula el valor v(x) en el tiempo q(size(v), m), para algún polinomio fijo q(·, ·).2 En las rondas intermedias de una subasta (terativa), el subastador habrá obtenido información sobre las funciones de Por lo tanto, habrá construido un conjunto de valoraciones manifiestas, denotadas . . Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha adquirido información sobre ciertos paquetes. El objetivo en el problema de la excitación de preferencia es construir un conjunto de valoraciones manifiestas tales que: arg max (S1,...,Sn) iÃ3n Ã3vi(Si)  arg max (S1,...,Sn) iÃ3n vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que es óptima con respecto a las valoraciones verdaderas. Tenga en cuenta que sólo se requiere una asignación óptima. condición de la libre eliminación (monotonicidad), pero no la necesitamos en este punto. 2 Esto excluye OR*, asumiendo P = NP, porque la interpretación de las ofertas de este lenguaje es NP-duro por reducción de set-embalaje ponderado, y no hay clase de representación bien estudiada en teoría de aprendizaje que es claramente análogo a OR*. 3 Esta visión de las subastas iterativas tiene por objeto paralelizar el entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente están implícitas por la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son consultas de valor y demanda. En una consulta de valor, el subastador presenta un paquete S  M y el agente responde con su valor (exacto) para el paquete v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p • • • (2m ) sobre los paquetes junto con un paquete S. El agente responde SI si es el caso de que S • arg max S M v(S ) − p(S ) ¡ o de otro modo presenta un paquete S tal que v(S ) − p(S ) > v( Tenga en cuenta también que comunicar precios no lineales no implica necesariamente citar un precio por cada paquete posible. Puede haber formas más sucintas de comunicar este vector, como se muestra en la sección 5. Hacemos las siguientes definiciones para paralelizar la configuración de aprendizaje de la consulta y para simplificar las declaraciones de resultados posteriores: Definición 2. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si hay un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes tales que para cualquier (v1,. . . , vn) V1 ×. . . × Vn, L salidas después de como máximo p(size(v1,. . . , vn), m) consulta una asignación (S1,. . . , Sn) arg max(S1,...,Sn) È vi(Si). Del mismo modo, la clase de representación C se puede obtener eficientemente de las consultas de valor y demanda si el algoritmo L produce una asignación óptima con comunicación p(size(v1, ). . . , vn), m), para algunos polinomios fijos p(·, ·). Hay algunas diferencias clave aquí con la definición de aprendizaje de la consulta. Hemos eliminado el término exactamente ya que las funciones de valoración no necesitan ser determinadas exactamente con el fin de calcular una asignación óptima. Además, un algoritmo de excitación eficiente es la comunicación polinomio, en lugar de tiempo polinomio. Esto refleja el hecho de que la comunicación en lugar del tiempo de espera es el cuello de botella en la excitación. Cálculo de una asignación óptima de bienes incluso cuando se dan las valoraciones verdaderas es NP-duro para una amplia gama de clases de valoración. Por lo tanto, no es razonable exigir tiempo polinomio en la definición de un algoritmo de excitación de preferencias eficiente. Nos complace centrarnos en la complejidad comunicativa de la excitación porque se cree que este problema es más significativo en la práctica que el de la determinación del ganador [11].5 4 Esto difiere ligeramente de la definición proporcionada por Blum et al. [5] Sus consultas sobre la demanda se limitan a precios lineales sobre las mercancías, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir. un precio distinto por cada paquete posible. Es por eso que el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. 5 Aunque el problema de determinación del ganador es NP-hard para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta aproximaciones usando solucionadores IP fuera de la plataforma [1]. 182 Dado que no es necesario obtener exactamente las valoraciones, es inicialmente menos claro si la dependencia polinómica del tamaño (v1, ). . . , vn) está justificado en este contexto. Intuitivamente, este parámetro está justificado porque debemos aprender valoraciones exactamente cuando se realiza la excitación, en el peor de los casos. Nos ocupamos de esto en la siguiente sección. 3. PARALLESBETWEEN EQUIVALENCIA Y QUERIDAS DE DEMANDA Hemos descrito los ajustes de aprendizaje y excitación de preferencias de la consulta de una manera que destaca sus similitudes. Las consultas de valor y membresía son claras analógicas. Un poco menos obvio es el hecho de que las consultas de equivalencia y demanda también son analógicas. Para ver esto, necesitamos el concepto de precios Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios sobre sus bienes subyacentes. Son no anónimos en el sentido de que dos agentes pueden tener que hacer frente a precios diferentes para el mismo paquete de mercancías. Así los precios de Lindahl son de la forma pi(S), para todos S  M, para todos los precios de i  N. Lindahl se presentan a los agentes en consultas de la demanda. Cuando los agentes han normalizado las funciones de utilidad cuasi-lineal, Bikhchandani y Ostroy [4] muestran que siempre existen precios Lindahl tales que (S1,. . . , Sn) es una asignación óptima si y sólo si Si • arg max Si vi(Si) − pi(Si) • i N (1) (S1,. . . , Sn)  arg max (S1,...,Sn) iN pi(Si) (2) Condición (1) establece que cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos de los subastadores a los precios indicados. El escenario en el que se mantienen estas condiciones se llama equilibrio Lindahl, o a menudo un equilibrio competitivo. Decimos que los precios de Lindahl apoyan la asignación óptima. Por lo tanto, basta con anunciar los precios de apoyo de Lindahl para verificar una asignación óptima. Una vez que hemos encontrado una asignación con el apoyo de precios Lindahl, el problema de excitación se resuelve. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones estén garantizadas como integrales [4]. Las variables duales de este programa lineal están soportando los precios de Lindahl para la asignación resultante. La función objetiva del programa dual es: min pi(S) Por lo general, hay una gama de posibles precios Lindahl que apoyan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios válidos Lindahl, y nos referimos a ellos como precios máximos Lindahl. De todos los vectores posibles de precios Lindahl, precios máximos Lindahl maximizar la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È iÃ3N πi del objetivo (la suma de los agentes de utilidades) son precios mínimos Lindahl. Cualquier Lindahl precios hará para nuestros resultados, pero algunos pueden tener mejores propiedades de excitación que otros. Tenga en cuenta que una consulta de demanda con precios máximos de Lindahl es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para el trabajo futuro la cuestión de los precios de Lindahl para elegir minimizar la obtención de preferencias. Teniendo en cuenta ahora por qué las consultas de demanda y equivalencia son analógicas directas, primero tenga en cuenta que dado el πi en algún equilibrio Lindahl, establecer pi(S) = max{0, Estos precios dejan a cada agente indiferente en todos los paquetes con precio positivo, y satisfacen la condición (1). Así, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl típicamente serán una constante aditivo lejos de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos de consultas de equivalencia a través de consultas de demanda. Lemma 1. Supongamos que un agente responde con un paquete preferido S cuando se propone un paquete S y soporta los precios de Lindahl p(S) (soportando con respecto a la valoración manifiesta de los agentes). A continuación, o bien?v(S) = v(S) o?v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: Φv(S) − p(S) ≥ Desigualdad (6) se mantiene porque el agente de hecho prefiere S a S dados los precios, de acuerdo con su respuesta a la consulta de demanda. Si fuera el caso de que?v(S) = v(S) y Así, al menos uno de S y S es un contraejemplo de la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño(v1,. . . , vn) en problemas de excitación. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que apoyar los precios de Lindahl debe necesariamente revelarse en el curso de cualquier protocolo de obtención de preferencias que termina con una asignación óptima. Además, Nisan y Segal (Lemma 1, [12]) afirman que en el peor de los casos los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones dobles (como será el caso de las clases más interesantes). Puesto que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y puesto que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitiendo la dependencia del tamaño(v1,. . . , vn) en problemas de excitación es totalmente natural. 183 4. DE APRENDIZAJE A LA LICITACIÓN DE PREFERENCIA La clave para convertir un algoritmo de aprendizaje a un algoritmo de excitación es simular consultas de equivalencia con consultas de demanda y valor hasta que se encuentre una asignación óptima. Debido a nuestra construcción de precios Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en que un agente responde SÍ a una consulta de equivalencia cuando la función de destino se ha aprendido exactamente. De lo contrario, podemos obtener un contraejemplo a una consulta de equivalencia dada una respuesta de agentes a una consulta de demanda. Teorema 1. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si cada uno puede ser polinomio-consulta exactamente aprendido de consultas de membresía y equivalencia. Prueba. Considere el algoritmo de excitación en la Figura 1. Cada consulta de membresía en el paso 1 es simulada con una consulta de valor ya que estas son de hecho idénticas. Considere el paso 4. Si todos los agentes responden SÍ, la condición (1) se mantiene. Condición (2) se mantiene porque la asignación calculada es la maximización de ingresos para el subastador, independientemente de los agentes verdaderas valoraciones. Así pues, se ha encontrado una asignación óptima. De lo contrario, por lo menos uno de Si o Si es un contraejemplo a Vi, por Lemma 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones del agente se conocerán exactamente, en cuyo caso la asignación óptima y los precios Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinomio de consultas, desde A1,. . . , A son todos los algoritmos de aprendizaje polinomio-quería. Tenga en cuenta que el procedimiento de conversión resulta en un algoritmo de excitación de preferencias, no un algoritmo de aprendizaje. Es decir, el algoritmo resultante no simplemente aprender las valoraciones exactamente, a continuación, calcular una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor, y periódicamente comprueba si se ha reunido suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio Lindahl para las valoraciones v1,. . . , vn utilizando una asignación y precios derivados de valoraciones manifiestas . . y encontrar una asignación óptima no implica que las valoraciones de los agentes se hayan aprendido exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta interrupción temprana. No obtendremos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE COMUNICACIÓN En esta sección, pasamos a la cuestión de la complejidad comunicativa de la excitación. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (tales como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos de determinar los precios de Lindahl es exponencial en el número de mercancías, m. La carga de comunicación se mide en términos del número de bits transmitidos entre agentes y subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. La conversión de algoritmos de aprendizaje eficientes a un algoritmo de excitación produce un algoritmo cuyas consultas tienen tamaños polinomios en los parámetros m y tamaño (v1, ). . . , vn). Teorema 2. Las clases de representación V1,. . . , Vn se puede obtener de forma eficiente de las consultas de valor y demanda si cada uno puede ser aprendido exactamente de las consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, basta con comunicar la función de valoración manifiesta de los agentes y el valor Nótese que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinomio, porque el tiempo de ejecución de los algoritmos también sería superpolinomio, contradiciendo la eficiencia. Por lo tanto, la comunicación de la valoración manifiesta requiere tamaño a lo sumo p(size(vi), m), para algunos polinomios p que limita superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representando el excedente πi al agente no se puede requerir espacio mayor que q(size( También debemos comunicarnos con su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es como máximo p(size(vi), m) + q(p(size(vi), m), m)+O(m). Claramente, una respuesta de agentes a una consulta de valor o demanda tiene un tamaño máximo de q(size(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, son siempre de tamaño polinomio. Un algoritmo de aprendizaje eficiente realiza un número polinomio de consultas, por lo que la comunicación total del algoritmo de excitación resultante es polinomio en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites pueden ser traducidos a límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de excitación resultante. Con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2 se determinó el tamaño de la hipótesis manifiesta. Es probable que podamos hacerlo mucho mejor que esto en la práctica. Recuerde que una consulta de equivalencia es apropiada si size( ̃f) ≤ size(f) en el momento de realizar la consulta. Si las consultas de equivalencia de algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites estrechos en los requisitos de comunicación del algoritmo de excitación resultante. El teorema 2 muestra que los algoritmos de excitación que dependen del tamaño (v1,. . . El parámetro, vn) evita los resultados negativos de Nisan y Segals [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto al tamaño de las instancias de las funciones de valoración que se enfrentan a cualquier ejecución del algoritmo. Estos algoritmos van bien si la clase de representación elegida proporciona representaciones sucintas para la más simple y común de las valoraciones, y por lo tanto el enfoque se mueve de nuevo a uno de lenguajes de licitación compactos pero expresivos. A continuación se examinan estas cuestiones. 6. APLICACIONES En esta sección, demostramos la aplicación de nuestros métodos a clases particulares de representación para valoraciones combinatorias. Hemos demostrado que el problema de excitación de preferencias para las clases de valoración V1,. . . , Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1,. . . , Una para las valoraciones de las clases V1,. . . , Vn respectivamente. Encaje hasta que haya una señal para detenerse: 1. Corre A1,. . . , Un en paralelo sobre sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se ha detenido con los agentes valoración exacta. 2. Calcular una asignación óptima (S1,. . . , Sn ) y los correspondientes precios de Lindahl con respecto a las valoraciones manifiestas . . , їvn determinado hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de consulta de demanda. 4. Si todos ellos responden SÍ, salida la asignación y parada. De lo contrario hay algún agente i que ha respondido con algún paquete preferido Si. Realizar consultas de valor en Si y Si para encontrar un contraejemplo a ‡vi, y proporcionarlo a Ai. Figura 1: Convertir algoritmos de aprendizaje a un algoritmo de excitación. al problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de función, y porque a menudo puede ser más simple resolver cada subproblema de aprendizaje por separado que atacar el problema de excitación de preferencias directamente. Podemos desarrollar un algoritmo de excitación que se adapta a cada valoración de agentes, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Demostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas de DNF monotono y funciones de umbral lineal se pueden convertir en algoritmos de excitación de preferencia para valoraciones generales, valoraciones con eliminación libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en las representaciones que son polinomialmente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la traqueabilidad computacional [18]. Al interpretar los métodos enfatizamos la expresividad y sucinta de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de licitación, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debe representar sucintamente las funciones más simples y comunes de la clase. 6.1 Las Representaciones Polinómicas Schapire y Sellie [17] dan un algoritmo de aprendizaje para polinomios multivariables escasos que pueden utilizarse como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas apropiadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados de t-sparse sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-sparse tiene como máximo t términos, donde un término es un producto de variables, por ejemplo. x1x3x4. Un polinomio sobre los números reales tiene coeficientes extraídos de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M →  se puede escribir exclusivamente como un polinomio [17]. Para tener una idea de la sucintaidad de los polinomios como lenguaje de licitación, considere las valoraciones aditivas y mono-ítem presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es el número de mercancías que contiene el paquete. En la valoración de un solo elemento, todos los paquetes tienen valor 1, excepto el valor 0 (i.e. el agente está satisfecho tan pronto como ha adquirido un único artículo). No es difícil demostrar que la valoración de un solo elemento requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Por lo tanto, los polinomios son adecuados para valoraciones que en su mayoría son aditivas, con algunas sustituibilidades y complementariedades que pueden introducirse ajustando los coeficientes. El algoritmo de aprendizaje para polinomios hace como máximo consultas de equivalencia mti +2 y como máximo (mti +1) (t2 i +3ti)/2 consultas de membresía a un agente i, donde ti es la esparcidad del polinomio que representa vi [17]. Por lo tanto, se obtiene un algoritmo que provoca valoraciones generales con un número polinomio de consultas y comunicación polinomio.6 6.2 XOR Representaciones El lenguaje de licitación XOR es estándar en la literatura de subastas combinatoria. Recordemos que una oferta XOR se caracteriza por un conjunto de paquetes B  2M y una función de valor w : B →  definida en esos paquetes, que induce la función de valoración: v(B) = max {B  B  B  B} w(B) (7) Las ofertas XOR pueden representar valoraciones que satisfacen la libre eliminación (y sólo tales valoraciones), que de nuevo es la propiedad que A  B El lenguaje de licitación XOR es ligeramente menos expresivo que los polinomios, porque los polinomios pueden representar valoraciones que no satisfacen la libre eliminación. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas de XOR pueden representar la valoración de un solo elemento con ofertas atómicas m, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario se aplica a los polinomios, estas dos lenguas son incomparables en sucintas y algo complementarias para su uso práctico. Blum et al. [5] note que las fórmulas DNF monotonas son los análogos de las pujas XOR en la literatura de teoría del aprendizaje. Una fórmula de DNF monotona es una disyunción de conjunciones en las que las variables aparecen sin negación, por ejemplo x1x2 x3 x2x4x5. Tenga en cuenta que tales fórmulas pueden ser representadas como ofertas XOR donde cada oferta atómica tiene valor 1; por lo tanto XOR ofrece generalizar fórmulas DNF monotono de Boolean a funciones de valor real. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para el DNF monotono ([3] Teorema 6 Tenga en cuenta que el Teorema 1 se aplica incluso si las valoraciones no satisfacen la eliminación libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lemma 2. Una oferta XOR que contiene ofertas t atómicas se puede aprender exactamente con consultas de equivalencia t + 1 y a lo sumo consultas de membresía tm. Prueba. El algoritmo identificará cada puja atómica en la puja XOR objetivo a su vez. Initialice la valoración manifiesta v a la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presente ‡v como consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un paquete S para el que v(S) = Crear un paquete T de la siguiente manera. Primero inicialice T = S. Para cada elemento i en T, compruebe a través de una consulta de membresía si v(T) = v(T − {i}). Si así se establece T = T − {i}. De lo contrario, deje T como está y pase al siguiente punto. Afirmamos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada ítem i en T, tenemos v(T) = v(T − {i}). Para ver esto, tenga en cuenta que en algún momento al generar T, tuvimos un ̄T tal que T  ̄T  S y v( ̄T) > v( ̄T − {i}), de modo que me mantuvo en ̄T. Tenga en cuenta que v(S) = v( ̄T) = v(T) porque el valor del paquete S se mantiene durante todo el proceso de eliminación de elementos. Ahora asume v(T) = v(T − {i}). Entonces v( ̄T) = v(T) = v(T − {i}) > v( ̄T − {i}) que contradice la libre eliminación, ya que T {i}  ̄T − {i}. Por lo tanto v(T) > v(T − {i}) para todos los ítems i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si este no fuera el caso, T tomaría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = máx itat {max T T Ahora mostramos que v(T) = ̃v(T), que implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Asumir que toda oferta atómica (R, Esta suposición se mantiene vagamente cuando se inicializa la valoración manifiesta. Usando la notación de (7), dejar ( Tenemos B  B, y Bw(B) = w(B) para B Por lo tanto,?v(S) = max {B} {B} {B} {B} {B} {B} = max {B} {B} {B} ≤ {B} {B} {B} {B} {S} w(B} = v(S) (8) Ahora asume v(T) {v(T La segunda igualdad se deriva del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad sostiene porque S es un contraejemplo de la valoración manifiesta. De la ecuación (9) y la eliminación libre, nosotros 7 El algoritmo citado también se utilizó como base para Zinkevich et al.s [19] algoritmo de excitación para Toolbox DNF. Recuerde que Toolbox DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia se puede simular con una consulta de valor en el paquete que contiene todas las mercancías. que tengan ‡v(T) < Entonces de nuevo de la ecuación (9) se deduce que v(S) < Esto contradice (8), por lo que de hecho tenemos v(T) = Por lo tanto (T, v(T)) no está actualmente en nuestra hipótesis como una oferta atómica, o tendríamos correctamente?v(T) = v(T) por la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas adicionales de equivalencia hasta que todas las ofertas atómicas hayan sido identificadas. Después de cada consulta de equivalencia, una oferta atómica se identifica con como máximo m consultas de membresía. Cada contraejemplo conduce al descubrimiento de una nueva oferta atómica. Por lo tanto, hacemos a lo sumo consultas de membresía tm y exactamente consultas de equivalencia t + 1. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR se puede obtener eficientemente de las consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al.s ([5], Teorema 2) afirmando que el DNF monotono (y por lo tanto las ofertas XOR) no se pueden obtener de manera eficiente cuando las consultas de demanda se limitan a precios lineales y anónimos sobre las mercancías. 6.3 Las representaciones lineales de umbral polinomios, las ofertas XOR y todas las lenguas basadas en el lenguaje de licitación OR (como XOR-de-OR, OR-de-XOR y OR*) no representan sucintamente la valoración mayoritaria [11]. En esta valoración, los paquetes tienen valor 1 si contienen al menos m/2 ítems, y valor 0 de lo contrario. Más generalmente, considere la familia de r-of-S de valoraciones donde los paquetes tienen valor 1 si contienen al menos r artículos de un conjunto especificado de ítems S  M, y valor 0 de otra manera. La valoración mayoritaria es un caso especial de la valoración de r-of-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar las sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede añadir valor. Dejando k = S, tales valoraciones están sucintamente representadas por funciones de umbral r-of-k. Estas funciones adoptan la forma de desigualdades lineales: xi1 +. . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se mantiene, y 0 de lo contrario. Aquí i1,. . . , ik son los elementos en S. Littlestones WINNOW 2 algoritmo puede aprender tales funciones utilizando consultas de equivalencia sólo, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de excitación que resulta de WINNOW 2 sólo utiliza consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos están implícitos cuando sólo hay dos valores posibles). Tenga en cuenta que las funciones de umbral r-of-k siempre se pueden representar sucintamente en el espacio O(m). Así se obtiene un algoritmo que puede generar tales funciones con un número polinomio de consultas y comunicación polinomio, en los parámetros n y m solos. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exactos con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de excitación de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas en el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la riqueza de algoritmos de aprendizaje disponibles al problema de la excitación de preferencias. Un enfoque de aprendizaje para la excitación también motiva un enfoque diferente para diseñar algoritmos de excitación que se descomponen cuidadosamente entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivos, muchos sustitutos, etc.), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de excitación. El algoritmo de excitación resultante hace un número polinomio de consultas, y hace comunicación polinomio si los algoritmos de aprendizaje originales son eficientes. No exigimos que las valoraciones de agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia sólo pueden ser, y sólo necesitan ser, simuladas hasta el punto en que se ha calculado una asignación óptima. Este es el problema de la excitación de preferencias. Teorema 1 implica que la excitación con consultas de valor y demanda no es más difícil que aprender con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las que la excitación es más fácil que el aprendizaje. Blum et al. [5] proporcionar tal ejemplo al considerar solamente consultas de membresía/valor (Teorema 4). En el trabajo futuro planeamos abordar la cuestión de los incentivos al convertir algoritmos de aprendizaje a algoritmos de excitación. En el entorno de aprendizaje, por lo general suponemos que los oráculos proporcionarán respuestas honestas a las preguntas; en el entorno de excitación, los agentes son generalmente egoístas y proporcionarán respuestas posiblemente deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para el aprendizaje de polinomios y ofertas XOR como algoritmos de excitación, y probar su rendimiento contra otros protocolos de subasta combinatoria establecidos [6, 15]. Una pregunta interesante aquí es: ¿qué precios Lindahl en el rango máximo a mínimo son los mejores para citar con el fin de minimizar la revelación de información? Suponemos que la revelación de información se reduce al pasar de precios máximos a precios mínimos de Lindahl, es decir, a medida que desplazamos las consultas de demanda más lejos de las consultas de equivalencia. Por último, sería útil determinar si el lenguaje de licitación de OR* [11] puede aprenderse (y, por lo tanto, obtenerse) de manera eficiente, dada la expresividad y sucinta de estas lenguas para una amplia variedad de clases de valoración. Agradecimientos Queremos agradecer a Debasis Mishra por sus útiles discusiones. Este trabajo está apoyado en parte por la subvención de NSF IIS0238147. 8. REFERENCIAS [1] A. Andersson, M. Tenhunen, y F. Ygge. Programación integral para la determinación del ganador de la subasta combinatoria. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprender conjuntos regulares de consultas y contraejemplos. Información e computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje conceptual. Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El modelo de asignación de paquetes. Diario de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Provocación de preferencias y aprendizaje de consultas. En Proc. 16a Conferencia Anual sobre Teoría del Aprendizaje Computacional (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. la 18a Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, e Y. Shoham. Domar la complejidad computacional de las subastas combinatoria: Enfoques óptimos y aproximados. En Proc. , 16a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), págs. 548 a 553, 1999. [8] B. Hudson y T. Sandholm. Uso de consultas de valor en subastas combinatoria. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría del aprendizaje computacional. MIT Press, 1994. [10] N. Littlestone. Aprender rápidamente cuando los atributos irrelevantes abundan: Un nuevo algoritmo de umbral lineal. Machine Learning, 2:285-318, 1988. [11] N. Nisan. Licitación y asignación en subastas combinatoria. En Proc. la Conferencia de la ACM sobre Comercio Electrónico, págs. 1 a 12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y el apoyo a los precios Lindahl. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de mínima revelación. En Padget et al., editor, Agent-Mediated Electronic Commerce IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. Diseño de subastas con costosas preferencias. En Temas Especiales de Anales de Matemáticas y AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17a Conferencia Nacional sobre Inteligencia Artificial (AAAI-00), págs. 74 a 81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. la 17a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariables escasos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de ACM sobre Teoría del Aprendizaje Computacional, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendido. Comun. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum, y T. Sandholm. Sobre la excitación de la preferencia polinomio-tiempo con las consultas de valor. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "error": []
        },
        "preference elicitation": {
            "translated_key": [
                " Demostramos que los algoritmos de aprendizaje pueden ser usados como base para algoritmos de ",
                ". Los algoritmos de excitación resultantes realizan un número polinomio de consultas. También damos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. En particular, se obtiene un algoritmo que provoca pujas XOR con comunicación polinómica. Categorías y Descriptores sujetos F.2.0 [Análisis de algoritmos y complejidad de problemas]: General; J.4 [Ciencias Sociales y Conductuales]: Economía; I.2.6 [Inteligencia Artificial]: Términos generales de aprendizaje Algoritmos, Economía, Teoría 1. INTRODUCCIÓN En una subasta combinatoria, los agentes pueden pujar por paquetes de bienes en lugar de por cada uno de ellos. Puesto que hay un número exponencial de paquetes (en el número de bienes), comunicar los valores sobre estos paquetes puede ser problemático. Comunicar las valoraciones de una sola vez puede ser prohibitivamente costoso si el número de bienes es sólo moderadamente grande. Además, incluso podría ser difícil para los agentes determinar sus valoraciones para paquetes únicos [14]. A esos agentes les interesa disponer de protocolos de subasta que les obliguen a pujar en el menor número posible de paquetes. Incluso si los agentes pueden calcular eficientemente sus valoraciones, podrían ser reacios a revelarlas enteramente en el curso de una subasta, porque tal información puede ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información necesaria para determinar una asignación óptima de los bienes. Ha habido un trabajo reciente explorando los vínculos entre el problema de la ",
                " en las subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje computacional [5, 19]. En teoría de aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, tales como ¿Cuál es el valor de las funciones en estas entradas? En la ",
                ", el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos de aprendizaje y ",
                " difieren algo, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Demostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia se puede convertir en un algoritmo de ",
                " con consultas de valor y demanda. El algoritmo de excitación resultante garantiza la excitación en un número polinomio de consultas de valor y demanda. Aquí queremos decir polinomio en el número de bienes, agentes, y los tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Argumentamos que las garantías de complejidad para los esquemas de excitación deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar la comunicación polinómica en el peor de los casos, que normalmente no se puede lograr en el número de productos y agentes por sí solos. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. Por supuesto, una subasta combinatoria de un solo disparo donde los agentes proporcionan todas sus funciones de valoración a la vez también tendría comunicación polinómica en el tamaño de las valoraciones de los agentes, y sólo requieren una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay ninguna carga para los agentes de formular sus valoraciones en un esquema de codificación de los subastadores que elijan. Esperamos que esta sea una consideración importante en la práctica. Además, con nuestro esquema la revelación entera sólo ocurre en el peor de los casos. 180 Por ahora, dejamos a un lado la cuestión de los incentivos al derivar algoritmos de excitación. Nos centramos en el tiempo y la complejidad de la comunicación de la ",
                " independientemente de las limitaciones de incentivo, y en la relación entre las complejidades del aprendizaje y la ",
                ". Trabajo relacionado. Zinkevich y otros [19] considerar el problema del aprendizaje de clases restringidas de funciones de valoración que se pueden representar utilizando fórmulas de lectura once y Toolbox DNF. Las fórmulas Read-once pueden representar ciertas sustitutibilidades, pero no complementariedades, mientras que lo contrario se mantiene para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten depender del tamaño de la valoración objetivo como lo hacemos (aunque las valoraciones de read-once siempre se pueden representar sucintamente de todos modos). Su trabajo sólo hace uso de consultas de valor, que son bastante limitados en el poder. Debido a que nos permitimos pedir consultas, somos capaces de derivar un esquema de excitación para las funciones de valoración general. Blum et al. [5] proporcionar resultados relacionados con las complejidades del aprendizaje de la consulta y la ",
                ". Consideran modelos con consultas de membresía y equivalencia en el aprendizaje de consultas, y consultas de valor y demanda en la ",
                ". Muestran que ciertas clases de funciones se pueden aprender eficientemente, pero no se pueden obtener eficientemente, y viceversa. En contraste, nuestro trabajo muestra que dada una versión más general (todavía bastante estándar) de la consulta de demanda que el tipo que consideran, la complejidad de la ",
                " no es mayor que la complejidad del aprendizaje. Demostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre valoraciones para implicar una solución al problema de excitación. Nisan y Segal [12] estudian la complejidad comunicativa de la ",
                ". Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos de la computación una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo se permite a los algoritmos hacer preguntas sobre valoraciones de agentes y recibir respuestas honestas, sin ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda la cuestión de la complejidad de la comunicación, y somos capaces de derivar algoritmos que proporcionan garantías de comunicación significativas a pesar de los resultados negativos de Nisan y Segals. Su trabajo motiva la necesidad de confiar en el tamaño de los agentes funciones de valoración para indicar los peores resultados. 2. LOS MODELOS 2.1 Aprendizaje de la consulta El modelo de aprendizaje de la consulta que consideramos aquí se llama aprendizaje exacto de la membresía y consultas de equivalencia, introducido por Angluin [2]. En este modelo el objetivo de los algoritmos de aprendizaje es identificar exactamente una función diana desconocida f : X → Y a través de consultas a un oráculo. La función de destino se extrae de una función de clase C que es conocida por el algoritmo. Típicamente el dominio X es algún subconjunto de {0, 1}m, y el rango Y es {0, 1} o algún subconjunto de los números reales. A medida que el algoritmo avanza, construye una hipótesis manifiesta?f que es su estimación actual de la función de destino. Después de la terminación, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface?f(x) = f(x) para todos x?X. Es importante especificar la representación que se utilizará para codificar funciones de C. Por ejemplo, considere la siguiente función de {0, 1}m a ♥: f(x) = 2 si x consiste en m 1s, y f(x) = 0 de otra manera. Esta función puede representarse simplemente como una lista de valores de 2m. O puede codificarse como el polinomio 2x1 · · · xm, que es mucho más sucinto. Así pues, la elección de la codificación puede tener un impacto significativo en las necesidades de tiempo y espacio del algoritmo de aprendizaje. Let size(f) ser el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes distintos de cero en el polinomio, por ejemplo. Por lo general, sólo nos referiremos a las clases de representación; las clases de funciones correspondientes serán implícitas. Por ejemplo, la clase de representación de fórmulas DNF monotonas implica la clase de función de funciones booleanas monotonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: la membresía y las consultas de equivalencia. En una consulta de membresía, el aprendiz presenta algunas x x x y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta f. El oráculo responde SÍ si?f = f, o devuelve un contraejemplo x de tal manera que?f(x) = f(x). Una consulta de equivalencia es apropiada si el tamaño( ̃f) ≤ tamaño(f) en el momento de presentar la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones se adaptan a partir de Kearns y Vazirani [9]: Definición 1. La clase de representación C es polinomialquery exactamente aprendeble de las consultas de membresía y equivalencia si hay un polinomial fijo p(·, ·) y un algoritmo L con acceso a la membresía y consultas de equivalencia de un oráculo tal que para cualquier función de destino f • C, L salidas después de a lo sumo p(size(f), m) consultas de una función?f • C tal que?f Del mismo modo, la clase de representación C se puede aprender exactamente de las consultas de membresía y equivalencia si el algoritmo L produce una hipótesis correcta en el tiempo p(size(f), m), para algunos polinomios fijos p(·, ·). Aquí m es la dimensión del dominio. Dado que la función de destino debe ser reconstruida, también permitimos necesariamente la dependencia polinómica del tamaño (f). 2.2 Eliminación de preferencias En una subasta combinatoria, un conjunto de bienes M se asignará entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Tal asignación se llama eficiente en la literatura de economía, pero nos referiremos a ella como óptima y reservar el término eficiente para referirse a la eficiencia computacional. Dejamos n = N y m = M. Una asignación es una partición de los objetos en paquetes (S1,. . . , Sn), de tal manera que Si â € ¬ Sj = â € para todos los i, j â € N. Let â € € sea el conjunto de posibles asignaciones. Cada agente i+N tiene una función de valoración vi : 2M → • sobre el espacio de los paquetes posibles. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no tienen que coincidir. Asumimos que todas las valoraciones consideradas están normalizadas, es decir, v() = 0, y que no hay externalidades, es decir, vi(S1,..., Sn) = vi(Si), para todos los agentes i  N, para cualquier asignación (S1,..., Sn)  (es decir, un agente se preocupa sólo por el paquete asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales.1 Nosotros 1 A menudo las valoraciones generales se hacen para satisfacer los 181 adicionales también asumen que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que los agentes utilidades pueden ser divididos en componentes monetarios y no monetarios. Si a un agente i se le asigna el paquete S al precio p, deriva utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más sucintas para ciertas clases de valoración, y ha habido mucha investigación en lenguajes de licitación concisos para diversos tipos de valoraciones [11]. Un ejemplo clásico al que nos referiremos más adelante es el lenguaje de licitación XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, que consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estas pujas, se busca el paquete S del valor más alto listado en las pujas atómicas de tal manera que S  S. Es entonces el caso que v(S) = v(S). Al igual que en el contexto de la teoría del aprendizaje, por lo general sólo nos referiremos a idiomas de oferta en lugar de clases de valoración, ya que las clases de valoración correspondientes serán implícitas. Por ejemplo, el lenguaje de licitación XOR implica la clase de valoraciones que satisfacen la disposición libre, que es la condición de que A  B ♥ v(A) ≤ v(B). Dejamos el tamaño(v1,. . . , vn) = Èn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de licitación). Para hacer una analogía con la teoría del aprendizaje computacional, suponemos que todas las clases de representación consideradas son polinomiamente interpretables [11], lo que significa que el valor de un paquete puede ser calculado en tiempo polinomio dada la representación de funciones de valoración. Más formalmente, una clase de representación (lenguaje de licitación) C es polinomialmente interpretable si existe un algoritmo que da como entrada algunos v • C y una instancia x • X calcula el valor v(x) en el tiempo q(size(v), m), para algún polinomio fijo q(·, ·).2 En las rondas intermedias de una subasta (terativa), el subastador habrá obtenido información sobre las funciones de Por lo tanto, habrá construido un conjunto de valoraciones manifiestas, denotadas . . Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha adquirido información sobre ciertos paquetes. El objetivo en el problema de la ",
                " es construir un conjunto de valoraciones manifiestas de tal manera que: arg max (S1,...,Sn) iÃ3n ̃vi(Si)  arg max (S1,...,Sn) iÃ3n vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que es óptima con respecto a las valoraciones verdaderas Tenga en cuenta que sólo se requiere una asignación óptima. condición de la libre eliminación (monotonicidad), pero no la necesitamos en este punto. 2 Esto excluye OR*, asumiendo P = NP, porque la interpretación de las ofertas de este lenguaje es NP-duro por reducción de set-embalaje ponderado, y no hay clase de representación bien estudiada en teoría de aprendizaje que es claramente análogo a OR*. 3 Esta visión de las subastas iterativas tiene por objeto paralelizar el entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente están implícitas por la historia de las ofertas. Dos consultas típicas utilizadas en la ",
                " son consultas de valor y demanda. En una consulta de valor, el subastador presenta un paquete S  M y el agente responde con su valor (exacto) para el paquete v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p • • • (2m ) sobre los paquetes junto con un paquete S. El agente responde SI si es el caso de que S • arg max S M v(S ) − p(S ) ¡ o de otro modo presenta un paquete S tal que v(S ) − p(S ) > v( Tenga en cuenta también que comunicar precios no lineales no implica necesariamente citar un precio por cada paquete posible. Puede haber formas más sucintas de comunicar este vector, como se muestra en la sección 5. Hacemos las siguientes definiciones para paralelizar la configuración de aprendizaje de la consulta y para simplificar las declaraciones de resultados posteriores: Definición 2. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si hay un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes tales que para cualquier (v1,. . . , vn) V1 ×. . . × Vn, L salidas después de como máximo p(size(v1,. . . , vn), m) consulta una asignación (S1,. . . , Sn) arg max(S1,...,Sn) È vi(Si). Del mismo modo, la clase de representación C se puede obtener eficientemente de las consultas de valor y demanda si el algoritmo L produce una asignación óptima con comunicación p(size(v1, ). . . , vn), m), para algunos polinomios fijos p(·, ·). Hay algunas diferencias clave aquí con la definición de aprendizaje de la consulta. Hemos eliminado el término exactamente ya que las funciones de valoración no necesitan ser determinadas exactamente con el fin de calcular una asignación óptima. Además, un algoritmo de excitación eficiente es la comunicación polinomio, en lugar de tiempo polinomio. Esto refleja el hecho de que la comunicación en lugar del tiempo de espera es el cuello de botella en la excitación. Cálculo de una asignación óptima de bienes incluso cuando se dan las valoraciones verdaderas es NP-duro para una amplia gama de clases de valoración. Por lo tanto, no es razonable exigir tiempo polinomio en la definición de un algoritmo eficiente de ",
                ". Nos complace centrarnos en la complejidad comunicativa de la excitación porque se cree que este problema es más significativo en la práctica que el de la determinación del ganador [11].5 4 Esto difiere ligeramente de la definición proporcionada por Blum et al. [5] Sus consultas sobre la demanda se limitan a precios lineales sobre las mercancías, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir. un precio distinto por cada paquete posible. Es por eso que el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. 5 Aunque el problema de determinación del ganador es NP-hard para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta aproximaciones usando solucionadores IP fuera de la plataforma [1]. 182 Dado que no es necesario obtener exactamente las valoraciones, es inicialmente menos claro si la dependencia polinómica del tamaño (v1, ). . . , vn) está justificado en este contexto. Intuitivamente, este parámetro está justificado porque debemos aprender valoraciones exactamente cuando se realiza la excitación, en el peor de los casos. Nos ocupamos de esto en la siguiente sección. 3. PARAALLELSBETWEEN EQUIVALENCIA Y QUERIDAS DE DEMANDA Hemos descrito los ajustes de aprendizaje de la consulta y ",
                " de una manera que resalta sus similitudes. Las consultas de valor y membresía son claras analógicas. Un poco menos obvio es el hecho de que las consultas de equivalencia y demanda también son analógicas. Para ver esto, necesitamos el concepto de precios Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios sobre sus bienes subyacentes. Son no anónimos en el sentido de que dos agentes pueden tener que hacer frente a precios diferentes para el mismo paquete de mercancías. Así los precios de Lindahl son de la forma pi(S), para todos S  M, para todos los precios de i  N. Lindahl se presentan a los agentes en consultas de la demanda. Cuando los agentes han normalizado las funciones de utilidad cuasi-lineal, Bikhchandani y Ostroy [4] muestran que siempre existen precios Lindahl tales que (S1,. . . , Sn) es una asignación óptima si y sólo si Si • arg max Si vi(Si) − pi(Si) • i N (1) (S1,. . . , Sn)  arg max (S1,...,Sn) iN pi(Si) (2) Condición (1) establece que cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos de los subastadores a los precios indicados. El escenario en el que se mantienen estas condiciones se llama equilibrio Lindahl, o a menudo un equilibrio competitivo. Decimos que los precios de Lindahl apoyan la asignación óptima. Por lo tanto, basta con anunciar los precios de apoyo de Lindahl para verificar una asignación óptima. Una vez que hemos encontrado una asignación con el apoyo de precios Lindahl, el problema de excitación se resuelve. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones estén garantizadas como integrales [4]. Las variables duales de este programa lineal están soportando los precios de Lindahl para la asignación resultante. La función objetiva del programa dual es: min pi(S) Por lo general, hay una gama de posibles precios Lindahl que apoyan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios válidos Lindahl, y nos referimos a ellos como precios máximos Lindahl. De todos los vectores posibles de precios Lindahl, precios máximos Lindahl maximizar la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È iÃ3N πi del objetivo (la suma de los agentes de utilidades) son precios mínimos Lindahl. Cualquier Lindahl precios hará para nuestros resultados, pero algunos pueden tener mejores propiedades de excitación que otros. Tenga en cuenta que una consulta de demanda con precios máximos de Lindahl es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para el trabajo futuro la cuestión de cuáles precios Lindahl elegir para minimizar ",
                ". Teniendo en cuenta ahora por qué las consultas de demanda y equivalencia son analógicas directas, primero tenga en cuenta que dado el πi en algún equilibrio Lindahl, establecer pi(S) = max{0, Estos precios dejan a cada agente indiferente en todos los paquetes con precio positivo, y satisfacen la condición (1). Así, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl típicamente serán una constante aditivo lejos de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos de consultas de equivalencia a través de consultas de demanda. Lemma 1. Supongamos que un agente responde con un paquete preferido S cuando se propone un paquete S y soporta los precios de Lindahl p(S) (soportando con respecto a la valoración manifiesta de los agentes). A continuación, o bien?v(S) = v(S) o?v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: Φv(S) − p(S) ≥ Desigualdad (6) se mantiene porque el agente de hecho prefiere S a S dados los precios, de acuerdo con su respuesta a la consulta de demanda. Si fuera el caso de que?v(S) = v(S) y Así, al menos uno de S y S es un contraejemplo de la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño(v1,. . . , vn) en problemas de excitación. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que apoyar los precios de Lindahl debe necesariamente ser revelado en el curso de cualquier protocolo de ",
                " que termina con una asignación óptima. Además, Nisan y Segal (Lemma 1, [12]) afirman que en el peor de los casos los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones dobles (como será el caso de las clases más interesantes). Puesto que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y puesto que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitiendo la dependencia del tamaño(v1,. . . , vn) en problemas de excitación es totalmente natural. 183 4. DE APRENDIZAJE A LA LICITACIÓN DE PREFERENCIA La clave para convertir un algoritmo de aprendizaje a un algoritmo de excitación es simular consultas de equivalencia con consultas de demanda y valor hasta que se encuentre una asignación óptima. Debido a nuestra construcción de precios Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en que un agente responde SÍ a una consulta de equivalencia cuando la función de destino se ha aprendido exactamente. De lo contrario, podemos obtener un contraejemplo a una consulta de equivalencia dada una respuesta de agentes a una consulta de demanda. Teorema 1. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si cada uno puede ser polinomio-consulta exactamente aprendido de consultas de membresía y equivalencia. Prueba. Considere el algoritmo de excitación en la Figura 1. Cada consulta de membresía en el paso 1 es simulada con una consulta de valor ya que estas son de hecho idénticas. Considere el paso 4. Si todos los agentes responden SÍ, la condición (1) se mantiene. Condición (2) se mantiene porque la asignación calculada es la maximización de ingresos para el subastador, independientemente de los agentes verdaderas valoraciones. Así pues, se ha encontrado una asignación óptima. De lo contrario, por lo menos uno de Si o Si es un contraejemplo a Vi, por Lemma 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones del agente se conocerán exactamente, en cuyo caso la asignación óptima y los precios Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinomio de consultas, desde A1,. . . , A son todos los algoritmos de aprendizaje polinomio-quería. Tenga en cuenta que el procedimiento de conversión resulta en un algoritmo de ",
                ", no un algoritmo de aprendizaje. Es decir, el algoritmo resultante no simplemente aprender las valoraciones exactamente, a continuación, calcular una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor, y periódicamente comprueba si se ha reunido suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio Lindahl para las valoraciones v1,. . . , vn utilizando una asignación y precios derivados de valoraciones manifiestas . . y encontrar una asignación óptima no implica que las valoraciones de los agentes se hayan aprendido exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta interrupción temprana. No obtendremos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE COMUNICACIÓN En esta sección, pasamos a la cuestión de la complejidad comunicativa de la excitación. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (tales como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos de determinar los precios de Lindahl es exponencial en el número de mercancías, m. La carga de comunicación se mide en términos del número de bits transmitidos entre agentes y subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. La conversión de algoritmos de aprendizaje eficientes a un algoritmo de excitación produce un algoritmo cuyas consultas tienen tamaños polinomios en los parámetros m y tamaño (v1, ). . . , vn). Teorema 2. Las clases de representación V1,. . . , Vn se puede obtener de forma eficiente de las consultas de valor y demanda si cada uno puede ser aprendido exactamente de las consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, basta con comunicar la función de valoración manifiesta de los agentes y el valor Nótese que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinomio, porque el tiempo de ejecución de los algoritmos también sería superpolinomio, contradiciendo la eficiencia. Por lo tanto, la comunicación de la valoración manifiesta requiere tamaño a lo sumo p(size(vi), m), para algunos polinomios p que limita superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representando el excedente πi al agente no se puede requerir espacio mayor que q(size( También debemos comunicarnos con su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es como máximo p(size(vi), m) + q(p(size(vi), m), m)+O(m). Claramente, una respuesta de agentes a una consulta de valor o demanda tiene un tamaño máximo de q(size(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, son siempre de tamaño polinomio. Un algoritmo de aprendizaje eficiente realiza un número polinomio de consultas, por lo que la comunicación total del algoritmo de excitación resultante es polinomio en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites pueden ser traducidos a límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de excitación resultante. Con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2 se determinó el tamaño de la hipótesis manifiesta. Es probable que podamos hacerlo mucho mejor que esto en la práctica. Recuerde que una consulta de equivalencia es apropiada si size( ̃f) ≤ size(f) en el momento de realizar la consulta. Si las consultas de equivalencia de algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites estrechos en los requisitos de comunicación del algoritmo de excitación resultante. El teorema 2 muestra que los algoritmos de excitación que dependen del tamaño (v1,. . . El parámetro, vn) evita los resultados negativos de Nisan y Segals [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto al tamaño de las instancias de las funciones de valoración que se enfrentan a cualquier ejecución del algoritmo. Estos algoritmos van bien si la clase de representación elegida proporciona representaciones sucintas para la más simple y común de las valoraciones, y por lo tanto el enfoque se mueve de nuevo a uno de lenguajes de licitación compactos pero expresivos. A continuación se examinan estas cuestiones. 6. APLICACIONES En esta sección, demostramos la aplicación de nuestros métodos a clases particulares de representación para valoraciones combinatorias. Hemos demostrado que el problema de ",
                " para las clases de valoración V1,. . . , Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1,. . . , Una para las valoraciones de las clases V1,. . . , Vn respectivamente. Encaje hasta que haya una señal para detenerse: 1. Corre A1,. . . , Un en paralelo sobre sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se ha detenido con los agentes valoración exacta. 2. Calcular una asignación óptima (S1,. . . , Sn ) y los correspondientes precios de Lindahl con respecto a las valoraciones manifiestas . . , їvn determinado hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de consulta de demanda. 4. Si todos ellos responden SÍ, salida la asignación y parada. De lo contrario hay algún agente i que ha respondido con algún paquete preferido Si. Realizar consultas de valor en Si y Si para encontrar un contraejemplo a ‡vi, y proporcionarlo a Ai. Figura 1: Convertir algoritmos de aprendizaje a un algoritmo de excitación. al problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de función, y porque a menudo puede ser más simple resolver cada subproblema de aprendizaje por separado que atacar el problema de ",
                " directamente. Podemos desarrollar un algoritmo de excitación que se adapta a cada valoración de agentes, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Demostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas de DNF monotono y funciones de umbral lineal se pueden convertir en algoritmos de ",
                " para valoraciones generales, valoraciones con eliminación libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en las representaciones que son polinomialmente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la traqueabilidad computacional [18]. Al interpretar los métodos enfatizamos la expresividad y sucinta de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de licitación, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debe representar sucintamente las funciones más simples y comunes de la clase. 6.1 Las Representaciones Polinómicas Schapire y Sellie [17] dan un algoritmo de aprendizaje para polinomios multivariables escasos que pueden utilizarse como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas apropiadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados de t-sparse sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-sparse tiene como máximo t términos, donde un término es un producto de variables, por ejemplo. x1x3x4. Un polinomio sobre los números reales tiene coeficientes extraídos de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M →  se puede escribir exclusivamente como un polinomio [17]. Para tener una idea de la sucintaidad de los polinomios como lenguaje de licitación, considere las valoraciones aditivas y mono-ítem presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es el número de mercancías que contiene el paquete. En la valoración de un solo elemento, todos los paquetes tienen valor 1, excepto el valor 0 (i.e. el agente está satisfecho tan pronto como ha adquirido un único artículo). No es difícil demostrar que la valoración de un solo elemento requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Por lo tanto, los polinomios son adecuados para valoraciones que en su mayoría son aditivas, con algunas sustituibilidades y complementariedades que pueden introducirse ajustando los coeficientes. El algoritmo de aprendizaje para polinomios hace como máximo consultas de equivalencia mti +2 y como máximo (mti +1) (t2 i +3ti)/2 consultas de membresía a un agente i, donde ti es la esparcidad del polinomio que representa vi [17]. Por lo tanto, se obtiene un algoritmo que provoca valoraciones generales con un número polinomio de consultas y comunicación polinomio.6 6.2 XOR Representaciones El lenguaje de licitación XOR es estándar en la literatura de subastas combinatoria. Recordemos que una oferta XOR se caracteriza por un conjunto de paquetes B  2M y una función de valor w : B →  definida en esos paquetes, que induce la función de valoración: v(B) = max {B  B  B  B} w(B) (7) Las ofertas XOR pueden representar valoraciones que satisfacen la libre eliminación (y sólo tales valoraciones), que de nuevo es la propiedad que A  B El lenguaje de licitación XOR es ligeramente menos expresivo que los polinomios, porque los polinomios pueden representar valoraciones que no satisfacen la libre eliminación. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas de XOR pueden representar la valoración de un solo elemento con ofertas atómicas m, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario se aplica a los polinomios, estas dos lenguas son incomparables en sucintas y algo complementarias para su uso práctico. Blum et al. [5] note que las fórmulas DNF monotonas son los análogos de las pujas XOR en la literatura de teoría del aprendizaje. Una fórmula de DNF monotona es una disyunción de conjunciones en las que las variables aparecen sin negación, por ejemplo x1x2 x3 x2x4x5. Tenga en cuenta que tales fórmulas pueden ser representadas como ofertas XOR donde cada oferta atómica tiene valor 1; por lo tanto XOR ofrece generalizar fórmulas DNF monotono de Boolean a funciones de valor real. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para el DNF monotono ([3] Teorema 6 Tenga en cuenta que el Teorema 1 se aplica incluso si las valoraciones no satisfacen la eliminación libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lemma 2. Una oferta XOR que contiene ofertas t atómicas se puede aprender exactamente con consultas de equivalencia t + 1 y a lo sumo consultas de membresía tm. Prueba. El algoritmo identificará cada puja atómica en la puja XOR objetivo a su vez. Initialice la valoración manifiesta v a la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presente ‡v como consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un paquete S para el que v(S) = Crear un paquete T de la siguiente manera. Primero inicialice T = S. Para cada elemento i en T, compruebe a través de una consulta de membresía si v(T) = v(T − {i}). Si así se establece T = T − {i}. De lo contrario, deje T como está y pase al siguiente punto. Afirmamos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada ítem i en T, tenemos v(T) = v(T − {i}). Para ver esto, tenga en cuenta que en algún momento al generar T, tuvimos un ̄T tal que T  ̄T  S y v( ̄T) > v( ̄T − {i}), de modo que me mantuvo en ̄T. Tenga en cuenta que v(S) = v( ̄T) = v(T) porque el valor del paquete S se mantiene durante todo el proceso de eliminación de elementos. Ahora asume v(T) = v(T − {i}). Entonces v( ̄T) = v(T) = v(T − {i}) > v( ̄T − {i}) que contradice la libre eliminación, ya que T {i}  ̄T − {i}. Por lo tanto v(T) > v(T − {i}) para todos los ítems i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si este no fuera el caso, T tomaría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = máx itat {max T T Ahora mostramos que v(T) = ̃v(T), que implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Asumir que toda oferta atómica (R, Esta suposición se mantiene vagamente cuando se inicializa la valoración manifiesta. Usando la notación de (7), dejar ( Tenemos B  B, y Bw(B) = w(B) para B Por lo tanto,?v(S) = max {B} {B} {B} {B} {B} {B} = max {B} {B} {B} ≤ {B} {B} {B} {B} {S} w(B} = v(S) (8) Ahora asume v(T) {v(T La segunda igualdad se deriva del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad sostiene porque S es un contraejemplo de la valoración manifiesta. De la ecuación (9) y la eliminación libre, nosotros 7 El algoritmo citado también se utilizó como base para Zinkevich et al.s [19] algoritmo de excitación para Toolbox DNF. Recuerde que Toolbox DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia se puede simular con una consulta de valor en el paquete que contiene todas las mercancías. que tengan ‡v(T) < Entonces de nuevo de la ecuación (9) se deduce que v(S) < Esto contradice (8), por lo que de hecho tenemos v(T) = Por lo tanto (T, v(T)) no está actualmente en nuestra hipótesis como una oferta atómica, o tendríamos correctamente?v(T) = v(T) por la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas adicionales de equivalencia hasta que todas las ofertas atómicas hayan sido identificadas. Después de cada consulta de equivalencia, una oferta atómica se identifica con como máximo m consultas de membresía. Cada contraejemplo conduce al descubrimiento de una nueva oferta atómica. Por lo tanto, hacemos a lo sumo consultas de membresía tm y exactamente consultas de equivalencia t + 1. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR se puede obtener eficientemente de las consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al.s ([5], Teorema 2) afirmando que el DNF monotono (y por lo tanto las ofertas XOR) no se pueden obtener de manera eficiente cuando las consultas de demanda se limitan a precios lineales y anónimos sobre las mercancías. 6.3 Las representaciones lineales de umbral polinomios, las ofertas XOR y todas las lenguas basadas en el lenguaje de licitación OR (como XOR-de-OR, OR-de-XOR y OR*) no representan sucintamente la valoración mayoritaria [11]. En esta valoración, los paquetes tienen valor 1 si contienen al menos m/2 ítems, y valor 0 de lo contrario. Más generalmente, considere la familia de r-of-S de valoraciones donde los paquetes tienen valor 1 si contienen al menos r artículos de un conjunto especificado de ítems S  M, y valor 0 de otra manera. La valoración mayoritaria es un caso especial de la valoración de r-of-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar las sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede añadir valor. Dejando k = S, tales valoraciones están sucintamente representadas por funciones de umbral r-of-k. Estas funciones adoptan la forma de desigualdades lineales: xi1 +. . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se mantiene, y 0 de lo contrario. Aquí i1,. . . , ik son los elementos en S. Littlestones WINNOW 2 algoritmo puede aprender tales funciones utilizando consultas de equivalencia sólo, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de excitación que resulta de WINNOW 2 sólo utiliza consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos están implícitos cuando sólo hay dos valores posibles). Tenga en cuenta que las funciones de umbral r-of-k siempre se pueden representar sucintamente en el espacio O(m). Así se obtiene un algoritmo que puede generar tales funciones con un número polinomio de consultas y comunicación polinomio, en los parámetros n y m solos. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exactos con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de ",
                " con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas en el problema de la ",
                ". Nuestro resultado nos permite aplicar la riqueza de algoritmos de aprendizaje disponibles al problema de la ",
                ". Un enfoque de aprendizaje para la excitación también motiva un enfoque diferente para diseñar algoritmos de excitación que se descomponen cuidadosamente entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivos, muchos sustitutos, etc.), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de excitación. El algoritmo de excitación resultante hace un número polinomio de consultas, y hace comunicación polinomio si los algoritmos de aprendizaje originales son eficientes. No exigimos que las valoraciones de agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia sólo pueden ser, y sólo necesitan ser, simuladas hasta el punto en que se ha calculado una asignación óptima. Este es el problema de la ",
                ". Teorema 1 implica que la excitación con consultas de valor y demanda no es más difícil que aprender con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las que la excitación es más fácil que el aprendizaje. Blum et al. [5] proporcionar tal ejemplo al considerar solamente consultas de membresía/valor (Teorema 4). En el trabajo futuro planeamos abordar la cuestión de los incentivos al convertir algoritmos de aprendizaje a algoritmos de excitación. En el entorno de aprendizaje, por lo general suponemos que los oráculos proporcionarán respuestas honestas a las preguntas; en el entorno de excitación, los agentes son generalmente egoístas y proporcionarán respuestas posiblemente deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para el aprendizaje de polinomios y ofertas XOR como algoritmos de excitación, y probar su rendimiento contra otros protocolos de subasta combinatoria establecidos [6, 15]. Una pregunta interesante aquí es: ¿qué precios Lindahl en el rango máximo a mínimo son los mejores para citar con el fin de minimizar la revelación de información? Suponemos que la revelación de información se reduce al pasar de precios máximos a precios mínimos de Lindahl, es decir, a medida que desplazamos las consultas de demanda más lejos de las consultas de equivalencia. Por último, sería útil determinar si el lenguaje de licitación de OR* [11] puede aprenderse (y, por lo tanto, obtenerse) de manera eficiente, dada la expresividad y sucinta de estas lenguas para una amplia variedad de clases de valoración. Agradecimientos Queremos agradecer a Debasis Mishra por sus útiles discusiones. Este trabajo está apoyado en parte por la subvención de NSF IIS0238147. 8. REFERENCIAS [1] A. Andersson, M. Tenhunen, y F. Ygge. Programación integral para la determinación del ganador de la subasta combinatoria. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprender conjuntos regulares de consultas y contraejemplos. Información e computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje conceptual. Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El modelo de asignación de paquetes. Diario de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Provocación de preferencias y aprendizaje de consultas. En Proc. 16a Conferencia Anual sobre Teoría del Aprendizaje Computacional (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. la 18a Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, e Y. Shoham. Domar la complejidad computacional de las subastas combinatoria: Enfoques óptimos y aproximados. En Proc. , 16a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), págs. 548 a 553, 1999. [8] B. Hudson y T. Sandholm. Uso de consultas de valor en subastas combinatoria. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría del aprendizaje computacional. MIT Press, 1994. [10] N. Littlestone. Aprender rápidamente cuando los atributos irrelevantes abundan: Un nuevo algoritmo de umbral lineal. Machine Learning, 2:285-318, 1988. [11] N. Nisan. Licitación y asignación en subastas combinatoria. En Proc. la Conferencia de la ACM sobre Comercio Electrónico, págs. 1 a 12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y el apoyo a los precios Lindahl. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de mínima revelación. En Padget et al., editor, Agent-Mediated Electronic Commerce IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. Diseño de subasta con costosa ",
                ". En Temas Especiales de Anales de Matemáticas y AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17a Conferencia Nacional sobre Inteligencia Artificial (AAAI-00), págs. 74 a 81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. la 17a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariables escasos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de ACM sobre Teoría del Aprendizaje Computacional, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendido. Comun. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum, y T. Sandholm. En tiempo polinomio "
            ],
            "translated_annotated_text": "Aplicando algoritmos de aprendizaje a la eliminación de preferencia Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de la \" Demostramos que los algoritmos de aprendizaje pueden ser usados como base para algoritmos de \"excitación de preferencia\". Los algoritmos de excitación resultantes realizan un número polinomio de consultas. También damos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. En particular, se obtiene un algoritmo que provoca pujas XOR con comunicación polinómica. Categorías y Descriptores sujetos F.2.0 [Análisis de algoritmos y complejidad de problemas]: General; J.4 [Ciencias Sociales y Conductuales]: Economía; I.2.6 [Inteligencia Artificial]: Términos generales de aprendizaje Algoritmos, Economía, Teoría 1. INTRODUCCIÓN En una subasta combinatoria, los agentes pueden pujar por paquetes de bienes en lugar de por cada uno de ellos. Puesto que hay un número exponencial de paquetes (en el número de bienes), comunicar los valores sobre estos paquetes puede ser problemático. Comunicar las valoraciones de una sola vez puede ser prohibitivamente costoso si el número de bienes es sólo moderadamente grande. Además, incluso podría ser difícil para los agentes determinar sus valoraciones para paquetes únicos [14]. A esos agentes les interesa disponer de protocolos de subasta que les obliguen a pujar en el menor número posible de paquetes. Incluso si los agentes pueden calcular eficientemente sus valoraciones, podrían ser reacios a revelarlas enteramente en el curso de una subasta, porque tal información puede ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información necesaria para determinar una asignación óptima de los bienes. Ha habido un trabajo reciente explorando los vínculos entre el problema de la \"provocación preferente\" en las subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje computacional [5, 19]. En teoría de aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, tales como ¿Cuál es el valor de las funciones en estas entradas? En la \"excitación de preferencia\", el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos de aprendizaje y \"excitación de preferencia\" difieren algo, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Demostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia se puede convertir en un algoritmo de \"excitación de preferencia\" con consultas de valor y demanda. El algoritmo de excitación resultante garantiza la excitación en un número polinomio de consultas de valor y demanda. Aquí queremos decir polinomio en el número de bienes, agentes, y los tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Argumentamos que las garantías de complejidad para los esquemas de excitación deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar la comunicación polinómica en el peor de los casos, que normalmente no se puede lograr en el número de productos y agentes por sí solos. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. Por supuesto, una subasta combinatoria de un solo disparo donde los agentes proporcionan todas sus funciones de valoración a la vez también tendría comunicación polinómica en el tamaño de las valoraciones de los agentes, y sólo requieren una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay ninguna carga para los agentes de formular sus valoraciones en un esquema de codificación de los subastadores que elijan. Esperamos que esta sea una consideración importante en la práctica. Además, con nuestro esquema la revelación entera sólo ocurre en el peor de los casos. 180 Por ahora, dejamos a un lado la cuestión de los incentivos al derivar algoritmos de excitación. Nos centramos en el tiempo y la complejidad de la comunicación de la \"excitación de preferencia\" independientemente de las limitaciones de incentivo, y en la relación entre las complejidades del aprendizaje y la \"excitación de preferencia\". Trabajo relacionado. Zinkevich y otros [19] considerar el problema del aprendizaje de clases restringidas de funciones de valoración que se pueden representar utilizando fórmulas de lectura once y Toolbox DNF. Las fórmulas Read-once pueden representar ciertas sustitutibilidades, pero no complementariedades, mientras que lo contrario se mantiene para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten depender del tamaño de la valoración objetivo como lo hacemos (aunque las valoraciones de read-once siempre se pueden representar sucintamente de todos modos). Su trabajo sólo hace uso de consultas de valor, que son bastante limitados en el poder. Debido a que nos permitimos pedir consultas, somos capaces de derivar un esquema de excitación para las funciones de valoración general. Blum et al. [5] proporcionar resultados relacionados con las complejidades del aprendizaje de la consulta y la \"excitación de preferencia\". Consideran modelos con consultas de membresía y equivalencia en el aprendizaje de consultas, y consultas de valor y demanda en la \"excitación de preferencia\". Muestran que ciertas clases de funciones se pueden aprender eficientemente, pero no se pueden obtener eficientemente, y viceversa. En contraste, nuestro trabajo muestra que dada una versión más general (todavía bastante estándar) de la consulta de demanda que el tipo que consideran, la complejidad de la \"excitación de preferencia\" no es mayor que la complejidad del aprendizaje. Demostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre valoraciones para implicar una solución al problema de excitación. Nisan y Segal [12] estudian la complejidad comunicativa de la \"excitación de preferencia\". Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos de la computación una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo se permite a los algoritmos hacer preguntas sobre valoraciones de agentes y recibir respuestas honestas, sin ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda la cuestión de la complejidad de la comunicación, y somos capaces de derivar algoritmos que proporcionan garantías de comunicación significativas a pesar de los resultados negativos de Nisan y Segals. Su trabajo motiva la necesidad de confiar en el tamaño de los agentes funciones de valoración para indicar los peores resultados. 2. LOS MODELOS 2.1 Aprendizaje de la consulta El modelo de aprendizaje de la consulta que consideramos aquí se llama aprendizaje exacto de la membresía y consultas de equivalencia, introducido por Angluin [2]. En este modelo el objetivo de los algoritmos de aprendizaje es identificar exactamente una función diana desconocida f : X → Y a través de consultas a un oráculo. La función de destino se extrae de una función de clase C que es conocida por el algoritmo. Típicamente el dominio X es algún subconjunto de {0, 1}m, y el rango Y es {0, 1} o algún subconjunto de los números reales. A medida que el algoritmo avanza, construye una hipótesis manifiesta?f que es su estimación actual de la función de destino. Después de la terminación, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface?f(x) = f(x) para todos x?X. Es importante especificar la representación que se utilizará para codificar funciones de C. Por ejemplo, considere la siguiente función de {0, 1}m a ♥: f(x) = 2 si x consiste en m 1s, y f(x) = 0 de otra manera. Esta función puede representarse simplemente como una lista de valores de 2m. O puede codificarse como el polinomio 2x1 · · · xm, que es mucho más sucinto. Así pues, la elección de la codificación puede tener un impacto significativo en las necesidades de tiempo y espacio del algoritmo de aprendizaje. Let size(f) ser el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes distintos de cero en el polinomio, por ejemplo. Por lo general, sólo nos referiremos a las clases de representación; las clases de funciones correspondientes serán implícitas. Por ejemplo, la clase de representación de fórmulas DNF monotonas implica la clase de función de funciones booleanas monotonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: la membresía y las consultas de equivalencia. En una consulta de membresía, el aprendiz presenta algunas x x x y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta f. El oráculo responde SÍ si?f = f, o devuelve un contraejemplo x de tal manera que?f(x) = f(x). Una consulta de equivalencia es apropiada si el tamaño( ̃f) ≤ tamaño(f) en el momento de presentar la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones se adaptan a partir de Kearns y Vazirani [9]: Definición 1. La clase de representación C es polinomialquery exactamente aprendeble de las consultas de membresía y equivalencia si hay un polinomial fijo p(·, ·) y un algoritmo L con acceso a la membresía y consultas de equivalencia de un oráculo tal que para cualquier función de destino f • C, L salidas después de a lo sumo p(size(f), m) consultas de una función?f • C tal que?f Del mismo modo, la clase de representación C se puede aprender exactamente de las consultas de membresía y equivalencia si el algoritmo L produce una hipótesis correcta en el tiempo p(size(f), m), para algunos polinomios fijos p(·, ·). Aquí m es la dimensión del dominio. Dado que la función de destino debe ser reconstruida, también permitimos necesariamente la dependencia polinómica del tamaño (f). 2.2 Eliminación de preferencias En una subasta combinatoria, un conjunto de bienes M se asignará entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Tal asignación se llama eficiente en la literatura de economía, pero nos referiremos a ella como óptima y reservar el término eficiente para referirse a la eficiencia computacional. Dejamos n = N y m = M. Una asignación es una partición de los objetos en paquetes (S1,. . . , Sn), de tal manera que Si â € ¬ Sj = â € para todos los i, j â € N. Let â € € sea el conjunto de posibles asignaciones. Cada agente i+N tiene una función de valoración vi : 2M → • sobre el espacio de los paquetes posibles. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no tienen que coincidir. Asumimos que todas las valoraciones consideradas están normalizadas, es decir, v() = 0, y que no hay externalidades, es decir, vi(S1,..., Sn) = vi(Si), para todos los agentes i  N, para cualquier asignación (S1,..., Sn)  (es decir, un agente se preocupa sólo por el paquete asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales.1 Nosotros 1 A menudo las valoraciones generales se hacen para satisfacer los 181 adicionales también asumen que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que los agentes utilidades pueden ser divididos en componentes monetarios y no monetarios. Si a un agente i se le asigna el paquete S al precio p, deriva utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más sucintas para ciertas clases de valoración, y ha habido mucha investigación en lenguajes de licitación concisos para diversos tipos de valoraciones [11]. Un ejemplo clásico al que nos referiremos más adelante es el lenguaje de licitación XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, que consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estas pujas, se busca el paquete S del valor más alto listado en las pujas atómicas de tal manera que S  S. Es entonces el caso que v(S) = v(S). Al igual que en el contexto de la teoría del aprendizaje, por lo general sólo nos referiremos a idiomas de oferta en lugar de clases de valoración, ya que las clases de valoración correspondientes serán implícitas. Por ejemplo, el lenguaje de licitación XOR implica la clase de valoraciones que satisfacen la disposición libre, que es la condición de que A  B ♥ v(A) ≤ v(B). Dejamos el tamaño(v1,. . . , vn) = Èn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de licitación). Para hacer una analogía con la teoría del aprendizaje computacional, suponemos que todas las clases de representación consideradas son polinomiamente interpretables [11], lo que significa que el valor de un paquete puede ser calculado en tiempo polinomio dada la representación de funciones de valoración. Más formalmente, una clase de representación (lenguaje de licitación) C es polinomialmente interpretable si existe un algoritmo que da como entrada algunos v • C y una instancia x • X calcula el valor v(x) en el tiempo q(size(v), m), para algún polinomio fijo q(·, ·).2 En las rondas intermedias de una subasta (terativa), el subastador habrá obtenido información sobre las funciones de Por lo tanto, habrá construido un conjunto de valoraciones manifiestas, denotadas . . Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha adquirido información sobre ciertos paquetes. El objetivo en el problema de la \"excitación de preferencia\" es construir un conjunto de valoraciones manifiestas de tal manera que: arg max (S1,...,Sn) iÃ3n ̃vi(Si)  arg max (S1,...,Sn) iÃ3n vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que es óptima con respecto a las valoraciones verdaderas Tenga en cuenta que sólo se requiere una asignación óptima. condición de la libre eliminación (monotonicidad), pero no la necesitamos en este punto. 2 Esto excluye OR*, asumiendo P = NP, porque la interpretación de las ofertas de este lenguaje es NP-duro por reducción de set-embalaje ponderado, y no hay clase de representación bien estudiada en teoría de aprendizaje que es claramente análogo a OR*. 3 Esta visión de las subastas iterativas tiene por objeto paralelizar el entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente están implícitas por la historia de las ofertas. Dos consultas típicas utilizadas en la \"excitación de preferencia\" son consultas de valor y demanda. En una consulta de valor, el subastador presenta un paquete S  M y el agente responde con su valor (exacto) para el paquete v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p • • • (2m ) sobre los paquetes junto con un paquete S. El agente responde SI si es el caso de que S • arg max S M v(S ) − p(S ) ¡ o de otro modo presenta un paquete S tal que v(S ) − p(S ) > v( Tenga en cuenta también que comunicar precios no lineales no implica necesariamente citar un precio por cada paquete posible. Puede haber formas más sucintas de comunicar este vector, como se muestra en la sección 5. Hacemos las siguientes definiciones para paralelizar la configuración de aprendizaje de la consulta y para simplificar las declaraciones de resultados posteriores: Definición 2. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si hay un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes tales que para cualquier (v1,. . . , vn) V1 ×. . . × Vn, L salidas después de como máximo p(size(v1,. . . , vn), m) consulta una asignación (S1,. . . , Sn) arg max(S1,...,Sn) È vi(Si). Del mismo modo, la clase de representación C se puede obtener eficientemente de las consultas de valor y demanda si el algoritmo L produce una asignación óptima con comunicación p(size(v1, ). . . , vn), m), para algunos polinomios fijos p(·, ·). Hay algunas diferencias clave aquí con la definición de aprendizaje de la consulta. Hemos eliminado el término exactamente ya que las funciones de valoración no necesitan ser determinadas exactamente con el fin de calcular una asignación óptima. Además, un algoritmo de excitación eficiente es la comunicación polinomio, en lugar de tiempo polinomio. Esto refleja el hecho de que la comunicación en lugar del tiempo de espera es el cuello de botella en la excitación. Cálculo de una asignación óptima de bienes incluso cuando se dan las valoraciones verdaderas es NP-duro para una amplia gama de clases de valoración. Por lo tanto, no es razonable exigir tiempo polinomio en la definición de un algoritmo eficiente de \"excitación de preferencia\". Nos complace centrarnos en la complejidad comunicativa de la excitación porque se cree que este problema es más significativo en la práctica que el de la determinación del ganador [11].5 4 Esto difiere ligeramente de la definición proporcionada por Blum et al. [5] Sus consultas sobre la demanda se limitan a precios lineales sobre las mercancías, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir. un precio distinto por cada paquete posible. Es por eso que el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. 5 Aunque el problema de determinación del ganador es NP-hard para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta aproximaciones usando solucionadores IP fuera de la plataforma [1]. 182 Dado que no es necesario obtener exactamente las valoraciones, es inicialmente menos claro si la dependencia polinómica del tamaño (v1, ). . . , vn) está justificado en este contexto. Intuitivamente, este parámetro está justificado porque debemos aprender valoraciones exactamente cuando se realiza la excitación, en el peor de los casos. Nos ocupamos de esto en la siguiente sección. 3. PARAALLELSBETWEEN EQUIVALENCIA Y QUERIDAS DE DEMANDA Hemos descrito los ajustes de aprendizaje de la consulta y \"excitación de preferencia\" de una manera que resalta sus similitudes. Las consultas de valor y membresía son claras analógicas. Un poco menos obvio es el hecho de que las consultas de equivalencia y demanda también son analógicas. Para ver esto, necesitamos el concepto de precios Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios sobre sus bienes subyacentes. Son no anónimos en el sentido de que dos agentes pueden tener que hacer frente a precios diferentes para el mismo paquete de mercancías. Así los precios de Lindahl son de la forma pi(S), para todos S  M, para todos los precios de i  N. Lindahl se presentan a los agentes en consultas de la demanda. Cuando los agentes han normalizado las funciones de utilidad cuasi-lineal, Bikhchandani y Ostroy [4] muestran que siempre existen precios Lindahl tales que (S1,. . . , Sn) es una asignación óptima si y sólo si Si • arg max Si vi(Si) − pi(Si) • i N (1) (S1,. . . , Sn)  arg max (S1,...,Sn) iN pi(Si) (2) Condición (1) establece que cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos de los subastadores a los precios indicados. El escenario en el que se mantienen estas condiciones se llama equilibrio Lindahl, o a menudo un equilibrio competitivo. Decimos que los precios de Lindahl apoyan la asignación óptima. Por lo tanto, basta con anunciar los precios de apoyo de Lindahl para verificar una asignación óptima. Una vez que hemos encontrado una asignación con el apoyo de precios Lindahl, el problema de excitación se resuelve. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones estén garantizadas como integrales [4]. Las variables duales de este programa lineal están soportando los precios de Lindahl para la asignación resultante. La función objetiva del programa dual es: min pi(S) Por lo general, hay una gama de posibles precios Lindahl que apoyan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios válidos Lindahl, y nos referimos a ellos como precios máximos Lindahl. De todos los vectores posibles de precios Lindahl, precios máximos Lindahl maximizar la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È iÃ3N πi del objetivo (la suma de los agentes de utilidades) son precios mínimos Lindahl. Cualquier Lindahl precios hará para nuestros resultados, pero algunos pueden tener mejores propiedades de excitación que otros. Tenga en cuenta que una consulta de demanda con precios máximos de Lindahl es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para el trabajo futuro la cuestión de cuáles precios Lindahl elegir para minimizar \"provocación de preferencia\". Teniendo en cuenta ahora por qué las consultas de demanda y equivalencia son analógicas directas, primero tenga en cuenta que dado el πi en algún equilibrio Lindahl, establecer pi(S) = max{0, Estos precios dejan a cada agente indiferente en todos los paquetes con precio positivo, y satisfacen la condición (1). Así, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl típicamente serán una constante aditivo lejos de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos de consultas de equivalencia a través de consultas de demanda. Lemma 1. Supongamos que un agente responde con un paquete preferido S cuando se propone un paquete S y soporta los precios de Lindahl p(S) (soportando con respecto a la valoración manifiesta de los agentes). A continuación, o bien?v(S) = v(S) o?v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: Φv(S) − p(S) ≥ Desigualdad (6) se mantiene porque el agente de hecho prefiere S a S dados los precios, de acuerdo con su respuesta a la consulta de demanda. Si fuera el caso de que?v(S) = v(S) y Así, al menos uno de S y S es un contraejemplo de la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño(v1,. . . , vn) en problemas de excitación. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que apoyar los precios de Lindahl debe necesariamente ser revelado en el curso de cualquier protocolo de \"excitación de preferencia\" que termina con una asignación óptima. Además, Nisan y Segal (Lemma 1, [12]) afirman que en el peor de los casos los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones dobles (como será el caso de las clases más interesantes). Puesto que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y puesto que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitiendo la dependencia del tamaño(v1,. . . , vn) en problemas de excitación es totalmente natural. 183 4. DE APRENDIZAJE A LA LICITACIÓN DE PREFERENCIA La clave para convertir un algoritmo de aprendizaje a un algoritmo de excitación es simular consultas de equivalencia con consultas de demanda y valor hasta que se encuentre una asignación óptima. Debido a nuestra construcción de precios Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en que un agente responde SÍ a una consulta de equivalencia cuando la función de destino se ha aprendido exactamente. De lo contrario, podemos obtener un contraejemplo a una consulta de equivalencia dada una respuesta de agentes a una consulta de demanda. Teorema 1. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si cada uno puede ser polinomio-consulta exactamente aprendido de consultas de membresía y equivalencia. Prueba. Considere el algoritmo de excitación en la Figura 1. Cada consulta de membresía en el paso 1 es simulada con una consulta de valor ya que estas son de hecho idénticas. Considere el paso 4. Si todos los agentes responden SÍ, la condición (1) se mantiene. Condición (2) se mantiene porque la asignación calculada es la maximización de ingresos para el subastador, independientemente de los agentes verdaderas valoraciones. Así pues, se ha encontrado una asignación óptima. De lo contrario, por lo menos uno de Si o Si es un contraejemplo a Vi, por Lemma 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones del agente se conocerán exactamente, en cuyo caso la asignación óptima y los precios Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinomio de consultas, desde A1,. . . , A son todos los algoritmos de aprendizaje polinomio-quería. Tenga en cuenta que el procedimiento de conversión resulta en un algoritmo de \"excitación de preferencia\", no un algoritmo de aprendizaje. Es decir, el algoritmo resultante no simplemente aprender las valoraciones exactamente, a continuación, calcular una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor, y periódicamente comprueba si se ha reunido suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio Lindahl para las valoraciones v1,. . . , vn utilizando una asignación y precios derivados de valoraciones manifiestas . . y encontrar una asignación óptima no implica que las valoraciones de los agentes se hayan aprendido exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta interrupción temprana. No obtendremos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE COMUNICACIÓN En esta sección, pasamos a la cuestión de la complejidad comunicativa de la excitación. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (tales como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos de determinar los precios de Lindahl es exponencial en el número de mercancías, m. La carga de comunicación se mide en términos del número de bits transmitidos entre agentes y subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. La conversión de algoritmos de aprendizaje eficientes a un algoritmo de excitación produce un algoritmo cuyas consultas tienen tamaños polinomios en los parámetros m y tamaño (v1, ). . . , vn). Teorema 2. Las clases de representación V1,. . . , Vn se puede obtener de forma eficiente de las consultas de valor y demanda si cada uno puede ser aprendido exactamente de las consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, basta con comunicar la función de valoración manifiesta de los agentes y el valor Nótese que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinomio, porque el tiempo de ejecución de los algoritmos también sería superpolinomio, contradiciendo la eficiencia. Por lo tanto, la comunicación de la valoración manifiesta requiere tamaño a lo sumo p(size(vi), m), para algunos polinomios p que limita superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representando el excedente πi al agente no se puede requerir espacio mayor que q(size( También debemos comunicarnos con su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es como máximo p(size(vi), m) + q(p(size(vi), m), m)+O(m). Claramente, una respuesta de agentes a una consulta de valor o demanda tiene un tamaño máximo de q(size(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, son siempre de tamaño polinomio. Un algoritmo de aprendizaje eficiente realiza un número polinomio de consultas, por lo que la comunicación total del algoritmo de excitación resultante es polinomio en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites pueden ser traducidos a límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de excitación resultante. Con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2 se determinó el tamaño de la hipótesis manifiesta. Es probable que podamos hacerlo mucho mejor que esto en la práctica. Recuerde que una consulta de equivalencia es apropiada si size( ̃f) ≤ size(f) en el momento de realizar la consulta. Si las consultas de equivalencia de algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites estrechos en los requisitos de comunicación del algoritmo de excitación resultante. El teorema 2 muestra que los algoritmos de excitación que dependen del tamaño (v1,. . . El parámetro, vn) evita los resultados negativos de Nisan y Segals [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto al tamaño de las instancias de las funciones de valoración que se enfrentan a cualquier ejecución del algoritmo. Estos algoritmos van bien si la clase de representación elegida proporciona representaciones sucintas para la más simple y común de las valoraciones, y por lo tanto el enfoque se mueve de nuevo a uno de lenguajes de licitación compactos pero expresivos. A continuación se examinan estas cuestiones. 6. APLICACIONES En esta sección, demostramos la aplicación de nuestros métodos a clases particulares de representación para valoraciones combinatorias. Hemos demostrado que el problema de \"provocación de preferencia\" para las clases de valoración V1,. . . , Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1,. . . , Una para las valoraciones de las clases V1,. . . , Vn respectivamente. Encaje hasta que haya una señal para detenerse: 1. Corre A1,. . . , Un en paralelo sobre sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se ha detenido con los agentes valoración exacta. 2. Calcular una asignación óptima (S1,. . . , Sn ) y los correspondientes precios de Lindahl con respecto a las valoraciones manifiestas . . , їvn determinado hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de consulta de demanda. 4. Si todos ellos responden SÍ, salida la asignación y parada. De lo contrario hay algún agente i que ha respondido con algún paquete preferido Si. Realizar consultas de valor en Si y Si para encontrar un contraejemplo a ‡vi, y proporcionarlo a Ai. Figura 1: Convertir algoritmos de aprendizaje a un algoritmo de excitación. al problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de función, y porque a menudo puede ser más simple resolver cada subproblema de aprendizaje por separado que atacar el problema de \"provocación de preferencia\" directamente. Podemos desarrollar un algoritmo de excitación que se adapta a cada valoración de agentes, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Demostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas de DNF monotono y funciones de umbral lineal se pueden convertir en algoritmos de \"excitación de preferencia\" para valoraciones generales, valoraciones con eliminación libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en las representaciones que son polinomialmente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la traqueabilidad computacional [18]. Al interpretar los métodos enfatizamos la expresividad y sucinta de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de licitación, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debe representar sucintamente las funciones más simples y comunes de la clase. 6.1 Las Representaciones Polinómicas Schapire y Sellie [17] dan un algoritmo de aprendizaje para polinomios multivariables escasos que pueden utilizarse como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas apropiadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados de t-sparse sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-sparse tiene como máximo t términos, donde un término es un producto de variables, por ejemplo. x1x3x4. Un polinomio sobre los números reales tiene coeficientes extraídos de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M →  se puede escribir exclusivamente como un polinomio [17]. Para tener una idea de la sucintaidad de los polinomios como lenguaje de licitación, considere las valoraciones aditivas y mono-ítem presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es el número de mercancías que contiene el paquete. En la valoración de un solo elemento, todos los paquetes tienen valor 1, excepto el valor 0 (i.e. el agente está satisfecho tan pronto como ha adquirido un único artículo). No es difícil demostrar que la valoración de un solo elemento requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Por lo tanto, los polinomios son adecuados para valoraciones que en su mayoría son aditivas, con algunas sustituibilidades y complementariedades que pueden introducirse ajustando los coeficientes. El algoritmo de aprendizaje para polinomios hace como máximo consultas de equivalencia mti +2 y como máximo (mti +1) (t2 i +3ti)/2 consultas de membresía a un agente i, donde ti es la esparcidad del polinomio que representa vi [17]. Por lo tanto, se obtiene un algoritmo que provoca valoraciones generales con un número polinomio de consultas y comunicación polinomio.6 6.2 XOR Representaciones El lenguaje de licitación XOR es estándar en la literatura de subastas combinatoria. Recordemos que una oferta XOR se caracteriza por un conjunto de paquetes B  2M y una función de valor w : B →  definida en esos paquetes, que induce la función de valoración: v(B) = max {B  B  B  B} w(B) (7) Las ofertas XOR pueden representar valoraciones que satisfacen la libre eliminación (y sólo tales valoraciones), que de nuevo es la propiedad que A  B El lenguaje de licitación XOR es ligeramente menos expresivo que los polinomios, porque los polinomios pueden representar valoraciones que no satisfacen la libre eliminación. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas de XOR pueden representar la valoración de un solo elemento con ofertas atómicas m, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario se aplica a los polinomios, estas dos lenguas son incomparables en sucintas y algo complementarias para su uso práctico. Blum et al. [5] note que las fórmulas DNF monotonas son los análogos de las pujas XOR en la literatura de teoría del aprendizaje. Una fórmula de DNF monotona es una disyunción de conjunciones en las que las variables aparecen sin negación, por ejemplo x1x2 x3 x2x4x5. Tenga en cuenta que tales fórmulas pueden ser representadas como ofertas XOR donde cada oferta atómica tiene valor 1; por lo tanto XOR ofrece generalizar fórmulas DNF monotono de Boolean a funciones de valor real. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para el DNF monotono ([3] Teorema 6 Tenga en cuenta que el Teorema 1 se aplica incluso si las valoraciones no satisfacen la eliminación libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lemma 2. Una oferta XOR que contiene ofertas t atómicas se puede aprender exactamente con consultas de equivalencia t + 1 y a lo sumo consultas de membresía tm. Prueba. El algoritmo identificará cada puja atómica en la puja XOR objetivo a su vez. Initialice la valoración manifiesta v a la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presente ‡v como consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un paquete S para el que v(S) = Crear un paquete T de la siguiente manera. Primero inicialice T = S. Para cada elemento i en T, compruebe a través de una consulta de membresía si v(T) = v(T − {i}). Si así se establece T = T − {i}. De lo contrario, deje T como está y pase al siguiente punto. Afirmamos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada ítem i en T, tenemos v(T) = v(T − {i}). Para ver esto, tenga en cuenta que en algún momento al generar T, tuvimos un ̄T tal que T  ̄T  S y v( ̄T) > v( ̄T − {i}), de modo que me mantuvo en ̄T. Tenga en cuenta que v(S) = v( ̄T) = v(T) porque el valor del paquete S se mantiene durante todo el proceso de eliminación de elementos. Ahora asume v(T) = v(T − {i}). Entonces v( ̄T) = v(T) = v(T − {i}) > v( ̄T − {i}) que contradice la libre eliminación, ya que T {i}  ̄T − {i}. Por lo tanto v(T) > v(T − {i}) para todos los ítems i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si este no fuera el caso, T tomaría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = máx itat {max T T Ahora mostramos que v(T) = ̃v(T), que implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Asumir que toda oferta atómica (R, Esta suposición se mantiene vagamente cuando se inicializa la valoración manifiesta. Usando la notación de (7), dejar ( Tenemos B  B, y Bw(B) = w(B) para B Por lo tanto,?v(S) = max {B} {B} {B} {B} {B} {B} = max {B} {B} {B} ≤ {B} {B} {B} {B} {S} w(B} = v(S) (8) Ahora asume v(T) {v(T La segunda igualdad se deriva del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad sostiene porque S es un contraejemplo de la valoración manifiesta. De la ecuación (9) y la eliminación libre, nosotros 7 El algoritmo citado también se utilizó como base para Zinkevich et al.s [19] algoritmo de excitación para Toolbox DNF. Recuerde que Toolbox DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia se puede simular con una consulta de valor en el paquete que contiene todas las mercancías. que tengan ‡v(T) < Entonces de nuevo de la ecuación (9) se deduce que v(S) < Esto contradice (8), por lo que de hecho tenemos v(T) = Por lo tanto (T, v(T)) no está actualmente en nuestra hipótesis como una oferta atómica, o tendríamos correctamente?v(T) = v(T) por la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas adicionales de equivalencia hasta que todas las ofertas atómicas hayan sido identificadas. Después de cada consulta de equivalencia, una oferta atómica se identifica con como máximo m consultas de membresía. Cada contraejemplo conduce al descubrimiento de una nueva oferta atómica. Por lo tanto, hacemos a lo sumo consultas de membresía tm y exactamente consultas de equivalencia t + 1. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR se puede obtener eficientemente de las consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al.s ([5], Teorema 2) afirmando que el DNF monotono (y por lo tanto las ofertas XOR) no se pueden obtener de manera eficiente cuando las consultas de demanda se limitan a precios lineales y anónimos sobre las mercancías. 6.3 Las representaciones lineales de umbral polinomios, las ofertas XOR y todas las lenguas basadas en el lenguaje de licitación OR (como XOR-de-OR, OR-de-XOR y OR*) no representan sucintamente la valoración mayoritaria [11]. En esta valoración, los paquetes tienen valor 1 si contienen al menos m/2 ítems, y valor 0 de lo contrario. Más generalmente, considere la familia de r-of-S de valoraciones donde los paquetes tienen valor 1 si contienen al menos r artículos de un conjunto especificado de ítems S  M, y valor 0 de otra manera. La valoración mayoritaria es un caso especial de la valoración de r-of-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar las sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede añadir valor. Dejando k = S, tales valoraciones están sucintamente representadas por funciones de umbral r-of-k. Estas funciones adoptan la forma de desigualdades lineales: xi1 +. . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se mantiene, y 0 de lo contrario. Aquí i1,. . . , ik son los elementos en S. Littlestones WINNOW 2 algoritmo puede aprender tales funciones utilizando consultas de equivalencia sólo, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de excitación que resulta de WINNOW 2 sólo utiliza consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos están implícitos cuando sólo hay dos valores posibles). Tenga en cuenta que las funciones de umbral r-of-k siempre se pueden representar sucintamente en el espacio O(m). Así se obtiene un algoritmo que puede generar tales funciones con un número polinomio de consultas y comunicación polinomio, en los parámetros n y m solos. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exactos con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de \"excitación de preferencia\" con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas en el problema de la \"excitación de preferencia\". Nuestro resultado nos permite aplicar la riqueza de algoritmos de aprendizaje disponibles al problema de la \"excitación de preferencia\". Un enfoque de aprendizaje para la excitación también motiva un enfoque diferente para diseñar algoritmos de excitación que se descomponen cuidadosamente entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivos, muchos sustitutos, etc.), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de excitación. El algoritmo de excitación resultante hace un número polinomio de consultas, y hace comunicación polinomio si los algoritmos de aprendizaje originales son eficientes. No exigimos que las valoraciones de agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia sólo pueden ser, y sólo necesitan ser, simuladas hasta el punto en que se ha calculado una asignación óptima. Este es el problema de la \"provocación de preferencia\". Teorema 1 implica que la excitación con consultas de valor y demanda no es más difícil que aprender con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las que la excitación es más fácil que el aprendizaje. Blum et al. [5] proporcionar tal ejemplo al considerar solamente consultas de membresía/valor (Teorema 4). En el trabajo futuro planeamos abordar la cuestión de los incentivos al convertir algoritmos de aprendizaje a algoritmos de excitación. En el entorno de aprendizaje, por lo general suponemos que los oráculos proporcionarán respuestas honestas a las preguntas; en el entorno de excitación, los agentes son generalmente egoístas y proporcionarán respuestas posiblemente deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para el aprendizaje de polinomios y ofertas XOR como algoritmos de excitación, y probar su rendimiento contra otros protocolos de subasta combinatoria establecidos [6, 15]. Una pregunta interesante aquí es: ¿qué precios Lindahl en el rango máximo a mínimo son los mejores para citar con el fin de minimizar la revelación de información? Suponemos que la revelación de información se reduce al pasar de precios máximos a precios mínimos de Lindahl, es decir, a medida que desplazamos las consultas de demanda más lejos de las consultas de equivalencia. Por último, sería útil determinar si el lenguaje de licitación de OR* [11] puede aprenderse (y, por lo tanto, obtenerse) de manera eficiente, dada la expresividad y sucinta de estas lenguas para una amplia variedad de clases de valoración. Agradecimientos Queremos agradecer a Debasis Mishra por sus útiles discusiones. Este trabajo está apoyado en parte por la subvención de NSF IIS0238147. 8. REFERENCIAS [1] A. Andersson, M. Tenhunen, y F. Ygge. Programación integral para la determinación del ganador de la subasta combinatoria. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprender conjuntos regulares de consultas y contraejemplos. Información e computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje conceptual. Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El modelo de asignación de paquetes. Diario de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Provocación de preferencias y aprendizaje de consultas. En Proc. 16a Conferencia Anual sobre Teoría del Aprendizaje Computacional (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. la 18a Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, e Y. Shoham. Domar la complejidad computacional de las subastas combinatoria: Enfoques óptimos y aproximados. En Proc. , 16a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), págs. 548 a 553, 1999. [8] B. Hudson y T. Sandholm. Uso de consultas de valor en subastas combinatoria. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría del aprendizaje computacional. MIT Press, 1994. [10] N. Littlestone. Aprender rápidamente cuando los atributos irrelevantes abundan: Un nuevo algoritmo de umbral lineal. Machine Learning, 2:285-318, 1988. [11] N. Nisan. Licitación y asignación en subastas combinatoria. En Proc. la Conferencia de la ACM sobre Comercio Electrónico, págs. 1 a 12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y el apoyo a los precios Lindahl. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de mínima revelación. En Padget et al., editor, Agent-Mediated Electronic Commerce IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. Diseño de subasta con costosa \"excitación de preferencia\". En Temas Especiales de Anales de Matemáticas y AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17a Conferencia Nacional sobre Inteligencia Artificial (AAAI-00), págs. 74 a 81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. la 17a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariables escasos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de ACM sobre Teoría del Aprendizaje Computacional, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendido. Comun. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum, y T. Sandholm. En tiempo polinomio \"excitación de preferencia\" con consultas de valor. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "error": [
                " Demostramos que los algoritmos de aprendizaje pueden ser usados como base para algoritmos de ",
                ". Los algoritmos de excitación resultantes realizan un número polinomio de consultas. También damos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. En particular, se obtiene un algoritmo que provoca pujas XOR con comunicación polinómica. Categorías y Descriptores sujetos F.2.0 [Análisis de algoritmos y complejidad de problemas]: General; J.4 [Ciencias Sociales y Conductuales]: Economía; I.2.6 [Inteligencia Artificial]: Términos generales de aprendizaje Algoritmos, Economía, Teoría 1. INTRODUCCIÓN En una subasta combinatoria, los agentes pueden pujar por paquetes de bienes en lugar de por cada uno de ellos. Puesto que hay un número exponencial de paquetes (en el número de bienes), comunicar los valores sobre estos paquetes puede ser problemático. Comunicar las valoraciones de una sola vez puede ser prohibitivamente costoso si el número de bienes es sólo moderadamente grande. Además, incluso podría ser difícil para los agentes determinar sus valoraciones para paquetes únicos [14]. A esos agentes les interesa disponer de protocolos de subasta que les obliguen a pujar en el menor número posible de paquetes. Incluso si los agentes pueden calcular eficientemente sus valoraciones, podrían ser reacios a revelarlas enteramente en el curso de una subasta, porque tal información puede ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información necesaria para determinar una asignación óptima de los bienes. Ha habido un trabajo reciente explorando los vínculos entre el problema de la ",
                " en las subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje computacional [5, 19]. En teoría de aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, tales como ¿Cuál es el valor de las funciones en estas entradas? En la ",
                ", el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos de aprendizaje y ",
                " difieren algo, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Demostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia se puede convertir en un algoritmo de ",
                " con consultas de valor y demanda. El algoritmo de excitación resultante garantiza la excitación en un número polinomio de consultas de valor y demanda. Aquí queremos decir polinomio en el número de bienes, agentes, y los tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Argumentamos que las garantías de complejidad para los esquemas de excitación deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar la comunicación polinómica en el peor de los casos, que normalmente no se puede lograr en el número de productos y agentes por sí solos. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. Por supuesto, una subasta combinatoria de un solo disparo donde los agentes proporcionan todas sus funciones de valoración a la vez también tendría comunicación polinómica en el tamaño de las valoraciones de los agentes, y sólo requieren una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay ninguna carga para los agentes de formular sus valoraciones en un esquema de codificación de los subastadores que elijan. Esperamos que esta sea una consideración importante en la práctica. Además, con nuestro esquema la revelación entera sólo ocurre en el peor de los casos. 180 Por ahora, dejamos a un lado la cuestión de los incentivos al derivar algoritmos de excitación. Nos centramos en el tiempo y la complejidad de la comunicación de la ",
                " independientemente de las limitaciones de incentivo, y en la relación entre las complejidades del aprendizaje y la ",
                ". Trabajo relacionado. Zinkevich y otros [19] considerar el problema del aprendizaje de clases restringidas de funciones de valoración que se pueden representar utilizando fórmulas de lectura once y Toolbox DNF. Las fórmulas Read-once pueden representar ciertas sustitutibilidades, pero no complementariedades, mientras que lo contrario se mantiene para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten depender del tamaño de la valoración objetivo como lo hacemos (aunque las valoraciones de read-once siempre se pueden representar sucintamente de todos modos). Su trabajo sólo hace uso de consultas de valor, que son bastante limitados en el poder. Debido a que nos permitimos pedir consultas, somos capaces de derivar un esquema de excitación para las funciones de valoración general. Blum et al. [5] proporcionar resultados relacionados con las complejidades del aprendizaje de la consulta y la ",
                ". Consideran modelos con consultas de membresía y equivalencia en el aprendizaje de consultas, y consultas de valor y demanda en la ",
                ". Muestran que ciertas clases de funciones se pueden aprender eficientemente, pero no se pueden obtener eficientemente, y viceversa. En contraste, nuestro trabajo muestra que dada una versión más general (todavía bastante estándar) de la consulta de demanda que el tipo que consideran, la complejidad de la ",
                " no es mayor que la complejidad del aprendizaje. Demostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre valoraciones para implicar una solución al problema de excitación. Nisan y Segal [12] estudian la complejidad comunicativa de la ",
                ". Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos de la computación una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo se permite a los algoritmos hacer preguntas sobre valoraciones de agentes y recibir respuestas honestas, sin ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda la cuestión de la complejidad de la comunicación, y somos capaces de derivar algoritmos que proporcionan garantías de comunicación significativas a pesar de los resultados negativos de Nisan y Segals. Su trabajo motiva la necesidad de confiar en el tamaño de los agentes funciones de valoración para indicar los peores resultados. 2. LOS MODELOS 2.1 Aprendizaje de la consulta El modelo de aprendizaje de la consulta que consideramos aquí se llama aprendizaje exacto de la membresía y consultas de equivalencia, introducido por Angluin [2]. En este modelo el objetivo de los algoritmos de aprendizaje es identificar exactamente una función diana desconocida f : X → Y a través de consultas a un oráculo. La función de destino se extrae de una función de clase C que es conocida por el algoritmo. Típicamente el dominio X es algún subconjunto de {0, 1}m, y el rango Y es {0, 1} o algún subconjunto de los números reales. A medida que el algoritmo avanza, construye una hipótesis manifiesta?f que es su estimación actual de la función de destino. Después de la terminación, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface?f(x) = f(x) para todos x?X. Es importante especificar la representación que se utilizará para codificar funciones de C. Por ejemplo, considere la siguiente función de {0, 1}m a ♥: f(x) = 2 si x consiste en m 1s, y f(x) = 0 de otra manera. Esta función puede representarse simplemente como una lista de valores de 2m. O puede codificarse como el polinomio 2x1 · · · xm, que es mucho más sucinto. Así pues, la elección de la codificación puede tener un impacto significativo en las necesidades de tiempo y espacio del algoritmo de aprendizaje. Let size(f) ser el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes distintos de cero en el polinomio, por ejemplo. Por lo general, sólo nos referiremos a las clases de representación; las clases de funciones correspondientes serán implícitas. Por ejemplo, la clase de representación de fórmulas DNF monotonas implica la clase de función de funciones booleanas monotonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: la membresía y las consultas de equivalencia. En una consulta de membresía, el aprendiz presenta algunas x x x y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta f. El oráculo responde SÍ si?f = f, o devuelve un contraejemplo x de tal manera que?f(x) = f(x). Una consulta de equivalencia es apropiada si el tamaño( ̃f) ≤ tamaño(f) en el momento de presentar la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones se adaptan a partir de Kearns y Vazirani [9]: Definición 1. La clase de representación C es polinomialquery exactamente aprendeble de las consultas de membresía y equivalencia si hay un polinomial fijo p(·, ·) y un algoritmo L con acceso a la membresía y consultas de equivalencia de un oráculo tal que para cualquier función de destino f • C, L salidas después de a lo sumo p(size(f), m) consultas de una función?f • C tal que?f Del mismo modo, la clase de representación C se puede aprender exactamente de las consultas de membresía y equivalencia si el algoritmo L produce una hipótesis correcta en el tiempo p(size(f), m), para algunos polinomios fijos p(·, ·). Aquí m es la dimensión del dominio. Dado que la función de destino debe ser reconstruida, también permitimos necesariamente la dependencia polinómica del tamaño (f). 2.2 Eliminación de preferencias En una subasta combinatoria, un conjunto de bienes M se asignará entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Tal asignación se llama eficiente en la literatura de economía, pero nos referiremos a ella como óptima y reservar el término eficiente para referirse a la eficiencia computacional. Dejamos n = N y m = M. Una asignación es una partición de los objetos en paquetes (S1,. . . , Sn), de tal manera que Si â € ¬ Sj = â € para todos los i, j â € N. Let â € € sea el conjunto de posibles asignaciones. Cada agente i+N tiene una función de valoración vi : 2M → • sobre el espacio de los paquetes posibles. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no tienen que coincidir. Asumimos que todas las valoraciones consideradas están normalizadas, es decir, v() = 0, y que no hay externalidades, es decir, vi(S1,..., Sn) = vi(Si), para todos los agentes i  N, para cualquier asignación (S1,..., Sn)  (es decir, un agente se preocupa sólo por el paquete asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales.1 Nosotros 1 A menudo las valoraciones generales se hacen para satisfacer los 181 adicionales también asumen que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que los agentes utilidades pueden ser divididos en componentes monetarios y no monetarios. Si a un agente i se le asigna el paquete S al precio p, deriva utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más sucintas para ciertas clases de valoración, y ha habido mucha investigación en lenguajes de licitación concisos para diversos tipos de valoraciones [11]. Un ejemplo clásico al que nos referiremos más adelante es el lenguaje de licitación XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, que consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estas pujas, se busca el paquete S del valor más alto listado en las pujas atómicas de tal manera que S  S. Es entonces el caso que v(S) = v(S). Al igual que en el contexto de la teoría del aprendizaje, por lo general sólo nos referiremos a idiomas de oferta en lugar de clases de valoración, ya que las clases de valoración correspondientes serán implícitas. Por ejemplo, el lenguaje de licitación XOR implica la clase de valoraciones que satisfacen la disposición libre, que es la condición de que A  B ♥ v(A) ≤ v(B). Dejamos el tamaño(v1,. . . , vn) = Èn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de licitación). Para hacer una analogía con la teoría del aprendizaje computacional, suponemos que todas las clases de representación consideradas son polinomiamente interpretables [11], lo que significa que el valor de un paquete puede ser calculado en tiempo polinomio dada la representación de funciones de valoración. Más formalmente, una clase de representación (lenguaje de licitación) C es polinomialmente interpretable si existe un algoritmo que da como entrada algunos v • C y una instancia x • X calcula el valor v(x) en el tiempo q(size(v), m), para algún polinomio fijo q(·, ·).2 En las rondas intermedias de una subasta (terativa), el subastador habrá obtenido información sobre las funciones de Por lo tanto, habrá construido un conjunto de valoraciones manifiestas, denotadas . . Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha adquirido información sobre ciertos paquetes. El objetivo en el problema de la ",
                " es construir un conjunto de valoraciones manifiestas de tal manera que: arg max (S1,...,Sn) iÃ3n ̃vi(Si)  arg max (S1,...,Sn) iÃ3n vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que es óptima con respecto a las valoraciones verdaderas Tenga en cuenta que sólo se requiere una asignación óptima. condición de la libre eliminación (monotonicidad), pero no la necesitamos en este punto. 2 Esto excluye OR*, asumiendo P = NP, porque la interpretación de las ofertas de este lenguaje es NP-duro por reducción de set-embalaje ponderado, y no hay clase de representación bien estudiada en teoría de aprendizaje que es claramente análogo a OR*. 3 Esta visión de las subastas iterativas tiene por objeto paralelizar el entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente están implícitas por la historia de las ofertas. Dos consultas típicas utilizadas en la ",
                " son consultas de valor y demanda. En una consulta de valor, el subastador presenta un paquete S  M y el agente responde con su valor (exacto) para el paquete v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p • • • (2m ) sobre los paquetes junto con un paquete S. El agente responde SI si es el caso de que S • arg max S M v(S ) − p(S ) ¡ o de otro modo presenta un paquete S tal que v(S ) − p(S ) > v( Tenga en cuenta también que comunicar precios no lineales no implica necesariamente citar un precio por cada paquete posible. Puede haber formas más sucintas de comunicar este vector, como se muestra en la sección 5. Hacemos las siguientes definiciones para paralelizar la configuración de aprendizaje de la consulta y para simplificar las declaraciones de resultados posteriores: Definición 2. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si hay un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes tales que para cualquier (v1,. . . , vn) V1 ×. . . × Vn, L salidas después de como máximo p(size(v1,. . . , vn), m) consulta una asignación (S1,. . . , Sn) arg max(S1,...,Sn) È vi(Si). Del mismo modo, la clase de representación C se puede obtener eficientemente de las consultas de valor y demanda si el algoritmo L produce una asignación óptima con comunicación p(size(v1, ). . . , vn), m), para algunos polinomios fijos p(·, ·). Hay algunas diferencias clave aquí con la definición de aprendizaje de la consulta. Hemos eliminado el término exactamente ya que las funciones de valoración no necesitan ser determinadas exactamente con el fin de calcular una asignación óptima. Además, un algoritmo de excitación eficiente es la comunicación polinomio, en lugar de tiempo polinomio. Esto refleja el hecho de que la comunicación en lugar del tiempo de espera es el cuello de botella en la excitación. Cálculo de una asignación óptima de bienes incluso cuando se dan las valoraciones verdaderas es NP-duro para una amplia gama de clases de valoración. Por lo tanto, no es razonable exigir tiempo polinomio en la definición de un algoritmo eficiente de ",
                ". Nos complace centrarnos en la complejidad comunicativa de la excitación porque se cree que este problema es más significativo en la práctica que el de la determinación del ganador [11].5 4 Esto difiere ligeramente de la definición proporcionada por Blum et al. [5] Sus consultas sobre la demanda se limitan a precios lineales sobre las mercancías, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir. un precio distinto por cada paquete posible. Es por eso que el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. 5 Aunque el problema de determinación del ganador es NP-hard para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta aproximaciones usando solucionadores IP fuera de la plataforma [1]. 182 Dado que no es necesario obtener exactamente las valoraciones, es inicialmente menos claro si la dependencia polinómica del tamaño (v1, ). . . , vn) está justificado en este contexto. Intuitivamente, este parámetro está justificado porque debemos aprender valoraciones exactamente cuando se realiza la excitación, en el peor de los casos. Nos ocupamos de esto en la siguiente sección. 3. PARAALLELSBETWEEN EQUIVALENCIA Y QUERIDAS DE DEMANDA Hemos descrito los ajustes de aprendizaje de la consulta y ",
                " de una manera que resalta sus similitudes. Las consultas de valor y membresía son claras analógicas. Un poco menos obvio es el hecho de que las consultas de equivalencia y demanda también son analógicas. Para ver esto, necesitamos el concepto de precios Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios sobre sus bienes subyacentes. Son no anónimos en el sentido de que dos agentes pueden tener que hacer frente a precios diferentes para el mismo paquete de mercancías. Así los precios de Lindahl son de la forma pi(S), para todos S  M, para todos los precios de i  N. Lindahl se presentan a los agentes en consultas de la demanda. Cuando los agentes han normalizado las funciones de utilidad cuasi-lineal, Bikhchandani y Ostroy [4] muestran que siempre existen precios Lindahl tales que (S1,. . . , Sn) es una asignación óptima si y sólo si Si • arg max Si vi(Si) − pi(Si) • i N (1) (S1,. . . , Sn)  arg max (S1,...,Sn) iN pi(Si) (2) Condición (1) establece que cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos de los subastadores a los precios indicados. El escenario en el que se mantienen estas condiciones se llama equilibrio Lindahl, o a menudo un equilibrio competitivo. Decimos que los precios de Lindahl apoyan la asignación óptima. Por lo tanto, basta con anunciar los precios de apoyo de Lindahl para verificar una asignación óptima. Una vez que hemos encontrado una asignación con el apoyo de precios Lindahl, el problema de excitación se resuelve. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones estén garantizadas como integrales [4]. Las variables duales de este programa lineal están soportando los precios de Lindahl para la asignación resultante. La función objetiva del programa dual es: min pi(S) Por lo general, hay una gama de posibles precios Lindahl que apoyan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios válidos Lindahl, y nos referimos a ellos como precios máximos Lindahl. De todos los vectores posibles de precios Lindahl, precios máximos Lindahl maximizar la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È iÃ3N πi del objetivo (la suma de los agentes de utilidades) son precios mínimos Lindahl. Cualquier Lindahl precios hará para nuestros resultados, pero algunos pueden tener mejores propiedades de excitación que otros. Tenga en cuenta que una consulta de demanda con precios máximos de Lindahl es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para el trabajo futuro la cuestión de cuáles precios Lindahl elegir para minimizar ",
                ". Teniendo en cuenta ahora por qué las consultas de demanda y equivalencia son analógicas directas, primero tenga en cuenta que dado el πi en algún equilibrio Lindahl, establecer pi(S) = max{0, Estos precios dejan a cada agente indiferente en todos los paquetes con precio positivo, y satisfacen la condición (1). Así, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl típicamente serán una constante aditivo lejos de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos de consultas de equivalencia a través de consultas de demanda. Lemma 1. Supongamos que un agente responde con un paquete preferido S cuando se propone un paquete S y soporta los precios de Lindahl p(S) (soportando con respecto a la valoración manifiesta de los agentes). A continuación, o bien?v(S) = v(S) o?v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: Φv(S) − p(S) ≥ Desigualdad (6) se mantiene porque el agente de hecho prefiere S a S dados los precios, de acuerdo con su respuesta a la consulta de demanda. Si fuera el caso de que?v(S) = v(S) y Así, al menos uno de S y S es un contraejemplo de la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño(v1,. . . , vn) en problemas de excitación. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que apoyar los precios de Lindahl debe necesariamente ser revelado en el curso de cualquier protocolo de ",
                " que termina con una asignación óptima. Además, Nisan y Segal (Lemma 1, [12]) afirman que en el peor de los casos los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones dobles (como será el caso de las clases más interesantes). Puesto que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y puesto que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitiendo la dependencia del tamaño(v1,. . . , vn) en problemas de excitación es totalmente natural. 183 4. DE APRENDIZAJE A LA LICITACIÓN DE PREFERENCIA La clave para convertir un algoritmo de aprendizaje a un algoritmo de excitación es simular consultas de equivalencia con consultas de demanda y valor hasta que se encuentre una asignación óptima. Debido a nuestra construcción de precios Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en que un agente responde SÍ a una consulta de equivalencia cuando la función de destino se ha aprendido exactamente. De lo contrario, podemos obtener un contraejemplo a una consulta de equivalencia dada una respuesta de agentes a una consulta de demanda. Teorema 1. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si cada uno puede ser polinomio-consulta exactamente aprendido de consultas de membresía y equivalencia. Prueba. Considere el algoritmo de excitación en la Figura 1. Cada consulta de membresía en el paso 1 es simulada con una consulta de valor ya que estas son de hecho idénticas. Considere el paso 4. Si todos los agentes responden SÍ, la condición (1) se mantiene. Condición (2) se mantiene porque la asignación calculada es la maximización de ingresos para el subastador, independientemente de los agentes verdaderas valoraciones. Así pues, se ha encontrado una asignación óptima. De lo contrario, por lo menos uno de Si o Si es un contraejemplo a Vi, por Lemma 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones del agente se conocerán exactamente, en cuyo caso la asignación óptima y los precios Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinomio de consultas, desde A1,. . . , A son todos los algoritmos de aprendizaje polinomio-quería. Tenga en cuenta que el procedimiento de conversión resulta en un algoritmo de ",
                ", no un algoritmo de aprendizaje. Es decir, el algoritmo resultante no simplemente aprender las valoraciones exactamente, a continuación, calcular una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor, y periódicamente comprueba si se ha reunido suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio Lindahl para las valoraciones v1,. . . , vn utilizando una asignación y precios derivados de valoraciones manifiestas . . y encontrar una asignación óptima no implica que las valoraciones de los agentes se hayan aprendido exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta interrupción temprana. No obtendremos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE COMUNICACIÓN En esta sección, pasamos a la cuestión de la complejidad comunicativa de la excitación. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (tales como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos de determinar los precios de Lindahl es exponencial en el número de mercancías, m. La carga de comunicación se mide en términos del número de bits transmitidos entre agentes y subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. La conversión de algoritmos de aprendizaje eficientes a un algoritmo de excitación produce un algoritmo cuyas consultas tienen tamaños polinomios en los parámetros m y tamaño (v1, ). . . , vn). Teorema 2. Las clases de representación V1,. . . , Vn se puede obtener de forma eficiente de las consultas de valor y demanda si cada uno puede ser aprendido exactamente de las consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, basta con comunicar la función de valoración manifiesta de los agentes y el valor Nótese que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinomio, porque el tiempo de ejecución de los algoritmos también sería superpolinomio, contradiciendo la eficiencia. Por lo tanto, la comunicación de la valoración manifiesta requiere tamaño a lo sumo p(size(vi), m), para algunos polinomios p que limita superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representando el excedente πi al agente no se puede requerir espacio mayor que q(size( También debemos comunicarnos con su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es como máximo p(size(vi), m) + q(p(size(vi), m), m)+O(m). Claramente, una respuesta de agentes a una consulta de valor o demanda tiene un tamaño máximo de q(size(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, son siempre de tamaño polinomio. Un algoritmo de aprendizaje eficiente realiza un número polinomio de consultas, por lo que la comunicación total del algoritmo de excitación resultante es polinomio en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites pueden ser traducidos a límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de excitación resultante. Con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2 se determinó el tamaño de la hipótesis manifiesta. Es probable que podamos hacerlo mucho mejor que esto en la práctica. Recuerde que una consulta de equivalencia es apropiada si size( ̃f) ≤ size(f) en el momento de realizar la consulta. Si las consultas de equivalencia de algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites estrechos en los requisitos de comunicación del algoritmo de excitación resultante. El teorema 2 muestra que los algoritmos de excitación que dependen del tamaño (v1,. . . El parámetro, vn) evita los resultados negativos de Nisan y Segals [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto al tamaño de las instancias de las funciones de valoración que se enfrentan a cualquier ejecución del algoritmo. Estos algoritmos van bien si la clase de representación elegida proporciona representaciones sucintas para la más simple y común de las valoraciones, y por lo tanto el enfoque se mueve de nuevo a uno de lenguajes de licitación compactos pero expresivos. A continuación se examinan estas cuestiones. 6. APLICACIONES En esta sección, demostramos la aplicación de nuestros métodos a clases particulares de representación para valoraciones combinatorias. Hemos demostrado que el problema de ",
                " para las clases de valoración V1,. . . , Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1,. . . , Una para las valoraciones de las clases V1,. . . , Vn respectivamente. Encaje hasta que haya una señal para detenerse: 1. Corre A1,. . . , Un en paralelo sobre sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se ha detenido con los agentes valoración exacta. 2. Calcular una asignación óptima (S1,. . . , Sn ) y los correspondientes precios de Lindahl con respecto a las valoraciones manifiestas . . , їvn determinado hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de consulta de demanda. 4. Si todos ellos responden SÍ, salida la asignación y parada. De lo contrario hay algún agente i que ha respondido con algún paquete preferido Si. Realizar consultas de valor en Si y Si para encontrar un contraejemplo a ‡vi, y proporcionarlo a Ai. Figura 1: Convertir algoritmos de aprendizaje a un algoritmo de excitación. al problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de función, y porque a menudo puede ser más simple resolver cada subproblema de aprendizaje por separado que atacar el problema de ",
                " directamente. Podemos desarrollar un algoritmo de excitación que se adapta a cada valoración de agentes, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Demostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas de DNF monotono y funciones de umbral lineal se pueden convertir en algoritmos de ",
                " para valoraciones generales, valoraciones con eliminación libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en las representaciones que son polinomialmente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la traqueabilidad computacional [18]. Al interpretar los métodos enfatizamos la expresividad y sucinta de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de licitación, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debe representar sucintamente las funciones más simples y comunes de la clase. 6.1 Las Representaciones Polinómicas Schapire y Sellie [17] dan un algoritmo de aprendizaje para polinomios multivariables escasos que pueden utilizarse como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas apropiadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados de t-sparse sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-sparse tiene como máximo t términos, donde un término es un producto de variables, por ejemplo. x1x3x4. Un polinomio sobre los números reales tiene coeficientes extraídos de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M →  se puede escribir exclusivamente como un polinomio [17]. Para tener una idea de la sucintaidad de los polinomios como lenguaje de licitación, considere las valoraciones aditivas y mono-ítem presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es el número de mercancías que contiene el paquete. En la valoración de un solo elemento, todos los paquetes tienen valor 1, excepto el valor 0 (i.e. el agente está satisfecho tan pronto como ha adquirido un único artículo). No es difícil demostrar que la valoración de un solo elemento requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Por lo tanto, los polinomios son adecuados para valoraciones que en su mayoría son aditivas, con algunas sustituibilidades y complementariedades que pueden introducirse ajustando los coeficientes. El algoritmo de aprendizaje para polinomios hace como máximo consultas de equivalencia mti +2 y como máximo (mti +1) (t2 i +3ti)/2 consultas de membresía a un agente i, donde ti es la esparcidad del polinomio que representa vi [17]. Por lo tanto, se obtiene un algoritmo que provoca valoraciones generales con un número polinomio de consultas y comunicación polinomio.6 6.2 XOR Representaciones El lenguaje de licitación XOR es estándar en la literatura de subastas combinatoria. Recordemos que una oferta XOR se caracteriza por un conjunto de paquetes B  2M y una función de valor w : B →  definida en esos paquetes, que induce la función de valoración: v(B) = max {B  B  B  B} w(B) (7) Las ofertas XOR pueden representar valoraciones que satisfacen la libre eliminación (y sólo tales valoraciones), que de nuevo es la propiedad que A  B El lenguaje de licitación XOR es ligeramente menos expresivo que los polinomios, porque los polinomios pueden representar valoraciones que no satisfacen la libre eliminación. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas de XOR pueden representar la valoración de un solo elemento con ofertas atómicas m, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario se aplica a los polinomios, estas dos lenguas son incomparables en sucintas y algo complementarias para su uso práctico. Blum et al. [5] note que las fórmulas DNF monotonas son los análogos de las pujas XOR en la literatura de teoría del aprendizaje. Una fórmula de DNF monotona es una disyunción de conjunciones en las que las variables aparecen sin negación, por ejemplo x1x2 x3 x2x4x5. Tenga en cuenta que tales fórmulas pueden ser representadas como ofertas XOR donde cada oferta atómica tiene valor 1; por lo tanto XOR ofrece generalizar fórmulas DNF monotono de Boolean a funciones de valor real. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para el DNF monotono ([3] Teorema 6 Tenga en cuenta que el Teorema 1 se aplica incluso si las valoraciones no satisfacen la eliminación libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lemma 2. Una oferta XOR que contiene ofertas t atómicas se puede aprender exactamente con consultas de equivalencia t + 1 y a lo sumo consultas de membresía tm. Prueba. El algoritmo identificará cada puja atómica en la puja XOR objetivo a su vez. Initialice la valoración manifiesta v a la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presente ‡v como consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un paquete S para el que v(S) = Crear un paquete T de la siguiente manera. Primero inicialice T = S. Para cada elemento i en T, compruebe a través de una consulta de membresía si v(T) = v(T − {i}). Si así se establece T = T − {i}. De lo contrario, deje T como está y pase al siguiente punto. Afirmamos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada ítem i en T, tenemos v(T) = v(T − {i}). Para ver esto, tenga en cuenta que en algún momento al generar T, tuvimos un ̄T tal que T  ̄T  S y v( ̄T) > v( ̄T − {i}), de modo que me mantuvo en ̄T. Tenga en cuenta que v(S) = v( ̄T) = v(T) porque el valor del paquete S se mantiene durante todo el proceso de eliminación de elementos. Ahora asume v(T) = v(T − {i}). Entonces v( ̄T) = v(T) = v(T − {i}) > v( ̄T − {i}) que contradice la libre eliminación, ya que T {i}  ̄T − {i}. Por lo tanto v(T) > v(T − {i}) para todos los ítems i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si este no fuera el caso, T tomaría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = máx itat {max T T Ahora mostramos que v(T) = ̃v(T), que implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Asumir que toda oferta atómica (R, Esta suposición se mantiene vagamente cuando se inicializa la valoración manifiesta. Usando la notación de (7), dejar ( Tenemos B  B, y Bw(B) = w(B) para B Por lo tanto,?v(S) = max {B} {B} {B} {B} {B} {B} = max {B} {B} {B} ≤ {B} {B} {B} {B} {S} w(B} = v(S) (8) Ahora asume v(T) {v(T La segunda igualdad se deriva del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad sostiene porque S es un contraejemplo de la valoración manifiesta. De la ecuación (9) y la eliminación libre, nosotros 7 El algoritmo citado también se utilizó como base para Zinkevich et al.s [19] algoritmo de excitación para Toolbox DNF. Recuerde que Toolbox DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia se puede simular con una consulta de valor en el paquete que contiene todas las mercancías. que tengan ‡v(T) < Entonces de nuevo de la ecuación (9) se deduce que v(S) < Esto contradice (8), por lo que de hecho tenemos v(T) = Por lo tanto (T, v(T)) no está actualmente en nuestra hipótesis como una oferta atómica, o tendríamos correctamente?v(T) = v(T) por la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas adicionales de equivalencia hasta que todas las ofertas atómicas hayan sido identificadas. Después de cada consulta de equivalencia, una oferta atómica se identifica con como máximo m consultas de membresía. Cada contraejemplo conduce al descubrimiento de una nueva oferta atómica. Por lo tanto, hacemos a lo sumo consultas de membresía tm y exactamente consultas de equivalencia t + 1. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR se puede obtener eficientemente de las consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al.s ([5], Teorema 2) afirmando que el DNF monotono (y por lo tanto las ofertas XOR) no se pueden obtener de manera eficiente cuando las consultas de demanda se limitan a precios lineales y anónimos sobre las mercancías. 6.3 Las representaciones lineales de umbral polinomios, las ofertas XOR y todas las lenguas basadas en el lenguaje de licitación OR (como XOR-de-OR, OR-de-XOR y OR*) no representan sucintamente la valoración mayoritaria [11]. En esta valoración, los paquetes tienen valor 1 si contienen al menos m/2 ítems, y valor 0 de lo contrario. Más generalmente, considere la familia de r-of-S de valoraciones donde los paquetes tienen valor 1 si contienen al menos r artículos de un conjunto especificado de ítems S  M, y valor 0 de otra manera. La valoración mayoritaria es un caso especial de la valoración de r-of-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar las sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede añadir valor. Dejando k = S, tales valoraciones están sucintamente representadas por funciones de umbral r-of-k. Estas funciones adoptan la forma de desigualdades lineales: xi1 +. . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se mantiene, y 0 de lo contrario. Aquí i1,. . . , ik son los elementos en S. Littlestones WINNOW 2 algoritmo puede aprender tales funciones utilizando consultas de equivalencia sólo, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de excitación que resulta de WINNOW 2 sólo utiliza consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos están implícitos cuando sólo hay dos valores posibles). Tenga en cuenta que las funciones de umbral r-of-k siempre se pueden representar sucintamente en el espacio O(m). Así se obtiene un algoritmo que puede generar tales funciones con un número polinomio de consultas y comunicación polinomio, en los parámetros n y m solos. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exactos con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de ",
                " con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas en el problema de la ",
                ". Nuestro resultado nos permite aplicar la riqueza de algoritmos de aprendizaje disponibles al problema de la ",
                ". Un enfoque de aprendizaje para la excitación también motiva un enfoque diferente para diseñar algoritmos de excitación que se descomponen cuidadosamente entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivos, muchos sustitutos, etc.), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de excitación. El algoritmo de excitación resultante hace un número polinomio de consultas, y hace comunicación polinomio si los algoritmos de aprendizaje originales son eficientes. No exigimos que las valoraciones de agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia sólo pueden ser, y sólo necesitan ser, simuladas hasta el punto en que se ha calculado una asignación óptima. Este es el problema de la ",
                ". Teorema 1 implica que la excitación con consultas de valor y demanda no es más difícil que aprender con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las que la excitación es más fácil que el aprendizaje. Blum et al. [5] proporcionar tal ejemplo al considerar solamente consultas de membresía/valor (Teorema 4). En el trabajo futuro planeamos abordar la cuestión de los incentivos al convertir algoritmos de aprendizaje a algoritmos de excitación. En el entorno de aprendizaje, por lo general suponemos que los oráculos proporcionarán respuestas honestas a las preguntas; en el entorno de excitación, los agentes son generalmente egoístas y proporcionarán respuestas posiblemente deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para el aprendizaje de polinomios y ofertas XOR como algoritmos de excitación, y probar su rendimiento contra otros protocolos de subasta combinatoria establecidos [6, 15]. Una pregunta interesante aquí es: ¿qué precios Lindahl en el rango máximo a mínimo son los mejores para citar con el fin de minimizar la revelación de información? Suponemos que la revelación de información se reduce al pasar de precios máximos a precios mínimos de Lindahl, es decir, a medida que desplazamos las consultas de demanda más lejos de las consultas de equivalencia. Por último, sería útil determinar si el lenguaje de licitación de OR* [11] puede aprenderse (y, por lo tanto, obtenerse) de manera eficiente, dada la expresividad y sucinta de estas lenguas para una amplia variedad de clases de valoración. Agradecimientos Queremos agradecer a Debasis Mishra por sus útiles discusiones. Este trabajo está apoyado en parte por la subvención de NSF IIS0238147. 8. REFERENCIAS [1] A. Andersson, M. Tenhunen, y F. Ygge. Programación integral para la determinación del ganador de la subasta combinatoria. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprender conjuntos regulares de consultas y contraejemplos. Información e computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje conceptual. Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El modelo de asignación de paquetes. Diario de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Provocación de preferencias y aprendizaje de consultas. En Proc. 16a Conferencia Anual sobre Teoría del Aprendizaje Computacional (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. la 18a Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, e Y. Shoham. Domar la complejidad computacional de las subastas combinatoria: Enfoques óptimos y aproximados. En Proc. , 16a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), págs. 548 a 553, 1999. [8] B. Hudson y T. Sandholm. Uso de consultas de valor en subastas combinatoria. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría del aprendizaje computacional. MIT Press, 1994. [10] N. Littlestone. Aprender rápidamente cuando los atributos irrelevantes abundan: Un nuevo algoritmo de umbral lineal. Machine Learning, 2:285-318, 1988. [11] N. Nisan. Licitación y asignación en subastas combinatoria. En Proc. la Conferencia de la ACM sobre Comercio Electrónico, págs. 1 a 12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y el apoyo a los precios Lindahl. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de mínima revelación. En Padget et al., editor, Agent-Mediated Electronic Commerce IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. Diseño de subasta con costosa ",
                ". En Temas Especiales de Anales de Matemáticas y AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17a Conferencia Nacional sobre Inteligencia Artificial (AAAI-00), págs. 74 a 81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. la 17a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariables escasos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de ACM sobre Teoría del Aprendizaje Computacional, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendido. Comun. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum, y T. Sandholm. En tiempo polinomio "
            ]
        },
        "learn": {
            "translated_key": "aprender",
            "translated_annotated_text": "Aplicando algoritmos de aprendizaje a la eliminación de preferencia Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de excitación Demostramos que los algoritmos de aprendizaje pueden ser usados como base para algoritmos de excitación de preferencias. Los algoritmos de excitación resultantes realizan un número polinomio de consultas. También damos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. En particular, se obtiene un algoritmo que provoca pujas XOR con comunicación polinómica. Categorías y Descriptores sujetos F.2.0 [Análisis de algoritmos y complejidad de problemas]: General; J.4 [Ciencias Sociales y Conductuales]: Economía; I.2.6 [Inteligencia Artificial]: Términos generales de aprendizaje Algoritmos, Economía, Teoría 1. INTRODUCCIÓN En una subasta combinatoria, los agentes pueden pujar por paquetes de bienes en lugar de por cada uno de ellos. Puesto que hay un número exponencial de paquetes (en el número de bienes), comunicar los valores sobre estos paquetes puede ser problemático. Comunicar las valoraciones de una sola vez puede ser prohibitivamente costoso si el número de bienes es sólo moderadamente grande. Además, incluso podría ser difícil para los agentes determinar sus valoraciones para paquetes únicos [14]. A esos agentes les interesa disponer de protocolos de subasta que les obliguen a pujar en el menor número posible de paquetes. Incluso si los agentes pueden calcular eficientemente sus valoraciones, podrían ser reacios a revelarlas enteramente en el curso de una subasta, porque tal información puede ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información necesaria para determinar una asignación óptima de los bienes. Ha habido un trabajo reciente explorando los vínculos entre el problema de la excitación de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje computacional [5, 19]. En teoría de aprendizaje, el objetivo es \"aprender\" una función a través de varios tipos de consultas, tales como ¿Cuál es el valor de las funciones en estas entradas? En la obtención de preferencia, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Demostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia se puede convertir en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de excitación resultante garantiza la excitación en un número polinomio de consultas de valor y demanda. Aquí queremos decir polinomio en el número de bienes, agentes, y los tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Argumentamos que las garantías de complejidad para los esquemas de excitación deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar la comunicación polinómica en el peor de los casos, que normalmente no se puede lograr en el número de productos y agentes por sí solos. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monotono y funciones de umbral lineal. Por supuesto, una subasta combinatoria de un solo disparo donde los agentes proporcionan todas sus funciones de valoración a la vez también tendría comunicación polinómica en el tamaño de las valoraciones de los agentes, y sólo requieren una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay ninguna carga para los agentes de formular sus valoraciones en un esquema de codificación de los subastadores que elijan. Esperamos que esta sea una consideración importante en la práctica. Además, con nuestro esquema la revelación entera sólo ocurre en el peor de los casos. 180 Por ahora, dejamos a un lado la cuestión de los incentivos al derivar algoritmos de excitación. Nos centramos en el tiempo y la complejidad de la comunicación de la obtención de preferencias, independientemente de las limitaciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich y otros [19] considerar el problema del aprendizaje de clases restringidas de funciones de valoración que se pueden representar utilizando fórmulas de lectura once y Toolbox DNF. Las fórmulas Read-once pueden representar ciertas sustitutibilidades, pero no complementariedades, mientras que lo contrario se mantiene para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten depender del tamaño de la valoración objetivo como lo hacemos (aunque las valoraciones de read-once siempre se pueden representar sucintamente de todos modos). Su trabajo sólo hace uso de consultas de valor, que son bastante limitados en el poder. Debido a que nos permitimos pedir consultas, somos capaces de derivar un esquema de excitación para las funciones de valoración general. Blum et al. [5] proporcionar resultados relacionados con las complejidades del aprendizaje de la consulta y la excitación de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje de consultas, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones se pueden aprender eficientemente, pero no se pueden obtener eficientemente, y viceversa. En contraste, nuestro trabajo muestra que dada una versión más general (todavía bastante estándar) de la consulta de demanda que el tipo que consideran, la complejidad de la excitación de preferencia no es mayor que la complejidad del aprendizaje. Demostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre valoraciones para implicar una solución al problema de excitación. Nisan y Segal [12] estudian la complejidad comunicativa de la excitación de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos de la computación una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo se permite a los algoritmos hacer preguntas sobre valoraciones de agentes y recibir respuestas honestas, sin ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda la cuestión de la complejidad de la comunicación, y somos capaces de derivar algoritmos que proporcionan garantías de comunicación significativas a pesar de los resultados negativos de Nisan y Segals. Su trabajo motiva la necesidad de confiar en el tamaño de los agentes funciones de valoración para indicar los peores resultados. 2. LOS MODELOS 2.1 Aprendizaje de la consulta El modelo de aprendizaje de la consulta que consideramos aquí se llama aprendizaje exacto de la membresía y consultas de equivalencia, introducido por Angluin [2]. En este modelo el objetivo de los algoritmos de aprendizaje es identificar exactamente una función diana desconocida f : X → Y a través de consultas a un oráculo. La función de destino se extrae de una función de clase C que es conocida por el algoritmo. Típicamente el dominio X es algún subconjunto de {0, 1}m, y el rango Y es {0, 1} o algún subconjunto de los números reales. A medida que el algoritmo avanza, construye una hipótesis manifiesta?f que es su estimación actual de la función de destino. Después de la terminación, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface?f(x) = f(x) para todos x?X. Es importante especificar la representación que se utilizará para codificar funciones de C. Por ejemplo, considere la siguiente función de {0, 1}m a ♥: f(x) = 2 si x consiste en m 1s, y f(x) = 0 de otra manera. Esta función puede representarse simplemente como una lista de valores de 2m. O puede codificarse como el polinomio 2x1 · · · xm, que es mucho más sucinto. Así pues, la elección de la codificación puede tener un impacto significativo en las necesidades de tiempo y espacio del algoritmo de aprendizaje. Let size(f) ser el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes distintos de cero en el polinomio, por ejemplo. Por lo general, sólo nos referiremos a las clases de representación; las clases de funciones correspondientes serán implícitas. Por ejemplo, la clase de representación de fórmulas DNF monotonas implica la clase de función de funciones booleanas monotonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: la membresía y las consultas de equivalencia. En una consulta de membresía, el aprendiz presenta algunas x x x y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta f. El oráculo responde SÍ si?f = f, o devuelve un contraejemplo x de tal manera que?f(x) = f(x). Una consulta de equivalencia es apropiada si el tamaño( ̃f) ≤ tamaño(f) en el momento de presentar la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones se adaptan a partir de Kearns y Vazirani [9]: Definición 1. La clase de representación C es polinomialquery exactamente aprendeble de las consultas de membresía y equivalencia si hay un polinomial fijo p(·, ·) y un algoritmo L con acceso a la membresía y consultas de equivalencia de un oráculo tal que para cualquier función de destino f • C, L salidas después de a lo sumo p(size(f), m) consultas de una función?f • C tal que?f Del mismo modo, la clase de representación C se puede aprender exactamente de las consultas de membresía y equivalencia si el algoritmo L produce una hipótesis correcta en el tiempo p(size(f), m), para algunos polinomios fijos p(·, ·). Aquí m es la dimensión del dominio. Dado que la función de destino debe ser reconstruida, también permitimos necesariamente la dependencia polinómica del tamaño (f). 2.2 Eliminación de preferencias En una subasta combinatoria, un conjunto de bienes M se asignará entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Tal asignación se llama eficiente en la literatura de economía, pero nos referiremos a ella como óptima y reservar el término eficiente para referirse a la eficiencia computacional. Dejamos n = N y m = M. Una asignación es una partición de los objetos en paquetes (S1,. . . , Sn), de tal manera que Si â € ¬ Sj = â € para todos los i, j â € N. Let â € € sea el conjunto de posibles asignaciones. Cada agente i+N tiene una función de valoración vi : 2M → • sobre el espacio de los paquetes posibles. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no tienen que coincidir. Asumimos que todas las valoraciones consideradas están normalizadas, es decir, v() = 0, y que no hay externalidades, es decir, vi(S1,..., Sn) = vi(Si), para todos los agentes i  N, para cualquier asignación (S1,..., Sn)  (es decir, un agente se preocupa sólo por el paquete asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales.1 Nosotros 1 A menudo las valoraciones generales se hacen para satisfacer los 181 adicionales también asumen que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que los agentes utilidades pueden ser divididos en componentes monetarios y no monetarios. Si a un agente i se le asigna el paquete S al precio p, deriva utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más sucintas para ciertas clases de valoración, y ha habido mucha investigación en lenguajes de licitación concisos para diversos tipos de valoraciones [11]. Un ejemplo clásico al que nos referiremos más adelante es el lenguaje de licitación XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, que consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estas pujas, se busca el paquete S del valor más alto listado en las pujas atómicas de tal manera que S  S. Es entonces el caso que v(S) = v(S). Al igual que en el contexto de la teoría del aprendizaje, por lo general sólo nos referiremos a idiomas de oferta en lugar de clases de valoración, ya que las clases de valoración correspondientes serán implícitas. Por ejemplo, el lenguaje de licitación XOR implica la clase de valoraciones que satisfacen la disposición libre, que es la condición de que A  B ♥ v(A) ≤ v(B). Dejamos el tamaño(v1,. . . , vn) = Èn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de licitación). Para hacer una analogía con la teoría del aprendizaje computacional, suponemos que todas las clases de representación consideradas son polinomiamente interpretables [11], lo que significa que el valor de un paquete puede ser calculado en tiempo polinomio dada la representación de funciones de valoración. Más formalmente, una clase de representación (lenguaje de licitación) C es polinomialmente interpretable si existe un algoritmo que da como entrada algunos v • C y una instancia x • X calcula el valor v(x) en el tiempo q(size(v), m), para algún polinomio fijo q(·, ·).2 En las rondas intermedias de una subasta (terativa), el subastador habrá obtenido información sobre las funciones de Por lo tanto, habrá construido un conjunto de valoraciones manifiestas, denotadas . . Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha adquirido información sobre ciertos paquetes. El objetivo en el problema de la excitación de preferencia es construir un conjunto de valoraciones manifiestas tales que: arg max (S1,...,Sn) iÃ3n Ã3vi(Si)  arg max (S1,...,Sn) iÃ3n vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que es óptima con respecto a las valoraciones verdaderas. Tenga en cuenta que sólo se requiere una asignación óptima. condición de la libre eliminación (monotonicidad), pero no la necesitamos en este punto. 2 Esto excluye OR*, asumiendo P = NP, porque la interpretación de las ofertas de este lenguaje es NP-duro por reducción de set-embalaje ponderado, y no hay clase de representación bien estudiada en teoría de aprendizaje que es claramente análogo a OR*. 3 Esta visión de las subastas iterativas tiene por objeto paralelizar el entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente están implícitas por la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son consultas de valor y demanda. En una consulta de valor, el subastador presenta un paquete S  M y el agente responde con su valor (exacto) para el paquete v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p • • • (2m ) sobre los paquetes junto con un paquete S. El agente responde SI si es el caso de que S • arg max S M v(S ) − p(S ) ¡ o de otro modo presenta un paquete S tal que v(S ) − p(S ) > v( Tenga en cuenta también que comunicar precios no lineales no implica necesariamente citar un precio por cada paquete posible. Puede haber formas más sucintas de comunicar este vector, como se muestra en la sección 5. Hacemos las siguientes definiciones para paralelizar la configuración de aprendizaje de la consulta y para simplificar las declaraciones de resultados posteriores: Definición 2. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si hay un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes tales que para cualquier (v1,. . . , vn) V1 ×. . . × Vn, L salidas después de como máximo p(size(v1,. . . , vn), m) consulta una asignación (S1,. . . , Sn) arg max(S1,...,Sn) È vi(Si). Del mismo modo, la clase de representación C se puede obtener eficientemente de las consultas de valor y demanda si el algoritmo L produce una asignación óptima con comunicación p(size(v1, ). . . , vn), m), para algunos polinomios fijos p(·, ·). Hay algunas diferencias clave aquí con la definición de aprendizaje de la consulta. Hemos eliminado el término exactamente ya que las funciones de valoración no necesitan ser determinadas exactamente con el fin de calcular una asignación óptima. Además, un algoritmo de excitación eficiente es la comunicación polinomio, en lugar de tiempo polinomio. Esto refleja el hecho de que la comunicación en lugar del tiempo de espera es el cuello de botella en la excitación. Cálculo de una asignación óptima de bienes incluso cuando se dan las valoraciones verdaderas es NP-duro para una amplia gama de clases de valoración. Por lo tanto, no es razonable exigir tiempo polinomio en la definición de un algoritmo de excitación de preferencias eficiente. Nos complace centrarnos en la complejidad comunicativa de la excitación porque se cree que este problema es más significativo en la práctica que el de la determinación del ganador [11].5 4 Esto difiere ligeramente de la definición proporcionada por Blum et al. [5] Sus consultas sobre la demanda se limitan a precios lineales sobre las mercancías, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir. un precio distinto por cada paquete posible. Es por eso que el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. 5 Aunque el problema de determinación del ganador es NP-hard para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta aproximaciones usando solucionadores IP fuera de la plataforma [1]. 182 Dado que no es necesario obtener exactamente las valoraciones, es inicialmente menos claro si la dependencia polinómica del tamaño (v1, ). . . , vn) está justificado en este contexto. Intuitivamente, este parámetro está justificado porque debemos \"aprender\" valoraciones exactamente cuando se realiza la excitación, en el peor de los casos. Nos ocupamos de esto en la siguiente sección. 3. PARALLESBETWEEN EQUIVALENCIA Y QUERIDAS DE DEMANDA Hemos descrito los ajustes de aprendizaje y excitación de preferencias de la consulta de una manera que destaca sus similitudes. Las consultas de valor y membresía son claras analógicas. Un poco menos obvio es el hecho de que las consultas de equivalencia y demanda también son analógicas. Para ver esto, necesitamos el concepto de precios Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios sobre sus bienes subyacentes. Son no anónimos en el sentido de que dos agentes pueden tener que hacer frente a precios diferentes para el mismo paquete de mercancías. Así los precios de Lindahl son de la forma pi(S), para todos S  M, para todos los precios de i  N. Lindahl se presentan a los agentes en consultas de la demanda. Cuando los agentes han normalizado las funciones de utilidad cuasi-lineal, Bikhchandani y Ostroy [4] muestran que siempre existen precios Lindahl tales que (S1,. . . , Sn) es una asignación óptima si y sólo si Si • arg max Si vi(Si) − pi(Si) • i N (1) (S1,. . . , Sn)  arg max (S1,...,Sn) iN pi(Si) (2) Condición (1) establece que cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos de los subastadores a los precios indicados. El escenario en el que se mantienen estas condiciones se llama equilibrio Lindahl, o a menudo un equilibrio competitivo. Decimos que los precios de Lindahl apoyan la asignación óptima. Por lo tanto, basta con anunciar los precios de apoyo de Lindahl para verificar una asignación óptima. Una vez que hemos encontrado una asignación con el apoyo de precios Lindahl, el problema de excitación se resuelve. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones estén garantizadas como integrales [4]. Las variables duales de este programa lineal están soportando los precios de Lindahl para la asignación resultante. La función objetiva del programa dual es: min pi(S) Por lo general, hay una gama de posibles precios Lindahl que apoyan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios válidos Lindahl, y nos referimos a ellos como precios máximos Lindahl. De todos los vectores posibles de precios Lindahl, precios máximos Lindahl maximizar la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È iÃ3N πi del objetivo (la suma de los agentes de utilidades) son precios mínimos Lindahl. Cualquier Lindahl precios hará para nuestros resultados, pero algunos pueden tener mejores propiedades de excitación que otros. Tenga en cuenta que una consulta de demanda con precios máximos de Lindahl es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para el trabajo futuro la cuestión de los precios de Lindahl para elegir minimizar la obtención de preferencias. Teniendo en cuenta ahora por qué las consultas de demanda y equivalencia son analógicas directas, primero tenga en cuenta que dado el πi en algún equilibrio Lindahl, establecer pi(S) = max{0, Estos precios dejan a cada agente indiferente en todos los paquetes con precio positivo, y satisfacen la condición (1). Así, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl típicamente serán una constante aditivo lejos de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos de consultas de equivalencia a través de consultas de demanda. Lemma 1. Supongamos que un agente responde con un paquete preferido S cuando se propone un paquete S y soporta los precios de Lindahl p(S) (soportando con respecto a la valoración manifiesta de los agentes). A continuación, o bien?v(S) = v(S) o?v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: Φv(S) − p(S) ≥ Desigualdad (6) se mantiene porque el agente de hecho prefiere S a S dados los precios, de acuerdo con su respuesta a la consulta de demanda. Si fuera el caso de que?v(S) = v(S) y Así, al menos uno de S y S es un contraejemplo de la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño(v1,. . . , vn) en problemas de excitación. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que apoyar los precios de Lindahl debe necesariamente revelarse en el curso de cualquier protocolo de obtención de preferencias que termina con una asignación óptima. Además, Nisan y Segal (Lemma 1, [12]) afirman que en el peor de los casos los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones dobles (como será el caso de las clases más interesantes). Puesto que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y puesto que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitiendo la dependencia del tamaño(v1,. . . , vn) en problemas de excitación es totalmente natural. 183 4. DE APRENDIZAJE A LA LICITACIÓN DE PREFERENCIA La clave para convertir un algoritmo de aprendizaje a un algoritmo de excitación es simular consultas de equivalencia con consultas de demanda y valor hasta que se encuentre una asignación óptima. Debido a nuestra construcción de precios Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en que un agente responde SÍ a una consulta de equivalencia cuando la función de destino se ha aprendido exactamente. De lo contrario, podemos obtener un contraejemplo a una consulta de equivalencia dada una respuesta de agentes a una consulta de demanda. Teorema 1. Las clases de representación V1,. . . , Vn puede ser polinomio-consulta obtenida de consultas de valor y demanda si cada uno puede ser polinomio-consulta exactamente aprendido de consultas de membresía y equivalencia. Prueba. Considere el algoritmo de excitación en la Figura 1. Cada consulta de membresía en el paso 1 es simulada con una consulta de valor ya que estas son de hecho idénticas. Considere el paso 4. Si todos los agentes responden SÍ, la condición (1) se mantiene. Condición (2) se mantiene porque la asignación calculada es la maximización de ingresos para el subastador, independientemente de los agentes verdaderas valoraciones. Así pues, se ha encontrado una asignación óptima. De lo contrario, por lo menos uno de Si o Si es un contraejemplo a Vi, por Lemma 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones del agente se conocerán exactamente, en cuyo caso la asignación óptima y los precios Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinomio de consultas, desde A1,. . . , A son todos los algoritmos de aprendizaje polinomio-quería. Tenga en cuenta que el procedimiento de conversión resulta en un algoritmo de excitación de preferencias, no un algoritmo de aprendizaje. Es decir, el algoritmo resultante no simplemente \"aprender\" las valoraciones exactamente, a continuación, calcular una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor, y periódicamente comprueba si se ha reunido suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio Lindahl para las valoraciones v1,. . . , vn utilizando una asignación y precios derivados de valoraciones manifiestas . . y encontrar una asignación óptima no implica que las valoraciones de los agentes se hayan aprendido exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta interrupción temprana. No obtendremos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE COMUNICACIÓN En esta sección, pasamos a la cuestión de la complejidad comunicativa de la excitación. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (tales como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos de determinar los precios de Lindahl es exponencial en el número de mercancías, m. La carga de comunicación se mide en términos del número de bits transmitidos entre agentes y subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. La conversión de algoritmos de aprendizaje eficientes a un algoritmo de excitación produce un algoritmo cuyas consultas tienen tamaños polinomios en los parámetros m y tamaño (v1, ). . . , vn). Teorema 2. Las clases de representación V1,. . . , Vn se puede obtener de forma eficiente de las consultas de valor y demanda si cada uno puede ser aprendido exactamente de las consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, basta con comunicar la función de valoración manifiesta de los agentes y el valor Nótese que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinomio, porque el tiempo de ejecución de los algoritmos también sería superpolinomio, contradiciendo la eficiencia. Por lo tanto, la comunicación de la valoración manifiesta requiere tamaño a lo sumo p(size(vi), m), para algunos polinomios p que limita superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representando el excedente πi al agente no se puede requerir espacio mayor que q(size( También debemos comunicarnos con su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es como máximo p(size(vi), m) + q(p(size(vi), m), m)+O(m). Claramente, una respuesta de agentes a una consulta de valor o demanda tiene un tamaño máximo de q(size(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, son siempre de tamaño polinomio. Un algoritmo de aprendizaje eficiente realiza un número polinomio de consultas, por lo que la comunicación total del algoritmo de excitación resultante es polinomio en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites pueden ser traducidos a límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de excitación resultante. Con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2 se determinó el tamaño de la hipótesis manifiesta. Es probable que podamos hacerlo mucho mejor que esto en la práctica. Recuerde que una consulta de equivalencia es apropiada si size( ̃f) ≤ size(f) en el momento de realizar la consulta. Si las consultas de equivalencia de algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites estrechos en los requisitos de comunicación del algoritmo de excitación resultante. El teorema 2 muestra que los algoritmos de excitación que dependen del tamaño (v1,. . . El parámetro, vn) evita los resultados negativos de Nisan y Segals [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto al tamaño de las instancias de las funciones de valoración que se enfrentan a cualquier ejecución del algoritmo. Estos algoritmos van bien si la clase de representación elegida proporciona representaciones sucintas para la más simple y común de las valoraciones, y por lo tanto el enfoque se mueve de nuevo a uno de lenguajes de licitación compactos pero expresivos. A continuación se examinan estas cuestiones. 6. APLICACIONES En esta sección, demostramos la aplicación de nuestros métodos a clases particulares de representación para valoraciones combinatorias. Hemos demostrado que el problema de excitación de preferencias para las clases de valoración V1,. . . , Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1,. . . , Una para las valoraciones de las clases V1,. . . , Vn respectivamente. Encaje hasta que haya una señal para detenerse: 1. Corre A1,. . . , Un en paralelo sobre sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se ha detenido con los agentes valoración exacta. 2. Calcular una asignación óptima (S1,. . . , Sn ) y los correspondientes precios de Lindahl con respecto a las valoraciones manifiestas . . , їvn determinado hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de consulta de demanda. 4. Si todos ellos responden SÍ, salida la asignación y parada. De lo contrario hay algún agente i que ha respondido con algún paquete preferido Si. Realizar consultas de valor en Si y Si para encontrar un contraejemplo a ‡vi, y proporcionarlo a Ai. Figura 1: Convertir algoritmos de aprendizaje a un algoritmo de excitación. al problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de función, y porque a menudo puede ser más simple resolver cada subproblema de aprendizaje por separado que atacar el problema de excitación de preferencias directamente. Podemos desarrollar un algoritmo de excitación que se adapta a cada valoración de agentes, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Demostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas de DNF monotono y funciones de umbral lineal se pueden convertir en algoritmos de excitación de preferencia para valoraciones generales, valoraciones con eliminación libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en las representaciones que son polinomialmente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la traqueabilidad computacional [18]. Al interpretar los métodos enfatizamos la expresividad y sucinta de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de licitación, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debe representar sucintamente las funciones más simples y comunes de la clase. 6.1 Las Representaciones Polinómicas Schapire y Sellie [17] dan un algoritmo de aprendizaje para polinomios multivariables escasos que pueden utilizarse como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas apropiadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados de t-sparse sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-sparse tiene como máximo t términos, donde un término es un producto de variables, por ejemplo. x1x3x4. Un polinomio sobre los números reales tiene coeficientes extraídos de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M →  se puede escribir exclusivamente como un polinomio [17]. Para tener una idea de la sucintaidad de los polinomios como lenguaje de licitación, considere las valoraciones aditivas y mono-ítem presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es el número de mercancías que contiene el paquete. En la valoración de un solo elemento, todos los paquetes tienen valor 1, excepto el valor 0 (i.e. el agente está satisfecho tan pronto como ha adquirido un único artículo). No es difícil demostrar que la valoración de un solo elemento requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Por lo tanto, los polinomios son adecuados para valoraciones que en su mayoría son aditivas, con algunas sustituibilidades y complementariedades que pueden introducirse ajustando los coeficientes. El algoritmo de aprendizaje para polinomios hace como máximo consultas de equivalencia mti +2 y como máximo (mti +1) (t2 i +3ti)/2 consultas de membresía a un agente i, donde ti es la esparcidad del polinomio que representa vi [17]. Por lo tanto, se obtiene un algoritmo que provoca valoraciones generales con un número polinomio de consultas y comunicación polinomio.6 6.2 XOR Representaciones El lenguaje de licitación XOR es estándar en la literatura de subastas combinatoria. Recordemos que una oferta XOR se caracteriza por un conjunto de paquetes B  2M y una función de valor w : B →  definida en esos paquetes, que induce la función de valoración: v(B) = max {B  B  B  B} w(B) (7) Las ofertas XOR pueden representar valoraciones que satisfacen la libre eliminación (y sólo tales valoraciones), que de nuevo es la propiedad que A  B El lenguaje de licitación XOR es ligeramente menos expresivo que los polinomios, porque los polinomios pueden representar valoraciones que no satisfacen la libre eliminación. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas de XOR pueden representar la valoración de un solo elemento con ofertas atómicas m, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario se aplica a los polinomios, estas dos lenguas son incomparables en sucintas y algo complementarias para su uso práctico. Blum et al. [5] note que las fórmulas DNF monotonas son los análogos de las pujas XOR en la literatura de teoría del aprendizaje. Una fórmula de DNF monotona es una disyunción de conjunciones en las que las variables aparecen sin negación, por ejemplo x1x2 x3 x2x4x5. Tenga en cuenta que tales fórmulas pueden ser representadas como ofertas XOR donde cada oferta atómica tiene valor 1; por lo tanto XOR ofrece generalizar fórmulas DNF monotono de Boolean a funciones de valor real. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para el DNF monotono ([3] Teorema 6 Tenga en cuenta que el Teorema 1 se aplica incluso si las valoraciones no satisfacen la eliminación libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lemma 2. Una oferta XOR que contiene ofertas t atómicas se puede aprender exactamente con consultas de equivalencia t + 1 y a lo sumo consultas de membresía tm. Prueba. El algoritmo identificará cada puja atómica en la puja XOR objetivo a su vez. Initialice la valoración manifiesta v a la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presente ‡v como consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un paquete S para el que v(S) = Crear un paquete T de la siguiente manera. Primero inicialice T = S. Para cada elemento i en T, compruebe a través de una consulta de membresía si v(T) = v(T − {i}). Si así se establece T = T − {i}. De lo contrario, deje T como está y pase al siguiente punto. Afirmamos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada ítem i en T, tenemos v(T) = v(T − {i}). Para ver esto, tenga en cuenta que en algún momento al generar T, tuvimos un ̄T tal que T  ̄T  S y v( ̄T) > v( ̄T − {i}), de modo que me mantuvo en ̄T. Tenga en cuenta que v(S) = v( ̄T) = v(T) porque el valor del paquete S se mantiene durante todo el proceso de eliminación de elementos. Ahora asume v(T) = v(T − {i}). Entonces v( ̄T) = v(T) = v(T − {i}) > v( ̄T − {i}) que contradice la libre eliminación, ya que T {i}  ̄T − {i}. Por lo tanto v(T) > v(T − {i}) para todos los ítems i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si este no fuera el caso, T tomaría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = máx itat {max T T Ahora mostramos que v(T) = ̃v(T), que implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Asumir que toda oferta atómica (R, Esta suposición se mantiene vagamente cuando se inicializa la valoración manifiesta. Usando la notación de (7), dejar ( Tenemos B  B, y Bw(B) = w(B) para B Por lo tanto,?v(S) = max {B} {B} {B} {B} {B} {B} = max {B} {B} {B} ≤ {B} {B} {B} {B} {S} w(B} = v(S) (8) Ahora asume v(T) {v(T La segunda igualdad se deriva del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad sostiene porque S es un contraejemplo de la valoración manifiesta. De la ecuación (9) y la eliminación libre, nosotros 7 El algoritmo citado también se utilizó como base para Zinkevich et al.s [19] algoritmo de excitación para Toolbox DNF. Recuerde que Toolbox DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia se puede simular con una consulta de valor en el paquete que contiene todas las mercancías. que tengan ‡v(T) < Entonces de nuevo de la ecuación (9) se deduce que v(S) < Esto contradice (8), por lo que de hecho tenemos v(T) = Por lo tanto (T, v(T)) no está actualmente en nuestra hipótesis como una oferta atómica, o tendríamos correctamente?v(T) = v(T) por la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas adicionales de equivalencia hasta que todas las ofertas atómicas hayan sido identificadas. Después de cada consulta de equivalencia, una oferta atómica se identifica con como máximo m consultas de membresía. Cada contraejemplo conduce al descubrimiento de una nueva oferta atómica. Por lo tanto, hacemos a lo sumo consultas de membresía tm y exactamente consultas de equivalencia t + 1. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR se puede obtener eficientemente de las consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al.s ([5], Teorema 2) afirmando que el DNF monotono (y por lo tanto las ofertas XOR) no se pueden obtener de manera eficiente cuando las consultas de demanda se limitan a precios lineales y anónimos sobre las mercancías. 6.3 Las representaciones lineales de umbral polinomios, las ofertas XOR y todas las lenguas basadas en el lenguaje de licitación OR (como XOR-de-OR, OR-de-XOR y OR*) no representan sucintamente la valoración mayoritaria [11]. En esta valoración, los paquetes tienen valor 1 si contienen al menos m/2 ítems, y valor 0 de lo contrario. Más generalmente, considere la familia de r-of-S de valoraciones donde los paquetes tienen valor 1 si contienen al menos r artículos de un conjunto especificado de ítems S  M, y valor 0 de otra manera. La valoración mayoritaria es un caso especial de la valoración de r-of-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar las sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede añadir valor. Dejando k = S, tales valoraciones están sucintamente representadas por funciones de umbral r-of-k. Estas funciones adoptan la forma de desigualdades lineales: xi1 +. . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se mantiene, y 0 de lo contrario. Aquí i1,. . . , ik son los elementos en S. Littlestones WINNOW 2 algoritmo puede \"aprender\" tales funciones utilizando consultas de equivalencia sólo, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de excitación que resulta de WINNOW 2 sólo utiliza consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos están implícitos cuando sólo hay dos valores posibles). Tenga en cuenta que las funciones de umbral r-of-k siempre se pueden representar sucintamente en el espacio O(m). Así se obtiene un algoritmo que puede generar tales funciones con un número polinomio de consultas y comunicación polinomio, en los parámetros n y m solos. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exactos con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de excitación de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas en el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la riqueza de algoritmos de aprendizaje disponibles al problema de la excitación de preferencias. Un enfoque de aprendizaje para la excitación también motiva un enfoque diferente para diseñar algoritmos de excitación que se descomponen cuidadosamente entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivos, muchos sustitutos, etc.), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de excitación. El algoritmo de excitación resultante hace un número polinomio de consultas, y hace comunicación polinomio si los algoritmos de aprendizaje originales son eficientes. No exigimos que las valoraciones de agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia sólo pueden ser, y sólo necesitan ser, simuladas hasta el punto en que se ha calculado una asignación óptima. Este es el problema de la excitación de preferencias. Teorema 1 implica que la excitación con consultas de valor y demanda no es más difícil que aprender con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las que la excitación es más fácil que el aprendizaje. Blum et al. [5] proporcionar tal ejemplo al considerar solamente consultas de membresía/valor (Teorema 4). En el trabajo futuro planeamos abordar la cuestión de los incentivos al convertir algoritmos de aprendizaje a algoritmos de excitación. En el entorno de aprendizaje, por lo general suponemos que los oráculos proporcionarán respuestas honestas a las preguntas; en el entorno de excitación, los agentes son generalmente egoístas y proporcionarán respuestas posiblemente deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para el aprendizaje de polinomios y ofertas XOR como algoritmos de excitación, y probar su rendimiento contra otros protocolos de subasta combinatoria establecidos [6, 15]. Una pregunta interesante aquí es: ¿qué precios Lindahl en el rango máximo a mínimo son los mejores para citar con el fin de minimizar la revelación de información? Suponemos que la revelación de información se reduce al pasar de precios máximos a precios mínimos de Lindahl, es decir, a medida que desplazamos las consultas de demanda más lejos de las consultas de equivalencia. Por último, sería útil determinar si el lenguaje de licitación de OR* [11] puede aprenderse (y, por lo tanto, obtenerse) de manera eficiente, dada la expresividad y sucinta de estas lenguas para una amplia variedad de clases de valoración. Agradecimientos Queremos agradecer a Debasis Mishra por sus útiles discusiones. Este trabajo está apoyado en parte por la subvención de NSF IIS0238147. 8. REFERENCIAS [1] A. Andersson, M. Tenhunen, y F. Ygge. Programación integral para la determinación del ganador de la subasta combinatoria. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprender conjuntos regulares de consultas y contraejemplos. Información e computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje conceptual. Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El modelo de asignación de paquetes. Diario de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Provocación de preferencias y aprendizaje de consultas. En Proc. 16a Conferencia Anual sobre Teoría del Aprendizaje Computacional (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. la 18a Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, e Y. Shoham. Domar la complejidad computacional de las subastas combinatoria: Enfoques óptimos y aproximados. En Proc. , 16a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), págs. 548 a 553, 1999. [8] B. Hudson y T. Sandholm. Uso de consultas de valor en subastas combinatoria. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría del aprendizaje computacional. MIT Press, 1994. [10] N. Littlestone. Aprender rápidamente cuando los atributos irrelevantes abundan: Un nuevo algoritmo de umbral lineal. Machine Learning, 2:285-318, 1988. [11] N. Nisan. Licitación y asignación en subastas combinatoria. En Proc. la Conferencia de la ACM sobre Comercio Electrónico, págs. 1 a 12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y el apoyo a los precios Lindahl. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de mínima revelación. En Padget et al., editor, Agent-Mediated Electronic Commerce IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. Diseño de subastas con costosas preferencias. En Temas Especiales de Anales de Matemáticas y AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17a Conferencia Nacional sobre Inteligencia Artificial (AAAI-00), págs. 74 a 81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. la 17a Conferencia Internacional Conjunta sobre Inteligencia Artificial (ICCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariables escasos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de ACM sobre Teoría del Aprendizaje Computacional, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendido. Comun. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum, y T. Sandholm. Sobre la excitación de la preferencia polinomio-tiempo con las consultas de valor. En Proc. Cuarta Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "error": [
                ""
            ]
        }
    }
}