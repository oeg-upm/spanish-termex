{
    "original_text": "Demonstration of Grid-Enabled Ensemble Kalman Filter Data Assimilation Methodology for Reservoir Characterization Ravi Vadapalli High Performance Computing Center Texas Tech University Lubbock, TX 79409 001-806-742-4350 Ravi.Vadapalli@ttu.edu Ajitabh Kumar Department of Petroleum Engineering Texas A&M University College Station, TX 77843 001-979-847-8735 akumar@tamu.edu Ping Luo Supercomputing Facility Texas A&M University College Station, TX 77843 001-979-862-3107 pingluo@sc.tamu.edu Shameem Siddiqui Department of Petroleum Engineering Texas Tech University Lubbock, TX 79409 001-806-742-3573 Shameem.Siddiqui@ttu.edu Taesung Kim Supercomputing Facility Texas A&M University College Station, TX 77843 001-979-204-5076 tskim@sc.tamu.edu ABSTRACT Ensemble Kalman filter data assimilation methodology is a popular approach for hydrocarbon reservoir simulations in energy exploration. In this approach, an ensemble of geological models and production data of oil fields is used to forecast the dynamic response of oil wells. The Schlumberger ECLIPSE software is used for these simulations. Since models in the ensemble do not communicate, message-passing implementation is a good choice. Each model checks out an ECLIPSE license and therefore, parallelizability of reservoir simulations depends on the number licenses available. We have Grid-enabled the ensemble Kalman filter data assimilation methodology for the TIGRE Grid computing environment. By pooling the licenses and computing resources across the collaborating institutions using GridWay metascheduler and TIGRE environment, the computational accuracy can be increased while reducing the simulation runtime. In this paper, we provide an account of our efforts in Gridenabling the ensemble Kalman Filter data assimilation methodology. Potential benefits of this approach, observations and lessons learned will be discussed. Categories and Subject Descriptors C 2.4 [Distributed Systems]: Distributed applications General Terms Algorithms, Design, Performance 1. INTRODUCTION Grid computing [1] is an emerging collaborative computing paradigm to extend institution/organization specific high performance computing (HPC) capabilities greatly beyond local resources. Its importance stems from the fact that ground breaking research in strategic application areas such as bioscience and medicine, energy exploration and environmental modeling involve strong interdisciplinary components and often require intercampus collaborations and computational capabilities beyond institutional limitations. The Texas Internet Grid for Research and Education (TIGRE) [2,3] is a state funded cyberinfrastructure development project carried out by five (Rice, A&M, TTU, UH and UT Austin) major university systems - collectively called TIGRE Institutions. The purpose of TIGRE is to create a higher education Grid to sustain and extend research and educational opportunities across Texas. TIGRE is a project of the High Performance Computing across Texas (HiPCAT) [4] consortium. The goal of HiPCAT is to support advanced computational technologies to enhance research, development, and educational activities. The primary goal of TIGRE is to design and deploy state-of-the-art Grid middleware that enables integration of computing systems, storage systems and databases, visualization laboratories and displays, and even instruments and sensors across Texas. The secondary goal is to demonstrate the TIGRE capabilities to enhance research and educational opportunities in strategic application areas of interest to the State of Texas. These are bioscience and medicine, energy exploration and air quality modeling. Vision of the TIGRE project is to foster interdisciplinary and intercampus collaborations, identify novel approaches to extend academic-government-private partnerships, and become a competitive model for external funding opportunities. The overall goal of TIGRE is to support local, campus and regional user interests and offer avenues to connect with national Grid projects such as Open Science Grid [5], and TeraGrid [6]. Within the energy exploration strategic application area, we have Grid-enabled the ensemble Kalman Filter (EnKF) [7] approach for data assimilation in reservoir modeling and demonstrated the extensibility of the application using the TIGRE environment and the GridWay [8] metascheduler. Section 2 provides an overview of the TIGRE environment and capabilities. Application description and the need for Grid-enabling EnKF methodology is provided in Section 3. The implementation details and merits of our approach are discussed in Section 4. Conclusions are provided in Section 5. Finally, observations and lessons learned are documented in Section 6. 2. TIGRE ENVIRONMENT The TIGRE Grid middleware consists of minimal set of components derived from a subset of the Virtual Data Toolkit (VDT) [9] which supports a variety of operating systems. The purpose of choosing a minimal software stack is to support applications at hand, and to simplify installation and distribution of client/server stacks across TIGRE sites. Additional components will be added as they become necessary. The PacMan [10] packaging and distribution mechanism is employed for TIGRE client/server installation and management. The PacMan distribution mechanism involves retrieval, installation, and often configuration of the packaged software. This approach allows the clients to keep current, consistent versions of TIGRE software. It also helps TIGRE sites to install the needed components on resources distributed throughout the participating sites. The TIGRE client/server stack consists of an authentication and authorization layer, Globus GRAM4-based job submission via web services (pre-web services installations are available up on request). The tools for handling Grid proxy generation, Grid-enabled file transfer and Grid-enabled remote login are supported. The pertinent details of TIGRE services and tools for job scheduling and management are provided below. 2.1. Certificate Authority The TIGRE security infrastructure includes a certificate authority (CA) accredited by the International Grid Trust Federation (IGTF) for issuing X. 509 user and resource Grid certificates [11]. The Texas Advanced Computing Center (TACC), University of Texas at Austin is the TIGREs shared CA. The TIGRE Institutions serve as Registration Authorities (RA) for their respective local user base. For up-to-date information on securing user and resource certificates and their installation instructions see ref [2]. The users and hosts on TIGRE are identified by their distinguished name (DN) in their X.509 certificate provided by the CA. A native Grid-mapfile that contains a list of authorized DNs is used to authenticate and authorize user job scheduling and management on TIGRE site resources. At Texas Tech University, the users are dynamically allocated one of the many generic pool accounts. This is accomplished through the Grid User Management System (GUMS) [12]. 2.2. Job Scheduling and Management The TIGRE environment supports GRAM4-based job submission via web services. The job submission scripts are generated using XML. The web services GRAM translates the XML scripts into target cluster specific batch schedulers such as LSF, PBS, or SGE. The high bandwidth file transfer protocols such as GridFTP are utilized for staging files in and out of the target machine. The login to remote hosts for compilation and debugging is only through GSISSH service which requires resource authentication through X.509 certificates. The authentication and authorization of Grid jobs are managed by issuing Grid certificates to both users and hosts. The certificate revocation lists (CRL) are updated on a daily basis to maintain high security standards of the TIGRE Grid services. The TIGRE portal [2] documentation area provides a quick start tutorial on running jobs on TIGRE. 2.3. Metascheduler The metascheduler interoperates with the cluster level batch schedulers (such as LSF, PBS) in the overall Grid workflow management. In the present work, we have employed GridWay [8] metascheduler - a Globus incubator project - to schedule and manage jobs across TIGRE. The GridWay is a light-weight metascheduler that fully utilizes Globus functionalities. It is designed to provide efficient use of dynamic Grid resources by multiple users for Grid infrastructures built on top of Globus services. The TIGRE site administrator can control the resource sharing through a powerful built-in scheduler provided by GridWay or by extending GridWays external scheduling module to provide their own scheduling policies. Application users can write job descriptions using GridWays simple and direct job template format (see Section 4 for details) or standard Job Submission Description Language (JSDL). See section 4 for implementation details. 2.4. Customer Service Management System A TIGRE portal [2] was designed and deployed to interface users and resource providers. It was designed using GridPort [13] and is maintained by TACC. The TIGRE environment is supported by open source tools such as the Open Ticket Request System (OTRS) [14] for servicing trouble tickets, and MoinMoin [15] Wiki for TIGRE content and knowledge management for education, outreach and training. The links for OTRS and Wiki are consumed by the TIGRE portal [2] - the gateway for users and resource providers. The TIGRE resource status and loads are monitored by the Grid Port Information Repository (GPIR) service of the GridPort toolkit [13] which interfaces with local cluster load monitoring service such as Ganglia. The GPIR utilizes cron jobs on each resource to gather site specific resource characteristics such as jobs that are running, queued and waiting for resource allocation. 3. ENSEMBLE KALMAN FILTER APPLICATION The main goal of hydrocarbon reservoir simulations is to forecast the production behavior of oil and gas field (denoted as field hereafter) for its development and optimal management. In reservoir modeling, the field is divided into several geological models as shown in Figure 1. For accurate performance forecasting of the field, it is necessary to reconcile several geological models to the dynamic response of the field through history matching [16-20]. Figure 1. Cross-sectional view of the Field. Vertical layers correspond to different geological models and the nails are oil wells whose historical information will be used for forecasting the production behavior. (Figure Ref:http://faculty.smu.edu/zchen/research.html). The EnKF is a Monte Carlo method that works with an ensemble of reservoir models. This method utilizes crosscovariances [21] between the field measurements and the reservoir model parameters (derived from several models) to estimate prediction uncertainties. The geological model parameters in the ensemble are sequentially updated with a goal to minimize the prediction uncertainties. Historical production response of the field for over 50 years is used in these simulations. The main advantage of EnKF is that it can be readily linked to any reservoir simulator, and can assimilate latest production data without the need to re-run the simulator from initial conditions. Researchers in Texas are large subscribers of the Schlumberger ECLIPSE [22] package for reservoir simulations. In the reservoir modeling, each geological model checks out an ECLIPSE license. The simulation runtime of the EnKF methodology depends on the number of geological models used, number of ECLIPSE licenses available, production history of the field, and propagated uncertainties in history matching. The overall EnKF workflow is shown Figure 2. Figure 2. Ensemble Kaman Filter Data Assimilation Workflow. Each site has L licenses. At START, the master/control process (EnKF main program) reads the simulation configuration file for number (N) of models, and model-specific input files. Then, N working directories are created to store the output files. At the end of iteration, the master/control process collects the output files from N models and post processes crosscovariances [21] to estimate the prediction uncertainties. This information will be used to update models (or input files) for the next iteration. The simulation continues until the production histories are exhausted. Typical EnKF simulation with N=50 and field histories of 50-60 years, in time steps ranging from three months to a year, takes about three weeks on a serial computing environment. In parallel computing environment, there is no interprocess communication between the geological models in the ensemble. However, at the end of each simulation time-step, model-specific output files are to be collected for analyzing cross covariances [21] and to prepare next set of input files. Therefore, master-slave model in messagepassing (MPI) environment is a suitable paradigm. In this approach, the geological models are treated as slaves and are distributed across the available processors. The master Cluster or (TIGRE/GridWay) START Read Configuration File Create N Working Directories Create N Input files Model l Model 2 Model N. . . ECLIPSE on site A ECLIPSE on Site B ECLIPSE on Site Z Collect N Model Outputs, Post-process Output files END . . . process collects model-specific output files, analyzes and prepares next set of input files for the simulation. Since each geological model checks out an ECLIPSE license, parallelizability of the simulation depends on the number of licenses available. When the available number of licenses is less than the number of models in the ensemble, one or more of the nodes in the MPI group have to handle more than one model in a serial fashion and therefore, it takes longer to complete the simulation. A Petroleum Engineering Department usually procures 10-15 ECLIPSE licenses while at least ten-fold increase in the number of licenses would be necessary for industry standard simulations. The number of licenses can be increased by involving several Petroleum Engineering Departments that support ECLIPSE package. Since MPI does not scale very well for applications that involve remote compute clusters, and to get around the firewall issues with license servers across administrative domains, Grid-enabling the EnKF workflow seems to be necessary. With this motivation, we have implemented Grid-enabled EnKF workflow for the TIGRE environment and demonstrated parallelizability of the application across TIGRE using GridWay metascheduler. Further details are provided in the next section. 4. IMPLEMENTATION DETAILS To Grid-enable the EnKF approach, we have eliminated the MPI code for parallel processing and replaced with N single processor jobs (or sub-jobs) where, N is the number of geological models in the ensemble. These model-specific sub-jobs were distributed across TIGRE sites that support ECLIPSE package using the GridWay [8] metascheduler. For each sub-job, we have constructed a GridWay job template that specifies the executable, input and output files, and resource requirements. Since the TIGRE compute resources are not expected to change frequently, we have used static resource discovery policy for GridWay and the sub-jobs were scheduled dynamically across the TIGRE resources using GridWay. Figure 3 represents the sub-job template file for the GridWay metascheduler. Figure 3. GridWay Sub-Job Template In Figure 3, REQUIREMENTS flag is set to choose the resources that satisfy the application requirements. In the case of EnKF application, for example, we need resources that support ECLIPSE package. ARGUMENTS flag specifies the model in the ensemble that will invoke ECLIPSE at a remote site. INPUT_FILES is prepared by the EnKF main program (or master/control process) and is transferred by GridWay to the remote site where it is untared and is prepared for execution. Finally, OUTPUT_FILES specifies the name and location where the output files are to be written. The command-line features of GridWay were used to collect and process the model-specific outputs to prepare new set of input files. This step mimics MPI process synchronization in master-slave model. At the end of each iteration, the compute resources and licenses are committed back to the pool. Table 1 shows the sub-jobs in TIGRE Grid via GridWay using gwps command and for clarity, only selected columns were shown . USER JID DM EM NAME HOST pingluo 88 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 89 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 90 wrap actv enkf.jt minigar.hpcc.ttu.edu/LSF pingluo 91 wrap pend enkf.jt minigar.hpcc.ttu.edu/LSF pingluo 92 wrap done enkf.jt cosmos.tamu.edu/PBS pingluo 93 wrap epil enkf.jt cosmos.tamu.edu/PBS Table 1. Job scheduling across TIGRE using GridWay Metascheduler. DM: Dispatch state, EM: Execution state, JID is the job id and HOST corresponds to site specific cluster and its local batch scheduler. When a job is submitted to GridWay, it will go through a series of dispatch (DM) and execution (EM) states. For DM, the states include pend(ing), prol(og), wrap(per), epil(og), and done. DM=prol means the job has been scheduled to a resource and the remote working directory is in preparation. DM=warp implies that GridWay is executing the wrapper which in turn executes the application. DM=epil implies the job has finished running at the remote site and results are being transferred back to the GridWay server. Similarly, when EM=pend implies the job is waiting in the queue for resource and the job is running when EM=actv. For complete list of message flags and their descriptions, see the documentation in ref [8]. We have demonstrated the Grid-enabled EnKF runs using GridWay for TIGRE environment. The jobs are so chosen that the runtime doesnt exceed more than a half hour. The simulation runs involved up to 20 jobs between A&M and TTU sites with TTU serving 10 licenses. For resource information, see Table I. One of the main advantages of Grid-enabled EnKF simulation is that both the resources and licenses are released back to the pool at the end of each simulation time step unlike in the case of MPI implementation where licenses and nodes are locked until the completion of entire simulation. However, the fact that each sub-job gets scheduled independently via GridWay could possibly incur another time delay caused by waiting in queue for execution in each simulation time step. Such delays are not expected EXECUTABLE=runFORWARD REQUIREMENTS=HOSTNAME=cosmos.tamu.edu | HOSTNAME=antaeus.hpcc.ttu.edu | HOSTNAME=minigar.hpcc.ttu.edu | ARGUMENTS=001 INPUT_FILES=001.in.tar OUTPUT_FILES=001.out.tar in MPI implementation where the node is blocked for processing sub-jobs (model-specific calculation) until the end of the simulation. There are two main scenarios for comparing Grid and cluster computing approaches. Scenario I: The cluster is heavily loaded. The conceived average waiting time of job requesting large number of CPUs is usually longer than waiting time of jobs requesting single CPU. Therefore, overall waiting time could be shorter in Grid approach which requests single CPU for each sub-job many times compared to MPI implementation that requests large number of CPUs at a single time. It is apparent that Grid scheduling is beneficial especially when cluster is heavily loaded and requested number of CPUs for the MPI job is not readily available. Scenario II: The cluster is relatively less loaded or largely available. It appears the MPI implementation is favorable compared to the Grid scheduling. However, parallelizability of the EnKF application depends on the number of ECLIPSE licenses and ideally, the number of licenses should be equal to the number of models in the ensemble. Therefore, if a single institution does not have sufficient number of licenses, the cluster availability doesnt help as much as it is expected. Since the collaborative environment such as TIGRE can address both compute and software resource requirements for the EnKF application, Grid-enabled approach is still advantageous over the conventional MPI implementation in any of the above scenarios. 5. CONCLUSIONS AND FUTURE WORK TIGRE is a higher education Grid development project and its purpose is to sustain and extend research and educational opportunities across Texas. Within the energy exploration application area, we have Grid-enabled the MPI implementation of the ensemble Kalman filter data assimilation methodology for reservoir characterization. This task was accomplished by removing MPI code for parallel processing and replacing with single processor jobs one for each geological model in the ensemble. These single processor jobs were scheduled across TIGRE via GridWay metascheduler. We have demonstrated that by pooling licenses across TIGRE sites, more geological models can be handled in parallel and therefore conceivably better simulation accuracy. This approach has several advantages over MPI implementation especially when a site specific cluster is heavily loaded and/or the number licenses required for the simulation is more than those available at a single site. Towards the future work, it would be interesting to compare the runtime between MPI, and Grid implementations for the EnKF application. This effort could shed light on quality of service (QoS) of Grid environments in comparison with cluster computing. Another aspect of interest in the near future would be managing both compute and license resources to address the job (or processor)-to-license ratio management. 6. OBSERVATIONS AND LESSIONS LEARNED The Grid-enabling efforts for EnKF application have provided ample opportunities to gather insights on the visibility and promise of Grid computing environments for application development and support. The main issues are industry standard data security and QoS comparable to cluster computing. Since the reservoir modeling research involves proprietary data of the field, we had to invest substantial efforts initially in educating the application researchers on the ability of Grid services in supporting the industry standard data security through role- and privilege-based access using X.509 standard. With respect to QoS, application researchers expect cluster level QoS with Grid environments. Also, there is a steep learning curve in Grid computing compared to the conventional cluster computing. Since Grid computing is still an emerging technology, and it spans over several administrative domains, Grid computing is still premature especially in terms of the level of QoS although, it offers better data security standards compared to commodity clusters. It is our observation that training and outreach programs that compare and contrast the Grid and cluster computing environments would be a suitable approach for enhancing user participation in Grid computing. This approach also helps users to match their applications and abilities Grids can offer. In summary, our efforts through TIGRE in Grid-enabling the EnKF data assimilation methodology showed substantial promise in engaging Petroleum Engineering researchers through intercampus collaborations. Efforts are under way to involve more schools in this effort. These efforts may result in increased collaborative research, educational opportunities, and workforce development through graduate/faculty research programs across TIGRE Institutions. 7. ACKNOWLEDGMENTS The authors acknowledge the State of Texas for supporting the TIGRE project through the Texas Enterprise Fund, and TIGRE Institutions for providing the mechanism, in which the authors (Ravi Vadapalli, Taesung Kim, and Ping Luo) are also participating. The authors thank the application researchers Prof. Akhil Datta-Gupta of Texas A&M University and Prof. Lloyd Heinze of Texas Tech University for their discussions and interest to exploit the TIGRE environment to extend opportunities in research and development. 8. REFERENCES [1] Foster, I. and Kesselman, C. (eds.) 2004. The Grid: Blueprint for a new computing infrastructure (The Elsevier series in Grid computing) [2] TIGRE Portal: http://tigreportal.hipcat.net [3] Vadapalli, R. Sill, A., Dooley, R., Murray, M., Luo, P., Kim, T., Huang, M., Thyagaraja, K., and Chaffin, D. 2007. Demonstration of TIGRE environment for Grid enabled/suitable applications. 8th IEEE/ACM Int. Conf. on Grid Computing, Sept 19-21, Austin [4] The High Performance Computing across Texas Consortium http://www.hipcat.net [5] Pordes, R. Petravick, D. Kramer, B. Olson, D. Livny, M. Roy, A. Avery, P. Blackburn, K. Wenaus, T. Würthwein, F. Foster, I. Gardner, R. Wilde, M. Blatecky, A. McGee, J. and Quick, R. 2007. The Open Science Grid, J. Phys Conf Series http://www.iop.org/EJ/abstract/1742-6596/78/1/012057 and http://www.opensciencegrid.org [6] Reed, D.A. 2003. Grids, the TeraGrid and Beyond, Computer, vol 30, no. 1 and http://www.teragrid.org [7] Evensen, G. 2006. Data Assimilation: The Ensemble Kalman Filter, Springer [8] Herrera, J. Huedo, E. Montero, R. S. and Llorente, I. M. 2005. Scientific Programming, vol 12, No. 4. pp 317-331 [9] Avery, P. and Foster, I. 2001. The GriPhyN project: Towards petascale virtual data grids, technical report GriPhyN-200115 and http://vdt.cs.wisc.edu [10] The PacMan documentation and installation guide http://physics.bu.edu/pacman/htmls [11] Caskey, P. Murray, M. Perez, J. and Sill, A. 2007. Case studies in identify management for virtual organizations, EDUCAUSE Southwest Reg. Conf., Feb 21-23, Austin, TX. http://www.educause.edu/ir/library/pdf/SWR07058.pdf [12] The Grid User Management System (GUMS) https://www.racf.bnl.gov/Facility/GUMS/index.html [13] Thomas, M. and Boisseau, J. 2003. Building grid computing portals: The NPACI grid portal toolkit, Grid computing: making the global infrastructure a reality, Chapter 28, Berman, F. Fox, G. Thomas, M. Boisseau, J. and Hey, T. (eds), John Wiley and Sons, Ltd, Chichester [14] Open Ticket Request System http://otrs.org [15] The MoinMoin Wiki Engine http://moinmoin.wikiwikiweb.de [16] Vasco, D.W. Yoon, S. and Datta-Gupta, A. 1999. Integrating dynamic data into high resolution reservoir models using streamline-based analytic sensitivity coefficients, Society of Petroleum Engineers (SPE) Journal, 4 (4). [17] Emanuel, A. S. and Milliken, W. J. 1998. History matching finite difference models with 3D streamlines, SPE 49000, Proc of the Annual Technical Conf and Exhibition, Sept 2730, New Orleans, LA. [18] Nævdal, G. Johnsen, L.M. Aanonsen, S.I. and Vefring, E.H. 2003. Reservoir monitoring and Continuous Model Updating using Ensemble Kalman Filter, SPE 84372, Proc of the Annual Technical Conf and Exhibition, Oct 5-8, Denver, CO. [19] Jafarpour B. and McLaughlin, D.B. 2007. History matching with an ensemble Kalman filter and discrete cosine parameterization, SPE 108761, Proc of the Annual Technical Conf and Exhibition, Nov 11-14, Anaheim, CA [20] Li, G. and Reynolds, A. C. 2007. An iterative ensemble Kalman filter for data assimilation, SPE 109808, Proc of the SPE Annual Technical Conf and Exhibition, Nov 11-14, Anaheim, CA [21] Arroyo-Negrete, E. Devagowda, D. Datta-Gupta, A. 2006. Streamline assisted ensemble Kalman filter for rapid and continuous reservoir model updating. Proc of the Int. Oil & Gas Conf and Exhibition, SPE 104255, Dec 5-7, China [22] ECLIPSE Reservoir Engineering Software http://www.slb.com/content/services/software/reseng/index.a sp",
    "original_translation": "Demostración del conjunto de datos de Kalman Assimulation Method for Reservoir Caracterisation Ravi Vadapalli Centro de computación de alto rendimiento Texas Tech University Lubbock, TX 79409 001-806-742-4350 Ravi.Vadapalli@ttu.edu Ajitabh Kumar Department of Petroleum Engineering Texas A&M University College Station, En este enfoque, se utiliza un conjunto de modelos geológicos y datos de producción de yacimientos de petróleo para predecir la respuesta dinámica de los pozos de petróleo. El software Schlumberger ECLIPSE se utiliza para estas simulaciones. Puesto que los modelos en el conjunto no se comunican, la implementación de mensaje-passing es una buena opción. Cada modelo comprueba una licencia ECLIPSE y, por lo tanto, la paralelización de las simulaciones de reservorio depende de las licencias de número disponibles. Hemos habilitado Grid para el conjunto Kalman metodología de asimilación de datos de filtro para el entorno de computación TIGRE Grid. Al poner en común las licencias y los recursos informáticos en todas las instituciones colaboradoras utilizando el metaprogramador GridWay y el entorno TIGRE, la precisión computacional puede aumentarse al tiempo que se reduce el tiempo de ejecución de la simulación. En este artículo, proporcionamos un relato de nuestros esfuerzos en Gridenabilizar el conjunto Kalman Filter metodología de asimilación de datos. Se examinarán los posibles beneficios de este enfoque, las observaciones y la experiencia adquirida. Categorías y Descriptores sujetos C 2.4 [Sistemas distribuidos]: Aplicaciones distribuidas Términos generales Algoritmos, Diseño, Rendimiento 1. INTRODUCCIÓN La computación de cuadrícula [1] es un paradigma de computación colaborativa emergente para ampliar las capacidades específicas de computación de alto rendimiento (HPC) mucho más allá de los recursos locales. Su importancia se deriva del hecho de que la investigación innovadora en áreas de aplicación estratégicas como la biociencia y la medicina, la exploración de energía y el modelado ambiental involucran componentes interdisciplinarios fuertes y a menudo requieren colaboraciones intercampus y capacidades computacionales más allá de las limitaciones institucionales. The Texas Internet Grid for Research and Education (TIGRE) [2,3] es un proyecto de desarrollo de infraestructuras cibernéticas financiado por el estado, llevado a cabo por cinco grandes sistemas universitarios (Rice, A&M, TTU, UH y UT Austin), llamados colectivamente Instituciones TIGRE. El propósito de TIGRE es crear una red de educación superior para sostener y ampliar las oportunidades de investigación y educación en Texas. TIGRE es un proyecto del consorcio de computación de alto rendimiento en Texas (HiPCAT) [4]. El objetivo de HiPCAT es apoyar tecnologías computacionales avanzadas para mejorar la investigación, el desarrollo y las actividades educativas. El objetivo principal de TIGRE es diseñar e implementar middleware Grid de última generación que permita la integración de sistemas de computación, sistemas de almacenamiento y bases de datos, laboratorios de visualización y pantallas, e incluso instrumentos y sensores en Texas. El objetivo secundario es demostrar las capacidades de TIGRE para mejorar las oportunidades de investigación y educación en áreas de aplicación estratégica de interés para el Estado de Texas. Estos son biociencia y medicina, exploración energética y modelado de la calidad del aire. La visión del proyecto TIGRE es fomentar la colaboración interdisciplinaria e intercampus, identificar enfoques novedosos para ampliar las asociaciones académicas, gubernamentales y privadas, y convertirse en un modelo competitivo para las oportunidades de financiación externa. El objetivo general de TIGRE es apoyar los intereses de los usuarios locales, universitarios y regionales y ofrecer vías para conectar con proyectos nacionales de Red como Open Science Grid [5] y TeraGrid [6]. Dentro del área de aplicación estratégica de exploración energética, hemos habilitado el enfoque conjunto Kalman Filter (EnKF) [7] para la asimilación de datos en el modelado de reservorios y hemos demostrado la extensibilidad de la aplicación utilizando el entorno TIGRE y el metaprogramador GridWay [8]. En la sección 2 se ofrece una visión general del entorno y las capacidades de TIGRE. La descripción de la aplicación y la necesidad de una metodología EnKF compatible con la cuadrícula figuran en la sección 3. Los detalles de la aplicación y los méritos de nuestro enfoque se examinan en la sección 4. Las conclusiones figuran en la sección 5. Por último, en la sección 6 se documentan las observaciones y la experiencia adquirida. 2. TIGRE ENTORNO El MIddleware TIGRE Grid consiste en un conjunto mínimo de componentes derivados de un subconjunto del Virtual Data Toolkit (VDT) [9] que soporta una variedad de sistemas operativos. El propósito de elegir una pila de software mínima es apoyar las aplicaciones disponibles y simplificar la instalación y distribución de las pilas cliente/servidor en los sitios de TIGRE. Se añadirán componentes adicionales a medida que sean necesarios. El mecanismo de packaging y distribución PacMan [10] se emplea para la instalación y gestión del cliente/servidor TIGRE. El mecanismo de distribución de PacMan implica la recuperación, instalación y a menudo configuración del software empaquetado. Este enfoque permite a los clientes mantener versiones actualizadas y consistentes del software TIGRE. También ayuda a los sitios TIGRE a instalar los componentes necesarios en los recursos distribuidos en los sitios participantes. La pila cliente/servidor TIGRE consiste en una capa de autenticación y autorización, Globus GRAM4-basada en la presentación de trabajos a través de servicios web (las instalaciones de servicios pre-web están disponibles bajo petición). Las herramientas para manejar la generación de proxy de cuadrícula, la transferencia de archivos habilitada para cuadrícula y el inicio de sesión remoto habilitado para cuadrícula son compatibles. A continuación se proporcionan los detalles pertinentes de los servicios y herramientas de TIGRE para la programación y gestión de puestos. 2.1. Autoridad certificadora La infraestructura de seguridad TIGRE incluye una autoridad certificadora (CA) acreditada por la International Grid Trust Federation (IGTF) para emitir X. 509 certificados de usuario y recurso Grid [11]. El Texas Advanced Computing Center (TACC), Universidad de Texas en Austin, es el TIGREs CA compartido. Las instituciones de TIGRE actúan como autoridades de registro (RA) para sus respectivas bases de usuarios locales. Para obtener información actualizada sobre la seguridad de los certificados de usuario y de recursos y sus instrucciones de instalación, véase ref [2]. Los usuarios y hosts de TIGRE son identificados por su distinguido nombre (DN) en su certificado X.509 proporcionado por la CA. Un archivo nativo Grid-mapfile que contiene una lista de DNs autorizados se utiliza para autenticar y autorizar la programación y gestión de trabajos de los usuarios en los recursos del sitio TIGRE. En la Universidad Texas Tech, a los usuarios se les asigna dinámicamente una de las muchas cuentas genéricas. Esto se logra a través del Sistema de Gestión de Usuarios de Red (GUMS) [12]. 2.2. Programación y gestión de empleos El entorno TIGRE apoya la presentación de trabajos basada en GRAM4 a través de servicios web. Los scripts de envío de trabajos se generan usando XML. Los servicios web GRAM traducen los scripts XML en programadores de lotes específicos de grupos de destino como LSF, PBS o SGE. Los protocolos de transferencia de archivos de alto ancho de banda como GridFTP se utilizan para estadificación de archivos dentro y fuera de la máquina de destino. El acceso a hosts remotos para compilar y depurar es sólo a través del servicio GSISSH que requiere autenticación de recursos a través de certificados X.509. La autenticación y autorización de los trabajos de Grid se gestionan mediante la emisión de certificados de Grid a usuarios y anfitriones. Las listas de revocación de certificados (CRL) se actualizan diariamente para mantener altos estándares de seguridad de los servicios de TIGRE Grid. El área de documentación del portal TIGRE [2] proporciona un tutorial de inicio rápido sobre cómo ejecutar trabajos en TIGRE. 2.3. Metascheduler El metascheduler interopera con los programadores de lotes de nivel de cluster (como LSF, PBS) en la gestión general del flujo de trabajo de Grid. En el presente trabajo, hemos empleado el metaprogramador GridWay [8] -un proyecto de incubadora Globus- para programar y gestionar trabajos en TIGRE. El GridWay es un metaprogramador ligero que utiliza plenamente las funcionalidades de Globus. Está diseñado para proporcionar un uso eficiente de los recursos dinámicos de Grid por múltiples usuarios para las infraestructuras de Grid construidas sobre los servicios de Globus. El administrador del sitio TIGRE puede controlar el uso compartido de recursos a través de un potente programador integrado proporcionado por GridWay o ampliando el módulo de programación externa GridWays para proporcionar sus propias políticas de programación. Los usuarios de aplicaciones pueden escribir descripciones de trabajos usando el formato de plantilla de trabajo simple y directo de GridWays (ver Sección 4 para más detalles) o el lenguaje estándar de descripción de la presentación de trabajos (JSDL). Para más detalles sobre la aplicación, véase la sección 4. 2.4. Sistema de Gestión de Servicios al Cliente Un portal TIGRE [2] fue diseñado e implementado para interconectar usuarios y proveedores de recursos. Fue diseñado utilizando GridPort [13] y es mantenido por TACC. El entorno TIGRE es compatible con herramientas de código abierto como el Open Ticket Request System (OTRS) [14] para el servicio de tickets de problemas, y MoinMoin [15] Wiki para la gestión de contenido y conocimiento de TIGRE para educación, extensión y capacitación. Los enlaces para OTRS y Wiki son consumidos por el portal TIGRE [2] - el portal para usuarios y proveedores de recursos. El estado y las cargas de los recursos de TIGRE son monitoreados por el servicio de Repositorio de Información de Puertos Grid (GPIR) del kit de herramientas GridPort [13] que interactúa con el servicio local de monitoreo de carga de clústeres como Ganglia. El GPIR utiliza trabajos de cron en cada recurso para reunir características específicas de los recursos del sitio, tales como trabajos que se ejecutan, en cola y esperando la asignación de recursos. 3. APLICACIÓN ENSEMBLE KALMAN FILTER El objetivo principal de las simulaciones de yacimientos de hidrocarburos es predecir el comportamiento de la producción de yacimientos de petróleo y gas (denominados en lo sucesivo campo) para su desarrollo y gestión óptima. En el modelado de yacimientos, el campo se divide en varios modelos geológicos, como se muestra en la Figura 1. Para una previsión precisa del rendimiento del campo, es necesario conciliar varios modelos geológicos con la respuesta dinámica del campo a través de la coincidencia histórica [16-20]. Gráfico 1 Vista transversal del Campo. Las capas verticales corresponden a diferentes modelos geológicos y los clavos son pozos de aceite cuya información histórica se utilizará para predecir el comportamiento de la producción. (Figura Ref:http://faculty.smu.edu/zchen/research.html). El EnKF es un método de Monte Carlo que trabaja con un conjunto de modelos de embalses. Este método utiliza covarianzas cruzadas [21] entre las mediciones de campo y los parámetros del modelo de reservorio (derivados de varios modelos) para estimar las incertidumbres de predicción. Los parámetros del modelo geológico en el conjunto se actualizan secuencialmente con el objetivo de minimizar las incertidumbres de predicción. La respuesta histórica de la producción del campo durante más de 50 años se utiliza en estas simulaciones. La principal ventaja de EnKF es que puede vincularse fácilmente a cualquier simulador de depósito, y puede asimilar los últimos datos de producción sin necesidad de volver a ejecutar el simulador desde las condiciones iniciales. Investigadores en Texas son grandes suscriptores del paquete de Schlumberger ECLIPSE [22] para simulaciones de reservorios. En el modelado del embalse, cada modelo geológico comprueba una licencia ECLIPSE. La duración de la simulación de la metodología EnKF depende del número de modelos geológicos utilizados, el número de licencias ECLIPSE disponibles, la historia de producción del campo y las incertidumbres propagadas en la correspondencia de la historia. El flujo de trabajo general de EnKF se muestra en la Figura 2. Gráfico 2 Ensemble Kaman Filter Data Assimulation Workflow. Cada sitio tiene licencias L. En START, el proceso maestro/control (programa principal EnKF) lee el archivo de configuración de simulación para el número (N) de modelos y archivos de entrada específicos del modelo. A continuación, N directorios de trabajo se crean para almacenar los archivos de salida. Al final de la iteración, el proceso maestro/control recoge los archivos de salida de los modelos N y las crosscovarianzas de los procesos posteriores [21] para estimar las incertidumbres de predicción. Esta información se utilizará para actualizar modelos (o archivos de entrada) para la siguiente iteración. La simulación continúa hasta agotar las historias de producción. La simulación típica de EnKF con N=50 y historias de campo de 50-60 años, en pasos de tiempo que van de tres meses a un año, toma unas tres semanas en un entorno de computación en serie. En el entorno informático paralelo, no hay comunicación interproceso entre los modelos geológicos en el conjunto. Sin embargo, al final de cada paso del tiempo de simulación, los archivos de salida específicos del modelo deben ser recogidos para analizar covarianzas cruzadas [21] y para preparar el siguiente conjunto de archivos de entrada. Por lo tanto, el modelo maestro-esclavo en el entorno de mensajepassing (MPI) es un paradigma adecuado. En este enfoque, los modelos geológicos son tratados como esclavos y se distribuyen entre los procesadores disponibles. El master Cluster o (TIGRE/GridWay) START Read Configuration File Create N Working Directories Create N Input files Model l Model 2 Model N.. . ECLIPSE in situ Un ECLIPSE in situ B ECLIPSE in situ Z Collect N Model Outputs, Post-process Output files FIN. . . proceso recoge archivos de salida específicos del modelo, analiza y prepara el siguiente conjunto de archivos de entrada para la simulación. Dado que cada modelo geológico comprueba una licencia ECLIPSE, la paralelización de la simulación depende del número de licencias disponibles. Cuando el número de licencias disponible es menor que el número de modelos en el conjunto, uno o más de los nodos del grupo MPI tienen que manejar más de un modelo en serie y, por lo tanto, se tarda más tiempo en completar la simulación. Un Departamento de Ingeniería Petrolera generalmente adquiere 10-15 licencias ECLIPSE, mientras que al menos diez veces más número de licencias sería necesario para simulaciones estándar de la industria. El número de licencias puede incrementarse con la participación de varios departamentos de ingeniería petrolera que apoyan el paquete ECLIPSE. Dado que MPI no se escala muy bien para aplicaciones que involucran clústeres de computación remotos, y para evitar los problemas del firewall con servidores de licencias en todos los dominios administrativos, parece necesario activar el flujo de trabajo de EnKF. Con esta motivación, hemos implementado el flujo de trabajo EnKF habilitado para Grid para el entorno TIGRE y hemos demostrado la paralelización de la aplicación a través de TIGRE usando el metascheduler GridWay. En la siguiente sección figuran más detalles al respecto. 4. DETALLES DE APLICACION Para habilitar Grid-enable el enfoque EnKF, hemos eliminado el código MPI para el procesamiento paralelo y reemplazado por trabajos de N monoprocesador (o sub-trabajos) donde, N es el número de modelos geológicos en el conjunto. Estos sub-trabajos específicos de modelos se distribuyeron a través de sitios TIGRE que soportan el paquete ECLIPSE utilizando el metaprogramador GridWay [8]. Para cada sub-trabajo, hemos construido una plantilla de trabajo GridWay que especifica los archivos ejecutables, de entrada y salida, y los requisitos de recursos. Dado que los recursos de cálculo de TIGRE no se espera que cambien con frecuencia, hemos utilizado la política de descubrimiento de recursos estáticos para GridWay y los sub-trabajos fueron programados dinámicamente a través de los recursos de TIGRE usando GridWay. La Figura 3 representa el archivo de plantilla de subtrabajo para el metaprogramador GridWay. Gráfico 3 Plantilla de subtrabajo GridWay En la Figura 3, REQUISITOS bandera se establece para elegir los recursos que satisfacen los requisitos de la aplicación. En el caso de la aplicación EnKF, por ejemplo, necesitamos recursos que apoyen el paquete ECLIPSE. ARGUMENTS flag especifica el modelo en el conjunto que invocará ECLIPSE en un sitio remoto. INPUT_FILES es preparado por el programa principal de EnKF (o proceso maestro/control) y es transferido por GridWay al sitio remoto donde está desatendido y está preparado para su ejecución. Finalmente, OUTPUT_FILES especifica el nombre y la ubicación donde se escribirán los archivos de salida. Las características de la línea de comandos de GridWay se utilizaron para recopilar y procesar las salidas específicas del modelo para preparar un nuevo conjunto de archivos de entrada. Este paso imita la sincronización del proceso MPI en el modelo maestro-esclavo. Al final de cada iteración, los recursos computacionales y las licencias se devuelven al grupo. La Tabla 1 muestra los sub-trabajos en TIGRE Grid via GridWay usando el comando gwps y para mayor claridad, sólo se mostraron las columnas seleccionadas. USUARIO JID DM EM NOMBRE HOST pingluo 88 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 89 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 90 wrap actv enkf.jt minigar.hp Programación de trabajo a través de TIGRE usando GridWay Metascheduler. DM: Estado de envío, EM: Estado de ejecución, JID es el id de trabajo y HOST corresponde al cluster específico del sitio y su planificador de lotes local. Cuando un trabajo es enviado a GridWay, pasará por una serie de estados de envío (DM) y ejecución (EM). Para DM, los estados incluyen pend(ing), prol(og), wrap(per), epil(og), y hecho. DM=prol significa que el trabajo ha sido programado a un recurso y el directorio de trabajo remoto está en preparación. DM=warp implica que GridWay está ejecutando el envoltorio que a su vez ejecuta la aplicación. DM=epil implica que el trabajo ha terminado de ejecutarse en el sitio remoto y los resultados se están transfiriendo al servidor GridWay. Del mismo modo, cuando EM=pend implica que el trabajo está esperando en la cola para el recurso y el trabajo se está ejecutando cuando EM=actv. Para ver la lista completa de las banderas de mensajes y sus descripciones, consulte la documentación en ref [8]. Hemos demostrado las ejecuciones de EnKF habilitadas para Grid usando GridWay para entorno TIGRE. Los trabajos son tan elegidos que el tiempo de ejecución no supera más de media hora. La simulación incluyó hasta 20 trabajos entre sitios de A&M y TTU con TTU cumpliendo 10 licencias. Para obtener información sobre los recursos, véase el cuadro I. Una de las principales ventajas de la simulación EnKF habilitada por Grid es que tanto los recursos como las licencias se devuelven al grupo al final de cada paso del tiempo de simulación a diferencia del caso de la implementación de MPI donde las licencias y nodos están bloqueados hasta la finalización de la simulación completa. Sin embargo, el hecho de que cada sub-trabajo se programe independientemente a través de GridWay podría posiblemente incurrir en otro retraso de tiempo causado por esperar en la cola para la ejecución en cada paso del tiempo de simulación. Tales retrasos no se esperan EXECUTABLE=runFORWARD NECESIDADES=HOSTNAME=cosmos.tamu.edu  HOSTNAME=antaeus.hpcc.ttu.edu  HOSTNAME=minigar.hpcc.ttu.edu  ARGUMENTOS=001 INPUT_FILES=001.in.tar OUTPUT_FI Hay dos escenarios principales para comparar los enfoques de computación de red y clúster. Escenario I: El cúmulo está muy cargado. El tiempo promedio de espera concebido del trabajo que solicita un gran número de CPUs es generalmente más largo que el tiempo de espera de los trabajos que solicitan una sola CPU. Por lo tanto, el tiempo de espera general podría ser más corto en el enfoque Grid que solicita una sola CPU para cada sub-trabajo muchas veces en comparación con la implementación MPI que requiere un gran número de CPUs en un solo momento. Es evidente que la programación de la cuadrícula es beneficiosa especialmente cuando el clúster está fuertemente cargado y el número solicitado de CPUs para el trabajo del MPI no está fácilmente disponible. Escenario II: El clúster está relativamente menos cargado o disponible en gran medida. Parece que la implementación del MPI es favorable en comparación con la programación de la Rejilla. Sin embargo, la paralelización de la aplicación EnKF depende del número de licencias ECLIPSE e idealmente, el número de licencias debe ser igual al número de modelos en el conjunto. Por lo tanto, si una sola institución no tiene suficiente número de licencias, la disponibilidad del clúster no ayuda tanto como se espera. Dado que el entorno colaborativo, como TIGRE, puede abordar tanto los requisitos de computación como los de recursos de software para la aplicación EnKF, el enfoque compatible con Grid sigue siendo ventajoso sobre la implementación MPI convencional en cualquiera de los escenarios anteriores. 5. CONCLUSIONES Y FUTURO TRABAJO TIGRE es un proyecto de desarrollo de la red de educación superior y su propósito es mantener y ampliar las oportunidades de investigación y educación a través de Texas. Dentro del área de aplicación de exploración energética, hemos habilitado la implementación MPI del conjunto Kalman metodología de asimilación de datos de filtro para la caracterización de reservorios. Esta tarea se llevó a cabo eliminando el código MPI para el procesamiento paralelo y reemplazando con trabajos de un solo procesador uno para cada modelo geológico en el conjunto. Estos trabajos de un solo procesador fueron programados a través de TIGRE a través de GridWay metascheduler. Hemos demostrado que mediante la puesta en común de licencias a través de sitios TIGRE, más modelos geológicos pueden ser manejados en paralelo y por lo tanto concebiblemente mejor precisión de simulación. Este enfoque tiene varias ventajas sobre la implementación de MPI, especialmente cuando un clúster específico del sitio está muy cargado y/o las licencias de número requeridas para la simulación son más que las disponibles en un solo sitio. Hacia el trabajo futuro, sería interesante comparar el tiempo de ejecución entre MPI y las implementaciones de Grid para la aplicación EnKF. Este esfuerzo podría arrojar luz sobre la calidad del servicio (QoS) de los entornos Grid en comparación con la computación de clústers. Otro aspecto de interés en un futuro próximo sería la gestión de recursos de computación y licencia para abordar la gestión de la relación trabajo (o procesador)-licencia. 6. OBSERVACIONES Y MENOS APRENDIZADOS Los esfuerzos que facilitan la red para la aplicación EnKF han proporcionado amplias oportunidades para reunir información sobre la visibilidad y la promesa de los entornos de computación de Grid para el desarrollo y soporte de aplicaciones. Los principales problemas son la seguridad de los datos estándar de la industria y la CV comparable a la computación de clústers. Dado que la investigación de modelado de reservorios involucra datos propietarios del campo, tuvimos que invertir esfuerzos sustanciales inicialmente en educar a los investigadores de aplicaciones sobre la capacidad de los servicios de Grid para apoyar la seguridad de datos estándar de la industria a través de acceso basado en roles y privilegios utilizando el estándar X.509. Con respecto a QoS, los investigadores de aplicaciones esperan niveles de QoS con entornos de cuadrícula. Además, hay una curva de aprendizaje pronunciada en la computación de cuadrícula en comparación con la computación de clúster convencional. Dado que la computación de cuadrícula sigue siendo una tecnología emergente, y abarca varios ámbitos administrativos, la computación de cuadrícula sigue siendo prematura, especialmente en términos del nivel de QoS, aunque ofrece mejores normas de seguridad de los datos en comparación con los grupos de productos básicos. Es nuestra observación que los programas de capacitación y divulgación que comparan y contrastan los entornos de computación de red y clúster serían un enfoque adecuado para mejorar la participación de los usuarios en la computación de red. Este enfoque también ayuda a los usuarios a emparejar sus aplicaciones y habilidades que las cuadrículas pueden ofrecer. En resumen, nuestros esfuerzos a través de TIGRE en la metodología de asimilación de datos de la EnKF demostraron una promesa sustancial en la contratación de investigadores de Ingeniería Petrolera a través de colaboraciones entre campus. Se están realizando esfuerzos para lograr la participación de más escuelas en este esfuerzo. Estos esfuerzos pueden resultar en un aumento de la investigación colaborativa, oportunidades educativas y desarrollo de la fuerza laboral a través de programas de investigación de posgrado/facultad en instituciones TIGRE. 7. AGRADECIMIENTOS Los autores reconocen al Estado de Texas por apoyar el proyecto TIGRE a través del Fondo Empresarial de Texas, y a las Instituciones TIGRE por proporcionar el mecanismo, en el que también participan los autores (Ravi Vadapalli, Taesung Kim y Ping Luo). Los autores agradecen a los investigadores de aplicaciones Prof. Akhil Datta-Gupta de Texas A&M University y Prof. Lloyd Heinze de Texas Tech University por sus discusiones e interés en explotar el entorno TIGRE para ampliar las oportunidades en investigación y desarrollo. 8. REFERENCIAS [1] Foster, I. y Kesselman, C. (eds.) 2004. The Grid: Blueprint for a new computing infraestructura (The Elsevier series in Grid computing) [2] Portal TIGRE: http://tigreportal.hipcat.net [3] Vadapalli, R. Sill, A., Dooley, R., Murray, M., Luo, P., Kim, T., Huang, M., Thyagaraja, K., y Chaffin, Demostración del entorno TIGRE para aplicaciones de cuadrícula habilitadas/adecuadas. 8o IEEE/ACM Int. Conf. on Grid Computing, 19-21 de septiembre, Austin [4] The High Performance Computing cross Texas Consortium http://www.hipcat.net [5] Pordes, R. Petravick, D. Kramer, B. Olson, D. Livny, M. Roy, A. Avery, P. Blackburn, K. Wenaus, T. Würthwein, F. Foster, I. Gar The Open Science Grid, J. Phys Conf Series http://www.iop.org/EJ/abstract/1742-6596/78/1/012057 y http://www.opensciencegrid.org [6] Reed, D.A. 2003. Rejilla, el Teragrid y más allá, Ordenador, vol. 30, no. 1 y http://www.teragrid.org [7] Evensen, G. 2006. Asimilación de datos: El conjunto Kalman Filter, Springer [8] Herrera, J. Huedo, E. Montero, R. S. y Llorente, I. M. 2005. Programación Científica, vol 12, No. 4. pp 317-331 [9] Avery, P. and Foster, I. 2001. El proyecto GriPhyN: Hacia redes virtuales de datos a petaescala, informe técnico GriPhyN-200115 y http://vdt.cs.wisc.edu [10] La guía de documentación e instalación de PacMan http://physics.bu.edu/pacman/htmls [11] Caskey, P. Murray, M. Perez, J. y Sill, A. 2007. Estudios de casos en la gestión de identificación para organizaciones virtuales, EDUCOUSO Southwest Reg. Conf., 21-23 febrero, Austin, TX. http://www.educause.edu/ir/library/pdf/SWR07058.pdf [12] El Sistema de Gestión de Usuarios de Grid (GUMS) https://www.racf.bnl.gov/Facility/GUMS/index.html [13] Thomas, M. y Boisseau, J. 2003. Construyendo portales de computación de cuadrículas: El kit de herramientas para el portal de cuadrículas NPACI, Grid computing: haciendo realidad la infraestructura global, Capítulo 28, Berman, F. Fox, G. Thomas, M. Boisseau, J. y Hey, T. (eds), John Wiley and Sons, Ltd, Chichester [14] Open Ticket Request System http:// 1999. Integración de datos dinámicos en modelos de depósito de alta resolución utilizando coeficientes de sensibilidad basados en la racionalización, Society of Petroleum Engineers (SPE), 4 (4). [17] Emanuel, A. S. y Milliken, W. J. 1998. Historia que combina modelos de diferencias finitas con racionalizaciones 3D, SPE 49000, Proc de la Conf Técnica Anual y Exposición, 2730 de septiembre, Nueva Orleans, LA. [18] Nævdal, G. Johnsen, L.M. Aanonsen, S.I. y Vefring, E.H. 2003. Monitorización de embalses y actualización continua de modelos utilizando Ensemble Kalman Filter, SPE 84372, Proc del Conf Técnico Anual y Exposición, Oct 5-8, Denver, CO. [19] Jafarpour B. y McLaughlin, D.B. 2007. Historia que coincide con un conjunto de filtro Kalman y parametrización discreta de coseno, SPE 108761, Proc de la Conf Técnica Anual y Exposición, 11-14 de noviembre, Anaheim, CA [20] Li, G. y Reynolds, A. C. 2007. Un conjunto iterativo Kalman filtro para la asimilación de datos, SPE 109808, Proc de la SPE Conf y Exposición Técnica Anual, 11-14 de noviembre, Anaheim, CA [21] Arroyo-Negrete, E. Devagowda, D. Datta-Gupta, A. 2006. Simplificar el conjunto asistido Kalman filtro para la actualización rápida y continua del modelo de depósito. Proc de la Int. Oil & Gas Conf and Exhibition, SPE 104255, Dec 5-7, China [22] ECLIPSE Reservoir Engineering Software http://www.slb.com/content/services/software/reseng/index.a sp",
    "error_count": 10,
    "keys": {
        "ensemble kalman filter": {
            "translated_key": [],
            "translated_annotated_text": "Demostración del conjunto de datos de Kalman Assimulation Method for Reservoir Caracterisation Ravi Vadapalli Centro de computación de alto rendimiento Texas Tech University Lubbock, TX 79409 001-806-742-4350 Ravi.Vadapalli@ttu.edu Ajitabh Kumar Department of Petroleum Engineering Texas A&M University College Station, En este enfoque, se utiliza un conjunto de modelos geológicos y datos de producción de yacimientos de petróleo para predecir la respuesta dinámica de los pozos de petróleo. El software Schlumberger ECLIPSE se utiliza para estas simulaciones. Puesto que los modelos en el conjunto no se comunican, la implementación de mensaje-passing es una buena opción. Cada modelo comprueba una licencia ECLIPSE y, por lo tanto, la paralelización de las simulaciones de reservorio depende de las licencias de número disponibles. Hemos habilitado Grid para el conjunto Kalman metodología de asimilación de datos de filtro para el entorno de computación TIGRE Grid. Al poner en común las licencias y los recursos informáticos en todas las instituciones colaboradoras utilizando el metaprogramador GridWay y el entorno TIGRE, la precisión computacional puede aumentarse al tiempo que se reduce el tiempo de ejecución de la simulación. En este artículo, proporcionamos un relato de nuestros esfuerzos en Gridenabilizar el conjunto Kalman Filter metodología de asimilación de datos. Se examinarán los posibles beneficios de este enfoque, las observaciones y la experiencia adquirida. Categorías y Descriptores sujetos C 2.4 [Sistemas distribuidos]: Aplicaciones distribuidas Términos generales Algoritmos, Diseño, Rendimiento 1. INTRODUCCIÓN La computación de cuadrícula [1] es un paradigma de computación colaborativa emergente para ampliar las capacidades específicas de computación de alto rendimiento (HPC) mucho más allá de los recursos locales. Su importancia se deriva del hecho de que la investigación innovadora en áreas de aplicación estratégicas como la biociencia y la medicina, la exploración de energía y el modelado ambiental involucran componentes interdisciplinarios fuertes y a menudo requieren colaboraciones intercampus y capacidades computacionales más allá de las limitaciones institucionales. The Texas Internet Grid for Research and Education (TIGRE) [2,3] es un proyecto de desarrollo de infraestructuras cibernéticas financiado por el estado, llevado a cabo por cinco grandes sistemas universitarios (Rice, A&M, TTU, UH y UT Austin), llamados colectivamente Instituciones TIGRE. El propósito de TIGRE es crear una red de educación superior para sostener y ampliar las oportunidades de investigación y educación en Texas. TIGRE es un proyecto del consorcio de computación de alto rendimiento en Texas (HiPCAT) [4]. El objetivo de HiPCAT es apoyar tecnologías computacionales avanzadas para mejorar la investigación, el desarrollo y las actividades educativas. El objetivo principal de TIGRE es diseñar e implementar middleware Grid de última generación que permita la integración de sistemas de computación, sistemas de almacenamiento y bases de datos, laboratorios de visualización y pantallas, e incluso instrumentos y sensores en Texas. El objetivo secundario es demostrar las capacidades de TIGRE para mejorar las oportunidades de investigación y educación en áreas de aplicación estratégica de interés para el Estado de Texas. Estos son biociencia y medicina, exploración energética y modelado de la calidad del aire. La visión del proyecto TIGRE es fomentar la colaboración interdisciplinaria e intercampus, identificar enfoques novedosos para ampliar las asociaciones académicas, gubernamentales y privadas, y convertirse en un modelo competitivo para las oportunidades de financiación externa. El objetivo general de TIGRE es apoyar los intereses de los usuarios locales, universitarios y regionales y ofrecer vías para conectar con proyectos nacionales de Red como Open Science Grid [5] y TeraGrid [6]. Dentro del área de aplicación estratégica de exploración energética, hemos habilitado el enfoque conjunto Kalman Filter (EnKF) [7] para la asimilación de datos en el modelado de reservorios y hemos demostrado la extensibilidad de la aplicación utilizando el entorno TIGRE y el metaprogramador GridWay [8]. En la sección 2 se ofrece una visión general del entorno y las capacidades de TIGRE. La descripción de la aplicación y la necesidad de una metodología EnKF compatible con la cuadrícula figuran en la sección 3. Los detalles de la aplicación y los méritos de nuestro enfoque se examinan en la sección 4. Las conclusiones figuran en la sección 5. Por último, en la sección 6 se documentan las observaciones y la experiencia adquirida. 2. TIGRE ENTORNO El MIddleware TIGRE Grid consiste en un conjunto mínimo de componentes derivados de un subconjunto del Virtual Data Toolkit (VDT) [9] que soporta una variedad de sistemas operativos. El propósito de elegir una pila de software mínima es apoyar las aplicaciones disponibles y simplificar la instalación y distribución de las pilas cliente/servidor en los sitios de TIGRE. Se añadirán componentes adicionales a medida que sean necesarios. El mecanismo de packaging y distribución PacMan [10] se emplea para la instalación y gestión del cliente/servidor TIGRE. El mecanismo de distribución de PacMan implica la recuperación, instalación y a menudo configuración del software empaquetado. Este enfoque permite a los clientes mantener versiones actualizadas y consistentes del software TIGRE. También ayuda a los sitios TIGRE a instalar los componentes necesarios en los recursos distribuidos en los sitios participantes. La pila cliente/servidor TIGRE consiste en una capa de autenticación y autorización, Globus GRAM4-basada en la presentación de trabajos a través de servicios web (las instalaciones de servicios pre-web están disponibles bajo petición). Las herramientas para manejar la generación de proxy de cuadrícula, la transferencia de archivos habilitada para cuadrícula y el inicio de sesión remoto habilitado para cuadrícula son compatibles. A continuación se proporcionan los detalles pertinentes de los servicios y herramientas de TIGRE para la programación y gestión de puestos. 2.1. Autoridad certificadora La infraestructura de seguridad TIGRE incluye una autoridad certificadora (CA) acreditada por la International Grid Trust Federation (IGTF) para emitir X. 509 certificados de usuario y recurso Grid [11]. El Texas Advanced Computing Center (TACC), Universidad de Texas en Austin, es el TIGREs CA compartido. Las instituciones de TIGRE actúan como autoridades de registro (RA) para sus respectivas bases de usuarios locales. Para obtener información actualizada sobre la seguridad de los certificados de usuario y de recursos y sus instrucciones de instalación, véase ref [2]. Los usuarios y hosts de TIGRE son identificados por su distinguido nombre (DN) en su certificado X.509 proporcionado por la CA. Un archivo nativo Grid-mapfile que contiene una lista de DNs autorizados se utiliza para autenticar y autorizar la programación y gestión de trabajos de los usuarios en los recursos del sitio TIGRE. En la Universidad Texas Tech, a los usuarios se les asigna dinámicamente una de las muchas cuentas genéricas. Esto se logra a través del Sistema de Gestión de Usuarios de Red (GUMS) [12]. 2.2. Programación y gestión de empleos El entorno TIGRE apoya la presentación de trabajos basada en GRAM4 a través de servicios web. Los scripts de envío de trabajos se generan usando XML. Los servicios web GRAM traducen los scripts XML en programadores de lotes específicos de grupos de destino como LSF, PBS o SGE. Los protocolos de transferencia de archivos de alto ancho de banda como GridFTP se utilizan para estadificación de archivos dentro y fuera de la máquina de destino. El acceso a hosts remotos para compilar y depurar es sólo a través del servicio GSISSH que requiere autenticación de recursos a través de certificados X.509. La autenticación y autorización de los trabajos de Grid se gestionan mediante la emisión de certificados de Grid a usuarios y anfitriones. Las listas de revocación de certificados (CRL) se actualizan diariamente para mantener altos estándares de seguridad de los servicios de TIGRE Grid. El área de documentación del portal TIGRE [2] proporciona un tutorial de inicio rápido sobre cómo ejecutar trabajos en TIGRE. 2.3. Metascheduler El metascheduler interopera con los programadores de lotes de nivel de cluster (como LSF, PBS) en la gestión general del flujo de trabajo de Grid. En el presente trabajo, hemos empleado el metaprogramador GridWay [8] -un proyecto de incubadora Globus- para programar y gestionar trabajos en TIGRE. El GridWay es un metaprogramador ligero que utiliza plenamente las funcionalidades de Globus. Está diseñado para proporcionar un uso eficiente de los recursos dinámicos de Grid por múltiples usuarios para las infraestructuras de Grid construidas sobre los servicios de Globus. El administrador del sitio TIGRE puede controlar el uso compartido de recursos a través de un potente programador integrado proporcionado por GridWay o ampliando el módulo de programación externa GridWays para proporcionar sus propias políticas de programación. Los usuarios de aplicaciones pueden escribir descripciones de trabajos usando el formato de plantilla de trabajo simple y directo de GridWays (ver Sección 4 para más detalles) o el lenguaje estándar de descripción de la presentación de trabajos (JSDL). Para más detalles sobre la aplicación, véase la sección 4. 2.4. Sistema de Gestión de Servicios al Cliente Un portal TIGRE [2] fue diseñado e implementado para interconectar usuarios y proveedores de recursos. Fue diseñado utilizando GridPort [13] y es mantenido por TACC. El entorno TIGRE es compatible con herramientas de código abierto como el Open Ticket Request System (OTRS) [14] para el servicio de tickets de problemas, y MoinMoin [15] Wiki para la gestión de contenido y conocimiento de TIGRE para educación, extensión y capacitación. Los enlaces para OTRS y Wiki son consumidos por el portal TIGRE [2] - el portal para usuarios y proveedores de recursos. El estado y las cargas de los recursos de TIGRE son monitoreados por el servicio de Repositorio de Información de Puertos Grid (GPIR) del kit de herramientas GridPort [13] que interactúa con el servicio local de monitoreo de carga de clústeres como Ganglia. El GPIR utiliza trabajos de cron en cada recurso para reunir características específicas de los recursos del sitio, tales como trabajos que se ejecutan, en cola y esperando la asignación de recursos. 3. APLICACIÓN ENSEMBLE KALMAN FILTER El objetivo principal de las simulaciones de yacimientos de hidrocarburos es predecir el comportamiento de la producción de yacimientos de petróleo y gas (denominados en lo sucesivo campo) para su desarrollo y gestión óptima. En el modelado de yacimientos, el campo se divide en varios modelos geológicos, como se muestra en la Figura 1. Para una previsión precisa del rendimiento del campo, es necesario conciliar varios modelos geológicos con la respuesta dinámica del campo a través de la coincidencia histórica [16-20]. Gráfico 1 Vista transversal del Campo. Las capas verticales corresponden a diferentes modelos geológicos y los clavos son pozos de aceite cuya información histórica se utilizará para predecir el comportamiento de la producción. (Figura Ref:http://faculty.smu.edu/zchen/research.html). El EnKF es un método de Monte Carlo que trabaja con un conjunto de modelos de embalses. Este método utiliza covarianzas cruzadas [21] entre las mediciones de campo y los parámetros del modelo de reservorio (derivados de varios modelos) para estimar las incertidumbres de predicción. Los parámetros del modelo geológico en el conjunto se actualizan secuencialmente con el objetivo de minimizar las incertidumbres de predicción. La respuesta histórica de la producción del campo durante más de 50 años se utiliza en estas simulaciones. La principal ventaja de EnKF es que puede vincularse fácilmente a cualquier simulador de depósito, y puede asimilar los últimos datos de producción sin necesidad de volver a ejecutar el simulador desde las condiciones iniciales. Investigadores en Texas son grandes suscriptores del paquete de Schlumberger ECLIPSE [22] para simulaciones de reservorios. En el modelado del embalse, cada modelo geológico comprueba una licencia ECLIPSE. La duración de la simulación de la metodología EnKF depende del número de modelos geológicos utilizados, el número de licencias ECLIPSE disponibles, la historia de producción del campo y las incertidumbres propagadas en la correspondencia de la historia. El flujo de trabajo general de EnKF se muestra en la Figura 2. Gráfico 2 Ensemble Kaman Filter Data Assimulation Workflow. Cada sitio tiene licencias L. En START, el proceso maestro/control (programa principal EnKF) lee el archivo de configuración de simulación para el número (N) de modelos y archivos de entrada específicos del modelo. A continuación, N directorios de trabajo se crean para almacenar los archivos de salida. Al final de la iteración, el proceso maestro/control recoge los archivos de salida de los modelos N y las crosscovarianzas de los procesos posteriores [21] para estimar las incertidumbres de predicción. Esta información se utilizará para actualizar modelos (o archivos de entrada) para la siguiente iteración. La simulación continúa hasta agotar las historias de producción. La simulación típica de EnKF con N=50 y historias de campo de 50-60 años, en pasos de tiempo que van de tres meses a un año, toma unas tres semanas en un entorno de computación en serie. En el entorno informático paralelo, no hay comunicación interproceso entre los modelos geológicos en el conjunto. Sin embargo, al final de cada paso del tiempo de simulación, los archivos de salida específicos del modelo deben ser recogidos para analizar covarianzas cruzadas [21] y para preparar el siguiente conjunto de archivos de entrada. Por lo tanto, el modelo maestro-esclavo en el entorno de mensajepassing (MPI) es un paradigma adecuado. En este enfoque, los modelos geológicos son tratados como esclavos y se distribuyen entre los procesadores disponibles. El master Cluster o (TIGRE/GridWay) START Read Configuration File Create N Working Directories Create N Input files Model l Model 2 Model N.. . ECLIPSE in situ Un ECLIPSE in situ B ECLIPSE in situ Z Collect N Model Outputs, Post-process Output files FIN. . . proceso recoge archivos de salida específicos del modelo, analiza y prepara el siguiente conjunto de archivos de entrada para la simulación. Dado que cada modelo geológico comprueba una licencia ECLIPSE, la paralelización de la simulación depende del número de licencias disponibles. Cuando el número de licencias disponible es menor que el número de modelos en el conjunto, uno o más de los nodos del grupo MPI tienen que manejar más de un modelo en serie y, por lo tanto, se tarda más tiempo en completar la simulación. Un Departamento de Ingeniería Petrolera generalmente adquiere 10-15 licencias ECLIPSE, mientras que al menos diez veces más número de licencias sería necesario para simulaciones estándar de la industria. El número de licencias puede incrementarse con la participación de varios departamentos de ingeniería petrolera que apoyan el paquete ECLIPSE. Dado que MPI no se escala muy bien para aplicaciones que involucran clústeres de computación remotos, y para evitar los problemas del firewall con servidores de licencias en todos los dominios administrativos, parece necesario activar el flujo de trabajo de EnKF. Con esta motivación, hemos implementado el flujo de trabajo EnKF habilitado para Grid para el entorno TIGRE y hemos demostrado la paralelización de la aplicación a través de TIGRE usando el metascheduler GridWay. En la siguiente sección figuran más detalles al respecto. 4. DETALLES DE APLICACION Para habilitar Grid-enable el enfoque EnKF, hemos eliminado el código MPI para el procesamiento paralelo y reemplazado por trabajos de N monoprocesador (o sub-trabajos) donde, N es el número de modelos geológicos en el conjunto. Estos sub-trabajos específicos de modelos se distribuyeron a través de sitios TIGRE que soportan el paquete ECLIPSE utilizando el metaprogramador GridWay [8]. Para cada sub-trabajo, hemos construido una plantilla de trabajo GridWay que especifica los archivos ejecutables, de entrada y salida, y los requisitos de recursos. Dado que los recursos de cálculo de TIGRE no se espera que cambien con frecuencia, hemos utilizado la política de descubrimiento de recursos estáticos para GridWay y los sub-trabajos fueron programados dinámicamente a través de los recursos de TIGRE usando GridWay. La Figura 3 representa el archivo de plantilla de subtrabajo para el metaprogramador GridWay. Gráfico 3 Plantilla de subtrabajo GridWay En la Figura 3, REQUISITOS bandera se establece para elegir los recursos que satisfacen los requisitos de la aplicación. En el caso de la aplicación EnKF, por ejemplo, necesitamos recursos que apoyen el paquete ECLIPSE. ARGUMENTS flag especifica el modelo en el conjunto que invocará ECLIPSE en un sitio remoto. INPUT_FILES es preparado por el programa principal de EnKF (o proceso maestro/control) y es transferido por GridWay al sitio remoto donde está desatendido y está preparado para su ejecución. Finalmente, OUTPUT_FILES especifica el nombre y la ubicación donde se escribirán los archivos de salida. Las características de la línea de comandos de GridWay se utilizaron para recopilar y procesar las salidas específicas del modelo para preparar un nuevo conjunto de archivos de entrada. Este paso imita la sincronización del proceso MPI en el modelo maestro-esclavo. Al final de cada iteración, los recursos computacionales y las licencias se devuelven al grupo. La Tabla 1 muestra los sub-trabajos en TIGRE Grid via GridWay usando el comando gwps y para mayor claridad, sólo se mostraron las columnas seleccionadas. USUARIO JID DM EM NOMBRE HOST pingluo 88 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 89 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 90 wrap actv enkf.jt minigar.hp Programación de trabajo a través de TIGRE usando GridWay Metascheduler. DM: Estado de envío, EM: Estado de ejecución, JID es el id de trabajo y HOST corresponde al cluster específico del sitio y su planificador de lotes local. Cuando un trabajo es enviado a GridWay, pasará por una serie de estados de envío (DM) y ejecución (EM). Para DM, los estados incluyen pend(ing), prol(og), wrap(per), epil(og), y hecho. DM=prol significa que el trabajo ha sido programado a un recurso y el directorio de trabajo remoto está en preparación. DM=warp implica que GridWay está ejecutando el envoltorio que a su vez ejecuta la aplicación. DM=epil implica que el trabajo ha terminado de ejecutarse en el sitio remoto y los resultados se están transfiriendo al servidor GridWay. Del mismo modo, cuando EM=pend implica que el trabajo está esperando en la cola para el recurso y el trabajo se está ejecutando cuando EM=actv. Para ver la lista completa de las banderas de mensajes y sus descripciones, consulte la documentación en ref [8]. Hemos demostrado las ejecuciones de EnKF habilitadas para Grid usando GridWay para entorno TIGRE. Los trabajos son tan elegidos que el tiempo de ejecución no supera más de media hora. La simulación incluyó hasta 20 trabajos entre sitios de A&M y TTU con TTU cumpliendo 10 licencias. Para obtener información sobre los recursos, véase el cuadro I. Una de las principales ventajas de la simulación EnKF habilitada por Grid es que tanto los recursos como las licencias se devuelven al grupo al final de cada paso del tiempo de simulación a diferencia del caso de la implementación de MPI donde las licencias y nodos están bloqueados hasta la finalización de la simulación completa. Sin embargo, el hecho de que cada sub-trabajo se programe independientemente a través de GridWay podría posiblemente incurrir en otro retraso de tiempo causado por esperar en la cola para la ejecución en cada paso del tiempo de simulación. Tales retrasos no se esperan EXECUTABLE=runFORWARD NECESIDADES=HOSTNAME=cosmos.tamu.edu  HOSTNAME=antaeus.hpcc.ttu.edu  HOSTNAME=minigar.hpcc.ttu.edu  ARGUMENTOS=001 INPUT_FILES=001.in.tar OUTPUT_FI Hay dos escenarios principales para comparar los enfoques de computación de red y clúster. Escenario I: El cúmulo está muy cargado. El tiempo promedio de espera concebido del trabajo que solicita un gran número de CPUs es generalmente más largo que el tiempo de espera de los trabajos que solicitan una sola CPU. Por lo tanto, el tiempo de espera general podría ser más corto en el enfoque Grid que solicita una sola CPU para cada sub-trabajo muchas veces en comparación con la implementación MPI que requiere un gran número de CPUs en un solo momento. Es evidente que la programación de la cuadrícula es beneficiosa especialmente cuando el clúster está fuertemente cargado y el número solicitado de CPUs para el trabajo del MPI no está fácilmente disponible. Escenario II: El clúster está relativamente menos cargado o disponible en gran medida. Parece que la implementación del MPI es favorable en comparación con la programación de la Rejilla. Sin embargo, la paralelización de la aplicación EnKF depende del número de licencias ECLIPSE e idealmente, el número de licencias debe ser igual al número de modelos en el conjunto. Por lo tanto, si una sola institución no tiene suficiente número de licencias, la disponibilidad del clúster no ayuda tanto como se espera. Dado que el entorno colaborativo, como TIGRE, puede abordar tanto los requisitos de computación como los de recursos de software para la aplicación EnKF, el enfoque compatible con Grid sigue siendo ventajoso sobre la implementación MPI convencional en cualquiera de los escenarios anteriores. 5. CONCLUSIONES Y FUTURO TRABAJO TIGRE es un proyecto de desarrollo de la red de educación superior y su propósito es mantener y ampliar las oportunidades de investigación y educación a través de Texas. Dentro del área de aplicación de exploración energética, hemos habilitado la implementación MPI del conjunto Kalman metodología de asimilación de datos de filtro para la caracterización de reservorios. Esta tarea se llevó a cabo eliminando el código MPI para el procesamiento paralelo y reemplazando con trabajos de un solo procesador uno para cada modelo geológico en el conjunto. Estos trabajos de un solo procesador fueron programados a través de TIGRE a través de GridWay metascheduler. Hemos demostrado que mediante la puesta en común de licencias a través de sitios TIGRE, más modelos geológicos pueden ser manejados en paralelo y por lo tanto concebiblemente mejor precisión de simulación. Este enfoque tiene varias ventajas sobre la implementación de MPI, especialmente cuando un clúster específico del sitio está muy cargado y/o las licencias de número requeridas para la simulación son más que las disponibles en un solo sitio. Hacia el trabajo futuro, sería interesante comparar el tiempo de ejecución entre MPI y las implementaciones de Grid para la aplicación EnKF. Este esfuerzo podría arrojar luz sobre la calidad del servicio (QoS) de los entornos Grid en comparación con la computación de clústers. Otro aspecto de interés en un futuro próximo sería la gestión de recursos de computación y licencia para abordar la gestión de la relación trabajo (o procesador)-licencia. 6. OBSERVACIONES Y MENOS APRENDIZADOS Los esfuerzos que facilitan la red para la aplicación EnKF han proporcionado amplias oportunidades para reunir información sobre la visibilidad y la promesa de los entornos de computación de Grid para el desarrollo y soporte de aplicaciones. Los principales problemas son la seguridad de los datos estándar de la industria y la CV comparable a la computación de clústers. Dado que la investigación de modelado de reservorios involucra datos propietarios del campo, tuvimos que invertir esfuerzos sustanciales inicialmente en educar a los investigadores de aplicaciones sobre la capacidad de los servicios de Grid para apoyar la seguridad de datos estándar de la industria a través de acceso basado en roles y privilegios utilizando el estándar X.509. Con respecto a QoS, los investigadores de aplicaciones esperan niveles de QoS con entornos de cuadrícula. Además, hay una curva de aprendizaje pronunciada en la computación de cuadrícula en comparación con la computación de clúster convencional. Dado que la computación de cuadrícula sigue siendo una tecnología emergente, y abarca varios ámbitos administrativos, la computación de cuadrícula sigue siendo prematura, especialmente en términos del nivel de QoS, aunque ofrece mejores normas de seguridad de los datos en comparación con los grupos de productos básicos. Es nuestra observación que los programas de capacitación y divulgación que comparan y contrastan los entornos de computación de red y clúster serían un enfoque adecuado para mejorar la participación de los usuarios en la computación de red. Este enfoque también ayuda a los usuarios a emparejar sus aplicaciones y habilidades que las cuadrículas pueden ofrecer. En resumen, nuestros esfuerzos a través de TIGRE en la metodología de asimilación de datos de la EnKF demostraron una promesa sustancial en la contratación de investigadores de Ingeniería Petrolera a través de colaboraciones entre campus. Se están realizando esfuerzos para lograr la participación de más escuelas en este esfuerzo. Estos esfuerzos pueden resultar en un aumento de la investigación colaborativa, oportunidades educativas y desarrollo de la fuerza laboral a través de programas de investigación de posgrado/facultad en instituciones TIGRE. 7. AGRADECIMIENTOS Los autores reconocen al Estado de Texas por apoyar el proyecto TIGRE a través del Fondo Empresarial de Texas, y a las Instituciones TIGRE por proporcionar el mecanismo, en el que también participan los autores (Ravi Vadapalli, Taesung Kim y Ping Luo). Los autores agradecen a los investigadores de aplicaciones Prof. Akhil Datta-Gupta de Texas A&M University y Prof. Lloyd Heinze de Texas Tech University por sus discusiones e interés en explotar el entorno TIGRE para ampliar las oportunidades en investigación y desarrollo. 8. REFERENCIAS [1] Foster, I. y Kesselman, C. (eds.) 2004. The Grid: Blueprint for a new computing infraestructura (The Elsevier series in Grid computing) [2] Portal TIGRE: http://tigreportal.hipcat.net [3] Vadapalli, R. Sill, A., Dooley, R., Murray, M., Luo, P., Kim, T., Huang, M., Thyagaraja, K., y Chaffin, Demostración del entorno TIGRE para aplicaciones de cuadrícula habilitadas/adecuadas. 8o IEEE/ACM Int. Conf. on Grid Computing, 19-21 de septiembre, Austin [4] The High Performance Computing cross Texas Consortium http://www.hipcat.net [5] Pordes, R. Petravick, D. Kramer, B. Olson, D. Livny, M. Roy, A. Avery, P. Blackburn, K. Wenaus, T. Würthwein, F. Foster, I. Gar The Open Science Grid, J. Phys Conf Series http://www.iop.org/EJ/abstract/1742-6596/78/1/012057 y http://www.opensciencegrid.org [6] Reed, D.A. 2003. Rejilla, el Teragrid y más allá, Ordenador, vol. 30, no. 1 y http://www.teragrid.org [7] Evensen, G. 2006. Asimilación de datos: El conjunto Kalman Filter, Springer [8] Herrera, J. Huedo, E. Montero, R. S. y Llorente, I. M. 2005. Programación Científica, vol 12, No. 4. pp 317-331 [9] Avery, P. and Foster, I. 2001. El proyecto GriPhyN: Hacia redes virtuales de datos a petaescala, informe técnico GriPhyN-200115 y http://vdt.cs.wisc.edu [10] La guía de documentación e instalación de PacMan http://physics.bu.edu/pacman/htmls [11] Caskey, P. Murray, M. Perez, J. y Sill, A. 2007. Estudios de casos en la gestión de identificación para organizaciones virtuales, EDUCOUSO Southwest Reg. Conf., 21-23 febrero, Austin, TX. http://www.educause.edu/ir/library/pdf/SWR07058.pdf [12] El Sistema de Gestión de Usuarios de Grid (GUMS) https://www.racf.bnl.gov/Facility/GUMS/index.html [13] Thomas, M. y Boisseau, J. 2003. Construyendo portales de computación de cuadrículas: El kit de herramientas para el portal de cuadrículas NPACI, Grid computing: haciendo realidad la infraestructura global, Capítulo 28, Berman, F. Fox, G. Thomas, M. Boisseau, J. y Hey, T. (eds), John Wiley and Sons, Ltd, Chichester [14] Open Ticket Request System http:// 1999. Integración de datos dinámicos en modelos de depósito de alta resolución utilizando coeficientes de sensibilidad basados en la racionalización, Society of Petroleum Engineers (SPE), 4 (4). [17] Emanuel, A. S. y Milliken, W. J. 1998. Historia que combina modelos de diferencias finitas con racionalizaciones 3D, SPE 49000, Proc de la Conf Técnica Anual y Exposición, 2730 de septiembre, Nueva Orleans, LA. [18] Nævdal, G. Johnsen, L.M. Aanonsen, S.I. y Vefring, E.H. 2003. Monitorización de embalses y actualización continua de modelos utilizando Ensemble Kalman Filter, SPE 84372, Proc del Conf Técnico Anual y Exposición, Oct 5-8, Denver, CO. [19] Jafarpour B. y McLaughlin, D.B. 2007. Historia que coincide con un conjunto de filtro Kalman y parametrización discreta de coseno, SPE 108761, Proc de la Conf Técnica Anual y Exposición, 11-14 de noviembre, Anaheim, CA [20] Li, G. y Reynolds, A. C. 2007. Un conjunto iterativo Kalman filtro para la asimilación de datos, SPE 109808, Proc de la SPE Conf y Exposición Técnica Anual, 11-14 de noviembre, Anaheim, CA [21] Arroyo-Negrete, E. Devagowda, D. Datta-Gupta, A. 2006. Simplificar el conjunto asistido Kalman filtro para la actualización rápida y continua del modelo de depósito. Proc de la Int. Oil & Gas Conf and Exhibition, SPE 104255, Dec 5-7, China [22] ECLIPSE Reservoir Engineering Software http://www.slb.com/content/services/software/reseng/index.a sp ",
            "error": []
        },
        "datum assimilation methodology": {
            "translated_key": [],
            "translated_annotated_text": "Demostración del conjunto de datos de Kalman Assimulation Method for Reservoir Caracterisation Ravi Vadapalli Centro de computación de alto rendimiento Texas Tech University Lubbock, TX 79409 001-806-742-4350 Ravi.Vadapalli@ttu.edu Ajitabh Kumar Department of Petroleum Engineering Texas A&M University College Station, En este enfoque, se utiliza un conjunto de modelos geológicos y datos de producción de yacimientos de petróleo para predecir la respuesta dinámica de los pozos de petróleo. El software Schlumberger ECLIPSE se utiliza para estas simulaciones. Puesto que los modelos en el conjunto no se comunican, la implementación de mensaje-passing es una buena opción. Cada modelo comprueba una licencia ECLIPSE y, por lo tanto, la paralelización de las simulaciones de reservorio depende de las licencias de número disponibles. Hemos habilitado Grid para el conjunto Kalman metodología de asimilación de datos de filtro para el entorno de computación TIGRE Grid. Al poner en común las licencias y los recursos informáticos en todas las instituciones colaboradoras utilizando el metaprogramador GridWay y el entorno TIGRE, la precisión computacional puede aumentarse al tiempo que se reduce el tiempo de ejecución de la simulación. En este artículo, proporcionamos un relato de nuestros esfuerzos en Gridenabilizar el conjunto Kalman Filter metodología de asimilación de datos. Se examinarán los posibles beneficios de este enfoque, las observaciones y la experiencia adquirida. Categorías y Descriptores sujetos C 2.4 [Sistemas distribuidos]: Aplicaciones distribuidas Términos generales Algoritmos, Diseño, Rendimiento 1. INTRODUCCIÓN La computación de cuadrícula [1] es un paradigma de computación colaborativa emergente para ampliar las capacidades específicas de computación de alto rendimiento (HPC) mucho más allá de los recursos locales. Su importancia se deriva del hecho de que la investigación innovadora en áreas de aplicación estratégicas como la biociencia y la medicina, la exploración de energía y el modelado ambiental involucran componentes interdisciplinarios fuertes y a menudo requieren colaboraciones intercampus y capacidades computacionales más allá de las limitaciones institucionales. The Texas Internet Grid for Research and Education (TIGRE) [2,3] es un proyecto de desarrollo de infraestructuras cibernéticas financiado por el estado, llevado a cabo por cinco grandes sistemas universitarios (Rice, A&M, TTU, UH y UT Austin), llamados colectivamente Instituciones TIGRE. El propósito de TIGRE es crear una red de educación superior para sostener y ampliar las oportunidades de investigación y educación en Texas. TIGRE es un proyecto del consorcio de computación de alto rendimiento en Texas (HiPCAT) [4]. El objetivo de HiPCAT es apoyar tecnologías computacionales avanzadas para mejorar la investigación, el desarrollo y las actividades educativas. El objetivo principal de TIGRE es diseñar e implementar middleware Grid de última generación que permita la integración de sistemas de computación, sistemas de almacenamiento y bases de datos, laboratorios de visualización y pantallas, e incluso instrumentos y sensores en Texas. El objetivo secundario es demostrar las capacidades de TIGRE para mejorar las oportunidades de investigación y educación en áreas de aplicación estratégica de interés para el Estado de Texas. Estos son biociencia y medicina, exploración energética y modelado de la calidad del aire. La visión del proyecto TIGRE es fomentar la colaboración interdisciplinaria e intercampus, identificar enfoques novedosos para ampliar las asociaciones académicas, gubernamentales y privadas, y convertirse en un modelo competitivo para las oportunidades de financiación externa. El objetivo general de TIGRE es apoyar los intereses de los usuarios locales, universitarios y regionales y ofrecer vías para conectar con proyectos nacionales de Red como Open Science Grid [5] y TeraGrid [6]. Dentro del área de aplicación estratégica de exploración energética, hemos habilitado el enfoque conjunto Kalman Filter (EnKF) [7] para la asimilación de datos en el modelado de reservorios y hemos demostrado la extensibilidad de la aplicación utilizando el entorno TIGRE y el metaprogramador GridWay [8]. En la sección 2 se ofrece una visión general del entorno y las capacidades de TIGRE. La descripción de la aplicación y la necesidad de una metodología EnKF compatible con la cuadrícula figuran en la sección 3. Los detalles de la aplicación y los méritos de nuestro enfoque se examinan en la sección 4. Las conclusiones figuran en la sección 5. Por último, en la sección 6 se documentan las observaciones y la experiencia adquirida. 2. TIGRE ENTORNO El MIddleware TIGRE Grid consiste en un conjunto mínimo de componentes derivados de un subconjunto del Virtual Data Toolkit (VDT) [9] que soporta una variedad de sistemas operativos. El propósito de elegir una pila de software mínima es apoyar las aplicaciones disponibles y simplificar la instalación y distribución de las pilas cliente/servidor en los sitios de TIGRE. Se añadirán componentes adicionales a medida que sean necesarios. El mecanismo de packaging y distribución PacMan [10] se emplea para la instalación y gestión del cliente/servidor TIGRE. El mecanismo de distribución de PacMan implica la recuperación, instalación y a menudo configuración del software empaquetado. Este enfoque permite a los clientes mantener versiones actualizadas y consistentes del software TIGRE. También ayuda a los sitios TIGRE a instalar los componentes necesarios en los recursos distribuidos en los sitios participantes. La pila cliente/servidor TIGRE consiste en una capa de autenticación y autorización, Globus GRAM4-basada en la presentación de trabajos a través de servicios web (las instalaciones de servicios pre-web están disponibles bajo petición). Las herramientas para manejar la generación de proxy de cuadrícula, la transferencia de archivos habilitada para cuadrícula y el inicio de sesión remoto habilitado para cuadrícula son compatibles. A continuación se proporcionan los detalles pertinentes de los servicios y herramientas de TIGRE para la programación y gestión de puestos. 2.1. Autoridad certificadora La infraestructura de seguridad TIGRE incluye una autoridad certificadora (CA) acreditada por la International Grid Trust Federation (IGTF) para emitir X. 509 certificados de usuario y recurso Grid [11]. El Texas Advanced Computing Center (TACC), Universidad de Texas en Austin, es el TIGREs CA compartido. Las instituciones de TIGRE actúan como autoridades de registro (RA) para sus respectivas bases de usuarios locales. Para obtener información actualizada sobre la seguridad de los certificados de usuario y de recursos y sus instrucciones de instalación, véase ref [2]. Los usuarios y hosts de TIGRE son identificados por su distinguido nombre (DN) en su certificado X.509 proporcionado por la CA. Un archivo nativo Grid-mapfile que contiene una lista de DNs autorizados se utiliza para autenticar y autorizar la programación y gestión de trabajos de los usuarios en los recursos del sitio TIGRE. En la Universidad Texas Tech, a los usuarios se les asigna dinámicamente una de las muchas cuentas genéricas. Esto se logra a través del Sistema de Gestión de Usuarios de Red (GUMS) [12]. 2.2. Programación y gestión de empleos El entorno TIGRE apoya la presentación de trabajos basada en GRAM4 a través de servicios web. Los scripts de envío de trabajos se generan usando XML. Los servicios web GRAM traducen los scripts XML en programadores de lotes específicos de grupos de destino como LSF, PBS o SGE. Los protocolos de transferencia de archivos de alto ancho de banda como GridFTP se utilizan para estadificación de archivos dentro y fuera de la máquina de destino. El acceso a hosts remotos para compilar y depurar es sólo a través del servicio GSISSH que requiere autenticación de recursos a través de certificados X.509. La autenticación y autorización de los trabajos de Grid se gestionan mediante la emisión de certificados de Grid a usuarios y anfitriones. Las listas de revocación de certificados (CRL) se actualizan diariamente para mantener altos estándares de seguridad de los servicios de TIGRE Grid. El área de documentación del portal TIGRE [2] proporciona un tutorial de inicio rápido sobre cómo ejecutar trabajos en TIGRE. 2.3. Metascheduler El metascheduler interopera con los programadores de lotes de nivel de cluster (como LSF, PBS) en la gestión general del flujo de trabajo de Grid. En el presente trabajo, hemos empleado el metaprogramador GridWay [8] -un proyecto de incubadora Globus- para programar y gestionar trabajos en TIGRE. El GridWay es un metaprogramador ligero que utiliza plenamente las funcionalidades de Globus. Está diseñado para proporcionar un uso eficiente de los recursos dinámicos de Grid por múltiples usuarios para las infraestructuras de Grid construidas sobre los servicios de Globus. El administrador del sitio TIGRE puede controlar el uso compartido de recursos a través de un potente programador integrado proporcionado por GridWay o ampliando el módulo de programación externa GridWays para proporcionar sus propias políticas de programación. Los usuarios de aplicaciones pueden escribir descripciones de trabajos usando el formato de plantilla de trabajo simple y directo de GridWays (ver Sección 4 para más detalles) o el lenguaje estándar de descripción de la presentación de trabajos (JSDL). Para más detalles sobre la aplicación, véase la sección 4. 2.4. Sistema de Gestión de Servicios al Cliente Un portal TIGRE [2] fue diseñado e implementado para interconectar usuarios y proveedores de recursos. Fue diseñado utilizando GridPort [13] y es mantenido por TACC. El entorno TIGRE es compatible con herramientas de código abierto como el Open Ticket Request System (OTRS) [14] para el servicio de tickets de problemas, y MoinMoin [15] Wiki para la gestión de contenido y conocimiento de TIGRE para educación, extensión y capacitación. Los enlaces para OTRS y Wiki son consumidos por el portal TIGRE [2] - el portal para usuarios y proveedores de recursos. El estado y las cargas de los recursos de TIGRE son monitoreados por el servicio de Repositorio de Información de Puertos Grid (GPIR) del kit de herramientas GridPort [13] que interactúa con el servicio local de monitoreo de carga de clústeres como Ganglia. El GPIR utiliza trabajos de cron en cada recurso para reunir características específicas de los recursos del sitio, tales como trabajos que se ejecutan, en cola y esperando la asignación de recursos. 3. APLICACIÓN ENSEMBLE KALMAN FILTER El objetivo principal de las simulaciones de yacimientos de hidrocarburos es predecir el comportamiento de la producción de yacimientos de petróleo y gas (denominados en lo sucesivo campo) para su desarrollo y gestión óptima. En el modelado de yacimientos, el campo se divide en varios modelos geológicos, como se muestra en la Figura 1. Para una previsión precisa del rendimiento del campo, es necesario conciliar varios modelos geológicos con la respuesta dinámica del campo a través de la coincidencia histórica [16-20]. Gráfico 1 Vista transversal del Campo. Las capas verticales corresponden a diferentes modelos geológicos y los clavos son pozos de aceite cuya información histórica se utilizará para predecir el comportamiento de la producción. (Figura Ref:http://faculty.smu.edu/zchen/research.html). El EnKF es un método de Monte Carlo que trabaja con un conjunto de modelos de embalses. Este método utiliza covarianzas cruzadas [21] entre las mediciones de campo y los parámetros del modelo de reservorio (derivados de varios modelos) para estimar las incertidumbres de predicción. Los parámetros del modelo geológico en el conjunto se actualizan secuencialmente con el objetivo de minimizar las incertidumbres de predicción. La respuesta histórica de la producción del campo durante más de 50 años se utiliza en estas simulaciones. La principal ventaja de EnKF es que puede vincularse fácilmente a cualquier simulador de depósito, y puede asimilar los últimos datos de producción sin necesidad de volver a ejecutar el simulador desde las condiciones iniciales. Investigadores en Texas son grandes suscriptores del paquete de Schlumberger ECLIPSE [22] para simulaciones de reservorios. En el modelado del embalse, cada modelo geológico comprueba una licencia ECLIPSE. La duración de la simulación de la metodología EnKF depende del número de modelos geológicos utilizados, el número de licencias ECLIPSE disponibles, la historia de producción del campo y las incertidumbres propagadas en la correspondencia de la historia. El flujo de trabajo general de EnKF se muestra en la Figura 2. Gráfico 2 Ensemble Kaman Filter Data Assimulation Workflow. Cada sitio tiene licencias L. En START, el proceso maestro/control (programa principal EnKF) lee el archivo de configuración de simulación para el número (N) de modelos y archivos de entrada específicos del modelo. A continuación, N directorios de trabajo se crean para almacenar los archivos de salida. Al final de la iteración, el proceso maestro/control recoge los archivos de salida de los modelos N y las crosscovarianzas de los procesos posteriores [21] para estimar las incertidumbres de predicción. Esta información se utilizará para actualizar modelos (o archivos de entrada) para la siguiente iteración. La simulación continúa hasta agotar las historias de producción. La simulación típica de EnKF con N=50 y historias de campo de 50-60 años, en pasos de tiempo que van de tres meses a un año, toma unas tres semanas en un entorno de computación en serie. En el entorno informático paralelo, no hay comunicación interproceso entre los modelos geológicos en el conjunto. Sin embargo, al final de cada paso del tiempo de simulación, los archivos de salida específicos del modelo deben ser recogidos para analizar covarianzas cruzadas [21] y para preparar el siguiente conjunto de archivos de entrada. Por lo tanto, el modelo maestro-esclavo en el entorno de mensajepassing (MPI) es un paradigma adecuado. En este enfoque, los modelos geológicos son tratados como esclavos y se distribuyen entre los procesadores disponibles. El master Cluster o (TIGRE/GridWay) START Read Configuration File Create N Working Directories Create N Input files Model l Model 2 Model N.. . ECLIPSE in situ Un ECLIPSE in situ B ECLIPSE in situ Z Collect N Model Outputs, Post-process Output files FIN. . . proceso recoge archivos de salida específicos del modelo, analiza y prepara el siguiente conjunto de archivos de entrada para la simulación. Dado que cada modelo geológico comprueba una licencia ECLIPSE, la paralelización de la simulación depende del número de licencias disponibles. Cuando el número de licencias disponible es menor que el número de modelos en el conjunto, uno o más de los nodos del grupo MPI tienen que manejar más de un modelo en serie y, por lo tanto, se tarda más tiempo en completar la simulación. Un Departamento de Ingeniería Petrolera generalmente adquiere 10-15 licencias ECLIPSE, mientras que al menos diez veces más número de licencias sería necesario para simulaciones estándar de la industria. El número de licencias puede incrementarse con la participación de varios departamentos de ingeniería petrolera que apoyan el paquete ECLIPSE. Dado que MPI no se escala muy bien para aplicaciones que involucran clústeres de computación remotos, y para evitar los problemas del firewall con servidores de licencias en todos los dominios administrativos, parece necesario activar el flujo de trabajo de EnKF. Con esta motivación, hemos implementado el flujo de trabajo EnKF habilitado para Grid para el entorno TIGRE y hemos demostrado la paralelización de la aplicación a través de TIGRE usando el metascheduler GridWay. En la siguiente sección figuran más detalles al respecto. 4. DETALLES DE APLICACION Para habilitar Grid-enable el enfoque EnKF, hemos eliminado el código MPI para el procesamiento paralelo y reemplazado por trabajos de N monoprocesador (o sub-trabajos) donde, N es el número de modelos geológicos en el conjunto. Estos sub-trabajos específicos de modelos se distribuyeron a través de sitios TIGRE que soportan el paquete ECLIPSE utilizando el metaprogramador GridWay [8]. Para cada sub-trabajo, hemos construido una plantilla de trabajo GridWay que especifica los archivos ejecutables, de entrada y salida, y los requisitos de recursos. Dado que los recursos de cálculo de TIGRE no se espera que cambien con frecuencia, hemos utilizado la política de descubrimiento de recursos estáticos para GridWay y los sub-trabajos fueron programados dinámicamente a través de los recursos de TIGRE usando GridWay. La Figura 3 representa el archivo de plantilla de subtrabajo para el metaprogramador GridWay. Gráfico 3 Plantilla de subtrabajo GridWay En la Figura 3, REQUISITOS bandera se establece para elegir los recursos que satisfacen los requisitos de la aplicación. En el caso de la aplicación EnKF, por ejemplo, necesitamos recursos que apoyen el paquete ECLIPSE. ARGUMENTS flag especifica el modelo en el conjunto que invocará ECLIPSE en un sitio remoto. INPUT_FILES es preparado por el programa principal de EnKF (o proceso maestro/control) y es transferido por GridWay al sitio remoto donde está desatendido y está preparado para su ejecución. Finalmente, OUTPUT_FILES especifica el nombre y la ubicación donde se escribirán los archivos de salida. Las características de la línea de comandos de GridWay se utilizaron para recopilar y procesar las salidas específicas del modelo para preparar un nuevo conjunto de archivos de entrada. Este paso imita la sincronización del proceso MPI en el modelo maestro-esclavo. Al final de cada iteración, los recursos computacionales y las licencias se devuelven al grupo. La Tabla 1 muestra los sub-trabajos en TIGRE Grid via GridWay usando el comando gwps y para mayor claridad, sólo se mostraron las columnas seleccionadas. USUARIO JID DM EM NOMBRE HOST pingluo 88 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 89 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 90 wrap actv enkf.jt minigar.hp Programación de trabajo a través de TIGRE usando GridWay Metascheduler. DM: Estado de envío, EM: Estado de ejecución, JID es el id de trabajo y HOST corresponde al cluster específico del sitio y su planificador de lotes local. Cuando un trabajo es enviado a GridWay, pasará por una serie de estados de envío (DM) y ejecución (EM). Para DM, los estados incluyen pend(ing), prol(og), wrap(per), epil(og), y hecho. DM=prol significa que el trabajo ha sido programado a un recurso y el directorio de trabajo remoto está en preparación. DM=warp implica que GridWay está ejecutando el envoltorio que a su vez ejecuta la aplicación. DM=epil implica que el trabajo ha terminado de ejecutarse en el sitio remoto y los resultados se están transfiriendo al servidor GridWay. Del mismo modo, cuando EM=pend implica que el trabajo está esperando en la cola para el recurso y el trabajo se está ejecutando cuando EM=actv. Para ver la lista completa de las banderas de mensajes y sus descripciones, consulte la documentación en ref [8]. Hemos demostrado las ejecuciones de EnKF habilitadas para Grid usando GridWay para entorno TIGRE. Los trabajos son tan elegidos que el tiempo de ejecución no supera más de media hora. La simulación incluyó hasta 20 trabajos entre sitios de A&M y TTU con TTU cumpliendo 10 licencias. Para obtener información sobre los recursos, véase el cuadro I. Una de las principales ventajas de la simulación EnKF habilitada por Grid es que tanto los recursos como las licencias se devuelven al grupo al final de cada paso del tiempo de simulación a diferencia del caso de la implementación de MPI donde las licencias y nodos están bloqueados hasta la finalización de la simulación completa. Sin embargo, el hecho de que cada sub-trabajo se programe independientemente a través de GridWay podría posiblemente incurrir en otro retraso de tiempo causado por esperar en la cola para la ejecución en cada paso del tiempo de simulación. Tales retrasos no se esperan EXECUTABLE=runFORWARD NECESIDADES=HOSTNAME=cosmos.tamu.edu  HOSTNAME=antaeus.hpcc.ttu.edu  HOSTNAME=minigar.hpcc.ttu.edu  ARGUMENTOS=001 INPUT_FILES=001.in.tar OUTPUT_FI Hay dos escenarios principales para comparar los enfoques de computación de red y clúster. Escenario I: El cúmulo está muy cargado. El tiempo promedio de espera concebido del trabajo que solicita un gran número de CPUs es generalmente más largo que el tiempo de espera de los trabajos que solicitan una sola CPU. Por lo tanto, el tiempo de espera general podría ser más corto en el enfoque Grid que solicita una sola CPU para cada sub-trabajo muchas veces en comparación con la implementación MPI que requiere un gran número de CPUs en un solo momento. Es evidente que la programación de la cuadrícula es beneficiosa especialmente cuando el clúster está fuertemente cargado y el número solicitado de CPUs para el trabajo del MPI no está fácilmente disponible. Escenario II: El clúster está relativamente menos cargado o disponible en gran medida. Parece que la implementación del MPI es favorable en comparación con la programación de la Rejilla. Sin embargo, la paralelización de la aplicación EnKF depende del número de licencias ECLIPSE e idealmente, el número de licencias debe ser igual al número de modelos en el conjunto. Por lo tanto, si una sola institución no tiene suficiente número de licencias, la disponibilidad del clúster no ayuda tanto como se espera. Dado que el entorno colaborativo, como TIGRE, puede abordar tanto los requisitos de computación como los de recursos de software para la aplicación EnKF, el enfoque compatible con Grid sigue siendo ventajoso sobre la implementación MPI convencional en cualquiera de los escenarios anteriores. 5. CONCLUSIONES Y FUTURO TRABAJO TIGRE es un proyecto de desarrollo de la red de educación superior y su propósito es mantener y ampliar las oportunidades de investigación y educación a través de Texas. Dentro del área de aplicación de exploración energética, hemos habilitado la implementación MPI del conjunto Kalman metodología de asimilación de datos de filtro para la caracterización de reservorios. Esta tarea se llevó a cabo eliminando el código MPI para el procesamiento paralelo y reemplazando con trabajos de un solo procesador uno para cada modelo geológico en el conjunto. Estos trabajos de un solo procesador fueron programados a través de TIGRE a través de GridWay metascheduler. Hemos demostrado que mediante la puesta en común de licencias a través de sitios TIGRE, más modelos geológicos pueden ser manejados en paralelo y por lo tanto concebiblemente mejor precisión de simulación. Este enfoque tiene varias ventajas sobre la implementación de MPI, especialmente cuando un clúster específico del sitio está muy cargado y/o las licencias de número requeridas para la simulación son más que las disponibles en un solo sitio. Hacia el trabajo futuro, sería interesante comparar el tiempo de ejecución entre MPI y las implementaciones de Grid para la aplicación EnKF. Este esfuerzo podría arrojar luz sobre la calidad del servicio (QoS) de los entornos Grid en comparación con la computación de clústers. Otro aspecto de interés en un futuro próximo sería la gestión de recursos de computación y licencia para abordar la gestión de la relación trabajo (o procesador)-licencia. 6. OBSERVACIONES Y MENOS APRENDIZADOS Los esfuerzos que facilitan la red para la aplicación EnKF han proporcionado amplias oportunidades para reunir información sobre la visibilidad y la promesa de los entornos de computación de Grid para el desarrollo y soporte de aplicaciones. Los principales problemas son la seguridad de los datos estándar de la industria y la CV comparable a la computación de clústers. Dado que la investigación de modelado de reservorios involucra datos propietarios del campo, tuvimos que invertir esfuerzos sustanciales inicialmente en educar a los investigadores de aplicaciones sobre la capacidad de los servicios de Grid para apoyar la seguridad de datos estándar de la industria a través de acceso basado en roles y privilegios utilizando el estándar X.509. Con respecto a QoS, los investigadores de aplicaciones esperan niveles de QoS con entornos de cuadrícula. Además, hay una curva de aprendizaje pronunciada en la computación de cuadrícula en comparación con la computación de clúster convencional. Dado que la computación de cuadrícula sigue siendo una tecnología emergente, y abarca varios ámbitos administrativos, la computación de cuadrícula sigue siendo prematura, especialmente en términos del nivel de QoS, aunque ofrece mejores normas de seguridad de los datos en comparación con los grupos de productos básicos. Es nuestra observación que los programas de capacitación y divulgación que comparan y contrastan los entornos de computación de red y clúster serían un enfoque adecuado para mejorar la participación de los usuarios en la computación de red. Este enfoque también ayuda a los usuarios a emparejar sus aplicaciones y habilidades que las cuadrículas pueden ofrecer. En resumen, nuestros esfuerzos a través de TIGRE en la metodología de asimilación de datos de la EnKF demostraron una promesa sustancial en la contratación de investigadores de Ingeniería Petrolera a través de colaboraciones entre campus. Se están realizando esfuerzos para lograr la participación de más escuelas en este esfuerzo. Estos esfuerzos pueden resultar en un aumento de la investigación colaborativa, oportunidades educativas y desarrollo de la fuerza laboral a través de programas de investigación de posgrado/facultad en instituciones TIGRE. 7. AGRADECIMIENTOS Los autores reconocen al Estado de Texas por apoyar el proyecto TIGRE a través del Fondo Empresarial de Texas, y a las Instituciones TIGRE por proporcionar el mecanismo, en el que también participan los autores (Ravi Vadapalli, Taesung Kim y Ping Luo). Los autores agradecen a los investigadores de aplicaciones Prof. Akhil Datta-Gupta de Texas A&M University y Prof. Lloyd Heinze de Texas Tech University por sus discusiones e interés en explotar el entorno TIGRE para ampliar las oportunidades en investigación y desarrollo. 8. REFERENCIAS [1] Foster, I. y Kesselman, C. (eds.) 2004. The Grid: Blueprint for a new computing infraestructura (The Elsevier series in Grid computing) [2] Portal TIGRE: http://tigreportal.hipcat.net [3] Vadapalli, R. Sill, A., Dooley, R., Murray, M., Luo, P., Kim, T., Huang, M., Thyagaraja, K., y Chaffin, Demostración del entorno TIGRE para aplicaciones de cuadrícula habilitadas/adecuadas. 8o IEEE/ACM Int. Conf. on Grid Computing, 19-21 de septiembre, Austin [4] The High Performance Computing cross Texas Consortium http://www.hipcat.net [5] Pordes, R. Petravick, D. Kramer, B. Olson, D. Livny, M. Roy, A. Avery, P. Blackburn, K. Wenaus, T. Würthwein, F. Foster, I. Gar The Open Science Grid, J. Phys Conf Series http://www.iop.org/EJ/abstract/1742-6596/78/1/012057 y http://www.opensciencegrid.org [6] Reed, D.A. 2003. Rejilla, el Teragrid y más allá, Ordenador, vol. 30, no. 1 y http://www.teragrid.org [7] Evensen, G. 2006. Asimilación de datos: El conjunto Kalman Filter, Springer [8] Herrera, J. Huedo, E. Montero, R. S. y Llorente, I. M. 2005. Programación Científica, vol 12, No. 4. pp 317-331 [9] Avery, P. and Foster, I. 2001. El proyecto GriPhyN: Hacia redes virtuales de datos a petaescala, informe técnico GriPhyN-200115 y http://vdt.cs.wisc.edu [10] La guía de documentación e instalación de PacMan http://physics.bu.edu/pacman/htmls [11] Caskey, P. Murray, M. Perez, J. y Sill, A. 2007. Estudios de casos en la gestión de identificación para organizaciones virtuales, EDUCOUSO Southwest Reg. Conf., 21-23 febrero, Austin, TX. http://www.educause.edu/ir/library/pdf/SWR07058.pdf [12] El Sistema de Gestión de Usuarios de Grid (GUMS) https://www.racf.bnl.gov/Facility/GUMS/index.html [13] Thomas, M. y Boisseau, J. 2003. Construyendo portales de computación de cuadrículas: El kit de herramientas para el portal de cuadrículas NPACI, Grid computing: haciendo realidad la infraestructura global, Capítulo 28, Berman, F. Fox, G. Thomas, M. Boisseau, J. y Hey, T. (eds), John Wiley and Sons, Ltd, Chichester [14] Open Ticket Request System http:// 1999. Integración de datos dinámicos en modelos de depósito de alta resolución utilizando coeficientes de sensibilidad basados en la racionalización, Society of Petroleum Engineers (SPE), 4 (4). [17] Emanuel, A. S. y Milliken, W. J. 1998. Historia que combina modelos de diferencias finitas con racionalizaciones 3D, SPE 49000, Proc de la Conf Técnica Anual y Exposición, 2730 de septiembre, Nueva Orleans, LA. [18] Nævdal, G. Johnsen, L.M. Aanonsen, S.I. y Vefring, E.H. 2003. Monitorización de embalses y actualización continua de modelos utilizando Ensemble Kalman Filter, SPE 84372, Proc del Conf Técnico Anual y Exposición, Oct 5-8, Denver, CO. [19] Jafarpour B. y McLaughlin, D.B. 2007. Historia que coincide con un conjunto de filtro Kalman y parametrización discreta de coseno, SPE 108761, Proc de la Conf Técnica Anual y Exposición, 11-14 de noviembre, Anaheim, CA [20] Li, G. y Reynolds, A. C. 2007. Un conjunto iterativo Kalman filtro para la asimilación de datos, SPE 109808, Proc de la SPE Conf y Exposición Técnica Anual, 11-14 de noviembre, Anaheim, CA [21] Arroyo-Negrete, E. Devagowda, D. Datta-Gupta, A. 2006. Simplificar el conjunto asistido Kalman filtro para la actualización rápida y continua del modelo de depósito. Proc de la Int. Oil & Gas Conf and Exhibition, SPE 104255, Dec 5-7, China [22] ECLIPSE Reservoir Engineering Software http://www.slb.com/content/services/software/reseng/index.a sp ",
            "error": []
        },
        "hydrocarbon reservoir simulation": {
            "translated_key": [],
            "translated_annotated_text": "Demostración del conjunto de datos de Kalman Assimulation Method for Reservoir Caracterisation Ravi Vadapalli Centro de computación de alto rendimiento Texas Tech University Lubbock, TX 79409 001-806-742-4350 Ravi.Vadapalli@ttu.edu Ajitabh Kumar Department of Petroleum Engineering Texas A&M University College Station, En este enfoque, se utiliza un conjunto de modelos geológicos y datos de producción de yacimientos de petróleo para predecir la respuesta dinámica de los pozos de petróleo. El software Schlumberger ECLIPSE se utiliza para estas simulaciones. Puesto que los modelos en el conjunto no se comunican, la implementación de mensaje-passing es una buena opción. Cada modelo comprueba una licencia ECLIPSE y, por lo tanto, la paralelización de las simulaciones de reservorio depende de las licencias de número disponibles. Hemos habilitado Grid para el conjunto Kalman metodología de asimilación de datos de filtro para el entorno de computación TIGRE Grid. Al poner en común las licencias y los recursos informáticos en todas las instituciones colaboradoras utilizando el metaprogramador GridWay y el entorno TIGRE, la precisión computacional puede aumentarse al tiempo que se reduce el tiempo de ejecución de la simulación. En este artículo, proporcionamos un relato de nuestros esfuerzos en Gridenabilizar el conjunto Kalman Filter metodología de asimilación de datos. Se examinarán los posibles beneficios de este enfoque, las observaciones y la experiencia adquirida. Categorías y Descriptores sujetos C 2.4 [Sistemas distribuidos]: Aplicaciones distribuidas Términos generales Algoritmos, Diseño, Rendimiento 1. INTRODUCCIÓN La computación de cuadrícula [1] es un paradigma de computación colaborativa emergente para ampliar las capacidades específicas de computación de alto rendimiento (HPC) mucho más allá de los recursos locales. Su importancia se deriva del hecho de que la investigación innovadora en áreas de aplicación estratégicas como la biociencia y la medicina, la exploración de energía y el modelado ambiental involucran componentes interdisciplinarios fuertes y a menudo requieren colaboraciones intercampus y capacidades computacionales más allá de las limitaciones institucionales. The Texas Internet Grid for Research and Education (TIGRE) [2,3] es un proyecto de desarrollo de infraestructuras cibernéticas financiado por el estado, llevado a cabo por cinco grandes sistemas universitarios (Rice, A&M, TTU, UH y UT Austin), llamados colectivamente Instituciones TIGRE. El propósito de TIGRE es crear una red de educación superior para sostener y ampliar las oportunidades de investigación y educación en Texas. TIGRE es un proyecto del consorcio de computación de alto rendimiento en Texas (HiPCAT) [4]. El objetivo de HiPCAT es apoyar tecnologías computacionales avanzadas para mejorar la investigación, el desarrollo y las actividades educativas. El objetivo principal de TIGRE es diseñar e implementar middleware Grid de última generación que permita la integración de sistemas de computación, sistemas de almacenamiento y bases de datos, laboratorios de visualización y pantallas, e incluso instrumentos y sensores en Texas. El objetivo secundario es demostrar las capacidades de TIGRE para mejorar las oportunidades de investigación y educación en áreas de aplicación estratégica de interés para el Estado de Texas. Estos son biociencia y medicina, exploración energética y modelado de la calidad del aire. La visión del proyecto TIGRE es fomentar la colaboración interdisciplinaria e intercampus, identificar enfoques novedosos para ampliar las asociaciones académicas, gubernamentales y privadas, y convertirse en un modelo competitivo para las oportunidades de financiación externa. El objetivo general de TIGRE es apoyar los intereses de los usuarios locales, universitarios y regionales y ofrecer vías para conectar con proyectos nacionales de Red como Open Science Grid [5] y TeraGrid [6]. Dentro del área de aplicación estratégica de exploración energética, hemos habilitado el enfoque conjunto Kalman Filter (EnKF) [7] para la asimilación de datos en el modelado de reservorios y hemos demostrado la extensibilidad de la aplicación utilizando el entorno TIGRE y el metaprogramador GridWay [8]. En la sección 2 se ofrece una visión general del entorno y las capacidades de TIGRE. La descripción de la aplicación y la necesidad de una metodología EnKF compatible con la cuadrícula figuran en la sección 3. Los detalles de la aplicación y los méritos de nuestro enfoque se examinan en la sección 4. Las conclusiones figuran en la sección 5. Por último, en la sección 6 se documentan las observaciones y la experiencia adquirida. 2. TIGRE ENTORNO El MIddleware TIGRE Grid consiste en un conjunto mínimo de componentes derivados de un subconjunto del Virtual Data Toolkit (VDT) [9] que soporta una variedad de sistemas operativos. El propósito de elegir una pila de software mínima es apoyar las aplicaciones disponibles y simplificar la instalación y distribución de las pilas cliente/servidor en los sitios de TIGRE. Se añadirán componentes adicionales a medida que sean necesarios. El mecanismo de packaging y distribución PacMan [10] se emplea para la instalación y gestión del cliente/servidor TIGRE. El mecanismo de distribución de PacMan implica la recuperación, instalación y a menudo configuración del software empaquetado. Este enfoque permite a los clientes mantener versiones actualizadas y consistentes del software TIGRE. También ayuda a los sitios TIGRE a instalar los componentes necesarios en los recursos distribuidos en los sitios participantes. La pila cliente/servidor TIGRE consiste en una capa de autenticación y autorización, Globus GRAM4-basada en la presentación de trabajos a través de servicios web (las instalaciones de servicios pre-web están disponibles bajo petición). Las herramientas para manejar la generación de proxy de cuadrícula, la transferencia de archivos habilitada para cuadrícula y el inicio de sesión remoto habilitado para cuadrícula son compatibles. A continuación se proporcionan los detalles pertinentes de los servicios y herramientas de TIGRE para la programación y gestión de puestos. 2.1. Autoridad certificadora La infraestructura de seguridad TIGRE incluye una autoridad certificadora (CA) acreditada por la International Grid Trust Federation (IGTF) para emitir X. 509 certificados de usuario y recurso Grid [11]. El Texas Advanced Computing Center (TACC), Universidad de Texas en Austin, es el TIGREs CA compartido. Las instituciones de TIGRE actúan como autoridades de registro (RA) para sus respectivas bases de usuarios locales. Para obtener información actualizada sobre la seguridad de los certificados de usuario y de recursos y sus instrucciones de instalación, véase ref [2]. Los usuarios y hosts de TIGRE son identificados por su distinguido nombre (DN) en su certificado X.509 proporcionado por la CA. Un archivo nativo Grid-mapfile que contiene una lista de DNs autorizados se utiliza para autenticar y autorizar la programación y gestión de trabajos de los usuarios en los recursos del sitio TIGRE. En la Universidad Texas Tech, a los usuarios se les asigna dinámicamente una de las muchas cuentas genéricas. Esto se logra a través del Sistema de Gestión de Usuarios de Red (GUMS) [12]. 2.2. Programación y gestión de empleos El entorno TIGRE apoya la presentación de trabajos basada en GRAM4 a través de servicios web. Los scripts de envío de trabajos se generan usando XML. Los servicios web GRAM traducen los scripts XML en programadores de lotes específicos de grupos de destino como LSF, PBS o SGE. Los protocolos de transferencia de archivos de alto ancho de banda como GridFTP se utilizan para estadificación de archivos dentro y fuera de la máquina de destino. El acceso a hosts remotos para compilar y depurar es sólo a través del servicio GSISSH que requiere autenticación de recursos a través de certificados X.509. La autenticación y autorización de los trabajos de Grid se gestionan mediante la emisión de certificados de Grid a usuarios y anfitriones. Las listas de revocación de certificados (CRL) se actualizan diariamente para mantener altos estándares de seguridad de los servicios de TIGRE Grid. El área de documentación del portal TIGRE [2] proporciona un tutorial de inicio rápido sobre cómo ejecutar trabajos en TIGRE. 2.3. Metascheduler El metascheduler interopera con los programadores de lotes de nivel de cluster (como LSF, PBS) en la gestión general del flujo de trabajo de Grid. En el presente trabajo, hemos empleado el metaprogramador GridWay [8] -un proyecto de incubadora Globus- para programar y gestionar trabajos en TIGRE. El GridWay es un metaprogramador ligero que utiliza plenamente las funcionalidades de Globus. Está diseñado para proporcionar un uso eficiente de los recursos dinámicos de Grid por múltiples usuarios para las infraestructuras de Grid construidas sobre los servicios de Globus. El administrador del sitio TIGRE puede controlar el uso compartido de recursos a través de un potente programador integrado proporcionado por GridWay o ampliando el módulo de programación externa GridWays para proporcionar sus propias políticas de programación. Los usuarios de aplicaciones pueden escribir descripciones de trabajos usando el formato de plantilla de trabajo simple y directo de GridWays (ver Sección 4 para más detalles) o el lenguaje estándar de descripción de la presentación de trabajos (JSDL). Para más detalles sobre la aplicación, véase la sección 4. 2.4. Sistema de Gestión de Servicios al Cliente Un portal TIGRE [2] fue diseñado e implementado para interconectar usuarios y proveedores de recursos. Fue diseñado utilizando GridPort [13] y es mantenido por TACC. El entorno TIGRE es compatible con herramientas de código abierto como el Open Ticket Request System (OTRS) [14] para el servicio de tickets de problemas, y MoinMoin [15] Wiki para la gestión de contenido y conocimiento de TIGRE para educación, extensión y capacitación. Los enlaces para OTRS y Wiki son consumidos por el portal TIGRE [2] - el portal para usuarios y proveedores de recursos. El estado y las cargas de los recursos de TIGRE son monitoreados por el servicio de Repositorio de Información de Puertos Grid (GPIR) del kit de herramientas GridPort [13] que interactúa con el servicio local de monitoreo de carga de clústeres como Ganglia. El GPIR utiliza trabajos de cron en cada recurso para reunir características específicas de los recursos del sitio, tales como trabajos que se ejecutan, en cola y esperando la asignación de recursos. 3. APLICACIÓN ENSEMBLE KALMAN FILTER El objetivo principal de las simulaciones de yacimientos de hidrocarburos es predecir el comportamiento de la producción de yacimientos de petróleo y gas (denominados en lo sucesivo campo) para su desarrollo y gestión óptima. En el modelado de yacimientos, el campo se divide en varios modelos geológicos, como se muestra en la Figura 1. Para una previsión precisa del rendimiento del campo, es necesario conciliar varios modelos geológicos con la respuesta dinámica del campo a través de la coincidencia histórica [16-20]. Gráfico 1 Vista transversal del Campo. Las capas verticales corresponden a diferentes modelos geológicos y los clavos son pozos de aceite cuya información histórica se utilizará para predecir el comportamiento de la producción. (Figura Ref:http://faculty.smu.edu/zchen/research.html). El EnKF es un método de Monte Carlo que trabaja con un conjunto de modelos de embalses. Este método utiliza covarianzas cruzadas [21] entre las mediciones de campo y los parámetros del modelo de reservorio (derivados de varios modelos) para estimar las incertidumbres de predicción. Los parámetros del modelo geológico en el conjunto se actualizan secuencialmente con el objetivo de minimizar las incertidumbres de predicción. La respuesta histórica de la producción del campo durante más de 50 años se utiliza en estas simulaciones. La principal ventaja de EnKF es que puede vincularse fácilmente a cualquier simulador de depósito, y puede asimilar los últimos datos de producción sin necesidad de volver a ejecutar el simulador desde las condiciones iniciales. Investigadores en Texas son grandes suscriptores del paquete de Schlumberger ECLIPSE [22] para simulaciones de reservorios. En el modelado del embalse, cada modelo geológico comprueba una licencia ECLIPSE. La duración de la simulación de la metodología EnKF depende del número de modelos geológicos utilizados, el número de licencias ECLIPSE disponibles, la historia de producción del campo y las incertidumbres propagadas en la correspondencia de la historia. El flujo de trabajo general de EnKF se muestra en la Figura 2. Gráfico 2 Ensemble Kaman Filter Data Assimulation Workflow. Cada sitio tiene licencias L. En START, el proceso maestro/control (programa principal EnKF) lee el archivo de configuración de simulación para el número (N) de modelos y archivos de entrada específicos del modelo. A continuación, N directorios de trabajo se crean para almacenar los archivos de salida. Al final de la iteración, el proceso maestro/control recoge los archivos de salida de los modelos N y las crosscovarianzas de los procesos posteriores [21] para estimar las incertidumbres de predicción. Esta información se utilizará para actualizar modelos (o archivos de entrada) para la siguiente iteración. La simulación continúa hasta agotar las historias de producción. La simulación típica de EnKF con N=50 y historias de campo de 50-60 años, en pasos de tiempo que van de tres meses a un año, toma unas tres semanas en un entorno de computación en serie. En el entorno informático paralelo, no hay comunicación interproceso entre los modelos geológicos en el conjunto. Sin embargo, al final de cada paso del tiempo de simulación, los archivos de salida específicos del modelo deben ser recogidos para analizar covarianzas cruzadas [21] y para preparar el siguiente conjunto de archivos de entrada. Por lo tanto, el modelo maestro-esclavo en el entorno de mensajepassing (MPI) es un paradigma adecuado. En este enfoque, los modelos geológicos son tratados como esclavos y se distribuyen entre los procesadores disponibles. El master Cluster o (TIGRE/GridWay) START Read Configuration File Create N Working Directories Create N Input files Model l Model 2 Model N.. . ECLIPSE in situ Un ECLIPSE in situ B ECLIPSE in situ Z Collect N Model Outputs, Post-process Output files FIN. . . proceso recoge archivos de salida específicos del modelo, analiza y prepara el siguiente conjunto de archivos de entrada para la simulación. Dado que cada modelo geológico comprueba una licencia ECLIPSE, la paralelización de la simulación depende del número de licencias disponibles. Cuando el número de licencias disponible es menor que el número de modelos en el conjunto, uno o más de los nodos del grupo MPI tienen que manejar más de un modelo en serie y, por lo tanto, se tarda más tiempo en completar la simulación. Un Departamento de Ingeniería Petrolera generalmente adquiere 10-15 licencias ECLIPSE, mientras que al menos diez veces más número de licencias sería necesario para simulaciones estándar de la industria. El número de licencias puede incrementarse con la participación de varios departamentos de ingeniería petrolera que apoyan el paquete ECLIPSE. Dado que MPI no se escala muy bien para aplicaciones que involucran clústeres de computación remotos, y para evitar los problemas del firewall con servidores de licencias en todos los dominios administrativos, parece necesario activar el flujo de trabajo de EnKF. Con esta motivación, hemos implementado el flujo de trabajo EnKF habilitado para Grid para el entorno TIGRE y hemos demostrado la paralelización de la aplicación a través de TIGRE usando el metascheduler GridWay. En la siguiente sección figuran más detalles al respecto. 4. DETALLES DE APLICACION Para habilitar Grid-enable el enfoque EnKF, hemos eliminado el código MPI para el procesamiento paralelo y reemplazado por trabajos de N monoprocesador (o sub-trabajos) donde, N es el número de modelos geológicos en el conjunto. Estos sub-trabajos específicos de modelos se distribuyeron a través de sitios TIGRE que soportan el paquete ECLIPSE utilizando el metaprogramador GridWay [8]. Para cada sub-trabajo, hemos construido una plantilla de trabajo GridWay que especifica los archivos ejecutables, de entrada y salida, y los requisitos de recursos. Dado que los recursos de cálculo de TIGRE no se espera que cambien con frecuencia, hemos utilizado la política de descubrimiento de recursos estáticos para GridWay y los sub-trabajos fueron programados dinámicamente a través de los recursos de TIGRE usando GridWay. La Figura 3 representa el archivo de plantilla de subtrabajo para el metaprogramador GridWay. Gráfico 3 Plantilla de subtrabajo GridWay En la Figura 3, REQUISITOS bandera se establece para elegir los recursos que satisfacen los requisitos de la aplicación. En el caso de la aplicación EnKF, por ejemplo, necesitamos recursos que apoyen el paquete ECLIPSE. ARGUMENTS flag especifica el modelo en el conjunto que invocará ECLIPSE en un sitio remoto. INPUT_FILES es preparado por el programa principal de EnKF (o proceso maestro/control) y es transferido por GridWay al sitio remoto donde está desatendido y está preparado para su ejecución. Finalmente, OUTPUT_FILES especifica el nombre y la ubicación donde se escribirán los archivos de salida. Las características de la línea de comandos de GridWay se utilizaron para recopilar y procesar las salidas específicas del modelo para preparar un nuevo conjunto de archivos de entrada. Este paso imita la sincronización del proceso MPI en el modelo maestro-esclavo. Al final de cada iteración, los recursos computacionales y las licencias se devuelven al grupo. La Tabla 1 muestra los sub-trabajos en TIGRE Grid via GridWay usando el comando gwps y para mayor claridad, sólo se mostraron las columnas seleccionadas. USUARIO JID DM EM NOMBRE HOST pingluo 88 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 89 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 90 wrap actv enkf.jt minigar.hp Programación de trabajo a través de TIGRE usando GridWay Metascheduler. DM: Estado de envío, EM: Estado de ejecución, JID es el id de trabajo y HOST corresponde al cluster específico del sitio y su planificador de lotes local. Cuando un trabajo es enviado a GridWay, pasará por una serie de estados de envío (DM) y ejecución (EM). Para DM, los estados incluyen pend(ing), prol(og), wrap(per), epil(og), y hecho. DM=prol significa que el trabajo ha sido programado a un recurso y el directorio de trabajo remoto está en preparación. DM=warp implica que GridWay está ejecutando el envoltorio que a su vez ejecuta la aplicación. DM=epil implica que el trabajo ha terminado de ejecutarse en el sitio remoto y los resultados se están transfiriendo al servidor GridWay. Del mismo modo, cuando EM=pend implica que el trabajo está esperando en la cola para el recurso y el trabajo se está ejecutando cuando EM=actv. Para ver la lista completa de las banderas de mensajes y sus descripciones, consulte la documentación en ref [8]. Hemos demostrado las ejecuciones de EnKF habilitadas para Grid usando GridWay para entorno TIGRE. Los trabajos son tan elegidos que el tiempo de ejecución no supera más de media hora. La simulación incluyó hasta 20 trabajos entre sitios de A&M y TTU con TTU cumpliendo 10 licencias. Para obtener información sobre los recursos, véase el cuadro I. Una de las principales ventajas de la simulación EnKF habilitada por Grid es que tanto los recursos como las licencias se devuelven al grupo al final de cada paso del tiempo de simulación a diferencia del caso de la implementación de MPI donde las licencias y nodos están bloqueados hasta la finalización de la simulación completa. Sin embargo, el hecho de que cada sub-trabajo se programe independientemente a través de GridWay podría posiblemente incurrir en otro retraso de tiempo causado por esperar en la cola para la ejecución en cada paso del tiempo de simulación. Tales retrasos no se esperan EXECUTABLE=runFORWARD NECESIDADES=HOSTNAME=cosmos.tamu.edu  HOSTNAME=antaeus.hpcc.ttu.edu  HOSTNAME=minigar.hpcc.ttu.edu  ARGUMENTOS=001 INPUT_FILES=001.in.tar OUTPUT_FI Hay dos escenarios principales para comparar los enfoques de computación de red y clúster. Escenario I: El cúmulo está muy cargado. El tiempo promedio de espera concebido del trabajo que solicita un gran número de CPUs es generalmente más largo que el tiempo de espera de los trabajos que solicitan una sola CPU. Por lo tanto, el tiempo de espera general podría ser más corto en el enfoque Grid que solicita una sola CPU para cada sub-trabajo muchas veces en comparación con la implementación MPI que requiere un gran número de CPUs en un solo momento. Es evidente que la programación de la cuadrícula es beneficiosa especialmente cuando el clúster está fuertemente cargado y el número solicitado de CPUs para el trabajo del MPI no está fácilmente disponible. Escenario II: El clúster está relativamente menos cargado o disponible en gran medida. Parece que la implementación del MPI es favorable en comparación con la programación de la Rejilla. Sin embargo, la paralelización de la aplicación EnKF depende del número de licencias ECLIPSE e idealmente, el número de licencias debe ser igual al número de modelos en el conjunto. Por lo tanto, si una sola institución no tiene suficiente número de licencias, la disponibilidad del clúster no ayuda tanto como se espera. Dado que el entorno colaborativo, como TIGRE, puede abordar tanto los requisitos de computación como los de recursos de software para la aplicación EnKF, el enfoque compatible con Grid sigue siendo ventajoso sobre la implementación MPI convencional en cualquiera de los escenarios anteriores. 5. CONCLUSIONES Y FUTURO TRABAJO TIGRE es un proyecto de desarrollo de la red de educación superior y su propósito es mantener y ampliar las oportunidades de investigación y educación a través de Texas. Dentro del área de aplicación de exploración energética, hemos habilitado la implementación MPI del conjunto Kalman metodología de asimilación de datos de filtro para la caracterización de reservorios. Esta tarea se llevó a cabo eliminando el código MPI para el procesamiento paralelo y reemplazando con trabajos de un solo procesador uno para cada modelo geológico en el conjunto. Estos trabajos de un solo procesador fueron programados a través de TIGRE a través de GridWay metascheduler. Hemos demostrado que mediante la puesta en común de licencias a través de sitios TIGRE, más modelos geológicos pueden ser manejados en paralelo y por lo tanto concebiblemente mejor precisión de simulación. Este enfoque tiene varias ventajas sobre la implementación de MPI, especialmente cuando un clúster específico del sitio está muy cargado y/o las licencias de número requeridas para la simulación son más que las disponibles en un solo sitio. Hacia el trabajo futuro, sería interesante comparar el tiempo de ejecución entre MPI y las implementaciones de Grid para la aplicación EnKF. Este esfuerzo podría arrojar luz sobre la calidad del servicio (QoS) de los entornos Grid en comparación con la computación de clústers. Otro aspecto de interés en un futuro próximo sería la gestión de recursos de computación y licencia para abordar la gestión de la relación trabajo (o procesador)-licencia. 6. OBSERVACIONES Y MENOS APRENDIZADOS Los esfuerzos que facilitan la red para la aplicación EnKF han proporcionado amplias oportunidades para reunir información sobre la visibilidad y la promesa de los entornos de computación de Grid para el desarrollo y soporte de aplicaciones. Los principales problemas son la seguridad de los datos estándar de la industria y la CV comparable a la computación de clústers. Dado que la investigación de modelado de reservorios involucra datos propietarios del campo, tuvimos que invertir esfuerzos sustanciales inicialmente en educar a los investigadores de aplicaciones sobre la capacidad de los servicios de Grid para apoyar la seguridad de datos estándar de la industria a través de acceso basado en roles y privilegios utilizando el estándar X.509. Con respecto a QoS, los investigadores de aplicaciones esperan niveles de QoS con entornos de cuadrícula. Además, hay una curva de aprendizaje pronunciada en la computación de cuadrícula en comparación con la computación de clúster convencional. Dado que la computación de cuadrícula sigue siendo una tecnología emergente, y abarca varios ámbitos administrativos, la computación de cuadrícula sigue siendo prematura, especialmente en términos del nivel de QoS, aunque ofrece mejores normas de seguridad de los datos en comparación con los grupos de productos básicos. Es nuestra observación que los programas de capacitación y divulgación que comparan y contrastan los entornos de computación de red y clúster serían un enfoque adecuado para mejorar la participación de los usuarios en la computación de red. Este enfoque también ayuda a los usuarios a emparejar sus aplicaciones y habilidades que las cuadrículas pueden ofrecer. En resumen, nuestros esfuerzos a través de TIGRE en la metodología de asimilación de datos de la EnKF demostraron una promesa sustancial en la contratación de investigadores de Ingeniería Petrolera a través de colaboraciones entre campus. Se están realizando esfuerzos para lograr la participación de más escuelas en este esfuerzo. Estos esfuerzos pueden resultar en un aumento de la investigación colaborativa, oportunidades educativas y desarrollo de la fuerza laboral a través de programas de investigación de posgrado/facultad en instituciones TIGRE. 7. AGRADECIMIENTOS Los autores reconocen al Estado de Texas por apoyar el proyecto TIGRE a través del Fondo Empresarial de Texas, y a las Instituciones TIGRE por proporcionar el mecanismo, en el que también participan los autores (Ravi Vadapalli, Taesung Kim y Ping Luo). Los autores agradecen a los investigadores de aplicaciones Prof. Akhil Datta-Gupta de Texas A&M University y Prof. Lloyd Heinze de Texas Tech University por sus discusiones e interés en explotar el entorno TIGRE para ampliar las oportunidades en investigación y desarrollo. 8. REFERENCIAS [1] Foster, I. y Kesselman, C. (eds.) 2004. The Grid: Blueprint for a new computing infraestructura (The Elsevier series in Grid computing) [2] Portal TIGRE: http://tigreportal.hipcat.net [3] Vadapalli, R. Sill, A., Dooley, R., Murray, M., Luo, P., Kim, T., Huang, M., Thyagaraja, K., y Chaffin, Demostración del entorno TIGRE para aplicaciones de cuadrícula habilitadas/adecuadas. 8o IEEE/ACM Int. Conf. on Grid Computing, 19-21 de septiembre, Austin [4] The High Performance Computing cross Texas Consortium http://www.hipcat.net [5] Pordes, R. Petravick, D. Kramer, B. Olson, D. Livny, M. Roy, A. Avery, P. Blackburn, K. Wenaus, T. Würthwein, F. Foster, I. Gar The Open Science Grid, J. Phys Conf Series http://www.iop.org/EJ/abstract/1742-6596/78/1/012057 y http://www.opensciencegrid.org [6] Reed, D.A. 2003. Rejilla, el Teragrid y más allá, Ordenador, vol. 30, no. 1 y http://www.teragrid.org [7] Evensen, G. 2006. Asimilación de datos: El conjunto Kalman Filter, Springer [8] Herrera, J. Huedo, E. Montero, R. S. y Llorente, I. M. 2005. Programación Científica, vol 12, No. 4. pp 317-331 [9] Avery, P. and Foster, I. 2001. El proyecto GriPhyN: Hacia redes virtuales de datos a petaescala, informe técnico GriPhyN-200115 y http://vdt.cs.wisc.edu [10] La guía de documentación e instalación de PacMan http://physics.bu.edu/pacman/htmls [11] Caskey, P. Murray, M. Perez, J. y Sill, A. 2007. Estudios de casos en la gestión de identificación para organizaciones virtuales, EDUCOUSO Southwest Reg. Conf., 21-23 febrero, Austin, TX. http://www.educause.edu/ir/library/pdf/SWR07058.pdf [12] El Sistema de Gestión de Usuarios de Grid (GUMS) https://www.racf.bnl.gov/Facility/GUMS/index.html [13] Thomas, M. y Boisseau, J. 2003. Construyendo portales de computación de cuadrículas: El kit de herramientas para el portal de cuadrículas NPACI, Grid computing: haciendo realidad la infraestructura global, Capítulo 28, Berman, F. Fox, G. Thomas, M. Boisseau, J. y Hey, T. (eds), John Wiley and Sons, Ltd, Chichester [14] Open Ticket Request System http:// 1999. Integración de datos dinámicos en modelos de depósito de alta resolución utilizando coeficientes de sensibilidad basados en la racionalización, Society of Petroleum Engineers (SPE), 4 (4). [17] Emanuel, A. S. y Milliken, W. J. 1998. Historia que combina modelos de diferencias finitas con racionalizaciones 3D, SPE 49000, Proc de la Conf Técnica Anual y Exposición, 2730 de septiembre, Nueva Orleans, LA. [18] Nævdal, G. Johnsen, L.M. Aanonsen, S.I. y Vefring, E.H. 2003. Monitorización de embalses y actualización continua de modelos utilizando Ensemble Kalman Filter, SPE 84372, Proc del Conf Técnico Anual y Exposición, Oct 5-8, Denver, CO. [19] Jafarpour B. y McLaughlin, D.B. 2007. Historia que coincide con un conjunto de filtro Kalman y parametrización discreta de coseno, SPE 108761, Proc de la Conf Técnica Anual y Exposición, 11-14 de noviembre, Anaheim, CA [20] Li, G. y Reynolds, A. C. 2007. Un conjunto iterativo Kalman filtro para la asimilación de datos, SPE 109808, Proc de la SPE Conf y Exposición Técnica Anual, 11-14 de noviembre, Anaheim, CA [21] Arroyo-Negrete, E. Devagowda, D. Datta-Gupta, A. 2006. Simplificar el conjunto asistido Kalman filtro para la actualización rápida y continua del modelo de depósito. Proc de la Int. Oil & Gas Conf and Exhibition, SPE 104255, Dec 5-7, China [22] ECLIPSE Reservoir Engineering Software http://www.slb.com/content/services/software/reseng/index.a sp ",
            "error": []
        },
        "energy exploration": {
            "translated_key": "exploración de energía",
            "translated_annotated_text": "Demostración de la metodología de asimilación de los datos del filtro de Kalman en el conjunto de la red ABSTRACOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOMECOM En este enfoque, se utiliza un conjunto de modelos geológicos y datos de producción de yacimientos de petróleo para predecir la respuesta dinámica de los pozos de petróleo. El software Schlumberger ECLIPSE se utiliza para estas simulaciones. Puesto que los modelos en el conjunto no se comunican, la implementación de mensaje-passing es una buena opción. Cada modelo comprueba una licencia ECLIPSE y, por lo tanto, la paralelización de las simulaciones de reservorio depende de las licencias de número disponibles. Hemos habilitado Grid para el conjunto Kalman metodología de asimilación de datos de filtro para el entorno de computación TIGRE Grid. Al poner en común las licencias y los recursos informáticos en todas las instituciones colaboradoras utilizando el metaprogramador GridWay y el entorno TIGRE, la precisión computacional puede aumentarse al tiempo que se reduce el tiempo de ejecución de la simulación. En este artículo, proporcionamos un relato de nuestros esfuerzos en Gridenabilizar el conjunto Kalman Filter metodología de asimilación de datos. Se examinarán los posibles beneficios de este enfoque, las observaciones y la experiencia adquirida. Categorías y Descriptores sujetos C 2.4 [Sistemas distribuidos]: Aplicaciones distribuidas Términos generales Algoritmos, Diseño, Rendimiento 1. INTRODUCCIÓN La computación de cuadrícula [1] es un paradigma de computación colaborativa emergente para ampliar las capacidades específicas de computación de alto rendimiento (HPC) mucho más allá de los recursos locales. Su importancia se deriva del hecho de que la investigación innovadora en áreas de aplicación estratégicas como la biociencia y la medicina, la \"exploración de energía\" y el modelado ambiental involucran fuertes componentes interdisciplinarios y a menudo requieren colaboraciones intercampus y capacidades computacionales más allá de las limitaciones institucionales. The Texas Internet Grid for Research and Education (TIGRE) [2,3] es un proyecto de desarrollo de infraestructuras cibernéticas financiado por el estado, llevado a cabo por cinco grandes sistemas universitarios (Rice, A&M, TTU, UH y UT Austin), llamados colectivamente Instituciones TIGRE. El propósito de TIGRE es crear una red de educación superior para sostener y ampliar las oportunidades de investigación y educación en Texas. TIGRE es un proyecto del consorcio de computación de alto rendimiento en Texas (HiPCAT) [4]. El objetivo de HiPCAT es apoyar tecnologías computacionales avanzadas para mejorar la investigación, el desarrollo y las actividades educativas. El objetivo principal de TIGRE es diseñar e implementar middleware Grid de última generación que permita la integración de sistemas de computación, sistemas de almacenamiento y bases de datos, laboratorios de visualización y pantallas, e incluso instrumentos y sensores en Texas. El objetivo secundario es demostrar las capacidades de TIGRE para mejorar las oportunidades de investigación y educación en áreas de aplicación estratégica de interés para el Estado de Texas. Estos son la biociencia y la medicina, la \"exploración de energía\" y el modelado de la calidad del aire. La visión del proyecto TIGRE es fomentar la colaboración interdisciplinaria e intercampus, identificar enfoques novedosos para ampliar las asociaciones académicas, gubernamentales y privadas, y convertirse en un modelo competitivo para las oportunidades de financiación externa. El objetivo general de TIGRE es apoyar los intereses de los usuarios locales, universitarios y regionales y ofrecer vías para conectar con proyectos nacionales de Red como Open Science Grid [5] y TeraGrid [6]. Dentro del área de aplicación estratégica de \"exploración de energía\", hemos habilitado el enfoque conjunto Kalman Filter (EnKF) [7] para la asimilación de datos en el modelado de reservorios y hemos demostrado la extensibilidad de la aplicación utilizando el entorno TIGRE y el metaprogramador GridWay [8]. En la sección 2 se ofrece una visión general del entorno y las capacidades de TIGRE. La descripción de la aplicación y la necesidad de una metodología EnKF compatible con la cuadrícula figuran en la sección 3. Los detalles de la aplicación y los méritos de nuestro enfoque se examinan en la sección 4. Las conclusiones figuran en la sección 5. Por último, en la sección 6 se documentan las observaciones y la experiencia adquirida. 2. TIGRE ENTORNO El MIddleware TIGRE Grid consiste en un conjunto mínimo de componentes derivados de un subconjunto del Virtual Data Toolkit (VDT) [9] que soporta una variedad de sistemas operativos. El propósito de elegir una pila de software mínima es apoyar las aplicaciones disponibles y simplificar la instalación y distribución de las pilas cliente/servidor en los sitios de TIGRE. Se añadirán componentes adicionales a medida que sean necesarios. El mecanismo de packaging y distribución PacMan [10] se emplea para la instalación y gestión del cliente/servidor TIGRE. El mecanismo de distribución de PacMan implica la recuperación, instalación y a menudo configuración del software empaquetado. Este enfoque permite a los clientes mantener versiones actualizadas y consistentes del software TIGRE. También ayuda a los sitios TIGRE a instalar los componentes necesarios en los recursos distribuidos en los sitios participantes. La pila cliente/servidor TIGRE consiste en una capa de autenticación y autorización, Globus GRAM4-basada en la presentación de trabajos a través de servicios web (las instalaciones de servicios pre-web están disponibles bajo petición). Las herramientas para manejar la generación de proxy de cuadrícula, la transferencia de archivos habilitada para cuadrícula y el inicio de sesión remoto habilitado para cuadrícula son compatibles. A continuación se proporcionan los detalles pertinentes de los servicios y herramientas de TIGRE para la programación y gestión de puestos. 2.1. Autoridad certificadora La infraestructura de seguridad TIGRE incluye una autoridad certificadora (CA) acreditada por la International Grid Trust Federation (IGTF) para emitir X. 509 certificados de usuario y recurso Grid [11]. El Texas Advanced Computing Center (TACC), Universidad de Texas en Austin, es el TIGREs CA compartido. Las instituciones de TIGRE actúan como autoridades de registro (RA) para sus respectivas bases de usuarios locales. Para obtener información actualizada sobre la seguridad de los certificados de usuario y de recursos y sus instrucciones de instalación, véase ref [2]. Los usuarios y hosts de TIGRE son identificados por su distinguido nombre (DN) en su certificado X.509 proporcionado por la CA. Un archivo nativo Grid-mapfile que contiene una lista de DNs autorizados se utiliza para autenticar y autorizar la programación y gestión de trabajos de los usuarios en los recursos del sitio TIGRE. En la Universidad Texas Tech, a los usuarios se les asigna dinámicamente una de las muchas cuentas genéricas. Esto se logra a través del Sistema de Gestión de Usuarios de Red (GUMS) [12]. 2.2. Programación y gestión de empleos El entorno TIGRE apoya la presentación de trabajos basada en GRAM4 a través de servicios web. Los scripts de envío de trabajos se generan usando XML. Los servicios web GRAM traducen los scripts XML en programadores de lotes específicos de grupos de destino como LSF, PBS o SGE. Los protocolos de transferencia de archivos de alto ancho de banda como GridFTP se utilizan para estadificación de archivos dentro y fuera de la máquina de destino. El acceso a hosts remotos para compilar y depurar es sólo a través del servicio GSISSH que requiere autenticación de recursos a través de certificados X.509. La autenticación y autorización de los trabajos de Grid se gestionan mediante la emisión de certificados de Grid a usuarios y anfitriones. Las listas de revocación de certificados (CRL) se actualizan diariamente para mantener altos estándares de seguridad de los servicios de TIGRE Grid. El área de documentación del portal TIGRE [2] proporciona un tutorial de inicio rápido sobre cómo ejecutar trabajos en TIGRE. 2.3. Metascheduler El metascheduler interopera con los programadores de lotes de nivel de cluster (como LSF, PBS) en la gestión general del flujo de trabajo de Grid. En el presente trabajo, hemos empleado el metaprogramador GridWay [8] -un proyecto de incubadora Globus- para programar y gestionar trabajos en TIGRE. El GridWay es un metaprogramador ligero que utiliza plenamente las funcionalidades de Globus. Está diseñado para proporcionar un uso eficiente de los recursos dinámicos de Grid por múltiples usuarios para las infraestructuras de Grid construidas sobre los servicios de Globus. El administrador del sitio TIGRE puede controlar el uso compartido de recursos a través de un potente programador integrado proporcionado por GridWay o ampliando el módulo de programación externa GridWays para proporcionar sus propias políticas de programación. Los usuarios de aplicaciones pueden escribir descripciones de trabajos usando el formato de plantilla de trabajo simple y directo de GridWays (ver Sección 4 para más detalles) o el lenguaje estándar de descripción de la presentación de trabajos (JSDL). Para más detalles sobre la aplicación, véase la sección 4. 2.4. Sistema de Gestión de Servicios al Cliente Un portal TIGRE [2] fue diseñado e implementado para interconectar usuarios y proveedores de recursos. Fue diseñado utilizando GridPort [13] y es mantenido por TACC. El entorno TIGRE es compatible con herramientas de código abierto como el Open Ticket Request System (OTRS) [14] para el servicio de tickets de problemas, y MoinMoin [15] Wiki para la gestión de contenido y conocimiento de TIGRE para educación, extensión y capacitación. Los enlaces para OTRS y Wiki son consumidos por el portal TIGRE [2] - el portal para usuarios y proveedores de recursos. El estado y las cargas de los recursos de TIGRE son monitoreados por el servicio de Repositorio de Información de Puertos Grid (GPIR) del kit de herramientas GridPort [13] que interactúa con el servicio local de monitoreo de carga de clústeres como Ganglia. El GPIR utiliza trabajos de cron en cada recurso para reunir características específicas de los recursos del sitio, tales como trabajos que se ejecutan, en cola y esperando la asignación de recursos. 3. APLICACIÓN ENSEMBLE KALMAN FILTER El objetivo principal de las simulaciones de yacimientos de hidrocarburos es predecir el comportamiento de la producción de yacimientos de petróleo y gas (denominados en lo sucesivo campo) para su desarrollo y gestión óptima. En el modelado de yacimientos, el campo se divide en varios modelos geológicos, como se muestra en la Figura 1. Para una previsión precisa del rendimiento del campo, es necesario conciliar varios modelos geológicos con la respuesta dinámica del campo a través de la coincidencia histórica [16-20]. Gráfico 1 Vista transversal del Campo. Las capas verticales corresponden a diferentes modelos geológicos y los clavos son pozos de aceite cuya información histórica se utilizará para predecir el comportamiento de la producción. (Figura Ref:http://faculty.smu.edu/zchen/research.html). El EnKF es un método de Monte Carlo que trabaja con un conjunto de modelos de embalses. Este método utiliza covarianzas cruzadas [21] entre las mediciones de campo y los parámetros del modelo de reservorio (derivados de varios modelos) para estimar las incertidumbres de predicción. Los parámetros del modelo geológico en el conjunto se actualizan secuencialmente con el objetivo de minimizar las incertidumbres de predicción. La respuesta histórica de la producción del campo durante más de 50 años se utiliza en estas simulaciones. La principal ventaja de EnKF es que puede vincularse fácilmente a cualquier simulador de depósito, y puede asimilar los últimos datos de producción sin necesidad de volver a ejecutar el simulador desde las condiciones iniciales. Investigadores en Texas son grandes suscriptores del paquete de Schlumberger ECLIPSE [22] para simulaciones de reservorios. En el modelado del embalse, cada modelo geológico comprueba una licencia ECLIPSE. La duración de la simulación de la metodología EnKF depende del número de modelos geológicos utilizados, el número de licencias ECLIPSE disponibles, la historia de producción del campo y las incertidumbres propagadas en la correspondencia de la historia. El flujo de trabajo general de EnKF se muestra en la Figura 2. Gráfico 2 Ensemble Kaman Filter Data Assimulation Workflow. Cada sitio tiene licencias L. En START, el proceso maestro/control (programa principal EnKF) lee el archivo de configuración de simulación para el número (N) de modelos y archivos de entrada específicos del modelo. A continuación, N directorios de trabajo se crean para almacenar los archivos de salida. Al final de la iteración, el proceso maestro/control recoge los archivos de salida de los modelos N y las crosscovarianzas de los procesos posteriores [21] para estimar las incertidumbres de predicción. Esta información se utilizará para actualizar modelos (o archivos de entrada) para la siguiente iteración. La simulación continúa hasta agotar las historias de producción. La simulación típica de EnKF con N=50 y historias de campo de 50-60 años, en pasos de tiempo que van de tres meses a un año, toma unas tres semanas en un entorno de computación en serie. En el entorno informático paralelo, no hay comunicación interproceso entre los modelos geológicos en el conjunto. Sin embargo, al final de cada paso del tiempo de simulación, los archivos de salida específicos del modelo deben ser recogidos para analizar covarianzas cruzadas [21] y para preparar el siguiente conjunto de archivos de entrada. Por lo tanto, el modelo maestro-esclavo en el entorno de mensajepassing (MPI) es un paradigma adecuado. En este enfoque, los modelos geológicos son tratados como esclavos y se distribuyen entre los procesadores disponibles. El master Cluster o (TIGRE/GridWay) START Read Configuration File Create N Working Directories Create N Input files Model l Model 2 Model N.. . ECLIPSE in situ Un ECLIPSE in situ B ECLIPSE in situ Z Collect N Model Outputs, Post-process Output files FIN. . . proceso recoge archivos de salida específicos del modelo, analiza y prepara el siguiente conjunto de archivos de entrada para la simulación. Dado que cada modelo geológico comprueba una licencia ECLIPSE, la paralelización de la simulación depende del número de licencias disponibles. Cuando el número de licencias disponible es menor que el número de modelos en el conjunto, uno o más de los nodos del grupo MPI tienen que manejar más de un modelo en serie y, por lo tanto, se tarda más tiempo en completar la simulación. Un Departamento de Ingeniería Petrolera generalmente adquiere 10-15 licencias ECLIPSE, mientras que al menos diez veces más número de licencias sería necesario para simulaciones estándar de la industria. El número de licencias puede incrementarse con la participación de varios departamentos de ingeniería petrolera que apoyan el paquete ECLIPSE. Dado que MPI no se escala muy bien para aplicaciones que involucran clústeres de computación remotos, y para evitar los problemas del firewall con servidores de licencias en todos los dominios administrativos, parece necesario activar el flujo de trabajo de EnKF. Con esta motivación, hemos implementado el flujo de trabajo EnKF habilitado para Grid para el entorno TIGRE y hemos demostrado la paralelización de la aplicación a través de TIGRE usando el metascheduler GridWay. En la siguiente sección figuran más detalles al respecto. 4. DETALLES DE APLICACION Para habilitar Grid-enable el enfoque EnKF, hemos eliminado el código MPI para el procesamiento paralelo y reemplazado por trabajos de N monoprocesador (o sub-trabajos) donde, N es el número de modelos geológicos en el conjunto. Estos sub-trabajos específicos de modelos se distribuyeron a través de sitios TIGRE que soportan el paquete ECLIPSE utilizando el metaprogramador GridWay [8]. Para cada sub-trabajo, hemos construido una plantilla de trabajo GridWay que especifica los archivos ejecutables, de entrada y salida, y los requisitos de recursos. Dado que los recursos de cálculo de TIGRE no se espera que cambien con frecuencia, hemos utilizado la política de descubrimiento de recursos estáticos para GridWay y los sub-trabajos fueron programados dinámicamente a través de los recursos de TIGRE usando GridWay. La Figura 3 representa el archivo de plantilla de subtrabajo para el metaprogramador GridWay. Gráfico 3 Plantilla de subtrabajo GridWay En la Figura 3, REQUISITOS bandera se establece para elegir los recursos que satisfacen los requisitos de la aplicación. En el caso de la aplicación EnKF, por ejemplo, necesitamos recursos que apoyen el paquete ECLIPSE. ARGUMENTS flag especifica el modelo en el conjunto que invocará ECLIPSE en un sitio remoto. INPUT_FILES es preparado por el programa principal de EnKF (o proceso maestro/control) y es transferido por GridWay al sitio remoto donde está desatendido y está preparado para su ejecución. Finalmente, OUTPUT_FILES especifica el nombre y la ubicación donde se escribirán los archivos de salida. Las características de la línea de comandos de GridWay se utilizaron para recopilar y procesar las salidas específicas del modelo para preparar un nuevo conjunto de archivos de entrada. Este paso imita la sincronización del proceso MPI en el modelo maestro-esclavo. Al final de cada iteración, los recursos computacionales y las licencias se devuelven al grupo. La Tabla 1 muestra los sub-trabajos en TIGRE Grid via GridWay usando el comando gwps y para mayor claridad, sólo se mostraron las columnas seleccionadas. USUARIO JID DM EM NOMBRE HOST pingluo 88 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 89 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 90 wrap actv enkf.jt minigar.hp Programación de trabajo a través de TIGRE usando GridWay Metascheduler. DM: Estado de envío, EM: Estado de ejecución, JID es el id de trabajo y HOST corresponde al cluster específico del sitio y su planificador de lotes local. Cuando un trabajo es enviado a GridWay, pasará por una serie de estados de envío (DM) y ejecución (EM). Para DM, los estados incluyen pend(ing), prol(og), wrap(per), epil(og), y hecho. DM=prol significa que el trabajo ha sido programado a un recurso y el directorio de trabajo remoto está en preparación. DM=warp implica que GridWay está ejecutando el envoltorio que a su vez ejecuta la aplicación. DM=epil implica que el trabajo ha terminado de ejecutarse en el sitio remoto y los resultados se están transfiriendo al servidor GridWay. Del mismo modo, cuando EM=pend implica que el trabajo está esperando en la cola para el recurso y el trabajo se está ejecutando cuando EM=actv. Para ver la lista completa de las banderas de mensajes y sus descripciones, consulte la documentación en ref [8]. Hemos demostrado las ejecuciones de EnKF habilitadas para Grid usando GridWay para entorno TIGRE. Los trabajos son tan elegidos que el tiempo de ejecución no supera más de media hora. La simulación incluyó hasta 20 trabajos entre sitios de A&M y TTU con TTU cumpliendo 10 licencias. Para obtener información sobre los recursos, véase el cuadro I. Una de las principales ventajas de la simulación EnKF habilitada por Grid es que tanto los recursos como las licencias se devuelven al grupo al final de cada paso del tiempo de simulación a diferencia del caso de la implementación de MPI donde las licencias y nodos están bloqueados hasta la finalización de la simulación completa. Sin embargo, el hecho de que cada sub-trabajo se programe independientemente a través de GridWay podría posiblemente incurrir en otro retraso de tiempo causado por esperar en la cola para la ejecución en cada paso del tiempo de simulación. Tales retrasos no se esperan EXECUTABLE=runFORWARD NECESIDADES=HOSTNAME=cosmos.tamu.edu  HOSTNAME=antaeus.hpcc.ttu.edu  HOSTNAME=minigar.hpcc.ttu.edu  ARGUMENTOS=001 INPUT_FILES=001.in.tar OUTPUT_FI Hay dos escenarios principales para comparar los enfoques de computación de red y clúster. Escenario I: El cúmulo está muy cargado. El tiempo promedio de espera concebido del trabajo que solicita un gran número de CPUs es generalmente más largo que el tiempo de espera de los trabajos que solicitan una sola CPU. Por lo tanto, el tiempo de espera general podría ser más corto en el enfoque Grid que solicita una sola CPU para cada sub-trabajo muchas veces en comparación con la implementación MPI que requiere un gran número de CPUs en un solo momento. Es evidente que la programación de la cuadrícula es beneficiosa especialmente cuando el clúster está fuertemente cargado y el número solicitado de CPUs para el trabajo del MPI no está fácilmente disponible. Escenario II: El clúster está relativamente menos cargado o disponible en gran medida. Parece que la implementación del MPI es favorable en comparación con la programación de la Rejilla. Sin embargo, la paralelización de la aplicación EnKF depende del número de licencias ECLIPSE e idealmente, el número de licencias debe ser igual al número de modelos en el conjunto. Por lo tanto, si una sola institución no tiene suficiente número de licencias, la disponibilidad del clúster no ayuda tanto como se espera. Dado que el entorno colaborativo, como TIGRE, puede abordar tanto los requisitos de computación como los de recursos de software para la aplicación EnKF, el enfoque compatible con Grid sigue siendo ventajoso sobre la implementación MPI convencional en cualquiera de los escenarios anteriores. 5. CONCLUSIONES Y FUTURO TRABAJO TIGRE es un proyecto de desarrollo de la red de educación superior y su propósito es mantener y ampliar las oportunidades de investigación y educación a través de Texas. Dentro del área de aplicación \"exploración de energía\", hemos habilitado la implementación MPI del conjunto Kalman metodología de asimilación de datos filtrantes para la caracterización de reservorios. Esta tarea se llevó a cabo eliminando el código MPI para el procesamiento paralelo y reemplazando con trabajos de un solo procesador uno para cada modelo geológico en el conjunto. Estos trabajos de un solo procesador fueron programados a través de TIGRE a través de GridWay metascheduler. Hemos demostrado que mediante la puesta en común de licencias a través de sitios TIGRE, más modelos geológicos pueden ser manejados en paralelo y por lo tanto concebiblemente mejor precisión de simulación. Este enfoque tiene varias ventajas sobre la implementación de MPI, especialmente cuando un clúster específico del sitio está muy cargado y/o las licencias de número requeridas para la simulación son más que las disponibles en un solo sitio. Hacia el trabajo futuro, sería interesante comparar el tiempo de ejecución entre MPI y las implementaciones de Grid para la aplicación EnKF. Este esfuerzo podría arrojar luz sobre la calidad del servicio (QoS) de los entornos Grid en comparación con la computación de clústers. Otro aspecto de interés en un futuro próximo sería la gestión de recursos de computación y licencia para abordar la gestión de la relación trabajo (o procesador)-licencia. 6. OBSERVACIONES Y MENOS APRENDIZADOS Los esfuerzos que facilitan la red para la aplicación EnKF han proporcionado amplias oportunidades para reunir información sobre la visibilidad y la promesa de los entornos de computación de Grid para el desarrollo y soporte de aplicaciones. Los principales problemas son la seguridad de los datos estándar de la industria y la CV comparable a la computación de clústers. Dado que la investigación de modelado de reservorios involucra datos propietarios del campo, tuvimos que invertir esfuerzos sustanciales inicialmente en educar a los investigadores de aplicaciones sobre la capacidad de los servicios de Grid para apoyar la seguridad de datos estándar de la industria a través de acceso basado en roles y privilegios utilizando el estándar X.509. Con respecto a QoS, los investigadores de aplicaciones esperan niveles de QoS con entornos de cuadrícula. Además, hay una curva de aprendizaje pronunciada en la computación de cuadrícula en comparación con la computación de clúster convencional. Dado que la computación de cuadrícula sigue siendo una tecnología emergente, y abarca varios ámbitos administrativos, la computación de cuadrícula sigue siendo prematura, especialmente en términos del nivel de QoS, aunque ofrece mejores normas de seguridad de los datos en comparación con los grupos de productos básicos. Es nuestra observación que los programas de capacitación y divulgación que comparan y contrastan los entornos de computación de red y clúster serían un enfoque adecuado para mejorar la participación de los usuarios en la computación de red. Este enfoque también ayuda a los usuarios a emparejar sus aplicaciones y habilidades que las cuadrículas pueden ofrecer. En resumen, nuestros esfuerzos a través de TIGRE en la metodología de asimilación de datos de la EnKF demostraron una promesa sustancial en la contratación de investigadores de Ingeniería Petrolera a través de colaboraciones entre campus. Se están realizando esfuerzos para lograr la participación de más escuelas en este esfuerzo. Estos esfuerzos pueden resultar en un aumento de la investigación colaborativa, oportunidades educativas y desarrollo de la fuerza laboral a través de programas de investigación de posgrado/facultad en instituciones TIGRE. 7. AGRADECIMIENTOS Los autores reconocen al Estado de Texas por apoyar el proyecto TIGRE a través del Fondo Empresarial de Texas, y a las Instituciones TIGRE por proporcionar el mecanismo, en el que también participan los autores (Ravi Vadapalli, Taesung Kim y Ping Luo). Los autores agradecen a los investigadores de aplicaciones Prof. Akhil Datta-Gupta de Texas A&M University y Prof. Lloyd Heinze de Texas Tech University por sus discusiones e interés en explotar el entorno TIGRE para ampliar las oportunidades en investigación y desarrollo. 8. REFERENCIAS [1] Foster, I. y Kesselman, C. (eds.) 2004. The Grid: Blueprint for a new computing infraestructura (The Elsevier series in Grid computing) [2] Portal TIGRE: http://tigreportal.hipcat.net [3] Vadapalli, R. Sill, A., Dooley, R., Murray, M., Luo, P., Kim, T., Huang, M., Thyagaraja, K., y Chaffin, Demostración del entorno TIGRE para aplicaciones de cuadrícula habilitadas/adecuadas. 8o IEEE/ACM Int. Conf. on Grid Computing, 19-21 de septiembre, Austin [4] The High Performance Computing cross Texas Consortium http://www.hipcat.net [5] Pordes, R. Petravick, D. Kramer, B. Olson, D. Livny, M. Roy, A. Avery, P. Blackburn, K. Wenaus, T. Würthwein, F. Foster, I. Gar The Open Science Grid, J. Phys Conf Series http://www.iop.org/EJ/abstract/1742-6596/78/1/012057 y http://www.opensciencegrid.org [6] Reed, D.A. 2003. Rejilla, el Teragrid y más allá, Ordenador, vol. 30, no. 1 y http://www.teragrid.org [7] Evensen, G. 2006. Asimilación de datos: El conjunto Kalman Filter, Springer [8] Herrera, J. Huedo, E. Montero, R. S. y Llorente, I. M. 2005. Programación Científica, vol 12, No. 4. pp 317-331 [9] Avery, P. and Foster, I. 2001. El proyecto GriPhyN: Hacia redes virtuales de datos a petaescala, informe técnico GriPhyN-200115 y http://vdt.cs.wisc.edu [10] La guía de documentación e instalación de PacMan http://physics.bu.edu/pacman/htmls [11] Caskey, P. Murray, M. Perez, J. y Sill, A. 2007. Estudios de casos en la gestión de identificación para organizaciones virtuales, EDUCOUSO Southwest Reg. Conf., 21-23 febrero, Austin, TX. http://www.educause.edu/ir/library/pdf/SWR07058.pdf [12] El Sistema de Gestión de Usuarios de Grid (GUMS) https://www.racf.bnl.gov/Facility/GUMS/index.html [13] Thomas, M. y Boisseau, J. 2003. Construyendo portales de computación de cuadrículas: El kit de herramientas para el portal de cuadrículas NPACI, Grid computing: haciendo realidad la infraestructura global, Capítulo 28, Berman, F. Fox, G. Thomas, M. Boisseau, J. y Hey, T. (eds), John Wiley and Sons, Ltd, Chichester [14] Open Ticket Request System http:// 1999. Integración de datos dinámicos en modelos de depósito de alta resolución utilizando coeficientes de sensibilidad basados en la racionalización, Society of Petroleum Engineers (SPE), 4 (4). [17] Emanuel, A. S. y Milliken, W. J. 1998. Historia que combina modelos de diferencias finitas con racionalizaciones 3D, SPE 49000, Proc de la Conf Técnica Anual y Exposición, 2730 de septiembre, Nueva Orleans, LA. [18] Nævdal, G. Johnsen, L.M. Aanonsen, S.I. y Vefring, E.H. 2003. Monitorización de embalses y actualización continua de modelos utilizando Ensemble Kalman Filter, SPE 84372, Proc del Conf Técnico Anual y Exposición, Oct 5-8, Denver, CO. [19] Jafarpour B. y McLaughlin, D.B. 2007. Historia que coincide con un conjunto de filtro Kalman y parametrización discreta de coseno, SPE 108761, Proc de la Conf Técnica Anual y Exposición, 11-14 de noviembre, Anaheim, CA [20] Li, G. y Reynolds, A. C. 2007. Un conjunto iterativo Kalman filtro para la asimilación de datos, SPE 109808, Proc de la SPE Conf y Exposición Técnica Anual, 11-14 de noviembre, Anaheim, CA [21] Arroyo-Negrete, E. Devagowda, D. Datta-Gupta, A. 2006. Simplificar el conjunto asistido Kalman filtro para la actualización rápida y continua del modelo de depósito. Proc de la Int. Oil & Gas Conf and Exhibition, SPE 104255, Dec 5-7, China [22] ECLIPSE Reservoir Engineering Software http://www.slb.com/content/services/software/reseng/index.a sp ",
            "error": [
                ""
            ]
        },
        "tigre grid computing environment": {
            "translated_key": [],
            "translated_annotated_text": "Demostración del conjunto de datos de Kalman Assimulation Method for Reservoir Caracterisation Ravi Vadapalli Centro de computación de alto rendimiento Texas Tech University Lubbock, TX 79409 001-806-742-4350 Ravi.Vadapalli@ttu.edu Ajitabh Kumar Department of Petroleum Engineering Texas A&M University College Station, En este enfoque, se utiliza un conjunto de modelos geológicos y datos de producción de yacimientos de petróleo para predecir la respuesta dinámica de los pozos de petróleo. El software Schlumberger ECLIPSE se utiliza para estas simulaciones. Puesto que los modelos en el conjunto no se comunican, la implementación de mensaje-passing es una buena opción. Cada modelo comprueba una licencia ECLIPSE y, por lo tanto, la paralelización de las simulaciones de reservorio depende de las licencias de número disponibles. Hemos habilitado Grid para el conjunto Kalman metodología de asimilación de datos de filtro para el entorno de computación TIGRE Grid. Al poner en común las licencias y los recursos informáticos en todas las instituciones colaboradoras utilizando el metaprogramador GridWay y el entorno TIGRE, la precisión computacional puede aumentarse al tiempo que se reduce el tiempo de ejecución de la simulación. En este artículo, proporcionamos un relato de nuestros esfuerzos en Gridenabilizar el conjunto Kalman Filter metodología de asimilación de datos. Se examinarán los posibles beneficios de este enfoque, las observaciones y la experiencia adquirida. Categorías y Descriptores sujetos C 2.4 [Sistemas distribuidos]: Aplicaciones distribuidas Términos generales Algoritmos, Diseño, Rendimiento 1. INTRODUCCIÓN La computación de cuadrícula [1] es un paradigma de computación colaborativa emergente para ampliar las capacidades específicas de computación de alto rendimiento (HPC) mucho más allá de los recursos locales. Su importancia se deriva del hecho de que la investigación innovadora en áreas de aplicación estratégicas como la biociencia y la medicina, la exploración de energía y el modelado ambiental involucran componentes interdisciplinarios fuertes y a menudo requieren colaboraciones intercampus y capacidades computacionales más allá de las limitaciones institucionales. The Texas Internet Grid for Research and Education (TIGRE) [2,3] es un proyecto de desarrollo de infraestructuras cibernéticas financiado por el estado, llevado a cabo por cinco grandes sistemas universitarios (Rice, A&M, TTU, UH y UT Austin), llamados colectivamente Instituciones TIGRE. El propósito de TIGRE es crear una red de educación superior para sostener y ampliar las oportunidades de investigación y educación en Texas. TIGRE es un proyecto del consorcio de computación de alto rendimiento en Texas (HiPCAT) [4]. El objetivo de HiPCAT es apoyar tecnologías computacionales avanzadas para mejorar la investigación, el desarrollo y las actividades educativas. El objetivo principal de TIGRE es diseñar e implementar middleware Grid de última generación que permita la integración de sistemas de computación, sistemas de almacenamiento y bases de datos, laboratorios de visualización y pantallas, e incluso instrumentos y sensores en Texas. El objetivo secundario es demostrar las capacidades de TIGRE para mejorar las oportunidades de investigación y educación en áreas de aplicación estratégica de interés para el Estado de Texas. Estos son biociencia y medicina, exploración energética y modelado de la calidad del aire. La visión del proyecto TIGRE es fomentar la colaboración interdisciplinaria e intercampus, identificar enfoques novedosos para ampliar las asociaciones académicas, gubernamentales y privadas, y convertirse en un modelo competitivo para las oportunidades de financiación externa. El objetivo general de TIGRE es apoyar los intereses de los usuarios locales, universitarios y regionales y ofrecer vías para conectar con proyectos nacionales de Red como Open Science Grid [5] y TeraGrid [6]. Dentro del área de aplicación estratégica de exploración energética, hemos habilitado el enfoque conjunto Kalman Filter (EnKF) [7] para la asimilación de datos en el modelado de reservorios y hemos demostrado la extensibilidad de la aplicación utilizando el entorno TIGRE y el metaprogramador GridWay [8]. En la sección 2 se ofrece una visión general del entorno y las capacidades de TIGRE. La descripción de la aplicación y la necesidad de una metodología EnKF compatible con la cuadrícula figuran en la sección 3. Los detalles de la aplicación y los méritos de nuestro enfoque se examinan en la sección 4. Las conclusiones figuran en la sección 5. Por último, en la sección 6 se documentan las observaciones y la experiencia adquirida. 2. TIGRE ENTORNO El MIddleware TIGRE Grid consiste en un conjunto mínimo de componentes derivados de un subconjunto del Virtual Data Toolkit (VDT) [9] que soporta una variedad de sistemas operativos. El propósito de elegir una pila de software mínima es apoyar las aplicaciones disponibles y simplificar la instalación y distribución de las pilas cliente/servidor en los sitios de TIGRE. Se añadirán componentes adicionales a medida que sean necesarios. El mecanismo de packaging y distribución PacMan [10] se emplea para la instalación y gestión del cliente/servidor TIGRE. El mecanismo de distribución de PacMan implica la recuperación, instalación y a menudo configuración del software empaquetado. Este enfoque permite a los clientes mantener versiones actualizadas y consistentes del software TIGRE. También ayuda a los sitios TIGRE a instalar los componentes necesarios en los recursos distribuidos en los sitios participantes. La pila cliente/servidor TIGRE consiste en una capa de autenticación y autorización, Globus GRAM4-basada en la presentación de trabajos a través de servicios web (las instalaciones de servicios pre-web están disponibles bajo petición). Las herramientas para manejar la generación de proxy de cuadrícula, la transferencia de archivos habilitada para cuadrícula y el inicio de sesión remoto habilitado para cuadrícula son compatibles. A continuación se proporcionan los detalles pertinentes de los servicios y herramientas de TIGRE para la programación y gestión de puestos. 2.1. Autoridad certificadora La infraestructura de seguridad TIGRE incluye una autoridad certificadora (CA) acreditada por la International Grid Trust Federation (IGTF) para emitir X. 509 certificados de usuario y recurso Grid [11]. El Texas Advanced Computing Center (TACC), Universidad de Texas en Austin, es el TIGREs CA compartido. Las instituciones de TIGRE actúan como autoridades de registro (RA) para sus respectivas bases de usuarios locales. Para obtener información actualizada sobre la seguridad de los certificados de usuario y de recursos y sus instrucciones de instalación, véase ref [2]. Los usuarios y hosts de TIGRE son identificados por su distinguido nombre (DN) en su certificado X.509 proporcionado por la CA. Un archivo nativo Grid-mapfile que contiene una lista de DNs autorizados se utiliza para autenticar y autorizar la programación y gestión de trabajos de los usuarios en los recursos del sitio TIGRE. En la Universidad Texas Tech, a los usuarios se les asigna dinámicamente una de las muchas cuentas genéricas. Esto se logra a través del Sistema de Gestión de Usuarios de Red (GUMS) [12]. 2.2. Programación y gestión de empleos El entorno TIGRE apoya la presentación de trabajos basada en GRAM4 a través de servicios web. Los scripts de envío de trabajos se generan usando XML. Los servicios web GRAM traducen los scripts XML en programadores de lotes específicos de grupos de destino como LSF, PBS o SGE. Los protocolos de transferencia de archivos de alto ancho de banda como GridFTP se utilizan para estadificación de archivos dentro y fuera de la máquina de destino. El acceso a hosts remotos para compilar y depurar es sólo a través del servicio GSISSH que requiere autenticación de recursos a través de certificados X.509. La autenticación y autorización de los trabajos de Grid se gestionan mediante la emisión de certificados de Grid a usuarios y anfitriones. Las listas de revocación de certificados (CRL) se actualizan diariamente para mantener altos estándares de seguridad de los servicios de TIGRE Grid. El área de documentación del portal TIGRE [2] proporciona un tutorial de inicio rápido sobre cómo ejecutar trabajos en TIGRE. 2.3. Metascheduler El metascheduler interopera con los programadores de lotes de nivel de cluster (como LSF, PBS) en la gestión general del flujo de trabajo de Grid. En el presente trabajo, hemos empleado el metaprogramador GridWay [8] -un proyecto de incubadora Globus- para programar y gestionar trabajos en TIGRE. El GridWay es un metaprogramador ligero que utiliza plenamente las funcionalidades de Globus. Está diseñado para proporcionar un uso eficiente de los recursos dinámicos de Grid por múltiples usuarios para las infraestructuras de Grid construidas sobre los servicios de Globus. El administrador del sitio TIGRE puede controlar el uso compartido de recursos a través de un potente programador integrado proporcionado por GridWay o ampliando el módulo de programación externa GridWays para proporcionar sus propias políticas de programación. Los usuarios de aplicaciones pueden escribir descripciones de trabajos usando el formato de plantilla de trabajo simple y directo de GridWays (ver Sección 4 para más detalles) o el lenguaje estándar de descripción de la presentación de trabajos (JSDL). Para más detalles sobre la aplicación, véase la sección 4. 2.4. Sistema de Gestión de Servicios al Cliente Un portal TIGRE [2] fue diseñado e implementado para interconectar usuarios y proveedores de recursos. Fue diseñado utilizando GridPort [13] y es mantenido por TACC. El entorno TIGRE es compatible con herramientas de código abierto como el Open Ticket Request System (OTRS) [14] para el servicio de tickets de problemas, y MoinMoin [15] Wiki para la gestión de contenido y conocimiento de TIGRE para educación, extensión y capacitación. Los enlaces para OTRS y Wiki son consumidos por el portal TIGRE [2] - el portal para usuarios y proveedores de recursos. El estado y las cargas de los recursos de TIGRE son monitoreados por el servicio de Repositorio de Información de Puertos Grid (GPIR) del kit de herramientas GridPort [13] que interactúa con el servicio local de monitoreo de carga de clústeres como Ganglia. El GPIR utiliza trabajos de cron en cada recurso para reunir características específicas de los recursos del sitio, tales como trabajos que se ejecutan, en cola y esperando la asignación de recursos. 3. APLICACIÓN ENSEMBLE KALMAN FILTER El objetivo principal de las simulaciones de yacimientos de hidrocarburos es predecir el comportamiento de la producción de yacimientos de petróleo y gas (denominados en lo sucesivo campo) para su desarrollo y gestión óptima. En el modelado de yacimientos, el campo se divide en varios modelos geológicos, como se muestra en la Figura 1. Para una previsión precisa del rendimiento del campo, es necesario conciliar varios modelos geológicos con la respuesta dinámica del campo a través de la coincidencia histórica [16-20]. Gráfico 1 Vista transversal del Campo. Las capas verticales corresponden a diferentes modelos geológicos y los clavos son pozos de aceite cuya información histórica se utilizará para predecir el comportamiento de la producción. (Figura Ref:http://faculty.smu.edu/zchen/research.html). El EnKF es un método de Monte Carlo que trabaja con un conjunto de modelos de embalses. Este método utiliza covarianzas cruzadas [21] entre las mediciones de campo y los parámetros del modelo de reservorio (derivados de varios modelos) para estimar las incertidumbres de predicción. Los parámetros del modelo geológico en el conjunto se actualizan secuencialmente con el objetivo de minimizar las incertidumbres de predicción. La respuesta histórica de la producción del campo durante más de 50 años se utiliza en estas simulaciones. La principal ventaja de EnKF es que puede vincularse fácilmente a cualquier simulador de depósito, y puede asimilar los últimos datos de producción sin necesidad de volver a ejecutar el simulador desde las condiciones iniciales. Investigadores en Texas son grandes suscriptores del paquete de Schlumberger ECLIPSE [22] para simulaciones de reservorios. En el modelado del embalse, cada modelo geológico comprueba una licencia ECLIPSE. La duración de la simulación de la metodología EnKF depende del número de modelos geológicos utilizados, el número de licencias ECLIPSE disponibles, la historia de producción del campo y las incertidumbres propagadas en la correspondencia de la historia. El flujo de trabajo general de EnKF se muestra en la Figura 2. Gráfico 2 Ensemble Kaman Filter Data Assimulation Workflow. Cada sitio tiene licencias L. En START, el proceso maestro/control (programa principal EnKF) lee el archivo de configuración de simulación para el número (N) de modelos y archivos de entrada específicos del modelo. A continuación, N directorios de trabajo se crean para almacenar los archivos de salida. Al final de la iteración, el proceso maestro/control recoge los archivos de salida de los modelos N y las crosscovarianzas de los procesos posteriores [21] para estimar las incertidumbres de predicción. Esta información se utilizará para actualizar modelos (o archivos de entrada) para la siguiente iteración. La simulación continúa hasta agotar las historias de producción. La simulación típica de EnKF con N=50 y historias de campo de 50-60 años, en pasos de tiempo que van de tres meses a un año, toma unas tres semanas en un entorno de computación en serie. En el entorno informático paralelo, no hay comunicación interproceso entre los modelos geológicos en el conjunto. Sin embargo, al final de cada paso del tiempo de simulación, los archivos de salida específicos del modelo deben ser recogidos para analizar covarianzas cruzadas [21] y para preparar el siguiente conjunto de archivos de entrada. Por lo tanto, el modelo maestro-esclavo en el entorno de mensajepassing (MPI) es un paradigma adecuado. En este enfoque, los modelos geológicos son tratados como esclavos y se distribuyen entre los procesadores disponibles. El master Cluster o (TIGRE/GridWay) START Read Configuration File Create N Working Directories Create N Input files Model l Model 2 Model N.. . ECLIPSE in situ Un ECLIPSE in situ B ECLIPSE in situ Z Collect N Model Outputs, Post-process Output files FIN. . . proceso recoge archivos de salida específicos del modelo, analiza y prepara el siguiente conjunto de archivos de entrada para la simulación. Dado que cada modelo geológico comprueba una licencia ECLIPSE, la paralelización de la simulación depende del número de licencias disponibles. Cuando el número de licencias disponible es menor que el número de modelos en el conjunto, uno o más de los nodos del grupo MPI tienen que manejar más de un modelo en serie y, por lo tanto, se tarda más tiempo en completar la simulación. Un Departamento de Ingeniería Petrolera generalmente adquiere 10-15 licencias ECLIPSE, mientras que al menos diez veces más número de licencias sería necesario para simulaciones estándar de la industria. El número de licencias puede incrementarse con la participación de varios departamentos de ingeniería petrolera que apoyan el paquete ECLIPSE. Dado que MPI no se escala muy bien para aplicaciones que involucran clústeres de computación remotos, y para evitar los problemas del firewall con servidores de licencias en todos los dominios administrativos, parece necesario activar el flujo de trabajo de EnKF. Con esta motivación, hemos implementado el flujo de trabajo EnKF habilitado para Grid para el entorno TIGRE y hemos demostrado la paralelización de la aplicación a través de TIGRE usando el metascheduler GridWay. En la siguiente sección figuran más detalles al respecto. 4. DETALLES DE APLICACION Para habilitar Grid-enable el enfoque EnKF, hemos eliminado el código MPI para el procesamiento paralelo y reemplazado por trabajos de N monoprocesador (o sub-trabajos) donde, N es el número de modelos geológicos en el conjunto. Estos sub-trabajos específicos de modelos se distribuyeron a través de sitios TIGRE que soportan el paquete ECLIPSE utilizando el metaprogramador GridWay [8]. Para cada sub-trabajo, hemos construido una plantilla de trabajo GridWay que especifica los archivos ejecutables, de entrada y salida, y los requisitos de recursos. Dado que los recursos de cálculo de TIGRE no se espera que cambien con frecuencia, hemos utilizado la política de descubrimiento de recursos estáticos para GridWay y los sub-trabajos fueron programados dinámicamente a través de los recursos de TIGRE usando GridWay. La Figura 3 representa el archivo de plantilla de subtrabajo para el metaprogramador GridWay. Gráfico 3 Plantilla de subtrabajo GridWay En la Figura 3, REQUISITOS bandera se establece para elegir los recursos que satisfacen los requisitos de la aplicación. En el caso de la aplicación EnKF, por ejemplo, necesitamos recursos que apoyen el paquete ECLIPSE. ARGUMENTS flag especifica el modelo en el conjunto que invocará ECLIPSE en un sitio remoto. INPUT_FILES es preparado por el programa principal de EnKF (o proceso maestro/control) y es transferido por GridWay al sitio remoto donde está desatendido y está preparado para su ejecución. Finalmente, OUTPUT_FILES especifica el nombre y la ubicación donde se escribirán los archivos de salida. Las características de la línea de comandos de GridWay se utilizaron para recopilar y procesar las salidas específicas del modelo para preparar un nuevo conjunto de archivos de entrada. Este paso imita la sincronización del proceso MPI en el modelo maestro-esclavo. Al final de cada iteración, los recursos computacionales y las licencias se devuelven al grupo. La Tabla 1 muestra los sub-trabajos en TIGRE Grid via GridWay usando el comando gwps y para mayor claridad, sólo se mostraron las columnas seleccionadas. USUARIO JID DM EM NOMBRE HOST pingluo 88 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 89 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 90 wrap actv enkf.jt minigar.hp Programación de trabajo a través de TIGRE usando GridWay Metascheduler. DM: Estado de envío, EM: Estado de ejecución, JID es el id de trabajo y HOST corresponde al cluster específico del sitio y su planificador de lotes local. Cuando un trabajo es enviado a GridWay, pasará por una serie de estados de envío (DM) y ejecución (EM). Para DM, los estados incluyen pend(ing), prol(og), wrap(per), epil(og), y hecho. DM=prol significa que el trabajo ha sido programado a un recurso y el directorio de trabajo remoto está en preparación. DM=warp implica que GridWay está ejecutando el envoltorio que a su vez ejecuta la aplicación. DM=epil implica que el trabajo ha terminado de ejecutarse en el sitio remoto y los resultados se están transfiriendo al servidor GridWay. Del mismo modo, cuando EM=pend implica que el trabajo está esperando en la cola para el recurso y el trabajo se está ejecutando cuando EM=actv. Para ver la lista completa de las banderas de mensajes y sus descripciones, consulte la documentación en ref [8]. Hemos demostrado las ejecuciones de EnKF habilitadas para Grid usando GridWay para entorno TIGRE. Los trabajos son tan elegidos que el tiempo de ejecución no supera más de media hora. La simulación incluyó hasta 20 trabajos entre sitios de A&M y TTU con TTU cumpliendo 10 licencias. Para obtener información sobre los recursos, véase el cuadro I. Una de las principales ventajas de la simulación EnKF habilitada por Grid es que tanto los recursos como las licencias se devuelven al grupo al final de cada paso del tiempo de simulación a diferencia del caso de la implementación de MPI donde las licencias y nodos están bloqueados hasta la finalización de la simulación completa. Sin embargo, el hecho de que cada sub-trabajo se programe independientemente a través de GridWay podría posiblemente incurrir en otro retraso de tiempo causado por esperar en la cola para la ejecución en cada paso del tiempo de simulación. Tales retrasos no se esperan EXECUTABLE=runFORWARD NECESIDADES=HOSTNAME=cosmos.tamu.edu  HOSTNAME=antaeus.hpcc.ttu.edu  HOSTNAME=minigar.hpcc.ttu.edu  ARGUMENTOS=001 INPUT_FILES=001.in.tar OUTPUT_FI Hay dos escenarios principales para comparar los enfoques de computación de red y clúster. Escenario I: El cúmulo está muy cargado. El tiempo promedio de espera concebido del trabajo que solicita un gran número de CPUs es generalmente más largo que el tiempo de espera de los trabajos que solicitan una sola CPU. Por lo tanto, el tiempo de espera general podría ser más corto en el enfoque Grid que solicita una sola CPU para cada sub-trabajo muchas veces en comparación con la implementación MPI que requiere un gran número de CPUs en un solo momento. Es evidente que la programación de la cuadrícula es beneficiosa especialmente cuando el clúster está fuertemente cargado y el número solicitado de CPUs para el trabajo del MPI no está fácilmente disponible. Escenario II: El clúster está relativamente menos cargado o disponible en gran medida. Parece que la implementación del MPI es favorable en comparación con la programación de la Rejilla. Sin embargo, la paralelización de la aplicación EnKF depende del número de licencias ECLIPSE e idealmente, el número de licencias debe ser igual al número de modelos en el conjunto. Por lo tanto, si una sola institución no tiene suficiente número de licencias, la disponibilidad del clúster no ayuda tanto como se espera. Dado que el entorno colaborativo, como TIGRE, puede abordar tanto los requisitos de computación como los de recursos de software para la aplicación EnKF, el enfoque compatible con Grid sigue siendo ventajoso sobre la implementación MPI convencional en cualquiera de los escenarios anteriores. 5. CONCLUSIONES Y FUTURO TRABAJO TIGRE es un proyecto de desarrollo de la red de educación superior y su propósito es mantener y ampliar las oportunidades de investigación y educación a través de Texas. Dentro del área de aplicación de exploración energética, hemos habilitado la implementación MPI del conjunto Kalman metodología de asimilación de datos de filtro para la caracterización de reservorios. Esta tarea se llevó a cabo eliminando el código MPI para el procesamiento paralelo y reemplazando con trabajos de un solo procesador uno para cada modelo geológico en el conjunto. Estos trabajos de un solo procesador fueron programados a través de TIGRE a través de GridWay metascheduler. Hemos demostrado que mediante la puesta en común de licencias a través de sitios TIGRE, más modelos geológicos pueden ser manejados en paralelo y por lo tanto concebiblemente mejor precisión de simulación. Este enfoque tiene varias ventajas sobre la implementación de MPI, especialmente cuando un clúster específico del sitio está muy cargado y/o las licencias de número requeridas para la simulación son más que las disponibles en un solo sitio. Hacia el trabajo futuro, sería interesante comparar el tiempo de ejecución entre MPI y las implementaciones de Grid para la aplicación EnKF. Este esfuerzo podría arrojar luz sobre la calidad del servicio (QoS) de los entornos Grid en comparación con la computación de clústers. Otro aspecto de interés en un futuro próximo sería la gestión de recursos de computación y licencia para abordar la gestión de la relación trabajo (o procesador)-licencia. 6. OBSERVACIONES Y MENOS APRENDIZADOS Los esfuerzos que facilitan la red para la aplicación EnKF han proporcionado amplias oportunidades para reunir información sobre la visibilidad y la promesa de los entornos de computación de Grid para el desarrollo y soporte de aplicaciones. Los principales problemas son la seguridad de los datos estándar de la industria y la CV comparable a la computación de clústers. Dado que la investigación de modelado de reservorios involucra datos propietarios del campo, tuvimos que invertir esfuerzos sustanciales inicialmente en educar a los investigadores de aplicaciones sobre la capacidad de los servicios de Grid para apoyar la seguridad de datos estándar de la industria a través de acceso basado en roles y privilegios utilizando el estándar X.509. Con respecto a QoS, los investigadores de aplicaciones esperan niveles de QoS con entornos de cuadrícula. Además, hay una curva de aprendizaje pronunciada en la computación de cuadrícula en comparación con la computación de clúster convencional. Dado que la computación de cuadrícula sigue siendo una tecnología emergente, y abarca varios ámbitos administrativos, la computación de cuadrícula sigue siendo prematura, especialmente en términos del nivel de QoS, aunque ofrece mejores normas de seguridad de los datos en comparación con los grupos de productos básicos. Es nuestra observación que los programas de capacitación y divulgación que comparan y contrastan los entornos de computación de red y clúster serían un enfoque adecuado para mejorar la participación de los usuarios en la computación de red. Este enfoque también ayuda a los usuarios a emparejar sus aplicaciones y habilidades que las cuadrículas pueden ofrecer. En resumen, nuestros esfuerzos a través de TIGRE en la metodología de asimilación de datos de la EnKF demostraron una promesa sustancial en la contratación de investigadores de Ingeniería Petrolera a través de colaboraciones entre campus. Se están realizando esfuerzos para lograr la participación de más escuelas en este esfuerzo. Estos esfuerzos pueden resultar en un aumento de la investigación colaborativa, oportunidades educativas y desarrollo de la fuerza laboral a través de programas de investigación de posgrado/facultad en instituciones TIGRE. 7. AGRADECIMIENTOS Los autores reconocen al Estado de Texas por apoyar el proyecto TIGRE a través del Fondo Empresarial de Texas, y a las Instituciones TIGRE por proporcionar el mecanismo, en el que también participan los autores (Ravi Vadapalli, Taesung Kim y Ping Luo). Los autores agradecen a los investigadores de aplicaciones Prof. Akhil Datta-Gupta de Texas A&M University y Prof. Lloyd Heinze de Texas Tech University por sus discusiones e interés en explotar el entorno TIGRE para ampliar las oportunidades en investigación y desarrollo. 8. REFERENCIAS [1] Foster, I. y Kesselman, C. (eds.) 2004. The Grid: Blueprint for a new computing infraestructura (The Elsevier series in Grid computing) [2] Portal TIGRE: http://tigreportal.hipcat.net [3] Vadapalli, R. Sill, A., Dooley, R., Murray, M., Luo, P., Kim, T., Huang, M., Thyagaraja, K., y Chaffin, Demostración del entorno TIGRE para aplicaciones de cuadrícula habilitadas/adecuadas. 8o IEEE/ACM Int. Conf. on Grid Computing, 19-21 de septiembre, Austin [4] The High Performance Computing cross Texas Consortium http://www.hipcat.net [5] Pordes, R. Petravick, D. Kramer, B. Olson, D. Livny, M. Roy, A. Avery, P. Blackburn, K. Wenaus, T. Würthwein, F. Foster, I. Gar The Open Science Grid, J. Phys Conf Series http://www.iop.org/EJ/abstract/1742-6596/78/1/012057 y http://www.opensciencegrid.org [6] Reed, D.A. 2003. Rejilla, el Teragrid y más allá, Ordenador, vol. 30, no. 1 y http://www.teragrid.org [7] Evensen, G. 2006. Asimilación de datos: El conjunto Kalman Filter, Springer [8] Herrera, J. Huedo, E. Montero, R. S. y Llorente, I. M. 2005. Programación Científica, vol 12, No. 4. pp 317-331 [9] Avery, P. and Foster, I. 2001. El proyecto GriPhyN: Hacia redes virtuales de datos a petaescala, informe técnico GriPhyN-200115 y http://vdt.cs.wisc.edu [10] La guía de documentación e instalación de PacMan http://physics.bu.edu/pacman/htmls [11] Caskey, P. Murray, M. Perez, J. y Sill, A. 2007. Estudios de casos en la gestión de identificación para organizaciones virtuales, EDUCOUSO Southwest Reg. Conf., 21-23 febrero, Austin, TX. http://www.educause.edu/ir/library/pdf/SWR07058.pdf [12] El Sistema de Gestión de Usuarios de Grid (GUMS) https://www.racf.bnl.gov/Facility/GUMS/index.html [13] Thomas, M. y Boisseau, J. 2003. Construyendo portales de computación de cuadrículas: El kit de herramientas para el portal de cuadrículas NPACI, Grid computing: haciendo realidad la infraestructura global, Capítulo 28, Berman, F. Fox, G. Thomas, M. Boisseau, J. y Hey, T. (eds), John Wiley and Sons, Ltd, Chichester [14] Open Ticket Request System http:// 1999. Integración de datos dinámicos en modelos de depósito de alta resolución utilizando coeficientes de sensibilidad basados en la racionalización, Society of Petroleum Engineers (SPE), 4 (4). [17] Emanuel, A. S. y Milliken, W. J. 1998. Historia que combina modelos de diferencias finitas con racionalizaciones 3D, SPE 49000, Proc de la Conf Técnica Anual y Exposición, 2730 de septiembre, Nueva Orleans, LA. [18] Nævdal, G. Johnsen, L.M. Aanonsen, S.I. y Vefring, E.H. 2003. Monitorización de embalses y actualización continua de modelos utilizando Ensemble Kalman Filter, SPE 84372, Proc del Conf Técnico Anual y Exposición, Oct 5-8, Denver, CO. [19] Jafarpour B. y McLaughlin, D.B. 2007. Historia que coincide con un conjunto de filtro Kalman y parametrización discreta de coseno, SPE 108761, Proc de la Conf Técnica Anual y Exposición, 11-14 de noviembre, Anaheim, CA [20] Li, G. y Reynolds, A. C. 2007. Un conjunto iterativo Kalman filtro para la asimilación de datos, SPE 109808, Proc de la SPE Conf y Exposición Técnica Anual, 11-14 de noviembre, Anaheim, CA [21] Arroyo-Negrete, E. Devagowda, D. Datta-Gupta, A. 2006. Simplificar el conjunto asistido Kalman filtro para la actualización rápida y continua del modelo de depósito. Proc de la Int. Oil & Gas Conf and Exhibition, SPE 104255, Dec 5-7, China [22] ECLIPSE Reservoir Engineering Software http://www.slb.com/content/services/software/reseng/index.a sp ",
            "error": []
        },
        "grid computing": {
            "translated_key": "computación por red",
            "translated_annotated_text": "Demostración del conjunto de datos de Kalman Assimulation Method for Reservoir Caracterisation Ravi Vadapalli Centro de computación de alto rendimiento Texas Tech University Lubbock, TX 79409 001-806-742-4350 Ravi.Vadapalli@ttu.edu Ajitabh Kumar Department of Petroleum Engineering Texas A&M University College Station, En este enfoque, se utiliza un conjunto de modelos geológicos y datos de producción de yacimientos de petróleo para predecir la respuesta dinámica de los pozos de petróleo. El software Schlumberger ECLIPSE se utiliza para estas simulaciones. Puesto que los modelos en el conjunto no se comunican, la implementación de mensaje-passing es una buena opción. Cada modelo comprueba una licencia ECLIPSE y, por lo tanto, la paralelización de las simulaciones de reservorio depende de las licencias de número disponibles. Hemos habilitado Grid para el conjunto Kalman metodología de asimilación de datos de filtro para el entorno de computación TIGRE Grid. Al poner en común las licencias y los recursos informáticos en todas las instituciones colaboradoras utilizando el metaprogramador GridWay y el entorno TIGRE, la precisión computacional puede aumentarse al tiempo que se reduce el tiempo de ejecución de la simulación. En este artículo, proporcionamos un relato de nuestros esfuerzos en Gridenabilizar el conjunto Kalman Filter metodología de asimilación de datos. Se examinarán los posibles beneficios de este enfoque, las observaciones y la experiencia adquirida. Categorías y Descriptores sujetos C 2.4 [Sistemas distribuidos]: Aplicaciones distribuidas Términos generales Algoritmos, Diseño, Rendimiento 1. INTRODUCCIÓN La computación de cuadrícula [1] es un paradigma de computación colaborativa emergente para ampliar las capacidades específicas de computación de alto rendimiento (HPC) mucho más allá de los recursos locales. Su importancia se deriva del hecho de que la investigación innovadora en áreas de aplicación estratégicas como la biociencia y la medicina, la exploración de energía y el modelado ambiental involucran componentes interdisciplinarios fuertes y a menudo requieren colaboraciones intercampus y capacidades computacionales más allá de las limitaciones institucionales. The Texas Internet Grid for Research and Education (TIGRE) [2,3] es un proyecto de desarrollo de infraestructuras cibernéticas financiado por el estado, llevado a cabo por cinco grandes sistemas universitarios (Rice, A&M, TTU, UH y UT Austin), llamados colectivamente Instituciones TIGRE. El propósito de TIGRE es crear una red de educación superior para sostener y ampliar las oportunidades de investigación y educación en Texas. TIGRE es un proyecto del consorcio de computación de alto rendimiento en Texas (HiPCAT) [4]. El objetivo de HiPCAT es apoyar tecnologías computacionales avanzadas para mejorar la investigación, el desarrollo y las actividades educativas. El objetivo principal de TIGRE es diseñar e implementar middleware Grid de última generación que permita la integración de sistemas de computación, sistemas de almacenamiento y bases de datos, laboratorios de visualización y pantallas, e incluso instrumentos y sensores en Texas. El objetivo secundario es demostrar las capacidades de TIGRE para mejorar las oportunidades de investigación y educación en áreas de aplicación estratégica de interés para el Estado de Texas. Estos son biociencia y medicina, exploración energética y modelado de la calidad del aire. La visión del proyecto TIGRE es fomentar la colaboración interdisciplinaria e intercampus, identificar enfoques novedosos para ampliar las asociaciones académicas, gubernamentales y privadas, y convertirse en un modelo competitivo para las oportunidades de financiación externa. El objetivo general de TIGRE es apoyar los intereses de los usuarios locales, universitarios y regionales y ofrecer vías para conectar con proyectos nacionales de Red como Open Science Grid [5] y TeraGrid [6]. Dentro del área de aplicación estratégica de exploración energética, hemos habilitado el enfoque conjunto Kalman Filter (EnKF) [7] para la asimilación de datos en el modelado de reservorios y hemos demostrado la extensibilidad de la aplicación utilizando el entorno TIGRE y el metaprogramador GridWay [8]. En la sección 2 se ofrece una visión general del entorno y las capacidades de TIGRE. La descripción de la aplicación y la necesidad de una metodología EnKF compatible con la cuadrícula figuran en la sección 3. Los detalles de la aplicación y los méritos de nuestro enfoque se examinan en la sección 4. Las conclusiones figuran en la sección 5. Por último, en la sección 6 se documentan las observaciones y la experiencia adquirida. 2. TIGRE ENTORNO El MIddleware TIGRE Grid consiste en un conjunto mínimo de componentes derivados de un subconjunto del Virtual Data Toolkit (VDT) [9] que soporta una variedad de sistemas operativos. El propósito de elegir una pila de software mínima es apoyar las aplicaciones disponibles y simplificar la instalación y distribución de las pilas cliente/servidor en los sitios de TIGRE. Se añadirán componentes adicionales a medida que sean necesarios. El mecanismo de packaging y distribución PacMan [10] se emplea para la instalación y gestión del cliente/servidor TIGRE. El mecanismo de distribución de PacMan implica la recuperación, instalación y a menudo configuración del software empaquetado. Este enfoque permite a los clientes mantener versiones actualizadas y consistentes del software TIGRE. También ayuda a los sitios TIGRE a instalar los componentes necesarios en los recursos distribuidos en los sitios participantes. La pila cliente/servidor TIGRE consiste en una capa de autenticación y autorización, Globus GRAM4-basada en la presentación de trabajos a través de servicios web (las instalaciones de servicios pre-web están disponibles bajo petición). Las herramientas para manejar la generación de proxy de cuadrícula, la transferencia de archivos habilitada para cuadrícula y el inicio de sesión remoto habilitado para cuadrícula son compatibles. A continuación se proporcionan los detalles pertinentes de los servicios y herramientas de TIGRE para la programación y gestión de puestos. 2.1. Autoridad certificadora La infraestructura de seguridad TIGRE incluye una autoridad certificadora (CA) acreditada por la International Grid Trust Federation (IGTF) para emitir X. 509 certificados de usuario y recurso Grid [11]. El Texas Advanced Computing Center (TACC), Universidad de Texas en Austin, es el TIGREs CA compartido. Las instituciones de TIGRE actúan como autoridades de registro (RA) para sus respectivas bases de usuarios locales. Para obtener información actualizada sobre la seguridad de los certificados de usuario y de recursos y sus instrucciones de instalación, véase ref [2]. Los usuarios y hosts de TIGRE son identificados por su distinguido nombre (DN) en su certificado X.509 proporcionado por la CA. Un archivo nativo Grid-mapfile que contiene una lista de DNs autorizados se utiliza para autenticar y autorizar la programación y gestión de trabajos de los usuarios en los recursos del sitio TIGRE. En la Universidad Texas Tech, a los usuarios se les asigna dinámicamente una de las muchas cuentas genéricas. Esto se logra a través del Sistema de Gestión de Usuarios de Red (GUMS) [12]. 2.2. Programación y gestión de empleos El entorno TIGRE apoya la presentación de trabajos basada en GRAM4 a través de servicios web. Los scripts de envío de trabajos se generan usando XML. Los servicios web GRAM traducen los scripts XML en programadores de lotes específicos de grupos de destino como LSF, PBS o SGE. Los protocolos de transferencia de archivos de alto ancho de banda como GridFTP se utilizan para estadificación de archivos dentro y fuera de la máquina de destino. El acceso a hosts remotos para compilar y depurar es sólo a través del servicio GSISSH que requiere autenticación de recursos a través de certificados X.509. La autenticación y autorización de los trabajos de Grid se gestionan mediante la emisión de certificados de Grid a usuarios y anfitriones. Las listas de revocación de certificados (CRL) se actualizan diariamente para mantener altos estándares de seguridad de los servicios de TIGRE Grid. El área de documentación del portal TIGRE [2] proporciona un tutorial de inicio rápido sobre cómo ejecutar trabajos en TIGRE. 2.3. Metascheduler El metascheduler interopera con los programadores de lotes de nivel de cluster (como LSF, PBS) en la gestión general del flujo de trabajo de Grid. En el presente trabajo, hemos empleado el metaprogramador GridWay [8] -un proyecto de incubadora Globus- para programar y gestionar trabajos en TIGRE. El GridWay es un metaprogramador ligero que utiliza plenamente las funcionalidades de Globus. Está diseñado para proporcionar un uso eficiente de los recursos dinámicos de Grid por múltiples usuarios para las infraestructuras de Grid construidas sobre los servicios de Globus. El administrador del sitio TIGRE puede controlar el uso compartido de recursos a través de un potente programador integrado proporcionado por GridWay o ampliando el módulo de programación externa GridWays para proporcionar sus propias políticas de programación. Los usuarios de aplicaciones pueden escribir descripciones de trabajos usando el formato de plantilla de trabajo simple y directo de GridWays (ver Sección 4 para más detalles) o el lenguaje estándar de descripción de la presentación de trabajos (JSDL). Para más detalles sobre la aplicación, véase la sección 4. 2.4. Sistema de Gestión de Servicios al Cliente Un portal TIGRE [2] fue diseñado e implementado para interconectar usuarios y proveedores de recursos. Fue diseñado utilizando GridPort [13] y es mantenido por TACC. El entorno TIGRE es compatible con herramientas de código abierto como el Open Ticket Request System (OTRS) [14] para el servicio de tickets de problemas, y MoinMoin [15] Wiki para la gestión de contenido y conocimiento de TIGRE para educación, extensión y capacitación. Los enlaces para OTRS y Wiki son consumidos por el portal TIGRE [2] - el portal para usuarios y proveedores de recursos. El estado y las cargas de los recursos de TIGRE son monitoreados por el servicio de Repositorio de Información de Puertos Grid (GPIR) del kit de herramientas GridPort [13] que interactúa con el servicio local de monitoreo de carga de clústeres como Ganglia. El GPIR utiliza trabajos de cron en cada recurso para reunir características específicas de los recursos del sitio, tales como trabajos que se ejecutan, en cola y esperando la asignación de recursos. 3. APLICACIÓN ENSEMBLE KALMAN FILTER El objetivo principal de las simulaciones de yacimientos de hidrocarburos es predecir el comportamiento de la producción de yacimientos de petróleo y gas (denominados en lo sucesivo campo) para su desarrollo y gestión óptima. En el modelado de yacimientos, el campo se divide en varios modelos geológicos, como se muestra en la Figura 1. Para una previsión precisa del rendimiento del campo, es necesario conciliar varios modelos geológicos con la respuesta dinámica del campo a través de la coincidencia histórica [16-20]. Gráfico 1 Vista transversal del Campo. Las capas verticales corresponden a diferentes modelos geológicos y los clavos son pozos de aceite cuya información histórica se utilizará para predecir el comportamiento de la producción. (Figura Ref:http://faculty.smu.edu/zchen/research.html). El EnKF es un método de Monte Carlo que trabaja con un conjunto de modelos de embalses. Este método utiliza covarianzas cruzadas [21] entre las mediciones de campo y los parámetros del modelo de reservorio (derivados de varios modelos) para estimar las incertidumbres de predicción. Los parámetros del modelo geológico en el conjunto se actualizan secuencialmente con el objetivo de minimizar las incertidumbres de predicción. La respuesta histórica de la producción del campo durante más de 50 años se utiliza en estas simulaciones. La principal ventaja de EnKF es que puede vincularse fácilmente a cualquier simulador de depósito, y puede asimilar los últimos datos de producción sin necesidad de volver a ejecutar el simulador desde las condiciones iniciales. Investigadores en Texas son grandes suscriptores del paquete de Schlumberger ECLIPSE [22] para simulaciones de reservorios. En el modelado del embalse, cada modelo geológico comprueba una licencia ECLIPSE. La duración de la simulación de la metodología EnKF depende del número de modelos geológicos utilizados, el número de licencias ECLIPSE disponibles, la historia de producción del campo y las incertidumbres propagadas en la correspondencia de la historia. El flujo de trabajo general de EnKF se muestra en la Figura 2. Gráfico 2 Ensemble Kaman Filter Data Assimulation Workflow. Cada sitio tiene licencias L. En START, el proceso maestro/control (programa principal EnKF) lee el archivo de configuración de simulación para el número (N) de modelos y archivos de entrada específicos del modelo. A continuación, N directorios de trabajo se crean para almacenar los archivos de salida. Al final de la iteración, el proceso maestro/control recoge los archivos de salida de los modelos N y las crosscovarianzas de los procesos posteriores [21] para estimar las incertidumbres de predicción. Esta información se utilizará para actualizar modelos (o archivos de entrada) para la siguiente iteración. La simulación continúa hasta agotar las historias de producción. La simulación típica de EnKF con N=50 y historias de campo de 50-60 años, en pasos de tiempo que van de tres meses a un año, toma unas tres semanas en un entorno de computación en serie. En el entorno informático paralelo, no hay comunicación interproceso entre los modelos geológicos en el conjunto. Sin embargo, al final de cada paso del tiempo de simulación, los archivos de salida específicos del modelo deben ser recogidos para analizar covarianzas cruzadas [21] y para preparar el siguiente conjunto de archivos de entrada. Por lo tanto, el modelo maestro-esclavo en el entorno de mensajepassing (MPI) es un paradigma adecuado. En este enfoque, los modelos geológicos son tratados como esclavos y se distribuyen entre los procesadores disponibles. El master Cluster o (TIGRE/GridWay) START Read Configuration File Create N Working Directories Create N Input files Model l Model 2 Model N.. . ECLIPSE in situ Un ECLIPSE in situ B ECLIPSE in situ Z Collect N Model Outputs, Post-process Output files FIN. . . proceso recoge archivos de salida específicos del modelo, analiza y prepara el siguiente conjunto de archivos de entrada para la simulación. Dado que cada modelo geológico comprueba una licencia ECLIPSE, la paralelización de la simulación depende del número de licencias disponibles. Cuando el número de licencias disponible es menor que el número de modelos en el conjunto, uno o más de los nodos del grupo MPI tienen que manejar más de un modelo en serie y, por lo tanto, se tarda más tiempo en completar la simulación. Un Departamento de Ingeniería Petrolera generalmente adquiere 10-15 licencias ECLIPSE, mientras que al menos diez veces más número de licencias sería necesario para simulaciones estándar de la industria. El número de licencias puede incrementarse con la participación de varios departamentos de ingeniería petrolera que apoyan el paquete ECLIPSE. Dado que MPI no se escala muy bien para aplicaciones que involucran clústeres de computación remotos, y para evitar los problemas del firewall con servidores de licencias en todos los dominios administrativos, parece necesario activar el flujo de trabajo de EnKF. Con esta motivación, hemos implementado el flujo de trabajo EnKF habilitado para Grid para el entorno TIGRE y hemos demostrado la paralelización de la aplicación a través de TIGRE usando el metascheduler GridWay. En la siguiente sección figuran más detalles al respecto. 4. DETALLES DE APLICACION Para habilitar Grid-enable el enfoque EnKF, hemos eliminado el código MPI para el procesamiento paralelo y reemplazado por trabajos de N monoprocesador (o sub-trabajos) donde, N es el número de modelos geológicos en el conjunto. Estos sub-trabajos específicos de modelos se distribuyeron a través de sitios TIGRE que soportan el paquete ECLIPSE utilizando el metaprogramador GridWay [8]. Para cada sub-trabajo, hemos construido una plantilla de trabajo GridWay que especifica los archivos ejecutables, de entrada y salida, y los requisitos de recursos. Dado que los recursos de cálculo de TIGRE no se espera que cambien con frecuencia, hemos utilizado la política de descubrimiento de recursos estáticos para GridWay y los sub-trabajos fueron programados dinámicamente a través de los recursos de TIGRE usando GridWay. La Figura 3 representa el archivo de plantilla de subtrabajo para el metaprogramador GridWay. Gráfico 3 Plantilla de subtrabajo GridWay En la Figura 3, REQUISITOS bandera se establece para elegir los recursos que satisfacen los requisitos de la aplicación. En el caso de la aplicación EnKF, por ejemplo, necesitamos recursos que apoyen el paquete ECLIPSE. ARGUMENTS flag especifica el modelo en el conjunto que invocará ECLIPSE en un sitio remoto. INPUT_FILES es preparado por el programa principal de EnKF (o proceso maestro/control) y es transferido por GridWay al sitio remoto donde está desatendido y está preparado para su ejecución. Finalmente, OUTPUT_FILES especifica el nombre y la ubicación donde se escribirán los archivos de salida. Las características de la línea de comandos de GridWay se utilizaron para recopilar y procesar las salidas específicas del modelo para preparar un nuevo conjunto de archivos de entrada. Este paso imita la sincronización del proceso MPI en el modelo maestro-esclavo. Al final de cada iteración, los recursos computacionales y las licencias se devuelven al grupo. La Tabla 1 muestra los sub-trabajos en TIGRE Grid via GridWay usando el comando gwps y para mayor claridad, sólo se mostraron las columnas seleccionadas. USUARIO JID DM EM NOMBRE HOST pingluo 88 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 89 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 90 wrap actv enkf.jt minigar.hp Programación de trabajo a través de TIGRE usando GridWay Metascheduler. DM: Estado de envío, EM: Estado de ejecución, JID es el id de trabajo y HOST corresponde al cluster específico del sitio y su planificador de lotes local. Cuando un trabajo es enviado a GridWay, pasará por una serie de estados de envío (DM) y ejecución (EM). Para DM, los estados incluyen pend(ing), prol(og), wrap(per), epil(og), y hecho. DM=prol significa que el trabajo ha sido programado a un recurso y el directorio de trabajo remoto está en preparación. DM=warp implica que GridWay está ejecutando el envoltorio que a su vez ejecuta la aplicación. DM=epil implica que el trabajo ha terminado de ejecutarse en el sitio remoto y los resultados se están transfiriendo al servidor GridWay. Del mismo modo, cuando EM=pend implica que el trabajo está esperando en la cola para el recurso y el trabajo se está ejecutando cuando EM=actv. Para ver la lista completa de las banderas de mensajes y sus descripciones, consulte la documentación en ref [8]. Hemos demostrado las ejecuciones de EnKF habilitadas para Grid usando GridWay para entorno TIGRE. Los trabajos son tan elegidos que el tiempo de ejecución no supera más de media hora. La simulación incluyó hasta 20 trabajos entre sitios de A&M y TTU con TTU cumpliendo 10 licencias. Para obtener información sobre los recursos, véase el cuadro I. Una de las principales ventajas de la simulación EnKF habilitada por Grid es que tanto los recursos como las licencias se devuelven al grupo al final de cada paso del tiempo de simulación a diferencia del caso de la implementación de MPI donde las licencias y nodos están bloqueados hasta la finalización de la simulación completa. Sin embargo, el hecho de que cada sub-trabajo se programe independientemente a través de GridWay podría posiblemente incurrir en otro retraso de tiempo causado por esperar en la cola para la ejecución en cada paso del tiempo de simulación. Tales retrasos no se esperan EXECUTABLE=runFORWARD NECESIDADES=HOSTNAME=cosmos.tamu.edu  HOSTNAME=antaeus.hpcc.ttu.edu  HOSTNAME=minigar.hpcc.ttu.edu  ARGUMENTOS=001 INPUT_FILES=001.in.tar OUTPUT_FI Hay dos escenarios principales para comparar los enfoques de computación de red y clúster. Escenario I: El cúmulo está muy cargado. El tiempo promedio de espera concebido del trabajo que solicita un gran número de CPUs es generalmente más largo que el tiempo de espera de los trabajos que solicitan una sola CPU. Por lo tanto, el tiempo de espera general podría ser más corto en el enfoque Grid que solicita una sola CPU para cada sub-trabajo muchas veces en comparación con la implementación MPI que requiere un gran número de CPUs en un solo momento. Es evidente que la programación de la cuadrícula es beneficiosa especialmente cuando el clúster está fuertemente cargado y el número solicitado de CPUs para el trabajo del MPI no está fácilmente disponible. Escenario II: El clúster está relativamente menos cargado o disponible en gran medida. Parece que la implementación del MPI es favorable en comparación con la programación de la Rejilla. Sin embargo, la paralelización de la aplicación EnKF depende del número de licencias ECLIPSE e idealmente, el número de licencias debe ser igual al número de modelos en el conjunto. Por lo tanto, si una sola institución no tiene suficiente número de licencias, la disponibilidad del clúster no ayuda tanto como se espera. Dado que el entorno colaborativo, como TIGRE, puede abordar tanto los requisitos de computación como los de recursos de software para la aplicación EnKF, el enfoque compatible con Grid sigue siendo ventajoso sobre la implementación MPI convencional en cualquiera de los escenarios anteriores. 5. CONCLUSIONES Y FUTURO TRABAJO TIGRE es un proyecto de desarrollo de la red de educación superior y su propósito es mantener y ampliar las oportunidades de investigación y educación a través de Texas. Dentro del área de aplicación de exploración energética, hemos habilitado la implementación MPI del conjunto Kalman metodología de asimilación de datos de filtro para la caracterización de reservorios. Esta tarea se llevó a cabo eliminando el código MPI para el procesamiento paralelo y reemplazando con trabajos de un solo procesador uno para cada modelo geológico en el conjunto. Estos trabajos de un solo procesador fueron programados a través de TIGRE a través de GridWay metascheduler. Hemos demostrado que mediante la puesta en común de licencias a través de sitios TIGRE, más modelos geológicos pueden ser manejados en paralelo y por lo tanto concebiblemente mejor precisión de simulación. Este enfoque tiene varias ventajas sobre la implementación de MPI, especialmente cuando un clúster específico del sitio está muy cargado y/o las licencias de número requeridas para la simulación son más que las disponibles en un solo sitio. Hacia el trabajo futuro, sería interesante comparar el tiempo de ejecución entre MPI y las implementaciones de Grid para la aplicación EnKF. Este esfuerzo podría arrojar luz sobre la calidad del servicio (QoS) de los entornos Grid en comparación con la computación de clústers. Otro aspecto de interés en un futuro próximo sería la gestión de recursos de computación y licencia para abordar la gestión de la relación trabajo (o procesador)-licencia. 6. OBSERVACIONES Y MENOS APRENDIZADOS Los esfuerzos que facilitan la red para la aplicación EnKF han proporcionado amplias oportunidades para reunir información sobre la visibilidad y la promesa de los entornos de computación de Grid para el desarrollo y soporte de aplicaciones. Los principales problemas son la seguridad de los datos estándar de la industria y la CV comparable a la computación de clústers. Dado que la investigación de modelado de reservorios involucra datos propietarios del campo, tuvimos que invertir esfuerzos sustanciales inicialmente en educar a los investigadores de aplicaciones sobre la capacidad de los servicios de Grid para apoyar la seguridad de datos estándar de la industria a través de acceso basado en roles y privilegios utilizando el estándar X.509. Con respecto a QoS, los investigadores de aplicaciones esperan niveles de QoS con entornos de cuadrícula. Además, hay una curva de aprendizaje pronunciada en la computación de cuadrícula en comparación con la computación de clúster convencional. Dado que la computación de cuadrícula sigue siendo una tecnología emergente, y abarca varios ámbitos administrativos, la computación de cuadrícula sigue siendo prematura, especialmente en términos del nivel de QoS, aunque ofrece mejores normas de seguridad de los datos en comparación con los grupos de productos básicos. Es nuestra observación que los programas de capacitación y divulgación que comparan y contrastan los entornos de computación de red y clúster serían un enfoque adecuado para mejorar la participación de los usuarios en la computación de red. Este enfoque también ayuda a los usuarios a emparejar sus aplicaciones y habilidades que las cuadrículas pueden ofrecer. En resumen, nuestros esfuerzos a través de TIGRE en la metodología de asimilación de datos de la EnKF demostraron una promesa sustancial en la contratación de investigadores de Ingeniería Petrolera a través de colaboraciones entre campus. Se están realizando esfuerzos para lograr la participación de más escuelas en este esfuerzo. Estos esfuerzos pueden resultar en un aumento de la investigación colaborativa, oportunidades educativas y desarrollo de la fuerza laboral a través de programas de investigación de posgrado/facultad en instituciones TIGRE. 7. AGRADECIMIENTOS Los autores reconocen al Estado de Texas por apoyar el proyecto TIGRE a través del Fondo Empresarial de Texas, y a las Instituciones TIGRE por proporcionar el mecanismo, en el que también participan los autores (Ravi Vadapalli, Taesung Kim y Ping Luo). Los autores agradecen a los investigadores de aplicaciones Prof. Akhil Datta-Gupta de Texas A&M University y Prof. Lloyd Heinze de Texas Tech University por sus discusiones e interés en explotar el entorno TIGRE para ampliar las oportunidades en investigación y desarrollo. 8. REFERENCIAS [1] Foster, I. y Kesselman, C. (eds.) 2004. The Grid: Blueprint for a new computing infraestructura (The Elsevier series in Grid computing) [2] Portal TIGRE: http://tigreportal.hipcat.net [3] Vadapalli, R. Sill, A., Dooley, R., Murray, M., Luo, P., Kim, T., Huang, M., Thyagaraja, K., y Chaffin, Demostración del entorno TIGRE para aplicaciones de cuadrícula habilitadas/adecuadas. 8o IEEE/ACM Int. Conf. on Grid Computing, 19-21 de septiembre, Austin [4] The High Performance Computing cross Texas Consortium http://www.hipcat.net [5] Pordes, R. Petravick, D. Kramer, B. Olson, D. Livny, M. Roy, A. Avery, P. Blackburn, K. Wenaus, T. Würthwein, F. Foster, I. Gar The Open Science Grid, J. Phys Conf Series http://www.iop.org/EJ/abstract/1742-6596/78/1/012057 y http://www.opensciencegrid.org [6] Reed, D.A. 2003. Rejilla, el Teragrid y más allá, Ordenador, vol. 30, no. 1 y http://www.teragrid.org [7] Evensen, G. 2006. Asimilación de datos: El conjunto Kalman Filter, Springer [8] Herrera, J. Huedo, E. Montero, R. S. y Llorente, I. M. 2005. Programación Científica, vol 12, No. 4. pp 317-331 [9] Avery, P. and Foster, I. 2001. El proyecto GriPhyN: Hacia redes virtuales de datos a petaescala, informe técnico GriPhyN-200115 y http://vdt.cs.wisc.edu [10] La guía de documentación e instalación de PacMan http://physics.bu.edu/pacman/htmls [11] Caskey, P. Murray, M. Perez, J. y Sill, A. 2007. Estudios de casos en la gestión de identificación para organizaciones virtuales, EDUCOUSO Southwest Reg. Conf., 21-23 febrero, Austin, TX. http://www.educause.edu/ir/library/pdf/SWR07058.pdf [12] El Sistema de Gestión de Usuarios de Grid (GUMS) https://www.racf.bnl.gov/Facility/GUMS/index.html [13] Thomas, M. y Boisseau, J. 2003. Creación de portales de \"computación por red\": el conjunto de herramientas del portal NPACI, Grid computing: hacer realidad la infraestructura mundial, Capítulo 28, Berman, F. Fox, G. Thomas, M. Boisseau, J. y Hey, T. (eds), John Wiley and Sons, Ltd, Chichester [14] Open Ticket Request System http://otrs.org [ 1999. Integración de datos dinámicos en modelos de depósito de alta resolución utilizando coeficientes de sensibilidad basados en la racionalización, Society of Petroleum Engineers (SPE), 4 (4). [17] Emanuel, A. S. y Milliken, W. J. 1998. Historia que combina modelos de diferencias finitas con racionalizaciones 3D, SPE 49000, Proc de la Conf Técnica Anual y Exposición, 2730 de septiembre, Nueva Orleans, LA. [18] Nævdal, G. Johnsen, L.M. Aanonsen, S.I. y Vefring, E.H. 2003. Monitorización de embalses y actualización continua de modelos utilizando Ensemble Kalman Filter, SPE 84372, Proc del Conf Técnico Anual y Exposición, Oct 5-8, Denver, CO. [19] Jafarpour B. y McLaughlin, D.B. 2007. Historia que coincide con un conjunto de filtro Kalman y parametrización discreta de coseno, SPE 108761, Proc de la Conf Técnica Anual y Exposición, 11-14 de noviembre, Anaheim, CA [20] Li, G. y Reynolds, A. C. 2007. Un conjunto iterativo Kalman filtro para la asimilación de datos, SPE 109808, Proc de la SPE Conf y Exposición Técnica Anual, 11-14 de noviembre, Anaheim, CA [21] Arroyo-Negrete, E. Devagowda, D. Datta-Gupta, A. 2006. Simplificar el conjunto asistido Kalman filtro para la actualización rápida y continua del modelo de depósito. Proc de la Int. Oil & Gas Conf and Exhibition, SPE 104255, Dec 5-7, China [22] ECLIPSE Reservoir Engineering Software http://www.slb.com/content/services/software/reseng/index.a sp ",
            "error": [
                ""
            ]
        },
        "cyberinfrastructure development project": {
            "translated_key": "proyecto de desarrollo de la ciberinfraestructura",
            "translated_annotated_text": "Demostración del conjunto de datos de Kalman Assimulation Method for Reservoir Caracterisation Ravi Vadapalli Centro de computación de alto rendimiento Texas Tech University Lubbock, TX 79409 001-806-742-4350 Ravi.Vadapalli@ttu.edu Ajitabh Kumar Department of Petroleum Engineering Texas A&M University College Station, En este enfoque, se utiliza un conjunto de modelos geológicos y datos de producción de yacimientos de petróleo para predecir la respuesta dinámica de los pozos de petróleo. El software Schlumberger ECLIPSE se utiliza para estas simulaciones. Puesto que los modelos en el conjunto no se comunican, la implementación de mensaje-passing es una buena opción. Cada modelo comprueba una licencia ECLIPSE y, por lo tanto, la paralelización de las simulaciones de reservorio depende de las licencias de número disponibles. Hemos habilitado Grid para el conjunto Kalman metodología de asimilación de datos de filtro para el entorno de computación TIGRE Grid. Al poner en común las licencias y los recursos informáticos en todas las instituciones colaboradoras utilizando el metaprogramador GridWay y el entorno TIGRE, la precisión computacional puede aumentarse al tiempo que se reduce el tiempo de ejecución de la simulación. En este artículo, proporcionamos un relato de nuestros esfuerzos en Gridenabilizar el conjunto Kalman Filter metodología de asimilación de datos. Se examinarán los posibles beneficios de este enfoque, las observaciones y la experiencia adquirida. Categorías y Descriptores sujetos C 2.4 [Sistemas distribuidos]: Aplicaciones distribuidas Términos generales Algoritmos, Diseño, Rendimiento 1. INTRODUCCIÓN La computación de cuadrícula [1] es un paradigma de computación colaborativa emergente para ampliar las capacidades específicas de computación de alto rendimiento (HPC) mucho más allá de los recursos locales. Su importancia se deriva del hecho de que la investigación innovadora en áreas de aplicación estratégicas como la biociencia y la medicina, la exploración de energía y el modelado ambiental involucran componentes interdisciplinarios fuertes y a menudo requieren colaboraciones intercampus y capacidades computacionales más allá de las limitaciones institucionales. The Texas Internet Grid for Research and Education (TIGRE) [2,3] es un \"proyecto de desarrollo de la ciberinfraestructura\" financiado por el estado, llevado a cabo por cinco grandes sistemas universitarios (Rice, A&M, TTU, UH y UT Austin), llamados colectivamente Instituciones TIGRE. El propósito de TIGRE es crear una red de educación superior para sostener y ampliar las oportunidades de investigación y educación en Texas. TIGRE es un proyecto del consorcio de computación de alto rendimiento en Texas (HiPCAT) [4]. El objetivo de HiPCAT es apoyar tecnologías computacionales avanzadas para mejorar la investigación, el desarrollo y las actividades educativas. El objetivo principal de TIGRE es diseñar e implementar middleware Grid de última generación que permita la integración de sistemas de computación, sistemas de almacenamiento y bases de datos, laboratorios de visualización y pantallas, e incluso instrumentos y sensores en Texas. El objetivo secundario es demostrar las capacidades de TIGRE para mejorar las oportunidades de investigación y educación en áreas de aplicación estratégica de interés para el Estado de Texas. Estos son biociencia y medicina, exploración energética y modelado de la calidad del aire. La visión del proyecto TIGRE es fomentar la colaboración interdisciplinaria e intercampus, identificar enfoques novedosos para ampliar las asociaciones académicas, gubernamentales y privadas, y convertirse en un modelo competitivo para las oportunidades de financiación externa. El objetivo general de TIGRE es apoyar los intereses de los usuarios locales, universitarios y regionales y ofrecer vías para conectar con proyectos nacionales de Red como Open Science Grid [5] y TeraGrid [6]. Dentro del área de aplicación estratégica de exploración energética, hemos habilitado el enfoque conjunto Kalman Filter (EnKF) [7] para la asimilación de datos en el modelado de reservorios y hemos demostrado la extensibilidad de la aplicación utilizando el entorno TIGRE y el metaprogramador GridWay [8]. En la sección 2 se ofrece una visión general del entorno y las capacidades de TIGRE. La descripción de la aplicación y la necesidad de una metodología EnKF compatible con la cuadrícula figuran en la sección 3. Los detalles de la aplicación y los méritos de nuestro enfoque se examinan en la sección 4. Las conclusiones figuran en la sección 5. Por último, en la sección 6 se documentan las observaciones y la experiencia adquirida. 2. TIGRE ENTORNO El MIddleware TIGRE Grid consiste en un conjunto mínimo de componentes derivados de un subconjunto del Virtual Data Toolkit (VDT) [9] que soporta una variedad de sistemas operativos. El propósito de elegir una pila de software mínima es apoyar las aplicaciones disponibles y simplificar la instalación y distribución de las pilas cliente/servidor en los sitios de TIGRE. Se añadirán componentes adicionales a medida que sean necesarios. El mecanismo de packaging y distribución PacMan [10] se emplea para la instalación y gestión del cliente/servidor TIGRE. El mecanismo de distribución de PacMan implica la recuperación, instalación y a menudo configuración del software empaquetado. Este enfoque permite a los clientes mantener versiones actualizadas y consistentes del software TIGRE. También ayuda a los sitios TIGRE a instalar los componentes necesarios en los recursos distribuidos en los sitios participantes. La pila cliente/servidor TIGRE consiste en una capa de autenticación y autorización, Globus GRAM4-basada en la presentación de trabajos a través de servicios web (las instalaciones de servicios pre-web están disponibles bajo petición). Las herramientas para manejar la generación de proxy de cuadrícula, la transferencia de archivos habilitada para cuadrícula y el inicio de sesión remoto habilitado para cuadrícula son compatibles. A continuación se proporcionan los detalles pertinentes de los servicios y herramientas de TIGRE para la programación y gestión de puestos. 2.1. Autoridad certificadora La infraestructura de seguridad TIGRE incluye una autoridad certificadora (CA) acreditada por la International Grid Trust Federation (IGTF) para emitir X. 509 certificados de usuario y recurso Grid [11]. El Texas Advanced Computing Center (TACC), Universidad de Texas en Austin, es el TIGREs CA compartido. Las instituciones de TIGRE actúan como autoridades de registro (RA) para sus respectivas bases de usuarios locales. Para obtener información actualizada sobre la seguridad de los certificados de usuario y de recursos y sus instrucciones de instalación, véase ref [2]. Los usuarios y hosts de TIGRE son identificados por su distinguido nombre (DN) en su certificado X.509 proporcionado por la CA. Un archivo nativo Grid-mapfile que contiene una lista de DNs autorizados se utiliza para autenticar y autorizar la programación y gestión de trabajos de los usuarios en los recursos del sitio TIGRE. En la Universidad Texas Tech, a los usuarios se les asigna dinámicamente una de las muchas cuentas genéricas. Esto se logra a través del Sistema de Gestión de Usuarios de Red (GUMS) [12]. 2.2. Programación y gestión de empleos El entorno TIGRE apoya la presentación de trabajos basada en GRAM4 a través de servicios web. Los scripts de envío de trabajos se generan usando XML. Los servicios web GRAM traducen los scripts XML en programadores de lotes específicos de grupos de destino como LSF, PBS o SGE. Los protocolos de transferencia de archivos de alto ancho de banda como GridFTP se utilizan para estadificación de archivos dentro y fuera de la máquina de destino. El acceso a hosts remotos para compilar y depurar es sólo a través del servicio GSISSH que requiere autenticación de recursos a través de certificados X.509. La autenticación y autorización de los trabajos de Grid se gestionan mediante la emisión de certificados de Grid a usuarios y anfitriones. Las listas de revocación de certificados (CRL) se actualizan diariamente para mantener altos estándares de seguridad de los servicios de TIGRE Grid. El área de documentación del portal TIGRE [2] proporciona un tutorial de inicio rápido sobre cómo ejecutar trabajos en TIGRE. 2.3. Metascheduler El metascheduler interopera con los programadores de lotes de nivel de cluster (como LSF, PBS) en la gestión general del flujo de trabajo de Grid. En el presente trabajo, hemos empleado el metaprogramador GridWay [8] -un proyecto de incubadora Globus- para programar y gestionar trabajos en TIGRE. El GridWay es un metaprogramador ligero que utiliza plenamente las funcionalidades de Globus. Está diseñado para proporcionar un uso eficiente de los recursos dinámicos de Grid por múltiples usuarios para las infraestructuras de Grid construidas sobre los servicios de Globus. El administrador del sitio TIGRE puede controlar el uso compartido de recursos a través de un potente programador integrado proporcionado por GridWay o ampliando el módulo de programación externa GridWays para proporcionar sus propias políticas de programación. Los usuarios de aplicaciones pueden escribir descripciones de trabajos usando el formato de plantilla de trabajo simple y directo de GridWays (ver Sección 4 para más detalles) o el lenguaje estándar de descripción de la presentación de trabajos (JSDL). Para más detalles sobre la aplicación, véase la sección 4. 2.4. Sistema de Gestión de Servicios al Cliente Un portal TIGRE [2] fue diseñado e implementado para interconectar usuarios y proveedores de recursos. Fue diseñado utilizando GridPort [13] y es mantenido por TACC. El entorno TIGRE es compatible con herramientas de código abierto como el Open Ticket Request System (OTRS) [14] para el servicio de tickets de problemas, y MoinMoin [15] Wiki para la gestión de contenido y conocimiento de TIGRE para educación, extensión y capacitación. Los enlaces para OTRS y Wiki son consumidos por el portal TIGRE [2] - el portal para usuarios y proveedores de recursos. El estado y las cargas de los recursos de TIGRE son monitoreados por el servicio de Repositorio de Información de Puertos Grid (GPIR) del kit de herramientas GridPort [13] que interactúa con el servicio local de monitoreo de carga de clústeres como Ganglia. El GPIR utiliza trabajos de cron en cada recurso para reunir características específicas de los recursos del sitio, tales como trabajos que se ejecutan, en cola y esperando la asignación de recursos. 3. APLICACIÓN ENSEMBLE KALMAN FILTER El objetivo principal de las simulaciones de yacimientos de hidrocarburos es predecir el comportamiento de la producción de yacimientos de petróleo y gas (denominados en lo sucesivo campo) para su desarrollo y gestión óptima. En el modelado de yacimientos, el campo se divide en varios modelos geológicos, como se muestra en la Figura 1. Para una previsión precisa del rendimiento del campo, es necesario conciliar varios modelos geológicos con la respuesta dinámica del campo a través de la coincidencia histórica [16-20]. Gráfico 1 Vista transversal del Campo. Las capas verticales corresponden a diferentes modelos geológicos y los clavos son pozos de aceite cuya información histórica se utilizará para predecir el comportamiento de la producción. (Figura Ref:http://faculty.smu.edu/zchen/research.html). El EnKF es un método de Monte Carlo que trabaja con un conjunto de modelos de embalses. Este método utiliza covarianzas cruzadas [21] entre las mediciones de campo y los parámetros del modelo de reservorio (derivados de varios modelos) para estimar las incertidumbres de predicción. Los parámetros del modelo geológico en el conjunto se actualizan secuencialmente con el objetivo de minimizar las incertidumbres de predicción. La respuesta histórica de la producción del campo durante más de 50 años se utiliza en estas simulaciones. La principal ventaja de EnKF es que puede vincularse fácilmente a cualquier simulador de depósito, y puede asimilar los últimos datos de producción sin necesidad de volver a ejecutar el simulador desde las condiciones iniciales. Investigadores en Texas son grandes suscriptores del paquete de Schlumberger ECLIPSE [22] para simulaciones de reservorios. En el modelado del embalse, cada modelo geológico comprueba una licencia ECLIPSE. La duración de la simulación de la metodología EnKF depende del número de modelos geológicos utilizados, el número de licencias ECLIPSE disponibles, la historia de producción del campo y las incertidumbres propagadas en la correspondencia de la historia. El flujo de trabajo general de EnKF se muestra en la Figura 2. Gráfico 2 Ensemble Kaman Filter Data Assimulation Workflow. Cada sitio tiene licencias L. En START, el proceso maestro/control (programa principal EnKF) lee el archivo de configuración de simulación para el número (N) de modelos y archivos de entrada específicos del modelo. A continuación, N directorios de trabajo se crean para almacenar los archivos de salida. Al final de la iteración, el proceso maestro/control recoge los archivos de salida de los modelos N y las crosscovarianzas de los procesos posteriores [21] para estimar las incertidumbres de predicción. Esta información se utilizará para actualizar modelos (o archivos de entrada) para la siguiente iteración. La simulación continúa hasta agotar las historias de producción. La simulación típica de EnKF con N=50 y historias de campo de 50-60 años, en pasos de tiempo que van de tres meses a un año, toma unas tres semanas en un entorno de computación en serie. En el entorno informático paralelo, no hay comunicación interproceso entre los modelos geológicos en el conjunto. Sin embargo, al final de cada paso del tiempo de simulación, los archivos de salida específicos del modelo deben ser recogidos para analizar covarianzas cruzadas [21] y para preparar el siguiente conjunto de archivos de entrada. Por lo tanto, el modelo maestro-esclavo en el entorno de mensajepassing (MPI) es un paradigma adecuado. En este enfoque, los modelos geológicos son tratados como esclavos y se distribuyen entre los procesadores disponibles. El master Cluster o (TIGRE/GridWay) START Read Configuration File Create N Working Directories Create N Input files Model l Model 2 Model N.. . ECLIPSE in situ Un ECLIPSE in situ B ECLIPSE in situ Z Collect N Model Outputs, Post-process Output files FIN. . . proceso recoge archivos de salida específicos del modelo, analiza y prepara el siguiente conjunto de archivos de entrada para la simulación. Dado que cada modelo geológico comprueba una licencia ECLIPSE, la paralelización de la simulación depende del número de licencias disponibles. Cuando el número de licencias disponible es menor que el número de modelos en el conjunto, uno o más de los nodos del grupo MPI tienen que manejar más de un modelo en serie y, por lo tanto, se tarda más tiempo en completar la simulación. Un Departamento de Ingeniería Petrolera generalmente adquiere 10-15 licencias ECLIPSE, mientras que al menos diez veces más número de licencias sería necesario para simulaciones estándar de la industria. El número de licencias puede incrementarse con la participación de varios departamentos de ingeniería petrolera que apoyan el paquete ECLIPSE. Dado que MPI no se escala muy bien para aplicaciones que involucran clústeres de computación remotos, y para evitar los problemas del firewall con servidores de licencias en todos los dominios administrativos, parece necesario activar el flujo de trabajo de EnKF. Con esta motivación, hemos implementado el flujo de trabajo EnKF habilitado para Grid para el entorno TIGRE y hemos demostrado la paralelización de la aplicación a través de TIGRE usando el metascheduler GridWay. En la siguiente sección figuran más detalles al respecto. 4. DETALLES DE APLICACION Para habilitar Grid-enable el enfoque EnKF, hemos eliminado el código MPI para el procesamiento paralelo y reemplazado por trabajos de N monoprocesador (o sub-trabajos) donde, N es el número de modelos geológicos en el conjunto. Estos sub-trabajos específicos de modelos se distribuyeron a través de sitios TIGRE que soportan el paquete ECLIPSE utilizando el metaprogramador GridWay [8]. Para cada sub-trabajo, hemos construido una plantilla de trabajo GridWay que especifica los archivos ejecutables, de entrada y salida, y los requisitos de recursos. Dado que los recursos de cálculo de TIGRE no se espera que cambien con frecuencia, hemos utilizado la política de descubrimiento de recursos estáticos para GridWay y los sub-trabajos fueron programados dinámicamente a través de los recursos de TIGRE usando GridWay. La Figura 3 representa el archivo de plantilla de subtrabajo para el metaprogramador GridWay. Gráfico 3 Plantilla de subtrabajo GridWay En la Figura 3, REQUISITOS bandera se establece para elegir los recursos que satisfacen los requisitos de la aplicación. En el caso de la aplicación EnKF, por ejemplo, necesitamos recursos que apoyen el paquete ECLIPSE. ARGUMENTS flag especifica el modelo en el conjunto que invocará ECLIPSE en un sitio remoto. INPUT_FILES es preparado por el programa principal de EnKF (o proceso maestro/control) y es transferido por GridWay al sitio remoto donde está desatendido y está preparado para su ejecución. Finalmente, OUTPUT_FILES especifica el nombre y la ubicación donde se escribirán los archivos de salida. Las características de la línea de comandos de GridWay se utilizaron para recopilar y procesar las salidas específicas del modelo para preparar un nuevo conjunto de archivos de entrada. Este paso imita la sincronización del proceso MPI en el modelo maestro-esclavo. Al final de cada iteración, los recursos computacionales y las licencias se devuelven al grupo. La Tabla 1 muestra los sub-trabajos en TIGRE Grid via GridWay usando el comando gwps y para mayor claridad, sólo se mostraron las columnas seleccionadas. USUARIO JID DM EM NOMBRE HOST pingluo 88 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 89 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 90 wrap actv enkf.jt minigar.hp Programación de trabajo a través de TIGRE usando GridWay Metascheduler. DM: Estado de envío, EM: Estado de ejecución, JID es el id de trabajo y HOST corresponde al cluster específico del sitio y su planificador de lotes local. Cuando un trabajo es enviado a GridWay, pasará por una serie de estados de envío (DM) y ejecución (EM). Para DM, los estados incluyen pend(ing), prol(og), wrap(per), epil(og), y hecho. DM=prol significa que el trabajo ha sido programado a un recurso y el directorio de trabajo remoto está en preparación. DM=warp implica que GridWay está ejecutando el envoltorio que a su vez ejecuta la aplicación. DM=epil implica que el trabajo ha terminado de ejecutarse en el sitio remoto y los resultados se están transfiriendo al servidor GridWay. Del mismo modo, cuando EM=pend implica que el trabajo está esperando en la cola para el recurso y el trabajo se está ejecutando cuando EM=actv. Para ver la lista completa de las banderas de mensajes y sus descripciones, consulte la documentación en ref [8]. Hemos demostrado las ejecuciones de EnKF habilitadas para Grid usando GridWay para entorno TIGRE. Los trabajos son tan elegidos que el tiempo de ejecución no supera más de media hora. La simulación incluyó hasta 20 trabajos entre sitios de A&M y TTU con TTU cumpliendo 10 licencias. Para obtener información sobre los recursos, véase el cuadro I. Una de las principales ventajas de la simulación EnKF habilitada por Grid es que tanto los recursos como las licencias se devuelven al grupo al final de cada paso del tiempo de simulación a diferencia del caso de la implementación de MPI donde las licencias y nodos están bloqueados hasta la finalización de la simulación completa. Sin embargo, el hecho de que cada sub-trabajo se programe independientemente a través de GridWay podría posiblemente incurrir en otro retraso de tiempo causado por esperar en la cola para la ejecución en cada paso del tiempo de simulación. Tales retrasos no se esperan EXECUTABLE=runFORWARD NECESIDADES=HOSTNAME=cosmos.tamu.edu  HOSTNAME=antaeus.hpcc.ttu.edu  HOSTNAME=minigar.hpcc.ttu.edu  ARGUMENTOS=001 INPUT_FILES=001.in.tar OUTPUT_FI Hay dos escenarios principales para comparar los enfoques de computación de red y clúster. Escenario I: El cúmulo está muy cargado. El tiempo promedio de espera concebido del trabajo que solicita un gran número de CPUs es generalmente más largo que el tiempo de espera de los trabajos que solicitan una sola CPU. Por lo tanto, el tiempo de espera general podría ser más corto en el enfoque Grid que solicita una sola CPU para cada sub-trabajo muchas veces en comparación con la implementación MPI que requiere un gran número de CPUs en un solo momento. Es evidente que la programación de la cuadrícula es beneficiosa especialmente cuando el clúster está fuertemente cargado y el número solicitado de CPUs para el trabajo del MPI no está fácilmente disponible. Escenario II: El clúster está relativamente menos cargado o disponible en gran medida. Parece que la implementación del MPI es favorable en comparación con la programación de la Rejilla. Sin embargo, la paralelización de la aplicación EnKF depende del número de licencias ECLIPSE e idealmente, el número de licencias debe ser igual al número de modelos en el conjunto. Por lo tanto, si una sola institución no tiene suficiente número de licencias, la disponibilidad del clúster no ayuda tanto como se espera. Dado que el entorno colaborativo, como TIGRE, puede abordar tanto los requisitos de computación como los de recursos de software para la aplicación EnKF, el enfoque compatible con Grid sigue siendo ventajoso sobre la implementación MPI convencional en cualquiera de los escenarios anteriores. 5. CONCLUSIONES Y FUTURO TRABAJO TIGRE es un proyecto de desarrollo de la red de educación superior y su propósito es mantener y ampliar las oportunidades de investigación y educación a través de Texas. Dentro del área de aplicación de exploración energética, hemos habilitado la implementación MPI del conjunto Kalman metodología de asimilación de datos de filtro para la caracterización de reservorios. Esta tarea se llevó a cabo eliminando el código MPI para el procesamiento paralelo y reemplazando con trabajos de un solo procesador uno para cada modelo geológico en el conjunto. Estos trabajos de un solo procesador fueron programados a través de TIGRE a través de GridWay metascheduler. Hemos demostrado que mediante la puesta en común de licencias a través de sitios TIGRE, más modelos geológicos pueden ser manejados en paralelo y por lo tanto concebiblemente mejor precisión de simulación. Este enfoque tiene varias ventajas sobre la implementación de MPI, especialmente cuando un clúster específico del sitio está muy cargado y/o las licencias de número requeridas para la simulación son más que las disponibles en un solo sitio. Hacia el trabajo futuro, sería interesante comparar el tiempo de ejecución entre MPI y las implementaciones de Grid para la aplicación EnKF. Este esfuerzo podría arrojar luz sobre la calidad del servicio (QoS) de los entornos Grid en comparación con la computación de clústers. Otro aspecto de interés en un futuro próximo sería la gestión de recursos de computación y licencia para abordar la gestión de la relación trabajo (o procesador)-licencia. 6. OBSERVACIONES Y MENOS APRENDIZADOS Los esfuerzos que facilitan la red para la aplicación EnKF han proporcionado amplias oportunidades para reunir información sobre la visibilidad y la promesa de los entornos de computación de Grid para el desarrollo y soporte de aplicaciones. Los principales problemas son la seguridad de los datos estándar de la industria y la CV comparable a la computación de clústers. Dado que la investigación de modelado de reservorios involucra datos propietarios del campo, tuvimos que invertir esfuerzos sustanciales inicialmente en educar a los investigadores de aplicaciones sobre la capacidad de los servicios de Grid para apoyar la seguridad de datos estándar de la industria a través de acceso basado en roles y privilegios utilizando el estándar X.509. Con respecto a QoS, los investigadores de aplicaciones esperan niveles de QoS con entornos de cuadrícula. Además, hay una curva de aprendizaje pronunciada en la computación de cuadrícula en comparación con la computación de clúster convencional. Dado que la computación de cuadrícula sigue siendo una tecnología emergente, y abarca varios ámbitos administrativos, la computación de cuadrícula sigue siendo prematura, especialmente en términos del nivel de QoS, aunque ofrece mejores normas de seguridad de los datos en comparación con los grupos de productos básicos. Es nuestra observación que los programas de capacitación y divulgación que comparan y contrastan los entornos de computación de red y clúster serían un enfoque adecuado para mejorar la participación de los usuarios en la computación de red. Este enfoque también ayuda a los usuarios a emparejar sus aplicaciones y habilidades que las cuadrículas pueden ofrecer. En resumen, nuestros esfuerzos a través de TIGRE en la metodología de asimilación de datos de la EnKF demostraron una promesa sustancial en la contratación de investigadores de Ingeniería Petrolera a través de colaboraciones entre campus. Se están realizando esfuerzos para lograr la participación de más escuelas en este esfuerzo. Estos esfuerzos pueden resultar en un aumento de la investigación colaborativa, oportunidades educativas y desarrollo de la fuerza laboral a través de programas de investigación de posgrado/facultad en instituciones TIGRE. 7. AGRADECIMIENTOS Los autores reconocen al Estado de Texas por apoyar el proyecto TIGRE a través del Fondo Empresarial de Texas, y a las Instituciones TIGRE por proporcionar el mecanismo, en el que también participan los autores (Ravi Vadapalli, Taesung Kim y Ping Luo). Los autores agradecen a los investigadores de aplicaciones Prof. Akhil Datta-Gupta de Texas A&M University y Prof. Lloyd Heinze de Texas Tech University por sus discusiones e interés en explotar el entorno TIGRE para ampliar las oportunidades en investigación y desarrollo. 8. REFERENCIAS [1] Foster, I. y Kesselman, C. (eds.) 2004. The Grid: Blueprint for a new computing infraestructura (The Elsevier series in Grid computing) [2] Portal TIGRE: http://tigreportal.hipcat.net [3] Vadapalli, R. Sill, A., Dooley, R., Murray, M., Luo, P., Kim, T., Huang, M., Thyagaraja, K., y Chaffin, Demostración del entorno TIGRE para aplicaciones de cuadrícula habilitadas/adecuadas. 8o IEEE/ACM Int. Conf. on Grid Computing, 19-21 de septiembre, Austin [4] The High Performance Computing cross Texas Consortium http://www.hipcat.net [5] Pordes, R. Petravick, D. Kramer, B. Olson, D. Livny, M. Roy, A. Avery, P. Blackburn, K. Wenaus, T. Würthwein, F. Foster, I. Gar The Open Science Grid, J. Phys Conf Series http://www.iop.org/EJ/abstract/1742-6596/78/1/012057 y http://www.opensciencegrid.org [6] Reed, D.A. 2003. Rejilla, el Teragrid y más allá, Ordenador, vol. 30, no. 1 y http://www.teragrid.org [7] Evensen, G. 2006. Asimilación de datos: El conjunto Kalman Filter, Springer [8] Herrera, J. Huedo, E. Montero, R. S. y Llorente, I. M. 2005. Programación Científica, vol 12, No. 4. pp 317-331 [9] Avery, P. and Foster, I. 2001. El proyecto GriPhyN: Hacia redes virtuales de datos a petaescala, informe técnico GriPhyN-200115 y http://vdt.cs.wisc.edu [10] La guía de documentación e instalación de PacMan http://physics.bu.edu/pacman/htmls [11] Caskey, P. Murray, M. Perez, J. y Sill, A. 2007. Estudios de casos en la gestión de identificación para organizaciones virtuales, EDUCOUSO Southwest Reg. Conf., 21-23 febrero, Austin, TX. http://www.educause.edu/ir/library/pdf/SWR07058.pdf [12] El Sistema de Gestión de Usuarios de Grid (GUMS) https://www.racf.bnl.gov/Facility/GUMS/index.html [13] Thomas, M. y Boisseau, J. 2003. Construyendo portales de computación de cuadrículas: El kit de herramientas para el portal de cuadrículas NPACI, Grid computing: haciendo realidad la infraestructura global, Capítulo 28, Berman, F. Fox, G. Thomas, M. Boisseau, J. y Hey, T. (eds), John Wiley and Sons, Ltd, Chichester [14] Open Ticket Request System http:// 1999. Integración de datos dinámicos en modelos de depósito de alta resolución utilizando coeficientes de sensibilidad basados en la racionalización, Society of Petroleum Engineers (SPE), 4 (4). [17] Emanuel, A. S. y Milliken, W. J. 1998. Historia que combina modelos de diferencias finitas con racionalizaciones 3D, SPE 49000, Proc de la Conf Técnica Anual y Exposición, 2730 de septiembre, Nueva Orleans, LA. [18] Nævdal, G. Johnsen, L.M. Aanonsen, S.I. y Vefring, E.H. 2003. Monitorización de embalses y actualización continua de modelos utilizando Ensemble Kalman Filter, SPE 84372, Proc del Conf Técnico Anual y Exposición, Oct 5-8, Denver, CO. [19] Jafarpour B. y McLaughlin, D.B. 2007. Historia que coincide con un conjunto de filtro Kalman y parametrización discreta de coseno, SPE 108761, Proc de la Conf Técnica Anual y Exposición, 11-14 de noviembre, Anaheim, CA [20] Li, G. y Reynolds, A. C. 2007. Un conjunto iterativo Kalman filtro para la asimilación de datos, SPE 109808, Proc de la SPE Conf y Exposición Técnica Anual, 11-14 de noviembre, Anaheim, CA [21] Arroyo-Negrete, E. Devagowda, D. Datta-Gupta, A. 2006. Simplificar el conjunto asistido Kalman filtro para la actualización rápida y continua del modelo de depósito. Proc de la Int. Oil & Gas Conf and Exhibition, SPE 104255, Dec 5-7, China [22] ECLIPSE Reservoir Engineering Software http://www.slb.com/content/services/software/reseng/index.a sp ",
            "error": [
                ""
            ]
        },
        "high performance computing": {
            "translated_key": "computación de alto rendimiento",
            "translated_annotated_text": "Demostración del conjunto de datos de Kalman Assimulation Method for Reservoir Caracterisation Ravi Vadapalli Centro de computación de alto rendimiento Texas Tech University Lubbock, TX 79409 001-806-742-4350 Ravi.Vadapalli@ttu.edu Ajitabh Kumar Department of Petroleum Engineering Texas A&M University College Station, En este enfoque, se utiliza un conjunto de modelos geológicos y datos de producción de yacimientos de petróleo para predecir la respuesta dinámica de los pozos de petróleo. El software Schlumberger ECLIPSE se utiliza para estas simulaciones. Puesto que los modelos en el conjunto no se comunican, la implementación de mensaje-passing es una buena opción. Cada modelo comprueba una licencia ECLIPSE y, por lo tanto, la paralelización de las simulaciones de reservorio depende de las licencias de número disponibles. Hemos habilitado Grid para el conjunto Kalman metodología de asimilación de datos de filtro para el entorno de computación TIGRE Grid. Al poner en común las licencias y los recursos informáticos en todas las instituciones colaboradoras utilizando el metaprogramador GridWay y el entorno TIGRE, la precisión computacional puede aumentarse al tiempo que se reduce el tiempo de ejecución de la simulación. En este artículo, proporcionamos un relato de nuestros esfuerzos en Gridenabilizar el conjunto Kalman Filter metodología de asimilación de datos. Se examinarán los posibles beneficios de este enfoque, las observaciones y la experiencia adquirida. Categorías y Descriptores sujetos C 2.4 [Sistemas distribuidos]: Aplicaciones distribuidas Términos generales Algoritmos, Diseño, Rendimiento 1. INTRODUCCIÓN La computación de cuadrícula [1] es un paradigma de computación colaborativa emergente para ampliar las capacidades específicas de \"computación de alto rendimiento\" (HPC) mucho más allá de los recursos locales. Su importancia se deriva del hecho de que la investigación innovadora en áreas de aplicación estratégicas como la biociencia y la medicina, la exploración de energía y el modelado ambiental involucran componentes interdisciplinarios fuertes y a menudo requieren colaboraciones intercampus y capacidades computacionales más allá de las limitaciones institucionales. The Texas Internet Grid for Research and Education (TIGRE) [2,3] es un proyecto de desarrollo de infraestructuras cibernéticas financiado por el estado, llevado a cabo por cinco grandes sistemas universitarios (Rice, A&M, TTU, UH y UT Austin), llamados colectivamente Instituciones TIGRE. El propósito de TIGRE es crear una red de educación superior para sostener y ampliar las oportunidades de investigación y educación en Texas. TIGRE es un proyecto del consorcio de computación de alto rendimiento en Texas (HiPCAT) [4]. El objetivo de HiPCAT es apoyar tecnologías computacionales avanzadas para mejorar la investigación, el desarrollo y las actividades educativas. El objetivo principal de TIGRE es diseñar e implementar middleware Grid de última generación que permita la integración de sistemas de computación, sistemas de almacenamiento y bases de datos, laboratorios de visualización y pantallas, e incluso instrumentos y sensores en Texas. El objetivo secundario es demostrar las capacidades de TIGRE para mejorar las oportunidades de investigación y educación en áreas de aplicación estratégica de interés para el Estado de Texas. Estos son biociencia y medicina, exploración energética y modelado de la calidad del aire. La visión del proyecto TIGRE es fomentar la colaboración interdisciplinaria e intercampus, identificar enfoques novedosos para ampliar las asociaciones académicas, gubernamentales y privadas, y convertirse en un modelo competitivo para las oportunidades de financiación externa. El objetivo general de TIGRE es apoyar los intereses de los usuarios locales, universitarios y regionales y ofrecer vías para conectar con proyectos nacionales de Red como Open Science Grid [5] y TeraGrid [6]. Dentro del área de aplicación estratégica de exploración energética, hemos habilitado el enfoque conjunto Kalman Filter (EnKF) [7] para la asimilación de datos en el modelado de reservorios y hemos demostrado la extensibilidad de la aplicación utilizando el entorno TIGRE y el metaprogramador GridWay [8]. En la sección 2 se ofrece una visión general del entorno y las capacidades de TIGRE. La descripción de la aplicación y la necesidad de una metodología EnKF compatible con la cuadrícula figuran en la sección 3. Los detalles de la aplicación y los méritos de nuestro enfoque se examinan en la sección 4. Las conclusiones figuran en la sección 5. Por último, en la sección 6 se documentan las observaciones y la experiencia adquirida. 2. TIGRE ENTORNO El MIddleware TIGRE Grid consiste en un conjunto mínimo de componentes derivados de un subconjunto del Virtual Data Toolkit (VDT) [9] que soporta una variedad de sistemas operativos. El propósito de elegir una pila de software mínima es apoyar las aplicaciones disponibles y simplificar la instalación y distribución de las pilas cliente/servidor en los sitios de TIGRE. Se añadirán componentes adicionales a medida que sean necesarios. El mecanismo de packaging y distribución PacMan [10] se emplea para la instalación y gestión del cliente/servidor TIGRE. El mecanismo de distribución de PacMan implica la recuperación, instalación y a menudo configuración del software empaquetado. Este enfoque permite a los clientes mantener versiones actualizadas y consistentes del software TIGRE. También ayuda a los sitios TIGRE a instalar los componentes necesarios en los recursos distribuidos en los sitios participantes. La pila cliente/servidor TIGRE consiste en una capa de autenticación y autorización, Globus GRAM4-basada en la presentación de trabajos a través de servicios web (las instalaciones de servicios pre-web están disponibles bajo petición). Las herramientas para manejar la generación de proxy de cuadrícula, la transferencia de archivos habilitada para cuadrícula y el inicio de sesión remoto habilitado para cuadrícula son compatibles. A continuación se proporcionan los detalles pertinentes de los servicios y herramientas de TIGRE para la programación y gestión de puestos. 2.1. Autoridad certificadora La infraestructura de seguridad TIGRE incluye una autoridad certificadora (CA) acreditada por la International Grid Trust Federation (IGTF) para emitir X. 509 certificados de usuario y recurso Grid [11]. El Texas Advanced Computing Center (TACC), Universidad de Texas en Austin, es el TIGREs CA compartido. Las instituciones de TIGRE actúan como autoridades de registro (RA) para sus respectivas bases de usuarios locales. Para obtener información actualizada sobre la seguridad de los certificados de usuario y de recursos y sus instrucciones de instalación, véase ref [2]. Los usuarios y hosts de TIGRE son identificados por su distinguido nombre (DN) en su certificado X.509 proporcionado por la CA. Un archivo nativo Grid-mapfile que contiene una lista de DNs autorizados se utiliza para autenticar y autorizar la programación y gestión de trabajos de los usuarios en los recursos del sitio TIGRE. En la Universidad Texas Tech, a los usuarios se les asigna dinámicamente una de las muchas cuentas genéricas. Esto se logra a través del Sistema de Gestión de Usuarios de Red (GUMS) [12]. 2.2. Programación y gestión de empleos El entorno TIGRE apoya la presentación de trabajos basada en GRAM4 a través de servicios web. Los scripts de envío de trabajos se generan usando XML. Los servicios web GRAM traducen los scripts XML en programadores de lotes específicos de grupos de destino como LSF, PBS o SGE. Los protocolos de transferencia de archivos de alto ancho de banda como GridFTP se utilizan para estadificación de archivos dentro y fuera de la máquina de destino. El acceso a hosts remotos para compilar y depurar es sólo a través del servicio GSISSH que requiere autenticación de recursos a través de certificados X.509. La autenticación y autorización de los trabajos de Grid se gestionan mediante la emisión de certificados de Grid a usuarios y anfitriones. Las listas de revocación de certificados (CRL) se actualizan diariamente para mantener altos estándares de seguridad de los servicios de TIGRE Grid. El área de documentación del portal TIGRE [2] proporciona un tutorial de inicio rápido sobre cómo ejecutar trabajos en TIGRE. 2.3. Metascheduler El metascheduler interopera con los programadores de lotes de nivel de cluster (como LSF, PBS) en la gestión general del flujo de trabajo de Grid. En el presente trabajo, hemos empleado el metaprogramador GridWay [8] -un proyecto de incubadora Globus- para programar y gestionar trabajos en TIGRE. El GridWay es un metaprogramador ligero que utiliza plenamente las funcionalidades de Globus. Está diseñado para proporcionar un uso eficiente de los recursos dinámicos de Grid por múltiples usuarios para las infraestructuras de Grid construidas sobre los servicios de Globus. El administrador del sitio TIGRE puede controlar el uso compartido de recursos a través de un potente programador integrado proporcionado por GridWay o ampliando el módulo de programación externa GridWays para proporcionar sus propias políticas de programación. Los usuarios de aplicaciones pueden escribir descripciones de trabajos usando el formato de plantilla de trabajo simple y directo de GridWays (ver Sección 4 para más detalles) o el lenguaje estándar de descripción de la presentación de trabajos (JSDL). Para más detalles sobre la aplicación, véase la sección 4. 2.4. Sistema de Gestión de Servicios al Cliente Un portal TIGRE [2] fue diseñado e implementado para interconectar usuarios y proveedores de recursos. Fue diseñado utilizando GridPort [13] y es mantenido por TACC. El entorno TIGRE es compatible con herramientas de código abierto como el Open Ticket Request System (OTRS) [14] para el servicio de tickets de problemas, y MoinMoin [15] Wiki para la gestión de contenido y conocimiento de TIGRE para educación, extensión y capacitación. Los enlaces para OTRS y Wiki son consumidos por el portal TIGRE [2] - el portal para usuarios y proveedores de recursos. El estado y las cargas de los recursos de TIGRE son monitoreados por el servicio de Repositorio de Información de Puertos Grid (GPIR) del kit de herramientas GridPort [13] que interactúa con el servicio local de monitoreo de carga de clústeres como Ganglia. El GPIR utiliza trabajos de cron en cada recurso para reunir características específicas de los recursos del sitio, tales como trabajos que se ejecutan, en cola y esperando la asignación de recursos. 3. APLICACIÓN ENSEMBLE KALMAN FILTER El objetivo principal de las simulaciones de yacimientos de hidrocarburos es predecir el comportamiento de la producción de yacimientos de petróleo y gas (denominados en lo sucesivo campo) para su desarrollo y gestión óptima. En el modelado de yacimientos, el campo se divide en varios modelos geológicos, como se muestra en la Figura 1. Para una previsión precisa del rendimiento del campo, es necesario conciliar varios modelos geológicos con la respuesta dinámica del campo a través de la coincidencia histórica [16-20]. Gráfico 1 Vista transversal del Campo. Las capas verticales corresponden a diferentes modelos geológicos y los clavos son pozos de aceite cuya información histórica se utilizará para predecir el comportamiento de la producción. (Figura Ref:http://faculty.smu.edu/zchen/research.html). El EnKF es un método de Monte Carlo que trabaja con un conjunto de modelos de embalses. Este método utiliza covarianzas cruzadas [21] entre las mediciones de campo y los parámetros del modelo de reservorio (derivados de varios modelos) para estimar las incertidumbres de predicción. Los parámetros del modelo geológico en el conjunto se actualizan secuencialmente con el objetivo de minimizar las incertidumbres de predicción. La respuesta histórica de la producción del campo durante más de 50 años se utiliza en estas simulaciones. La principal ventaja de EnKF es que puede vincularse fácilmente a cualquier simulador de depósito, y puede asimilar los últimos datos de producción sin necesidad de volver a ejecutar el simulador desde las condiciones iniciales. Investigadores en Texas son grandes suscriptores del paquete de Schlumberger ECLIPSE [22] para simulaciones de reservorios. En el modelado del embalse, cada modelo geológico comprueba una licencia ECLIPSE. La duración de la simulación de la metodología EnKF depende del número de modelos geológicos utilizados, el número de licencias ECLIPSE disponibles, la historia de producción del campo y las incertidumbres propagadas en la correspondencia de la historia. El flujo de trabajo general de EnKF se muestra en la Figura 2. Gráfico 2 Ensemble Kaman Filter Data Assimulation Workflow. Cada sitio tiene licencias L. En START, el proceso maestro/control (programa principal EnKF) lee el archivo de configuración de simulación para el número (N) de modelos y archivos de entrada específicos del modelo. A continuación, N directorios de trabajo se crean para almacenar los archivos de salida. Al final de la iteración, el proceso maestro/control recoge los archivos de salida de los modelos N y las crosscovarianzas de los procesos posteriores [21] para estimar las incertidumbres de predicción. Esta información se utilizará para actualizar modelos (o archivos de entrada) para la siguiente iteración. La simulación continúa hasta agotar las historias de producción. La simulación típica de EnKF con N=50 y historias de campo de 50-60 años, en pasos de tiempo que van de tres meses a un año, toma unas tres semanas en un entorno de computación en serie. En el entorno informático paralelo, no hay comunicación interproceso entre los modelos geológicos en el conjunto. Sin embargo, al final de cada paso del tiempo de simulación, los archivos de salida específicos del modelo deben ser recogidos para analizar covarianzas cruzadas [21] y para preparar el siguiente conjunto de archivos de entrada. Por lo tanto, el modelo maestro-esclavo en el entorno de mensajepassing (MPI) es un paradigma adecuado. En este enfoque, los modelos geológicos son tratados como esclavos y se distribuyen entre los procesadores disponibles. El master Cluster o (TIGRE/GridWay) START Read Configuration File Create N Working Directories Create N Input files Model l Model 2 Model N.. . ECLIPSE in situ Un ECLIPSE in situ B ECLIPSE in situ Z Collect N Model Outputs, Post-process Output files FIN. . . proceso recoge archivos de salida específicos del modelo, analiza y prepara el siguiente conjunto de archivos de entrada para la simulación. Dado que cada modelo geológico comprueba una licencia ECLIPSE, la paralelización de la simulación depende del número de licencias disponibles. Cuando el número de licencias disponible es menor que el número de modelos en el conjunto, uno o más de los nodos del grupo MPI tienen que manejar más de un modelo en serie y, por lo tanto, se tarda más tiempo en completar la simulación. Un Departamento de Ingeniería Petrolera generalmente adquiere 10-15 licencias ECLIPSE, mientras que al menos diez veces más número de licencias sería necesario para simulaciones estándar de la industria. El número de licencias puede incrementarse con la participación de varios departamentos de ingeniería petrolera que apoyan el paquete ECLIPSE. Dado que MPI no se escala muy bien para aplicaciones que involucran clústeres de computación remotos, y para evitar los problemas del firewall con servidores de licencias en todos los dominios administrativos, parece necesario activar el flujo de trabajo de EnKF. Con esta motivación, hemos implementado el flujo de trabajo EnKF habilitado para Grid para el entorno TIGRE y hemos demostrado la paralelización de la aplicación a través de TIGRE usando el metascheduler GridWay. En la siguiente sección figuran más detalles al respecto. 4. DETALLES DE APLICACION Para habilitar Grid-enable el enfoque EnKF, hemos eliminado el código MPI para el procesamiento paralelo y reemplazado por trabajos de N monoprocesador (o sub-trabajos) donde, N es el número de modelos geológicos en el conjunto. Estos sub-trabajos específicos de modelos se distribuyeron a través de sitios TIGRE que soportan el paquete ECLIPSE utilizando el metaprogramador GridWay [8]. Para cada sub-trabajo, hemos construido una plantilla de trabajo GridWay que especifica los archivos ejecutables, de entrada y salida, y los requisitos de recursos. Dado que los recursos de cálculo de TIGRE no se espera que cambien con frecuencia, hemos utilizado la política de descubrimiento de recursos estáticos para GridWay y los sub-trabajos fueron programados dinámicamente a través de los recursos de TIGRE usando GridWay. La Figura 3 representa el archivo de plantilla de subtrabajo para el metaprogramador GridWay. Gráfico 3 Plantilla de subtrabajo GridWay En la Figura 3, REQUISITOS bandera se establece para elegir los recursos que satisfacen los requisitos de la aplicación. En el caso de la aplicación EnKF, por ejemplo, necesitamos recursos que apoyen el paquete ECLIPSE. ARGUMENTS flag especifica el modelo en el conjunto que invocará ECLIPSE en un sitio remoto. INPUT_FILES es preparado por el programa principal de EnKF (o proceso maestro/control) y es transferido por GridWay al sitio remoto donde está desatendido y está preparado para su ejecución. Finalmente, OUTPUT_FILES especifica el nombre y la ubicación donde se escribirán los archivos de salida. Las características de la línea de comandos de GridWay se utilizaron para recopilar y procesar las salidas específicas del modelo para preparar un nuevo conjunto de archivos de entrada. Este paso imita la sincronización del proceso MPI en el modelo maestro-esclavo. Al final de cada iteración, los recursos computacionales y las licencias se devuelven al grupo. La Tabla 1 muestra los sub-trabajos en TIGRE Grid via GridWay usando el comando gwps y para mayor claridad, sólo se mostraron las columnas seleccionadas. USUARIO JID DM EM NOMBRE HOST pingluo 88 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 89 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 90 wrap actv enkf.jt minigar.hp Programación de trabajo a través de TIGRE usando GridWay Metascheduler. DM: Estado de envío, EM: Estado de ejecución, JID es el id de trabajo y HOST corresponde al cluster específico del sitio y su planificador de lotes local. Cuando un trabajo es enviado a GridWay, pasará por una serie de estados de envío (DM) y ejecución (EM). Para DM, los estados incluyen pend(ing), prol(og), wrap(per), epil(og), y hecho. DM=prol significa que el trabajo ha sido programado a un recurso y el directorio de trabajo remoto está en preparación. DM=warp implica que GridWay está ejecutando el envoltorio que a su vez ejecuta la aplicación. DM=epil implica que el trabajo ha terminado de ejecutarse en el sitio remoto y los resultados se están transfiriendo al servidor GridWay. Del mismo modo, cuando EM=pend implica que el trabajo está esperando en la cola para el recurso y el trabajo se está ejecutando cuando EM=actv. Para ver la lista completa de las banderas de mensajes y sus descripciones, consulte la documentación en ref [8]. Hemos demostrado las ejecuciones de EnKF habilitadas para Grid usando GridWay para entorno TIGRE. Los trabajos son tan elegidos que el tiempo de ejecución no supera más de media hora. La simulación incluyó hasta 20 trabajos entre sitios de A&M y TTU con TTU cumpliendo 10 licencias. Para obtener información sobre los recursos, véase el cuadro I. Una de las principales ventajas de la simulación EnKF habilitada por Grid es que tanto los recursos como las licencias se devuelven al grupo al final de cada paso del tiempo de simulación a diferencia del caso de la implementación de MPI donde las licencias y nodos están bloqueados hasta la finalización de la simulación completa. Sin embargo, el hecho de que cada sub-trabajo se programe independientemente a través de GridWay podría posiblemente incurrir en otro retraso de tiempo causado por esperar en la cola para la ejecución en cada paso del tiempo de simulación. Tales retrasos no se esperan EXECUTABLE=runFORWARD NECESIDADES=HOSTNAME=cosmos.tamu.edu  HOSTNAME=antaeus.hpcc.ttu.edu  HOSTNAME=minigar.hpcc.ttu.edu  ARGUMENTOS=001 INPUT_FILES=001.in.tar OUTPUT_FI Hay dos escenarios principales para comparar los enfoques de computación de red y clúster. Escenario I: El cúmulo está muy cargado. El tiempo promedio de espera concebido del trabajo que solicita un gran número de CPUs es generalmente más largo que el tiempo de espera de los trabajos que solicitan una sola CPU. Por lo tanto, el tiempo de espera general podría ser más corto en el enfoque Grid que solicita una sola CPU para cada sub-trabajo muchas veces en comparación con la implementación MPI que requiere un gran número de CPUs en un solo momento. Es evidente que la programación de la cuadrícula es beneficiosa especialmente cuando el clúster está fuertemente cargado y el número solicitado de CPUs para el trabajo del MPI no está fácilmente disponible. Escenario II: El clúster está relativamente menos cargado o disponible en gran medida. Parece que la implementación del MPI es favorable en comparación con la programación de la Rejilla. Sin embargo, la paralelización de la aplicación EnKF depende del número de licencias ECLIPSE e idealmente, el número de licencias debe ser igual al número de modelos en el conjunto. Por lo tanto, si una sola institución no tiene suficiente número de licencias, la disponibilidad del clúster no ayuda tanto como se espera. Dado que el entorno colaborativo, como TIGRE, puede abordar tanto los requisitos de computación como los de recursos de software para la aplicación EnKF, el enfoque compatible con Grid sigue siendo ventajoso sobre la implementación MPI convencional en cualquiera de los escenarios anteriores. 5. CONCLUSIONES Y FUTURO TRABAJO TIGRE es un proyecto de desarrollo de la red de educación superior y su propósito es mantener y ampliar las oportunidades de investigación y educación a través de Texas. Dentro del área de aplicación de exploración energética, hemos habilitado la implementación MPI del conjunto Kalman metodología de asimilación de datos de filtro para la caracterización de reservorios. Esta tarea se llevó a cabo eliminando el código MPI para el procesamiento paralelo y reemplazando con trabajos de un solo procesador uno para cada modelo geológico en el conjunto. Estos trabajos de un solo procesador fueron programados a través de TIGRE a través de GridWay metascheduler. Hemos demostrado que mediante la puesta en común de licencias a través de sitios TIGRE, más modelos geológicos pueden ser manejados en paralelo y por lo tanto concebiblemente mejor precisión de simulación. Este enfoque tiene varias ventajas sobre la implementación de MPI, especialmente cuando un clúster específico del sitio está muy cargado y/o las licencias de número requeridas para la simulación son más que las disponibles en un solo sitio. Hacia el trabajo futuro, sería interesante comparar el tiempo de ejecución entre MPI y las implementaciones de Grid para la aplicación EnKF. Este esfuerzo podría arrojar luz sobre la calidad del servicio (QoS) de los entornos Grid en comparación con la computación de clústers. Otro aspecto de interés en un futuro próximo sería la gestión de recursos de computación y licencia para abordar la gestión de la relación trabajo (o procesador)-licencia. 6. OBSERVACIONES Y MENOS APRENDIZADOS Los esfuerzos que facilitan la red para la aplicación EnKF han proporcionado amplias oportunidades para reunir información sobre la visibilidad y la promesa de los entornos de computación de Grid para el desarrollo y soporte de aplicaciones. Los principales problemas son la seguridad de los datos estándar de la industria y la CV comparable a la computación de clústers. Dado que la investigación de modelado de reservorios involucra datos propietarios del campo, tuvimos que invertir esfuerzos sustanciales inicialmente en educar a los investigadores de aplicaciones sobre la capacidad de los servicios de Grid para apoyar la seguridad de datos estándar de la industria a través de acceso basado en roles y privilegios utilizando el estándar X.509. Con respecto a QoS, los investigadores de aplicaciones esperan niveles de QoS con entornos de cuadrícula. Además, hay una curva de aprendizaje pronunciada en la computación de cuadrícula en comparación con la computación de clúster convencional. Dado que la computación de cuadrícula sigue siendo una tecnología emergente, y abarca varios ámbitos administrativos, la computación de cuadrícula sigue siendo prematura, especialmente en términos del nivel de QoS, aunque ofrece mejores normas de seguridad de los datos en comparación con los grupos de productos básicos. Es nuestra observación que los programas de capacitación y divulgación que comparan y contrastan los entornos de computación de red y clúster serían un enfoque adecuado para mejorar la participación de los usuarios en la computación de red. Este enfoque también ayuda a los usuarios a emparejar sus aplicaciones y habilidades que las cuadrículas pueden ofrecer. En resumen, nuestros esfuerzos a través de TIGRE en la metodología de asimilación de datos de la EnKF demostraron una promesa sustancial en la contratación de investigadores de Ingeniería Petrolera a través de colaboraciones entre campus. Se están realizando esfuerzos para lograr la participación de más escuelas en este esfuerzo. Estos esfuerzos pueden resultar en un aumento de la investigación colaborativa, oportunidades educativas y desarrollo de la fuerza laboral a través de programas de investigación de posgrado/facultad en instituciones TIGRE. 7. AGRADECIMIENTOS Los autores reconocen al Estado de Texas por apoyar el proyecto TIGRE a través del Fondo Empresarial de Texas, y a las Instituciones TIGRE por proporcionar el mecanismo, en el que también participan los autores (Ravi Vadapalli, Taesung Kim y Ping Luo). Los autores agradecen a los investigadores de aplicaciones Prof. Akhil Datta-Gupta de Texas A&M University y Prof. Lloyd Heinze de Texas Tech University por sus discusiones e interés en explotar el entorno TIGRE para ampliar las oportunidades en investigación y desarrollo. 8. REFERENCIAS [1] Foster, I. y Kesselman, C. (eds.) 2004. The Grid: Blueprint for a new computing infraestructura (The Elsevier series in Grid computing) [2] Portal TIGRE: http://tigreportal.hipcat.net [3] Vadapalli, R. Sill, A., Dooley, R., Murray, M., Luo, P., Kim, T., Huang, M., Thyagaraja, K., y Chaffin, Demostración del entorno TIGRE para aplicaciones de cuadrícula habilitadas/adecuadas. 8o IEEE/ACM Int. Conf. on Grid Computing, 19-21 de septiembre, Austin [4] The High Performance Computing cross Texas Consortium http://www.hipcat.net [5] Pordes, R. Petravick, D. Kramer, B. Olson, D. Livny, M. Roy, A. Avery, P. Blackburn, K. Wenaus, T. Würthwein, F. Foster, I. Gar The Open Science Grid, J. Phys Conf Series http://www.iop.org/EJ/abstract/1742-6596/78/1/012057 y http://www.opensciencegrid.org [6] Reed, D.A. 2003. Rejilla, el Teragrid y más allá, Ordenador, vol. 30, no. 1 y http://www.teragrid.org [7] Evensen, G. 2006. Asimilación de datos: El conjunto Kalman Filter, Springer [8] Herrera, J. Huedo, E. Montero, R. S. y Llorente, I. M. 2005. Programación Científica, vol 12, No. 4. pp 317-331 [9] Avery, P. and Foster, I. 2001. El proyecto GriPhyN: Hacia redes virtuales de datos a petaescala, informe técnico GriPhyN-200115 y http://vdt.cs.wisc.edu [10] La guía de documentación e instalación de PacMan http://physics.bu.edu/pacman/htmls [11] Caskey, P. Murray, M. Perez, J. y Sill, A. 2007. Estudios de casos en la gestión de identificación para organizaciones virtuales, EDUCOUSO Southwest Reg. Conf., 21-23 febrero, Austin, TX. http://www.educause.edu/ir/library/pdf/SWR07058.pdf [12] El Sistema de Gestión de Usuarios de Grid (GUMS) https://www.racf.bnl.gov/Facility/GUMS/index.html [13] Thomas, M. y Boisseau, J. 2003. Construyendo portales de computación de cuadrículas: El kit de herramientas para el portal de cuadrículas NPACI, Grid computing: haciendo realidad la infraestructura global, Capítulo 28, Berman, F. Fox, G. Thomas, M. Boisseau, J. y Hey, T. (eds), John Wiley and Sons, Ltd, Chichester [14] Open Ticket Request System http:// 1999. Integración de datos dinámicos en modelos de depósito de alta resolución utilizando coeficientes de sensibilidad basados en la racionalización, Society of Petroleum Engineers (SPE), 4 (4). [17] Emanuel, A. S. y Milliken, W. J. 1998. Historia que combina modelos de diferencias finitas con racionalizaciones 3D, SPE 49000, Proc de la Conf Técnica Anual y Exposición, 2730 de septiembre, Nueva Orleans, LA. [18] Nævdal, G. Johnsen, L.M. Aanonsen, S.I. y Vefring, E.H. 2003. Monitorización de embalses y actualización continua de modelos utilizando Ensemble Kalman Filter, SPE 84372, Proc del Conf Técnico Anual y Exposición, Oct 5-8, Denver, CO. [19] Jafarpour B. y McLaughlin, D.B. 2007. Historia que coincide con un conjunto de filtro Kalman y parametrización discreta de coseno, SPE 108761, Proc de la Conf Técnica Anual y Exposición, 11-14 de noviembre, Anaheim, CA [20] Li, G. y Reynolds, A. C. 2007. Un conjunto iterativo Kalman filtro para la asimilación de datos, SPE 109808, Proc de la SPE Conf y Exposición Técnica Anual, 11-14 de noviembre, Anaheim, CA [21] Arroyo-Negrete, E. Devagowda, D. Datta-Gupta, A. 2006. Simplificar el conjunto asistido Kalman filtro para la actualización rápida y continua del modelo de depósito. Proc de la Int. Oil & Gas Conf and Exhibition, SPE 104255, Dec 5-7, China [22] ECLIPSE Reservoir Engineering Software http://www.slb.com/content/services/software/reseng/index.a sp ",
            "error": [
                ""
            ]
        },
        "tigre grid middleware": {
            "translated_key": [],
            "translated_annotated_text": "Demostración del conjunto de datos de Kalman Assimulation Method for Reservoir Caracterisation Ravi Vadapalli Centro de computación de alto rendimiento Texas Tech University Lubbock, TX 79409 001-806-742-4350 Ravi.Vadapalli@ttu.edu Ajitabh Kumar Department of Petroleum Engineering Texas A&M University College Station, En este enfoque, se utiliza un conjunto de modelos geológicos y datos de producción de yacimientos de petróleo para predecir la respuesta dinámica de los pozos de petróleo. El software Schlumberger ECLIPSE se utiliza para estas simulaciones. Puesto que los modelos en el conjunto no se comunican, la implementación de mensaje-passing es una buena opción. Cada modelo comprueba una licencia ECLIPSE y, por lo tanto, la paralelización de las simulaciones de reservorio depende de las licencias de número disponibles. Hemos habilitado Grid para el conjunto Kalman metodología de asimilación de datos de filtro para el entorno de computación TIGRE Grid. Al poner en común las licencias y los recursos informáticos en todas las instituciones colaboradoras utilizando el metaprogramador GridWay y el entorno TIGRE, la precisión computacional puede aumentarse al tiempo que se reduce el tiempo de ejecución de la simulación. En este artículo, proporcionamos un relato de nuestros esfuerzos en Gridenabilizar el conjunto Kalman Filter metodología de asimilación de datos. Se examinarán los posibles beneficios de este enfoque, las observaciones y la experiencia adquirida. Categorías y Descriptores sujetos C 2.4 [Sistemas distribuidos]: Aplicaciones distribuidas Términos generales Algoritmos, Diseño, Rendimiento 1. INTRODUCCIÓN La computación de cuadrícula [1] es un paradigma de computación colaborativa emergente para ampliar las capacidades específicas de computación de alto rendimiento (HPC) mucho más allá de los recursos locales. Su importancia se deriva del hecho de que la investigación innovadora en áreas de aplicación estratégicas como la biociencia y la medicina, la exploración de energía y el modelado ambiental involucran componentes interdisciplinarios fuertes y a menudo requieren colaboraciones intercampus y capacidades computacionales más allá de las limitaciones institucionales. The Texas Internet Grid for Research and Education (TIGRE) [2,3] es un proyecto de desarrollo de infraestructuras cibernéticas financiado por el estado, llevado a cabo por cinco grandes sistemas universitarios (Rice, A&M, TTU, UH y UT Austin), llamados colectivamente Instituciones TIGRE. El propósito de TIGRE es crear una red de educación superior para sostener y ampliar las oportunidades de investigación y educación en Texas. TIGRE es un proyecto del consorcio de computación de alto rendimiento en Texas (HiPCAT) [4]. El objetivo de HiPCAT es apoyar tecnologías computacionales avanzadas para mejorar la investigación, el desarrollo y las actividades educativas. El objetivo principal de TIGRE es diseñar e implementar middleware Grid de última generación que permita la integración de sistemas de computación, sistemas de almacenamiento y bases de datos, laboratorios de visualización y pantallas, e incluso instrumentos y sensores en Texas. El objetivo secundario es demostrar las capacidades de TIGRE para mejorar las oportunidades de investigación y educación en áreas de aplicación estratégica de interés para el Estado de Texas. Estos son biociencia y medicina, exploración energética y modelado de la calidad del aire. La visión del proyecto TIGRE es fomentar la colaboración interdisciplinaria e intercampus, identificar enfoques novedosos para ampliar las asociaciones académicas, gubernamentales y privadas, y convertirse en un modelo competitivo para las oportunidades de financiación externa. El objetivo general de TIGRE es apoyar los intereses de los usuarios locales, universitarios y regionales y ofrecer vías para conectar con proyectos nacionales de Red como Open Science Grid [5] y TeraGrid [6]. Dentro del área de aplicación estratégica de exploración energética, hemos habilitado el enfoque conjunto Kalman Filter (EnKF) [7] para la asimilación de datos en el modelado de reservorios y hemos demostrado la extensibilidad de la aplicación utilizando el entorno TIGRE y el metaprogramador GridWay [8]. En la sección 2 se ofrece una visión general del entorno y las capacidades de TIGRE. La descripción de la aplicación y la necesidad de una metodología EnKF compatible con la cuadrícula figuran en la sección 3. Los detalles de la aplicación y los méritos de nuestro enfoque se examinan en la sección 4. Las conclusiones figuran en la sección 5. Por último, en la sección 6 se documentan las observaciones y la experiencia adquirida. 2. TIGRE ENTORNO El MIddleware TIGRE Grid consiste en un conjunto mínimo de componentes derivados de un subconjunto del Virtual Data Toolkit (VDT) [9] que soporta una variedad de sistemas operativos. El propósito de elegir una pila de software mínima es apoyar las aplicaciones disponibles y simplificar la instalación y distribución de las pilas cliente/servidor en los sitios de TIGRE. Se añadirán componentes adicionales a medida que sean necesarios. El mecanismo de packaging y distribución PacMan [10] se emplea para la instalación y gestión del cliente/servidor TIGRE. El mecanismo de distribución de PacMan implica la recuperación, instalación y a menudo configuración del software empaquetado. Este enfoque permite a los clientes mantener versiones actualizadas y consistentes del software TIGRE. También ayuda a los sitios TIGRE a instalar los componentes necesarios en los recursos distribuidos en los sitios participantes. La pila cliente/servidor TIGRE consiste en una capa de autenticación y autorización, Globus GRAM4-basada en la presentación de trabajos a través de servicios web (las instalaciones de servicios pre-web están disponibles bajo petición). Las herramientas para manejar la generación de proxy de cuadrícula, la transferencia de archivos habilitada para cuadrícula y el inicio de sesión remoto habilitado para cuadrícula son compatibles. A continuación se proporcionan los detalles pertinentes de los servicios y herramientas de TIGRE para la programación y gestión de puestos. 2.1. Autoridad certificadora La infraestructura de seguridad TIGRE incluye una autoridad certificadora (CA) acreditada por la International Grid Trust Federation (IGTF) para emitir X. 509 certificados de usuario y recurso Grid [11]. El Texas Advanced Computing Center (TACC), Universidad de Texas en Austin, es el TIGREs CA compartido. Las instituciones de TIGRE actúan como autoridades de registro (RA) para sus respectivas bases de usuarios locales. Para obtener información actualizada sobre la seguridad de los certificados de usuario y de recursos y sus instrucciones de instalación, véase ref [2]. Los usuarios y hosts de TIGRE son identificados por su distinguido nombre (DN) en su certificado X.509 proporcionado por la CA. Un archivo nativo Grid-mapfile que contiene una lista de DNs autorizados se utiliza para autenticar y autorizar la programación y gestión de trabajos de los usuarios en los recursos del sitio TIGRE. En la Universidad Texas Tech, a los usuarios se les asigna dinámicamente una de las muchas cuentas genéricas. Esto se logra a través del Sistema de Gestión de Usuarios de Red (GUMS) [12]. 2.2. Programación y gestión de empleos El entorno TIGRE apoya la presentación de trabajos basada en GRAM4 a través de servicios web. Los scripts de envío de trabajos se generan usando XML. Los servicios web GRAM traducen los scripts XML en programadores de lotes específicos de grupos de destino como LSF, PBS o SGE. Los protocolos de transferencia de archivos de alto ancho de banda como GridFTP se utilizan para estadificación de archivos dentro y fuera de la máquina de destino. El acceso a hosts remotos para compilar y depurar es sólo a través del servicio GSISSH que requiere autenticación de recursos a través de certificados X.509. La autenticación y autorización de los trabajos de Grid se gestionan mediante la emisión de certificados de Grid a usuarios y anfitriones. Las listas de revocación de certificados (CRL) se actualizan diariamente para mantener altos estándares de seguridad de los servicios de TIGRE Grid. El área de documentación del portal TIGRE [2] proporciona un tutorial de inicio rápido sobre cómo ejecutar trabajos en TIGRE. 2.3. Metascheduler El metascheduler interopera con los programadores de lotes de nivel de cluster (como LSF, PBS) en la gestión general del flujo de trabajo de Grid. En el presente trabajo, hemos empleado el metaprogramador GridWay [8] -un proyecto de incubadora Globus- para programar y gestionar trabajos en TIGRE. El GridWay es un metaprogramador ligero que utiliza plenamente las funcionalidades de Globus. Está diseñado para proporcionar un uso eficiente de los recursos dinámicos de Grid por múltiples usuarios para las infraestructuras de Grid construidas sobre los servicios de Globus. El administrador del sitio TIGRE puede controlar el uso compartido de recursos a través de un potente programador integrado proporcionado por GridWay o ampliando el módulo de programación externa GridWays para proporcionar sus propias políticas de programación. Los usuarios de aplicaciones pueden escribir descripciones de trabajos usando el formato de plantilla de trabajo simple y directo de GridWays (ver Sección 4 para más detalles) o el lenguaje estándar de descripción de la presentación de trabajos (JSDL). Para más detalles sobre la aplicación, véase la sección 4. 2.4. Sistema de Gestión de Servicios al Cliente Un portal TIGRE [2] fue diseñado e implementado para interconectar usuarios y proveedores de recursos. Fue diseñado utilizando GridPort [13] y es mantenido por TACC. El entorno TIGRE es compatible con herramientas de código abierto como el Open Ticket Request System (OTRS) [14] para el servicio de tickets de problemas, y MoinMoin [15] Wiki para la gestión de contenido y conocimiento de TIGRE para educación, extensión y capacitación. Los enlaces para OTRS y Wiki son consumidos por el portal TIGRE [2] - el portal para usuarios y proveedores de recursos. El estado y las cargas de los recursos de TIGRE son monitoreados por el servicio de Repositorio de Información de Puertos Grid (GPIR) del kit de herramientas GridPort [13] que interactúa con el servicio local de monitoreo de carga de clústeres como Ganglia. El GPIR utiliza trabajos de cron en cada recurso para reunir características específicas de los recursos del sitio, tales como trabajos que se ejecutan, en cola y esperando la asignación de recursos. 3. APLICACIÓN ENSEMBLE KALMAN FILTER El objetivo principal de las simulaciones de yacimientos de hidrocarburos es predecir el comportamiento de la producción de yacimientos de petróleo y gas (denominados en lo sucesivo campo) para su desarrollo y gestión óptima. En el modelado de yacimientos, el campo se divide en varios modelos geológicos, como se muestra en la Figura 1. Para una previsión precisa del rendimiento del campo, es necesario conciliar varios modelos geológicos con la respuesta dinámica del campo a través de la coincidencia histórica [16-20]. Gráfico 1 Vista transversal del Campo. Las capas verticales corresponden a diferentes modelos geológicos y los clavos son pozos de aceite cuya información histórica se utilizará para predecir el comportamiento de la producción. (Figura Ref:http://faculty.smu.edu/zchen/research.html). El EnKF es un método de Monte Carlo que trabaja con un conjunto de modelos de embalses. Este método utiliza covarianzas cruzadas [21] entre las mediciones de campo y los parámetros del modelo de reservorio (derivados de varios modelos) para estimar las incertidumbres de predicción. Los parámetros del modelo geológico en el conjunto se actualizan secuencialmente con el objetivo de minimizar las incertidumbres de predicción. La respuesta histórica de la producción del campo durante más de 50 años se utiliza en estas simulaciones. La principal ventaja de EnKF es que puede vincularse fácilmente a cualquier simulador de depósito, y puede asimilar los últimos datos de producción sin necesidad de volver a ejecutar el simulador desde las condiciones iniciales. Investigadores en Texas son grandes suscriptores del paquete de Schlumberger ECLIPSE [22] para simulaciones de reservorios. En el modelado del embalse, cada modelo geológico comprueba una licencia ECLIPSE. La duración de la simulación de la metodología EnKF depende del número de modelos geológicos utilizados, el número de licencias ECLIPSE disponibles, la historia de producción del campo y las incertidumbres propagadas en la correspondencia de la historia. El flujo de trabajo general de EnKF se muestra en la Figura 2. Gráfico 2 Ensemble Kaman Filter Data Assimulation Workflow. Cada sitio tiene licencias L. En START, el proceso maestro/control (programa principal EnKF) lee el archivo de configuración de simulación para el número (N) de modelos y archivos de entrada específicos del modelo. A continuación, N directorios de trabajo se crean para almacenar los archivos de salida. Al final de la iteración, el proceso maestro/control recoge los archivos de salida de los modelos N y las crosscovarianzas de los procesos posteriores [21] para estimar las incertidumbres de predicción. Esta información se utilizará para actualizar modelos (o archivos de entrada) para la siguiente iteración. La simulación continúa hasta agotar las historias de producción. La simulación típica de EnKF con N=50 y historias de campo de 50-60 años, en pasos de tiempo que van de tres meses a un año, toma unas tres semanas en un entorno de computación en serie. En el entorno informático paralelo, no hay comunicación interproceso entre los modelos geológicos en el conjunto. Sin embargo, al final de cada paso del tiempo de simulación, los archivos de salida específicos del modelo deben ser recogidos para analizar covarianzas cruzadas [21] y para preparar el siguiente conjunto de archivos de entrada. Por lo tanto, el modelo maestro-esclavo en el entorno de mensajepassing (MPI) es un paradigma adecuado. En este enfoque, los modelos geológicos son tratados como esclavos y se distribuyen entre los procesadores disponibles. El master Cluster o (TIGRE/GridWay) START Read Configuration File Create N Working Directories Create N Input files Model l Model 2 Model N.. . ECLIPSE in situ Un ECLIPSE in situ B ECLIPSE in situ Z Collect N Model Outputs, Post-process Output files FIN. . . proceso recoge archivos de salida específicos del modelo, analiza y prepara el siguiente conjunto de archivos de entrada para la simulación. Dado que cada modelo geológico comprueba una licencia ECLIPSE, la paralelización de la simulación depende del número de licencias disponibles. Cuando el número de licencias disponible es menor que el número de modelos en el conjunto, uno o más de los nodos del grupo MPI tienen que manejar más de un modelo en serie y, por lo tanto, se tarda más tiempo en completar la simulación. Un Departamento de Ingeniería Petrolera generalmente adquiere 10-15 licencias ECLIPSE, mientras que al menos diez veces más número de licencias sería necesario para simulaciones estándar de la industria. El número de licencias puede incrementarse con la participación de varios departamentos de ingeniería petrolera que apoyan el paquete ECLIPSE. Dado que MPI no se escala muy bien para aplicaciones que involucran clústeres de computación remotos, y para evitar los problemas del firewall con servidores de licencias en todos los dominios administrativos, parece necesario activar el flujo de trabajo de EnKF. Con esta motivación, hemos implementado el flujo de trabajo EnKF habilitado para Grid para el entorno TIGRE y hemos demostrado la paralelización de la aplicación a través de TIGRE usando el metascheduler GridWay. En la siguiente sección figuran más detalles al respecto. 4. DETALLES DE APLICACION Para habilitar Grid-enable el enfoque EnKF, hemos eliminado el código MPI para el procesamiento paralelo y reemplazado por trabajos de N monoprocesador (o sub-trabajos) donde, N es el número de modelos geológicos en el conjunto. Estos sub-trabajos específicos de modelos se distribuyeron a través de sitios TIGRE que soportan el paquete ECLIPSE utilizando el metaprogramador GridWay [8]. Para cada sub-trabajo, hemos construido una plantilla de trabajo GridWay que especifica los archivos ejecutables, de entrada y salida, y los requisitos de recursos. Dado que los recursos de cálculo de TIGRE no se espera que cambien con frecuencia, hemos utilizado la política de descubrimiento de recursos estáticos para GridWay y los sub-trabajos fueron programados dinámicamente a través de los recursos de TIGRE usando GridWay. La Figura 3 representa el archivo de plantilla de subtrabajo para el metaprogramador GridWay. Gráfico 3 Plantilla de subtrabajo GridWay En la Figura 3, REQUISITOS bandera se establece para elegir los recursos que satisfacen los requisitos de la aplicación. En el caso de la aplicación EnKF, por ejemplo, necesitamos recursos que apoyen el paquete ECLIPSE. ARGUMENTS flag especifica el modelo en el conjunto que invocará ECLIPSE en un sitio remoto. INPUT_FILES es preparado por el programa principal de EnKF (o proceso maestro/control) y es transferido por GridWay al sitio remoto donde está desatendido y está preparado para su ejecución. Finalmente, OUTPUT_FILES especifica el nombre y la ubicación donde se escribirán los archivos de salida. Las características de la línea de comandos de GridWay se utilizaron para recopilar y procesar las salidas específicas del modelo para preparar un nuevo conjunto de archivos de entrada. Este paso imita la sincronización del proceso MPI en el modelo maestro-esclavo. Al final de cada iteración, los recursos computacionales y las licencias se devuelven al grupo. La Tabla 1 muestra los sub-trabajos en TIGRE Grid via GridWay usando el comando gwps y para mayor claridad, sólo se mostraron las columnas seleccionadas. USUARIO JID DM EM NOMBRE HOST pingluo 88 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 89 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 90 wrap actv enkf.jt minigar.hp Programación de trabajo a través de TIGRE usando GridWay Metascheduler. DM: Estado de envío, EM: Estado de ejecución, JID es el id de trabajo y HOST corresponde al cluster específico del sitio y su planificador de lotes local. Cuando un trabajo es enviado a GridWay, pasará por una serie de estados de envío (DM) y ejecución (EM). Para DM, los estados incluyen pend(ing), prol(og), wrap(per), epil(og), y hecho. DM=prol significa que el trabajo ha sido programado a un recurso y el directorio de trabajo remoto está en preparación. DM=warp implica que GridWay está ejecutando el envoltorio que a su vez ejecuta la aplicación. DM=epil implica que el trabajo ha terminado de ejecutarse en el sitio remoto y los resultados se están transfiriendo al servidor GridWay. Del mismo modo, cuando EM=pend implica que el trabajo está esperando en la cola para el recurso y el trabajo se está ejecutando cuando EM=actv. Para ver la lista completa de las banderas de mensajes y sus descripciones, consulte la documentación en ref [8]. Hemos demostrado las ejecuciones de EnKF habilitadas para Grid usando GridWay para entorno TIGRE. Los trabajos son tan elegidos que el tiempo de ejecución no supera más de media hora. La simulación incluyó hasta 20 trabajos entre sitios de A&M y TTU con TTU cumpliendo 10 licencias. Para obtener información sobre los recursos, véase el cuadro I. Una de las principales ventajas de la simulación EnKF habilitada por Grid es que tanto los recursos como las licencias se devuelven al grupo al final de cada paso del tiempo de simulación a diferencia del caso de la implementación de MPI donde las licencias y nodos están bloqueados hasta la finalización de la simulación completa. Sin embargo, el hecho de que cada sub-trabajo se programe independientemente a través de GridWay podría posiblemente incurrir en otro retraso de tiempo causado por esperar en la cola para la ejecución en cada paso del tiempo de simulación. Tales retrasos no se esperan EXECUTABLE=runFORWARD NECESIDADES=HOSTNAME=cosmos.tamu.edu  HOSTNAME=antaeus.hpcc.ttu.edu  HOSTNAME=minigar.hpcc.ttu.edu  ARGUMENTOS=001 INPUT_FILES=001.in.tar OUTPUT_FI Hay dos escenarios principales para comparar los enfoques de computación de red y clúster. Escenario I: El cúmulo está muy cargado. El tiempo promedio de espera concebido del trabajo que solicita un gran número de CPUs es generalmente más largo que el tiempo de espera de los trabajos que solicitan una sola CPU. Por lo tanto, el tiempo de espera general podría ser más corto en el enfoque Grid que solicita una sola CPU para cada sub-trabajo muchas veces en comparación con la implementación MPI que requiere un gran número de CPUs en un solo momento. Es evidente que la programación de la cuadrícula es beneficiosa especialmente cuando el clúster está fuertemente cargado y el número solicitado de CPUs para el trabajo del MPI no está fácilmente disponible. Escenario II: El clúster está relativamente menos cargado o disponible en gran medida. Parece que la implementación del MPI es favorable en comparación con la programación de la Rejilla. Sin embargo, la paralelización de la aplicación EnKF depende del número de licencias ECLIPSE e idealmente, el número de licencias debe ser igual al número de modelos en el conjunto. Por lo tanto, si una sola institución no tiene suficiente número de licencias, la disponibilidad del clúster no ayuda tanto como se espera. Dado que el entorno colaborativo, como TIGRE, puede abordar tanto los requisitos de computación como los de recursos de software para la aplicación EnKF, el enfoque compatible con Grid sigue siendo ventajoso sobre la implementación MPI convencional en cualquiera de los escenarios anteriores. 5. CONCLUSIONES Y FUTURO TRABAJO TIGRE es un proyecto de desarrollo de la red de educación superior y su propósito es mantener y ampliar las oportunidades de investigación y educación a través de Texas. Dentro del área de aplicación de exploración energética, hemos habilitado la implementación MPI del conjunto Kalman metodología de asimilación de datos de filtro para la caracterización de reservorios. Esta tarea se llevó a cabo eliminando el código MPI para el procesamiento paralelo y reemplazando con trabajos de un solo procesador uno para cada modelo geológico en el conjunto. Estos trabajos de un solo procesador fueron programados a través de TIGRE a través de GridWay metascheduler. Hemos demostrado que mediante la puesta en común de licencias a través de sitios TIGRE, más modelos geológicos pueden ser manejados en paralelo y por lo tanto concebiblemente mejor precisión de simulación. Este enfoque tiene varias ventajas sobre la implementación de MPI, especialmente cuando un clúster específico del sitio está muy cargado y/o las licencias de número requeridas para la simulación son más que las disponibles en un solo sitio. Hacia el trabajo futuro, sería interesante comparar el tiempo de ejecución entre MPI y las implementaciones de Grid para la aplicación EnKF. Este esfuerzo podría arrojar luz sobre la calidad del servicio (QoS) de los entornos Grid en comparación con la computación de clústers. Otro aspecto de interés en un futuro próximo sería la gestión de recursos de computación y licencia para abordar la gestión de la relación trabajo (o procesador)-licencia. 6. OBSERVACIONES Y MENOS APRENDIZADOS Los esfuerzos que facilitan la red para la aplicación EnKF han proporcionado amplias oportunidades para reunir información sobre la visibilidad y la promesa de los entornos de computación de Grid para el desarrollo y soporte de aplicaciones. Los principales problemas son la seguridad de los datos estándar de la industria y la CV comparable a la computación de clústers. Dado que la investigación de modelado de reservorios involucra datos propietarios del campo, tuvimos que invertir esfuerzos sustanciales inicialmente en educar a los investigadores de aplicaciones sobre la capacidad de los servicios de Grid para apoyar la seguridad de datos estándar de la industria a través de acceso basado en roles y privilegios utilizando el estándar X.509. Con respecto a QoS, los investigadores de aplicaciones esperan niveles de QoS con entornos de cuadrícula. Además, hay una curva de aprendizaje pronunciada en la computación de cuadrícula en comparación con la computación de clúster convencional. Dado que la computación de cuadrícula sigue siendo una tecnología emergente, y abarca varios ámbitos administrativos, la computación de cuadrícula sigue siendo prematura, especialmente en términos del nivel de QoS, aunque ofrece mejores normas de seguridad de los datos en comparación con los grupos de productos básicos. Es nuestra observación que los programas de capacitación y divulgación que comparan y contrastan los entornos de computación de red y clúster serían un enfoque adecuado para mejorar la participación de los usuarios en la computación de red. Este enfoque también ayuda a los usuarios a emparejar sus aplicaciones y habilidades que las cuadrículas pueden ofrecer. En resumen, nuestros esfuerzos a través de TIGRE en la metodología de asimilación de datos de la EnKF demostraron una promesa sustancial en la contratación de investigadores de Ingeniería Petrolera a través de colaboraciones entre campus. Se están realizando esfuerzos para lograr la participación de más escuelas en este esfuerzo. Estos esfuerzos pueden resultar en un aumento de la investigación colaborativa, oportunidades educativas y desarrollo de la fuerza laboral a través de programas de investigación de posgrado/facultad en instituciones TIGRE. 7. AGRADECIMIENTOS Los autores reconocen al Estado de Texas por apoyar el proyecto TIGRE a través del Fondo Empresarial de Texas, y a las Instituciones TIGRE por proporcionar el mecanismo, en el que también participan los autores (Ravi Vadapalli, Taesung Kim y Ping Luo). Los autores agradecen a los investigadores de aplicaciones Prof. Akhil Datta-Gupta de Texas A&M University y Prof. Lloyd Heinze de Texas Tech University por sus discusiones e interés en explotar el entorno TIGRE para ampliar las oportunidades en investigación y desarrollo. 8. REFERENCIAS [1] Foster, I. y Kesselman, C. (eds.) 2004. The Grid: Blueprint for a new computing infraestructura (The Elsevier series in Grid computing) [2] Portal TIGRE: http://tigreportal.hipcat.net [3] Vadapalli, R. Sill, A., Dooley, R., Murray, M., Luo, P., Kim, T., Huang, M., Thyagaraja, K., y Chaffin, Demostración del entorno TIGRE para aplicaciones de cuadrícula habilitadas/adecuadas. 8o IEEE/ACM Int. Conf. on Grid Computing, 19-21 de septiembre, Austin [4] The High Performance Computing cross Texas Consortium http://www.hipcat.net [5] Pordes, R. Petravick, D. Kramer, B. Olson, D. Livny, M. Roy, A. Avery, P. Blackburn, K. Wenaus, T. Würthwein, F. Foster, I. Gar The Open Science Grid, J. Phys Conf Series http://www.iop.org/EJ/abstract/1742-6596/78/1/012057 y http://www.opensciencegrid.org [6] Reed, D.A. 2003. Rejilla, el Teragrid y más allá, Ordenador, vol. 30, no. 1 y http://www.teragrid.org [7] Evensen, G. 2006. Asimilación de datos: El conjunto Kalman Filter, Springer [8] Herrera, J. Huedo, E. Montero, R. S. y Llorente, I. M. 2005. Programación Científica, vol 12, No. 4. pp 317-331 [9] Avery, P. and Foster, I. 2001. El proyecto GriPhyN: Hacia redes virtuales de datos a petaescala, informe técnico GriPhyN-200115 y http://vdt.cs.wisc.edu [10] La guía de documentación e instalación de PacMan http://physics.bu.edu/pacman/htmls [11] Caskey, P. Murray, M. Perez, J. y Sill, A. 2007. Estudios de casos en la gestión de identificación para organizaciones virtuales, EDUCOUSO Southwest Reg. Conf., 21-23 febrero, Austin, TX. http://www.educause.edu/ir/library/pdf/SWR07058.pdf [12] El Sistema de Gestión de Usuarios de Grid (GUMS) https://www.racf.bnl.gov/Facility/GUMS/index.html [13] Thomas, M. y Boisseau, J. 2003. Construyendo portales de computación de cuadrículas: El kit de herramientas para el portal de cuadrículas NPACI, Grid computing: haciendo realidad la infraestructura global, Capítulo 28, Berman, F. Fox, G. Thomas, M. Boisseau, J. y Hey, T. (eds), John Wiley and Sons, Ltd, Chichester [14] Open Ticket Request System http:// 1999. Integración de datos dinámicos en modelos de depósito de alta resolución utilizando coeficientes de sensibilidad basados en la racionalización, Society of Petroleum Engineers (SPE), 4 (4). [17] Emanuel, A. S. y Milliken, W. J. 1998. Historia que combina modelos de diferencias finitas con racionalizaciones 3D, SPE 49000, Proc de la Conf Técnica Anual y Exposición, 2730 de septiembre, Nueva Orleans, LA. [18] Nævdal, G. Johnsen, L.M. Aanonsen, S.I. y Vefring, E.H. 2003. Monitorización de embalses y actualización continua de modelos utilizando Ensemble Kalman Filter, SPE 84372, Proc del Conf Técnico Anual y Exposición, Oct 5-8, Denver, CO. [19] Jafarpour B. y McLaughlin, D.B. 2007. Historia que coincide con un conjunto de filtro Kalman y parametrización discreta de coseno, SPE 108761, Proc de la Conf Técnica Anual y Exposición, 11-14 de noviembre, Anaheim, CA [20] Li, G. y Reynolds, A. C. 2007. Un conjunto iterativo Kalman filtro para la asimilación de datos, SPE 109808, Proc de la SPE Conf y Exposición Técnica Anual, 11-14 de noviembre, Anaheim, CA [21] Arroyo-Negrete, E. Devagowda, D. Datta-Gupta, A. 2006. Simplificar el conjunto asistido Kalman filtro para la actualización rápida y continua del modelo de depósito. Proc de la Int. Oil & Gas Conf and Exhibition, SPE 104255, Dec 5-7, China [22] ECLIPSE Reservoir Engineering Software http://www.slb.com/content/services/software/reseng/index.a sp ",
            "error": []
        },
        "strategic application area": {
            "translated_key": "área de aplicación estratégica",
            "translated_annotated_text": "Demostración del conjunto de datos de Kalman Assimulation Method for Reservoir Caracterisation Ravi Vadapalli Centro de computación de alto rendimiento Texas Tech University Lubbock, TX 79409 001-806-742-4350 Ravi.Vadapalli@ttu.edu Ajitabh Kumar Department of Petroleum Engineering Texas A&M University College Station, En este enfoque, se utiliza un conjunto de modelos geológicos y datos de producción de yacimientos de petróleo para predecir la respuesta dinámica de los pozos de petróleo. El software Schlumberger ECLIPSE se utiliza para estas simulaciones. Puesto que los modelos en el conjunto no se comunican, la implementación de mensaje-passing es una buena opción. Cada modelo comprueba una licencia ECLIPSE y, por lo tanto, la paralelización de las simulaciones de reservorio depende de las licencias de número disponibles. Hemos habilitado Grid para el conjunto Kalman metodología de asimilación de datos de filtro para el entorno de computación TIGRE Grid. Al poner en común las licencias y los recursos informáticos en todas las instituciones colaboradoras utilizando el metaprogramador GridWay y el entorno TIGRE, la precisión computacional puede aumentarse al tiempo que se reduce el tiempo de ejecución de la simulación. En este artículo, proporcionamos un relato de nuestros esfuerzos en Gridenabilizar el conjunto Kalman Filter metodología de asimilación de datos. Se examinarán los posibles beneficios de este enfoque, las observaciones y la experiencia adquirida. Categorías y Descriptores sujetos C 2.4 [Sistemas distribuidos]: Aplicaciones distribuidas Términos generales Algoritmos, Diseño, Rendimiento 1. INTRODUCCIÓN La computación de cuadrícula [1] es un paradigma de computación colaborativa emergente para ampliar las capacidades específicas de computación de alto rendimiento (HPC) mucho más allá de los recursos locales. Su importancia se deriva del hecho de que la investigación innovadora en áreas de aplicación estratégicas como la biociencia y la medicina, la exploración de energía y el modelado ambiental involucran componentes interdisciplinarios fuertes y a menudo requieren colaboraciones intercampus y capacidades computacionales más allá de las limitaciones institucionales. The Texas Internet Grid for Research and Education (TIGRE) [2,3] es un proyecto de desarrollo de infraestructuras cibernéticas financiado por el estado, llevado a cabo por cinco grandes sistemas universitarios (Rice, A&M, TTU, UH y UT Austin), llamados colectivamente Instituciones TIGRE. El propósito de TIGRE es crear una red de educación superior para sostener y ampliar las oportunidades de investigación y educación en Texas. TIGRE es un proyecto del consorcio de computación de alto rendimiento en Texas (HiPCAT) [4]. El objetivo de HiPCAT es apoyar tecnologías computacionales avanzadas para mejorar la investigación, el desarrollo y las actividades educativas. El objetivo principal de TIGRE es diseñar e implementar middleware Grid de última generación que permita la integración de sistemas de computación, sistemas de almacenamiento y bases de datos, laboratorios de visualización y pantallas, e incluso instrumentos y sensores en Texas. El objetivo secundario es demostrar las capacidades de TIGRE para mejorar las oportunidades de investigación y educación en áreas de aplicación estratégica de interés para el Estado de Texas. Estos son biociencia y medicina, exploración energética y modelado de la calidad del aire. La visión del proyecto TIGRE es fomentar la colaboración interdisciplinaria e intercampus, identificar enfoques novedosos para ampliar las asociaciones académicas, gubernamentales y privadas, y convertirse en un modelo competitivo para las oportunidades de financiación externa. El objetivo general de TIGRE es apoyar los intereses de los usuarios locales, universitarios y regionales y ofrecer vías para conectar con proyectos nacionales de Red como Open Science Grid [5] y TeraGrid [6]. Dentro del \"área de aplicación estratégica\" de exploración energética, hemos habilitado el enfoque conjunto Kalman Filter (EnKF) [7] para la asimilación de datos en el modelado de reservorios y hemos demostrado la extensibilidad de la aplicación utilizando el entorno TIGRE y el metaprogramador GridWay [8]. En la sección 2 se ofrece una visión general del entorno y las capacidades de TIGRE. La descripción de la aplicación y la necesidad de una metodología EnKF compatible con la cuadrícula figuran en la sección 3. Los detalles de la aplicación y los méritos de nuestro enfoque se examinan en la sección 4. Las conclusiones figuran en la sección 5. Por último, en la sección 6 se documentan las observaciones y la experiencia adquirida. 2. TIGRE ENTORNO El MIddleware TIGRE Grid consiste en un conjunto mínimo de componentes derivados de un subconjunto del Virtual Data Toolkit (VDT) [9] que soporta una variedad de sistemas operativos. El propósito de elegir una pila de software mínima es apoyar las aplicaciones disponibles y simplificar la instalación y distribución de las pilas cliente/servidor en los sitios de TIGRE. Se añadirán componentes adicionales a medida que sean necesarios. El mecanismo de packaging y distribución PacMan [10] se emplea para la instalación y gestión del cliente/servidor TIGRE. El mecanismo de distribución de PacMan implica la recuperación, instalación y a menudo configuración del software empaquetado. Este enfoque permite a los clientes mantener versiones actualizadas y consistentes del software TIGRE. También ayuda a los sitios TIGRE a instalar los componentes necesarios en los recursos distribuidos en los sitios participantes. La pila cliente/servidor TIGRE consiste en una capa de autenticación y autorización, Globus GRAM4-basada en la presentación de trabajos a través de servicios web (las instalaciones de servicios pre-web están disponibles bajo petición). Las herramientas para manejar la generación de proxy de cuadrícula, la transferencia de archivos habilitada para cuadrícula y el inicio de sesión remoto habilitado para cuadrícula son compatibles. A continuación se proporcionan los detalles pertinentes de los servicios y herramientas de TIGRE para la programación y gestión de puestos. 2.1. Autoridad certificadora La infraestructura de seguridad TIGRE incluye una autoridad certificadora (CA) acreditada por la International Grid Trust Federation (IGTF) para emitir X. 509 certificados de usuario y recurso Grid [11]. El Texas Advanced Computing Center (TACC), Universidad de Texas en Austin, es el TIGREs CA compartido. Las instituciones de TIGRE actúan como autoridades de registro (RA) para sus respectivas bases de usuarios locales. Para obtener información actualizada sobre la seguridad de los certificados de usuario y de recursos y sus instrucciones de instalación, véase ref [2]. Los usuarios y hosts de TIGRE son identificados por su distinguido nombre (DN) en su certificado X.509 proporcionado por la CA. Un archivo nativo Grid-mapfile que contiene una lista de DNs autorizados se utiliza para autenticar y autorizar la programación y gestión de trabajos de los usuarios en los recursos del sitio TIGRE. En la Universidad Texas Tech, a los usuarios se les asigna dinámicamente una de las muchas cuentas genéricas. Esto se logra a través del Sistema de Gestión de Usuarios de Red (GUMS) [12]. 2.2. Programación y gestión de empleos El entorno TIGRE apoya la presentación de trabajos basada en GRAM4 a través de servicios web. Los scripts de envío de trabajos se generan usando XML. Los servicios web GRAM traducen los scripts XML en programadores de lotes específicos de grupos de destino como LSF, PBS o SGE. Los protocolos de transferencia de archivos de alto ancho de banda como GridFTP se utilizan para estadificación de archivos dentro y fuera de la máquina de destino. El acceso a hosts remotos para compilar y depurar es sólo a través del servicio GSISSH que requiere autenticación de recursos a través de certificados X.509. La autenticación y autorización de los trabajos de Grid se gestionan mediante la emisión de certificados de Grid a usuarios y anfitriones. Las listas de revocación de certificados (CRL) se actualizan diariamente para mantener altos estándares de seguridad de los servicios de TIGRE Grid. El área de documentación del portal TIGRE [2] proporciona un tutorial de inicio rápido sobre cómo ejecutar trabajos en TIGRE. 2.3. Metascheduler El metascheduler interopera con los programadores de lotes de nivel de cluster (como LSF, PBS) en la gestión general del flujo de trabajo de Grid. En el presente trabajo, hemos empleado el metaprogramador GridWay [8] -un proyecto de incubadora Globus- para programar y gestionar trabajos en TIGRE. El GridWay es un metaprogramador ligero que utiliza plenamente las funcionalidades de Globus. Está diseñado para proporcionar un uso eficiente de los recursos dinámicos de Grid por múltiples usuarios para las infraestructuras de Grid construidas sobre los servicios de Globus. El administrador del sitio TIGRE puede controlar el uso compartido de recursos a través de un potente programador integrado proporcionado por GridWay o ampliando el módulo de programación externa GridWays para proporcionar sus propias políticas de programación. Los usuarios de aplicaciones pueden escribir descripciones de trabajos usando el formato de plantilla de trabajo simple y directo de GridWays (ver Sección 4 para más detalles) o el lenguaje estándar de descripción de la presentación de trabajos (JSDL). Para más detalles sobre la aplicación, véase la sección 4. 2.4. Sistema de Gestión de Servicios al Cliente Un portal TIGRE [2] fue diseñado e implementado para interconectar usuarios y proveedores de recursos. Fue diseñado utilizando GridPort [13] y es mantenido por TACC. El entorno TIGRE es compatible con herramientas de código abierto como el Open Ticket Request System (OTRS) [14] para el servicio de tickets de problemas, y MoinMoin [15] Wiki para la gestión de contenido y conocimiento de TIGRE para educación, extensión y capacitación. Los enlaces para OTRS y Wiki son consumidos por el portal TIGRE [2] - el portal para usuarios y proveedores de recursos. El estado y las cargas de los recursos de TIGRE son monitoreados por el servicio de Repositorio de Información de Puertos Grid (GPIR) del kit de herramientas GridPort [13] que interactúa con el servicio local de monitoreo de carga de clústeres como Ganglia. El GPIR utiliza trabajos de cron en cada recurso para reunir características específicas de los recursos del sitio, tales como trabajos que se ejecutan, en cola y esperando la asignación de recursos. 3. APLICACIÓN ENSEMBLE KALMAN FILTER El objetivo principal de las simulaciones de yacimientos de hidrocarburos es predecir el comportamiento de la producción de yacimientos de petróleo y gas (denominados en lo sucesivo campo) para su desarrollo y gestión óptima. En el modelado de yacimientos, el campo se divide en varios modelos geológicos, como se muestra en la Figura 1. Para una previsión precisa del rendimiento del campo, es necesario conciliar varios modelos geológicos con la respuesta dinámica del campo a través de la coincidencia histórica [16-20]. Gráfico 1 Vista transversal del Campo. Las capas verticales corresponden a diferentes modelos geológicos y los clavos son pozos de aceite cuya información histórica se utilizará para predecir el comportamiento de la producción. (Figura Ref:http://faculty.smu.edu/zchen/research.html). El EnKF es un método de Monte Carlo que trabaja con un conjunto de modelos de embalses. Este método utiliza covarianzas cruzadas [21] entre las mediciones de campo y los parámetros del modelo de reservorio (derivados de varios modelos) para estimar las incertidumbres de predicción. Los parámetros del modelo geológico en el conjunto se actualizan secuencialmente con el objetivo de minimizar las incertidumbres de predicción. La respuesta histórica de la producción del campo durante más de 50 años se utiliza en estas simulaciones. La principal ventaja de EnKF es que puede vincularse fácilmente a cualquier simulador de depósito, y puede asimilar los últimos datos de producción sin necesidad de volver a ejecutar el simulador desde las condiciones iniciales. Investigadores en Texas son grandes suscriptores del paquete de Schlumberger ECLIPSE [22] para simulaciones de reservorios. En el modelado del embalse, cada modelo geológico comprueba una licencia ECLIPSE. La duración de la simulación de la metodología EnKF depende del número de modelos geológicos utilizados, el número de licencias ECLIPSE disponibles, la historia de producción del campo y las incertidumbres propagadas en la correspondencia de la historia. El flujo de trabajo general de EnKF se muestra en la Figura 2. Gráfico 2 Ensemble Kaman Filter Data Assimulation Workflow. Cada sitio tiene licencias L. En START, el proceso maestro/control (programa principal EnKF) lee el archivo de configuración de simulación para el número (N) de modelos y archivos de entrada específicos del modelo. A continuación, N directorios de trabajo se crean para almacenar los archivos de salida. Al final de la iteración, el proceso maestro/control recoge los archivos de salida de los modelos N y las crosscovarianzas de los procesos posteriores [21] para estimar las incertidumbres de predicción. Esta información se utilizará para actualizar modelos (o archivos de entrada) para la siguiente iteración. La simulación continúa hasta agotar las historias de producción. La simulación típica de EnKF con N=50 y historias de campo de 50-60 años, en pasos de tiempo que van de tres meses a un año, toma unas tres semanas en un entorno de computación en serie. En el entorno informático paralelo, no hay comunicación interproceso entre los modelos geológicos en el conjunto. Sin embargo, al final de cada paso del tiempo de simulación, los archivos de salida específicos del modelo deben ser recogidos para analizar covarianzas cruzadas [21] y para preparar el siguiente conjunto de archivos de entrada. Por lo tanto, el modelo maestro-esclavo en el entorno de mensajepassing (MPI) es un paradigma adecuado. En este enfoque, los modelos geológicos son tratados como esclavos y se distribuyen entre los procesadores disponibles. El master Cluster o (TIGRE/GridWay) START Read Configuration File Create N Working Directories Create N Input files Model l Model 2 Model N.. . ECLIPSE in situ Un ECLIPSE in situ B ECLIPSE in situ Z Collect N Model Outputs, Post-process Output files FIN. . . proceso recoge archivos de salida específicos del modelo, analiza y prepara el siguiente conjunto de archivos de entrada para la simulación. Dado que cada modelo geológico comprueba una licencia ECLIPSE, la paralelización de la simulación depende del número de licencias disponibles. Cuando el número de licencias disponible es menor que el número de modelos en el conjunto, uno o más de los nodos del grupo MPI tienen que manejar más de un modelo en serie y, por lo tanto, se tarda más tiempo en completar la simulación. Un Departamento de Ingeniería Petrolera generalmente adquiere 10-15 licencias ECLIPSE, mientras que al menos diez veces más número de licencias sería necesario para simulaciones estándar de la industria. El número de licencias puede incrementarse con la participación de varios departamentos de ingeniería petrolera que apoyan el paquete ECLIPSE. Dado que MPI no se escala muy bien para aplicaciones que involucran clústeres de computación remotos, y para evitar los problemas del firewall con servidores de licencias en todos los dominios administrativos, parece necesario activar el flujo de trabajo de EnKF. Con esta motivación, hemos implementado el flujo de trabajo EnKF habilitado para Grid para el entorno TIGRE y hemos demostrado la paralelización de la aplicación a través de TIGRE usando el metascheduler GridWay. En la siguiente sección figuran más detalles al respecto. 4. DETALLES DE APLICACION Para habilitar Grid-enable el enfoque EnKF, hemos eliminado el código MPI para el procesamiento paralelo y reemplazado por trabajos de N monoprocesador (o sub-trabajos) donde, N es el número de modelos geológicos en el conjunto. Estos sub-trabajos específicos de modelos se distribuyeron a través de sitios TIGRE que soportan el paquete ECLIPSE utilizando el metaprogramador GridWay [8]. Para cada sub-trabajo, hemos construido una plantilla de trabajo GridWay que especifica los archivos ejecutables, de entrada y salida, y los requisitos de recursos. Dado que los recursos de cálculo de TIGRE no se espera que cambien con frecuencia, hemos utilizado la política de descubrimiento de recursos estáticos para GridWay y los sub-trabajos fueron programados dinámicamente a través de los recursos de TIGRE usando GridWay. La Figura 3 representa el archivo de plantilla de subtrabajo para el metaprogramador GridWay. Gráfico 3 Plantilla de subtrabajo GridWay En la Figura 3, REQUISITOS bandera se establece para elegir los recursos que satisfacen los requisitos de la aplicación. En el caso de la aplicación EnKF, por ejemplo, necesitamos recursos que apoyen el paquete ECLIPSE. ARGUMENTS flag especifica el modelo en el conjunto que invocará ECLIPSE en un sitio remoto. INPUT_FILES es preparado por el programa principal de EnKF (o proceso maestro/control) y es transferido por GridWay al sitio remoto donde está desatendido y está preparado para su ejecución. Finalmente, OUTPUT_FILES especifica el nombre y la ubicación donde se escribirán los archivos de salida. Las características de la línea de comandos de GridWay se utilizaron para recopilar y procesar las salidas específicas del modelo para preparar un nuevo conjunto de archivos de entrada. Este paso imita la sincronización del proceso MPI en el modelo maestro-esclavo. Al final de cada iteración, los recursos computacionales y las licencias se devuelven al grupo. La Tabla 1 muestra los sub-trabajos en TIGRE Grid via GridWay usando el comando gwps y para mayor claridad, sólo se mostraron las columnas seleccionadas. USUARIO JID DM EM NOMBRE HOST pingluo 88 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 89 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 90 wrap actv enkf.jt minigar.hp Programación de trabajo a través de TIGRE usando GridWay Metascheduler. DM: Estado de envío, EM: Estado de ejecución, JID es el id de trabajo y HOST corresponde al cluster específico del sitio y su planificador de lotes local. Cuando un trabajo es enviado a GridWay, pasará por una serie de estados de envío (DM) y ejecución (EM). Para DM, los estados incluyen pend(ing), prol(og), wrap(per), epil(og), y hecho. DM=prol significa que el trabajo ha sido programado a un recurso y el directorio de trabajo remoto está en preparación. DM=warp implica que GridWay está ejecutando el envoltorio que a su vez ejecuta la aplicación. DM=epil implica que el trabajo ha terminado de ejecutarse en el sitio remoto y los resultados se están transfiriendo al servidor GridWay. Del mismo modo, cuando EM=pend implica que el trabajo está esperando en la cola para el recurso y el trabajo se está ejecutando cuando EM=actv. Para ver la lista completa de las banderas de mensajes y sus descripciones, consulte la documentación en ref [8]. Hemos demostrado las ejecuciones de EnKF habilitadas para Grid usando GridWay para entorno TIGRE. Los trabajos son tan elegidos que el tiempo de ejecución no supera más de media hora. La simulación incluyó hasta 20 trabajos entre sitios de A&M y TTU con TTU cumpliendo 10 licencias. Para obtener información sobre los recursos, véase el cuadro I. Una de las principales ventajas de la simulación EnKF habilitada por Grid es que tanto los recursos como las licencias se devuelven al grupo al final de cada paso del tiempo de simulación a diferencia del caso de la implementación de MPI donde las licencias y nodos están bloqueados hasta la finalización de la simulación completa. Sin embargo, el hecho de que cada sub-trabajo se programe independientemente a través de GridWay podría posiblemente incurrir en otro retraso de tiempo causado por esperar en la cola para la ejecución en cada paso del tiempo de simulación. Tales retrasos no se esperan EXECUTABLE=runFORWARD NECESIDADES=HOSTNAME=cosmos.tamu.edu  HOSTNAME=antaeus.hpcc.ttu.edu  HOSTNAME=minigar.hpcc.ttu.edu  ARGUMENTOS=001 INPUT_FILES=001.in.tar OUTPUT_FI Hay dos escenarios principales para comparar los enfoques de computación de red y clúster. Escenario I: El cúmulo está muy cargado. El tiempo promedio de espera concebido del trabajo que solicita un gran número de CPUs es generalmente más largo que el tiempo de espera de los trabajos que solicitan una sola CPU. Por lo tanto, el tiempo de espera general podría ser más corto en el enfoque Grid que solicita una sola CPU para cada sub-trabajo muchas veces en comparación con la implementación MPI que requiere un gran número de CPUs en un solo momento. Es evidente que la programación de la cuadrícula es beneficiosa especialmente cuando el clúster está fuertemente cargado y el número solicitado de CPUs para el trabajo del MPI no está fácilmente disponible. Escenario II: El clúster está relativamente menos cargado o disponible en gran medida. Parece que la implementación del MPI es favorable en comparación con la programación de la Rejilla. Sin embargo, la paralelización de la aplicación EnKF depende del número de licencias ECLIPSE e idealmente, el número de licencias debe ser igual al número de modelos en el conjunto. Por lo tanto, si una sola institución no tiene suficiente número de licencias, la disponibilidad del clúster no ayuda tanto como se espera. Dado que el entorno colaborativo, como TIGRE, puede abordar tanto los requisitos de computación como los de recursos de software para la aplicación EnKF, el enfoque compatible con Grid sigue siendo ventajoso sobre la implementación MPI convencional en cualquiera de los escenarios anteriores. 5. CONCLUSIONES Y FUTURO TRABAJO TIGRE es un proyecto de desarrollo de la red de educación superior y su propósito es mantener y ampliar las oportunidades de investigación y educación a través de Texas. Dentro del área de aplicación de exploración energética, hemos habilitado la implementación MPI del conjunto Kalman metodología de asimilación de datos de filtro para la caracterización de reservorios. Esta tarea se llevó a cabo eliminando el código MPI para el procesamiento paralelo y reemplazando con trabajos de un solo procesador uno para cada modelo geológico en el conjunto. Estos trabajos de un solo procesador fueron programados a través de TIGRE a través de GridWay metascheduler. Hemos demostrado que mediante la puesta en común de licencias a través de sitios TIGRE, más modelos geológicos pueden ser manejados en paralelo y por lo tanto concebiblemente mejor precisión de simulación. Este enfoque tiene varias ventajas sobre la implementación de MPI, especialmente cuando un clúster específico del sitio está muy cargado y/o las licencias de número requeridas para la simulación son más que las disponibles en un solo sitio. Hacia el trabajo futuro, sería interesante comparar el tiempo de ejecución entre MPI y las implementaciones de Grid para la aplicación EnKF. Este esfuerzo podría arrojar luz sobre la calidad del servicio (QoS) de los entornos Grid en comparación con la computación de clústers. Otro aspecto de interés en un futuro próximo sería la gestión de recursos de computación y licencia para abordar la gestión de la relación trabajo (o procesador)-licencia. 6. OBSERVACIONES Y MENOS APRENDIZADOS Los esfuerzos que facilitan la red para la aplicación EnKF han proporcionado amplias oportunidades para reunir información sobre la visibilidad y la promesa de los entornos de computación de Grid para el desarrollo y soporte de aplicaciones. Los principales problemas son la seguridad de los datos estándar de la industria y la CV comparable a la computación de clústers. Dado que la investigación de modelado de reservorios involucra datos propietarios del campo, tuvimos que invertir esfuerzos sustanciales inicialmente en educar a los investigadores de aplicaciones sobre la capacidad de los servicios de Grid para apoyar la seguridad de datos estándar de la industria a través de acceso basado en roles y privilegios utilizando el estándar X.509. Con respecto a QoS, los investigadores de aplicaciones esperan niveles de QoS con entornos de cuadrícula. Además, hay una curva de aprendizaje pronunciada en la computación de cuadrícula en comparación con la computación de clúster convencional. Dado que la computación de cuadrícula sigue siendo una tecnología emergente, y abarca varios ámbitos administrativos, la computación de cuadrícula sigue siendo prematura, especialmente en términos del nivel de QoS, aunque ofrece mejores normas de seguridad de los datos en comparación con los grupos de productos básicos. Es nuestra observación que los programas de capacitación y divulgación que comparan y contrastan los entornos de computación de red y clúster serían un enfoque adecuado para mejorar la participación de los usuarios en la computación de red. Este enfoque también ayuda a los usuarios a emparejar sus aplicaciones y habilidades que las cuadrículas pueden ofrecer. En resumen, nuestros esfuerzos a través de TIGRE en la metodología de asimilación de datos de la EnKF demostraron una promesa sustancial en la contratación de investigadores de Ingeniería Petrolera a través de colaboraciones entre campus. Se están realizando esfuerzos para lograr la participación de más escuelas en este esfuerzo. Estos esfuerzos pueden resultar en un aumento de la investigación colaborativa, oportunidades educativas y desarrollo de la fuerza laboral a través de programas de investigación de posgrado/facultad en instituciones TIGRE. 7. AGRADECIMIENTOS Los autores reconocen al Estado de Texas por apoyar el proyecto TIGRE a través del Fondo Empresarial de Texas, y a las Instituciones TIGRE por proporcionar el mecanismo, en el que también participan los autores (Ravi Vadapalli, Taesung Kim y Ping Luo). Los autores agradecen a los investigadores de aplicaciones Prof. Akhil Datta-Gupta de Texas A&M University y Prof. Lloyd Heinze de Texas Tech University por sus discusiones e interés en explotar el entorno TIGRE para ampliar las oportunidades en investigación y desarrollo. 8. REFERENCIAS [1] Foster, I. y Kesselman, C. (eds.) 2004. The Grid: Blueprint for a new computing infraestructura (The Elsevier series in Grid computing) [2] Portal TIGRE: http://tigreportal.hipcat.net [3] Vadapalli, R. Sill, A., Dooley, R., Murray, M., Luo, P., Kim, T., Huang, M., Thyagaraja, K., y Chaffin, Demostración del entorno TIGRE para aplicaciones de cuadrícula habilitadas/adecuadas. 8o IEEE/ACM Int. Conf. on Grid Computing, 19-21 de septiembre, Austin [4] The High Performance Computing cross Texas Consortium http://www.hipcat.net [5] Pordes, R. Petravick, D. Kramer, B. Olson, D. Livny, M. Roy, A. Avery, P. Blackburn, K. Wenaus, T. Würthwein, F. Foster, I. Gar The Open Science Grid, J. Phys Conf Series http://www.iop.org/EJ/abstract/1742-6596/78/1/012057 y http://www.opensciencegrid.org [6] Reed, D.A. 2003. Rejilla, el Teragrid y más allá, Ordenador, vol. 30, no. 1 y http://www.teragrid.org [7] Evensen, G. 2006. Asimilación de datos: El conjunto Kalman Filter, Springer [8] Herrera, J. Huedo, E. Montero, R. S. y Llorente, I. M. 2005. Programación Científica, vol 12, No. 4. pp 317-331 [9] Avery, P. and Foster, I. 2001. El proyecto GriPhyN: Hacia redes virtuales de datos a petaescala, informe técnico GriPhyN-200115 y http://vdt.cs.wisc.edu [10] La guía de documentación e instalación de PacMan http://physics.bu.edu/pacman/htmls [11] Caskey, P. Murray, M. Perez, J. y Sill, A. 2007. Estudios de casos en la gestión de identificación para organizaciones virtuales, EDUCOUSO Southwest Reg. Conf., 21-23 febrero, Austin, TX. http://www.educause.edu/ir/library/pdf/SWR07058.pdf [12] El Sistema de Gestión de Usuarios de Grid (GUMS) https://www.racf.bnl.gov/Facility/GUMS/index.html [13] Thomas, M. y Boisseau, J. 2003. Construyendo portales de computación de cuadrículas: El kit de herramientas para el portal de cuadrículas NPACI, Grid computing: haciendo realidad la infraestructura global, Capítulo 28, Berman, F. Fox, G. Thomas, M. Boisseau, J. y Hey, T. (eds), John Wiley and Sons, Ltd, Chichester [14] Open Ticket Request System http:// 1999. Integración de datos dinámicos en modelos de depósito de alta resolución utilizando coeficientes de sensibilidad basados en la racionalización, Society of Petroleum Engineers (SPE), 4 (4). [17] Emanuel, A. S. y Milliken, W. J. 1998. Historia que combina modelos de diferencias finitas con racionalizaciones 3D, SPE 49000, Proc de la Conf Técnica Anual y Exposición, 2730 de septiembre, Nueva Orleans, LA. [18] Nævdal, G. Johnsen, L.M. Aanonsen, S.I. y Vefring, E.H. 2003. Monitorización de embalses y actualización continua de modelos utilizando Ensemble Kalman Filter, SPE 84372, Proc del Conf Técnico Anual y Exposición, Oct 5-8, Denver, CO. [19] Jafarpour B. y McLaughlin, D.B. 2007. Historia que coincide con un conjunto de filtro Kalman y parametrización discreta de coseno, SPE 108761, Proc de la Conf Técnica Anual y Exposición, 11-14 de noviembre, Anaheim, CA [20] Li, G. y Reynolds, A. C. 2007. Un conjunto iterativo Kalman filtro para la asimilación de datos, SPE 109808, Proc de la SPE Conf y Exposición Técnica Anual, 11-14 de noviembre, Anaheim, CA [21] Arroyo-Negrete, E. Devagowda, D. Datta-Gupta, A. 2006. Simplificar el conjunto asistido Kalman filtro para la actualización rápida y continua del modelo de depósito. Proc de la Int. Oil & Gas Conf and Exhibition, SPE 104255, Dec 5-7, China [22] ECLIPSE Reservoir Engineering Software http://www.slb.com/content/services/software/reseng/index.a sp ",
            "error": [
                ""
            ]
        },
        "gridway metascheduler": {
            "translated_key": [],
            "translated_annotated_text": "Demostración del conjunto de datos de Kalman Assimulation Method for Reservoir Caracterisation Ravi Vadapalli Centro de computación de alto rendimiento Texas Tech University Lubbock, TX 79409 001-806-742-4350 Ravi.Vadapalli@ttu.edu Ajitabh Kumar Department of Petroleum Engineering Texas A&M University College Station, En este enfoque, se utiliza un conjunto de modelos geológicos y datos de producción de yacimientos de petróleo para predecir la respuesta dinámica de los pozos de petróleo. El software Schlumberger ECLIPSE se utiliza para estas simulaciones. Puesto que los modelos en el conjunto no se comunican, la implementación de mensaje-passing es una buena opción. Cada modelo comprueba una licencia ECLIPSE y, por lo tanto, la paralelización de las simulaciones de reservorio depende de las licencias de número disponibles. Hemos habilitado Grid para el conjunto Kalman metodología de asimilación de datos de filtro para el entorno de computación TIGRE Grid. Al poner en común las licencias y los recursos informáticos en todas las instituciones colaboradoras utilizando el metaprogramador GridWay y el entorno TIGRE, la precisión computacional puede aumentarse al tiempo que se reduce el tiempo de ejecución de la simulación. En este artículo, proporcionamos un relato de nuestros esfuerzos en Gridenabilizar el conjunto Kalman Filter metodología de asimilación de datos. Se examinarán los posibles beneficios de este enfoque, las observaciones y la experiencia adquirida. Categorías y Descriptores sujetos C 2.4 [Sistemas distribuidos]: Aplicaciones distribuidas Términos generales Algoritmos, Diseño, Rendimiento 1. INTRODUCCIÓN La computación de cuadrícula [1] es un paradigma de computación colaborativa emergente para ampliar las capacidades específicas de computación de alto rendimiento (HPC) mucho más allá de los recursos locales. Su importancia se deriva del hecho de que la investigación innovadora en áreas de aplicación estratégicas como la biociencia y la medicina, la exploración de energía y el modelado ambiental involucran componentes interdisciplinarios fuertes y a menudo requieren colaboraciones intercampus y capacidades computacionales más allá de las limitaciones institucionales. The Texas Internet Grid for Research and Education (TIGRE) [2,3] es un proyecto de desarrollo de infraestructuras cibernéticas financiado por el estado, llevado a cabo por cinco grandes sistemas universitarios (Rice, A&M, TTU, UH y UT Austin), llamados colectivamente Instituciones TIGRE. El propósito de TIGRE es crear una red de educación superior para sostener y ampliar las oportunidades de investigación y educación en Texas. TIGRE es un proyecto del consorcio de computación de alto rendimiento en Texas (HiPCAT) [4]. El objetivo de HiPCAT es apoyar tecnologías computacionales avanzadas para mejorar la investigación, el desarrollo y las actividades educativas. El objetivo principal de TIGRE es diseñar e implementar middleware Grid de última generación que permita la integración de sistemas de computación, sistemas de almacenamiento y bases de datos, laboratorios de visualización y pantallas, e incluso instrumentos y sensores en Texas. El objetivo secundario es demostrar las capacidades de TIGRE para mejorar las oportunidades de investigación y educación en áreas de aplicación estratégica de interés para el Estado de Texas. Estos son biociencia y medicina, exploración energética y modelado de la calidad del aire. La visión del proyecto TIGRE es fomentar la colaboración interdisciplinaria e intercampus, identificar enfoques novedosos para ampliar las asociaciones académicas, gubernamentales y privadas, y convertirse en un modelo competitivo para las oportunidades de financiación externa. El objetivo general de TIGRE es apoyar los intereses de los usuarios locales, universitarios y regionales y ofrecer vías para conectar con proyectos nacionales de Red como Open Science Grid [5] y TeraGrid [6]. Dentro del área de aplicación estratégica de exploración energética, hemos habilitado el enfoque conjunto Kalman Filter (EnKF) [7] para la asimilación de datos en el modelado de reservorios y hemos demostrado la extensibilidad de la aplicación utilizando el entorno TIGRE y el metaprogramador GridWay [8]. En la sección 2 se ofrece una visión general del entorno y las capacidades de TIGRE. La descripción de la aplicación y la necesidad de una metodología EnKF compatible con la cuadrícula figuran en la sección 3. Los detalles de la aplicación y los méritos de nuestro enfoque se examinan en la sección 4. Las conclusiones figuran en la sección 5. Por último, en la sección 6 se documentan las observaciones y la experiencia adquirida. 2. TIGRE ENTORNO El MIddleware TIGRE Grid consiste en un conjunto mínimo de componentes derivados de un subconjunto del Virtual Data Toolkit (VDT) [9] que soporta una variedad de sistemas operativos. El propósito de elegir una pila de software mínima es apoyar las aplicaciones disponibles y simplificar la instalación y distribución de las pilas cliente/servidor en los sitios de TIGRE. Se añadirán componentes adicionales a medida que sean necesarios. El mecanismo de packaging y distribución PacMan [10] se emplea para la instalación y gestión del cliente/servidor TIGRE. El mecanismo de distribución de PacMan implica la recuperación, instalación y a menudo configuración del software empaquetado. Este enfoque permite a los clientes mantener versiones actualizadas y consistentes del software TIGRE. También ayuda a los sitios TIGRE a instalar los componentes necesarios en los recursos distribuidos en los sitios participantes. La pila cliente/servidor TIGRE consiste en una capa de autenticación y autorización, Globus GRAM4-basada en la presentación de trabajos a través de servicios web (las instalaciones de servicios pre-web están disponibles bajo petición). Las herramientas para manejar la generación de proxy de cuadrícula, la transferencia de archivos habilitada para cuadrícula y el inicio de sesión remoto habilitado para cuadrícula son compatibles. A continuación se proporcionan los detalles pertinentes de los servicios y herramientas de TIGRE para la programación y gestión de puestos. 2.1. Autoridad certificadora La infraestructura de seguridad TIGRE incluye una autoridad certificadora (CA) acreditada por la International Grid Trust Federation (IGTF) para emitir X. 509 certificados de usuario y recurso Grid [11]. El Texas Advanced Computing Center (TACC), Universidad de Texas en Austin, es el TIGREs CA compartido. Las instituciones de TIGRE actúan como autoridades de registro (RA) para sus respectivas bases de usuarios locales. Para obtener información actualizada sobre la seguridad de los certificados de usuario y de recursos y sus instrucciones de instalación, véase ref [2]. Los usuarios y hosts de TIGRE son identificados por su distinguido nombre (DN) en su certificado X.509 proporcionado por la CA. Un archivo nativo Grid-mapfile que contiene una lista de DNs autorizados se utiliza para autenticar y autorizar la programación y gestión de trabajos de los usuarios en los recursos del sitio TIGRE. En la Universidad Texas Tech, a los usuarios se les asigna dinámicamente una de las muchas cuentas genéricas. Esto se logra a través del Sistema de Gestión de Usuarios de Red (GUMS) [12]. 2.2. Programación y gestión de empleos El entorno TIGRE apoya la presentación de trabajos basada en GRAM4 a través de servicios web. Los scripts de envío de trabajos se generan usando XML. Los servicios web GRAM traducen los scripts XML en programadores de lotes específicos de grupos de destino como LSF, PBS o SGE. Los protocolos de transferencia de archivos de alto ancho de banda como GridFTP se utilizan para estadificación de archivos dentro y fuera de la máquina de destino. El acceso a hosts remotos para compilar y depurar es sólo a través del servicio GSISSH que requiere autenticación de recursos a través de certificados X.509. La autenticación y autorización de los trabajos de Grid se gestionan mediante la emisión de certificados de Grid a usuarios y anfitriones. Las listas de revocación de certificados (CRL) se actualizan diariamente para mantener altos estándares de seguridad de los servicios de TIGRE Grid. El área de documentación del portal TIGRE [2] proporciona un tutorial de inicio rápido sobre cómo ejecutar trabajos en TIGRE. 2.3. Metascheduler El metascheduler interopera con los programadores de lotes de nivel de cluster (como LSF, PBS) en la gestión general del flujo de trabajo de Grid. En el presente trabajo, hemos empleado el metaprogramador GridWay [8] -un proyecto de incubadora Globus- para programar y gestionar trabajos en TIGRE. El GridWay es un metaprogramador ligero que utiliza plenamente las funcionalidades de Globus. Está diseñado para proporcionar un uso eficiente de los recursos dinámicos de Grid por múltiples usuarios para las infraestructuras de Grid construidas sobre los servicios de Globus. El administrador del sitio TIGRE puede controlar el uso compartido de recursos a través de un potente programador integrado proporcionado por GridWay o ampliando el módulo de programación externa GridWays para proporcionar sus propias políticas de programación. Los usuarios de aplicaciones pueden escribir descripciones de trabajos usando el formato de plantilla de trabajo simple y directo de GridWays (ver Sección 4 para más detalles) o el lenguaje estándar de descripción de la presentación de trabajos (JSDL). Para más detalles sobre la aplicación, véase la sección 4. 2.4. Sistema de Gestión de Servicios al Cliente Un portal TIGRE [2] fue diseñado e implementado para interconectar usuarios y proveedores de recursos. Fue diseñado utilizando GridPort [13] y es mantenido por TACC. El entorno TIGRE es compatible con herramientas de código abierto como el Open Ticket Request System (OTRS) [14] para el servicio de tickets de problemas, y MoinMoin [15] Wiki para la gestión de contenido y conocimiento de TIGRE para educación, extensión y capacitación. Los enlaces para OTRS y Wiki son consumidos por el portal TIGRE [2] - el portal para usuarios y proveedores de recursos. El estado y las cargas de los recursos de TIGRE son monitoreados por el servicio de Repositorio de Información de Puertos Grid (GPIR) del kit de herramientas GridPort [13] que interactúa con el servicio local de monitoreo de carga de clústeres como Ganglia. El GPIR utiliza trabajos de cron en cada recurso para reunir características específicas de los recursos del sitio, tales como trabajos que se ejecutan, en cola y esperando la asignación de recursos. 3. APLICACIÓN ENSEMBLE KALMAN FILTER El objetivo principal de las simulaciones de yacimientos de hidrocarburos es predecir el comportamiento de la producción de yacimientos de petróleo y gas (denominados en lo sucesivo campo) para su desarrollo y gestión óptima. En el modelado de yacimientos, el campo se divide en varios modelos geológicos, como se muestra en la Figura 1. Para una previsión precisa del rendimiento del campo, es necesario conciliar varios modelos geológicos con la respuesta dinámica del campo a través de la coincidencia histórica [16-20]. Gráfico 1 Vista transversal del Campo. Las capas verticales corresponden a diferentes modelos geológicos y los clavos son pozos de aceite cuya información histórica se utilizará para predecir el comportamiento de la producción. (Figura Ref:http://faculty.smu.edu/zchen/research.html). El EnKF es un método de Monte Carlo que trabaja con un conjunto de modelos de embalses. Este método utiliza covarianzas cruzadas [21] entre las mediciones de campo y los parámetros del modelo de reservorio (derivados de varios modelos) para estimar las incertidumbres de predicción. Los parámetros del modelo geológico en el conjunto se actualizan secuencialmente con el objetivo de minimizar las incertidumbres de predicción. La respuesta histórica de la producción del campo durante más de 50 años se utiliza en estas simulaciones. La principal ventaja de EnKF es que puede vincularse fácilmente a cualquier simulador de depósito, y puede asimilar los últimos datos de producción sin necesidad de volver a ejecutar el simulador desde las condiciones iniciales. Investigadores en Texas son grandes suscriptores del paquete de Schlumberger ECLIPSE [22] para simulaciones de reservorios. En el modelado del embalse, cada modelo geológico comprueba una licencia ECLIPSE. La duración de la simulación de la metodología EnKF depende del número de modelos geológicos utilizados, el número de licencias ECLIPSE disponibles, la historia de producción del campo y las incertidumbres propagadas en la correspondencia de la historia. El flujo de trabajo general de EnKF se muestra en la Figura 2. Gráfico 2 Ensemble Kaman Filter Data Assimulation Workflow. Cada sitio tiene licencias L. En START, el proceso maestro/control (programa principal EnKF) lee el archivo de configuración de simulación para el número (N) de modelos y archivos de entrada específicos del modelo. A continuación, N directorios de trabajo se crean para almacenar los archivos de salida. Al final de la iteración, el proceso maestro/control recoge los archivos de salida de los modelos N y las crosscovarianzas de los procesos posteriores [21] para estimar las incertidumbres de predicción. Esta información se utilizará para actualizar modelos (o archivos de entrada) para la siguiente iteración. La simulación continúa hasta agotar las historias de producción. La simulación típica de EnKF con N=50 y historias de campo de 50-60 años, en pasos de tiempo que van de tres meses a un año, toma unas tres semanas en un entorno de computación en serie. En el entorno informático paralelo, no hay comunicación interproceso entre los modelos geológicos en el conjunto. Sin embargo, al final de cada paso del tiempo de simulación, los archivos de salida específicos del modelo deben ser recogidos para analizar covarianzas cruzadas [21] y para preparar el siguiente conjunto de archivos de entrada. Por lo tanto, el modelo maestro-esclavo en el entorno de mensajepassing (MPI) es un paradigma adecuado. En este enfoque, los modelos geológicos son tratados como esclavos y se distribuyen entre los procesadores disponibles. El master Cluster o (TIGRE/GridWay) START Read Configuration File Create N Working Directories Create N Input files Model l Model 2 Model N.. . ECLIPSE in situ Un ECLIPSE in situ B ECLIPSE in situ Z Collect N Model Outputs, Post-process Output files FIN. . . proceso recoge archivos de salida específicos del modelo, analiza y prepara el siguiente conjunto de archivos de entrada para la simulación. Dado que cada modelo geológico comprueba una licencia ECLIPSE, la paralelización de la simulación depende del número de licencias disponibles. Cuando el número de licencias disponible es menor que el número de modelos en el conjunto, uno o más de los nodos del grupo MPI tienen que manejar más de un modelo en serie y, por lo tanto, se tarda más tiempo en completar la simulación. Un Departamento de Ingeniería Petrolera generalmente adquiere 10-15 licencias ECLIPSE, mientras que al menos diez veces más número de licencias sería necesario para simulaciones estándar de la industria. El número de licencias puede incrementarse con la participación de varios departamentos de ingeniería petrolera que apoyan el paquete ECLIPSE. Dado que MPI no se escala muy bien para aplicaciones que involucran clústeres de computación remotos, y para evitar los problemas del firewall con servidores de licencias en todos los dominios administrativos, parece necesario activar el flujo de trabajo de EnKF. Con esta motivación, hemos implementado el flujo de trabajo EnKF habilitado para Grid para el entorno TIGRE y hemos demostrado la paralelización de la aplicación a través de TIGRE usando el metascheduler GridWay. En la siguiente sección figuran más detalles al respecto. 4. DETALLES DE APLICACION Para habilitar Grid-enable el enfoque EnKF, hemos eliminado el código MPI para el procesamiento paralelo y reemplazado por trabajos de N monoprocesador (o sub-trabajos) donde, N es el número de modelos geológicos en el conjunto. Estos sub-trabajos específicos de modelos se distribuyeron a través de sitios TIGRE que soportan el paquete ECLIPSE utilizando el metaprogramador GridWay [8]. Para cada sub-trabajo, hemos construido una plantilla de trabajo GridWay que especifica los archivos ejecutables, de entrada y salida, y los requisitos de recursos. Dado que los recursos de cálculo de TIGRE no se espera que cambien con frecuencia, hemos utilizado la política de descubrimiento de recursos estáticos para GridWay y los sub-trabajos fueron programados dinámicamente a través de los recursos de TIGRE usando GridWay. La Figura 3 representa el archivo de plantilla de subtrabajo para el metaprogramador GridWay. Gráfico 3 Plantilla de subtrabajo GridWay En la Figura 3, REQUISITOS bandera se establece para elegir los recursos que satisfacen los requisitos de la aplicación. En el caso de la aplicación EnKF, por ejemplo, necesitamos recursos que apoyen el paquete ECLIPSE. ARGUMENTS flag especifica el modelo en el conjunto que invocará ECLIPSE en un sitio remoto. INPUT_FILES es preparado por el programa principal de EnKF (o proceso maestro/control) y es transferido por GridWay al sitio remoto donde está desatendido y está preparado para su ejecución. Finalmente, OUTPUT_FILES especifica el nombre y la ubicación donde se escribirán los archivos de salida. Las características de la línea de comandos de GridWay se utilizaron para recopilar y procesar las salidas específicas del modelo para preparar un nuevo conjunto de archivos de entrada. Este paso imita la sincronización del proceso MPI en el modelo maestro-esclavo. Al final de cada iteración, los recursos computacionales y las licencias se devuelven al grupo. La Tabla 1 muestra los sub-trabajos en TIGRE Grid via GridWay usando el comando gwps y para mayor claridad, sólo se mostraron las columnas seleccionadas. USUARIO JID DM EM NOMBRE HOST pingluo 88 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 89 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 90 wrap actv enkf.jt minigar.hp Programación de trabajo a través de TIGRE usando GridWay Metascheduler. DM: Estado de envío, EM: Estado de ejecución, JID es el id de trabajo y HOST corresponde al cluster específico del sitio y su planificador de lotes local. Cuando un trabajo es enviado a GridWay, pasará por una serie de estados de envío (DM) y ejecución (EM). Para DM, los estados incluyen pend(ing), prol(og), wrap(per), epil(og), y hecho. DM=prol significa que el trabajo ha sido programado a un recurso y el directorio de trabajo remoto está en preparación. DM=warp implica que GridWay está ejecutando el envoltorio que a su vez ejecuta la aplicación. DM=epil implica que el trabajo ha terminado de ejecutarse en el sitio remoto y los resultados se están transfiriendo al servidor GridWay. Del mismo modo, cuando EM=pend implica que el trabajo está esperando en la cola para el recurso y el trabajo se está ejecutando cuando EM=actv. Para ver la lista completa de las banderas de mensajes y sus descripciones, consulte la documentación en ref [8]. Hemos demostrado las ejecuciones de EnKF habilitadas para Grid usando GridWay para entorno TIGRE. Los trabajos son tan elegidos que el tiempo de ejecución no supera más de media hora. La simulación incluyó hasta 20 trabajos entre sitios de A&M y TTU con TTU cumpliendo 10 licencias. Para obtener información sobre los recursos, véase el cuadro I. Una de las principales ventajas de la simulación EnKF habilitada por Grid es que tanto los recursos como las licencias se devuelven al grupo al final de cada paso del tiempo de simulación a diferencia del caso de la implementación de MPI donde las licencias y nodos están bloqueados hasta la finalización de la simulación completa. Sin embargo, el hecho de que cada sub-trabajo se programe independientemente a través de GridWay podría posiblemente incurrir en otro retraso de tiempo causado por esperar en la cola para la ejecución en cada paso del tiempo de simulación. Tales retrasos no se esperan EXECUTABLE=runFORWARD NECESIDADES=HOSTNAME=cosmos.tamu.edu  HOSTNAME=antaeus.hpcc.ttu.edu  HOSTNAME=minigar.hpcc.ttu.edu  ARGUMENTOS=001 INPUT_FILES=001.in.tar OUTPUT_FI Hay dos escenarios principales para comparar los enfoques de computación de red y clúster. Escenario I: El cúmulo está muy cargado. El tiempo promedio de espera concebido del trabajo que solicita un gran número de CPUs es generalmente más largo que el tiempo de espera de los trabajos que solicitan una sola CPU. Por lo tanto, el tiempo de espera general podría ser más corto en el enfoque Grid que solicita una sola CPU para cada sub-trabajo muchas veces en comparación con la implementación MPI que requiere un gran número de CPUs en un solo momento. Es evidente que la programación de la cuadrícula es beneficiosa especialmente cuando el clúster está fuertemente cargado y el número solicitado de CPUs para el trabajo del MPI no está fácilmente disponible. Escenario II: El clúster está relativamente menos cargado o disponible en gran medida. Parece que la implementación del MPI es favorable en comparación con la programación de la Rejilla. Sin embargo, la paralelización de la aplicación EnKF depende del número de licencias ECLIPSE e idealmente, el número de licencias debe ser igual al número de modelos en el conjunto. Por lo tanto, si una sola institución no tiene suficiente número de licencias, la disponibilidad del clúster no ayuda tanto como se espera. Dado que el entorno colaborativo, como TIGRE, puede abordar tanto los requisitos de computación como los de recursos de software para la aplicación EnKF, el enfoque compatible con Grid sigue siendo ventajoso sobre la implementación MPI convencional en cualquiera de los escenarios anteriores. 5. CONCLUSIONES Y FUTURO TRABAJO TIGRE es un proyecto de desarrollo de la red de educación superior y su propósito es mantener y ampliar las oportunidades de investigación y educación a través de Texas. Dentro del área de aplicación de exploración energética, hemos habilitado la implementación MPI del conjunto Kalman metodología de asimilación de datos de filtro para la caracterización de reservorios. Esta tarea se llevó a cabo eliminando el código MPI para el procesamiento paralelo y reemplazando con trabajos de un solo procesador uno para cada modelo geológico en el conjunto. Estos trabajos de un solo procesador fueron programados a través de TIGRE a través de GridWay metascheduler. Hemos demostrado que mediante la puesta en común de licencias a través de sitios TIGRE, más modelos geológicos pueden ser manejados en paralelo y por lo tanto concebiblemente mejor precisión de simulación. Este enfoque tiene varias ventajas sobre la implementación de MPI, especialmente cuando un clúster específico del sitio está muy cargado y/o las licencias de número requeridas para la simulación son más que las disponibles en un solo sitio. Hacia el trabajo futuro, sería interesante comparar el tiempo de ejecución entre MPI y las implementaciones de Grid para la aplicación EnKF. Este esfuerzo podría arrojar luz sobre la calidad del servicio (QoS) de los entornos Grid en comparación con la computación de clústers. Otro aspecto de interés en un futuro próximo sería la gestión de recursos de computación y licencia para abordar la gestión de la relación trabajo (o procesador)-licencia. 6. OBSERVACIONES Y MENOS APRENDIZADOS Los esfuerzos que facilitan la red para la aplicación EnKF han proporcionado amplias oportunidades para reunir información sobre la visibilidad y la promesa de los entornos de computación de Grid para el desarrollo y soporte de aplicaciones. Los principales problemas son la seguridad de los datos estándar de la industria y la CV comparable a la computación de clústers. Dado que la investigación de modelado de reservorios involucra datos propietarios del campo, tuvimos que invertir esfuerzos sustanciales inicialmente en educar a los investigadores de aplicaciones sobre la capacidad de los servicios de Grid para apoyar la seguridad de datos estándar de la industria a través de acceso basado en roles y privilegios utilizando el estándar X.509. Con respecto a QoS, los investigadores de aplicaciones esperan niveles de QoS con entornos de cuadrícula. Además, hay una curva de aprendizaje pronunciada en la computación de cuadrícula en comparación con la computación de clúster convencional. Dado que la computación de cuadrícula sigue siendo una tecnología emergente, y abarca varios ámbitos administrativos, la computación de cuadrícula sigue siendo prematura, especialmente en términos del nivel de QoS, aunque ofrece mejores normas de seguridad de los datos en comparación con los grupos de productos básicos. Es nuestra observación que los programas de capacitación y divulgación que comparan y contrastan los entornos de computación de red y clúster serían un enfoque adecuado para mejorar la participación de los usuarios en la computación de red. Este enfoque también ayuda a los usuarios a emparejar sus aplicaciones y habilidades que las cuadrículas pueden ofrecer. En resumen, nuestros esfuerzos a través de TIGRE en la metodología de asimilación de datos de la EnKF demostraron una promesa sustancial en la contratación de investigadores de Ingeniería Petrolera a través de colaboraciones entre campus. Se están realizando esfuerzos para lograr la participación de más escuelas en este esfuerzo. Estos esfuerzos pueden resultar en un aumento de la investigación colaborativa, oportunidades educativas y desarrollo de la fuerza laboral a través de programas de investigación de posgrado/facultad en instituciones TIGRE. 7. AGRADECIMIENTOS Los autores reconocen al Estado de Texas por apoyar el proyecto TIGRE a través del Fondo Empresarial de Texas, y a las Instituciones TIGRE por proporcionar el mecanismo, en el que también participan los autores (Ravi Vadapalli, Taesung Kim y Ping Luo). Los autores agradecen a los investigadores de aplicaciones Prof. Akhil Datta-Gupta de Texas A&M University y Prof. Lloyd Heinze de Texas Tech University por sus discusiones e interés en explotar el entorno TIGRE para ampliar las oportunidades en investigación y desarrollo. 8. REFERENCIAS [1] Foster, I. y Kesselman, C. (eds.) 2004. The Grid: Blueprint for a new computing infraestructura (The Elsevier series in Grid computing) [2] Portal TIGRE: http://tigreportal.hipcat.net [3] Vadapalli, R. Sill, A., Dooley, R., Murray, M., Luo, P., Kim, T., Huang, M., Thyagaraja, K., y Chaffin, Demostración del entorno TIGRE para aplicaciones de cuadrícula habilitadas/adecuadas. 8o IEEE/ACM Int. Conf. on Grid Computing, 19-21 de septiembre, Austin [4] The High Performance Computing cross Texas Consortium http://www.hipcat.net [5] Pordes, R. Petravick, D. Kramer, B. Olson, D. Livny, M. Roy, A. Avery, P. Blackburn, K. Wenaus, T. Würthwein, F. Foster, I. Gar The Open Science Grid, J. Phys Conf Series http://www.iop.org/EJ/abstract/1742-6596/78/1/012057 y http://www.opensciencegrid.org [6] Reed, D.A. 2003. Rejilla, el Teragrid y más allá, Ordenador, vol. 30, no. 1 y http://www.teragrid.org [7] Evensen, G. 2006. Asimilación de datos: El conjunto Kalman Filter, Springer [8] Herrera, J. Huedo, E. Montero, R. S. y Llorente, I. M. 2005. Programación Científica, vol 12, No. 4. pp 317-331 [9] Avery, P. and Foster, I. 2001. El proyecto GriPhyN: Hacia redes virtuales de datos a petaescala, informe técnico GriPhyN-200115 y http://vdt.cs.wisc.edu [10] La guía de documentación e instalación de PacMan http://physics.bu.edu/pacman/htmls [11] Caskey, P. Murray, M. Perez, J. y Sill, A. 2007. Estudios de casos en la gestión de identificación para organizaciones virtuales, EDUCOUSO Southwest Reg. Conf., 21-23 febrero, Austin, TX. http://www.educause.edu/ir/library/pdf/SWR07058.pdf [12] El Sistema de Gestión de Usuarios de Grid (GUMS) https://www.racf.bnl.gov/Facility/GUMS/index.html [13] Thomas, M. y Boisseau, J. 2003. Construyendo portales de computación de cuadrículas: El kit de herramientas para el portal de cuadrículas NPACI, Grid computing: haciendo realidad la infraestructura global, Capítulo 28, Berman, F. Fox, G. Thomas, M. Boisseau, J. y Hey, T. (eds), John Wiley and Sons, Ltd, Chichester [14] Open Ticket Request System http:// 1999. Integración de datos dinámicos en modelos de depósito de alta resolución utilizando coeficientes de sensibilidad basados en la racionalización, Society of Petroleum Engineers (SPE), 4 (4). [17] Emanuel, A. S. y Milliken, W. J. 1998. Historia que combina modelos de diferencias finitas con racionalizaciones 3D, SPE 49000, Proc de la Conf Técnica Anual y Exposición, 2730 de septiembre, Nueva Orleans, LA. [18] Nævdal, G. Johnsen, L.M. Aanonsen, S.I. y Vefring, E.H. 2003. Monitorización de embalses y actualización continua de modelos utilizando Ensemble Kalman Filter, SPE 84372, Proc del Conf Técnico Anual y Exposición, Oct 5-8, Denver, CO. [19] Jafarpour B. y McLaughlin, D.B. 2007. Historia que coincide con un conjunto de filtro Kalman y parametrización discreta de coseno, SPE 108761, Proc de la Conf Técnica Anual y Exposición, 11-14 de noviembre, Anaheim, CA [20] Li, G. y Reynolds, A. C. 2007. Un conjunto iterativo Kalman filtro para la asimilación de datos, SPE 109808, Proc de la SPE Conf y Exposición Técnica Anual, 11-14 de noviembre, Anaheim, CA [21] Arroyo-Negrete, E. Devagowda, D. Datta-Gupta, A. 2006. Simplificar el conjunto asistido Kalman filtro para la actualización rápida y continua del modelo de depósito. Proc de la Int. Oil & Gas Conf and Exhibition, SPE 104255, Dec 5-7, China [22] ECLIPSE Reservoir Engineering Software http://www.slb.com/content/services/software/reseng/index.a sp ",
            "error": []
        },
        "pooling license": {
            "translated_key": [],
            "translated_annotated_text": "Demostración del conjunto de datos de Kalman Assimulation Method for Reservoir Caracterisation Ravi Vadapalli Centro de computación de alto rendimiento Texas Tech University Lubbock, TX 79409 001-806-742-4350 Ravi.Vadapalli@ttu.edu Ajitabh Kumar Department of Petroleum Engineering Texas A&M University College Station, En este enfoque, se utiliza un conjunto de modelos geológicos y datos de producción de yacimientos de petróleo para predecir la respuesta dinámica de los pozos de petróleo. El software Schlumberger ECLIPSE se utiliza para estas simulaciones. Puesto que los modelos en el conjunto no se comunican, la implementación de mensaje-passing es una buena opción. Cada modelo comprueba una licencia ECLIPSE y, por lo tanto, la paralelización de las simulaciones de reservorio depende de las licencias de número disponibles. Hemos habilitado Grid para el conjunto Kalman metodología de asimilación de datos de filtro para el entorno de computación TIGRE Grid. Al poner en común las licencias y los recursos informáticos en todas las instituciones colaboradoras utilizando el metaprogramador GridWay y el entorno TIGRE, la precisión computacional puede aumentarse al tiempo que se reduce el tiempo de ejecución de la simulación. En este artículo, proporcionamos un relato de nuestros esfuerzos en Gridenabilizar el conjunto Kalman Filter metodología de asimilación de datos. Se examinarán los posibles beneficios de este enfoque, las observaciones y la experiencia adquirida. Categorías y Descriptores sujetos C 2.4 [Sistemas distribuidos]: Aplicaciones distribuidas Términos generales Algoritmos, Diseño, Rendimiento 1. INTRODUCCIÓN La computación de cuadrícula [1] es un paradigma de computación colaborativa emergente para ampliar las capacidades específicas de computación de alto rendimiento (HPC) mucho más allá de los recursos locales. Su importancia se deriva del hecho de que la investigación innovadora en áreas de aplicación estratégicas como la biociencia y la medicina, la exploración de energía y el modelado ambiental involucran componentes interdisciplinarios fuertes y a menudo requieren colaboraciones intercampus y capacidades computacionales más allá de las limitaciones institucionales. The Texas Internet Grid for Research and Education (TIGRE) [2,3] es un proyecto de desarrollo de infraestructuras cibernéticas financiado por el estado, llevado a cabo por cinco grandes sistemas universitarios (Rice, A&M, TTU, UH y UT Austin), llamados colectivamente Instituciones TIGRE. El propósito de TIGRE es crear una red de educación superior para sostener y ampliar las oportunidades de investigación y educación en Texas. TIGRE es un proyecto del consorcio de computación de alto rendimiento en Texas (HiPCAT) [4]. El objetivo de HiPCAT es apoyar tecnologías computacionales avanzadas para mejorar la investigación, el desarrollo y las actividades educativas. El objetivo principal de TIGRE es diseñar e implementar middleware Grid de última generación que permita la integración de sistemas de computación, sistemas de almacenamiento y bases de datos, laboratorios de visualización y pantallas, e incluso instrumentos y sensores en Texas. El objetivo secundario es demostrar las capacidades de TIGRE para mejorar las oportunidades de investigación y educación en áreas de aplicación estratégica de interés para el Estado de Texas. Estos son biociencia y medicina, exploración energética y modelado de la calidad del aire. La visión del proyecto TIGRE es fomentar la colaboración interdisciplinaria e intercampus, identificar enfoques novedosos para ampliar las asociaciones académicas, gubernamentales y privadas, y convertirse en un modelo competitivo para las oportunidades de financiación externa. El objetivo general de TIGRE es apoyar los intereses de los usuarios locales, universitarios y regionales y ofrecer vías para conectar con proyectos nacionales de Red como Open Science Grid [5] y TeraGrid [6]. Dentro del área de aplicación estratégica de exploración energética, hemos habilitado el enfoque conjunto Kalman Filter (EnKF) [7] para la asimilación de datos en el modelado de reservorios y hemos demostrado la extensibilidad de la aplicación utilizando el entorno TIGRE y el metaprogramador GridWay [8]. En la sección 2 se ofrece una visión general del entorno y las capacidades de TIGRE. La descripción de la aplicación y la necesidad de una metodología EnKF compatible con la cuadrícula figuran en la sección 3. Los detalles de la aplicación y los méritos de nuestro enfoque se examinan en la sección 4. Las conclusiones figuran en la sección 5. Por último, en la sección 6 se documentan las observaciones y la experiencia adquirida. 2. TIGRE ENTORNO El MIddleware TIGRE Grid consiste en un conjunto mínimo de componentes derivados de un subconjunto del Virtual Data Toolkit (VDT) [9] que soporta una variedad de sistemas operativos. El propósito de elegir una pila de software mínima es apoyar las aplicaciones disponibles y simplificar la instalación y distribución de las pilas cliente/servidor en los sitios de TIGRE. Se añadirán componentes adicionales a medida que sean necesarios. El mecanismo de packaging y distribución PacMan [10] se emplea para la instalación y gestión del cliente/servidor TIGRE. El mecanismo de distribución de PacMan implica la recuperación, instalación y a menudo configuración del software empaquetado. Este enfoque permite a los clientes mantener versiones actualizadas y consistentes del software TIGRE. También ayuda a los sitios TIGRE a instalar los componentes necesarios en los recursos distribuidos en los sitios participantes. La pila cliente/servidor TIGRE consiste en una capa de autenticación y autorización, Globus GRAM4-basada en la presentación de trabajos a través de servicios web (las instalaciones de servicios pre-web están disponibles bajo petición). Las herramientas para manejar la generación de proxy de cuadrícula, la transferencia de archivos habilitada para cuadrícula y el inicio de sesión remoto habilitado para cuadrícula son compatibles. A continuación se proporcionan los detalles pertinentes de los servicios y herramientas de TIGRE para la programación y gestión de puestos. 2.1. Autoridad certificadora La infraestructura de seguridad TIGRE incluye una autoridad certificadora (CA) acreditada por la International Grid Trust Federation (IGTF) para emitir X. 509 certificados de usuario y recurso Grid [11]. El Texas Advanced Computing Center (TACC), Universidad de Texas en Austin, es el TIGREs CA compartido. Las instituciones de TIGRE actúan como autoridades de registro (RA) para sus respectivas bases de usuarios locales. Para obtener información actualizada sobre la seguridad de los certificados de usuario y de recursos y sus instrucciones de instalación, véase ref [2]. Los usuarios y hosts de TIGRE son identificados por su distinguido nombre (DN) en su certificado X.509 proporcionado por la CA. Un archivo nativo Grid-mapfile que contiene una lista de DNs autorizados se utiliza para autenticar y autorizar la programación y gestión de trabajos de los usuarios en los recursos del sitio TIGRE. En la Universidad Texas Tech, a los usuarios se les asigna dinámicamente una de las muchas cuentas genéricas. Esto se logra a través del Sistema de Gestión de Usuarios de Red (GUMS) [12]. 2.2. Programación y gestión de empleos El entorno TIGRE apoya la presentación de trabajos basada en GRAM4 a través de servicios web. Los scripts de envío de trabajos se generan usando XML. Los servicios web GRAM traducen los scripts XML en programadores de lotes específicos de grupos de destino como LSF, PBS o SGE. Los protocolos de transferencia de archivos de alto ancho de banda como GridFTP se utilizan para estadificación de archivos dentro y fuera de la máquina de destino. El acceso a hosts remotos para compilar y depurar es sólo a través del servicio GSISSH que requiere autenticación de recursos a través de certificados X.509. La autenticación y autorización de los trabajos de Grid se gestionan mediante la emisión de certificados de Grid a usuarios y anfitriones. Las listas de revocación de certificados (CRL) se actualizan diariamente para mantener altos estándares de seguridad de los servicios de TIGRE Grid. El área de documentación del portal TIGRE [2] proporciona un tutorial de inicio rápido sobre cómo ejecutar trabajos en TIGRE. 2.3. Metascheduler El metascheduler interopera con los programadores de lotes de nivel de cluster (como LSF, PBS) en la gestión general del flujo de trabajo de Grid. En el presente trabajo, hemos empleado el metaprogramador GridWay [8] -un proyecto de incubadora Globus- para programar y gestionar trabajos en TIGRE. El GridWay es un metaprogramador ligero que utiliza plenamente las funcionalidades de Globus. Está diseñado para proporcionar un uso eficiente de los recursos dinámicos de Grid por múltiples usuarios para las infraestructuras de Grid construidas sobre los servicios de Globus. El administrador del sitio TIGRE puede controlar el uso compartido de recursos a través de un potente programador integrado proporcionado por GridWay o ampliando el módulo de programación externa GridWays para proporcionar sus propias políticas de programación. Los usuarios de aplicaciones pueden escribir descripciones de trabajos usando el formato de plantilla de trabajo simple y directo de GridWays (ver Sección 4 para más detalles) o el lenguaje estándar de descripción de la presentación de trabajos (JSDL). Para más detalles sobre la aplicación, véase la sección 4. 2.4. Sistema de Gestión de Servicios al Cliente Un portal TIGRE [2] fue diseñado e implementado para interconectar usuarios y proveedores de recursos. Fue diseñado utilizando GridPort [13] y es mantenido por TACC. El entorno TIGRE es compatible con herramientas de código abierto como el Open Ticket Request System (OTRS) [14] para el servicio de tickets de problemas, y MoinMoin [15] Wiki para la gestión de contenido y conocimiento de TIGRE para educación, extensión y capacitación. Los enlaces para OTRS y Wiki son consumidos por el portal TIGRE [2] - el portal para usuarios y proveedores de recursos. El estado y las cargas de los recursos de TIGRE son monitoreados por el servicio de Repositorio de Información de Puertos Grid (GPIR) del kit de herramientas GridPort [13] que interactúa con el servicio local de monitoreo de carga de clústeres como Ganglia. El GPIR utiliza trabajos de cron en cada recurso para reunir características específicas de los recursos del sitio, tales como trabajos que se ejecutan, en cola y esperando la asignación de recursos. 3. APLICACIÓN ENSEMBLE KALMAN FILTER El objetivo principal de las simulaciones de yacimientos de hidrocarburos es predecir el comportamiento de la producción de yacimientos de petróleo y gas (denominados en lo sucesivo campo) para su desarrollo y gestión óptima. En el modelado de yacimientos, el campo se divide en varios modelos geológicos, como se muestra en la Figura 1. Para una previsión precisa del rendimiento del campo, es necesario conciliar varios modelos geológicos con la respuesta dinámica del campo a través de la coincidencia histórica [16-20]. Gráfico 1 Vista transversal del Campo. Las capas verticales corresponden a diferentes modelos geológicos y los clavos son pozos de aceite cuya información histórica se utilizará para predecir el comportamiento de la producción. (Figura Ref:http://faculty.smu.edu/zchen/research.html). El EnKF es un método de Monte Carlo que trabaja con un conjunto de modelos de embalses. Este método utiliza covarianzas cruzadas [21] entre las mediciones de campo y los parámetros del modelo de reservorio (derivados de varios modelos) para estimar las incertidumbres de predicción. Los parámetros del modelo geológico en el conjunto se actualizan secuencialmente con el objetivo de minimizar las incertidumbres de predicción. La respuesta histórica de la producción del campo durante más de 50 años se utiliza en estas simulaciones. La principal ventaja de EnKF es que puede vincularse fácilmente a cualquier simulador de depósito, y puede asimilar los últimos datos de producción sin necesidad de volver a ejecutar el simulador desde las condiciones iniciales. Investigadores en Texas son grandes suscriptores del paquete de Schlumberger ECLIPSE [22] para simulaciones de reservorios. En el modelado del embalse, cada modelo geológico comprueba una licencia ECLIPSE. La duración de la simulación de la metodología EnKF depende del número de modelos geológicos utilizados, el número de licencias ECLIPSE disponibles, la historia de producción del campo y las incertidumbres propagadas en la correspondencia de la historia. El flujo de trabajo general de EnKF se muestra en la Figura 2. Gráfico 2 Ensemble Kaman Filter Data Assimulation Workflow. Cada sitio tiene licencias L. En START, el proceso maestro/control (programa principal EnKF) lee el archivo de configuración de simulación para el número (N) de modelos y archivos de entrada específicos del modelo. A continuación, N directorios de trabajo se crean para almacenar los archivos de salida. Al final de la iteración, el proceso maestro/control recoge los archivos de salida de los modelos N y las crosscovarianzas de los procesos posteriores [21] para estimar las incertidumbres de predicción. Esta información se utilizará para actualizar modelos (o archivos de entrada) para la siguiente iteración. La simulación continúa hasta agotar las historias de producción. La simulación típica de EnKF con N=50 y historias de campo de 50-60 años, en pasos de tiempo que van de tres meses a un año, toma unas tres semanas en un entorno de computación en serie. En el entorno informático paralelo, no hay comunicación interproceso entre los modelos geológicos en el conjunto. Sin embargo, al final de cada paso del tiempo de simulación, los archivos de salida específicos del modelo deben ser recogidos para analizar covarianzas cruzadas [21] y para preparar el siguiente conjunto de archivos de entrada. Por lo tanto, el modelo maestro-esclavo en el entorno de mensajepassing (MPI) es un paradigma adecuado. En este enfoque, los modelos geológicos son tratados como esclavos y se distribuyen entre los procesadores disponibles. El master Cluster o (TIGRE/GridWay) START Read Configuration File Create N Working Directories Create N Input files Model l Model 2 Model N.. . ECLIPSE in situ Un ECLIPSE in situ B ECLIPSE in situ Z Collect N Model Outputs, Post-process Output files FIN. . . proceso recoge archivos de salida específicos del modelo, analiza y prepara el siguiente conjunto de archivos de entrada para la simulación. Dado que cada modelo geológico comprueba una licencia ECLIPSE, la paralelización de la simulación depende del número de licencias disponibles. Cuando el número de licencias disponible es menor que el número de modelos en el conjunto, uno o más de los nodos del grupo MPI tienen que manejar más de un modelo en serie y, por lo tanto, se tarda más tiempo en completar la simulación. Un Departamento de Ingeniería Petrolera generalmente adquiere 10-15 licencias ECLIPSE, mientras que al menos diez veces más número de licencias sería necesario para simulaciones estándar de la industria. El número de licencias puede incrementarse con la participación de varios departamentos de ingeniería petrolera que apoyan el paquete ECLIPSE. Dado que MPI no se escala muy bien para aplicaciones que involucran clústeres de computación remotos, y para evitar los problemas del firewall con servidores de licencias en todos los dominios administrativos, parece necesario activar el flujo de trabajo de EnKF. Con esta motivación, hemos implementado el flujo de trabajo EnKF habilitado para Grid para el entorno TIGRE y hemos demostrado la paralelización de la aplicación a través de TIGRE usando el metascheduler GridWay. En la siguiente sección figuran más detalles al respecto. 4. DETALLES DE APLICACION Para habilitar Grid-enable el enfoque EnKF, hemos eliminado el código MPI para el procesamiento paralelo y reemplazado por trabajos de N monoprocesador (o sub-trabajos) donde, N es el número de modelos geológicos en el conjunto. Estos sub-trabajos específicos de modelos se distribuyeron a través de sitios TIGRE que soportan el paquete ECLIPSE utilizando el metaprogramador GridWay [8]. Para cada sub-trabajo, hemos construido una plantilla de trabajo GridWay que especifica los archivos ejecutables, de entrada y salida, y los requisitos de recursos. Dado que los recursos de cálculo de TIGRE no se espera que cambien con frecuencia, hemos utilizado la política de descubrimiento de recursos estáticos para GridWay y los sub-trabajos fueron programados dinámicamente a través de los recursos de TIGRE usando GridWay. La Figura 3 representa el archivo de plantilla de subtrabajo para el metaprogramador GridWay. Gráfico 3 Plantilla de subtrabajo GridWay En la Figura 3, REQUISITOS bandera se establece para elegir los recursos que satisfacen los requisitos de la aplicación. En el caso de la aplicación EnKF, por ejemplo, necesitamos recursos que apoyen el paquete ECLIPSE. ARGUMENTS flag especifica el modelo en el conjunto que invocará ECLIPSE en un sitio remoto. INPUT_FILES es preparado por el programa principal de EnKF (o proceso maestro/control) y es transferido por GridWay al sitio remoto donde está desatendido y está preparado para su ejecución. Finalmente, OUTPUT_FILES especifica el nombre y la ubicación donde se escribirán los archivos de salida. Las características de la línea de comandos de GridWay se utilizaron para recopilar y procesar las salidas específicas del modelo para preparar un nuevo conjunto de archivos de entrada. Este paso imita la sincronización del proceso MPI en el modelo maestro-esclavo. Al final de cada iteración, los recursos computacionales y las licencias se devuelven al grupo. La Tabla 1 muestra los sub-trabajos en TIGRE Grid via GridWay usando el comando gwps y para mayor claridad, sólo se mostraron las columnas seleccionadas. USUARIO JID DM EM NOMBRE HOST pingluo 88 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 89 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 90 wrap actv enkf.jt minigar.hp Programación de trabajo a través de TIGRE usando GridWay Metascheduler. DM: Estado de envío, EM: Estado de ejecución, JID es el id de trabajo y HOST corresponde al cluster específico del sitio y su planificador de lotes local. Cuando un trabajo es enviado a GridWay, pasará por una serie de estados de envío (DM) y ejecución (EM). Para DM, los estados incluyen pend(ing), prol(og), wrap(per), epil(og), y hecho. DM=prol significa que el trabajo ha sido programado a un recurso y el directorio de trabajo remoto está en preparación. DM=warp implica que GridWay está ejecutando el envoltorio que a su vez ejecuta la aplicación. DM=epil implica que el trabajo ha terminado de ejecutarse en el sitio remoto y los resultados se están transfiriendo al servidor GridWay. Del mismo modo, cuando EM=pend implica que el trabajo está esperando en la cola para el recurso y el trabajo se está ejecutando cuando EM=actv. Para ver la lista completa de las banderas de mensajes y sus descripciones, consulte la documentación en ref [8]. Hemos demostrado las ejecuciones de EnKF habilitadas para Grid usando GridWay para entorno TIGRE. Los trabajos son tan elegidos que el tiempo de ejecución no supera más de media hora. La simulación incluyó hasta 20 trabajos entre sitios de A&M y TTU con TTU cumpliendo 10 licencias. Para obtener información sobre los recursos, véase el cuadro I. Una de las principales ventajas de la simulación EnKF habilitada por Grid es que tanto los recursos como las licencias se devuelven al grupo al final de cada paso del tiempo de simulación a diferencia del caso de la implementación de MPI donde las licencias y nodos están bloqueados hasta la finalización de la simulación completa. Sin embargo, el hecho de que cada sub-trabajo se programe independientemente a través de GridWay podría posiblemente incurrir en otro retraso de tiempo causado por esperar en la cola para la ejecución en cada paso del tiempo de simulación. Tales retrasos no se esperan EXECUTABLE=runFORWARD NECESIDADES=HOSTNAME=cosmos.tamu.edu  HOSTNAME=antaeus.hpcc.ttu.edu  HOSTNAME=minigar.hpcc.ttu.edu  ARGUMENTOS=001 INPUT_FILES=001.in.tar OUTPUT_FI Hay dos escenarios principales para comparar los enfoques de computación de red y clúster. Escenario I: El cúmulo está muy cargado. El tiempo promedio de espera concebido del trabajo que solicita un gran número de CPUs es generalmente más largo que el tiempo de espera de los trabajos que solicitan una sola CPU. Por lo tanto, el tiempo de espera general podría ser más corto en el enfoque Grid que solicita una sola CPU para cada sub-trabajo muchas veces en comparación con la implementación MPI que requiere un gran número de CPUs en un solo momento. Es evidente que la programación de la cuadrícula es beneficiosa especialmente cuando el clúster está fuertemente cargado y el número solicitado de CPUs para el trabajo del MPI no está fácilmente disponible. Escenario II: El clúster está relativamente menos cargado o disponible en gran medida. Parece que la implementación del MPI es favorable en comparación con la programación de la Rejilla. Sin embargo, la paralelización de la aplicación EnKF depende del número de licencias ECLIPSE e idealmente, el número de licencias debe ser igual al número de modelos en el conjunto. Por lo tanto, si una sola institución no tiene suficiente número de licencias, la disponibilidad del clúster no ayuda tanto como se espera. Dado que el entorno colaborativo, como TIGRE, puede abordar tanto los requisitos de computación como los de recursos de software para la aplicación EnKF, el enfoque compatible con Grid sigue siendo ventajoso sobre la implementación MPI convencional en cualquiera de los escenarios anteriores. 5. CONCLUSIONES Y FUTURO TRABAJO TIGRE es un proyecto de desarrollo de la red de educación superior y su propósito es mantener y ampliar las oportunidades de investigación y educación a través de Texas. Dentro del área de aplicación de exploración energética, hemos habilitado la implementación MPI del conjunto Kalman metodología de asimilación de datos de filtro para la caracterización de reservorios. Esta tarea se llevó a cabo eliminando el código MPI para el procesamiento paralelo y reemplazando con trabajos de un solo procesador uno para cada modelo geológico en el conjunto. Estos trabajos de un solo procesador fueron programados a través de TIGRE a través de GridWay metascheduler. Hemos demostrado que mediante la puesta en común de licencias a través de sitios TIGRE, más modelos geológicos pueden ser manejados en paralelo y por lo tanto concebiblemente mejor precisión de simulación. Este enfoque tiene varias ventajas sobre la implementación de MPI, especialmente cuando un clúster específico del sitio está muy cargado y/o las licencias de número requeridas para la simulación son más que las disponibles en un solo sitio. Hacia el trabajo futuro, sería interesante comparar el tiempo de ejecución entre MPI y las implementaciones de Grid para la aplicación EnKF. Este esfuerzo podría arrojar luz sobre la calidad del servicio (QoS) de los entornos Grid en comparación con la computación de clústers. Otro aspecto de interés en un futuro próximo sería la gestión de recursos de computación y licencia para abordar la gestión de la relación trabajo (o procesador)-licencia. 6. OBSERVACIONES Y MENOS APRENDIZADOS Los esfuerzos que facilitan la red para la aplicación EnKF han proporcionado amplias oportunidades para reunir información sobre la visibilidad y la promesa de los entornos de computación de Grid para el desarrollo y soporte de aplicaciones. Los principales problemas son la seguridad de los datos estándar de la industria y la CV comparable a la computación de clústers. Dado que la investigación de modelado de reservorios involucra datos propietarios del campo, tuvimos que invertir esfuerzos sustanciales inicialmente en educar a los investigadores de aplicaciones sobre la capacidad de los servicios de Grid para apoyar la seguridad de datos estándar de la industria a través de acceso basado en roles y privilegios utilizando el estándar X.509. Con respecto a QoS, los investigadores de aplicaciones esperan niveles de QoS con entornos de cuadrícula. Además, hay una curva de aprendizaje pronunciada en la computación de cuadrícula en comparación con la computación de clúster convencional. Dado que la computación de cuadrícula sigue siendo una tecnología emergente, y abarca varios ámbitos administrativos, la computación de cuadrícula sigue siendo prematura, especialmente en términos del nivel de QoS, aunque ofrece mejores normas de seguridad de los datos en comparación con los grupos de productos básicos. Es nuestra observación que los programas de capacitación y divulgación que comparan y contrastan los entornos de computación de red y clúster serían un enfoque adecuado para mejorar la participación de los usuarios en la computación de red. Este enfoque también ayuda a los usuarios a emparejar sus aplicaciones y habilidades que las cuadrículas pueden ofrecer. En resumen, nuestros esfuerzos a través de TIGRE en la metodología de asimilación de datos de la EnKF demostraron una promesa sustancial en la contratación de investigadores de Ingeniería Petrolera a través de colaboraciones entre campus. Se están realizando esfuerzos para lograr la participación de más escuelas en este esfuerzo. Estos esfuerzos pueden resultar en un aumento de la investigación colaborativa, oportunidades educativas y desarrollo de la fuerza laboral a través de programas de investigación de posgrado/facultad en instituciones TIGRE. 7. AGRADECIMIENTOS Los autores reconocen al Estado de Texas por apoyar el proyecto TIGRE a través del Fondo Empresarial de Texas, y a las Instituciones TIGRE por proporcionar el mecanismo, en el que también participan los autores (Ravi Vadapalli, Taesung Kim y Ping Luo). Los autores agradecen a los investigadores de aplicaciones Prof. Akhil Datta-Gupta de Texas A&M University y Prof. Lloyd Heinze de Texas Tech University por sus discusiones e interés en explotar el entorno TIGRE para ampliar las oportunidades en investigación y desarrollo. 8. REFERENCIAS [1] Foster, I. y Kesselman, C. (eds.) 2004. The Grid: Blueprint for a new computing infraestructura (The Elsevier series in Grid computing) [2] Portal TIGRE: http://tigreportal.hipcat.net [3] Vadapalli, R. Sill, A., Dooley, R., Murray, M., Luo, P., Kim, T., Huang, M., Thyagaraja, K., y Chaffin, Demostración del entorno TIGRE para aplicaciones de cuadrícula habilitadas/adecuadas. 8o IEEE/ACM Int. Conf. on Grid Computing, 19-21 de septiembre, Austin [4] The High Performance Computing cross Texas Consortium http://www.hipcat.net [5] Pordes, R. Petravick, D. Kramer, B. Olson, D. Livny, M. Roy, A. Avery, P. Blackburn, K. Wenaus, T. Würthwein, F. Foster, I. Gar The Open Science Grid, J. Phys Conf Series http://www.iop.org/EJ/abstract/1742-6596/78/1/012057 y http://www.opensciencegrid.org [6] Reed, D.A. 2003. Rejilla, el Teragrid y más allá, Ordenador, vol. 30, no. 1 y http://www.teragrid.org [7] Evensen, G. 2006. Asimilación de datos: El conjunto Kalman Filter, Springer [8] Herrera, J. Huedo, E. Montero, R. S. y Llorente, I. M. 2005. Programación Científica, vol 12, No. 4. pp 317-331 [9] Avery, P. and Foster, I. 2001. El proyecto GriPhyN: Hacia redes virtuales de datos a petaescala, informe técnico GriPhyN-200115 y http://vdt.cs.wisc.edu [10] La guía de documentación e instalación de PacMan http://physics.bu.edu/pacman/htmls [11] Caskey, P. Murray, M. Perez, J. y Sill, A. 2007. Estudios de casos en la gestión de identificación para organizaciones virtuales, EDUCOUSO Southwest Reg. Conf., 21-23 febrero, Austin, TX. http://www.educause.edu/ir/library/pdf/SWR07058.pdf [12] El Sistema de Gestión de Usuarios de Grid (GUMS) https://www.racf.bnl.gov/Facility/GUMS/index.html [13] Thomas, M. y Boisseau, J. 2003. Construyendo portales de computación de cuadrículas: El kit de herramientas para el portal de cuadrículas NPACI, Grid computing: haciendo realidad la infraestructura global, Capítulo 28, Berman, F. Fox, G. Thomas, M. Boisseau, J. y Hey, T. (eds), John Wiley and Sons, Ltd, Chichester [14] Open Ticket Request System http:// 1999. Integración de datos dinámicos en modelos de depósito de alta resolución utilizando coeficientes de sensibilidad basados en la racionalización, Society of Petroleum Engineers (SPE), 4 (4). [17] Emanuel, A. S. y Milliken, W. J. 1998. Historia que combina modelos de diferencias finitas con racionalizaciones 3D, SPE 49000, Proc de la Conf Técnica Anual y Exposición, 2730 de septiembre, Nueva Orleans, LA. [18] Nævdal, G. Johnsen, L.M. Aanonsen, S.I. y Vefring, E.H. 2003. Monitorización de embalses y actualización continua de modelos utilizando Ensemble Kalman Filter, SPE 84372, Proc del Conf Técnico Anual y Exposición, Oct 5-8, Denver, CO. [19] Jafarpour B. y McLaughlin, D.B. 2007. Historia que coincide con un conjunto de filtro Kalman y parametrización discreta de coseno, SPE 108761, Proc de la Conf Técnica Anual y Exposición, 11-14 de noviembre, Anaheim, CA [20] Li, G. y Reynolds, A. C. 2007. Un conjunto iterativo Kalman filtro para la asimilación de datos, SPE 109808, Proc de la SPE Conf y Exposición Técnica Anual, 11-14 de noviembre, Anaheim, CA [21] Arroyo-Negrete, E. Devagowda, D. Datta-Gupta, A. 2006. Simplificar el conjunto asistido Kalman filtro para la actualización rápida y continua del modelo de depósito. Proc de la Int. Oil & Gas Conf and Exhibition, SPE 104255, Dec 5-7, China [22] ECLIPSE Reservoir Engineering Software http://www.slb.com/content/services/software/reseng/index.a sp ",
            "error": []
        },
        "grid-enabling": {
            "translated_key": [],
            "translated_annotated_text": "Demostración del conjunto de datos de Kalman Assimulation Method for Reservoir Caracterisation Ravi Vadapalli Centro de computación de alto rendimiento Texas Tech University Lubbock, TX 79409 001-806-742-4350 Ravi.Vadapalli@ttu.edu Ajitabh Kumar Department of Petroleum Engineering Texas A&M University College Station, En este enfoque, se utiliza un conjunto de modelos geológicos y datos de producción de yacimientos de petróleo para predecir la respuesta dinámica de los pozos de petróleo. El software Schlumberger ECLIPSE se utiliza para estas simulaciones. Puesto que los modelos en el conjunto no se comunican, la implementación de mensaje-passing es una buena opción. Cada modelo comprueba una licencia ECLIPSE y, por lo tanto, la paralelización de las simulaciones de reservorio depende de las licencias de número disponibles. Hemos habilitado Grid para el conjunto Kalman metodología de asimilación de datos de filtro para el entorno de computación TIGRE Grid. Al poner en común las licencias y los recursos informáticos en todas las instituciones colaboradoras utilizando el metaprogramador GridWay y el entorno TIGRE, la precisión computacional puede aumentarse al tiempo que se reduce el tiempo de ejecución de la simulación. En este artículo, proporcionamos un relato de nuestros esfuerzos en Gridenabilizar el conjunto Kalman Filter metodología de asimilación de datos. Se examinarán los posibles beneficios de este enfoque, las observaciones y la experiencia adquirida. Categorías y Descriptores sujetos C 2.4 [Sistemas distribuidos]: Aplicaciones distribuidas Términos generales Algoritmos, Diseño, Rendimiento 1. INTRODUCCIÓN La computación de cuadrícula [1] es un paradigma de computación colaborativa emergente para ampliar las capacidades específicas de computación de alto rendimiento (HPC) mucho más allá de los recursos locales. Su importancia se deriva del hecho de que la investigación innovadora en áreas de aplicación estratégicas como la biociencia y la medicina, la exploración de energía y el modelado ambiental involucran componentes interdisciplinarios fuertes y a menudo requieren colaboraciones intercampus y capacidades computacionales más allá de las limitaciones institucionales. The Texas Internet Grid for Research and Education (TIGRE) [2,3] es un proyecto de desarrollo de infraestructuras cibernéticas financiado por el estado, llevado a cabo por cinco grandes sistemas universitarios (Rice, A&M, TTU, UH y UT Austin), llamados colectivamente Instituciones TIGRE. El propósito de TIGRE es crear una red de educación superior para sostener y ampliar las oportunidades de investigación y educación en Texas. TIGRE es un proyecto del consorcio de computación de alto rendimiento en Texas (HiPCAT) [4]. El objetivo de HiPCAT es apoyar tecnologías computacionales avanzadas para mejorar la investigación, el desarrollo y las actividades educativas. El objetivo principal de TIGRE es diseñar e implementar middleware Grid de última generación que permita la integración de sistemas de computación, sistemas de almacenamiento y bases de datos, laboratorios de visualización y pantallas, e incluso instrumentos y sensores en Texas. El objetivo secundario es demostrar las capacidades de TIGRE para mejorar las oportunidades de investigación y educación en áreas de aplicación estratégica de interés para el Estado de Texas. Estos son biociencia y medicina, exploración energética y modelado de la calidad del aire. La visión del proyecto TIGRE es fomentar la colaboración interdisciplinaria e intercampus, identificar enfoques novedosos para ampliar las asociaciones académicas, gubernamentales y privadas, y convertirse en un modelo competitivo para las oportunidades de financiación externa. El objetivo general de TIGRE es apoyar los intereses de los usuarios locales, universitarios y regionales y ofrecer vías para conectar con proyectos nacionales de Red como Open Science Grid [5] y TeraGrid [6]. Dentro del área de aplicación estratégica de exploración energética, hemos habilitado el enfoque conjunto Kalman Filter (EnKF) [7] para la asimilación de datos en el modelado de reservorios y hemos demostrado la extensibilidad de la aplicación utilizando el entorno TIGRE y el metaprogramador GridWay [8]. En la sección 2 se ofrece una visión general del entorno y las capacidades de TIGRE. La descripción de la aplicación y la necesidad de una metodología EnKF compatible con la cuadrícula figuran en la sección 3. Los detalles de la aplicación y los méritos de nuestro enfoque se examinan en la sección 4. Las conclusiones figuran en la sección 5. Por último, en la sección 6 se documentan las observaciones y la experiencia adquirida. 2. TIGRE ENTORNO El MIddleware TIGRE Grid consiste en un conjunto mínimo de componentes derivados de un subconjunto del Virtual Data Toolkit (VDT) [9] que soporta una variedad de sistemas operativos. El propósito de elegir una pila de software mínima es apoyar las aplicaciones disponibles y simplificar la instalación y distribución de las pilas cliente/servidor en los sitios de TIGRE. Se añadirán componentes adicionales a medida que sean necesarios. El mecanismo de packaging y distribución PacMan [10] se emplea para la instalación y gestión del cliente/servidor TIGRE. El mecanismo de distribución de PacMan implica la recuperación, instalación y a menudo configuración del software empaquetado. Este enfoque permite a los clientes mantener versiones actualizadas y consistentes del software TIGRE. También ayuda a los sitios TIGRE a instalar los componentes necesarios en los recursos distribuidos en los sitios participantes. La pila cliente/servidor TIGRE consiste en una capa de autenticación y autorización, Globus GRAM4-basada en la presentación de trabajos a través de servicios web (las instalaciones de servicios pre-web están disponibles bajo petición). Las herramientas para manejar la generación de proxy de cuadrícula, la transferencia de archivos habilitada para cuadrícula y el inicio de sesión remoto habilitado para cuadrícula son compatibles. A continuación se proporcionan los detalles pertinentes de los servicios y herramientas de TIGRE para la programación y gestión de puestos. 2.1. Autoridad certificadora La infraestructura de seguridad TIGRE incluye una autoridad certificadora (CA) acreditada por la International Grid Trust Federation (IGTF) para emitir X. 509 certificados de usuario y recurso Grid [11]. El Texas Advanced Computing Center (TACC), Universidad de Texas en Austin, es el TIGREs CA compartido. Las instituciones de TIGRE actúan como autoridades de registro (RA) para sus respectivas bases de usuarios locales. Para obtener información actualizada sobre la seguridad de los certificados de usuario y de recursos y sus instrucciones de instalación, véase ref [2]. Los usuarios y hosts de TIGRE son identificados por su distinguido nombre (DN) en su certificado X.509 proporcionado por la CA. Un archivo nativo Grid-mapfile que contiene una lista de DNs autorizados se utiliza para autenticar y autorizar la programación y gestión de trabajos de los usuarios en los recursos del sitio TIGRE. En la Universidad Texas Tech, a los usuarios se les asigna dinámicamente una de las muchas cuentas genéricas. Esto se logra a través del Sistema de Gestión de Usuarios de Red (GUMS) [12]. 2.2. Programación y gestión de empleos El entorno TIGRE apoya la presentación de trabajos basada en GRAM4 a través de servicios web. Los scripts de envío de trabajos se generan usando XML. Los servicios web GRAM traducen los scripts XML en programadores de lotes específicos de grupos de destino como LSF, PBS o SGE. Los protocolos de transferencia de archivos de alto ancho de banda como GridFTP se utilizan para estadificación de archivos dentro y fuera de la máquina de destino. El acceso a hosts remotos para compilar y depurar es sólo a través del servicio GSISSH que requiere autenticación de recursos a través de certificados X.509. La autenticación y autorización de los trabajos de Grid se gestionan mediante la emisión de certificados de Grid a usuarios y anfitriones. Las listas de revocación de certificados (CRL) se actualizan diariamente para mantener altos estándares de seguridad de los servicios de TIGRE Grid. El área de documentación del portal TIGRE [2] proporciona un tutorial de inicio rápido sobre cómo ejecutar trabajos en TIGRE. 2.3. Metascheduler El metascheduler interopera con los programadores de lotes de nivel de cluster (como LSF, PBS) en la gestión general del flujo de trabajo de Grid. En el presente trabajo, hemos empleado el metaprogramador GridWay [8] -un proyecto de incubadora Globus- para programar y gestionar trabajos en TIGRE. El GridWay es un metaprogramador ligero que utiliza plenamente las funcionalidades de Globus. Está diseñado para proporcionar un uso eficiente de los recursos dinámicos de Grid por múltiples usuarios para las infraestructuras de Grid construidas sobre los servicios de Globus. El administrador del sitio TIGRE puede controlar el uso compartido de recursos a través de un potente programador integrado proporcionado por GridWay o ampliando el módulo de programación externa GridWays para proporcionar sus propias políticas de programación. Los usuarios de aplicaciones pueden escribir descripciones de trabajos usando el formato de plantilla de trabajo simple y directo de GridWays (ver Sección 4 para más detalles) o el lenguaje estándar de descripción de la presentación de trabajos (JSDL). Para más detalles sobre la aplicación, véase la sección 4. 2.4. Sistema de Gestión de Servicios al Cliente Un portal TIGRE [2] fue diseñado e implementado para interconectar usuarios y proveedores de recursos. Fue diseñado utilizando GridPort [13] y es mantenido por TACC. El entorno TIGRE es compatible con herramientas de código abierto como el Open Ticket Request System (OTRS) [14] para el servicio de tickets de problemas, y MoinMoin [15] Wiki para la gestión de contenido y conocimiento de TIGRE para educación, extensión y capacitación. Los enlaces para OTRS y Wiki son consumidos por el portal TIGRE [2] - el portal para usuarios y proveedores de recursos. El estado y las cargas de los recursos de TIGRE son monitoreados por el servicio de Repositorio de Información de Puertos Grid (GPIR) del kit de herramientas GridPort [13] que interactúa con el servicio local de monitoreo de carga de clústeres como Ganglia. El GPIR utiliza trabajos de cron en cada recurso para reunir características específicas de los recursos del sitio, tales como trabajos que se ejecutan, en cola y esperando la asignación de recursos. 3. APLICACIÓN ENSEMBLE KALMAN FILTER El objetivo principal de las simulaciones de yacimientos de hidrocarburos es predecir el comportamiento de la producción de yacimientos de petróleo y gas (denominados en lo sucesivo campo) para su desarrollo y gestión óptima. En el modelado de yacimientos, el campo se divide en varios modelos geológicos, como se muestra en la Figura 1. Para una previsión precisa del rendimiento del campo, es necesario conciliar varios modelos geológicos con la respuesta dinámica del campo a través de la coincidencia histórica [16-20]. Gráfico 1 Vista transversal del Campo. Las capas verticales corresponden a diferentes modelos geológicos y los clavos son pozos de aceite cuya información histórica se utilizará para predecir el comportamiento de la producción. (Figura Ref:http://faculty.smu.edu/zchen/research.html). El EnKF es un método de Monte Carlo que trabaja con un conjunto de modelos de embalses. Este método utiliza covarianzas cruzadas [21] entre las mediciones de campo y los parámetros del modelo de reservorio (derivados de varios modelos) para estimar las incertidumbres de predicción. Los parámetros del modelo geológico en el conjunto se actualizan secuencialmente con el objetivo de minimizar las incertidumbres de predicción. La respuesta histórica de la producción del campo durante más de 50 años se utiliza en estas simulaciones. La principal ventaja de EnKF es que puede vincularse fácilmente a cualquier simulador de depósito, y puede asimilar los últimos datos de producción sin necesidad de volver a ejecutar el simulador desde las condiciones iniciales. Investigadores en Texas son grandes suscriptores del paquete de Schlumberger ECLIPSE [22] para simulaciones de reservorios. En el modelado del embalse, cada modelo geológico comprueba una licencia ECLIPSE. La duración de la simulación de la metodología EnKF depende del número de modelos geológicos utilizados, el número de licencias ECLIPSE disponibles, la historia de producción del campo y las incertidumbres propagadas en la correspondencia de la historia. El flujo de trabajo general de EnKF se muestra en la Figura 2. Gráfico 2 Ensemble Kaman Filter Data Assimulation Workflow. Cada sitio tiene licencias L. En START, el proceso maestro/control (programa principal EnKF) lee el archivo de configuración de simulación para el número (N) de modelos y archivos de entrada específicos del modelo. A continuación, N directorios de trabajo se crean para almacenar los archivos de salida. Al final de la iteración, el proceso maestro/control recoge los archivos de salida de los modelos N y las crosscovarianzas de los procesos posteriores [21] para estimar las incertidumbres de predicción. Esta información se utilizará para actualizar modelos (o archivos de entrada) para la siguiente iteración. La simulación continúa hasta agotar las historias de producción. La simulación típica de EnKF con N=50 y historias de campo de 50-60 años, en pasos de tiempo que van de tres meses a un año, toma unas tres semanas en un entorno de computación en serie. En el entorno informático paralelo, no hay comunicación interproceso entre los modelos geológicos en el conjunto. Sin embargo, al final de cada paso del tiempo de simulación, los archivos de salida específicos del modelo deben ser recogidos para analizar covarianzas cruzadas [21] y para preparar el siguiente conjunto de archivos de entrada. Por lo tanto, el modelo maestro-esclavo en el entorno de mensajepassing (MPI) es un paradigma adecuado. En este enfoque, los modelos geológicos son tratados como esclavos y se distribuyen entre los procesadores disponibles. El master Cluster o (TIGRE/GridWay) START Read Configuration File Create N Working Directories Create N Input files Model l Model 2 Model N.. . ECLIPSE in situ Un ECLIPSE in situ B ECLIPSE in situ Z Collect N Model Outputs, Post-process Output files FIN. . . proceso recoge archivos de salida específicos del modelo, analiza y prepara el siguiente conjunto de archivos de entrada para la simulación. Dado que cada modelo geológico comprueba una licencia ECLIPSE, la paralelización de la simulación depende del número de licencias disponibles. Cuando el número de licencias disponible es menor que el número de modelos en el conjunto, uno o más de los nodos del grupo MPI tienen que manejar más de un modelo en serie y, por lo tanto, se tarda más tiempo en completar la simulación. Un Departamento de Ingeniería Petrolera generalmente adquiere 10-15 licencias ECLIPSE, mientras que al menos diez veces más número de licencias sería necesario para simulaciones estándar de la industria. El número de licencias puede incrementarse con la participación de varios departamentos de ingeniería petrolera que apoyan el paquete ECLIPSE. Dado que MPI no se escala muy bien para aplicaciones que involucran clústeres de computación remotos, y para evitar los problemas del firewall con servidores de licencias en todos los dominios administrativos, parece necesario activar el flujo de trabajo de EnKF. Con esta motivación, hemos implementado el flujo de trabajo EnKF habilitado para Grid para el entorno TIGRE y hemos demostrado la paralelización de la aplicación a través de TIGRE usando el metascheduler GridWay. En la siguiente sección figuran más detalles al respecto. 4. DETALLES DE APLICACION Para habilitar Grid-enable el enfoque EnKF, hemos eliminado el código MPI para el procesamiento paralelo y reemplazado por trabajos de N monoprocesador (o sub-trabajos) donde, N es el número de modelos geológicos en el conjunto. Estos sub-trabajos específicos de modelos se distribuyeron a través de sitios TIGRE que soportan el paquete ECLIPSE utilizando el metaprogramador GridWay [8]. Para cada sub-trabajo, hemos construido una plantilla de trabajo GridWay que especifica los archivos ejecutables, de entrada y salida, y los requisitos de recursos. Dado que los recursos de cálculo de TIGRE no se espera que cambien con frecuencia, hemos utilizado la política de descubrimiento de recursos estáticos para GridWay y los sub-trabajos fueron programados dinámicamente a través de los recursos de TIGRE usando GridWay. La Figura 3 representa el archivo de plantilla de subtrabajo para el metaprogramador GridWay. Gráfico 3 Plantilla de subtrabajo GridWay En la Figura 3, REQUISITOS bandera se establece para elegir los recursos que satisfacen los requisitos de la aplicación. En el caso de la aplicación EnKF, por ejemplo, necesitamos recursos que apoyen el paquete ECLIPSE. ARGUMENTS flag especifica el modelo en el conjunto que invocará ECLIPSE en un sitio remoto. INPUT_FILES es preparado por el programa principal de EnKF (o proceso maestro/control) y es transferido por GridWay al sitio remoto donde está desatendido y está preparado para su ejecución. Finalmente, OUTPUT_FILES especifica el nombre y la ubicación donde se escribirán los archivos de salida. Las características de la línea de comandos de GridWay se utilizaron para recopilar y procesar las salidas específicas del modelo para preparar un nuevo conjunto de archivos de entrada. Este paso imita la sincronización del proceso MPI en el modelo maestro-esclavo. Al final de cada iteración, los recursos computacionales y las licencias se devuelven al grupo. La Tabla 1 muestra los sub-trabajos en TIGRE Grid via GridWay usando el comando gwps y para mayor claridad, sólo se mostraron las columnas seleccionadas. USUARIO JID DM EM NOMBRE HOST pingluo 88 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 89 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 90 wrap actv enkf.jt minigar.hp Programación de trabajo a través de TIGRE usando GridWay Metascheduler. DM: Estado de envío, EM: Estado de ejecución, JID es el id de trabajo y HOST corresponde al cluster específico del sitio y su planificador de lotes local. Cuando un trabajo es enviado a GridWay, pasará por una serie de estados de envío (DM) y ejecución (EM). Para DM, los estados incluyen pend(ing), prol(og), wrap(per), epil(og), y hecho. DM=prol significa que el trabajo ha sido programado a un recurso y el directorio de trabajo remoto está en preparación. DM=warp implica que GridWay está ejecutando el envoltorio que a su vez ejecuta la aplicación. DM=epil implica que el trabajo ha terminado de ejecutarse en el sitio remoto y los resultados se están transfiriendo al servidor GridWay. Del mismo modo, cuando EM=pend implica que el trabajo está esperando en la cola para el recurso y el trabajo se está ejecutando cuando EM=actv. Para ver la lista completa de las banderas de mensajes y sus descripciones, consulte la documentación en ref [8]. Hemos demostrado las ejecuciones de EnKF habilitadas para Grid usando GridWay para entorno TIGRE. Los trabajos son tan elegidos que el tiempo de ejecución no supera más de media hora. La simulación incluyó hasta 20 trabajos entre sitios de A&M y TTU con TTU cumpliendo 10 licencias. Para obtener información sobre los recursos, véase el cuadro I. Una de las principales ventajas de la simulación EnKF habilitada por Grid es que tanto los recursos como las licencias se devuelven al grupo al final de cada paso del tiempo de simulación a diferencia del caso de la implementación de MPI donde las licencias y nodos están bloqueados hasta la finalización de la simulación completa. Sin embargo, el hecho de que cada sub-trabajo se programe independientemente a través de GridWay podría posiblemente incurrir en otro retraso de tiempo causado por esperar en la cola para la ejecución en cada paso del tiempo de simulación. Tales retrasos no se esperan EXECUTABLE=runFORWARD NECESIDADES=HOSTNAME=cosmos.tamu.edu  HOSTNAME=antaeus.hpcc.ttu.edu  HOSTNAME=minigar.hpcc.ttu.edu  ARGUMENTOS=001 INPUT_FILES=001.in.tar OUTPUT_FI Hay dos escenarios principales para comparar los enfoques de computación de red y clúster. Escenario I: El cúmulo está muy cargado. El tiempo promedio de espera concebido del trabajo que solicita un gran número de CPUs es generalmente más largo que el tiempo de espera de los trabajos que solicitan una sola CPU. Por lo tanto, el tiempo de espera general podría ser más corto en el enfoque Grid que solicita una sola CPU para cada sub-trabajo muchas veces en comparación con la implementación MPI que requiere un gran número de CPUs en un solo momento. Es evidente que la programación de la cuadrícula es beneficiosa especialmente cuando el clúster está fuertemente cargado y el número solicitado de CPUs para el trabajo del MPI no está fácilmente disponible. Escenario II: El clúster está relativamente menos cargado o disponible en gran medida. Parece que la implementación del MPI es favorable en comparación con la programación de la Rejilla. Sin embargo, la paralelización de la aplicación EnKF depende del número de licencias ECLIPSE e idealmente, el número de licencias debe ser igual al número de modelos en el conjunto. Por lo tanto, si una sola institución no tiene suficiente número de licencias, la disponibilidad del clúster no ayuda tanto como se espera. Dado que el entorno colaborativo, como TIGRE, puede abordar tanto los requisitos de computación como los de recursos de software para la aplicación EnKF, el enfoque compatible con Grid sigue siendo ventajoso sobre la implementación MPI convencional en cualquiera de los escenarios anteriores. 5. CONCLUSIONES Y FUTURO TRABAJO TIGRE es un proyecto de desarrollo de la red de educación superior y su propósito es mantener y ampliar las oportunidades de investigación y educación a través de Texas. Dentro del área de aplicación de exploración energética, hemos habilitado la implementación MPI del conjunto Kalman metodología de asimilación de datos de filtro para la caracterización de reservorios. Esta tarea se llevó a cabo eliminando el código MPI para el procesamiento paralelo y reemplazando con trabajos de un solo procesador uno para cada modelo geológico en el conjunto. Estos trabajos de un solo procesador fueron programados a través de TIGRE a través de GridWay metascheduler. Hemos demostrado que mediante la puesta en común de licencias a través de sitios TIGRE, más modelos geológicos pueden ser manejados en paralelo y por lo tanto concebiblemente mejor precisión de simulación. Este enfoque tiene varias ventajas sobre la implementación de MPI, especialmente cuando un clúster específico del sitio está muy cargado y/o las licencias de número requeridas para la simulación son más que las disponibles en un solo sitio. Hacia el trabajo futuro, sería interesante comparar el tiempo de ejecución entre MPI y las implementaciones de Grid para la aplicación EnKF. Este esfuerzo podría arrojar luz sobre la calidad del servicio (QoS) de los entornos Grid en comparación con la computación de clústers. Otro aspecto de interés en un futuro próximo sería la gestión de recursos de computación y licencia para abordar la gestión de la relación trabajo (o procesador)-licencia. 6. OBSERVACIONES Y MENOS APRENDIZADOS Los esfuerzos que facilitan la red para la aplicación EnKF han proporcionado amplias oportunidades para reunir información sobre la visibilidad y la promesa de los entornos de computación de Grid para el desarrollo y soporte de aplicaciones. Los principales problemas son la seguridad de los datos estándar de la industria y la CV comparable a la computación de clústers. Dado que la investigación de modelado de reservorios involucra datos propietarios del campo, tuvimos que invertir esfuerzos sustanciales inicialmente en educar a los investigadores de aplicaciones sobre la capacidad de los servicios de Grid para apoyar la seguridad de datos estándar de la industria a través de acceso basado en roles y privilegios utilizando el estándar X.509. Con respecto a QoS, los investigadores de aplicaciones esperan niveles de QoS con entornos de cuadrícula. Además, hay una curva de aprendizaje pronunciada en la computación de cuadrícula en comparación con la computación de clúster convencional. Dado que la computación de cuadrícula sigue siendo una tecnología emergente, y abarca varios ámbitos administrativos, la computación de cuadrícula sigue siendo prematura, especialmente en términos del nivel de QoS, aunque ofrece mejores normas de seguridad de los datos en comparación con los grupos de productos básicos. Es nuestra observación que los programas de capacitación y divulgación que comparan y contrastan los entornos de computación de red y clúster serían un enfoque adecuado para mejorar la participación de los usuarios en la computación de red. Este enfoque también ayuda a los usuarios a emparejar sus aplicaciones y habilidades que las cuadrículas pueden ofrecer. En resumen, nuestros esfuerzos a través de TIGRE en la metodología de asimilación de datos de la EnKF demostraron una promesa sustancial en la contratación de investigadores de Ingeniería Petrolera a través de colaboraciones entre campus. Se están realizando esfuerzos para lograr la participación de más escuelas en este esfuerzo. Estos esfuerzos pueden resultar en un aumento de la investigación colaborativa, oportunidades educativas y desarrollo de la fuerza laboral a través de programas de investigación de posgrado/facultad en instituciones TIGRE. 7. AGRADECIMIENTOS Los autores reconocen al Estado de Texas por apoyar el proyecto TIGRE a través del Fondo Empresarial de Texas, y a las Instituciones TIGRE por proporcionar el mecanismo, en el que también participan los autores (Ravi Vadapalli, Taesung Kim y Ping Luo). Los autores agradecen a los investigadores de aplicaciones Prof. Akhil Datta-Gupta de Texas A&M University y Prof. Lloyd Heinze de Texas Tech University por sus discusiones e interés en explotar el entorno TIGRE para ampliar las oportunidades en investigación y desarrollo. 8. REFERENCIAS [1] Foster, I. y Kesselman, C. (eds.) 2004. The Grid: Blueprint for a new computing infraestructura (The Elsevier series in Grid computing) [2] Portal TIGRE: http://tigreportal.hipcat.net [3] Vadapalli, R. Sill, A., Dooley, R., Murray, M., Luo, P., Kim, T., Huang, M., Thyagaraja, K., y Chaffin, Demostración del entorno TIGRE para aplicaciones de cuadrícula habilitadas/adecuadas. 8o IEEE/ACM Int. Conf. on Grid Computing, 19-21 de septiembre, Austin [4] The High Performance Computing cross Texas Consortium http://www.hipcat.net [5] Pordes, R. Petravick, D. Kramer, B. Olson, D. Livny, M. Roy, A. Avery, P. Blackburn, K. Wenaus, T. Würthwein, F. Foster, I. Gar The Open Science Grid, J. Phys Conf Series http://www.iop.org/EJ/abstract/1742-6596/78/1/012057 y http://www.opensciencegrid.org [6] Reed, D.A. 2003. Rejilla, el Teragrid y más allá, Ordenador, vol. 30, no. 1 y http://www.teragrid.org [7] Evensen, G. 2006. Asimilación de datos: El conjunto Kalman Filter, Springer [8] Herrera, J. Huedo, E. Montero, R. S. y Llorente, I. M. 2005. Programación Científica, vol 12, No. 4. pp 317-331 [9] Avery, P. and Foster, I. 2001. El proyecto GriPhyN: Hacia redes virtuales de datos a petaescala, informe técnico GriPhyN-200115 y http://vdt.cs.wisc.edu [10] La guía de documentación e instalación de PacMan http://physics.bu.edu/pacman/htmls [11] Caskey, P. Murray, M. Perez, J. y Sill, A. 2007. Estudios de casos en la gestión de identificación para organizaciones virtuales, EDUCOUSO Southwest Reg. Conf., 21-23 febrero, Austin, TX. http://www.educause.edu/ir/library/pdf/SWR07058.pdf [12] El Sistema de Gestión de Usuarios de Grid (GUMS) https://www.racf.bnl.gov/Facility/GUMS/index.html [13] Thomas, M. y Boisseau, J. 2003. Construyendo portales de computación de cuadrículas: El kit de herramientas para el portal de cuadrículas NPACI, Grid computing: haciendo realidad la infraestructura global, Capítulo 28, Berman, F. Fox, G. Thomas, M. Boisseau, J. y Hey, T. (eds), John Wiley and Sons, Ltd, Chichester [14] Open Ticket Request System http:// 1999. Integración de datos dinámicos en modelos de depósito de alta resolución utilizando coeficientes de sensibilidad basados en la racionalización, Society of Petroleum Engineers (SPE), 4 (4). [17] Emanuel, A. S. y Milliken, W. J. 1998. Historia que combina modelos de diferencias finitas con racionalizaciones 3D, SPE 49000, Proc de la Conf Técnica Anual y Exposición, 2730 de septiembre, Nueva Orleans, LA. [18] Nævdal, G. Johnsen, L.M. Aanonsen, S.I. y Vefring, E.H. 2003. Monitorización de embalses y actualización continua de modelos utilizando Ensemble Kalman Filter, SPE 84372, Proc del Conf Técnico Anual y Exposición, Oct 5-8, Denver, CO. [19] Jafarpour B. y McLaughlin, D.B. 2007. Historia que coincide con un conjunto de filtro Kalman y parametrización discreta de coseno, SPE 108761, Proc de la Conf Técnica Anual y Exposición, 11-14 de noviembre, Anaheim, CA [20] Li, G. y Reynolds, A. C. 2007. Un conjunto iterativo Kalman filtro para la asimilación de datos, SPE 109808, Proc de la SPE Conf y Exposición Técnica Anual, 11-14 de noviembre, Anaheim, CA [21] Arroyo-Negrete, E. Devagowda, D. Datta-Gupta, A. 2006. Simplificar el conjunto asistido Kalman filtro para la actualización rápida y continua del modelo de depósito. Proc de la Int. Oil & Gas Conf and Exhibition, SPE 104255, Dec 5-7, China [22] ECLIPSE Reservoir Engineering Software http://www.slb.com/content/services/software/reseng/index.a sp ",
            "error": []
        },
        "reservoir model": {
            "translated_key": "modelo de depósito",
            "translated_annotated_text": "Demostración del conjunto de datos de Kalman Assimulation Method for Reservoir Caracterisation Ravi Vadapalli Centro de computación de alto rendimiento Texas Tech University Lubbock, TX 79409 001-806-742-4350 Ravi.Vadapalli@ttu.edu Ajitabh Kumar Department of Petroleum Engineering Texas A&M University College Station, En este enfoque, se utiliza un conjunto de modelos geológicos y datos de producción de yacimientos de petróleo para predecir la respuesta dinámica de los pozos de petróleo. El software Schlumberger ECLIPSE se utiliza para estas simulaciones. Puesto que los modelos en el conjunto no se comunican, la implementación de mensaje-passing es una buena opción. Cada modelo comprueba una licencia ECLIPSE y, por lo tanto, la paralelización de las simulaciones de reservorio depende de las licencias de número disponibles. Hemos habilitado Grid para el conjunto Kalman metodología de asimilación de datos de filtro para el entorno de computación TIGRE Grid. Al poner en común las licencias y los recursos informáticos en todas las instituciones colaboradoras utilizando el metaprogramador GridWay y el entorno TIGRE, la precisión computacional puede aumentarse al tiempo que se reduce el tiempo de ejecución de la simulación. En este artículo, proporcionamos un relato de nuestros esfuerzos en Gridenabilizar el conjunto Kalman Filter metodología de asimilación de datos. Se examinarán los posibles beneficios de este enfoque, las observaciones y la experiencia adquirida. Categorías y Descriptores sujetos C 2.4 [Sistemas distribuidos]: Aplicaciones distribuidas Términos generales Algoritmos, Diseño, Rendimiento 1. INTRODUCCIÓN La computación de cuadrícula [1] es un paradigma de computación colaborativa emergente para ampliar las capacidades específicas de computación de alto rendimiento (HPC) mucho más allá de los recursos locales. Su importancia se deriva del hecho de que la investigación innovadora en áreas de aplicación estratégicas como la biociencia y la medicina, la exploración de energía y el modelado ambiental involucran componentes interdisciplinarios fuertes y a menudo requieren colaboraciones intercampus y capacidades computacionales más allá de las limitaciones institucionales. The Texas Internet Grid for Research and Education (TIGRE) [2,3] es un proyecto de desarrollo de infraestructuras cibernéticas financiado por el estado, llevado a cabo por cinco grandes sistemas universitarios (Rice, A&M, TTU, UH y UT Austin), llamados colectivamente Instituciones TIGRE. El propósito de TIGRE es crear una red de educación superior para sostener y ampliar las oportunidades de investigación y educación en Texas. TIGRE es un proyecto del consorcio de computación de alto rendimiento en Texas (HiPCAT) [4]. El objetivo de HiPCAT es apoyar tecnologías computacionales avanzadas para mejorar la investigación, el desarrollo y las actividades educativas. El objetivo principal de TIGRE es diseñar e implementar middleware Grid de última generación que permita la integración de sistemas de computación, sistemas de almacenamiento y bases de datos, laboratorios de visualización y pantallas, e incluso instrumentos y sensores en Texas. El objetivo secundario es demostrar las capacidades de TIGRE para mejorar las oportunidades de investigación y educación en áreas de aplicación estratégica de interés para el Estado de Texas. Estos son biociencia y medicina, exploración energética y modelado de la calidad del aire. La visión del proyecto TIGRE es fomentar la colaboración interdisciplinaria e intercampus, identificar enfoques novedosos para ampliar las asociaciones académicas, gubernamentales y privadas, y convertirse en un modelo competitivo para las oportunidades de financiación externa. El objetivo general de TIGRE es apoyar los intereses de los usuarios locales, universitarios y regionales y ofrecer vías para conectar con proyectos nacionales de Red como Open Science Grid [5] y TeraGrid [6]. Dentro del área de aplicación estratégica de exploración energética, hemos habilitado el enfoque conjunto Kalman Filter (EnKF) [7] para la asimilación de datos en el modelado de reservorios y hemos demostrado la extensibilidad de la aplicación utilizando el entorno TIGRE y el metaprogramador GridWay [8]. En la sección 2 se ofrece una visión general del entorno y las capacidades de TIGRE. La descripción de la aplicación y la necesidad de una metodología EnKF compatible con la cuadrícula figuran en la sección 3. Los detalles de la aplicación y los méritos de nuestro enfoque se examinan en la sección 4. Las conclusiones figuran en la sección 5. Por último, en la sección 6 se documentan las observaciones y la experiencia adquirida. 2. TIGRE ENTORNO El MIddleware TIGRE Grid consiste en un conjunto mínimo de componentes derivados de un subconjunto del Virtual Data Toolkit (VDT) [9] que soporta una variedad de sistemas operativos. El propósito de elegir una pila de software mínima es apoyar las aplicaciones disponibles y simplificar la instalación y distribución de las pilas cliente/servidor en los sitios de TIGRE. Se añadirán componentes adicionales a medida que sean necesarios. El mecanismo de packaging y distribución PacMan [10] se emplea para la instalación y gestión del cliente/servidor TIGRE. El mecanismo de distribución de PacMan implica la recuperación, instalación y a menudo configuración del software empaquetado. Este enfoque permite a los clientes mantener versiones actualizadas y consistentes del software TIGRE. También ayuda a los sitios TIGRE a instalar los componentes necesarios en los recursos distribuidos en los sitios participantes. La pila cliente/servidor TIGRE consiste en una capa de autenticación y autorización, Globus GRAM4-basada en la presentación de trabajos a través de servicios web (las instalaciones de servicios pre-web están disponibles bajo petición). Las herramientas para manejar la generación de proxy de cuadrícula, la transferencia de archivos habilitada para cuadrícula y el inicio de sesión remoto habilitado para cuadrícula son compatibles. A continuación se proporcionan los detalles pertinentes de los servicios y herramientas de TIGRE para la programación y gestión de puestos. 2.1. Autoridad certificadora La infraestructura de seguridad TIGRE incluye una autoridad certificadora (CA) acreditada por la International Grid Trust Federation (IGTF) para emitir X. 509 certificados de usuario y recurso Grid [11]. El Texas Advanced Computing Center (TACC), Universidad de Texas en Austin, es el TIGREs CA compartido. Las instituciones de TIGRE actúan como autoridades de registro (RA) para sus respectivas bases de usuarios locales. Para obtener información actualizada sobre la seguridad de los certificados de usuario y de recursos y sus instrucciones de instalación, véase ref [2]. Los usuarios y hosts de TIGRE son identificados por su distinguido nombre (DN) en su certificado X.509 proporcionado por la CA. Un archivo nativo Grid-mapfile que contiene una lista de DNs autorizados se utiliza para autenticar y autorizar la programación y gestión de trabajos de los usuarios en los recursos del sitio TIGRE. En la Universidad Texas Tech, a los usuarios se les asigna dinámicamente una de las muchas cuentas genéricas. Esto se logra a través del Sistema de Gestión de Usuarios de Red (GUMS) [12]. 2.2. Programación y gestión de empleos El entorno TIGRE apoya la presentación de trabajos basada en GRAM4 a través de servicios web. Los scripts de envío de trabajos se generan usando XML. Los servicios web GRAM traducen los scripts XML en programadores de lotes específicos de grupos de destino como LSF, PBS o SGE. Los protocolos de transferencia de archivos de alto ancho de banda como GridFTP se utilizan para estadificación de archivos dentro y fuera de la máquina de destino. El acceso a hosts remotos para compilar y depurar es sólo a través del servicio GSISSH que requiere autenticación de recursos a través de certificados X.509. La autenticación y autorización de los trabajos de Grid se gestionan mediante la emisión de certificados de Grid a usuarios y anfitriones. Las listas de revocación de certificados (CRL) se actualizan diariamente para mantener altos estándares de seguridad de los servicios de TIGRE Grid. El área de documentación del portal TIGRE [2] proporciona un tutorial de inicio rápido sobre cómo ejecutar trabajos en TIGRE. 2.3. Metascheduler El metascheduler interopera con los programadores de lotes de nivel de cluster (como LSF, PBS) en la gestión general del flujo de trabajo de Grid. En el presente trabajo, hemos empleado el metaprogramador GridWay [8] -un proyecto de incubadora Globus- para programar y gestionar trabajos en TIGRE. El GridWay es un metaprogramador ligero que utiliza plenamente las funcionalidades de Globus. Está diseñado para proporcionar un uso eficiente de los recursos dinámicos de Grid por múltiples usuarios para las infraestructuras de Grid construidas sobre los servicios de Globus. El administrador del sitio TIGRE puede controlar el uso compartido de recursos a través de un potente programador integrado proporcionado por GridWay o ampliando el módulo de programación externa GridWays para proporcionar sus propias políticas de programación. Los usuarios de aplicaciones pueden escribir descripciones de trabajos usando el formato de plantilla de trabajo simple y directo de GridWays (ver Sección 4 para más detalles) o el lenguaje estándar de descripción de la presentación de trabajos (JSDL). Para más detalles sobre la aplicación, véase la sección 4. 2.4. Sistema de Gestión de Servicios al Cliente Un portal TIGRE [2] fue diseñado e implementado para interconectar usuarios y proveedores de recursos. Fue diseñado utilizando GridPort [13] y es mantenido por TACC. El entorno TIGRE es compatible con herramientas de código abierto como el Open Ticket Request System (OTRS) [14] para el servicio de tickets de problemas, y MoinMoin [15] Wiki para la gestión de contenido y conocimiento de TIGRE para educación, extensión y capacitación. Los enlaces para OTRS y Wiki son consumidos por el portal TIGRE [2] - el portal para usuarios y proveedores de recursos. El estado y las cargas de los recursos de TIGRE son monitoreados por el servicio de Repositorio de Información de Puertos Grid (GPIR) del kit de herramientas GridPort [13] que interactúa con el servicio local de monitoreo de carga de clústeres como Ganglia. El GPIR utiliza trabajos de cron en cada recurso para reunir características específicas de los recursos del sitio, tales como trabajos que se ejecutan, en cola y esperando la asignación de recursos. 3. APLICACIÓN ENSEMBLE KALMAN FILTER El objetivo principal de las simulaciones de yacimientos de hidrocarburos es predecir el comportamiento de la producción de yacimientos de petróleo y gas (denominados en lo sucesivo campo) para su desarrollo y gestión óptima. En el modelado de yacimientos, el campo se divide en varios modelos geológicos, como se muestra en la Figura 1. Para una previsión precisa del rendimiento del campo, es necesario conciliar varios modelos geológicos con la respuesta dinámica del campo a través de la coincidencia histórica [16-20]. Gráfico 1 Vista transversal del Campo. Las capas verticales corresponden a diferentes modelos geológicos y los clavos son pozos de aceite cuya información histórica se utilizará para predecir el comportamiento de la producción. (Figura Ref:http://faculty.smu.edu/zchen/research.html). El EnKF es un método de Monte Carlo que trabaja con un conjunto de modelos de embalses. Este método utiliza covarianzas cruzadas [21] entre las mediciones de campo y los parámetros del \"modelo de depósito\" (derivado de varios modelos) para estimar las incertidumbres de predicción. Los parámetros del modelo geológico en el conjunto se actualizan secuencialmente con el objetivo de minimizar las incertidumbres de predicción. La respuesta histórica de la producción del campo durante más de 50 años se utiliza en estas simulaciones. La principal ventaja de EnKF es que puede vincularse fácilmente a cualquier simulador de depósito, y puede asimilar los últimos datos de producción sin necesidad de volver a ejecutar el simulador desde las condiciones iniciales. Investigadores en Texas son grandes suscriptores del paquete de Schlumberger ECLIPSE [22] para simulaciones de reservorios. En el modelado del embalse, cada modelo geológico comprueba una licencia ECLIPSE. La duración de la simulación de la metodología EnKF depende del número de modelos geológicos utilizados, el número de licencias ECLIPSE disponibles, la historia de producción del campo y las incertidumbres propagadas en la correspondencia de la historia. El flujo de trabajo general de EnKF se muestra en la Figura 2. Gráfico 2 Ensemble Kaman Filter Data Assimulation Workflow. Cada sitio tiene licencias L. En START, el proceso maestro/control (programa principal EnKF) lee el archivo de configuración de simulación para el número (N) de modelos y archivos de entrada específicos del modelo. A continuación, N directorios de trabajo se crean para almacenar los archivos de salida. Al final de la iteración, el proceso maestro/control recoge los archivos de salida de los modelos N y las crosscovarianzas de los procesos posteriores [21] para estimar las incertidumbres de predicción. Esta información se utilizará para actualizar modelos (o archivos de entrada) para la siguiente iteración. La simulación continúa hasta agotar las historias de producción. La simulación típica de EnKF con N=50 y historias de campo de 50-60 años, en pasos de tiempo que van de tres meses a un año, toma unas tres semanas en un entorno de computación en serie. En el entorno informático paralelo, no hay comunicación interproceso entre los modelos geológicos en el conjunto. Sin embargo, al final de cada paso del tiempo de simulación, los archivos de salida específicos del modelo deben ser recogidos para analizar covarianzas cruzadas [21] y para preparar el siguiente conjunto de archivos de entrada. Por lo tanto, el modelo maestro-esclavo en el entorno de mensajepassing (MPI) es un paradigma adecuado. En este enfoque, los modelos geológicos son tratados como esclavos y se distribuyen entre los procesadores disponibles. El master Cluster o (TIGRE/GridWay) START Read Configuration File Create N Working Directories Create N Input files Model l Model 2 Model N.. . ECLIPSE in situ Un ECLIPSE in situ B ECLIPSE in situ Z Collect N Model Outputs, Post-process Output files FIN. . . proceso recoge archivos de salida específicos del modelo, analiza y prepara el siguiente conjunto de archivos de entrada para la simulación. Dado que cada modelo geológico comprueba una licencia ECLIPSE, la paralelización de la simulación depende del número de licencias disponibles. Cuando el número de licencias disponible es menor que el número de modelos en el conjunto, uno o más de los nodos del grupo MPI tienen que manejar más de un modelo en serie y, por lo tanto, se tarda más tiempo en completar la simulación. Un Departamento de Ingeniería Petrolera generalmente adquiere 10-15 licencias ECLIPSE, mientras que al menos diez veces más número de licencias sería necesario para simulaciones estándar de la industria. El número de licencias puede incrementarse con la participación de varios departamentos de ingeniería petrolera que apoyan el paquete ECLIPSE. Dado que MPI no se escala muy bien para aplicaciones que involucran clústeres de computación remotos, y para evitar los problemas del firewall con servidores de licencias en todos los dominios administrativos, parece necesario activar el flujo de trabajo de EnKF. Con esta motivación, hemos implementado el flujo de trabajo EnKF habilitado para Grid para el entorno TIGRE y hemos demostrado la paralelización de la aplicación a través de TIGRE usando el metascheduler GridWay. En la siguiente sección figuran más detalles al respecto. 4. DETALLES DE APLICACION Para habilitar Grid-enable el enfoque EnKF, hemos eliminado el código MPI para el procesamiento paralelo y reemplazado por trabajos de N monoprocesador (o sub-trabajos) donde, N es el número de modelos geológicos en el conjunto. Estos sub-trabajos específicos de modelos se distribuyeron a través de sitios TIGRE que soportan el paquete ECLIPSE utilizando el metaprogramador GridWay [8]. Para cada sub-trabajo, hemos construido una plantilla de trabajo GridWay que especifica los archivos ejecutables, de entrada y salida, y los requisitos de recursos. Dado que los recursos de cálculo de TIGRE no se espera que cambien con frecuencia, hemos utilizado la política de descubrimiento de recursos estáticos para GridWay y los sub-trabajos fueron programados dinámicamente a través de los recursos de TIGRE usando GridWay. La Figura 3 representa el archivo de plantilla de subtrabajo para el metaprogramador GridWay. Gráfico 3 Plantilla de subtrabajo GridWay En la Figura 3, REQUISITOS bandera se establece para elegir los recursos que satisfacen los requisitos de la aplicación. En el caso de la aplicación EnKF, por ejemplo, necesitamos recursos que apoyen el paquete ECLIPSE. ARGUMENTS flag especifica el modelo en el conjunto que invocará ECLIPSE en un sitio remoto. INPUT_FILES es preparado por el programa principal de EnKF (o proceso maestro/control) y es transferido por GridWay al sitio remoto donde está desatendido y está preparado para su ejecución. Finalmente, OUTPUT_FILES especifica el nombre y la ubicación donde se escribirán los archivos de salida. Las características de la línea de comandos de GridWay se utilizaron para recopilar y procesar las salidas específicas del modelo para preparar un nuevo conjunto de archivos de entrada. Este paso imita la sincronización del proceso MPI en el modelo maestro-esclavo. Al final de cada iteración, los recursos computacionales y las licencias se devuelven al grupo. La Tabla 1 muestra los sub-trabajos en TIGRE Grid via GridWay usando el comando gwps y para mayor claridad, sólo se mostraron las columnas seleccionadas. USUARIO JID DM EM NOMBRE HOST pingluo 88 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 89 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 90 wrap actv enkf.jt minigar.hp Programación de trabajo a través de TIGRE usando GridWay Metascheduler. DM: Estado de envío, EM: Estado de ejecución, JID es el id de trabajo y HOST corresponde al cluster específico del sitio y su planificador de lotes local. Cuando un trabajo es enviado a GridWay, pasará por una serie de estados de envío (DM) y ejecución (EM). Para DM, los estados incluyen pend(ing), prol(og), wrap(per), epil(og), y hecho. DM=prol significa que el trabajo ha sido programado a un recurso y el directorio de trabajo remoto está en preparación. DM=warp implica que GridWay está ejecutando el envoltorio que a su vez ejecuta la aplicación. DM=epil implica que el trabajo ha terminado de ejecutarse en el sitio remoto y los resultados se están transfiriendo al servidor GridWay. Del mismo modo, cuando EM=pend implica que el trabajo está esperando en la cola para el recurso y el trabajo se está ejecutando cuando EM=actv. Para ver la lista completa de las banderas de mensajes y sus descripciones, consulte la documentación en ref [8]. Hemos demostrado las ejecuciones de EnKF habilitadas para Grid usando GridWay para entorno TIGRE. Los trabajos son tan elegidos que el tiempo de ejecución no supera más de media hora. La simulación incluyó hasta 20 trabajos entre sitios de A&M y TTU con TTU cumpliendo 10 licencias. Para obtener información sobre los recursos, véase el cuadro I. Una de las principales ventajas de la simulación EnKF habilitada por Grid es que tanto los recursos como las licencias se devuelven al grupo al final de cada paso del tiempo de simulación a diferencia del caso de la implementación de MPI donde las licencias y nodos están bloqueados hasta la finalización de la simulación completa. Sin embargo, el hecho de que cada sub-trabajo se programe independientemente a través de GridWay podría posiblemente incurrir en otro retraso de tiempo causado por esperar en la cola para la ejecución en cada paso del tiempo de simulación. Tales retrasos no se esperan EXECUTABLE=runFORWARD NECESIDADES=HOSTNAME=cosmos.tamu.edu  HOSTNAME=antaeus.hpcc.ttu.edu  HOSTNAME=minigar.hpcc.ttu.edu  ARGUMENTOS=001 INPUT_FILES=001.in.tar OUTPUT_FI Hay dos escenarios principales para comparar los enfoques de computación de red y clúster. Escenario I: El cúmulo está muy cargado. El tiempo promedio de espera concebido del trabajo que solicita un gran número de CPUs es generalmente más largo que el tiempo de espera de los trabajos que solicitan una sola CPU. Por lo tanto, el tiempo de espera general podría ser más corto en el enfoque Grid que solicita una sola CPU para cada sub-trabajo muchas veces en comparación con la implementación MPI que requiere un gran número de CPUs en un solo momento. Es evidente que la programación de la cuadrícula es beneficiosa especialmente cuando el clúster está fuertemente cargado y el número solicitado de CPUs para el trabajo del MPI no está fácilmente disponible. Escenario II: El clúster está relativamente menos cargado o disponible en gran medida. Parece que la implementación del MPI es favorable en comparación con la programación de la Rejilla. Sin embargo, la paralelización de la aplicación EnKF depende del número de licencias ECLIPSE e idealmente, el número de licencias debe ser igual al número de modelos en el conjunto. Por lo tanto, si una sola institución no tiene suficiente número de licencias, la disponibilidad del clúster no ayuda tanto como se espera. Dado que el entorno colaborativo, como TIGRE, puede abordar tanto los requisitos de computación como los de recursos de software para la aplicación EnKF, el enfoque compatible con Grid sigue siendo ventajoso sobre la implementación MPI convencional en cualquiera de los escenarios anteriores. 5. CONCLUSIONES Y FUTURO TRABAJO TIGRE es un proyecto de desarrollo de la red de educación superior y su propósito es mantener y ampliar las oportunidades de investigación y educación a través de Texas. Dentro del área de aplicación de exploración energética, hemos habilitado la implementación MPI del conjunto Kalman metodología de asimilación de datos de filtro para la caracterización de reservorios. Esta tarea se llevó a cabo eliminando el código MPI para el procesamiento paralelo y reemplazando con trabajos de un solo procesador uno para cada modelo geológico en el conjunto. Estos trabajos de un solo procesador fueron programados a través de TIGRE a través de GridWay metascheduler. Hemos demostrado que mediante la puesta en común de licencias a través de sitios TIGRE, más modelos geológicos pueden ser manejados en paralelo y por lo tanto concebiblemente mejor precisión de simulación. Este enfoque tiene varias ventajas sobre la implementación de MPI, especialmente cuando un clúster específico del sitio está muy cargado y/o las licencias de número requeridas para la simulación son más que las disponibles en un solo sitio. Hacia el trabajo futuro, sería interesante comparar el tiempo de ejecución entre MPI y las implementaciones de Grid para la aplicación EnKF. Este esfuerzo podría arrojar luz sobre la calidad del servicio (QoS) de los entornos Grid en comparación con la computación de clústers. Otro aspecto de interés en un futuro próximo sería la gestión de recursos de computación y licencia para abordar la gestión de la relación trabajo (o procesador)-licencia. 6. OBSERVACIONES Y MENOS APRENDIZADOS Los esfuerzos que facilitan la red para la aplicación EnKF han proporcionado amplias oportunidades para reunir información sobre la visibilidad y la promesa de los entornos de computación de Grid para el desarrollo y soporte de aplicaciones. Los principales problemas son la seguridad de los datos estándar de la industria y la CV comparable a la computación de clústers. Dado que la investigación de modelado de reservorios involucra datos propietarios del campo, tuvimos que invertir esfuerzos sustanciales inicialmente en educar a los investigadores de aplicaciones sobre la capacidad de los servicios de Grid para apoyar la seguridad de datos estándar de la industria a través de acceso basado en roles y privilegios utilizando el estándar X.509. Con respecto a QoS, los investigadores de aplicaciones esperan niveles de QoS con entornos de cuadrícula. Además, hay una curva de aprendizaje pronunciada en la computación de cuadrícula en comparación con la computación de clúster convencional. Dado que la computación de cuadrícula sigue siendo una tecnología emergente, y abarca varios ámbitos administrativos, la computación de cuadrícula sigue siendo prematura, especialmente en términos del nivel de QoS, aunque ofrece mejores normas de seguridad de los datos en comparación con los grupos de productos básicos. Es nuestra observación que los programas de capacitación y divulgación que comparan y contrastan los entornos de computación de red y clúster serían un enfoque adecuado para mejorar la participación de los usuarios en la computación de red. Este enfoque también ayuda a los usuarios a emparejar sus aplicaciones y habilidades que las cuadrículas pueden ofrecer. En resumen, nuestros esfuerzos a través de TIGRE en la metodología de asimilación de datos de la EnKF demostraron una promesa sustancial en la contratación de investigadores de Ingeniería Petrolera a través de colaboraciones entre campus. Se están realizando esfuerzos para lograr la participación de más escuelas en este esfuerzo. Estos esfuerzos pueden resultar en un aumento de la investigación colaborativa, oportunidades educativas y desarrollo de la fuerza laboral a través de programas de investigación de posgrado/facultad en instituciones TIGRE. 7. AGRADECIMIENTOS Los autores reconocen al Estado de Texas por apoyar el proyecto TIGRE a través del Fondo Empresarial de Texas, y a las Instituciones TIGRE por proporcionar el mecanismo, en el que también participan los autores (Ravi Vadapalli, Taesung Kim y Ping Luo). Los autores agradecen a los investigadores de aplicaciones Prof. Akhil Datta-Gupta de Texas A&M University y Prof. Lloyd Heinze de Texas Tech University por sus discusiones e interés en explotar el entorno TIGRE para ampliar las oportunidades en investigación y desarrollo. 8. REFERENCIAS [1] Foster, I. y Kesselman, C. (eds.) 2004. The Grid: Blueprint for a new computing infraestructura (The Elsevier series in Grid computing) [2] Portal TIGRE: http://tigreportal.hipcat.net [3] Vadapalli, R. Sill, A., Dooley, R., Murray, M., Luo, P., Kim, T., Huang, M., Thyagaraja, K., y Chaffin, Demostración del entorno TIGRE para aplicaciones de cuadrícula habilitadas/adecuadas. 8o IEEE/ACM Int. Conf. on Grid Computing, 19-21 de septiembre, Austin [4] The High Performance Computing cross Texas Consortium http://www.hipcat.net [5] Pordes, R. Petravick, D. Kramer, B. Olson, D. Livny, M. Roy, A. Avery, P. Blackburn, K. Wenaus, T. Würthwein, F. Foster, I. Gar The Open Science Grid, J. Phys Conf Series http://www.iop.org/EJ/abstract/1742-6596/78/1/012057 y http://www.opensciencegrid.org [6] Reed, D.A. 2003. Rejilla, el Teragrid y más allá, Ordenador, vol. 30, no. 1 y http://www.teragrid.org [7] Evensen, G. 2006. Asimilación de datos: El conjunto Kalman Filter, Springer [8] Herrera, J. Huedo, E. Montero, R. S. y Llorente, I. M. 2005. Programación Científica, vol 12, No. 4. pp 317-331 [9] Avery, P. and Foster, I. 2001. El proyecto GriPhyN: Hacia redes virtuales de datos a petaescala, informe técnico GriPhyN-200115 y http://vdt.cs.wisc.edu [10] La guía de documentación e instalación de PacMan http://physics.bu.edu/pacman/htmls [11] Caskey, P. Murray, M. Perez, J. y Sill, A. 2007. Estudios de casos en la gestión de identificación para organizaciones virtuales, EDUCOUSO Southwest Reg. Conf., 21-23 febrero, Austin, TX. http://www.educause.edu/ir/library/pdf/SWR07058.pdf [12] El Sistema de Gestión de Usuarios de Grid (GUMS) https://www.racf.bnl.gov/Facility/GUMS/index.html [13] Thomas, M. y Boisseau, J. 2003. Construyendo portales de computación de cuadrículas: El kit de herramientas para el portal de cuadrículas NPACI, Grid computing: haciendo realidad la infraestructura global, Capítulo 28, Berman, F. Fox, G. Thomas, M. Boisseau, J. y Hey, T. (eds), John Wiley and Sons, Ltd, Chichester [14] Open Ticket Request System http:// 1999. Integración de datos dinámicos en modelos de depósito de alta resolución utilizando coeficientes de sensibilidad basados en la racionalización, Society of Petroleum Engineers (SPE), 4 (4). [17] Emanuel, A. S. y Milliken, W. J. 1998. Historia que combina modelos de diferencias finitas con racionalizaciones 3D, SPE 49000, Proc de la Conf Técnica Anual y Exposición, 2730 de septiembre, Nueva Orleans, LA. [18] Nævdal, G. Johnsen, L.M. Aanonsen, S.I. y Vefring, E.H. 2003. Monitorización de embalses y actualización continua de modelos utilizando Ensemble Kalman Filter, SPE 84372, Proc del Conf Técnico Anual y Exposición, Oct 5-8, Denver, CO. [19] Jafarpour B. y McLaughlin, D.B. 2007. Historia que coincide con un conjunto de filtro Kalman y parametrización discreta de coseno, SPE 108761, Proc de la Conf Técnica Anual y Exposición, 11-14 de noviembre, Anaheim, CA [20] Li, G. y Reynolds, A. C. 2007. Un conjunto iterativo Kalman filtro para la asimilación de datos, SPE 109808, Proc de la SPE Conf y Exposición Técnica Anual, 11-14 de noviembre, Anaheim, CA [21] Arroyo-Negrete, E. Devagowda, D. Datta-Gupta, A. 2006. Simplifique el conjunto asistido Kalman filtro para una actualización \"modelo de depósito\" rápida y continua. Proc de la Int. Oil & Gas Conf and Exhibition, SPE 104255, Dec 5-7, China [22] ECLIPSE Reservoir Engineering Software http://www.slb.com/content/services/software/reseng/index.a sp ",
            "error": [
                ""
            ]
        },
        "enkf": {
            "translated_key": "enkf",
            "translated_annotated_text": "Demostración del conjunto de datos de Kalman Assimulation Method for Reservoir Caracterisation Ravi Vadapalli Centro de computación de alto rendimiento Texas Tech University Lubbock, TX 79409 001-806-742-4350 Ravi.Vadapalli@ttu.edu Ajitabh Kumar Department of Petroleum Engineering Texas A&M University College Station, En este enfoque, se utiliza un conjunto de modelos geológicos y datos de producción de yacimientos de petróleo para predecir la respuesta dinámica de los pozos de petróleo. El software Schlumberger ECLIPSE se utiliza para estas simulaciones. Puesto que los modelos en el conjunto no se comunican, la implementación de mensaje-passing es una buena opción. Cada modelo comprueba una licencia ECLIPSE y, por lo tanto, la paralelización de las simulaciones de reservorio depende de las licencias de número disponibles. Hemos habilitado Grid para el conjunto Kalman metodología de asimilación de datos de filtro para el entorno de computación TIGRE Grid. Al poner en común las licencias y los recursos informáticos en todas las instituciones colaboradoras utilizando el metaprogramador GridWay y el entorno TIGRE, la precisión computacional puede aumentarse al tiempo que se reduce el tiempo de ejecución de la simulación. En este artículo, proporcionamos un relato de nuestros esfuerzos en Gridenabilizar el conjunto Kalman Filter metodología de asimilación de datos. Se examinarán los posibles beneficios de este enfoque, las observaciones y la experiencia adquirida. Categorías y Descriptores sujetos C 2.4 [Sistemas distribuidos]: Aplicaciones distribuidas Términos generales Algoritmos, Diseño, Rendimiento 1. INTRODUCCIÓN La computación de cuadrícula [1] es un paradigma de computación colaborativa emergente para ampliar las capacidades específicas de computación de alto rendimiento (HPC) mucho más allá de los recursos locales. Su importancia se deriva del hecho de que la investigación innovadora en áreas de aplicación estratégicas como la biociencia y la medicina, la exploración de energía y el modelado ambiental involucran componentes interdisciplinarios fuertes y a menudo requieren colaboraciones intercampus y capacidades computacionales más allá de las limitaciones institucionales. The Texas Internet Grid for Research and Education (TIGRE) [2,3] es un proyecto de desarrollo de infraestructuras cibernéticas financiado por el estado, llevado a cabo por cinco grandes sistemas universitarios (Rice, A&M, TTU, UH y UT Austin), llamados colectivamente Instituciones TIGRE. El propósito de TIGRE es crear una red de educación superior para sostener y ampliar las oportunidades de investigación y educación en Texas. TIGRE es un proyecto del consorcio de computación de alto rendimiento en Texas (HiPCAT) [4]. El objetivo de HiPCAT es apoyar tecnologías computacionales avanzadas para mejorar la investigación, el desarrollo y las actividades educativas. El objetivo principal de TIGRE es diseñar e implementar middleware Grid de última generación que permita la integración de sistemas de computación, sistemas de almacenamiento y bases de datos, laboratorios de visualización y pantallas, e incluso instrumentos y sensores en Texas. El objetivo secundario es demostrar las capacidades de TIGRE para mejorar las oportunidades de investigación y educación en áreas de aplicación estratégica de interés para el Estado de Texas. Estos son biociencia y medicina, exploración energética y modelado de la calidad del aire. La visión del proyecto TIGRE es fomentar la colaboración interdisciplinaria e intercampus, identificar enfoques novedosos para ampliar las asociaciones académicas, gubernamentales y privadas, y convertirse en un modelo competitivo para las oportunidades de financiación externa. El objetivo general de TIGRE es apoyar los intereses de los usuarios locales, universitarios y regionales y ofrecer vías para conectar con proyectos nacionales de Red como Open Science Grid [5] y TeraGrid [6]. Dentro del área de aplicación estratégica de exploración energética, hemos habilitado el enfoque conjunto Kalman Filter (EnKF) [7] para la asimilación de datos en el modelado de reservorios y hemos demostrado la extensibilidad de la aplicación utilizando el entorno TIGRE y el metaprogramador GridWay [8]. En la sección 2 se ofrece una visión general del entorno y las capacidades de TIGRE. La descripción de la aplicación y la necesidad de una metodología EnKF compatible con la cuadrícula figuran en la sección 3. Los detalles de la aplicación y los méritos de nuestro enfoque se examinan en la sección 4. Las conclusiones figuran en la sección 5. Por último, en la sección 6 se documentan las observaciones y la experiencia adquirida. 2. TIGRE ENTORNO El MIddleware TIGRE Grid consiste en un conjunto mínimo de componentes derivados de un subconjunto del Virtual Data Toolkit (VDT) [9] que soporta una variedad de sistemas operativos. El propósito de elegir una pila de software mínima es apoyar las aplicaciones disponibles y simplificar la instalación y distribución de las pilas cliente/servidor en los sitios de TIGRE. Se añadirán componentes adicionales a medida que sean necesarios. El mecanismo de packaging y distribución PacMan [10] se emplea para la instalación y gestión del cliente/servidor TIGRE. El mecanismo de distribución de PacMan implica la recuperación, instalación y a menudo configuración del software empaquetado. Este enfoque permite a los clientes mantener versiones actualizadas y consistentes del software TIGRE. También ayuda a los sitios TIGRE a instalar los componentes necesarios en los recursos distribuidos en los sitios participantes. La pila cliente/servidor TIGRE consiste en una capa de autenticación y autorización, Globus GRAM4-basada en la presentación de trabajos a través de servicios web (las instalaciones de servicios pre-web están disponibles bajo petición). Las herramientas para manejar la generación de proxy de cuadrícula, la transferencia de archivos habilitada para cuadrícula y el inicio de sesión remoto habilitado para cuadrícula son compatibles. A continuación se proporcionan los detalles pertinentes de los servicios y herramientas de TIGRE para la programación y gestión de puestos. 2.1. Autoridad certificadora La infraestructura de seguridad TIGRE incluye una autoridad certificadora (CA) acreditada por la International Grid Trust Federation (IGTF) para emitir X. 509 certificados de usuario y recurso Grid [11]. El Texas Advanced Computing Center (TACC), Universidad de Texas en Austin, es el TIGREs CA compartido. Las instituciones de TIGRE actúan como autoridades de registro (RA) para sus respectivas bases de usuarios locales. Para obtener información actualizada sobre la seguridad de los certificados de usuario y de recursos y sus instrucciones de instalación, véase ref [2]. Los usuarios y hosts de TIGRE son identificados por su distinguido nombre (DN) en su certificado X.509 proporcionado por la CA. Un archivo nativo Grid-mapfile que contiene una lista de DNs autorizados se utiliza para autenticar y autorizar la programación y gestión de trabajos de los usuarios en los recursos del sitio TIGRE. En la Universidad Texas Tech, a los usuarios se les asigna dinámicamente una de las muchas cuentas genéricas. Esto se logra a través del Sistema de Gestión de Usuarios de Red (GUMS) [12]. 2.2. Programación y gestión de empleos El entorno TIGRE apoya la presentación de trabajos basada en GRAM4 a través de servicios web. Los scripts de envío de trabajos se generan usando XML. Los servicios web GRAM traducen los scripts XML en programadores de lotes específicos de grupos de destino como LSF, PBS o SGE. Los protocolos de transferencia de archivos de alto ancho de banda como GridFTP se utilizan para estadificación de archivos dentro y fuera de la máquina de destino. El acceso a hosts remotos para compilar y depurar es sólo a través del servicio GSISSH que requiere autenticación de recursos a través de certificados X.509. La autenticación y autorización de los trabajos de Grid se gestionan mediante la emisión de certificados de Grid a usuarios y anfitriones. Las listas de revocación de certificados (CRL) se actualizan diariamente para mantener altos estándares de seguridad de los servicios de TIGRE Grid. El área de documentación del portal TIGRE [2] proporciona un tutorial de inicio rápido sobre cómo ejecutar trabajos en TIGRE. 2.3. Metascheduler El metascheduler interopera con los programadores de lotes de nivel de cluster (como LSF, PBS) en la gestión general del flujo de trabajo de Grid. En el presente trabajo, hemos empleado el metaprogramador GridWay [8] -un proyecto de incubadora Globus- para programar y gestionar trabajos en TIGRE. El GridWay es un metaprogramador ligero que utiliza plenamente las funcionalidades de Globus. Está diseñado para proporcionar un uso eficiente de los recursos dinámicos de Grid por múltiples usuarios para las infraestructuras de Grid construidas sobre los servicios de Globus. El administrador del sitio TIGRE puede controlar el uso compartido de recursos a través de un potente programador integrado proporcionado por GridWay o ampliando el módulo de programación externa GridWays para proporcionar sus propias políticas de programación. Los usuarios de aplicaciones pueden escribir descripciones de trabajos usando el formato de plantilla de trabajo simple y directo de GridWays (ver Sección 4 para más detalles) o el lenguaje estándar de descripción de la presentación de trabajos (JSDL). Para más detalles sobre la aplicación, véase la sección 4. 2.4. Sistema de Gestión de Servicios al Cliente Un portal TIGRE [2] fue diseñado e implementado para interconectar usuarios y proveedores de recursos. Fue diseñado utilizando GridPort [13] y es mantenido por TACC. El entorno TIGRE es compatible con herramientas de código abierto como el Open Ticket Request System (OTRS) [14] para el servicio de tickets de problemas, y MoinMoin [15] Wiki para la gestión de contenido y conocimiento de TIGRE para educación, extensión y capacitación. Los enlaces para OTRS y Wiki son consumidos por el portal TIGRE [2] - el portal para usuarios y proveedores de recursos. El estado y las cargas de los recursos de TIGRE son monitoreados por el servicio de Repositorio de Información de Puertos Grid (GPIR) del kit de herramientas GridPort [13] que interactúa con el servicio local de monitoreo de carga de clústeres como Ganglia. El GPIR utiliza trabajos de cron en cada recurso para reunir características específicas de los recursos del sitio, tales como trabajos que se ejecutan, en cola y esperando la asignación de recursos. 3. APLICACIÓN ENSEMBLE KALMAN FILTER El objetivo principal de las simulaciones de yacimientos de hidrocarburos es predecir el comportamiento de la producción de yacimientos de petróleo y gas (denominados en lo sucesivo campo) para su desarrollo y gestión óptima. En el modelado de yacimientos, el campo se divide en varios modelos geológicos, como se muestra en la Figura 1. Para una previsión precisa del rendimiento del campo, es necesario conciliar varios modelos geológicos con la respuesta dinámica del campo a través de la coincidencia histórica [16-20]. Gráfico 1 Vista transversal del Campo. Las capas verticales corresponden a diferentes modelos geológicos y los clavos son pozos de aceite cuya información histórica se utilizará para predecir el comportamiento de la producción. (Figura Ref:http://faculty.smu.edu/zchen/research.html). El EnKF es un método de Monte Carlo que trabaja con un conjunto de modelos de embalses. Este método utiliza covarianzas cruzadas [21] entre las mediciones de campo y los parámetros del modelo de reservorio (derivados de varios modelos) para estimar las incertidumbres de predicción. Los parámetros del modelo geológico en el conjunto se actualizan secuencialmente con el objetivo de minimizar las incertidumbres de predicción. La respuesta histórica de la producción del campo durante más de 50 años se utiliza en estas simulaciones. La principal ventaja de EnKF es que puede vincularse fácilmente a cualquier simulador de depósito, y puede asimilar los últimos datos de producción sin necesidad de volver a ejecutar el simulador desde las condiciones iniciales. Investigadores en Texas son grandes suscriptores del paquete de Schlumberger ECLIPSE [22] para simulaciones de reservorios. En el modelado del embalse, cada modelo geológico comprueba una licencia ECLIPSE. La duración de la simulación de la metodología EnKF depende del número de modelos geológicos utilizados, el número de licencias ECLIPSE disponibles, la historia de producción del campo y las incertidumbres propagadas en la correspondencia de la historia. El flujo de trabajo general de EnKF se muestra en la Figura 2. Gráfico 2 Ensemble Kaman Filter Data Assimulation Workflow. Cada sitio tiene licencias L. En START, el proceso maestro/control (programa principal EnKF) lee el archivo de configuración de simulación para el número (N) de modelos y archivos de entrada específicos del modelo. A continuación, N directorios de trabajo se crean para almacenar los archivos de salida. Al final de la iteración, el proceso maestro/control recoge los archivos de salida de los modelos N y las crosscovarianzas de los procesos posteriores [21] para estimar las incertidumbres de predicción. Esta información se utilizará para actualizar modelos (o archivos de entrada) para la siguiente iteración. La simulación continúa hasta agotar las historias de producción. La simulación típica de EnKF con N=50 y historias de campo de 50-60 años, en pasos de tiempo que van de tres meses a un año, toma unas tres semanas en un entorno de computación en serie. En el entorno informático paralelo, no hay comunicación interproceso entre los modelos geológicos en el conjunto. Sin embargo, al final de cada paso del tiempo de simulación, los archivos de salida específicos del modelo deben ser recogidos para analizar covarianzas cruzadas [21] y para preparar el siguiente conjunto de archivos de entrada. Por lo tanto, el modelo maestro-esclavo en el entorno de mensajepassing (MPI) es un paradigma adecuado. En este enfoque, los modelos geológicos son tratados como esclavos y se distribuyen entre los procesadores disponibles. El master Cluster o (TIGRE/GridWay) START Read Configuration File Create N Working Directories Create N Input files Model l Model 2 Model N.. . ECLIPSE in situ Un ECLIPSE in situ B ECLIPSE in situ Z Collect N Model Outputs, Post-process Output files FIN. . . proceso recoge archivos de salida específicos del modelo, analiza y prepara el siguiente conjunto de archivos de entrada para la simulación. Dado que cada modelo geológico comprueba una licencia ECLIPSE, la paralelización de la simulación depende del número de licencias disponibles. Cuando el número de licencias disponible es menor que el número de modelos en el conjunto, uno o más de los nodos del grupo MPI tienen que manejar más de un modelo en serie y, por lo tanto, se tarda más tiempo en completar la simulación. Un Departamento de Ingeniería Petrolera generalmente adquiere 10-15 licencias ECLIPSE, mientras que al menos diez veces más número de licencias sería necesario para simulaciones estándar de la industria. El número de licencias puede incrementarse con la participación de varios departamentos de ingeniería petrolera que apoyan el paquete ECLIPSE. Dado que MPI no se escala muy bien para aplicaciones que involucran clústeres de computación remotos, y para evitar los problemas del firewall con servidores de licencias en todos los dominios administrativos, parece necesario activar el flujo de trabajo de EnKF. Con esta motivación, hemos implementado el flujo de trabajo EnKF habilitado para Grid para el entorno TIGRE y hemos demostrado la paralelización de la aplicación a través de TIGRE usando el metascheduler GridWay. En la siguiente sección figuran más detalles al respecto. 4. DETALLES DE APLICACION Para habilitar Grid-enable el enfoque EnKF, hemos eliminado el código MPI para el procesamiento paralelo y reemplazado por trabajos de N monoprocesador (o sub-trabajos) donde, N es el número de modelos geológicos en el conjunto. Estos sub-trabajos específicos de modelos se distribuyeron a través de sitios TIGRE que soportan el paquete ECLIPSE utilizando el metaprogramador GridWay [8]. Para cada sub-trabajo, hemos construido una plantilla de trabajo GridWay que especifica los archivos ejecutables, de entrada y salida, y los requisitos de recursos. Dado que los recursos de cálculo de TIGRE no se espera que cambien con frecuencia, hemos utilizado la política de descubrimiento de recursos estáticos para GridWay y los sub-trabajos fueron programados dinámicamente a través de los recursos de TIGRE usando GridWay. La Figura 3 representa el archivo de plantilla de subtrabajo para el metaprogramador GridWay. Gráfico 3 Plantilla de subtrabajo GridWay En la Figura 3, REQUISITOS bandera se establece para elegir los recursos que satisfacen los requisitos de la aplicación. En el caso de la aplicación EnKF, por ejemplo, necesitamos recursos que apoyen el paquete ECLIPSE. ARGUMENTS flag especifica el modelo en el conjunto que invocará ECLIPSE en un sitio remoto. INPUT_FILES es preparado por el programa principal de EnKF (o proceso maestro/control) y es transferido por GridWay al sitio remoto donde está desatendido y está preparado para su ejecución. Finalmente, OUTPUT_FILES especifica el nombre y la ubicación donde se escribirán los archivos de salida. Las características de la línea de comandos de GridWay se utilizaron para recopilar y procesar las salidas específicas del modelo para preparar un nuevo conjunto de archivos de entrada. Este paso imita la sincronización del proceso MPI en el modelo maestro-esclavo. Al final de cada iteración, los recursos computacionales y las licencias se devuelven al grupo. La Tabla 1 muestra los sub-trabajos en TIGRE Grid via GridWay usando el comando gwps y para mayor claridad, sólo se mostraron las columnas seleccionadas. USUARIO JID DM EM NOMBRE HOST pingluo 88 wrap pend \"enkf\".jt antaeus.hpcc.ttu.edu/LSF pingluo 89 wrap pend \"enkf\".jt antaeus.hpcc.ttu.edu/LSF pingluo 90 wrap actv \"enkf\".jt minigar Programación de trabajo a través de TIGRE usando GridWay Metascheduler. DM: Estado de envío, EM: Estado de ejecución, JID es el id de trabajo y HOST corresponde al cluster específico del sitio y su planificador de lotes local. Cuando un trabajo es enviado a GridWay, pasará por una serie de estados de envío (DM) y ejecución (EM). Para DM, los estados incluyen pend(ing), prol(og), wrap(per), epil(og), y hecho. DM=prol significa que el trabajo ha sido programado a un recurso y el directorio de trabajo remoto está en preparación. DM=warp implica que GridWay está ejecutando el envoltorio que a su vez ejecuta la aplicación. DM=epil implica que el trabajo ha terminado de ejecutarse en el sitio remoto y los resultados se están transfiriendo al servidor GridWay. Del mismo modo, cuando EM=pend implica que el trabajo está esperando en la cola para el recurso y el trabajo se está ejecutando cuando EM=actv. Para ver la lista completa de las banderas de mensajes y sus descripciones, consulte la documentación en ref [8]. Hemos demostrado las ejecuciones de EnKF habilitadas para Grid usando GridWay para entorno TIGRE. Los trabajos son tan elegidos que el tiempo de ejecución no supera más de media hora. La simulación incluyó hasta 20 trabajos entre sitios de A&M y TTU con TTU cumpliendo 10 licencias. Para obtener información sobre los recursos, véase el cuadro I. Una de las principales ventajas de la simulación EnKF habilitada por Grid es que tanto los recursos como las licencias se devuelven al grupo al final de cada paso del tiempo de simulación a diferencia del caso de la implementación de MPI donde las licencias y nodos están bloqueados hasta la finalización de la simulación completa. Sin embargo, el hecho de que cada sub-trabajo se programe independientemente a través de GridWay podría posiblemente incurrir en otro retraso de tiempo causado por esperar en la cola para la ejecución en cada paso del tiempo de simulación. Tales retrasos no se esperan EXECUTABLE=runFORWARD NECESIDADES=HOSTNAME=cosmos.tamu.edu  HOSTNAME=antaeus.hpcc.ttu.edu  HOSTNAME=minigar.hpcc.ttu.edu  ARGUMENTOS=001 INPUT_FILES=001.in.tar OUTPUT_FI Hay dos escenarios principales para comparar los enfoques de computación de red y clúster. Escenario I: El cúmulo está muy cargado. El tiempo promedio de espera concebido del trabajo que solicita un gran número de CPUs es generalmente más largo que el tiempo de espera de los trabajos que solicitan una sola CPU. Por lo tanto, el tiempo de espera general podría ser más corto en el enfoque Grid que solicita una sola CPU para cada sub-trabajo muchas veces en comparación con la implementación MPI que requiere un gran número de CPUs en un solo momento. Es evidente que la programación de la cuadrícula es beneficiosa especialmente cuando el clúster está fuertemente cargado y el número solicitado de CPUs para el trabajo del MPI no está fácilmente disponible. Escenario II: El clúster está relativamente menos cargado o disponible en gran medida. Parece que la implementación del MPI es favorable en comparación con la programación de la Rejilla. Sin embargo, la paralelización de la aplicación EnKF depende del número de licencias ECLIPSE e idealmente, el número de licencias debe ser igual al número de modelos en el conjunto. Por lo tanto, si una sola institución no tiene suficiente número de licencias, la disponibilidad del clúster no ayuda tanto como se espera. Dado que el entorno colaborativo, como TIGRE, puede abordar tanto los requisitos de computación como los de recursos de software para la aplicación EnKF, el enfoque compatible con Grid sigue siendo ventajoso sobre la implementación MPI convencional en cualquiera de los escenarios anteriores. 5. CONCLUSIONES Y FUTURO TRABAJO TIGRE es un proyecto de desarrollo de la red de educación superior y su propósito es mantener y ampliar las oportunidades de investigación y educación a través de Texas. Dentro del área de aplicación de exploración energética, hemos habilitado la implementación MPI del conjunto Kalman metodología de asimilación de datos de filtro para la caracterización de reservorios. Esta tarea se llevó a cabo eliminando el código MPI para el procesamiento paralelo y reemplazando con trabajos de un solo procesador uno para cada modelo geológico en el conjunto. Estos trabajos de un solo procesador fueron programados a través de TIGRE a través de GridWay metascheduler. Hemos demostrado que mediante la puesta en común de licencias a través de sitios TIGRE, más modelos geológicos pueden ser manejados en paralelo y por lo tanto concebiblemente mejor precisión de simulación. Este enfoque tiene varias ventajas sobre la implementación de MPI, especialmente cuando un clúster específico del sitio está muy cargado y/o las licencias de número requeridas para la simulación son más que las disponibles en un solo sitio. Hacia el trabajo futuro, sería interesante comparar el tiempo de ejecución entre MPI y las implementaciones de Grid para la aplicación EnKF. Este esfuerzo podría arrojar luz sobre la calidad del servicio (QoS) de los entornos Grid en comparación con la computación de clústers. Otro aspecto de interés en un futuro próximo sería la gestión de recursos de computación y licencia para abordar la gestión de la relación trabajo (o procesador)-licencia. 6. OBSERVACIONES Y MENOS APRENDIZADOS Los esfuerzos que facilitan la red para la aplicación EnKF han proporcionado amplias oportunidades para reunir información sobre la visibilidad y la promesa de los entornos de computación de Grid para el desarrollo y soporte de aplicaciones. Los principales problemas son la seguridad de los datos estándar de la industria y la CV comparable a la computación de clústers. Dado que la investigación de modelado de reservorios involucra datos propietarios del campo, tuvimos que invertir esfuerzos sustanciales inicialmente en educar a los investigadores de aplicaciones sobre la capacidad de los servicios de Grid para apoyar la seguridad de datos estándar de la industria a través de acceso basado en roles y privilegios utilizando el estándar X.509. Con respecto a QoS, los investigadores de aplicaciones esperan niveles de QoS con entornos de cuadrícula. Además, hay una curva de aprendizaje pronunciada en la computación de cuadrícula en comparación con la computación de clúster convencional. Dado que la computación de cuadrícula sigue siendo una tecnología emergente, y abarca varios ámbitos administrativos, la computación de cuadrícula sigue siendo prematura, especialmente en términos del nivel de QoS, aunque ofrece mejores normas de seguridad de los datos en comparación con los grupos de productos básicos. Es nuestra observación que los programas de capacitación y divulgación que comparan y contrastan los entornos de computación de red y clúster serían un enfoque adecuado para mejorar la participación de los usuarios en la computación de red. Este enfoque también ayuda a los usuarios a emparejar sus aplicaciones y habilidades que las cuadrículas pueden ofrecer. En resumen, nuestros esfuerzos a través de TIGRE en la metodología de asimilación de datos de la EnKF demostraron una promesa sustancial en la contratación de investigadores de Ingeniería Petrolera a través de colaboraciones entre campus. Se están realizando esfuerzos para lograr la participación de más escuelas en este esfuerzo. Estos esfuerzos pueden resultar en un aumento de la investigación colaborativa, oportunidades educativas y desarrollo de la fuerza laboral a través de programas de investigación de posgrado/facultad en instituciones TIGRE. 7. AGRADECIMIENTOS Los autores reconocen al Estado de Texas por apoyar el proyecto TIGRE a través del Fondo Empresarial de Texas, y a las Instituciones TIGRE por proporcionar el mecanismo, en el que también participan los autores (Ravi Vadapalli, Taesung Kim y Ping Luo). Los autores agradecen a los investigadores de aplicaciones Prof. Akhil Datta-Gupta de Texas A&M University y Prof. Lloyd Heinze de Texas Tech University por sus discusiones e interés en explotar el entorno TIGRE para ampliar las oportunidades en investigación y desarrollo. 8. REFERENCIAS [1] Foster, I. y Kesselman, C. (eds.) 2004. The Grid: Blueprint for a new computing infraestructura (The Elsevier series in Grid computing) [2] Portal TIGRE: http://tigreportal.hipcat.net [3] Vadapalli, R. Sill, A., Dooley, R., Murray, M., Luo, P., Kim, T., Huang, M., Thyagaraja, K., y Chaffin, Demostración del entorno TIGRE para aplicaciones de cuadrícula habilitadas/adecuadas. 8o IEEE/ACM Int. Conf. on Grid Computing, 19-21 de septiembre, Austin [4] The High Performance Computing cross Texas Consortium http://www.hipcat.net [5] Pordes, R. Petravick, D. Kramer, B. Olson, D. Livny, M. Roy, A. Avery, P. Blackburn, K. Wenaus, T. Würthwein, F. Foster, I. Gar The Open Science Grid, J. Phys Conf Series http://www.iop.org/EJ/abstract/1742-6596/78/1/012057 y http://www.opensciencegrid.org [6] Reed, D.A. 2003. Rejilla, el Teragrid y más allá, Ordenador, vol. 30, no. 1 y http://www.teragrid.org [7] Evensen, G. 2006. Asimilación de datos: El conjunto Kalman Filter, Springer [8] Herrera, J. Huedo, E. Montero, R. S. y Llorente, I. M. 2005. Programación Científica, vol 12, No. 4. pp 317-331 [9] Avery, P. and Foster, I. 2001. El proyecto GriPhyN: Hacia redes virtuales de datos a petaescala, informe técnico GriPhyN-200115 y http://vdt.cs.wisc.edu [10] La guía de documentación e instalación de PacMan http://physics.bu.edu/pacman/htmls [11] Caskey, P. Murray, M. Perez, J. y Sill, A. 2007. Estudios de casos en la gestión de identificación para organizaciones virtuales, EDUCOUSO Southwest Reg. Conf., 21-23 febrero, Austin, TX. http://www.educause.edu/ir/library/pdf/SWR07058.pdf [12] El Sistema de Gestión de Usuarios de Grid (GUMS) https://www.racf.bnl.gov/Facility/GUMS/index.html [13] Thomas, M. y Boisseau, J. 2003. Construyendo portales de computación de cuadrículas: El kit de herramientas para el portal de cuadrículas NPACI, Grid computing: haciendo realidad la infraestructura global, Capítulo 28, Berman, F. Fox, G. Thomas, M. Boisseau, J. y Hey, T. (eds), John Wiley and Sons, Ltd, Chichester [14] Open Ticket Request System http:// 1999. Integración de datos dinámicos en modelos de depósito de alta resolución utilizando coeficientes de sensibilidad basados en la racionalización, Society of Petroleum Engineers (SPE), 4 (4). [17] Emanuel, A. S. y Milliken, W. J. 1998. Historia que combina modelos de diferencias finitas con racionalizaciones 3D, SPE 49000, Proc de la Conf Técnica Anual y Exposición, 2730 de septiembre, Nueva Orleans, LA. [18] Nævdal, G. Johnsen, L.M. Aanonsen, S.I. y Vefring, E.H. 2003. Monitorización de embalses y actualización continua de modelos utilizando Ensemble Kalman Filter, SPE 84372, Proc del Conf Técnico Anual y Exposición, Oct 5-8, Denver, CO. [19] Jafarpour B. y McLaughlin, D.B. 2007. Historia que coincide con un conjunto de filtro Kalman y parametrización discreta de coseno, SPE 108761, Proc de la Conf Técnica Anual y Exposición, 11-14 de noviembre, Anaheim, CA [20] Li, G. y Reynolds, A. C. 2007. Un conjunto iterativo Kalman filtro para la asimilación de datos, SPE 109808, Proc de la SPE Conf y Exposición Técnica Anual, 11-14 de noviembre, Anaheim, CA [21] Arroyo-Negrete, E. Devagowda, D. Datta-Gupta, A. 2006. Simplificar el conjunto asistido Kalman filtro para la actualización rápida y continua del modelo de depósito. Proc de la Int. Oil & Gas Conf and Exhibition, SPE 104255, Dec 5-7, China [22] ECLIPSE Reservoir Engineering Software http://www.slb.com/content/services/software/reseng/index.a sp ",
            "error": [
                ""
            ]
        },
        "tigre": {
            "translated_key": [],
            "translated_annotated_text": "Demostración del conjunto de datos de Kalman Assimulation Method for Reservoir Caracterisation Ravi Vadapalli Centro de computación de alto rendimiento Texas Tech University Lubbock, TX 79409 001-806-742-4350 Ravi.Vadapalli@ttu.edu Ajitabh Kumar Department of Petroleum Engineering Texas A&M University College Station, En este enfoque, se utiliza un conjunto de modelos geológicos y datos de producción de yacimientos de petróleo para predecir la respuesta dinámica de los pozos de petróleo. El software Schlumberger ECLIPSE se utiliza para estas simulaciones. Puesto que los modelos en el conjunto no se comunican, la implementación de mensaje-passing es una buena opción. Cada modelo comprueba una licencia ECLIPSE y, por lo tanto, la paralelización de las simulaciones de reservorio depende de las licencias de número disponibles. Hemos habilitado Grid para el conjunto Kalman metodología de asimilación de datos de filtro para el entorno de computación TIGRE Grid. Al poner en común las licencias y los recursos informáticos en todas las instituciones colaboradoras utilizando el metaprogramador GridWay y el entorno TIGRE, la precisión computacional puede aumentarse al tiempo que se reduce el tiempo de ejecución de la simulación. En este artículo, proporcionamos un relato de nuestros esfuerzos en Gridenabilizar el conjunto Kalman Filter metodología de asimilación de datos. Se examinarán los posibles beneficios de este enfoque, las observaciones y la experiencia adquirida. Categorías y Descriptores sujetos C 2.4 [Sistemas distribuidos]: Aplicaciones distribuidas Términos generales Algoritmos, Diseño, Rendimiento 1. INTRODUCCIÓN La computación de cuadrícula [1] es un paradigma de computación colaborativa emergente para ampliar las capacidades específicas de computación de alto rendimiento (HPC) mucho más allá de los recursos locales. Su importancia se deriva del hecho de que la investigación innovadora en áreas de aplicación estratégicas como la biociencia y la medicina, la exploración de energía y el modelado ambiental involucran componentes interdisciplinarios fuertes y a menudo requieren colaboraciones intercampus y capacidades computacionales más allá de las limitaciones institucionales. The Texas Internet Grid for Research and Education (TIGRE) [2,3] es un proyecto de desarrollo de infraestructuras cibernéticas financiado por el estado, llevado a cabo por cinco grandes sistemas universitarios (Rice, A&M, TTU, UH y UT Austin), llamados colectivamente Instituciones TIGRE. El propósito de TIGRE es crear una red de educación superior para sostener y ampliar las oportunidades de investigación y educación en Texas. TIGRE es un proyecto del consorcio de computación de alto rendimiento en Texas (HiPCAT) [4]. El objetivo de HiPCAT es apoyar tecnologías computacionales avanzadas para mejorar la investigación, el desarrollo y las actividades educativas. El objetivo principal de TIGRE es diseñar e implementar middleware Grid de última generación que permita la integración de sistemas de computación, sistemas de almacenamiento y bases de datos, laboratorios de visualización y pantallas, e incluso instrumentos y sensores en Texas. El objetivo secundario es demostrar las capacidades de TIGRE para mejorar las oportunidades de investigación y educación en áreas de aplicación estratégica de interés para el Estado de Texas. Estos son biociencia y medicina, exploración energética y modelado de la calidad del aire. La visión del proyecto TIGRE es fomentar la colaboración interdisciplinaria e intercampus, identificar enfoques novedosos para ampliar las asociaciones académicas, gubernamentales y privadas, y convertirse en un modelo competitivo para las oportunidades de financiación externa. El objetivo general de TIGRE es apoyar los intereses de los usuarios locales, universitarios y regionales y ofrecer vías para conectar con proyectos nacionales de Red como Open Science Grid [5] y TeraGrid [6]. Dentro del área de aplicación estratégica de exploración energética, hemos habilitado el enfoque conjunto Kalman Filter (EnKF) [7] para la asimilación de datos en el modelado de reservorios y hemos demostrado la extensibilidad de la aplicación utilizando el entorno TIGRE y el metaprogramador GridWay [8]. En la sección 2 se ofrece una visión general del entorno y las capacidades de TIGRE. La descripción de la aplicación y la necesidad de una metodología EnKF compatible con la cuadrícula figuran en la sección 3. Los detalles de la aplicación y los méritos de nuestro enfoque se examinan en la sección 4. Las conclusiones figuran en la sección 5. Por último, en la sección 6 se documentan las observaciones y la experiencia adquirida. 2. TIGRE ENTORNO El MIddleware TIGRE Grid consiste en un conjunto mínimo de componentes derivados de un subconjunto del Virtual Data Toolkit (VDT) [9] que soporta una variedad de sistemas operativos. El propósito de elegir una pila de software mínima es apoyar las aplicaciones disponibles y simplificar la instalación y distribución de las pilas cliente/servidor en los sitios de TIGRE. Se añadirán componentes adicionales a medida que sean necesarios. El mecanismo de packaging y distribución PacMan [10] se emplea para la instalación y gestión del cliente/servidor TIGRE. El mecanismo de distribución de PacMan implica la recuperación, instalación y a menudo configuración del software empaquetado. Este enfoque permite a los clientes mantener versiones actualizadas y consistentes del software TIGRE. También ayuda a los sitios TIGRE a instalar los componentes necesarios en los recursos distribuidos en los sitios participantes. La pila cliente/servidor TIGRE consiste en una capa de autenticación y autorización, Globus GRAM4-basada en la presentación de trabajos a través de servicios web (las instalaciones de servicios pre-web están disponibles bajo petición). Las herramientas para manejar la generación de proxy de cuadrícula, la transferencia de archivos habilitada para cuadrícula y el inicio de sesión remoto habilitado para cuadrícula son compatibles. A continuación se proporcionan los detalles pertinentes de los servicios y herramientas de TIGRE para la programación y gestión de puestos. 2.1. Autoridad certificadora La infraestructura de seguridad TIGRE incluye una autoridad certificadora (CA) acreditada por la International Grid Trust Federation (IGTF) para emitir X. 509 certificados de usuario y recurso Grid [11]. El Texas Advanced Computing Center (TACC), Universidad de Texas en Austin, es el TIGREs CA compartido. Las instituciones de TIGRE actúan como autoridades de registro (RA) para sus respectivas bases de usuarios locales. Para obtener información actualizada sobre la seguridad de los certificados de usuario y de recursos y sus instrucciones de instalación, véase ref [2]. Los usuarios y hosts de TIGRE son identificados por su distinguido nombre (DN) en su certificado X.509 proporcionado por la CA. Un archivo nativo Grid-mapfile que contiene una lista de DNs autorizados se utiliza para autenticar y autorizar la programación y gestión de trabajos de los usuarios en los recursos del sitio TIGRE. En la Universidad Texas Tech, a los usuarios se les asigna dinámicamente una de las muchas cuentas genéricas. Esto se logra a través del Sistema de Gestión de Usuarios de Red (GUMS) [12]. 2.2. Programación y gestión de empleos El entorno TIGRE apoya la presentación de trabajos basada en GRAM4 a través de servicios web. Los scripts de envío de trabajos se generan usando XML. Los servicios web GRAM traducen los scripts XML en programadores de lotes específicos de grupos de destino como LSF, PBS o SGE. Los protocolos de transferencia de archivos de alto ancho de banda como GridFTP se utilizan para estadificación de archivos dentro y fuera de la máquina de destino. El acceso a hosts remotos para compilar y depurar es sólo a través del servicio GSISSH que requiere autenticación de recursos a través de certificados X.509. La autenticación y autorización de los trabajos de Grid se gestionan mediante la emisión de certificados de Grid a usuarios y anfitriones. Las listas de revocación de certificados (CRL) se actualizan diariamente para mantener altos estándares de seguridad de los servicios de TIGRE Grid. El área de documentación del portal TIGRE [2] proporciona un tutorial de inicio rápido sobre cómo ejecutar trabajos en TIGRE. 2.3. Metascheduler El metascheduler interopera con los programadores de lotes de nivel de cluster (como LSF, PBS) en la gestión general del flujo de trabajo de Grid. En el presente trabajo, hemos empleado el metaprogramador GridWay [8] -un proyecto de incubadora Globus- para programar y gestionar trabajos en TIGRE. El GridWay es un metaprogramador ligero que utiliza plenamente las funcionalidades de Globus. Está diseñado para proporcionar un uso eficiente de los recursos dinámicos de Grid por múltiples usuarios para las infraestructuras de Grid construidas sobre los servicios de Globus. El administrador del sitio TIGRE puede controlar el uso compartido de recursos a través de un potente programador integrado proporcionado por GridWay o ampliando el módulo de programación externa GridWays para proporcionar sus propias políticas de programación. Los usuarios de aplicaciones pueden escribir descripciones de trabajos usando el formato de plantilla de trabajo simple y directo de GridWays (ver Sección 4 para más detalles) o el lenguaje estándar de descripción de la presentación de trabajos (JSDL). Para más detalles sobre la aplicación, véase la sección 4. 2.4. Sistema de Gestión de Servicios al Cliente Un portal TIGRE [2] fue diseñado e implementado para interconectar usuarios y proveedores de recursos. Fue diseñado utilizando GridPort [13] y es mantenido por TACC. El entorno TIGRE es compatible con herramientas de código abierto como el Open Ticket Request System (OTRS) [14] para el servicio de tickets de problemas, y MoinMoin [15] Wiki para la gestión de contenido y conocimiento de TIGRE para educación, extensión y capacitación. Los enlaces para OTRS y Wiki son consumidos por el portal TIGRE [2] - el portal para usuarios y proveedores de recursos. El estado y las cargas de los recursos de TIGRE son monitoreados por el servicio de Repositorio de Información de Puertos Grid (GPIR) del kit de herramientas GridPort [13] que interactúa con el servicio local de monitoreo de carga de clústeres como Ganglia. El GPIR utiliza trabajos de cron en cada recurso para reunir características específicas de los recursos del sitio, tales como trabajos que se ejecutan, en cola y esperando la asignación de recursos. 3. APLICACIÓN ENSEMBLE KALMAN FILTER El objetivo principal de las simulaciones de yacimientos de hidrocarburos es predecir el comportamiento de la producción de yacimientos de petróleo y gas (denominados en lo sucesivo campo) para su desarrollo y gestión óptima. En el modelado de yacimientos, el campo se divide en varios modelos geológicos, como se muestra en la Figura 1. Para una previsión precisa del rendimiento del campo, es necesario conciliar varios modelos geológicos con la respuesta dinámica del campo a través de la coincidencia histórica [16-20]. Gráfico 1 Vista transversal del Campo. Las capas verticales corresponden a diferentes modelos geológicos y los clavos son pozos de aceite cuya información histórica se utilizará para predecir el comportamiento de la producción. (Figura Ref:http://faculty.smu.edu/zchen/research.html). El EnKF es un método de Monte Carlo que trabaja con un conjunto de modelos de embalses. Este método utiliza covarianzas cruzadas [21] entre las mediciones de campo y los parámetros del modelo de reservorio (derivados de varios modelos) para estimar las incertidumbres de predicción. Los parámetros del modelo geológico en el conjunto se actualizan secuencialmente con el objetivo de minimizar las incertidumbres de predicción. La respuesta histórica de la producción del campo durante más de 50 años se utiliza en estas simulaciones. La principal ventaja de EnKF es que puede vincularse fácilmente a cualquier simulador de depósito, y puede asimilar los últimos datos de producción sin necesidad de volver a ejecutar el simulador desde las condiciones iniciales. Investigadores en Texas son grandes suscriptores del paquete de Schlumberger ECLIPSE [22] para simulaciones de reservorios. En el modelado del embalse, cada modelo geológico comprueba una licencia ECLIPSE. La duración de la simulación de la metodología EnKF depende del número de modelos geológicos utilizados, el número de licencias ECLIPSE disponibles, la historia de producción del campo y las incertidumbres propagadas en la correspondencia de la historia. El flujo de trabajo general de EnKF se muestra en la Figura 2. Gráfico 2 Ensemble Kaman Filter Data Assimulation Workflow. Cada sitio tiene licencias L. En START, el proceso maestro/control (programa principal EnKF) lee el archivo de configuración de simulación para el número (N) de modelos y archivos de entrada específicos del modelo. A continuación, N directorios de trabajo se crean para almacenar los archivos de salida. Al final de la iteración, el proceso maestro/control recoge los archivos de salida de los modelos N y las crosscovarianzas de los procesos posteriores [21] para estimar las incertidumbres de predicción. Esta información se utilizará para actualizar modelos (o archivos de entrada) para la siguiente iteración. La simulación continúa hasta agotar las historias de producción. La simulación típica de EnKF con N=50 y historias de campo de 50-60 años, en pasos de tiempo que van de tres meses a un año, toma unas tres semanas en un entorno de computación en serie. En el entorno informático paralelo, no hay comunicación interproceso entre los modelos geológicos en el conjunto. Sin embargo, al final de cada paso del tiempo de simulación, los archivos de salida específicos del modelo deben ser recogidos para analizar covarianzas cruzadas [21] y para preparar el siguiente conjunto de archivos de entrada. Por lo tanto, el modelo maestro-esclavo en el entorno de mensajepassing (MPI) es un paradigma adecuado. En este enfoque, los modelos geológicos son tratados como esclavos y se distribuyen entre los procesadores disponibles. El master Cluster o (TIGRE/GridWay) START Read Configuration File Create N Working Directories Create N Input files Model l Model 2 Model N.. . ECLIPSE in situ Un ECLIPSE in situ B ECLIPSE in situ Z Collect N Model Outputs, Post-process Output files FIN. . . proceso recoge archivos de salida específicos del modelo, analiza y prepara el siguiente conjunto de archivos de entrada para la simulación. Dado que cada modelo geológico comprueba una licencia ECLIPSE, la paralelización de la simulación depende del número de licencias disponibles. Cuando el número de licencias disponible es menor que el número de modelos en el conjunto, uno o más de los nodos del grupo MPI tienen que manejar más de un modelo en serie y, por lo tanto, se tarda más tiempo en completar la simulación. Un Departamento de Ingeniería Petrolera generalmente adquiere 10-15 licencias ECLIPSE, mientras que al menos diez veces más número de licencias sería necesario para simulaciones estándar de la industria. El número de licencias puede incrementarse con la participación de varios departamentos de ingeniería petrolera que apoyan el paquete ECLIPSE. Dado que MPI no se escala muy bien para aplicaciones que involucran clústeres de computación remotos, y para evitar los problemas del firewall con servidores de licencias en todos los dominios administrativos, parece necesario activar el flujo de trabajo de EnKF. Con esta motivación, hemos implementado el flujo de trabajo EnKF habilitado para Grid para el entorno TIGRE y hemos demostrado la paralelización de la aplicación a través de TIGRE usando el metascheduler GridWay. En la siguiente sección figuran más detalles al respecto. 4. DETALLES DE APLICACION Para habilitar Grid-enable el enfoque EnKF, hemos eliminado el código MPI para el procesamiento paralelo y reemplazado por trabajos de N monoprocesador (o sub-trabajos) donde, N es el número de modelos geológicos en el conjunto. Estos sub-trabajos específicos de modelos se distribuyeron a través de sitios TIGRE que soportan el paquete ECLIPSE utilizando el metaprogramador GridWay [8]. Para cada sub-trabajo, hemos construido una plantilla de trabajo GridWay que especifica los archivos ejecutables, de entrada y salida, y los requisitos de recursos. Dado que los recursos de cálculo de TIGRE no se espera que cambien con frecuencia, hemos utilizado la política de descubrimiento de recursos estáticos para GridWay y los sub-trabajos fueron programados dinámicamente a través de los recursos de TIGRE usando GridWay. La Figura 3 representa el archivo de plantilla de subtrabajo para el metaprogramador GridWay. Gráfico 3 Plantilla de subtrabajo GridWay En la Figura 3, REQUISITOS bandera se establece para elegir los recursos que satisfacen los requisitos de la aplicación. En el caso de la aplicación EnKF, por ejemplo, necesitamos recursos que apoyen el paquete ECLIPSE. ARGUMENTS flag especifica el modelo en el conjunto que invocará ECLIPSE en un sitio remoto. INPUT_FILES es preparado por el programa principal de EnKF (o proceso maestro/control) y es transferido por GridWay al sitio remoto donde está desatendido y está preparado para su ejecución. Finalmente, OUTPUT_FILES especifica el nombre y la ubicación donde se escribirán los archivos de salida. Las características de la línea de comandos de GridWay se utilizaron para recopilar y procesar las salidas específicas del modelo para preparar un nuevo conjunto de archivos de entrada. Este paso imita la sincronización del proceso MPI en el modelo maestro-esclavo. Al final de cada iteración, los recursos computacionales y las licencias se devuelven al grupo. La Tabla 1 muestra los sub-trabajos en TIGRE Grid via GridWay usando el comando gwps y para mayor claridad, sólo se mostraron las columnas seleccionadas. USUARIO JID DM EM NOMBRE HOST pingluo 88 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 89 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 90 wrap actv enkf.jt minigar.hp Programación de trabajo a través de TIGRE usando GridWay Metascheduler. DM: Estado de envío, EM: Estado de ejecución, JID es el id de trabajo y HOST corresponde al cluster específico del sitio y su planificador de lotes local. Cuando un trabajo es enviado a GridWay, pasará por una serie de estados de envío (DM) y ejecución (EM). Para DM, los estados incluyen pend(ing), prol(og), wrap(per), epil(og), y hecho. DM=prol significa que el trabajo ha sido programado a un recurso y el directorio de trabajo remoto está en preparación. DM=warp implica que GridWay está ejecutando el envoltorio que a su vez ejecuta la aplicación. DM=epil implica que el trabajo ha terminado de ejecutarse en el sitio remoto y los resultados se están transfiriendo al servidor GridWay. Del mismo modo, cuando EM=pend implica que el trabajo está esperando en la cola para el recurso y el trabajo se está ejecutando cuando EM=actv. Para ver la lista completa de las banderas de mensajes y sus descripciones, consulte la documentación en ref [8]. Hemos demostrado las ejecuciones de EnKF habilitadas para Grid usando GridWay para entorno TIGRE. Los trabajos son tan elegidos que el tiempo de ejecución no supera más de media hora. La simulación incluyó hasta 20 trabajos entre sitios de A&M y TTU con TTU cumpliendo 10 licencias. Para obtener información sobre los recursos, véase el cuadro I. Una de las principales ventajas de la simulación EnKF habilitada por Grid es que tanto los recursos como las licencias se devuelven al grupo al final de cada paso del tiempo de simulación a diferencia del caso de la implementación de MPI donde las licencias y nodos están bloqueados hasta la finalización de la simulación completa. Sin embargo, el hecho de que cada sub-trabajo se programe independientemente a través de GridWay podría posiblemente incurrir en otro retraso de tiempo causado por esperar en la cola para la ejecución en cada paso del tiempo de simulación. Tales retrasos no se esperan EXECUTABLE=runFORWARD NECESIDADES=HOSTNAME=cosmos.tamu.edu  HOSTNAME=antaeus.hpcc.ttu.edu  HOSTNAME=minigar.hpcc.ttu.edu  ARGUMENTOS=001 INPUT_FILES=001.in.tar OUTPUT_FI Hay dos escenarios principales para comparar los enfoques de computación de red y clúster. Escenario I: El cúmulo está muy cargado. El tiempo promedio de espera concebido del trabajo que solicita un gran número de CPUs es generalmente más largo que el tiempo de espera de los trabajos que solicitan una sola CPU. Por lo tanto, el tiempo de espera general podría ser más corto en el enfoque Grid que solicita una sola CPU para cada sub-trabajo muchas veces en comparación con la implementación MPI que requiere un gran número de CPUs en un solo momento. Es evidente que la programación de la cuadrícula es beneficiosa especialmente cuando el clúster está fuertemente cargado y el número solicitado de CPUs para el trabajo del MPI no está fácilmente disponible. Escenario II: El clúster está relativamente menos cargado o disponible en gran medida. Parece que la implementación del MPI es favorable en comparación con la programación de la Rejilla. Sin embargo, la paralelización de la aplicación EnKF depende del número de licencias ECLIPSE e idealmente, el número de licencias debe ser igual al número de modelos en el conjunto. Por lo tanto, si una sola institución no tiene suficiente número de licencias, la disponibilidad del clúster no ayuda tanto como se espera. Dado que el entorno colaborativo, como TIGRE, puede abordar tanto los requisitos de computación como los de recursos de software para la aplicación EnKF, el enfoque compatible con Grid sigue siendo ventajoso sobre la implementación MPI convencional en cualquiera de los escenarios anteriores. 5. CONCLUSIONES Y FUTURO TRABAJO TIGRE es un proyecto de desarrollo de la red de educación superior y su propósito es mantener y ampliar las oportunidades de investigación y educación a través de Texas. Dentro del área de aplicación de exploración energética, hemos habilitado la implementación MPI del conjunto Kalman metodología de asimilación de datos de filtro para la caracterización de reservorios. Esta tarea se llevó a cabo eliminando el código MPI para el procesamiento paralelo y reemplazando con trabajos de un solo procesador uno para cada modelo geológico en el conjunto. Estos trabajos de un solo procesador fueron programados a través de TIGRE a través de GridWay metascheduler. Hemos demostrado que mediante la puesta en común de licencias a través de sitios TIGRE, más modelos geológicos pueden ser manejados en paralelo y por lo tanto concebiblemente mejor precisión de simulación. Este enfoque tiene varias ventajas sobre la implementación de MPI, especialmente cuando un clúster específico del sitio está muy cargado y/o las licencias de número requeridas para la simulación son más que las disponibles en un solo sitio. Hacia el trabajo futuro, sería interesante comparar el tiempo de ejecución entre MPI y las implementaciones de Grid para la aplicación EnKF. Este esfuerzo podría arrojar luz sobre la calidad del servicio (QoS) de los entornos Grid en comparación con la computación de clústers. Otro aspecto de interés en un futuro próximo sería la gestión de recursos de computación y licencia para abordar la gestión de la relación trabajo (o procesador)-licencia. 6. OBSERVACIONES Y MENOS APRENDIZADOS Los esfuerzos que facilitan la red para la aplicación EnKF han proporcionado amplias oportunidades para reunir información sobre la visibilidad y la promesa de los entornos de computación de Grid para el desarrollo y soporte de aplicaciones. Los principales problemas son la seguridad de los datos estándar de la industria y la CV comparable a la computación de clústers. Dado que la investigación de modelado de reservorios involucra datos propietarios del campo, tuvimos que invertir esfuerzos sustanciales inicialmente en educar a los investigadores de aplicaciones sobre la capacidad de los servicios de Grid para apoyar la seguridad de datos estándar de la industria a través de acceso basado en roles y privilegios utilizando el estándar X.509. Con respecto a QoS, los investigadores de aplicaciones esperan niveles de QoS con entornos de cuadrícula. Además, hay una curva de aprendizaje pronunciada en la computación de cuadrícula en comparación con la computación de clúster convencional. Dado que la computación de cuadrícula sigue siendo una tecnología emergente, y abarca varios ámbitos administrativos, la computación de cuadrícula sigue siendo prematura, especialmente en términos del nivel de QoS, aunque ofrece mejores normas de seguridad de los datos en comparación con los grupos de productos básicos. Es nuestra observación que los programas de capacitación y divulgación que comparan y contrastan los entornos de computación de red y clúster serían un enfoque adecuado para mejorar la participación de los usuarios en la computación de red. Este enfoque también ayuda a los usuarios a emparejar sus aplicaciones y habilidades que las cuadrículas pueden ofrecer. En resumen, nuestros esfuerzos a través de TIGRE en la metodología de asimilación de datos de la EnKF demostraron una promesa sustancial en la contratación de investigadores de Ingeniería Petrolera a través de colaboraciones entre campus. Se están realizando esfuerzos para lograr la participación de más escuelas en este esfuerzo. Estos esfuerzos pueden resultar en un aumento de la investigación colaborativa, oportunidades educativas y desarrollo de la fuerza laboral a través de programas de investigación de posgrado/facultad en instituciones TIGRE. 7. AGRADECIMIENTOS Los autores reconocen al Estado de Texas por apoyar el proyecto TIGRE a través del Fondo Empresarial de Texas, y a las Instituciones TIGRE por proporcionar el mecanismo, en el que también participan los autores (Ravi Vadapalli, Taesung Kim y Ping Luo). Los autores agradecen a los investigadores de aplicaciones Prof. Akhil Datta-Gupta de Texas A&M University y Prof. Lloyd Heinze de Texas Tech University por sus discusiones e interés en explotar el entorno TIGRE para ampliar las oportunidades en investigación y desarrollo. 8. REFERENCIAS [1] Foster, I. y Kesselman, C. (eds.) 2004. The Grid: Blueprint for a new computing infraestructura (The Elsevier series in Grid computing) [2] Portal TIGRE: http://tigreportal.hipcat.net [3] Vadapalli, R. Sill, A., Dooley, R., Murray, M., Luo, P., Kim, T., Huang, M., Thyagaraja, K., y Chaffin, Demostración del entorno TIGRE para aplicaciones de cuadrícula habilitadas/adecuadas. 8o IEEE/ACM Int. Conf. on Grid Computing, 19-21 de septiembre, Austin [4] The High Performance Computing cross Texas Consortium http://www.hipcat.net [5] Pordes, R. Petravick, D. Kramer, B. Olson, D. Livny, M. Roy, A. Avery, P. Blackburn, K. Wenaus, T. Würthwein, F. Foster, I. Gar The Open Science Grid, J. Phys Conf Series http://www.iop.org/EJ/abstract/1742-6596/78/1/012057 y http://www.opensciencegrid.org [6] Reed, D.A. 2003. Rejilla, el Teragrid y más allá, Ordenador, vol. 30, no. 1 y http://www.teragrid.org [7] Evensen, G. 2006. Asimilación de datos: El conjunto Kalman Filter, Springer [8] Herrera, J. Huedo, E. Montero, R. S. y Llorente, I. M. 2005. Programación Científica, vol 12, No. 4. pp 317-331 [9] Avery, P. and Foster, I. 2001. El proyecto GriPhyN: Hacia redes virtuales de datos a petaescala, informe técnico GriPhyN-200115 y http://vdt.cs.wisc.edu [10] La guía de documentación e instalación de PacMan http://physics.bu.edu/pacman/htmls [11] Caskey, P. Murray, M. Perez, J. y Sill, A. 2007. Estudios de casos en la gestión de identificación para organizaciones virtuales, EDUCOUSO Southwest Reg. Conf., 21-23 febrero, Austin, TX. http://www.educause.edu/ir/library/pdf/SWR07058.pdf [12] El Sistema de Gestión de Usuarios de Grid (GUMS) https://www.racf.bnl.gov/Facility/GUMS/index.html [13] Thomas, M. y Boisseau, J. 2003. Construyendo portales de computación de cuadrículas: El kit de herramientas para el portal de cuadrículas NPACI, Grid computing: haciendo realidad la infraestructura global, Capítulo 28, Berman, F. Fox, G. Thomas, M. Boisseau, J. y Hey, T. (eds), John Wiley and Sons, Ltd, Chichester [14] Open Ticket Request System http:// 1999. Integración de datos dinámicos en modelos de depósito de alta resolución utilizando coeficientes de sensibilidad basados en la racionalización, Society of Petroleum Engineers (SPE), 4 (4). [17] Emanuel, A. S. y Milliken, W. J. 1998. Historia que combina modelos de diferencias finitas con racionalizaciones 3D, SPE 49000, Proc de la Conf Técnica Anual y Exposición, 2730 de septiembre, Nueva Orleans, LA. [18] Nævdal, G. Johnsen, L.M. Aanonsen, S.I. y Vefring, E.H. 2003. Monitorización de embalses y actualización continua de modelos utilizando Ensemble Kalman Filter, SPE 84372, Proc del Conf Técnico Anual y Exposición, Oct 5-8, Denver, CO. [19] Jafarpour B. y McLaughlin, D.B. 2007. Historia que coincide con un conjunto de filtro Kalman y parametrización discreta de coseno, SPE 108761, Proc de la Conf Técnica Anual y Exposición, 11-14 de noviembre, Anaheim, CA [20] Li, G. y Reynolds, A. C. 2007. Un conjunto iterativo Kalman filtro para la asimilación de datos, SPE 109808, Proc de la SPE Conf y Exposición Técnica Anual, 11-14 de noviembre, Anaheim, CA [21] Arroyo-Negrete, E. Devagowda, D. Datta-Gupta, A. 2006. Simplificar el conjunto asistido Kalman filtro para la actualización rápida y continua del modelo de depósito. Proc de la Int. Oil & Gas Conf and Exhibition, SPE 104255, Dec 5-7, China [22] ECLIPSE Reservoir Engineering Software http://www.slb.com/content/services/software/reseng/index.a sp ",
            "error": []
        },
        "and gridway": {
            "translated_key": [],
            "translated_annotated_text": "Demostración del conjunto de datos de Kalman Assimulation Method for Reservoir Caracterisation Ravi Vadapalli Centro de computación de alto rendimiento Texas Tech University Lubbock, TX 79409 001-806-742-4350 Ravi.Vadapalli@ttu.edu Ajitabh Kumar Department of Petroleum Engineering Texas A&M University College Station, En este enfoque, se utiliza un conjunto de modelos geológicos y datos de producción de yacimientos de petróleo para predecir la respuesta dinámica de los pozos de petróleo. El software Schlumberger ECLIPSE se utiliza para estas simulaciones. Puesto que los modelos en el conjunto no se comunican, la implementación de mensaje-passing es una buena opción. Cada modelo comprueba una licencia ECLIPSE y, por lo tanto, la paralelización de las simulaciones de reservorio depende de las licencias de número disponibles. Hemos habilitado Grid para el conjunto Kalman metodología de asimilación de datos de filtro para el entorno de computación TIGRE Grid. Al poner en común las licencias y los recursos informáticos en todas las instituciones colaboradoras utilizando el metaprogramador GridWay y el entorno TIGRE, la precisión computacional puede aumentarse al tiempo que se reduce el tiempo de ejecución de la simulación. En este artículo, proporcionamos un relato de nuestros esfuerzos en Gridenabilizar el conjunto Kalman Filter metodología de asimilación de datos. Se examinarán los posibles beneficios de este enfoque, las observaciones y la experiencia adquirida. Categorías y Descriptores sujetos C 2.4 [Sistemas distribuidos]: Aplicaciones distribuidas Términos generales Algoritmos, Diseño, Rendimiento 1. INTRODUCCIÓN La computación de cuadrícula [1] es un paradigma de computación colaborativa emergente para ampliar las capacidades específicas de computación de alto rendimiento (HPC) mucho más allá de los recursos locales. Su importancia se deriva del hecho de que la investigación innovadora en áreas de aplicación estratégicas como la biociencia y la medicina, la exploración de energía y el modelado ambiental involucran componentes interdisciplinarios fuertes y a menudo requieren colaboraciones intercampus y capacidades computacionales más allá de las limitaciones institucionales. The Texas Internet Grid for Research and Education (TIGRE) [2,3] es un proyecto de desarrollo de infraestructuras cibernéticas financiado por el estado, llevado a cabo por cinco grandes sistemas universitarios (Rice, A&M, TTU, UH y UT Austin), llamados colectivamente Instituciones TIGRE. El propósito de TIGRE es crear una red de educación superior para sostener y ampliar las oportunidades de investigación y educación en Texas. TIGRE es un proyecto del consorcio de computación de alto rendimiento en Texas (HiPCAT) [4]. El objetivo de HiPCAT es apoyar tecnologías computacionales avanzadas para mejorar la investigación, el desarrollo y las actividades educativas. El objetivo principal de TIGRE es diseñar e implementar middleware Grid de última generación que permita la integración de sistemas de computación, sistemas de almacenamiento y bases de datos, laboratorios de visualización y pantallas, e incluso instrumentos y sensores en Texas. El objetivo secundario es demostrar las capacidades de TIGRE para mejorar las oportunidades de investigación y educación en áreas de aplicación estratégica de interés para el Estado de Texas. Estos son biociencia y medicina, exploración energética y modelado de la calidad del aire. La visión del proyecto TIGRE es fomentar la colaboración interdisciplinaria e intercampus, identificar enfoques novedosos para ampliar las asociaciones académicas, gubernamentales y privadas, y convertirse en un modelo competitivo para las oportunidades de financiación externa. El objetivo general de TIGRE es apoyar los intereses de los usuarios locales, universitarios y regionales y ofrecer vías para conectar con proyectos nacionales de Red como Open Science Grid [5] y TeraGrid [6]. Dentro del área de aplicación estratégica de exploración energética, hemos habilitado el enfoque conjunto Kalman Filter (EnKF) [7] para la asimilación de datos en el modelado de reservorios y hemos demostrado la extensibilidad de la aplicación utilizando el entorno TIGRE y el metaprogramador GridWay [8]. En la sección 2 se ofrece una visión general del entorno y las capacidades de TIGRE. La descripción de la aplicación y la necesidad de una metodología EnKF compatible con la cuadrícula figuran en la sección 3. Los detalles de la aplicación y los méritos de nuestro enfoque se examinan en la sección 4. Las conclusiones figuran en la sección 5. Por último, en la sección 6 se documentan las observaciones y la experiencia adquirida. 2. TIGRE ENTORNO El MIddleware TIGRE Grid consiste en un conjunto mínimo de componentes derivados de un subconjunto del Virtual Data Toolkit (VDT) [9] que soporta una variedad de sistemas operativos. El propósito de elegir una pila de software mínima es apoyar las aplicaciones disponibles y simplificar la instalación y distribución de las pilas cliente/servidor en los sitios de TIGRE. Se añadirán componentes adicionales a medida que sean necesarios. El mecanismo de packaging y distribución PacMan [10] se emplea para la instalación y gestión del cliente/servidor TIGRE. El mecanismo de distribución de PacMan implica la recuperación, instalación y a menudo configuración del software empaquetado. Este enfoque permite a los clientes mantener versiones actualizadas y consistentes del software TIGRE. También ayuda a los sitios TIGRE a instalar los componentes necesarios en los recursos distribuidos en los sitios participantes. La pila cliente/servidor TIGRE consiste en una capa de autenticación y autorización, Globus GRAM4-basada en la presentación de trabajos a través de servicios web (las instalaciones de servicios pre-web están disponibles bajo petición). Las herramientas para manejar la generación de proxy de cuadrícula, la transferencia de archivos habilitada para cuadrícula y el inicio de sesión remoto habilitado para cuadrícula son compatibles. A continuación se proporcionan los detalles pertinentes de los servicios y herramientas de TIGRE para la programación y gestión de puestos. 2.1. Autoridad certificadora La infraestructura de seguridad TIGRE incluye una autoridad certificadora (CA) acreditada por la International Grid Trust Federation (IGTF) para emitir X. 509 certificados de usuario y recurso Grid [11]. El Texas Advanced Computing Center (TACC), Universidad de Texas en Austin, es el TIGREs CA compartido. Las instituciones de TIGRE actúan como autoridades de registro (RA) para sus respectivas bases de usuarios locales. Para obtener información actualizada sobre la seguridad de los certificados de usuario y de recursos y sus instrucciones de instalación, véase ref [2]. Los usuarios y hosts de TIGRE son identificados por su distinguido nombre (DN) en su certificado X.509 proporcionado por la CA. Un archivo nativo Grid-mapfile que contiene una lista de DNs autorizados se utiliza para autenticar y autorizar la programación y gestión de trabajos de los usuarios en los recursos del sitio TIGRE. En la Universidad Texas Tech, a los usuarios se les asigna dinámicamente una de las muchas cuentas genéricas. Esto se logra a través del Sistema de Gestión de Usuarios de Red (GUMS) [12]. 2.2. Programación y gestión de empleos El entorno TIGRE apoya la presentación de trabajos basada en GRAM4 a través de servicios web. Los scripts de envío de trabajos se generan usando XML. Los servicios web GRAM traducen los scripts XML en programadores de lotes específicos de grupos de destino como LSF, PBS o SGE. Los protocolos de transferencia de archivos de alto ancho de banda como GridFTP se utilizan para estadificación de archivos dentro y fuera de la máquina de destino. El acceso a hosts remotos para compilar y depurar es sólo a través del servicio GSISSH que requiere autenticación de recursos a través de certificados X.509. La autenticación y autorización de los trabajos de Grid se gestionan mediante la emisión de certificados de Grid a usuarios y anfitriones. Las listas de revocación de certificados (CRL) se actualizan diariamente para mantener altos estándares de seguridad de los servicios de TIGRE Grid. El área de documentación del portal TIGRE [2] proporciona un tutorial de inicio rápido sobre cómo ejecutar trabajos en TIGRE. 2.3. Metascheduler El metascheduler interopera con los programadores de lotes de nivel de cluster (como LSF, PBS) en la gestión general del flujo de trabajo de Grid. En el presente trabajo, hemos empleado el metaprogramador GridWay [8] -un proyecto de incubadora Globus- para programar y gestionar trabajos en TIGRE. El GridWay es un metaprogramador ligero que utiliza plenamente las funcionalidades de Globus. Está diseñado para proporcionar un uso eficiente de los recursos dinámicos de Grid por múltiples usuarios para las infraestructuras de Grid construidas sobre los servicios de Globus. El administrador del sitio TIGRE puede controlar el uso compartido de recursos a través de un potente programador integrado proporcionado por GridWay o ampliando el módulo de programación externa GridWays para proporcionar sus propias políticas de programación. Los usuarios de aplicaciones pueden escribir descripciones de trabajos usando el formato de plantilla de trabajo simple y directo de GridWays (ver Sección 4 para más detalles) o el lenguaje estándar de descripción de la presentación de trabajos (JSDL). Para más detalles sobre la aplicación, véase la sección 4. 2.4. Sistema de Gestión de Servicios al Cliente Un portal TIGRE [2] fue diseñado e implementado para interconectar usuarios y proveedores de recursos. Fue diseñado utilizando GridPort [13] y es mantenido por TACC. El entorno TIGRE es compatible con herramientas de código abierto como el Open Ticket Request System (OTRS) [14] para el servicio de tickets de problemas, y MoinMoin [15] Wiki para la gestión de contenido y conocimiento de TIGRE para educación, extensión y capacitación. Los enlaces para OTRS y Wiki son consumidos por el portal TIGRE [2] - el portal para usuarios y proveedores de recursos. El estado y las cargas de los recursos de TIGRE son monitoreados por el servicio de Repositorio de Información de Puertos Grid (GPIR) del kit de herramientas GridPort [13] que interactúa con el servicio local de monitoreo de carga de clústeres como Ganglia. El GPIR utiliza trabajos de cron en cada recurso para reunir características específicas de los recursos del sitio, tales como trabajos que se ejecutan, en cola y esperando la asignación de recursos. 3. APLICACIÓN ENSEMBLE KALMAN FILTER El objetivo principal de las simulaciones de yacimientos de hidrocarburos es predecir el comportamiento de la producción de yacimientos de petróleo y gas (denominados en lo sucesivo campo) para su desarrollo y gestión óptima. En el modelado de yacimientos, el campo se divide en varios modelos geológicos, como se muestra en la Figura 1. Para una previsión precisa del rendimiento del campo, es necesario conciliar varios modelos geológicos con la respuesta dinámica del campo a través de la coincidencia histórica [16-20]. Gráfico 1 Vista transversal del Campo. Las capas verticales corresponden a diferentes modelos geológicos y los clavos son pozos de aceite cuya información histórica se utilizará para predecir el comportamiento de la producción. (Figura Ref:http://faculty.smu.edu/zchen/research.html). El EnKF es un método de Monte Carlo que trabaja con un conjunto de modelos de embalses. Este método utiliza covarianzas cruzadas [21] entre las mediciones de campo y los parámetros del modelo de reservorio (derivados de varios modelos) para estimar las incertidumbres de predicción. Los parámetros del modelo geológico en el conjunto se actualizan secuencialmente con el objetivo de minimizar las incertidumbres de predicción. La respuesta histórica de la producción del campo durante más de 50 años se utiliza en estas simulaciones. La principal ventaja de EnKF es que puede vincularse fácilmente a cualquier simulador de depósito, y puede asimilar los últimos datos de producción sin necesidad de volver a ejecutar el simulador desde las condiciones iniciales. Investigadores en Texas son grandes suscriptores del paquete de Schlumberger ECLIPSE [22] para simulaciones de reservorios. En el modelado del embalse, cada modelo geológico comprueba una licencia ECLIPSE. La duración de la simulación de la metodología EnKF depende del número de modelos geológicos utilizados, el número de licencias ECLIPSE disponibles, la historia de producción del campo y las incertidumbres propagadas en la correspondencia de la historia. El flujo de trabajo general de EnKF se muestra en la Figura 2. Gráfico 2 Ensemble Kaman Filter Data Assimulation Workflow. Cada sitio tiene licencias L. En START, el proceso maestro/control (programa principal EnKF) lee el archivo de configuración de simulación para el número (N) de modelos y archivos de entrada específicos del modelo. A continuación, N directorios de trabajo se crean para almacenar los archivos de salida. Al final de la iteración, el proceso maestro/control recoge los archivos de salida de los modelos N y las crosscovarianzas de los procesos posteriores [21] para estimar las incertidumbres de predicción. Esta información se utilizará para actualizar modelos (o archivos de entrada) para la siguiente iteración. La simulación continúa hasta agotar las historias de producción. La simulación típica de EnKF con N=50 y historias de campo de 50-60 años, en pasos de tiempo que van de tres meses a un año, toma unas tres semanas en un entorno de computación en serie. En el entorno informático paralelo, no hay comunicación interproceso entre los modelos geológicos en el conjunto. Sin embargo, al final de cada paso del tiempo de simulación, los archivos de salida específicos del modelo deben ser recogidos para analizar covarianzas cruzadas [21] y para preparar el siguiente conjunto de archivos de entrada. Por lo tanto, el modelo maestro-esclavo en el entorno de mensajepassing (MPI) es un paradigma adecuado. En este enfoque, los modelos geológicos son tratados como esclavos y se distribuyen entre los procesadores disponibles. El master Cluster o (TIGRE/GridWay) START Read Configuration File Create N Working Directories Create N Input files Model l Model 2 Model N.. . ECLIPSE in situ Un ECLIPSE in situ B ECLIPSE in situ Z Collect N Model Outputs, Post-process Output files FIN. . . proceso recoge archivos de salida específicos del modelo, analiza y prepara el siguiente conjunto de archivos de entrada para la simulación. Dado que cada modelo geológico comprueba una licencia ECLIPSE, la paralelización de la simulación depende del número de licencias disponibles. Cuando el número de licencias disponible es menor que el número de modelos en el conjunto, uno o más de los nodos del grupo MPI tienen que manejar más de un modelo en serie y, por lo tanto, se tarda más tiempo en completar la simulación. Un Departamento de Ingeniería Petrolera generalmente adquiere 10-15 licencias ECLIPSE, mientras que al menos diez veces más número de licencias sería necesario para simulaciones estándar de la industria. El número de licencias puede incrementarse con la participación de varios departamentos de ingeniería petrolera que apoyan el paquete ECLIPSE. Dado que MPI no se escala muy bien para aplicaciones que involucran clústeres de computación remotos, y para evitar los problemas del firewall con servidores de licencias en todos los dominios administrativos, parece necesario activar el flujo de trabajo de EnKF. Con esta motivación, hemos implementado el flujo de trabajo EnKF habilitado para Grid para el entorno TIGRE y hemos demostrado la paralelización de la aplicación a través de TIGRE usando el metascheduler GridWay. En la siguiente sección figuran más detalles al respecto. 4. DETALLES DE APLICACION Para habilitar Grid-enable el enfoque EnKF, hemos eliminado el código MPI para el procesamiento paralelo y reemplazado por trabajos de N monoprocesador (o sub-trabajos) donde, N es el número de modelos geológicos en el conjunto. Estos sub-trabajos específicos de modelos se distribuyeron a través de sitios TIGRE que soportan el paquete ECLIPSE utilizando el metaprogramador GridWay [8]. Para cada sub-trabajo, hemos construido una plantilla de trabajo GridWay que especifica los archivos ejecutables, de entrada y salida, y los requisitos de recursos. Dado que los recursos de cálculo de TIGRE no se espera que cambien con frecuencia, hemos utilizado la política de descubrimiento de recursos estáticos para GridWay y los sub-trabajos fueron programados dinámicamente a través de los recursos de TIGRE usando GridWay. La Figura 3 representa el archivo de plantilla de subtrabajo para el metaprogramador GridWay. Gráfico 3 Plantilla de subtrabajo GridWay En la Figura 3, REQUISITOS bandera se establece para elegir los recursos que satisfacen los requisitos de la aplicación. En el caso de la aplicación EnKF, por ejemplo, necesitamos recursos que apoyen el paquete ECLIPSE. ARGUMENTS flag especifica el modelo en el conjunto que invocará ECLIPSE en un sitio remoto. INPUT_FILES es preparado por el programa principal de EnKF (o proceso maestro/control) y es transferido por GridWay al sitio remoto donde está desatendido y está preparado para su ejecución. Finalmente, OUTPUT_FILES especifica el nombre y la ubicación donde se escribirán los archivos de salida. Las características de la línea de comandos de GridWay se utilizaron para recopilar y procesar las salidas específicas del modelo para preparar un nuevo conjunto de archivos de entrada. Este paso imita la sincronización del proceso MPI en el modelo maestro-esclavo. Al final de cada iteración, los recursos computacionales y las licencias se devuelven al grupo. La Tabla 1 muestra los sub-trabajos en TIGRE Grid via GridWay usando el comando gwps y para mayor claridad, sólo se mostraron las columnas seleccionadas. USUARIO JID DM EM NOMBRE HOST pingluo 88 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 89 wrap pend enkf.jt antaeus.hpcc.ttu.edu/LSF pingluo 90 wrap actv enkf.jt minigar.hp Programación de trabajo a través de TIGRE usando GridWay Metascheduler. DM: Estado de envío, EM: Estado de ejecución, JID es el id de trabajo y HOST corresponde al cluster específico del sitio y su planificador de lotes local. Cuando un trabajo es enviado a GridWay, pasará por una serie de estados de envío (DM) y ejecución (EM). Para DM, los estados incluyen pend(ing), prol(og), wrap(per), epil(og), y hecho. DM=prol significa que el trabajo ha sido programado a un recurso y el directorio de trabajo remoto está en preparación. DM=warp implica que GridWay está ejecutando el envoltorio que a su vez ejecuta la aplicación. DM=epil implica que el trabajo ha terminado de ejecutarse en el sitio remoto y los resultados se están transfiriendo al servidor GridWay. Del mismo modo, cuando EM=pend implica que el trabajo está esperando en la cola para el recurso y el trabajo se está ejecutando cuando EM=actv. Para ver la lista completa de las banderas de mensajes y sus descripciones, consulte la documentación en ref [8]. Hemos demostrado las ejecuciones de EnKF habilitadas para Grid usando GridWay para entorno TIGRE. Los trabajos son tan elegidos que el tiempo de ejecución no supera más de media hora. La simulación incluyó hasta 20 trabajos entre sitios de A&M y TTU con TTU cumpliendo 10 licencias. Para obtener información sobre los recursos, véase el cuadro I. Una de las principales ventajas de la simulación EnKF habilitada por Grid es que tanto los recursos como las licencias se devuelven al grupo al final de cada paso del tiempo de simulación a diferencia del caso de la implementación de MPI donde las licencias y nodos están bloqueados hasta la finalización de la simulación completa. Sin embargo, el hecho de que cada sub-trabajo se programe independientemente a través de GridWay podría posiblemente incurrir en otro retraso de tiempo causado por esperar en la cola para la ejecución en cada paso del tiempo de simulación. Tales retrasos no se esperan EXECUTABLE=runFORWARD NECESIDADES=HOSTNAME=cosmos.tamu.edu  HOSTNAME=antaeus.hpcc.ttu.edu  HOSTNAME=minigar.hpcc.ttu.edu  ARGUMENTOS=001 INPUT_FILES=001.in.tar OUTPUT_FI Hay dos escenarios principales para comparar los enfoques de computación de red y clúster. Escenario I: El cúmulo está muy cargado. El tiempo promedio de espera concebido del trabajo que solicita un gran número de CPUs es generalmente más largo que el tiempo de espera de los trabajos que solicitan una sola CPU. Por lo tanto, el tiempo de espera general podría ser más corto en el enfoque Grid que solicita una sola CPU para cada sub-trabajo muchas veces en comparación con la implementación MPI que requiere un gran número de CPUs en un solo momento. Es evidente que la programación de la cuadrícula es beneficiosa especialmente cuando el clúster está fuertemente cargado y el número solicitado de CPUs para el trabajo del MPI no está fácilmente disponible. Escenario II: El clúster está relativamente menos cargado o disponible en gran medida. Parece que la implementación del MPI es favorable en comparación con la programación de la Rejilla. Sin embargo, la paralelización de la aplicación EnKF depende del número de licencias ECLIPSE e idealmente, el número de licencias debe ser igual al número de modelos en el conjunto. Por lo tanto, si una sola institución no tiene suficiente número de licencias, la disponibilidad del clúster no ayuda tanto como se espera. Dado que el entorno colaborativo, como TIGRE, puede abordar tanto los requisitos de computación como los de recursos de software para la aplicación EnKF, el enfoque compatible con Grid sigue siendo ventajoso sobre la implementación MPI convencional en cualquiera de los escenarios anteriores. 5. CONCLUSIONES Y FUTURO TRABAJO TIGRE es un proyecto de desarrollo de la red de educación superior y su propósito es mantener y ampliar las oportunidades de investigación y educación a través de Texas. Dentro del área de aplicación de exploración energética, hemos habilitado la implementación MPI del conjunto Kalman metodología de asimilación de datos de filtro para la caracterización de reservorios. Esta tarea se llevó a cabo eliminando el código MPI para el procesamiento paralelo y reemplazando con trabajos de un solo procesador uno para cada modelo geológico en el conjunto. Estos trabajos de un solo procesador fueron programados a través de TIGRE a través de GridWay metascheduler. Hemos demostrado que mediante la puesta en común de licencias a través de sitios TIGRE, más modelos geológicos pueden ser manejados en paralelo y por lo tanto concebiblemente mejor precisión de simulación. Este enfoque tiene varias ventajas sobre la implementación de MPI, especialmente cuando un clúster específico del sitio está muy cargado y/o las licencias de número requeridas para la simulación son más que las disponibles en un solo sitio. Hacia el trabajo futuro, sería interesante comparar el tiempo de ejecución entre MPI y las implementaciones de Grid para la aplicación EnKF. Este esfuerzo podría arrojar luz sobre la calidad del servicio (QoS) de los entornos Grid en comparación con la computación de clústers. Otro aspecto de interés en un futuro próximo sería la gestión de recursos de computación y licencia para abordar la gestión de la relación trabajo (o procesador)-licencia. 6. OBSERVACIONES Y MENOS APRENDIZADOS Los esfuerzos que facilitan la red para la aplicación EnKF han proporcionado amplias oportunidades para reunir información sobre la visibilidad y la promesa de los entornos de computación de Grid para el desarrollo y soporte de aplicaciones. Los principales problemas son la seguridad de los datos estándar de la industria y la CV comparable a la computación de clústers. Dado que la investigación de modelado de reservorios involucra datos propietarios del campo, tuvimos que invertir esfuerzos sustanciales inicialmente en educar a los investigadores de aplicaciones sobre la capacidad de los servicios de Grid para apoyar la seguridad de datos estándar de la industria a través de acceso basado en roles y privilegios utilizando el estándar X.509. Con respecto a QoS, los investigadores de aplicaciones esperan niveles de QoS con entornos de cuadrícula. Además, hay una curva de aprendizaje pronunciada en la computación de cuadrícula en comparación con la computación de clúster convencional. Dado que la computación de cuadrícula sigue siendo una tecnología emergente, y abarca varios ámbitos administrativos, la computación de cuadrícula sigue siendo prematura, especialmente en términos del nivel de QoS, aunque ofrece mejores normas de seguridad de los datos en comparación con los grupos de productos básicos. Es nuestra observación que los programas de capacitación y divulgación que comparan y contrastan los entornos de computación de red y clúster serían un enfoque adecuado para mejorar la participación de los usuarios en la computación de red. Este enfoque también ayuda a los usuarios a emparejar sus aplicaciones y habilidades que las cuadrículas pueden ofrecer. En resumen, nuestros esfuerzos a través de TIGRE en la metodología de asimilación de datos de la EnKF demostraron una promesa sustancial en la contratación de investigadores de Ingeniería Petrolera a través de colaboraciones entre campus. Se están realizando esfuerzos para lograr la participación de más escuelas en este esfuerzo. Estos esfuerzos pueden resultar en un aumento de la investigación colaborativa, oportunidades educativas y desarrollo de la fuerza laboral a través de programas de investigación de posgrado/facultad en instituciones TIGRE. 7. AGRADECIMIENTOS Los autores reconocen al Estado de Texas por apoyar el proyecto TIGRE a través del Fondo Empresarial de Texas, y a las Instituciones TIGRE por proporcionar el mecanismo, en el que también participan los autores (Ravi Vadapalli, Taesung Kim y Ping Luo). Los autores agradecen a los investigadores de aplicaciones Prof. Akhil Datta-Gupta de Texas A&M University y Prof. Lloyd Heinze de Texas Tech University por sus discusiones e interés en explotar el entorno TIGRE para ampliar las oportunidades en investigación y desarrollo. 8. REFERENCIAS [1] Foster, I. y Kesselman, C. (eds.) 2004. The Grid: Blueprint for a new computing infraestructura (The Elsevier series in Grid computing) [2] Portal TIGRE: http://tigreportal.hipcat.net [3] Vadapalli, R. Sill, A., Dooley, R., Murray, M., Luo, P., Kim, T., Huang, M., Thyagaraja, K., y Chaffin, Demostración del entorno TIGRE para aplicaciones de cuadrícula habilitadas/adecuadas. 8o IEEE/ACM Int. Conf. on Grid Computing, 19-21 de septiembre, Austin [4] The High Performance Computing cross Texas Consortium http://www.hipcat.net [5] Pordes, R. Petravick, D. Kramer, B. Olson, D. Livny, M. Roy, A. Avery, P. Blackburn, K. Wenaus, T. Würthwein, F. Foster, I. Gar The Open Science Grid, J. Phys Conf Series http://www.iop.org/EJ/abstract/1742-6596/78/1/012057 y http://www.opensciencegrid.org [6] Reed, D.A. 2003. Rejilla, el Teragrid y más allá, Ordenador, vol. 30, no. 1 y http://www.teragrid.org [7] Evensen, G. 2006. Asimilación de datos: El conjunto Kalman Filter, Springer [8] Herrera, J. Huedo, E. Montero, R. S. y Llorente, I. M. 2005. Programación Científica, vol 12, No. 4. pp 317-331 [9] Avery, P. and Foster, I. 2001. El proyecto GriPhyN: Hacia redes virtuales de datos a petaescala, informe técnico GriPhyN-200115 y http://vdt.cs.wisc.edu [10] La guía de documentación e instalación de PacMan http://physics.bu.edu/pacman/htmls [11] Caskey, P. Murray, M. Perez, J. y Sill, A. 2007. Estudios de casos en la gestión de identificación para organizaciones virtuales, EDUCOUSO Southwest Reg. Conf., 21-23 febrero, Austin, TX. http://www.educause.edu/ir/library/pdf/SWR07058.pdf [12] El Sistema de Gestión de Usuarios de Grid (GUMS) https://www.racf.bnl.gov/Facility/GUMS/index.html [13] Thomas, M. y Boisseau, J. 2003. Construyendo portales de computación de cuadrículas: El kit de herramientas para el portal de cuadrículas NPACI, Grid computing: haciendo realidad la infraestructura global, Capítulo 28, Berman, F. Fox, G. Thomas, M. Boisseau, J. y Hey, T. (eds), John Wiley and Sons, Ltd, Chichester [14] Open Ticket Request System http:// 1999. Integración de datos dinámicos en modelos de depósito de alta resolución utilizando coeficientes de sensibilidad basados en la racionalización, Society of Petroleum Engineers (SPE), 4 (4). [17] Emanuel, A. S. y Milliken, W. J. 1998. Historia que combina modelos de diferencias finitas con racionalizaciones 3D, SPE 49000, Proc de la Conf Técnica Anual y Exposición, 2730 de septiembre, Nueva Orleans, LA. [18] Nævdal, G. Johnsen, L.M. Aanonsen, S.I. y Vefring, E.H. 2003. Monitorización de embalses y actualización continua de modelos utilizando Ensemble Kalman Filter, SPE 84372, Proc del Conf Técnico Anual y Exposición, Oct 5-8, Denver, CO. [19] Jafarpour B. y McLaughlin, D.B. 2007. Historia que coincide con un conjunto de filtro Kalman y parametrización discreta de coseno, SPE 108761, Proc de la Conf Técnica Anual y Exposición, 11-14 de noviembre, Anaheim, CA [20] Li, G. y Reynolds, A. C. 2007. Un conjunto iterativo Kalman filtro para la asimilación de datos, SPE 109808, Proc de la SPE Conf y Exposición Técnica Anual, 11-14 de noviembre, Anaheim, CA [21] Arroyo-Negrete, E. Devagowda, D. Datta-Gupta, A. 2006. Simplificar el conjunto asistido Kalman filtro para la actualización rápida y continua del modelo de depósito. Proc de la Int. Oil & Gas Conf and Exhibition, SPE 104255, Dec 5-7, China [22] ECLIPSE Reservoir Engineering Software http://www.slb.com/content/services/software/reseng/index.a sp ",
            "error": []
        }
    }
}