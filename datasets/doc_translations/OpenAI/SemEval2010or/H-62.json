{
    "id": "H-62",
    "original_text": "Implicit User Modeling for Personalized Search Xuehua Shen, Bin Tan, ChengXiang Zhai Department of Computer Science University of Illinois at Urbana-Champaign ABSTRACT Information retrieval systems (e.g., web search engines) are critical for overcoming information overload. A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users, resulting in inherently non-optimal retrieval performance. For example, a tourist and a programmer may use the same word java to search for different information, but the current search systems would return the same results. In this paper, we study how to infer a users interest from the users search context and use the inferred implicit user model for personalized search . We present a decision theoretic framework and develop techniques for implicit user modeling in information retrieval. We develop an intelligent client-side web search agent (UCAIR) that can perform eager implicit feedback, e.g., query expansion based on previous queries and immediate result reranking based on clickthrough information. Experiments on web search show that our search agent can improve search accuracy over the popular Google search engine. Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models, Relevance feedback, Search Process General Terms Algorithms 1. INTRODUCTION Although many information retrieval systems (e.g., web search engines and digital library systems) have been successfully deployed, the current retrieval systems are far from optimal. A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users [17]. This inherent non-optimality is seen clearly in the following two cases: (1) Different users may use exactly the same query (e.g., Java) to search for different information (e.g., the Java island in Indonesia or the Java programming language), but existing IR systems return the same results for these users. Without considering the actual user, it is impossible to know which sense Java refers to in a query. (2) A users information needs may change over time. The same user may use Java sometimes to mean the Java island in Indonesia and some other times to mean the programming language. Without recognizing the search context, it would be again impossible to recognize the correct sense. In order to optimize retrieval accuracy, we clearly need to model the user appropriately and personalize search according to each individual user. The major goal of user modeling for information retrieval is to accurately model a users information need, which is, unfortunately, a very difficult task. Indeed, it is even hard for a user to precisely describe what his/her information need is. What information is available for a system to infer a users information need? Obviously, the users query provides the most direct evidence. Indeed, most existing retrieval systems rely solely on the query to model a users information need. However, since a query is often extremely short, the user model constructed based on a keyword query is inevitably impoverished . An effective way to improve user modeling in information retrieval is to ask the user to explicitly specify which documents are relevant (i.e., useful for satisfying his/her information need), and then to improve user modeling based on such examples of relevant documents. This is called relevance feedback, which has been proved to be quite effective for improving retrieval accuracy [19, 20]. Unfortunately, in real world applications, users are usually reluctant to make the extra effort to provide relevant examples for feedback [11]. It is thus very interesting to study how to infer a users information need based on any implicit feedback information, which naturally exists through user interactions and thus does not require any extra user effort. Indeed, several previous studies have shown that implicit user modeling can improve retrieval accuracy. In [3], a web browser (Curious Browser) is developed to record a users explicit relevance ratings of web pages (relevance feedback) and browsing behavior when viewing a page, such as dwelling time, mouse click, mouse movement and scrolling (implicit feedback). It is shown that the dwelling time on a page, amount of scrolling on a page and the combination of time and scrolling have a strong correlation with explicit relevance ratings, which suggests that implicit feedback may be helpful for inferring user information need. In [10], user clickthrough data is collected as training data to learn a retrieval function, which is used to produce a customized ranking of search results that suits a group of users preferences. In [25], the clickthrough data collected over a long time period is exploited through query expansion to improve retrieval accuracy. 824 While a user may have general long term interests and preferences for information, often he/she is searching for documents to satisfy an ad-hoc information need, which only lasts for a short period of time; once the information need is satisfied, the user would generally no longer be interested in such information. For example, a user may be looking for information about used cars in order to buy one, but once the user has bought a car, he/she is generally no longer interested in such information. In such cases, implicit feedback information collected over a long period of time is unlikely to be very useful, but the immediate search context and feedback information, such as which of the search results for the current information need are viewed, can be expected to be much more useful. Consider the query Java again. Any of the following immediate feedback information about the user could potentially help determine the intended meaning of Java in the query: (1) The previous query submitted by the user is hashtable (as opposed to, e.g., travel Indonesia). (2) In the search results, the user viewed a page where words such as programming, software, and applet occur many times. To the best of our knowledge, how to exploit such immediate and short-term search context to improve search has so far not been well addressed in the previous work. In this paper, we study how to construct and update a user model based on the immediate search context and implicit feedback information and use the model to improve the accuracy of ad-hoc retrieval. In order to maximally benefit the user of a retrieval system through implicit user modeling, we propose to perform eager implicit feedback. That is, as soon as we observe any new piece of evidence from the user, we would update the systems belief about the users information need and respond with improved retrieval results based on the updated user model. We present a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function. In a traditional retrieval paradigm, the retrieval problem is to match a query with documents and rank documents according to their relevance values. As a result, the retrieval process is a simple independent cycle of query and result display. In the proposed new retrieval paradigm, the users search context plays an important role and the inferred implicit user model is exploited immediately to benefit the user. The new retrieval paradigm is thus fundamentally different from the traditional paradigm, and is inherently more general. We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user. Using these techniques, we develop a client-side web search agent UCAIR (User-Centered Adaptive Information Retrieval) on top of a popular search engine (Google). Experiments on web search show that our search agent can improve search accuracy over Google. Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort. Thus the developed search agent can improve existing web search performance without additional effort from the user. The remaining sections are organized as follows. In Section 2, we discuss the related work. In Section 3, we present a decisiontheoretic interactive retrieval framework for implicit user modeling. In Section 4, we present the design and implementation of an intelligent client-side web search agent (UCAIR) that performs eager implicit feedback. In Section 5, we report our experiment results using the search agent. Section 6 concludes our work. 2. RELATED WORK Implicit user modeling for personalized search has been studied in previous work, but our work differs from all previous work in several aspects: (1) We emphasize the exploitation of immediate search context such as the related immediately preceding query and the viewed documents in the same session, while most previous work relies on long-term collection of implicit feedback information [25]. (2) We perform eager feedback and bring the benefit of implicit user modeling as soon as any new implicit feedback information is available, while the previous work mostly exploits longterm implicit feedback [10]. (3) We propose a retrieval framework to integrate implicit user modeling with the interactive retrieval process, while the previous work either studies implicit user modeling separately from retrieval [3] or only studies specific retrieval models for exploiting implicit feedback to better match a query with documents [23, 27, 22]. (4) We develop and evaluate a personalized Web search agent with online user studies, while most existing work evaluates algorithms offline without real user interactions. Currently some search engines provide rudimentary personalization, such as Google Personalized web search [6], which allows users to explicitly describe their interests by selecting from predefined topics, so that those results that match their interests are brought to the top, and My Yahoo! search [16], which gives users the option to save web sites they like and block those they dislike. In contrast, UCAIR personalizes web search through implicit user modeling without any additional user efforts. Furthermore, the personalization of UCAIR is provided on the client side. There are two remarkable advantages on this. First, the user does not need to worry about the privacy infringement, which is a big concern for personalized search [26]. Second, both the computation of personalization and the storage of the user profile are done at the client side so that the server load is reduced dramatically [9]. There have been many works studying user query logs [1] or query dynamics [13]. UCAIR makes direct use of a users query history to benefit the same user immediately in the same search session. UCAIR first judges whether two neighboring queries belong to the same information session and if so, it selects terms from the previous query to perform query expansion. Our query expansion approach is similar to automatic query expansion [28, 15, 5], but instead of using pseudo feedback to expand the query, we use users implicit feedback information to expand the current query. These two techniques may be combined. 3. OPTIMIZATION IN INTERACTIVE IR In interactive IR, a user interacts with the retrieval system through an action dialogue, in which the system responds to each user action with some system action. For example, the users action may be submitting a query and the systems response may be returning a list of 10 document summaries. In general, the space of user actions and system responses and their granularities would depend on the interface of a particular retrieval system. In principle, every action of the user can potentially provide new evidence to help the system better infer the users information need. Thus in order to respond optimally, the system should use all the evidence collected so far about the user when choosing a response. When viewed in this way, most existing search engines are clearly non-optimal. For example, if a user has viewed some documents on the first page of search results, when the user clicks on the Next link to fetch more results, an existing retrieval system would still return the next page of results retrieved based on the original query without considering the new evidence that a particular result has been viewed by the user. 825 We propose to optimize retrieval performance by adapting system responses based on every action that a user has taken, and cast the optimization problem as a decision task. Specifically, at any time, the system would attempt to do two tasks: (1) User model updating: Monitor any useful evidence from the user regarding his/her information need and update the user model as soon as such evidence is available; (2) Improving search results: Rerank immediately all the documents that the user has not yet seen, as soon as the user model is updated. We emphasize eager updating and reranking, which makes our work quite different from any existing work. Below we present a formal decision theoretic framework for optimizing retrieval performance through implicit user modeling in interactive information retrieval. 3.1 A decision-theoretic framework Let A be the set of all user actions and R(a) be the set of all possible system responses to a user action a ∈ A. At any time, let At = (a1, ..., at) be the observed sequence of user actions so far (up to time point t) and Rt−1 = (r1, ..., rt−1) be the responses that the system has made responding to the user actions. The systems goal is to choose an optimal response rt ∈ R(at) for the current user action at. Let M be the space of all possible user models. We further define a loss function L(a, r, m) ∈ , where a ∈ A is a user action, r ∈ R(a) is a system response, and m ∈ M is a user model. L(a, r, m) encodes our decision preferences and assesses the optimality of responding with r when the current user model is m and the current user action is a. According to Bayesian decision theory, the optimal decision at time t is to choose a response that minimizes the Bayes risk, i.e., r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) where P(mt|U, D, At, Rt−1) is the posterior probability of the user model mt given all the observations about the user U we have made up to time t. To simplify the computation of Equation 1, let us assume that the posterior probability mass P(mt|U, D, At, Rt−1) is mostly concentrated on the mode m∗ t = argmaxmt P(mt|U, D, At, Rt−1). We can then approximate the integral with the value of the loss function at m∗ t . That is, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) where m∗ t = argmaxmt P(mt|U, D, At, Rt−1). Leaving aside how to define and estimate these probabilistic models and the loss function, we can see that such a decision-theoretic formulation suggests that, in order to choose the optimal response to at, the system should perform two tasks: (1) compute the current user model and obtain m∗ t based on all the useful information. (2) choose a response rt to minimize the loss function value L(at, rt, m∗ t ). When at does not affect our belief about m∗ t , the first step can be omitted and we may reuse m∗ t−1 for m∗ t . Note that our framework is quite general since we can potentially model any kind of user actions and system responses. In most cases, as we may expect, the systems response is some ranking of documents, i.e., for most actions a, R(a) consists of all the possible rankings of the unseen documents, and the decision problem boils down to choosing the best ranking of unseen documents based on the most current user model. When a is the action of submitting a keyword query, such a response is exactly what a current retrieval system would do. However, we can easily imagine that a more intelligent web search engine would respond to a users clicking of the Next link (to fetch more unseen results) with a more optimized ranking of documents based on any viewed documents in the current page of results. In fact, according to our eager updating strategy, we may even allow a system to respond to a users clicking of browsers Back button after viewing a document in the same way, so that the user can maximally benefit from implicit feedback. These are precisely what our UCAIR system does. 3.2 User models A user model m ∈ M represents what we know about the user U, so in principle, it can contain any information about the user that we wish to model. We now discuss two important components in a user model. The first component is a component model of the users information need. Presumably, the most important factor affecting the optimality of the systems response is how well the response addresses the users information need. Indeed, at any time, we may assume that the system has some belief about what the user is interested in, which we model through a term vector x = (x1, ..., x|V |), where V = {w1, ..., w|V |} is the set of all terms (i.e., vocabulary) and xi is the weight of term wi. Such a term vector is commonly used in information retrieval to represent both queries and documents. For example, the vector-space model, assumes that both the query and the documents are represented as term vectors and the score of a document with respect to a query is computed based on the similarity between the query vector and the document vector [21]. In a language modeling approach, we may also regard the query unigram language model [12, 29] or the relevance model [14] as a term vector representation of the users information need. Intuitively, x would assign high weights to terms that characterize the topics which the user is interested in. The second component we may include in our user model is the documents that the user has already viewed. Obviously, even if a document is relevant, if the user has already seen the document, it would not be useful to present the same document again. We thus introduce another variable S ⊂ D (D is the whole set of documents in the collection) to denote the subset of documents in the search results that the user has already seen/viewed. In general, at time t, we may represent a user model as mt = (S, x, At, Rt−1), where S is the seen documents, x is the systems understanding of the users information need, and (At, Rt−1) represents the users interaction history. Note that an even more general user model may also include other factors such as the users reading level and occupation. If we assume that the uncertainty of a user model mt is solely due to the uncertainty of x, the computation of our current estimate of user model m∗ t will mainly involve computing our best estimate of x. That is, the system would choose a response according to r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) where x∗ = argmaxx P(x|U, D, At, Rt−1). This is the decision mechanism implemented in the UCAIR system to be described later. In this system, we avoided specifying the probabilistic model P(x|U, D, At, Rt−1) by computing x∗ directly with some existing feedback method. 3.3 Loss functions The exact definition of loss function L depends on the responses, thus it is inevitably application-specific. We now briefly discuss some possibilities when the response is to rank all the unseen documents and present the top k of them. Let r = (d1, ..., dk) be the top k documents, S be the set of seen documents by the user, and x∗ be the systems best guess of the users information need. We 826 may simply define the loss associated with r as the negative sum of the probability that each of the di is relevant, i.e., L(a, r, m) = − k i=1 P(relevant|di, m). Clearly, in order to minimize this loss function, the optimal response r would contain the k documents with the highest probability of relevance, which is intuitively reasonable. One deficiency of this top-k loss function is that it is not sensitive to the internal order of the selected top k documents, so switching the ranking order of a non-relevant document and a relevant one would not affect the loss, which is unreasonable. To model ranking, we can introduce a factor of the user model - the probability of each of the k documents being viewed by the user, P(view|di), and define the following ranking loss function: L(a, r, m) = − k i=1 P(view|di)P(relevant|di, m) Since in general, if di is ranked above dj (i.e., i < j), P(view|di) > P(view|dj), this loss function would favor a decision to rank relevant documents above non-relevant ones, as otherwise, we could always switch di with dj to reduce the loss value. Thus the system should simply perform a regular retrieval and rank documents according to the probability of relevance [18]. Depending on the users retrieval preferences, there can be many other possibilities. For example, if the user does not want to see redundant documents, the loss function should include some redundancy measure on r based on the already seen documents S. Of course, when the response is not to choose a ranked list of documents, we would need a different loss function. We discuss one such example that is relevant to the search agent that we implement. When a user enters a query qt (current action), our search agent relies on some existing search engine to actually carry out search. In such a case, even though the search agent does not have control of the retrieval algorithm, it can still attempt to optimize the search results through refining the query sent to the search engine and/or reranking the results obtained from the search engine. The loss functions for reranking are already discussed above; we now take a look at the loss functions for query refinement. Let f be the retrieval function of the search engine that our agent uses so that f(q) would give us the search results using query q. Given that the current action of the user is entering a query qt (i.e., at = qt), our response would be f(q) for some q. Since we have no choice of f, our decision is to choose a good q. Formally, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) which shows that our goal is to find q∗ = argminqL(qt, f(q), m), i.e., an optimal query that would give us the best f(q). A different choice of loss function L(qt, f(q), m) would lead to a different query refinement strategy. In UCAIR, we heuristically compute q∗ by expanding qt with terms extracted from rt−1 whenever qt−1 and qt have high similarity. Note that rt−1 and qt−1 are contained in m as part of the users interaction history. 3.4 Implicit user modeling Implicit user modeling is captured in our framework through the computation of x∗ = argmaxx P(x|U, D, At, Rt−1), i.e., the systems current belief of what the users information need is. Here again there may be many possibilities, leading to different algorithms for implicit user modeling. We now discuss a few of them. First, when two consecutive queries are related, the previous query can be exploited to enrich the current query and provide more search context to help disambiguation. For this purpose, instead of performing query expansion as we did in the previous section, we could also compute an updated x∗ based on the previous query and retrieval results. The computed new user model can then be used to rank the documents with a standard information retrieval model. Second, we can also infer a users interest based on the summaries of the viewed documents. When a user is presented with a list of summaries of top ranked documents, if the user chooses to skip the first n documents and to view the (n+1)-th document, we may infer that the user is not interested in the displayed summaries for the first n documents, but is attracted by the displayed summary of the (n + 1)-th document. We can thus use these summaries as negative and positive examples to learn a more accurate user model x∗ . Here many standard relevance feedback techniques can be exploited [19, 20]. Note that we should use the displayed summaries, as opposed to the actual contents of those documents, since it is possible that the displayed summary of the viewed document is relevant, but the document content is actually not. Similarly, a displayed summary may mislead a user to skip a relevant document. Inferring user models based on such displayed information, rather than the actual content of a document is an important difference between UCAIR and some other similar systems. In UCAIR, both of these strategies for inferring an implicit user model are implemented. 4. UCAIR: A PERSONALIZED SEARCH AGENT 4.1 Design In this section, we present a client-side web search agent called UCAIR, in which we implement some of the methods discussed in the previous section for performing personalized search through implicit user modeling. UCAIR is a web browser plug-in 1 that acts as a proxy for web search engines. Currently, it is only implemented for Internet Explorer and Google, but it is a matter of engineering to make it run on other web browsers and interact with other search engines. The issue of privacy is a primary obstacle for deploying any real world applications involving serious user modeling, such as personalized search. For this reason, UCAIR is strictly running as a client-side search agent, as opposed to a server-side application. This way, the captured user information always resides on the computer that the user is using, thus the user does not need to release any information to the outside. Client-side personalization also allows the system to easily observe a lot of user information that may not be easily available to a server. Furthermore, performing personalized search on the client-side is more scalable than on the serverside, since the overhead of computation and storage is distributed among clients. As shown in Figure 1, the UCAIR toolbar has 3 major components: (1) The (implicit) user modeling module captures a users search context and history information, including the submitted queries and any clicked search results and infers search session boundaries. (2) The query modification module selectively improves the query formulation according to the current user model. (3) The result re-ranking module immediately re-ranks any unseen search results whenever the user model is updated. In UCAIR, we consider four basic user actions: (1) submitting a keyword query; (2) viewing a document; (3) clicking the Back button; (4) clicking the Next link on a result page. For each of these four actions, the system responds with, respectively, (1) 1 UCAIR is available at: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Search Engine (e.g., Google) Search History Log (e.g.,past queries, clicked results) Query Modification Result Re-Ranking User Modeling Result Buffer UCAIR Userquery results clickthrough… Figure 1: UCAIR architecture generating a ranked list of results by sending a possibly expanded query to a search engine; (2) updating the information need model x; (3) reranking the unseen results on the current result page based on the current model x; and (4) reranking the unseen pages and generating the next page of results based on the current model x. Behind these responses, there are three basic tasks: (1) Decide whether the previous query is related to the current query and if so expand the current query with useful terms from the previous query or the results of the previous query. (2) Update the information need model x based on a newly clicked document summary. (3) Rerank a set of unseen documents based on the current model x. Below we describe our algorithms for each of them. 4.2 Session boundary detection and query expansion To effectively exploit previous queries and their corresponding clickthrough information, UCAIR needs to judge whether two adjacent queries belong to the same search session (i.e., detect session boundaries). Existing work on session boundary detection is mostly in the context of web log analysis (e.g., [8]), and uses statistical information rather than textual features. Since our clientside agent does not have access to server query logs, we make session boundary decisions based on textual similarity between two queries. Because related queries do not necessarily share the same words (e.g., java island and travel Indonesia), it is insufficient to use only query text. Therefore we use the search results of the two queries to help decide whether they are topically related. For example, for the above queries java island and travel Indonesia, the words java, bali, island, indonesia and travel may occur frequently in both queries search results, yielding a high similarity score. We only use the titles and summaries of the search results to calculate the similarity since they are available in the retrieved search result page and fetching the full text of every result page would significantly slow down the process. To compensate for the terseness of titles and summaries, we retrieve more results than a user would normally view for the purpose of detecting session boundaries (typically 50 results). The similarity between the previous query q and the current query q is computed as follows. Let {s1, s2, . . . , sn } and {s1, s2, . . . , sn} be the result sets for the two queries. We use the pivoted normalization TF-IDF weighting formula [24] to compute a term weight vector si for each result si. We define the average result savg to be the centroid of all the result vectors, i.e., (s1 + s2 + . . . + sn)/n. The cosine similarity between the two average results is calculated as s avg · savg/ s 2 avg · s2 avg If the similarity value exceeds a predefined threshold, the two queries will be considered to be in the same information session. If the previous query and the current query are found to belong to the same search session, UCAIR would attempt to expand the current query with terms from the previous query and its search results. Specifically, for each term in the previous query or the corresponding search results, if its frequency in the results of the current query is greater than a preset threshold (e.g. 5 results out of 50), the term would be added to the current query to form an expanded query. In this case, UCAIR would send this expanded query rather than the original one to the search engine and return the results corresponding to the expanded query. Currently, UCAIR only uses the immediate preceding query for query expansion; in principle, we could exploit all related past queries. 4.3 Information need model updating Suppose at time t, we have observed that the user has viewed k documents whose summaries are s1, ..., sk. We update our user model by computing a new information need vector with a standard feedback method in information retrieval (i.e., Rocchio [19]). According to the vector space retrieval model, each clicked summary si can be represented by a term weight vector si with each term weighted by a TF-IDF weighting formula [21]. Rocchio computes the centroid vector of all the summaries and interpolates it with the original query vector to obtain an updated term vector. That is, x = αq + (1 − α) 1 k k i=1 si where q is the query vector, k is the number of summaries the user clicks immediately following the current query and α is a parameter that controls the influence of the clicked summaries on the inferred information need model. In our experiments, α is set to 0.5. Note that we update the information need model whenever the user views a document. 4.4 Result reranking In general, we want to rerank all the unseen results as soon as the user model is updated. Currently, UCAIR implements reranking in two cases, corresponding to the user clicking the Back button and Next link in the Internet Explorer. In both cases, the current (updated) user model would be used to rerank the unseen results so that the user would see improved search results immediately. To rerank any unseen document summaries, UCAIR uses the standard vector space retrieval model and scores each summary based on the similarity of the result and the current user information need vector x [21]. Since implicit feedback is not completely reliable, we bring up only a small number (e.g. 5) of highest reranked results to be followed by any originally high ranked results. 828 Google result (user query = java map) UCAIR result (user query =java map) previous query = travel Indonesia previous query = hashtable expanded user query = java map Indonesia expanded user query = java map class 1 Java map projections of the world ... Lonely Planet - Indonesia Map Map (Java 2 Platform SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Java map projections of the world ... INDONESIA TOURISM : CENTRAL JAVA - MAP Java 2 Platform SE v1.3.1: Interface Map www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Java Map INDONESIA TOURISM : WEST JAVA - MAP An Introduction to Java Map Collection Classes java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Java Technology Concept Map IndoStreets - Java Map An Introduction to Java Map Collection Classes java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Indonesia Regions and Islands Maps, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 An Introduction to Java Map Collection Classes Indonesia City Street Map,... Hibernate simplifies inheritance mapping www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Java Map Maps Of Indonesia tmap 30.map Class Hierarchy www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Java API Map Maps of Indonesia by Peter Loud Class Scope www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas : Sam Maps of Indonesia by Peter Loud Class PrintSafeHashMap www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 INDONESIA TOURISM : WEST JAVA - MAP indonesiaphoto.com Java Pro - Union and Vertical Mapping of Classes www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Table 1: Sample results of query expansion 5. EVALUATION OF UCAIR We now present some results on evaluating the two major UCAIR functions: selective query expansion and result reranking based on user clickthrough data. 5.1 Sample results The query expansion strategy implemented in UCAIR is intentionally conservative to avoid misinterpretation of implicit user models. In practice, whenever it chooses to expand the query, the expansion usually makes sense. In Table 1, we show how UCAIR can successfully distinguish two different search contexts for the query java map, corresponding to two different previous queries (i.e., travel Indonesia vs. hashtable). Due to implicit user modeling, UCAIR intelligently figures out to add Indonesia and class, respectively, to the users query java map, which would otherwise be ambiguous as shown in the original results from Google on March 21, 2005. UCAIRs results are much more accurate than Googles results and reflect personalization in search. The eager implicit feedback component is designed to immediately respond to a users activity such as viewing a document. In Figure 2, we show how UCAIR can successfully disambiguate an ambiguous query jaguar by exploiting a viewed document summary. In this case, the initial retrieval results using jaguar (shown on the left side) contain two results about the Jaguar cars followed by two results about the Jaguar software. However, after the user views the web page content of the second result (about Jaguar car) and returns to the search result page by clicking Back button, UCAIR automatically nominates two new search results about Jaguar cars (shown on the right side), while the original two results about Jaguar software are pushed down on the list (unseen from the picture). 5.2 Quantitative evaluation To further evaluate UCAIR quantitatively, we conduct a user study on the effectiveness of the eager implicit feedback component. It is a challenge to quantitatively evaluate the potential performance improvement of our proposed model and UCAIR over Google in an unbiased way [7]. Here, we design a user study, in which participants would do normal web search and judge a randomly and anonymously mixed set of results from Google and UCAIR at the end of the search session; participants do not know whether a result comes from Google or UCAIR. We recruited 6 graduate students for this user study, who have different backgrounds (3 computer science, 2 biology, and 1 chem<top> <num> Number: 716 <title> Spammer arrest sue <desc> Description: Have any spammers been arrested or sued for sending unsolicited e-mail? <narr> Narrative: Instances of arrests, prosecutions, convictions, and punishments of spammers, and lawsuits against them are relevant. Documents which describe laws to limit spam without giving details of lawsuits or criminal trials are not relevant. </top> Figure 3: An example of TREC query topic, expressed in a form which might be given to a human assistant or librarian istry). We use query topics from TREC 2 2004 Terabyte track [2] and TREC 2003 Web track [4] topic distillation task in the way to be described below. An example topic from TREC 2004 Terabyte track appears in Figure 3. The title is a short phrase and may be used as a query to the retrieval system. The description field provides a slightly longer statement of the topic requirement, usually expressed as a single complete sentence or question. Finally the narrative supplies additional information necessary to fully specify the requirement, expressed in the form of a short paragraph. Initially, each participant would browse 50 topics either from Terabyte track or Web track and pick 5 or 7 most interesting topics. For each picked topic, the participant would essentially do the normal web search using UCAIR to find many relevant web pages by using the title of the query topic as the initial keyword query. During this process, the participant may view the search results and possibly click on some interesting ones to view the web pages, just as in a normal web search. There is no requirement or restriction on how many queries the participant must submit or when the participant should stop the search for one topic. When the participant plans to change the search topic, he/she will simply press a button 2 Text REtrieval Conference: http://trec.nist.gov/ 829 Figure 2: Screen shots for result reranking to evaluate the search results before actually switching to the next topic. At the time of evaluation, 30 top ranked results from Google and UCAIR (some are overlapping) are randomly mixed together so that the participant would not know whether a result comes from Google or UCAIR. The participant would then judge the relevance of these results. We measure precision at top n (n = 5, 10, 20, 30) documents of Google and UCAIR. We also evaluate precisions at different recall levels. Altogether, 368 documents judged as relevant from Google search results and 429 documents judged as relevant from UCAIR by participants. Scatter plots of precision at top 10 and top 20 documents are shown in Figure 4 and Figure 5 respectively (The scatter plot of precision at top 30 documents is very similar to precision at top 20 documents). Each point of the scatter plots represents the precisions of Google and UCAIR on one query topic. Table 2 shows the average precision at top n documents among 32 topics. From Figure 4, Figure 5 and Table 2, we see that the search results from UCAIR are consistently better than those from Google by all the measures. Moreover, the performance improvement is more dramatic for precision at top 20 documents than that at precision at top 10 documents. One explanation for this is that the more interaction the user has with the system, the more clickthrough data UCAIR can be expected to collect. Thus the retrieval system can build more precise implicit user models, which lead to better retrieval accuracy. Ranking Method prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Improvement 8.0% 17.8% 20.2% 21.8% Table 2: Table of average precision at top n documents for 32 query topics The plot in Figure 6 shows the precision-recall curves for UCAIR and Google, where it is clearly seen that the performance of UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Scatterplot of Precision at Top 10 Documents Figure 4: Precision at top 10 documents of UCAIR and Google is consistently and considerably better than that of Google at all levels of recall. 6. CONCLUSIONS In this paper, we studied how to exploit implicit user modeling to intelligently personalize information retrieval and improve search accuracy. Unlike most previous work, we emphasize the use of immediate search context and implicit feedback information as well as eager updating of search results to maximally benefit a user. We presented a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function. We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user. Using these techniques, we develop a client-side web search agent (UCAIR) on top of a popular search engine (Google). Experiments on web search show that our search agent can improve search accuracy over 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Scatterplot of Precision at Top 20 documents Figure 5: Precision at top 20 documents of UCAIR and Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 recall precision Precision−Recall curves Google Result UCAIR Result Figure 6: Precision at top 20 result of UCAIR and Google Google. Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort. The developed search agent thus can improve existing web search performance without any additional effort from the user. 7. ACKNOWLEDGEMENT We thank the six participants of our evaluation experiments. This work was supported in part by the National Science Foundation grants IIS-0347933 and IIS-0428472. 8. REFERENCES [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman, and O. Frieder. Hourly analysis of a very large topically categorized web query log. In Proceedings of SIGIR 2004, pages 321-328, 2004. [2] C. Clarke, N. Craswell, and I. Soboroff. Overview of the TREC 2004 terabyte track. In Proceedings of TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda, and D. Brown. Implicit interest indicators. In Proceedings of Intelligent User Interfaces 2001, pages 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson, and M. Wu. Overview of the TREC 2003 web track. In Proceedings of TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend, and V. Larvrenko. Relevance feedback and personalization: A language modeling perspective. In Proeedings of Second DELOS Workshop: Personalisation and Recommender Systems in Digital Libraries, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite, and D. Harman. Results and challenges in web search evaluation. Computer Networks, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A. An, and D. Schuurmans. Dynamic web log session identification with statistical language models. Journal of the American Society for Information Science and Technology, 55(14):1290-1303, 2004. [9] G. Jeh and J. Widom. Scaling personalized web search. In Proceedings of WWW 2003, pages 271-279, 2003. [10] T. Joachims. Optimizing search engines using clickthrough data. In Proceedings of SIGKDD 2002, pages 133-142, 2002. [11] D. Kelly and J. Teevan. Implicit feedback for inferring user preference: A bibliography. SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty and C. Zhai. Document language models, query models, and risk minimization for information retrieval. In Proceedings of SIGIR01, pages 111-119, 2001. [13] T. Lau and E. Horvitz. Patterns of search: Analyzing and modeling web query refinement. In Proceedings of the Seventh International Conference on User Modeling (UM), pages 145 -152, 1999. [14] V. Lavrenko and B. Croft. Relevance-based language models. In Proceedings of SIGIR01, pages 120-127, 2001. [15] M. Mitra, A. Singhal, and C. Buckley. Improving automatic query expansion. In Proceedings of SIGIR 1998, pages 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg. As google goes, so goes the nation. New York Times, May 2003. [18] S. E. Robertson. The probability ranking principle in ı˚. Journal of Documentation, 33(4):294-304, 1977. [19] J. J. Rocchio. Relevance feedback in information retrieval. In The SMART Retrieval System: Experiments in Automatic Document Processing, pages 313-323. Prentice-Hall Inc., 1971. [20] G. Salton and C. Buckley. Improving retrieval performance by retrieval feedback. Journal of the American Society for Information Science, 41(4):288-297, 1990. [21] G. Salton and M. J. McGill. Introduction to Modern Information Retrieval. McGraw-Hill, 1983. [22] X. Shen, B. Tan, and C. Zhai. Context-sensitive information retrieval using implicit feedback. In Proceedings of SIGIR 2005, pages 43-50, 2005. [23] X. Shen and C. Zhai. Exploiting query history for document ranking in interactive information retrieval (Poster). In Proceedings of SIGIR 2003, pages 377-378, 2003. [24] A. Singhal. Modern information retrieval: A brief overview. Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano, and M. Yoshikawa. Adaptive web search based on user profile constructed without any effort from users. In Proceedings of WWW 2004, pages 675-684, 2004. [26] E. Volokh. Personalization and privacy. Communications of the ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen, and I. Ruthven. A simulated study of implicit feedback models. In Proceedings of ECIR 2004, pages 311-326, 2004. [28] J. Xu and W. B. Croft. Query expansion using local and global document analysis. In Proceedings of SIGIR 1996, pages 4-11, 1996. [29] C. Zhai and J. Lafferty. Model-based feedback in KL divergence retrieval model. In Proceedings of the CIKM 2001, pages 403-410, 2001. 831",
    "original_translation": "Modelado implícito de usuarios para búsqueda personalizada Xuehua Shen, Bin Tan, ChengXiang Zhai Departamento de Ciencias de la Computación Universidad de Illinois en Urbana-Champaign RESUMEN Los sistemas de recuperación de información (por ejemplo, motores de búsqueda web) son críticos para superar la sobrecarga de información. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales, lo que resulta en un rendimiento de recuperación inherentemente no óptimo. Por ejemplo, un turista y un programador pueden usar la misma palabra \"java\" para buscar información diferente, pero los sistemas de búsqueda actuales devolverían los mismos resultados. En este artículo, estudiamos cómo inferir el interés de un usuario a partir del contexto de búsqueda del usuario y utilizar el modelo de usuario implícito inferido para la búsqueda personalizada. Presentamos un marco teórico de toma de decisiones y desarrollamos técnicas para el modelado implícito del usuario en la recuperación de información. Desarrollamos un agente de búsqueda web inteligente del lado del cliente (UCAIR) que puede realizar retroalimentación implícita ansiosa, por ejemplo, expansión de consultas basada en consultas anteriores y reordenamiento inmediato de resultados basado en información de clics. Los experimentos sobre la búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda sobre el popular motor de búsqueda Google. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación, Retroalimentación de relevancia, Proceso de búsqueda Términos Generales Algoritmos 1. Aunque muchos sistemas de recuperación de información (por ejemplo, motores de búsqueda web y sistemas de biblioteca digital) se han implementado con éxito, los sistemas de recuperación actuales están lejos de ser óptimos. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales [17]. Esta no optimalidad inherente se ve claramente en los siguientes dos casos: (1) Diferentes usuarios pueden utilizar exactamente la misma consulta (por ejemplo, Java) para buscar información diferente (por ejemplo, la isla de Java en Indonesia o el lenguaje de programación Java), pero los sistemas de IR existentes devuelven los mismos resultados para estos usuarios. Sin considerar al usuario actual, es imposible saber a qué sentido se refiere Java en una consulta. (2) Las necesidades de información de un usuario pueden cambiar con el tiempo. El mismo usuario puede usar Java a veces para referirse a la isla de Java en Indonesia y otras veces para referirse al lenguaje de programación. Sin reconocer el contexto de búsqueda, sería nuevamente imposible reconocer el sentido correcto. Para optimizar la precisión de la recuperación, claramente necesitamos modelar al usuario de manera adecuada y personalizar la búsqueda según cada usuario individual. El objetivo principal del modelado de usuario para la recuperación de información es modelar con precisión la necesidad de información de un usuario, lo cual, desafortunadamente, es una tarea muy difícil. De hecho, incluso resulta difícil para un usuario describir con precisión cuál es su necesidad de información. ¿Qué información está disponible para que un sistema pueda inferir la necesidad de información de un usuario? Obviamente, la consulta de los usuarios proporciona la evidencia más directa. De hecho, la mayoría de los sistemas de recuperación existentes se basan únicamente en la consulta para modelar la necesidad de información de los usuarios. Sin embargo, dado que una consulta suele ser extremadamente corta, el modelo de usuario construido basado en una consulta de palabras clave inevitablemente resulta empobrecido. Una forma efectiva de mejorar la modelización de usuarios en la recuperación de información es pedir al usuario que especifique explícitamente qué documentos son relevantes (es decir, útiles para satisfacer su necesidad de información) y luego mejorar la modelización de usuarios basándose en ejemplos de documentos relevantes. Esto se llama retroalimentación de relevancia, lo cual ha demostrado ser bastante efectivo para mejorar la precisión de recuperación [19, 20]. Desafortunadamente, en aplicaciones del mundo real, los usuarios suelen ser reacios a hacer el esfuerzo adicional de proporcionar ejemplos relevantes para retroalimentación [11]. Por lo tanto, es muy interesante estudiar cómo inferir la necesidad de información de un usuario basándose en cualquier información de retroalimentación implícita, la cual existe naturalmente a través de las interacciones del usuario y no requiere ningún esfuerzo adicional por parte del usuario. De hecho, varios estudios previos han demostrado que el modelado implícito del usuario puede mejorar la precisión de recuperación. En [3], se desarrolla un navegador web (Curious Browser) para registrar las calificaciones explícitas de relevancia de las páginas web por parte de los usuarios (retroalimentación de relevancia) y el comportamiento de navegación al ver una página, como el tiempo de permanencia, clics de ratón, movimiento del ratón y desplazamiento (retroalimentación implícita). Se muestra que el tiempo de permanencia en una página, la cantidad de desplazamiento en una página y la combinación de tiempo y desplazamiento tienen una fuerte correlación con las calificaciones de relevancia explícita, lo que sugiere que la retroalimentación implícita puede ser útil para inferir la necesidad de información del usuario. En [10], se recopilan datos de clics de usuario como datos de entrenamiento para aprender una función de recuperación, que se utiliza para producir un ranking personalizado de resultados de búsqueda que se adapte a las preferencias de un grupo de usuarios. En [25], los datos de clics recopilados durante un largo período de tiempo se utilizan a través de la expansión de consultas para mejorar la precisión de recuperación. Si bien un usuario puede tener intereses y preferencias generales a largo plazo para la información, a menudo está buscando documentos para satisfacer una necesidad de información ad-hoc, que solo dura un corto período de tiempo; una vez que se satisface la necesidad de información, el usuario generalmente ya no estaría interesado en esa información. Por ejemplo, un usuario puede estar buscando información sobre autos usados para comprar uno, pero una vez que el usuario ha comprado un auto, generalmente ya no está interesado en esa información. En tales casos, la información de retroalimentación implícita recopilada durante un largo período de tiempo es poco probable que sea muy útil, pero el contexto de búsqueda inmediato y la información de retroalimentación, como cuáles de los resultados de búsqueda para la necesidad de información actual son vistos, se espera que sean mucho más útiles. Considera la consulta de Java nuevamente. Cualquiera de la siguiente información de retroalimentación inmediata sobre el usuario podría potencialmente ayudar a determinar el significado previsto de Java en la consulta: (1) La consulta anterior enviada por el usuario es hashtable (en lugar de, por ejemplo, viajar a Indonesia). (2) En los resultados de búsqueda, el usuario visualizó una página donde palabras como programación, software y applet ocurren muchas veces. Hasta donde sabemos, cómo aprovechar este contexto de búsqueda inmediato y a corto plazo para mejorar la búsqueda aún no ha sido abordado de manera satisfactoria en trabajos anteriores. En este artículo, estudiamos cómo construir y actualizar un modelo de usuario basado en el contexto de búsqueda inmediato y la información de retroalimentación implícita, y utilizar el modelo para mejorar la precisión de la recuperación ad-hoc. Para beneficiar al máximo al usuario de un sistema de recuperación a través de modelado implícito del usuario, proponemos realizar retroalimentación implícita entusiasta. Es decir, tan pronto como observemos cualquier nueva pieza de evidencia del usuario, actualizaríamos la creencia del sistema sobre la necesidad de información del usuario y responderíamos con resultados de recuperación mejorados basados en el modelo de usuario actualizado. Presentamos un marco de trabajo de teoría de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. En un paradigma de recuperación tradicional, el problema de recuperación consiste en emparejar una consulta con documentos y clasificar los documentos según sus valores de relevancia. Como resultado, el proceso de recuperación es un ciclo independiente simple de consulta y visualización de resultados. En el nuevo paradigma de recuperación propuesto, el contexto de búsqueda de los usuarios juega un papel importante y el modelo de usuario implícito inferido se explota inmediatamente para beneficiar al usuario. El nuevo paradigma de recuperación es, por lo tanto, fundamentalmente diferente del paradigma tradicional y es inherentemente más general. Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos apropiados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para reordenar inmediatamente cualquier documento que aún no haya sido visto por el usuario. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente UCAIR (Recuperación de Información Adaptativa Centrada en el Usuario) sobre un motor de búsqueda popular (Google). Los experimentos sobre búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en comparación con Google. Dado que la información implícita que explotamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional. Por lo tanto, el agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin esfuerzo adicional por parte del usuario. Las secciones restantes están organizadas de la siguiente manera. En la Sección 2, discutimos el trabajo relacionado. En la Sección 3, presentamos un marco de recuperación interactiva basado en teoría de decisiones para modelado implícito de usuarios. En la Sección 4, presentamos el diseño e implementación de un agente de búsqueda web inteligente del lado del cliente (UCAIR) que realiza retroalimentación implícita ansiosa. En la Sección 5, informamos nuestros resultados experimentales utilizando el agente de búsqueda. La sección 6 concluye nuestro trabajo. 2. El modelado implícito del usuario para la búsqueda personalizada ha sido estudiado en trabajos anteriores, pero nuestro trabajo difiere de todos los trabajos anteriores en varios aspectos: (1) Enfatizamos la explotación del contexto de búsqueda inmediato, como la consulta inmediatamente anterior relacionada y los documentos vistos en la misma sesión, mientras que la mayoría de los trabajos anteriores se basan en la recopilación a largo plazo de información de retroalimentación implícita [25]. (2) Realizamos una retroalimentación activa y obtenemos el beneficio del modelado implícito del usuario tan pronto como esté disponible cualquier nueva información de retroalimentación implícita, mientras que el trabajo anterior mayormente explota la retroalimentación implícita a largo plazo [10]. (3) Proponemos un marco de recuperación para integrar el modelado implícito del usuario con el proceso interactivo de recuperación, mientras que el trabajo anterior estudia el modelado implícito del usuario por separado de la recuperación [3] o solo estudia modelos de recuperación específicos para explotar la retroalimentación implícita para mejorar la coincidencia de una consulta con documentos [23, 27, 22]. (4) Desarrollamos y evaluamos un agente de búsqueda web personalizado con estudios de usuario en línea, mientras que la mayoría de los trabajos existentes evalúan algoritmos fuera de línea sin interacciones reales de usuarios. Actualmente algunos motores de búsqueda ofrecen personalización rudimentaria, como la búsqueda web personalizada de Google [6], que permite a los usuarios describir explícitamente sus intereses seleccionando entre temas predefinidos, de modo que los resultados que coinciden con sus intereses se muestren en la parte superior, y la búsqueda de My Yahoo! [16], que brinda a los usuarios la opción de guardar los sitios web que les gustan y bloquear aquellos que no les gustan. Por el contrario, UCAIR personaliza la búsqueda web a través de la modelización implícita del usuario sin necesidad de esfuerzos adicionales por parte del usuario. Además, la personalización de UCAIR se proporciona en el lado del cliente. Hay dos ventajas notables en esto. Primero, el usuario no necesita preocuparse por la infracción de privacidad, que es una gran preocupación para la búsqueda personalizada [26]. En segundo lugar, tanto el cálculo de la personalización como el almacenamiento del perfil del usuario se realizan en el lado del cliente para reducir drásticamente la carga del servidor [9]. Ha habido muchos trabajos estudiando los registros de consultas de usuarios [1] o la dinámica de consultas [13]. UCAIR hace uso directo del historial de consultas de un usuario para beneficiar al mismo usuario de inmediato en la misma sesión de búsqueda. UCAIR primero determina si dos consultas vecinas pertenecen a la misma sesión de información y, de ser así, selecciona términos de la consulta anterior para realizar la expansión de la consulta. Nuestro enfoque de expansión de consultas es similar a la expansión automática de consultas [28, 15, 5], pero en lugar de utilizar retroalimentación pseudo para expandir la consulta, utilizamos la información de retroalimentación implícita de los usuarios para expandir la consulta actual. Estas dos técnicas pueden ser combinadas. 3. OPTIMIZACIÓN EN IR INTERACTIVO En IR interactivo, un usuario interactúa con el sistema de recuperación a través de un diálogo de acción, en el cual el sistema responde a cada acción del usuario con alguna acción del sistema. Por ejemplo, la acción de los usuarios puede ser enviar una consulta y la respuesta del sistema puede ser devolver una lista de 10 resúmenes de documentos. En general, el espacio de acciones del usuario y respuestas del sistema y sus granularidades dependerían de la interfaz de un sistema de recuperación particular. En principio, cada acción del usuario puede potencialmente proporcionar nuevas pruebas para ayudar al sistema a inferir mejor la necesidad de información del usuario. Por lo tanto, para responder de manera óptima, el sistema debería utilizar toda la evidencia recopilada hasta ahora sobre el usuario al elegir una respuesta. Cuando se ven de esta manera, la mayoría de los motores de búsqueda existentes son claramente no óptimos. Por ejemplo, si un usuario ha visto algunos documentos en la primera página de resultados de búsqueda, cuando el usuario hace clic en el enlace Siguiente para obtener más resultados, un sistema de recuperación existente seguiría devolviendo la siguiente página de resultados recuperados en función de la consulta original sin considerar la nueva evidencia de que un resultado en particular ha sido visto por el usuario. Proponemos optimizar el rendimiento de la recuperación adaptando las respuestas del sistema en función de cada acción que un usuario haya tomado, y planteamos el problema de optimización como una tarea de decisión. Específicamente, en cualquier momento, el sistema intentaría realizar dos tareas: (1) Actualización del modelo de usuario: Monitorear cualquier evidencia útil del usuario con respecto a su necesidad de información y actualizar el modelo de usuario tan pronto como esta evidencia esté disponible; (2) Mejorar los resultados de búsqueda: Reclasificar inmediatamente todos los documentos que el usuario aún no ha visto, tan pronto como se actualice el modelo de usuario. Enfatizamos la actualización y reordenamiento entusiastas, lo que hace que nuestro trabajo sea bastante diferente a cualquier trabajo existente. A continuación presentamos un marco formal de teoría de decisiones para optimizar el rendimiento de recuperación a través de la modelización implícita del usuario en la recuperación de información interactiva. 3.1 Un marco de teoría de decisiones Sea A el conjunto de todas las acciones del usuario y R(a) el conjunto de todas las posibles respuestas del sistema a una acción del usuario a ∈ A. En cualquier momento, sea At = (a1, ..., at) la secuencia observada de acciones de usuario hasta ahora (hasta el momento t) y Rt−1 = (r1, ..., rt−1) las respuestas que el sistema ha dado en respuesta a las acciones del usuario. El objetivo del sistema es elegir una respuesta óptima rt ∈ R(at) para la acción actual del usuario at. Sea M el espacio de todos los posibles modelos de usuario. Definimos además una función de pérdida L(a, r, m) ∈ , donde a ∈ A es una acción del usuario, r ∈ R(a) es una respuesta del sistema, y m ∈ M es un modelo de usuario. L(a, r, m) codifica nuestras preferencias de decisión y evalúa la optimalidad de responder con r cuando el modelo de usuario actual es m y la acción de usuario actual es a. Según la teoría de decisión bayesiana, la decisión óptima en el tiempo t es elegir una respuesta que minimice el riesgo de Bayes, es decir, r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) donde P(mt|U, D, At, Rt−1) es la probabilidad posterior del modelo de usuario mt dadas todas las observaciones sobre el usuario U que hemos realizado hasta el tiempo t. Para simplificar el cálculo de la Ecuación 1, asumamos que la masa de probabilidad posterior P(mt|U, D, At, Rt−1) está principalmente concentrada en el modo m∗ t = argmaxmt P(mt|U, D, At, Rt−1). Podemos entonces aproximar la integral con el valor de la función de pérdida en m∗ t. Es decir, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) donde m∗ t = argmaxmt P(mt|U, D, At, Rt−1). Dejando de lado cómo definir y estimar estos modelos probabilísticos y la función de pérdida, podemos ver que tal formulación de la teoría de decisiones sugiere que, para elegir la respuesta óptima a at, el sistema debería realizar dos tareas: (1) calcular el modelo de usuario actual y obtener m∗ t basado en toda la información útil. (2) elegir una respuesta rt para minimizar el valor de la función de pérdida L(at, rt, m∗ t). Cuando at no afecta nuestra creencia sobre m∗ t , el primer paso puede omitirse y podemos reutilizar m∗ t−1 para m∗ t . Ten en cuenta que nuestro marco de trabajo es bastante general, ya que potencialmente podemos modelar cualquier tipo de acciones de usuario y respuestas del sistema. En la mayoría de los casos, como podríamos esperar, la respuesta del sistema es algún tipo de clasificación de documentos, es decir, para la mayoría de las acciones a, R(a) consiste en todas las posibles clasificaciones de los documentos no vistos, y el problema de decisión se reduce a elegir la mejor clasificación de los documentos no vistos basándose en el modelo de usuario más actualizado. Cuando a es la acción de enviar una consulta de palabras clave, tal respuesta es exactamente lo que haría un sistema de recuperación actual. Sin embargo, fácilmente podemos imaginar que un motor de búsqueda web más inteligente respondería al clic del usuario en el enlace Siguiente (para obtener más resultados no vistos) con una clasificación más optimizada de documentos basada en cualquier documento visto en la página actual de resultados. De hecho, según nuestra estrategia de actualización entusiasta, incluso podríamos permitir que un sistema responda al clic del botón Atrás del navegador por parte de un usuario después de ver un documento de la misma manera, para que el usuario pueda beneficiarse al máximo de la retroalimentación implícita. Estos son precisamente lo que nuestro sistema UCAIR hace. 3.2 Modelos de usuario Un modelo de usuario m ∈ M representa lo que sabemos sobre el usuario U, por lo que en principio, puede contener cualquier información sobre el usuario que deseemos modelar. Ahora discutimos dos componentes importantes en un modelo de usuario. El primer componente es un modelo de componente de la necesidad de información de los usuarios. Presumiblemente, el factor más importante que afecta la optimalidad de la respuesta del sistema es qué tan bien la respuesta aborda la necesidad de información de los usuarios. De hecho, en cualquier momento, podemos asumir que el sistema tiene alguna creencia sobre lo que le interesa al usuario, la cual modelamos a través de un vector de términos x = (x1, ..., x|V|), donde V = {w1, ..., w|V|} es el conjunto de todos los términos (es decir, vocabulario) y xi es el peso del término wi. Un vector de términos de este tipo se utiliza comúnmente en la recuperación de información para representar tanto consultas como documentos. Por ejemplo, el modelo de espacio vectorial asume que tanto la consulta como los documentos se representan como vectores de términos y que la puntuación de un documento con respecto a una consulta se calcula en función de la similitud entre el vector de la consulta y el vector del documento [21]. En un enfoque de modelado de lenguaje, también podemos considerar el modelo de lenguaje unigrama de consulta [12, 29] o el modelo de relevancia [14] como una representación vectorial de términos de la necesidad de información de los usuarios. Intuitivamente, x asignaría pesos altos a los términos que caracterizan los temas que interesan al usuario. El segundo componente que podemos incluir en nuestro modelo de usuario son los documentos que el usuario ya ha visto. Obviamente, incluso si un documento es relevante, si el usuario ya ha visto el documento, no sería útil presentar el mismo documento de nuevo. Por lo tanto, introducimos otra variable S ⊂ D (D es el conjunto completo de documentos en la colección) para denotar el subconjunto de documentos en los resultados de búsqueda que el usuario ya ha visto. En general, en el tiempo t, podemos representar un modelo de usuario como mt = (S, x, At, Rt−1), donde S son los documentos vistos, x es la comprensión del sistema de la necesidad de información del usuario, y (At, Rt−1) representa el historial de interacción del usuario. Ten en cuenta que un modelo de usuario aún más general también puede incluir otros factores como el nivel de lectura y la ocupación de los usuarios. Si asumimos que la incertidumbre de un modelo de usuario mt se debe únicamente a la incertidumbre de x, el cálculo de nuestra estimación actual del modelo de usuario m∗ t implicará principalmente calcular nuestra mejor estimación de x. Es decir, el sistema elegiría una respuesta de acuerdo a r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) donde x∗ = argmaxx P(x|U, D, At, Rt−1). Este es el mecanismo de decisión implementado en el sistema UCAIR que se describirá más adelante. En este sistema, evitamos especificar el modelo probabilístico P(x|U, D, At, Rt−1) calculando x∗ directamente con algún método de retroalimentación existente. 3.3 Funciones de pérdida La definición exacta de la función de pérdida L depende de las respuestas, por lo que es inevitablemente específica de la aplicación. Ahora discutimos brevemente algunas posibilidades cuando la respuesta es clasificar todos los documentos no vistos y presentar los mejores k de ellos. Sea r = (d1, ..., dk) los k documentos principales, S el conjunto de documentos vistos por el usuario, y x∗ la mejor suposición del sistema sobre la necesidad de información del usuario. Podemos definir simplemente la pérdida asociada con r como la suma negativa de la probabilidad de que cada uno de los di sea relevante, es decir, L(a, r, m) = − k i=1 P(relevante|di, m). Claramente, para minimizar esta función de pérdida, la respuesta óptima r contendría los k documentos con la probabilidad más alta de relevancia, lo cual es intuitivamente razonable. Una deficiencia de esta función de pérdida top-k es que no es sensible al orden interno de los documentos top k seleccionados, por lo que cambiar el orden de clasificación de un documento no relevante y uno relevante no afectaría la pérdida, lo cual es irrazonable. Para modelar el ranking, podemos introducir un factor del modelo de usuario: la probabilidad de que cada uno de los k documentos sea visto por el usuario, P(vista|di), y definir la siguiente función de pérdida de ranking: L(a, r, m) = − k i=1 P(vista|di)P(relevante|di, m). Dado que, en general, si di está clasificado por encima de dj (es decir, i < j), P(vista|di) > P(vista|dj), esta función de pérdida favorecería una decisión de clasificar documentos relevantes por encima de los no relevantes, ya que de lo contrario, siempre podríamos intercambiar di con dj para reducir el valor de pérdida. Por lo tanto, el sistema simplemente debería realizar una recuperación regular y clasificar los documentos según la probabilidad de relevancia [18]. Dependiendo de las preferencias de recuperación de los usuarios, puede haber muchas otras posibilidades. Por ejemplo, si el usuario no desea ver documentos redundantes, la función de pérdida debería incluir alguna medida de redundancia en r basada en los documentos ya vistos S. Por supuesto, cuando la respuesta no es elegir una lista clasificada de documentos, necesitaríamos una función de pérdida diferente. Discutimos un ejemplo relevante para el agente de búsqueda que implementamos. Cuando un usuario ingresa una consulta qt (acción actual), nuestro agente de búsqueda se basa en algún motor de búsqueda existente para llevar a cabo la búsqueda en realidad. En tal caso, aunque el agente de búsqueda no tenga control sobre el algoritmo de recuperación, aún puede intentar optimizar los resultados de la búsqueda refinando la consulta enviada al motor de búsqueda y/o reordenando los resultados obtenidos del motor de búsqueda. Las funciones de pérdida para el reordenamiento ya fueron discutidas anteriormente; ahora echamos un vistazo a las funciones de pérdida para el refinamiento de consultas. Sea f la función de recuperación del motor de búsqueda que nuestro agente utiliza, de modo que f(q) nos daría los resultados de búsqueda utilizando la consulta q. Dado que la acción actual del usuario es ingresar una consulta qt (es decir, at = qt), nuestra respuesta sería f(q) para algún q. Dado que no tenemos elección de f, nuestra decisión es elegir un buen q. Formalmente, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) lo cual muestra que nuestro objetivo es encontrar q∗ = argminqL(qt, f(q), m), es decir, una consulta óptima que nos daría el mejor f(q). Una elección diferente de la función de pérdida L(qt, f(q), m) llevaría a una estrategia de refinamiento de consulta diferente. En UCAIR, calculamos heurísticamente q∗ expandiendo qt con términos extraídos de rt−1 siempre que qt−1 y qt tengan una alta similitud. Se debe tener en cuenta que rt−1 y qt−1 están contenidos en m como parte del historial de interacción de los usuarios. 3.4 Modelado implícito del usuario El modelado implícito del usuario se captura en nuestro marco a través del cálculo de x∗ = argmaxx P(x|U, D, At, Rt−1), es decir, la creencia actual del sistema sobre cuál es la necesidad de información del usuario. Aquí nuevamente puede haber muchas posibilidades, lo que lleva a diferentes algoritmos para la modelización implícita del usuario. Ahora discutimos algunos de ellos. Primero, cuando dos consultas consecutivas están relacionadas, la consulta anterior puede ser explotada para enriquecer la consulta actual y proporcionar más contexto de búsqueda para ayudar en la desambiguación. Para este propósito, en lugar de realizar una expansión de consulta como lo hicimos en la sección anterior, también podríamos calcular un x∗ actualizado basado en la consulta anterior y los resultados de recuperación. El modelo de usuario nuevo calculado puede luego ser utilizado para clasificar los documentos con un modelo estándar de recuperación de información. Segundo, también podemos inferir los intereses de un usuario basándonos en los resúmenes de los documentos visualizados. Cuando a un usuario se le presenta una lista de resúmenes de documentos mejor clasificados, si el usuario elige saltarse los primeros n documentos y ver el documento (n+1)-ésimo, podemos inferir que el usuario no está interesado en los resúmenes mostrados para los primeros n documentos, pero está atraído por el resumen mostrado del documento (n+1)-ésimo. Por lo tanto, podemos usar estos resúmenes como ejemplos negativos y positivos para aprender un modelo de usuario más preciso x∗. Aquí se pueden explotar muchas técnicas estándar de retroalimentación de relevancia [19, 20]. Ten en cuenta que debemos utilizar los resúmenes mostrados, en lugar de los contenidos reales de esos documentos, ya que es posible que el resumen mostrado del documento visto sea relevante, pero el contenido del documento en realidad no lo sea. Del mismo modo, un resumen mostrado puede llevar a un usuario a omitir un documento relevante. Inferir modelos de usuario basados en dicha información mostrada, en lugar del contenido real de un documento, es una diferencia importante entre UCAIR y algunos otros sistemas similares. En UCAIR, ambas estrategias para inferir un modelo de usuario implícito están implementadas. 4. UCAIR: Un agente de búsqueda personalizado 4.1 Diseño En esta sección, presentamos un agente de búsqueda web del lado del cliente llamado UCAIR, en el cual implementamos algunos de los métodos discutidos en la sección anterior para realizar búsquedas personalizadas a través de modelado implícito del usuario. UCAIR es un complemento del navegador web que actúa como proxy para los motores de búsqueda en la web. Actualmente, solo está implementado para Internet Explorer y Google, pero es cuestión de ingeniería hacer que funcione en otros navegadores web e interactúe con otros motores de búsqueda. El tema de la privacidad es un obstáculo principal para implementar cualquier aplicación del mundo real que involucre modelado de usuarios serio, como la búsqueda personalizada. Por esta razón, UCAIR funciona estrictamente como un agente de búsqueda del lado del cliente, en lugar de ser una aplicación del lado del servidor. De esta manera, la información del usuario capturada siempre permanece en la computadora que está utilizando el usuario, por lo tanto, el usuario no necesita revelar ninguna información al exterior. La personalización del lado del cliente también permite que el sistema observe fácilmente una gran cantidad de información del usuario que puede no estar fácilmente disponible para un servidor. Además, realizar búsquedas personalizadas en el lado del cliente es más escalable que en el lado del servidor, ya que la sobrecarga de cálculo y almacenamiento se distribuye entre los clientes. Como se muestra en la Figura 1, la barra de herramientas UCAIR tiene 3 componentes principales: (1) El módulo de modelado de usuario (implícito) captura el contexto de búsqueda de un usuario e información de historial, incluidas las consultas enviadas y los resultados de búsqueda clicados, e infiere los límites de la sesión de búsqueda. (2) El módulo de modificación de consultas mejora selectivamente la formulación de la consulta de acuerdo con el modelo de usuario actual. (3) El módulo de reordenamiento de resultados reordena inmediatamente cualquier resultado de búsqueda no visto cada vez que se actualiza el modelo de usuario. En UCAIR, consideramos cuatro acciones básicas de usuario: (1) enviar una consulta de palabras clave; (2) ver un documento; (3) hacer clic en el botón Atrás; (4) hacer clic en el enlace Siguiente en una página de resultados. Para cada una de estas cuatro acciones, el sistema responde con, respectivamente, (1) 1 UCAIR está disponible en: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Registro de Historial de Búsqueda del Motor de Búsqueda (por ejemplo, Google) (consultas pasadas, resultados clicados) Modificación de Consulta Resultado de Reclasificación Modelo de Usuario Buffer de Resultados de Consulta de Usuario UCAIR... Figura 1: arquitectura de UCAIR generando una lista clasificada de resultados enviando una consulta posiblemente ampliada a un motor de búsqueda; (2) actualizando el modelo de necesidad de información x; (3) reordenando los resultados no vistos en la página de resultados actual basándose en el modelo actual x; y (4) reordenando las páginas no vistas y generando la siguiente página de resultados basándose en el modelo actual x. Detrás de estas respuestas, hay tres tareas básicas: (1) Decidir si la consulta anterior está relacionada con la consulta actual y, de ser así, ampliar la consulta actual con términos útiles de la consulta anterior o los resultados de la consulta anterior. (2) Actualizar el modelo de necesidad de información x basado en un resumen de documento recién seleccionado. (3) Reordenar un conjunto de documentos no vistos basado en el modelo x actual. A continuación describimos nuestros algoritmos para cada uno de ellos. 4.2 Detección de límites de sesión y expansión de consultas Para explotar eficazmente las consultas anteriores y su información correspondiente de clics, UCAIR necesita determinar si dos consultas adyacentes pertenecen a la misma sesión de búsqueda (es decir, detectar los límites de sesión). El trabajo existente sobre la detección de límites de sesión se encuentra principalmente en el contexto del análisis de registros web (por ejemplo, [8]), y utiliza información estadística en lugar de características textuales. Dado que nuestro agente del lado del cliente no tiene acceso a los registros de consultas del servidor, tomamos decisiones sobre los límites de sesión basadas en la similitud textual entre dos consultas. Debido a que las consultas relacionadas no necesariamente comparten las mismas palabras (por ejemplo, isla de Java y viajar a Indonesia), no es suficiente utilizar solo el texto de la consulta. Por lo tanto, utilizamos los resultados de búsqueda de las dos consultas para ayudar a decidir si están relacionadas temáticamente. Por ejemplo, para las consultas anteriores \"java island\" y \"travel Indonesia\", las palabras \"java\", \"bali\", \"island\", \"indonesia\" y \"travel\" pueden aparecer con frecuencia en los resultados de búsqueda de ambas consultas, lo que produce un alto puntaje de similitud. Solo utilizamos los títulos y resúmenes de los resultados de búsqueda para calcular la similitud, ya que están disponibles en la página de resultados de búsqueda recuperada y obtener el texto completo de cada página de resultados ralentizaría significativamente el proceso. Para compensar la concisión de los títulos y resúmenes, recuperamos más resultados de los que un usuario normalmente vería con el propósito de detectar los límites de sesión (típicamente 50 resultados). La similitud entre la consulta anterior q y la consulta actual q se calcula de la siguiente manera. Sean {s1, s2, . . . , sn} y {s1, s2, . . . , sn} los conjuntos de resultados de las dos consultas. Utilizamos la fórmula de ponderación TF-IDF normalizada pivotada [24] para calcular un vector de peso de término si para cada resultado si. Definimos el resultado promedio savg como el centroide de todos los vectores de resultado, es decir, (s1 + s2 + . . . + sn)/n. La similitud del coseno entre los dos resultados promedio se calcula como s avg · savg/ s 2 avg · s2 avg. Si el valor de similitud supera un umbral predefinido, se considerará que las dos consultas están en la misma sesión de información. Si se determina que la consulta anterior y la consulta actual pertenecen a la misma sesión de búsqueda, UCAIR intentaría expandir la consulta actual con términos de la consulta anterior y sus resultados de búsqueda. Específicamente, para cada término en la consulta anterior o los resultados de búsqueda correspondientes, si su frecuencia en los resultados de la consulta actual es mayor que un umbral preestablecido (por ejemplo, 5 resultados de 50), el término se agregaría a la consulta actual para formar una consulta ampliada. En este caso, UCAIR enviaría esta consulta ampliada en lugar de la original al motor de búsqueda y devolvería los resultados correspondientes a la consulta ampliada. Actualmente, UCAIR solo utiliza la consulta inmediatamente anterior para la expansión de consultas; en principio, podríamos aprovechar todas las consultas pasadas relacionadas. 4.3 Actualización del modelo de necesidad de información Supongamos que en el tiempo t, hemos observado que el usuario ha visto k documentos cuyos resúmenes son s1, ..., sk. Actualizamos nuestro modelo de usuario calculando un nuevo vector de necesidad de información con un método estándar de retroalimentación en la recuperación de información (es decir, Rocchio [19]). Según el modelo de recuperación de espacio vectorial, cada resumen clicado si puede ser representado por un vector de pesos de términos si, con cada término ponderado por una fórmula de ponderación TF-IDF [21]. Rocchio calcula el vector centroide de todos los resúmenes e interpola este con el vector de consulta original para obtener un vector de términos actualizado. Es decir, x = αq + (1 − α) 1 k k i=1 si donde q es el vector de consulta, k es el número de resúmenes que el usuario hace clic inmediatamente después de la consulta actual y α es un parámetro que controla la influencia de los resúmenes clicados en el modelo de necesidad de información inferida. En nuestros experimentos, α se establece en 0.5. Ten en cuenta que actualizamos el modelo de información necesario cada vez que el usuario ve un documento. 4.4 Reclasificación de resultados En general, queremos volver a clasificar todos los resultados no vistos tan pronto como se actualice el modelo de usuario. Actualmente, UCAIR implementa el reordenamiento en dos casos, correspondientes a cuando el usuario hace clic en el botón Atrás y en el enlace Siguiente en Internet Explorer. En ambos casos, el modelo de usuario actualizado se utilizaría para reordenar los resultados no vistos de manera que el usuario vea resultados de búsqueda mejorados de inmediato. Para volver a clasificar cualquier resumen de documento no visto, UCAIR utiliza el modelo estándar de recuperación de espacio vectorial y puntúa cada resumen en función de la similitud del resultado y el vector de necesidad de información actual del usuario x [21]. Dado que la retroalimentación implícita no es completamente confiable, presentamos solo un pequeño número (por ejemplo, 5) de los resultados reordenados más altos para ser seguidos por cualquier resultado originalmente clasificado alto. 828 resultados de Google (consulta del usuario = mapa de Java) Resultados de UCAIR (consulta del usuario = mapa de Java) consulta anterior = viajar a Indonesia consulta anterior = tabla hash consulta del usuario ampliada = mapa de Java Indonesia consulta del usuario ampliada = clase de mapa de Java 1 Proyecciones de mapas de Java del mundo ... Lonely Planet - Mapa de Indonesia Mapa (Plataforma Java SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Proyecciones de mapas de Java del mundo ... TURISMO DE INDONESIA: JAVA CENTRAL - MAPA Plataforma Java SE v1.3.1: Interfaz de Mapa www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Mapa de Java TURISMO DE INDONESIA: JAVA OESTE - MAPA Una introducción a las clases de colección de mapas de Java java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Mapa de Tecnología Java IndoStreets - Mapa de Java Una introducción a las clases de colección de mapas de Java java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Regiones e islas de Indonesia Mapas, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 Una introducción a las clases de colección de mapas de Java Mapa de calles de la ciudad de Indonesia,... Hibernate simplifica el mapeo de herencia www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Mapa de Java Mapas de Indonesia jerarquía de clases de tmap 30.map www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Mapa de API de Java Mapas de Indonesia por Peter Loud Alcance de clases www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas: Mapas de Sam de Indonesia por Peter Loud PrintSafeHashMap de la clase www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 TURISMO DE INDONESIA: JAVA OESTE - MAPA indonesiaphoto.com Java Pro - Unión y mapeo vertical de clases www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Tabla 1: Resultados de muestra de la expansión de la consulta EVALUACIÓN DE UCAIR Ahora presentamos algunos resultados sobre la evaluación de las dos principales funciones de UCAIR: la expansión selectiva de consultas y la reordenación de resultados basada en los datos de clics de los usuarios. 5.1 Resultados de muestra La estrategia de expansión de consultas implementada en UCAIR es intencionalmente conservadora para evitar la interpretación errónea de los modelos implícitos de los usuarios. En la práctica, cada vez que decide expandir la consulta, la expansión suele tener sentido. En la Tabla 1, mostramos cómo UCAIR puede distinguir exitosamente dos contextos de búsqueda diferentes para la consulta java map, correspondientes a dos consultas previas distintas (es decir, viajar a Indonesia vs. hashtable). Debido a la modelización implícita del usuario, UCAIR descubre inteligentemente agregar Indonesia y clase, respectivamente, a la consulta de los usuarios sobre el mapa de Java, lo cual de otro modo sería ambiguo, como se muestra en los resultados originales de Google el 21 de marzo de 2005. Los resultados de UCAIR son mucho más precisos que los resultados de Google y reflejan la personalización en la búsqueda. El componente de retroalimentación implícita entusiasta está diseñado para responder inmediatamente a la actividad de un usuario, como por ejemplo, al visualizar un documento. En la Figura 2, mostramos cómo UCAIR puede desambiguar con éxito una consulta ambigua de jaguar al explotar un resumen del documento visualizado. En este caso, los resultados iniciales de recuperación utilizando \"jaguar\" (mostrados en el lado izquierdo) contienen dos resultados sobre los autos Jaguar seguidos por dos resultados sobre el software Jaguar. Sin embargo, después de que el usuario ve el contenido de la página web del segundo resultado (sobre el automóvil Jaguar) y regresa a la página de resultados de búsqueda haciendo clic en el botón Atrás, UCAIR automáticamente selecciona dos nuevos resultados de búsqueda sobre automóviles Jaguar (mostrados en el lado derecho), mientras que los dos resultados originales sobre software de Jaguar se desplazan hacia abajo en la lista (no se ven en la imagen). 5.2 Evaluación cuantitativa Para evaluar UCAIR de manera cuantitativa, realizamos un estudio de usuario sobre la efectividad del componente de retroalimentación implícita ansiosa. Es un desafío evaluar cuantitativamente la mejora potencial en el rendimiento de nuestro modelo propuesto y UCAIR sobre Google de manera imparcial [7]. Aquí diseñamos un estudio de usuarios, en el cual los participantes realizarían una búsqueda web normal y evaluarían al azar y de forma anónima un conjunto de resultados mezclados de Google y UCAIR al final de la sesión de búsqueda; los participantes no saben si un resultado proviene de Google o de UCAIR. Reclutamos a 6 estudiantes de posgrado para este estudio de usuarios, quienes tienen diferentes antecedentes (3 en informática, 2 en biología y 1 en química). Los documentos que describen leyes para limitar el correo no deseado sin dar detalles de demandas judiciales o juicios penales no son relevantes. Utilizamos los temas de consulta de la pista Terabyte TREC 2 2004 [2] y la tarea de destilación de temas de la pista web TREC 2003 [4] de la manera que se describirá a continuación. Un ejemplo de tema del TREC 2004 Terabyte track aparece en la Figura 3. El título es una frase corta y puede ser utilizada como una consulta al sistema de recuperación. El campo de descripción proporciona una declaración ligeramente más larga del requisito del tema, generalmente expresado como una sola oración completa o pregunta. Finalmente, la narrativa proporciona información adicional necesaria para especificar completamente el requisito, expresado en forma de un breve párrafo. Inicialmente, cada participante exploraría 50 temas ya sea de la categoría Terabyte o de la categoría Web y elegiría los 5 o 7 temas más interesantes. Para cada tema seleccionado, el participante básicamente realizaría la búsqueda web normal utilizando UCAIR para encontrar muchas páginas web relevantes utilizando el título del tema de la consulta como la palabra clave inicial de la consulta. Durante este proceso, el participante puede ver los resultados de la búsqueda y posiblemente hacer clic en algunos interesantes para ver las páginas web, tal como en una búsqueda web normal. No hay ningún requisito o restricción sobre cuántas consultas debe enviar el participante o cuándo debe detener la búsqueda de un tema. Cuando el participante planea cambiar el tema de búsqueda, simplemente presionará un botón 2 de la Conferencia de Recuperación de Texto: http://trec.nist.gov/ 829 Figura 2: Capturas de pantalla para volver a clasificar los resultados y evaluar los resultados de búsqueda antes de cambiar al siguiente tema. En el momento de la evaluación, los 30 resultados mejor clasificados de Google y UCAIR (algunos se superponen) se mezclan aleatoriamente para que el participante no sepa si un resultado proviene de Google o de UCAIR. El participante luego juzgaría la relevancia de estos resultados. Medimos la precisión en los primeros n (n = 5, 10, 20, 30) documentos de Google y UCAIR. También evaluamos precisiones en diferentes niveles de recuperación. En total, 368 documentos fueron considerados relevantes a partir de los resultados de búsqueda de Google y 429 documentos fueron considerados relevantes por los participantes de UCAIR. Los diagramas de dispersión de precisión en los 10 y 20 documentos principales se muestran en la Figura 4 y la Figura 5 respectivamente (El diagrama de dispersión de precisión en los 30 documentos principales es muy similar al de los 20 documentos principales). Cada punto de los gráficos de dispersión representa las precisiones de Google y UCAIR en un tema de consulta. La Tabla 2 muestra la precisión promedio en los primeros n documentos entre 32 temas. A partir de la Figura 4, la Figura 5 y la Tabla 2, vemos que los resultados de búsqueda de UCAIR son consistentemente mejores que los de Google en todas las medidas. Además, la mejora en el rendimiento es más dramática para la precisión en los primeros 20 documentos que para la precisión en los primeros 10 documentos. Una explicación para esto es que cuanto más interacción tenga el usuario con el sistema, más datos de clics se espera que UCAIR pueda recopilar. Por lo tanto, el sistema de recuperación puede construir modelos de usuario implícitos más precisos, lo que conduce a una mayor precisión en la recuperación. El Método de Clasificación prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Mejora 8.0% 17.8% 20.2% 21.8% Tabla 2: Tabla de precisión promedio en los primeros n documentos para 32 temas de consulta El gráfico en la Figura 6 muestra las curvas de precisión-recuperación para UCAIR y Google, donde se observa claramente que el rendimiento de UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Gráfico de dispersión de Precisión en los 10 primeros documentos Figura 4: La precisión en los 10 primeros documentos de UCAIR y Google es consistentemente y considerablemente mejor que la de Google en todos los niveles de recuperación. 6. CONCLUSIONES En este artículo, estudiamos cómo aprovechar la modelización implícita del usuario para personalizar de manera inteligente la recuperación de información y mejorar la precisión de la búsqueda. A diferencia de la mayoría de trabajos anteriores, enfatizamos el uso del contexto de búsqueda inmediata y la información de retroalimentación implícita, así como la actualización rápida de los resultados de búsqueda para beneficiar al máximo a un usuario. Presentamos un marco de trabajo de toma de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos adecuados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para volver a clasificar inmediatamente cualquier documento que aún no haya sido visto por el usuario. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente (UCAIR) sobre un motor de búsqueda popular (Google). Los experimentos en la búsqueda web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en más de un 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Gráfico de dispersión de Precisión en los 20 documentos principales Figura 5: Precisión en los 20 documentos principales de UCAIR y Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 precisión recall Curvas de Precisión-Recall Resultado de Google Resultado de UCAIR Figura 6: Precisión en los 20 resultados principales de UCAIR y Google Google. Dado que la información implícita que aprovechamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional. El agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin necesidad de esfuerzo adicional por parte del usuario. AGRADECIMIENTO Agradecemos a los seis participantes de nuestros experimentos de evaluación. Este trabajo fue apoyado en parte por las subvenciones de la Fundación Nacional de Ciencias IIS-0347933 e IIS-0428472. REFERENCIAS [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman y O. Frieder. Análisis por hora de un registro de consultas web muy grande categorizado por tema. En Actas de SIGIR 2004, páginas 321-328, 2004. [2] C. Clarke, N. Craswell e I. Soboroff. Resumen de la pista de terabyte TREC 2004. En Actas de TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda y D. Brown. Indicadores implícitos de interés. En Actas de Interfaces de Usuario Inteligentes 2001, páginas 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson y M. Wu. Resumen de la pista web TREC 2003. En Actas de TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend y V. Larvrenko. Retroalimentación de relevancia y personalización: Una perspectiva de modelado del lenguaje. En Actas del Segundo Taller DELOS: Personalización y Sistemas de Recomendación en Bibliotecas Digitales, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite y D. Harman. Resultados y desafíos en la evaluación de búsqueda en la web. Redes de Computadoras, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A. An, y D. Schuurmans. Identificación dinámica de sesiones de registro web con modelos de lenguaje estadístico. Revista de la Sociedad Americana de Ciencia de la Información y Tecnología, 55(14):1290-1303, 2004. [9] G. Jeh y J. Widom. Escalando la búsqueda web personalizada. En Actas de WWW 2003, páginas 271-279, 2003. [10] T. Joachims. Optimización de motores de búsqueda utilizando datos de clics. En Actas de SIGKDD 2002, páginas 133-142, 2002. [11] D. Kelly y J. Teevan. Retroalimentación implícita para inferir preferencias de usuario: Una bibliografía. SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En Actas de SIGIR01, páginas 111-119, 2001. [13] T. Lau y E. Horvitz. Patrones de búsqueda: Análisis y modelado de la refinación de consultas web. En Actas de la Séptima Conferencia Internacional sobre Modelado de Usuarios (UM), páginas 145-152, 1999. [14] V. Lavrenko y B. Croft. Modelos de lenguaje basados en relevancia. En Actas de SIGIR01, páginas 120-127, 2001. [15] M. Mitra, A. Singhal y C. Buckley. Mejorando la expansión automática de consultas. En Actas de SIGIR 1998, páginas 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg. Según Google, así va la nación. New York Times, mayo de 2003. [18] S. E. Robertson. El principio de clasificación de probabilidad en ı˚. Revista de Documentación, 33(4):294-304, 1977. [19] J. J. Rocchio. Retroalimentación de relevancia en la recuperación de información. En el Sistema de Recuperación SMART: Experimentos en el Procesamiento Automático de Documentos, páginas 313-323. Prentice-Hall Inc., 1971. [20] G. Salton y C. Buckley. Mejorando el rendimiento de recuperación mediante retroalimentación de recuperación. Revista de la Sociedad Americana de Ciencia de la Información, 41(4):288-297, 1990. [21] G. Salton y M. J. McGill. Introducción a la Recuperación de Información Moderna. McGraw-Hill, 1983. [22] X. Shen, B. Tan y C. Zhai. Recuperación de información sensible al contexto utilizando retroalimentación implícita. En Actas de SIGIR 2005, páginas 43-50, 2005. [23] X. Shen y C. Zhai. Explotando el historial de consultas para la clasificación de documentos en la recuperación de información interactiva (Póster). En Actas de SIGIR 2003, páginas 377-378, 2003. [24] A. Singhal. Recuperación de información moderna: Una breve visión general. Boletín del Comité Técnico de Ingeniería de Datos de la Sociedad de Computación de IEEE, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano y M. Yoshikawa. Búsqueda web adaptativa basada en el perfil del usuario construido sin ningún esfuerzo por parte de los usuarios. En Actas de WWW 2004, páginas 675-684, 2004. [26] E. Volokh. Personalización y privacidad. Comunicaciones de la ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen e I. Ruthven. Un estudio simulado de modelos de retroalimentación implícita. En Actas de ECIR 2004, páginas 311-326, 2004. [28] J. Xu y W. B. Croft. Expansión de consultas utilizando análisis local y global de documentos. En Actas de SIGIR 1996, páginas 4-11, 1996. [29] C. Zhai y J. Lafferty. Modelo de retroalimentación basado en el modelo de recuperación de divergencia de KL. En Actas de la CIKM 2001, páginas 403-410, 2001. 831",
    "original_sentences": [
        "Implicit User Modeling for Personalized Search Xuehua Shen, Bin Tan, ChengXiang Zhai Department of Computer Science University of Illinois at Urbana-Champaign ABSTRACT Information retrieval systems (e.g., web search engines) are critical for overcoming information overload.",
        "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users, resulting in inherently non-optimal retrieval performance.",
        "For example, a tourist and a programmer may use the same word java to search for different information, but the current search systems would return the same results.",
        "In this paper, we study how to infer a users interest from the users search context and use the inferred implicit user model for personalized search .",
        "We present a decision theoretic framework and develop techniques for implicit user modeling in information retrieval.",
        "We develop an intelligent client-side web search agent (UCAIR) that can perform eager implicit feedback, e.g., query expansion based on previous queries and immediate result reranking based on clickthrough information.",
        "Experiments on web search show that our search agent can improve search accuracy over the popular Google search engine.",
        "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models, Relevance feedback, Search Process General Terms Algorithms 1.",
        "INTRODUCTION Although many information retrieval systems (e.g., web search engines and digital library systems) have been successfully deployed, the current retrieval systems are far from optimal.",
        "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users [17].",
        "This inherent non-optimality is seen clearly in the following two cases: (1) Different users may use exactly the same query (e.g., Java) to search for different information (e.g., the Java island in Indonesia or the Java programming language), but existing IR systems return the same results for these users.",
        "Without considering the actual user, it is impossible to know which sense Java refers to in a query. (2) A users information needs may change over time.",
        "The same user may use Java sometimes to mean the Java island in Indonesia and some other times to mean the programming language.",
        "Without recognizing the search context, it would be again impossible to recognize the correct sense.",
        "In order to optimize retrieval accuracy, we clearly need to model the user appropriately and personalize search according to each individual user.",
        "The major goal of user modeling for information retrieval is to accurately model a users information need, which is, unfortunately, a very difficult task.",
        "Indeed, it is even hard for a user to precisely describe what his/her information need is.",
        "What information is available for a system to infer a users information need?",
        "Obviously, the users query provides the most direct evidence.",
        "Indeed, most existing retrieval systems rely solely on the query to model a users information need.",
        "However, since a query is often extremely short, the user model constructed based on a keyword query is inevitably impoverished .",
        "An effective way to improve user modeling in information retrieval is to ask the user to explicitly specify which documents are relevant (i.e., useful for satisfying his/her information need), and then to improve user modeling based on such examples of relevant documents.",
        "This is called relevance feedback, which has been proved to be quite effective for improving retrieval accuracy [19, 20].",
        "Unfortunately, in real world applications, users are usually reluctant to make the extra effort to provide relevant examples for feedback [11].",
        "It is thus very interesting to study how to infer a users information need based on any implicit feedback information, which naturally exists through user interactions and thus does not require any extra user effort.",
        "Indeed, several previous studies have shown that implicit user modeling can improve retrieval accuracy.",
        "In [3], a web browser (Curious Browser) is developed to record a users explicit relevance ratings of web pages (relevance feedback) and browsing behavior when viewing a page, such as dwelling time, mouse click, mouse movement and scrolling (implicit feedback).",
        "It is shown that the dwelling time on a page, amount of scrolling on a page and the combination of time and scrolling have a strong correlation with explicit relevance ratings, which suggests that implicit feedback may be helpful for inferring user information need.",
        "In [10], user clickthrough data is collected as training data to learn a retrieval function, which is used to produce a customized ranking of search results that suits a group of users preferences.",
        "In [25], the clickthrough data collected over a long time period is exploited through query expansion to improve retrieval accuracy. 824 While a user may have general long term interests and preferences for information, often he/she is searching for documents to satisfy an ad-hoc information need, which only lasts for a short period of time; once the information need is satisfied, the user would generally no longer be interested in such information.",
        "For example, a user may be looking for information about used cars in order to buy one, but once the user has bought a car, he/she is generally no longer interested in such information.",
        "In such cases, implicit feedback information collected over a long period of time is unlikely to be very useful, but the immediate search context and feedback information, such as which of the search results for the current information need are viewed, can be expected to be much more useful.",
        "Consider the query Java again.",
        "Any of the following immediate feedback information about the user could potentially help determine the intended meaning of Java in the query: (1) The previous query submitted by the user is hashtable (as opposed to, e.g., travel Indonesia). (2) In the search results, the user viewed a page where words such as programming, software, and applet occur many times.",
        "To the best of our knowledge, how to exploit such immediate and short-term search context to improve search has so far not been well addressed in the previous work.",
        "In this paper, we study how to construct and update a user model based on the immediate search context and implicit feedback information and use the model to improve the accuracy of ad-hoc retrieval.",
        "In order to maximally benefit the user of a retrieval system through implicit user modeling, we propose to perform eager implicit feedback.",
        "That is, as soon as we observe any new piece of evidence from the user, we would update the systems belief about the users information need and respond with improved retrieval results based on the updated user model.",
        "We present a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
        "In a traditional retrieval paradigm, the retrieval problem is to match a query with documents and rank documents according to their relevance values.",
        "As a result, the retrieval process is a simple independent cycle of query and result display.",
        "In the proposed new retrieval paradigm, the users search context plays an important role and the inferred implicit user model is exploited immediately to benefit the user.",
        "The new retrieval paradigm is thus fundamentally different from the traditional paradigm, and is inherently more general.",
        "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
        "Using these techniques, we develop a client-side web search agent UCAIR (User-Centered Adaptive Information Retrieval) on top of a popular search engine (Google).",
        "Experiments on web search show that our search agent can improve search accuracy over Google.",
        "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
        "Thus the developed search agent can improve existing web search performance without additional effort from the user.",
        "The remaining sections are organized as follows.",
        "In Section 2, we discuss the related work.",
        "In Section 3, we present a decisiontheoretic interactive retrieval framework for implicit user modeling.",
        "In Section 4, we present the design and implementation of an intelligent client-side web search agent (UCAIR) that performs eager implicit feedback.",
        "In Section 5, we report our experiment results using the search agent.",
        "Section 6 concludes our work. 2.",
        "RELATED WORK Implicit user modeling for personalized search has been studied in previous work, but our work differs from all previous work in several aspects: (1) We emphasize the exploitation of immediate search context such as the related immediately preceding query and the viewed documents in the same session, while most previous work relies on long-term collection of implicit feedback information [25]. (2) We perform eager feedback and bring the benefit of implicit user modeling as soon as any new implicit feedback information is available, while the previous work mostly exploits longterm implicit feedback [10]. (3) We propose a retrieval framework to integrate implicit user modeling with the interactive retrieval process, while the previous work either studies implicit user modeling separately from retrieval [3] or only studies specific retrieval models for exploiting implicit feedback to better match a query with documents [23, 27, 22]. (4) We develop and evaluate a personalized Web search agent with online user studies, while most existing work evaluates algorithms offline without real user interactions.",
        "Currently some search engines provide rudimentary personalization, such as Google Personalized web search [6], which allows users to explicitly describe their interests by selecting from predefined topics, so that those results that match their interests are brought to the top, and My Yahoo! search [16], which gives users the option to save web sites they like and block those they dislike.",
        "In contrast, UCAIR personalizes web search through implicit user modeling without any additional user efforts.",
        "Furthermore, the personalization of UCAIR is provided on the client side.",
        "There are two remarkable advantages on this.",
        "First, the user does not need to worry about the privacy infringement, which is a big concern for personalized search [26].",
        "Second, both the computation of personalization and the storage of the user profile are done at the client side so that the server load is reduced dramatically [9].",
        "There have been many works studying user query logs [1] or query dynamics [13].",
        "UCAIR makes direct use of a users query history to benefit the same user immediately in the same search session.",
        "UCAIR first judges whether two neighboring queries belong to the same information session and if so, it selects terms from the previous query to perform query expansion.",
        "Our query expansion approach is similar to automatic query expansion [28, 15, 5], but instead of using pseudo feedback to expand the query, we use users implicit feedback information to expand the current query.",
        "These two techniques may be combined. 3.",
        "OPTIMIZATION IN INTERACTIVE IR In interactive IR, a user interacts with the retrieval system through an action dialogue, in which the system responds to each user action with some system action.",
        "For example, the users action may be submitting a query and the systems response may be returning a list of 10 document summaries.",
        "In general, the space of user actions and system responses and their granularities would depend on the interface of a particular retrieval system.",
        "In principle, every action of the user can potentially provide new evidence to help the system better infer the users information need.",
        "Thus in order to respond optimally, the system should use all the evidence collected so far about the user when choosing a response.",
        "When viewed in this way, most existing search engines are clearly non-optimal.",
        "For example, if a user has viewed some documents on the first page of search results, when the user clicks on the Next link to fetch more results, an existing retrieval system would still return the next page of results retrieved based on the original query without considering the new evidence that a particular result has been viewed by the user. 825 We propose to optimize retrieval performance by adapting system responses based on every action that a user has taken, and cast the optimization problem as a decision task.",
        "Specifically, at any time, the system would attempt to do two tasks: (1) User model updating: Monitor any useful evidence from the user regarding his/her information need and update the user model as soon as such evidence is available; (2) Improving search results: Rerank immediately all the documents that the user has not yet seen, as soon as the user model is updated.",
        "We emphasize eager updating and reranking, which makes our work quite different from any existing work.",
        "Below we present a formal decision theoretic framework for optimizing retrieval performance through implicit user modeling in interactive information retrieval. 3.1 A decision-theoretic framework Let A be the set of all user actions and R(a) be the set of all possible system responses to a user action a ∈ A.",
        "At any time, let At = (a1, ..., at) be the observed sequence of user actions so far (up to time point t) and Rt−1 = (r1, ..., rt−1) be the responses that the system has made responding to the user actions.",
        "The systems goal is to choose an optimal response rt ∈ R(at) for the current user action at.",
        "Let M be the space of all possible user models.",
        "We further define a loss function L(a, r, m) ∈ , where a ∈ A is a user action, r ∈ R(a) is a system response, and m ∈ M is a user model.",
        "L(a, r, m) encodes our decision preferences and assesses the optimality of responding with r when the current user model is m and the current user action is a.",
        "According to Bayesian decision theory, the optimal decision at time t is to choose a response that minimizes the Bayes risk, i.e., r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) where P(mt|U, D, At, Rt−1) is the posterior probability of the user model mt given all the observations about the user U we have made up to time t. To simplify the computation of Equation 1, let us assume that the posterior probability mass P(mt|U, D, At, Rt−1) is mostly concentrated on the mode m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
        "We can then approximate the integral with the value of the loss function at m∗ t .",
        "That is, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) where m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
        "Leaving aside how to define and estimate these probabilistic models and the loss function, we can see that such a decision-theoretic formulation suggests that, in order to choose the optimal response to at, the system should perform two tasks: (1) compute the current user model and obtain m∗ t based on all the useful information. (2) choose a response rt to minimize the loss function value L(at, rt, m∗ t ).",
        "When at does not affect our belief about m∗ t , the first step can be omitted and we may reuse m∗ t−1 for m∗ t .",
        "Note that our framework is quite general since we can potentially model any kind of user actions and system responses.",
        "In most cases, as we may expect, the systems response is some ranking of documents, i.e., for most actions a, R(a) consists of all the possible rankings of the unseen documents, and the decision problem boils down to choosing the best ranking of unseen documents based on the most current user model.",
        "When a is the action of submitting a keyword query, such a response is exactly what a current retrieval system would do.",
        "However, we can easily imagine that a more intelligent web search engine would respond to a users clicking of the Next link (to fetch more unseen results) with a more optimized ranking of documents based on any viewed documents in the current page of results.",
        "In fact, according to our eager updating strategy, we may even allow a system to respond to a users clicking of browsers Back button after viewing a document in the same way, so that the user can maximally benefit from implicit feedback.",
        "These are precisely what our UCAIR system does. 3.2 User models A user model m ∈ M represents what we know about the user U, so in principle, it can contain any information about the user that we wish to model.",
        "We now discuss two important components in a user model.",
        "The first component is a component model of the users information need.",
        "Presumably, the most important factor affecting the optimality of the systems response is how well the response addresses the users information need.",
        "Indeed, at any time, we may assume that the system has some belief about what the user is interested in, which we model through a term vector x = (x1, ..., x|V |), where V = {w1, ..., w|V |} is the set of all terms (i.e., vocabulary) and xi is the weight of term wi.",
        "Such a term vector is commonly used in information retrieval to represent both queries and documents.",
        "For example, the vector-space model, assumes that both the query and the documents are represented as term vectors and the score of a document with respect to a query is computed based on the similarity between the query vector and the document vector [21].",
        "In a language modeling approach, we may also regard the query unigram language model [12, 29] or the relevance model [14] as a term vector representation of the users information need.",
        "Intuitively, x would assign high weights to terms that characterize the topics which the user is interested in.",
        "The second component we may include in our user model is the documents that the user has already viewed.",
        "Obviously, even if a document is relevant, if the user has already seen the document, it would not be useful to present the same document again.",
        "We thus introduce another variable S ⊂ D (D is the whole set of documents in the collection) to denote the subset of documents in the search results that the user has already seen/viewed.",
        "In general, at time t, we may represent a user model as mt = (S, x, At, Rt−1), where S is the seen documents, x is the systems understanding of the users information need, and (At, Rt−1) represents the users interaction history.",
        "Note that an even more general user model may also include other factors such as the users reading level and occupation.",
        "If we assume that the uncertainty of a user model mt is solely due to the uncertainty of x, the computation of our current estimate of user model m∗ t will mainly involve computing our best estimate of x.",
        "That is, the system would choose a response according to r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) where x∗ = argmaxx P(x|U, D, At, Rt−1).",
        "This is the decision mechanism implemented in the UCAIR system to be described later.",
        "In this system, we avoided specifying the probabilistic model P(x|U, D, At, Rt−1) by computing x∗ directly with some existing feedback method. 3.3 Loss functions The exact definition of loss function L depends on the responses, thus it is inevitably application-specific.",
        "We now briefly discuss some possibilities when the response is to rank all the unseen documents and present the top k of them.",
        "Let r = (d1, ..., dk) be the top k documents, S be the set of seen documents by the user, and x∗ be the systems best guess of the users information need.",
        "We 826 may simply define the loss associated with r as the negative sum of the probability that each of the di is relevant, i.e., L(a, r, m) = − k i=1 P(relevant|di, m).",
        "Clearly, in order to minimize this loss function, the optimal response r would contain the k documents with the highest probability of relevance, which is intuitively reasonable.",
        "One deficiency of this top-k loss function is that it is not sensitive to the internal order of the selected top k documents, so switching the ranking order of a non-relevant document and a relevant one would not affect the loss, which is unreasonable.",
        "To model ranking, we can introduce a factor of the user model - the probability of each of the k documents being viewed by the user, P(view|di), and define the following ranking loss function: L(a, r, m) = − k i=1 P(view|di)P(relevant|di, m) Since in general, if di is ranked above dj (i.e., i < j), P(view|di) > P(view|dj), this loss function would favor a decision to rank relevant documents above non-relevant ones, as otherwise, we could always switch di with dj to reduce the loss value.",
        "Thus the system should simply perform a regular retrieval and rank documents according to the probability of relevance [18].",
        "Depending on the users retrieval preferences, there can be many other possibilities.",
        "For example, if the user does not want to see redundant documents, the loss function should include some redundancy measure on r based on the already seen documents S. Of course, when the response is not to choose a ranked list of documents, we would need a different loss function.",
        "We discuss one such example that is relevant to the search agent that we implement.",
        "When a user enters a query qt (current action), our search agent relies on some existing search engine to actually carry out search.",
        "In such a case, even though the search agent does not have control of the retrieval algorithm, it can still attempt to optimize the search results through refining the query sent to the search engine and/or reranking the results obtained from the search engine.",
        "The loss functions for reranking are already discussed above; we now take a look at the loss functions for query refinement.",
        "Let f be the retrieval function of the search engine that our agent uses so that f(q) would give us the search results using query q.",
        "Given that the current action of the user is entering a query qt (i.e., at = qt), our response would be f(q) for some q.",
        "Since we have no choice of f, our decision is to choose a good q.",
        "Formally, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) which shows that our goal is to find q∗ = argminqL(qt, f(q), m), i.e., an optimal query that would give us the best f(q).",
        "A different choice of loss function L(qt, f(q), m) would lead to a different query refinement strategy.",
        "In UCAIR, we heuristically compute q∗ by expanding qt with terms extracted from rt−1 whenever qt−1 and qt have high similarity.",
        "Note that rt−1 and qt−1 are contained in m as part of the users interaction history. 3.4 Implicit user modeling Implicit user modeling is captured in our framework through the computation of x∗ = argmaxx P(x|U, D, At, Rt−1), i.e., the systems current belief of what the users information need is.",
        "Here again there may be many possibilities, leading to different algorithms for implicit user modeling.",
        "We now discuss a few of them.",
        "First, when two consecutive queries are related, the previous query can be exploited to enrich the current query and provide more search context to help disambiguation.",
        "For this purpose, instead of performing query expansion as we did in the previous section, we could also compute an updated x∗ based on the previous query and retrieval results.",
        "The computed new user model can then be used to rank the documents with a standard information retrieval model.",
        "Second, we can also infer a users interest based on the summaries of the viewed documents.",
        "When a user is presented with a list of summaries of top ranked documents, if the user chooses to skip the first n documents and to view the (n+1)-th document, we may infer that the user is not interested in the displayed summaries for the first n documents, but is attracted by the displayed summary of the (n + 1)-th document.",
        "We can thus use these summaries as negative and positive examples to learn a more accurate user model x∗ .",
        "Here many standard relevance feedback techniques can be exploited [19, 20].",
        "Note that we should use the displayed summaries, as opposed to the actual contents of those documents, since it is possible that the displayed summary of the viewed document is relevant, but the document content is actually not.",
        "Similarly, a displayed summary may mislead a user to skip a relevant document.",
        "Inferring user models based on such displayed information, rather than the actual content of a document is an important difference between UCAIR and some other similar systems.",
        "In UCAIR, both of these strategies for inferring an implicit user model are implemented. 4.",
        "UCAIR: A PERSONALIZED SEARCH AGENT 4.1 Design In this section, we present a client-side web search agent called UCAIR, in which we implement some of the methods discussed in the previous section for performing personalized search through implicit user modeling.",
        "UCAIR is a web browser plug-in 1 that acts as a proxy for web search engines.",
        "Currently, it is only implemented for Internet Explorer and Google, but it is a matter of engineering to make it run on other web browsers and interact with other search engines.",
        "The issue of privacy is a primary obstacle for deploying any real world applications involving serious user modeling, such as personalized search.",
        "For this reason, UCAIR is strictly running as a client-side search agent, as opposed to a server-side application.",
        "This way, the captured user information always resides on the computer that the user is using, thus the user does not need to release any information to the outside.",
        "Client-side personalization also allows the system to easily observe a lot of user information that may not be easily available to a server.",
        "Furthermore, performing personalized search on the client-side is more scalable than on the serverside, since the overhead of computation and storage is distributed among clients.",
        "As shown in Figure 1, the UCAIR toolbar has 3 major components: (1) The (implicit) user modeling module captures a users search context and history information, including the submitted queries and any clicked search results and infers search session boundaries. (2) The query modification module selectively improves the query formulation according to the current user model. (3) The result re-ranking module immediately re-ranks any unseen search results whenever the user model is updated.",
        "In UCAIR, we consider four basic user actions: (1) submitting a keyword query; (2) viewing a document; (3) clicking the Back button; (4) clicking the Next link on a result page.",
        "For each of these four actions, the system responds with, respectively, (1) 1 UCAIR is available at: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Search Engine (e.g., Google) Search History Log (e.g.,past queries, clicked results) Query Modification Result Re-Ranking User Modeling Result Buffer UCAIR Userquery results clickthrough… Figure 1: UCAIR architecture generating a ranked list of results by sending a possibly expanded query to a search engine; (2) updating the information need model x; (3) reranking the unseen results on the current result page based on the current model x; and (4) reranking the unseen pages and generating the next page of results based on the current model x.",
        "Behind these responses, there are three basic tasks: (1) Decide whether the previous query is related to the current query and if so expand the current query with useful terms from the previous query or the results of the previous query. (2) Update the information need model x based on a newly clicked document summary. (3) Rerank a set of unseen documents based on the current model x.",
        "Below we describe our algorithms for each of them. 4.2 Session boundary detection and query expansion To effectively exploit previous queries and their corresponding clickthrough information, UCAIR needs to judge whether two adjacent queries belong to the same search session (i.e., detect session boundaries).",
        "Existing work on session boundary detection is mostly in the context of web log analysis (e.g., [8]), and uses statistical information rather than textual features.",
        "Since our clientside agent does not have access to server query logs, we make session boundary decisions based on textual similarity between two queries.",
        "Because related queries do not necessarily share the same words (e.g., java island and travel Indonesia), it is insufficient to use only query text.",
        "Therefore we use the search results of the two queries to help decide whether they are topically related.",
        "For example, for the above queries java island and travel Indonesia, the words java, bali, island, indonesia and travel may occur frequently in both queries search results, yielding a high similarity score.",
        "We only use the titles and summaries of the search results to calculate the similarity since they are available in the retrieved search result page and fetching the full text of every result page would significantly slow down the process.",
        "To compensate for the terseness of titles and summaries, we retrieve more results than a user would normally view for the purpose of detecting session boundaries (typically 50 results).",
        "The similarity between the previous query q and the current query q is computed as follows.",
        "Let {s1, s2, . . . , sn } and {s1, s2, . . . , sn} be the result sets for the two queries.",
        "We use the pivoted normalization TF-IDF weighting formula [24] to compute a term weight vector si for each result si.",
        "We define the average result savg to be the centroid of all the result vectors, i.e., (s1 + s2 + . . . + sn)/n.",
        "The cosine similarity between the two average results is calculated as s avg · savg/ s 2 avg · s2 avg If the similarity value exceeds a predefined threshold, the two queries will be considered to be in the same information session.",
        "If the previous query and the current query are found to belong to the same search session, UCAIR would attempt to expand the current query with terms from the previous query and its search results.",
        "Specifically, for each term in the previous query or the corresponding search results, if its frequency in the results of the current query is greater than a preset threshold (e.g. 5 results out of 50), the term would be added to the current query to form an expanded query.",
        "In this case, UCAIR would send this expanded query rather than the original one to the search engine and return the results corresponding to the expanded query.",
        "Currently, UCAIR only uses the immediate preceding query for query expansion; in principle, we could exploit all related past queries. 4.3 Information need model updating Suppose at time t, we have observed that the user has viewed k documents whose summaries are s1, ..., sk.",
        "We update our user model by computing a new information need vector with a standard feedback method in information retrieval (i.e., Rocchio [19]).",
        "According to the vector space retrieval model, each clicked summary si can be represented by a term weight vector si with each term weighted by a TF-IDF weighting formula [21].",
        "Rocchio computes the centroid vector of all the summaries and interpolates it with the original query vector to obtain an updated term vector.",
        "That is, x = αq + (1 − α) 1 k k i=1 si where q is the query vector, k is the number of summaries the user clicks immediately following the current query and α is a parameter that controls the influence of the clicked summaries on the inferred information need model.",
        "In our experiments, α is set to 0.5.",
        "Note that we update the information need model whenever the user views a document. 4.4 Result reranking In general, we want to rerank all the unseen results as soon as the user model is updated.",
        "Currently, UCAIR implements reranking in two cases, corresponding to the user clicking the Back button and Next link in the Internet Explorer.",
        "In both cases, the current (updated) user model would be used to rerank the unseen results so that the user would see improved search results immediately.",
        "To rerank any unseen document summaries, UCAIR uses the standard vector space retrieval model and scores each summary based on the similarity of the result and the current user information need vector x [21].",
        "Since implicit feedback is not completely reliable, we bring up only a small number (e.g. 5) of highest reranked results to be followed by any originally high ranked results. 828 Google result (user query = java map) UCAIR result (user query =java map) previous query = travel Indonesia previous query = hashtable expanded user query = java map Indonesia expanded user query = java map class 1 Java map projections of the world ... Lonely Planet - Indonesia Map Map (Java 2 Platform SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Java map projections of the world ... INDONESIA TOURISM : CENTRAL JAVA - MAP Java 2 Platform SE v1.3.1: Interface Map www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Java Map INDONESIA TOURISM : WEST JAVA - MAP An Introduction to Java Map Collection Classes java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Java Technology Concept Map IndoStreets - Java Map An Introduction to Java Map Collection Classes java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Indonesia Regions and Islands Maps, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 An Introduction to Java Map Collection Classes Indonesia City Street Map,... Hibernate simplifies inheritance mapping www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Java Map Maps Of Indonesia tmap 30.map Class Hierarchy www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Java API Map Maps of Indonesia by Peter Loud Class Scope www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas : Sam Maps of Indonesia by Peter Loud Class PrintSafeHashMap www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 INDONESIA TOURISM : WEST JAVA - MAP indonesiaphoto.com Java Pro - Union and Vertical Mapping of Classes www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Table 1: Sample results of query expansion 5.",
        "EVALUATION OF UCAIR We now present some results on evaluating the two major UCAIR functions: selective query expansion and result reranking based on user clickthrough data. 5.1 Sample results The query expansion strategy implemented in UCAIR is intentionally conservative to avoid misinterpretation of implicit user models.",
        "In practice, whenever it chooses to expand the query, the expansion usually makes sense.",
        "In Table 1, we show how UCAIR can successfully distinguish two different search contexts for the query java map, corresponding to two different previous queries (i.e., travel Indonesia vs. hashtable).",
        "Due to implicit user modeling, UCAIR intelligently figures out to add Indonesia and class, respectively, to the users query java map, which would otherwise be ambiguous as shown in the original results from Google on March 21, 2005.",
        "UCAIRs results are much more accurate than Googles results and reflect personalization in search.",
        "The eager implicit feedback component is designed to immediately respond to a users activity such as viewing a document.",
        "In Figure 2, we show how UCAIR can successfully disambiguate an ambiguous query jaguar by exploiting a viewed document summary.",
        "In this case, the initial retrieval results using jaguar (shown on the left side) contain two results about the Jaguar cars followed by two results about the Jaguar software.",
        "However, after the user views the web page content of the second result (about Jaguar car) and returns to the search result page by clicking Back button, UCAIR automatically nominates two new search results about Jaguar cars (shown on the right side), while the original two results about Jaguar software are pushed down on the list (unseen from the picture). 5.2 Quantitative evaluation To further evaluate UCAIR quantitatively, we conduct a user study on the effectiveness of the eager implicit feedback component.",
        "It is a challenge to quantitatively evaluate the potential performance improvement of our proposed model and UCAIR over Google in an unbiased way [7].",
        "Here, we design a user study, in which participants would do normal web search and judge a randomly and anonymously mixed set of results from Google and UCAIR at the end of the search session; participants do not know whether a result comes from Google or UCAIR.",
        "We recruited 6 graduate students for this user study, who have different backgrounds (3 computer science, 2 biology, and 1 chem<top> <num> Number: 716 <title> Spammer arrest sue <desc> Description: Have any spammers been arrested or sued for sending unsolicited e-mail? <narr> Narrative: Instances of arrests, prosecutions, convictions, and punishments of spammers, and lawsuits against them are relevant.",
        "Documents which describe laws to limit spam without giving details of lawsuits or criminal trials are not relevant. </top> Figure 3: An example of TREC query topic, expressed in a form which might be given to a human assistant or librarian istry).",
        "We use query topics from TREC 2 2004 Terabyte track [2] and TREC 2003 Web track [4] topic distillation task in the way to be described below.",
        "An example topic from TREC 2004 Terabyte track appears in Figure 3.",
        "The title is a short phrase and may be used as a query to the retrieval system.",
        "The description field provides a slightly longer statement of the topic requirement, usually expressed as a single complete sentence or question.",
        "Finally the narrative supplies additional information necessary to fully specify the requirement, expressed in the form of a short paragraph.",
        "Initially, each participant would browse 50 topics either from Terabyte track or Web track and pick 5 or 7 most interesting topics.",
        "For each picked topic, the participant would essentially do the normal web search using UCAIR to find many relevant web pages by using the title of the query topic as the initial keyword query.",
        "During this process, the participant may view the search results and possibly click on some interesting ones to view the web pages, just as in a normal web search.",
        "There is no requirement or restriction on how many queries the participant must submit or when the participant should stop the search for one topic.",
        "When the participant plans to change the search topic, he/she will simply press a button 2 Text REtrieval Conference: http://trec.nist.gov/ 829 Figure 2: Screen shots for result reranking to evaluate the search results before actually switching to the next topic.",
        "At the time of evaluation, 30 top ranked results from Google and UCAIR (some are overlapping) are randomly mixed together so that the participant would not know whether a result comes from Google or UCAIR.",
        "The participant would then judge the relevance of these results.",
        "We measure precision at top n (n = 5, 10, 20, 30) documents of Google and UCAIR.",
        "We also evaluate precisions at different recall levels.",
        "Altogether, 368 documents judged as relevant from Google search results and 429 documents judged as relevant from UCAIR by participants.",
        "Scatter plots of precision at top 10 and top 20 documents are shown in Figure 4 and Figure 5 respectively (The scatter plot of precision at top 30 documents is very similar to precision at top 20 documents).",
        "Each point of the scatter plots represents the precisions of Google and UCAIR on one query topic.",
        "Table 2 shows the average precision at top n documents among 32 topics.",
        "From Figure 4, Figure 5 and Table 2, we see that the search results from UCAIR are consistently better than those from Google by all the measures.",
        "Moreover, the performance improvement is more dramatic for precision at top 20 documents than that at precision at top 10 documents.",
        "One explanation for this is that the more interaction the user has with the system, the more clickthrough data UCAIR can be expected to collect.",
        "Thus the retrieval system can build more precise implicit user models, which lead to better retrieval accuracy.",
        "Ranking Method prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Improvement 8.0% 17.8% 20.2% 21.8% Table 2: Table of average precision at top n documents for 32 query topics The plot in Figure 6 shows the precision-recall curves for UCAIR and Google, where it is clearly seen that the performance of UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Scatterplot of Precision at Top 10 Documents Figure 4: Precision at top 10 documents of UCAIR and Google is consistently and considerably better than that of Google at all levels of recall. 6.",
        "CONCLUSIONS In this paper, we studied how to exploit implicit user modeling to intelligently personalize information retrieval and improve search accuracy.",
        "Unlike most previous work, we emphasize the use of immediate search context and implicit feedback information as well as eager updating of search results to maximally benefit a user.",
        "We presented a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
        "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
        "Using these techniques, we develop a client-side web search agent (UCAIR) on top of a popular search engine (Google).",
        "Experiments on web search show that our search agent can improve search accuracy over 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Scatterplot of Precision at Top 20 documents Figure 5: Precision at top 20 documents of UCAIR and Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 recall precision Precision−Recall curves Google Result UCAIR Result Figure 6: Precision at top 20 result of UCAIR and Google Google.",
        "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
        "The developed search agent thus can improve existing web search performance without any additional effort from the user. 7.",
        "ACKNOWLEDGEMENT We thank the six participants of our evaluation experiments.",
        "This work was supported in part by the National Science Foundation grants IIS-0347933 and IIS-0428472. 8.",
        "REFERENCES [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman, and O. Frieder.",
        "Hourly analysis of a very large topically categorized web query log.",
        "In Proceedings of SIGIR 2004, pages 321-328, 2004. [2] C. Clarke, N. Craswell, and I. Soboroff.",
        "Overview of the TREC 2004 terabyte track.",
        "In Proceedings of TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda, and D. Brown.",
        "Implicit interest indicators.",
        "In Proceedings of Intelligent User Interfaces 2001, pages 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson, and M. Wu.",
        "Overview of the TREC 2003 web track.",
        "In Proceedings of TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend, and V. Larvrenko.",
        "Relevance feedback and personalization: A language modeling perspective.",
        "In Proeedings of Second DELOS Workshop: Personalisation and Recommender Systems in Digital Libraries, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite, and D. Harman.",
        "Results and challenges in web search evaluation.",
        "Computer Networks, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A.",
        "An, and D. Schuurmans.",
        "Dynamic web log session identification with statistical language models.",
        "Journal of the American Society for Information Science and Technology, 55(14):1290-1303, 2004. [9] G. Jeh and J. Widom.",
        "Scaling personalized web search.",
        "In Proceedings of WWW 2003, pages 271-279, 2003. [10] T. Joachims.",
        "Optimizing search engines using clickthrough data.",
        "In Proceedings of SIGKDD 2002, pages 133-142, 2002. [11] D. Kelly and J. Teevan.",
        "Implicit feedback for inferring user preference: A bibliography.",
        "SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty and C. Zhai.",
        "Document language models, query models, and risk minimization for information retrieval.",
        "In Proceedings of SIGIR01, pages 111-119, 2001. [13] T. Lau and E. Horvitz.",
        "Patterns of search: Analyzing and modeling web query refinement.",
        "In Proceedings of the Seventh International Conference on User Modeling (UM), pages 145 -152, 1999. [14] V. Lavrenko and B. Croft.",
        "Relevance-based language models.",
        "In Proceedings of SIGIR01, pages 120-127, 2001. [15] M. Mitra, A. Singhal, and C. Buckley.",
        "Improving automatic query expansion.",
        "In Proceedings of SIGIR 1998, pages 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg.",
        "As google goes, so goes the nation.",
        "New York Times, May 2003. [18] S. E. Robertson.",
        "The probability ranking principle in ı˚.",
        "Journal of Documentation, 33(4):294-304, 1977. [19] J. J. Rocchio.",
        "Relevance feedback in information retrieval.",
        "In The SMART Retrieval System: Experiments in Automatic Document Processing, pages 313-323.",
        "Prentice-Hall Inc., 1971. [20] G. Salton and C. Buckley.",
        "Improving retrieval performance by retrieval feedback.",
        "Journal of the American Society for Information Science, 41(4):288-297, 1990. [21] G. Salton and M. J. McGill.",
        "Introduction to Modern Information Retrieval.",
        "McGraw-Hill, 1983. [22] X. Shen, B. Tan, and C. Zhai.",
        "Context-sensitive information retrieval using implicit feedback.",
        "In Proceedings of SIGIR 2005, pages 43-50, 2005. [23] X. Shen and C. Zhai.",
        "Exploiting query history for document ranking in interactive information retrieval (Poster).",
        "In Proceedings of SIGIR 2003, pages 377-378, 2003. [24] A. Singhal.",
        "Modern information retrieval: A brief overview.",
        "Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano, and M. Yoshikawa.",
        "Adaptive web search based on user profile constructed without any effort from users.",
        "In Proceedings of WWW 2004, pages 675-684, 2004. [26] E. Volokh.",
        "Personalization and privacy.",
        "Communications of the ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen, and I. Ruthven.",
        "A simulated study of implicit feedback models.",
        "In Proceedings of ECIR 2004, pages 311-326, 2004. [28] J. Xu and W. B. Croft.",
        "Query expansion using local and global document analysis.",
        "In Proceedings of SIGIR 1996, pages 4-11, 1996. [29] C. Zhai and J. Lafferty.",
        "Model-based feedback in KL divergence retrieval model.",
        "In Proceedings of the CIKM 2001, pages 403-410, 2001. 831"
    ],
    "translated_text_sentences": [
        "Modelado implícito de usuarios para búsqueda personalizada Xuehua Shen, Bin Tan, ChengXiang Zhai Departamento de Ciencias de la Computación Universidad de Illinois en Urbana-Champaign RESUMEN Los sistemas de recuperación de información (por ejemplo, motores de búsqueda web) son críticos para superar la sobrecarga de información.",
        "Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales, lo que resulta en un rendimiento de recuperación inherentemente no óptimo.",
        "Por ejemplo, un turista y un programador pueden usar la misma palabra \"java\" para buscar información diferente, pero los sistemas de búsqueda actuales devolverían los mismos resultados.",
        "En este artículo, estudiamos cómo inferir el interés de un usuario a partir del contexto de búsqueda del usuario y utilizar el modelo de usuario implícito inferido para la búsqueda personalizada.",
        "Presentamos un marco teórico de toma de decisiones y desarrollamos técnicas para el modelado implícito del usuario en la recuperación de información.",
        "Desarrollamos un agente de búsqueda web inteligente del lado del cliente (UCAIR) que puede realizar retroalimentación implícita ansiosa, por ejemplo, expansión de consultas basada en consultas anteriores y reordenamiento inmediato de resultados basado en información de clics.",
        "Los experimentos sobre la búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda sobre el popular motor de búsqueda Google.",
        "Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación, Retroalimentación de relevancia, Proceso de búsqueda Términos Generales Algoritmos 1.",
        "Aunque muchos sistemas de recuperación de información (por ejemplo, motores de búsqueda web y sistemas de biblioteca digital) se han implementado con éxito, los sistemas de recuperación actuales están lejos de ser óptimos.",
        "Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales [17].",
        "Esta no optimalidad inherente se ve claramente en los siguientes dos casos: (1) Diferentes usuarios pueden utilizar exactamente la misma consulta (por ejemplo, Java) para buscar información diferente (por ejemplo, la isla de Java en Indonesia o el lenguaje de programación Java), pero los sistemas de IR existentes devuelven los mismos resultados para estos usuarios.",
        "Sin considerar al usuario actual, es imposible saber a qué sentido se refiere Java en una consulta. (2) Las necesidades de información de un usuario pueden cambiar con el tiempo.",
        "El mismo usuario puede usar Java a veces para referirse a la isla de Java en Indonesia y otras veces para referirse al lenguaje de programación.",
        "Sin reconocer el contexto de búsqueda, sería nuevamente imposible reconocer el sentido correcto.",
        "Para optimizar la precisión de la recuperación, claramente necesitamos modelar al usuario de manera adecuada y personalizar la búsqueda según cada usuario individual.",
        "El objetivo principal del modelado de usuario para la recuperación de información es modelar con precisión la necesidad de información de un usuario, lo cual, desafortunadamente, es una tarea muy difícil.",
        "De hecho, incluso resulta difícil para un usuario describir con precisión cuál es su necesidad de información.",
        "¿Qué información está disponible para que un sistema pueda inferir la necesidad de información de un usuario?",
        "Obviamente, la consulta de los usuarios proporciona la evidencia más directa.",
        "De hecho, la mayoría de los sistemas de recuperación existentes se basan únicamente en la consulta para modelar la necesidad de información de los usuarios.",
        "Sin embargo, dado que una consulta suele ser extremadamente corta, el modelo de usuario construido basado en una consulta de palabras clave inevitablemente resulta empobrecido.",
        "Una forma efectiva de mejorar la modelización de usuarios en la recuperación de información es pedir al usuario que especifique explícitamente qué documentos son relevantes (es decir, útiles para satisfacer su necesidad de información) y luego mejorar la modelización de usuarios basándose en ejemplos de documentos relevantes.",
        "Esto se llama retroalimentación de relevancia, lo cual ha demostrado ser bastante efectivo para mejorar la precisión de recuperación [19, 20].",
        "Desafortunadamente, en aplicaciones del mundo real, los usuarios suelen ser reacios a hacer el esfuerzo adicional de proporcionar ejemplos relevantes para retroalimentación [11].",
        "Por lo tanto, es muy interesante estudiar cómo inferir la necesidad de información de un usuario basándose en cualquier información de retroalimentación implícita, la cual existe naturalmente a través de las interacciones del usuario y no requiere ningún esfuerzo adicional por parte del usuario.",
        "De hecho, varios estudios previos han demostrado que el modelado implícito del usuario puede mejorar la precisión de recuperación.",
        "En [3], se desarrolla un navegador web (Curious Browser) para registrar las calificaciones explícitas de relevancia de las páginas web por parte de los usuarios (retroalimentación de relevancia) y el comportamiento de navegación al ver una página, como el tiempo de permanencia, clics de ratón, movimiento del ratón y desplazamiento (retroalimentación implícita).",
        "Se muestra que el tiempo de permanencia en una página, la cantidad de desplazamiento en una página y la combinación de tiempo y desplazamiento tienen una fuerte correlación con las calificaciones de relevancia explícita, lo que sugiere que la retroalimentación implícita puede ser útil para inferir la necesidad de información del usuario.",
        "En [10], se recopilan datos de clics de usuario como datos de entrenamiento para aprender una función de recuperación, que se utiliza para producir un ranking personalizado de resultados de búsqueda que se adapte a las preferencias de un grupo de usuarios.",
        "En [25], los datos de clics recopilados durante un largo período de tiempo se utilizan a través de la expansión de consultas para mejorar la precisión de recuperación. Si bien un usuario puede tener intereses y preferencias generales a largo plazo para la información, a menudo está buscando documentos para satisfacer una necesidad de información ad-hoc, que solo dura un corto período de tiempo; una vez que se satisface la necesidad de información, el usuario generalmente ya no estaría interesado en esa información.",
        "Por ejemplo, un usuario puede estar buscando información sobre autos usados para comprar uno, pero una vez que el usuario ha comprado un auto, generalmente ya no está interesado en esa información.",
        "En tales casos, la información de retroalimentación implícita recopilada durante un largo período de tiempo es poco probable que sea muy útil, pero el contexto de búsqueda inmediato y la información de retroalimentación, como cuáles de los resultados de búsqueda para la necesidad de información actual son vistos, se espera que sean mucho más útiles.",
        "Considera la consulta de Java nuevamente.",
        "Cualquiera de la siguiente información de retroalimentación inmediata sobre el usuario podría potencialmente ayudar a determinar el significado previsto de Java en la consulta: (1) La consulta anterior enviada por el usuario es hashtable (en lugar de, por ejemplo, viajar a Indonesia). (2) En los resultados de búsqueda, el usuario visualizó una página donde palabras como programación, software y applet ocurren muchas veces.",
        "Hasta donde sabemos, cómo aprovechar este contexto de búsqueda inmediato y a corto plazo para mejorar la búsqueda aún no ha sido abordado de manera satisfactoria en trabajos anteriores.",
        "En este artículo, estudiamos cómo construir y actualizar un modelo de usuario basado en el contexto de búsqueda inmediato y la información de retroalimentación implícita, y utilizar el modelo para mejorar la precisión de la recuperación ad-hoc.",
        "Para beneficiar al máximo al usuario de un sistema de recuperación a través de modelado implícito del usuario, proponemos realizar retroalimentación implícita entusiasta.",
        "Es decir, tan pronto como observemos cualquier nueva pieza de evidencia del usuario, actualizaríamos la creencia del sistema sobre la necesidad de información del usuario y responderíamos con resultados de recuperación mejorados basados en el modelo de usuario actualizado.",
        "Presentamos un marco de trabajo de teoría de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad.",
        "En un paradigma de recuperación tradicional, el problema de recuperación consiste en emparejar una consulta con documentos y clasificar los documentos según sus valores de relevancia.",
        "Como resultado, el proceso de recuperación es un ciclo independiente simple de consulta y visualización de resultados.",
        "En el nuevo paradigma de recuperación propuesto, el contexto de búsqueda de los usuarios juega un papel importante y el modelo de usuario implícito inferido se explota inmediatamente para beneficiar al usuario.",
        "El nuevo paradigma de recuperación es, por lo tanto, fundamentalmente diferente del paradigma tradicional y es inherentemente más general.",
        "Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos apropiados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para reordenar inmediatamente cualquier documento que aún no haya sido visto por el usuario.",
        "Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente UCAIR (Recuperación de Información Adaptativa Centrada en el Usuario) sobre un motor de búsqueda popular (Google).",
        "Los experimentos sobre búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en comparación con Google.",
        "Dado que la información implícita que explotamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional.",
        "Por lo tanto, el agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin esfuerzo adicional por parte del usuario.",
        "Las secciones restantes están organizadas de la siguiente manera.",
        "En la Sección 2, discutimos el trabajo relacionado.",
        "En la Sección 3, presentamos un marco de recuperación interactiva basado en teoría de decisiones para modelado implícito de usuarios.",
        "En la Sección 4, presentamos el diseño e implementación de un agente de búsqueda web inteligente del lado del cliente (UCAIR) que realiza retroalimentación implícita ansiosa.",
        "En la Sección 5, informamos nuestros resultados experimentales utilizando el agente de búsqueda.",
        "La sección 6 concluye nuestro trabajo. 2.",
        "El modelado implícito del usuario para la búsqueda personalizada ha sido estudiado en trabajos anteriores, pero nuestro trabajo difiere de todos los trabajos anteriores en varios aspectos: (1) Enfatizamos la explotación del contexto de búsqueda inmediato, como la consulta inmediatamente anterior relacionada y los documentos vistos en la misma sesión, mientras que la mayoría de los trabajos anteriores se basan en la recopilación a largo plazo de información de retroalimentación implícita [25]. (2) Realizamos una retroalimentación activa y obtenemos el beneficio del modelado implícito del usuario tan pronto como esté disponible cualquier nueva información de retroalimentación implícita, mientras que el trabajo anterior mayormente explota la retroalimentación implícita a largo plazo [10]. (3) Proponemos un marco de recuperación para integrar el modelado implícito del usuario con el proceso interactivo de recuperación, mientras que el trabajo anterior estudia el modelado implícito del usuario por separado de la recuperación [3] o solo estudia modelos de recuperación específicos para explotar la retroalimentación implícita para mejorar la coincidencia de una consulta con documentos [23, 27, 22]. (4) Desarrollamos y evaluamos un agente de búsqueda web personalizado con estudios de usuario en línea, mientras que la mayoría de los trabajos existentes evalúan algoritmos fuera de línea sin interacciones reales de usuarios.",
        "Actualmente algunos motores de búsqueda ofrecen personalización rudimentaria, como la búsqueda web personalizada de Google [6], que permite a los usuarios describir explícitamente sus intereses seleccionando entre temas predefinidos, de modo que los resultados que coinciden con sus intereses se muestren en la parte superior, y la búsqueda de My Yahoo! [16], que brinda a los usuarios la opción de guardar los sitios web que les gustan y bloquear aquellos que no les gustan.",
        "Por el contrario, UCAIR personaliza la búsqueda web a través de la modelización implícita del usuario sin necesidad de esfuerzos adicionales por parte del usuario.",
        "Además, la personalización de UCAIR se proporciona en el lado del cliente.",
        "Hay dos ventajas notables en esto.",
        "Primero, el usuario no necesita preocuparse por la infracción de privacidad, que es una gran preocupación para la búsqueda personalizada [26].",
        "En segundo lugar, tanto el cálculo de la personalización como el almacenamiento del perfil del usuario se realizan en el lado del cliente para reducir drásticamente la carga del servidor [9].",
        "Ha habido muchos trabajos estudiando los registros de consultas de usuarios [1] o la dinámica de consultas [13].",
        "UCAIR hace uso directo del historial de consultas de un usuario para beneficiar al mismo usuario de inmediato en la misma sesión de búsqueda.",
        "UCAIR primero determina si dos consultas vecinas pertenecen a la misma sesión de información y, de ser así, selecciona términos de la consulta anterior para realizar la expansión de la consulta.",
        "Nuestro enfoque de expansión de consultas es similar a la expansión automática de consultas [28, 15, 5], pero en lugar de utilizar retroalimentación pseudo para expandir la consulta, utilizamos la información de retroalimentación implícita de los usuarios para expandir la consulta actual.",
        "Estas dos técnicas pueden ser combinadas. 3.",
        "OPTIMIZACIÓN EN IR INTERACTIVO En IR interactivo, un usuario interactúa con el sistema de recuperación a través de un diálogo de acción, en el cual el sistema responde a cada acción del usuario con alguna acción del sistema.",
        "Por ejemplo, la acción de los usuarios puede ser enviar una consulta y la respuesta del sistema puede ser devolver una lista de 10 resúmenes de documentos.",
        "En general, el espacio de acciones del usuario y respuestas del sistema y sus granularidades dependerían de la interfaz de un sistema de recuperación particular.",
        "En principio, cada acción del usuario puede potencialmente proporcionar nuevas pruebas para ayudar al sistema a inferir mejor la necesidad de información del usuario.",
        "Por lo tanto, para responder de manera óptima, el sistema debería utilizar toda la evidencia recopilada hasta ahora sobre el usuario al elegir una respuesta.",
        "Cuando se ven de esta manera, la mayoría de los motores de búsqueda existentes son claramente no óptimos.",
        "Por ejemplo, si un usuario ha visto algunos documentos en la primera página de resultados de búsqueda, cuando el usuario hace clic en el enlace Siguiente para obtener más resultados, un sistema de recuperación existente seguiría devolviendo la siguiente página de resultados recuperados en función de la consulta original sin considerar la nueva evidencia de que un resultado en particular ha sido visto por el usuario. Proponemos optimizar el rendimiento de la recuperación adaptando las respuestas del sistema en función de cada acción que un usuario haya tomado, y planteamos el problema de optimización como una tarea de decisión.",
        "Específicamente, en cualquier momento, el sistema intentaría realizar dos tareas: (1) Actualización del modelo de usuario: Monitorear cualquier evidencia útil del usuario con respecto a su necesidad de información y actualizar el modelo de usuario tan pronto como esta evidencia esté disponible; (2) Mejorar los resultados de búsqueda: Reclasificar inmediatamente todos los documentos que el usuario aún no ha visto, tan pronto como se actualice el modelo de usuario.",
        "Enfatizamos la actualización y reordenamiento entusiastas, lo que hace que nuestro trabajo sea bastante diferente a cualquier trabajo existente.",
        "A continuación presentamos un marco formal de teoría de decisiones para optimizar el rendimiento de recuperación a través de la modelización implícita del usuario en la recuperación de información interactiva. 3.1 Un marco de teoría de decisiones Sea A el conjunto de todas las acciones del usuario y R(a) el conjunto de todas las posibles respuestas del sistema a una acción del usuario a ∈ A.",
        "En cualquier momento, sea At = (a1, ..., at) la secuencia observada de acciones de usuario hasta ahora (hasta el momento t) y Rt−1 = (r1, ..., rt−1) las respuestas que el sistema ha dado en respuesta a las acciones del usuario.",
        "El objetivo del sistema es elegir una respuesta óptima rt ∈ R(at) para la acción actual del usuario at.",
        "Sea M el espacio de todos los posibles modelos de usuario.",
        "Definimos además una función de pérdida L(a, r, m) ∈ , donde a ∈ A es una acción del usuario, r ∈ R(a) es una respuesta del sistema, y m ∈ M es un modelo de usuario.",
        "L(a, r, m) codifica nuestras preferencias de decisión y evalúa la optimalidad de responder con r cuando el modelo de usuario actual es m y la acción de usuario actual es a.",
        "Según la teoría de decisión bayesiana, la decisión óptima en el tiempo t es elegir una respuesta que minimice el riesgo de Bayes, es decir, r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) donde P(mt|U, D, At, Rt−1) es la probabilidad posterior del modelo de usuario mt dadas todas las observaciones sobre el usuario U que hemos realizado hasta el tiempo t. Para simplificar el cálculo de la Ecuación 1, asumamos que la masa de probabilidad posterior P(mt|U, D, At, Rt−1) está principalmente concentrada en el modo m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
        "Podemos entonces aproximar la integral con el valor de la función de pérdida en m∗ t.",
        "Es decir, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) donde m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
        "Dejando de lado cómo definir y estimar estos modelos probabilísticos y la función de pérdida, podemos ver que tal formulación de la teoría de decisiones sugiere que, para elegir la respuesta óptima a at, el sistema debería realizar dos tareas: (1) calcular el modelo de usuario actual y obtener m∗ t basado en toda la información útil. (2) elegir una respuesta rt para minimizar el valor de la función de pérdida L(at, rt, m∗ t).",
        "Cuando at no afecta nuestra creencia sobre m∗ t , el primer paso puede omitirse y podemos reutilizar m∗ t−1 para m∗ t .",
        "Ten en cuenta que nuestro marco de trabajo es bastante general, ya que potencialmente podemos modelar cualquier tipo de acciones de usuario y respuestas del sistema.",
        "En la mayoría de los casos, como podríamos esperar, la respuesta del sistema es algún tipo de clasificación de documentos, es decir, para la mayoría de las acciones a, R(a) consiste en todas las posibles clasificaciones de los documentos no vistos, y el problema de decisión se reduce a elegir la mejor clasificación de los documentos no vistos basándose en el modelo de usuario más actualizado.",
        "Cuando a es la acción de enviar una consulta de palabras clave, tal respuesta es exactamente lo que haría un sistema de recuperación actual.",
        "Sin embargo, fácilmente podemos imaginar que un motor de búsqueda web más inteligente respondería al clic del usuario en el enlace Siguiente (para obtener más resultados no vistos) con una clasificación más optimizada de documentos basada en cualquier documento visto en la página actual de resultados.",
        "De hecho, según nuestra estrategia de actualización entusiasta, incluso podríamos permitir que un sistema responda al clic del botón Atrás del navegador por parte de un usuario después de ver un documento de la misma manera, para que el usuario pueda beneficiarse al máximo de la retroalimentación implícita.",
        "Estos son precisamente lo que nuestro sistema UCAIR hace. 3.2 Modelos de usuario Un modelo de usuario m ∈ M representa lo que sabemos sobre el usuario U, por lo que en principio, puede contener cualquier información sobre el usuario que deseemos modelar.",
        "Ahora discutimos dos componentes importantes en un modelo de usuario.",
        "El primer componente es un modelo de componente de la necesidad de información de los usuarios.",
        "Presumiblemente, el factor más importante que afecta la optimalidad de la respuesta del sistema es qué tan bien la respuesta aborda la necesidad de información de los usuarios.",
        "De hecho, en cualquier momento, podemos asumir que el sistema tiene alguna creencia sobre lo que le interesa al usuario, la cual modelamos a través de un vector de términos x = (x1, ..., x|V|), donde V = {w1, ..., w|V|} es el conjunto de todos los términos (es decir, vocabulario) y xi es el peso del término wi.",
        "Un vector de términos de este tipo se utiliza comúnmente en la recuperación de información para representar tanto consultas como documentos.",
        "Por ejemplo, el modelo de espacio vectorial asume que tanto la consulta como los documentos se representan como vectores de términos y que la puntuación de un documento con respecto a una consulta se calcula en función de la similitud entre el vector de la consulta y el vector del documento [21].",
        "En un enfoque de modelado de lenguaje, también podemos considerar el modelo de lenguaje unigrama de consulta [12, 29] o el modelo de relevancia [14] como una representación vectorial de términos de la necesidad de información de los usuarios.",
        "Intuitivamente, x asignaría pesos altos a los términos que caracterizan los temas que interesan al usuario.",
        "El segundo componente que podemos incluir en nuestro modelo de usuario son los documentos que el usuario ya ha visto.",
        "Obviamente, incluso si un documento es relevante, si el usuario ya ha visto el documento, no sería útil presentar el mismo documento de nuevo.",
        "Por lo tanto, introducimos otra variable S ⊂ D (D es el conjunto completo de documentos en la colección) para denotar el subconjunto de documentos en los resultados de búsqueda que el usuario ya ha visto.",
        "En general, en el tiempo t, podemos representar un modelo de usuario como mt = (S, x, At, Rt−1), donde S son los documentos vistos, x es la comprensión del sistema de la necesidad de información del usuario, y (At, Rt−1) representa el historial de interacción del usuario.",
        "Ten en cuenta que un modelo de usuario aún más general también puede incluir otros factores como el nivel de lectura y la ocupación de los usuarios.",
        "Si asumimos que la incertidumbre de un modelo de usuario mt se debe únicamente a la incertidumbre de x, el cálculo de nuestra estimación actual del modelo de usuario m∗ t implicará principalmente calcular nuestra mejor estimación de x.",
        "Es decir, el sistema elegiría una respuesta de acuerdo a r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) donde x∗ = argmaxx P(x|U, D, At, Rt−1).",
        "Este es el mecanismo de decisión implementado en el sistema UCAIR que se describirá más adelante.",
        "En este sistema, evitamos especificar el modelo probabilístico P(x|U, D, At, Rt−1) calculando x∗ directamente con algún método de retroalimentación existente. 3.3 Funciones de pérdida La definición exacta de la función de pérdida L depende de las respuestas, por lo que es inevitablemente específica de la aplicación.",
        "Ahora discutimos brevemente algunas posibilidades cuando la respuesta es clasificar todos los documentos no vistos y presentar los mejores k de ellos.",
        "Sea r = (d1, ..., dk) los k documentos principales, S el conjunto de documentos vistos por el usuario, y x∗ la mejor suposición del sistema sobre la necesidad de información del usuario.",
        "Podemos definir simplemente la pérdida asociada con r como la suma negativa de la probabilidad de que cada uno de los di sea relevante, es decir, L(a, r, m) = − k i=1 P(relevante|di, m).",
        "Claramente, para minimizar esta función de pérdida, la respuesta óptima r contendría los k documentos con la probabilidad más alta de relevancia, lo cual es intuitivamente razonable.",
        "Una deficiencia de esta función de pérdida top-k es que no es sensible al orden interno de los documentos top k seleccionados, por lo que cambiar el orden de clasificación de un documento no relevante y uno relevante no afectaría la pérdida, lo cual es irrazonable.",
        "Para modelar el ranking, podemos introducir un factor del modelo de usuario: la probabilidad de que cada uno de los k documentos sea visto por el usuario, P(vista|di), y definir la siguiente función de pérdida de ranking: L(a, r, m) = − k i=1 P(vista|di)P(relevante|di, m). Dado que, en general, si di está clasificado por encima de dj (es decir, i < j), P(vista|di) > P(vista|dj), esta función de pérdida favorecería una decisión de clasificar documentos relevantes por encima de los no relevantes, ya que de lo contrario, siempre podríamos intercambiar di con dj para reducir el valor de pérdida.",
        "Por lo tanto, el sistema simplemente debería realizar una recuperación regular y clasificar los documentos según la probabilidad de relevancia [18].",
        "Dependiendo de las preferencias de recuperación de los usuarios, puede haber muchas otras posibilidades.",
        "Por ejemplo, si el usuario no desea ver documentos redundantes, la función de pérdida debería incluir alguna medida de redundancia en r basada en los documentos ya vistos S. Por supuesto, cuando la respuesta no es elegir una lista clasificada de documentos, necesitaríamos una función de pérdida diferente.",
        "Discutimos un ejemplo relevante para el agente de búsqueda que implementamos.",
        "Cuando un usuario ingresa una consulta qt (acción actual), nuestro agente de búsqueda se basa en algún motor de búsqueda existente para llevar a cabo la búsqueda en realidad.",
        "En tal caso, aunque el agente de búsqueda no tenga control sobre el algoritmo de recuperación, aún puede intentar optimizar los resultados de la búsqueda refinando la consulta enviada al motor de búsqueda y/o reordenando los resultados obtenidos del motor de búsqueda.",
        "Las funciones de pérdida para el reordenamiento ya fueron discutidas anteriormente; ahora echamos un vistazo a las funciones de pérdida para el refinamiento de consultas.",
        "Sea f la función de recuperación del motor de búsqueda que nuestro agente utiliza, de modo que f(q) nos daría los resultados de búsqueda utilizando la consulta q.",
        "Dado que la acción actual del usuario es ingresar una consulta qt (es decir, at = qt), nuestra respuesta sería f(q) para algún q.",
        "Dado que no tenemos elección de f, nuestra decisión es elegir un buen q.",
        "Formalmente, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) lo cual muestra que nuestro objetivo es encontrar q∗ = argminqL(qt, f(q), m), es decir, una consulta óptima que nos daría el mejor f(q).",
        "Una elección diferente de la función de pérdida L(qt, f(q), m) llevaría a una estrategia de refinamiento de consulta diferente.",
        "En UCAIR, calculamos heurísticamente q∗ expandiendo qt con términos extraídos de rt−1 siempre que qt−1 y qt tengan una alta similitud.",
        "Se debe tener en cuenta que rt−1 y qt−1 están contenidos en m como parte del historial de interacción de los usuarios. 3.4 Modelado implícito del usuario El modelado implícito del usuario se captura en nuestro marco a través del cálculo de x∗ = argmaxx P(x|U, D, At, Rt−1), es decir, la creencia actual del sistema sobre cuál es la necesidad de información del usuario.",
        "Aquí nuevamente puede haber muchas posibilidades, lo que lleva a diferentes algoritmos para la modelización implícita del usuario.",
        "Ahora discutimos algunos de ellos.",
        "Primero, cuando dos consultas consecutivas están relacionadas, la consulta anterior puede ser explotada para enriquecer la consulta actual y proporcionar más contexto de búsqueda para ayudar en la desambiguación.",
        "Para este propósito, en lugar de realizar una expansión de consulta como lo hicimos en la sección anterior, también podríamos calcular un x∗ actualizado basado en la consulta anterior y los resultados de recuperación.",
        "El modelo de usuario nuevo calculado puede luego ser utilizado para clasificar los documentos con un modelo estándar de recuperación de información.",
        "Segundo, también podemos inferir los intereses de un usuario basándonos en los resúmenes de los documentos visualizados.",
        "Cuando a un usuario se le presenta una lista de resúmenes de documentos mejor clasificados, si el usuario elige saltarse los primeros n documentos y ver el documento (n+1)-ésimo, podemos inferir que el usuario no está interesado en los resúmenes mostrados para los primeros n documentos, pero está atraído por el resumen mostrado del documento (n+1)-ésimo.",
        "Por lo tanto, podemos usar estos resúmenes como ejemplos negativos y positivos para aprender un modelo de usuario más preciso x∗.",
        "Aquí se pueden explotar muchas técnicas estándar de retroalimentación de relevancia [19, 20].",
        "Ten en cuenta que debemos utilizar los resúmenes mostrados, en lugar de los contenidos reales de esos documentos, ya que es posible que el resumen mostrado del documento visto sea relevante, pero el contenido del documento en realidad no lo sea.",
        "Del mismo modo, un resumen mostrado puede llevar a un usuario a omitir un documento relevante.",
        "Inferir modelos de usuario basados en dicha información mostrada, en lugar del contenido real de un documento, es una diferencia importante entre UCAIR y algunos otros sistemas similares.",
        "En UCAIR, ambas estrategias para inferir un modelo de usuario implícito están implementadas. 4.",
        "UCAIR: Un agente de búsqueda personalizado 4.1 Diseño En esta sección, presentamos un agente de búsqueda web del lado del cliente llamado UCAIR, en el cual implementamos algunos de los métodos discutidos en la sección anterior para realizar búsquedas personalizadas a través de modelado implícito del usuario.",
        "UCAIR es un complemento del navegador web que actúa como proxy para los motores de búsqueda en la web.",
        "Actualmente, solo está implementado para Internet Explorer y Google, pero es cuestión de ingeniería hacer que funcione en otros navegadores web e interactúe con otros motores de búsqueda.",
        "El tema de la privacidad es un obstáculo principal para implementar cualquier aplicación del mundo real que involucre modelado de usuarios serio, como la búsqueda personalizada.",
        "Por esta razón, UCAIR funciona estrictamente como un agente de búsqueda del lado del cliente, en lugar de ser una aplicación del lado del servidor.",
        "De esta manera, la información del usuario capturada siempre permanece en la computadora que está utilizando el usuario, por lo tanto, el usuario no necesita revelar ninguna información al exterior.",
        "La personalización del lado del cliente también permite que el sistema observe fácilmente una gran cantidad de información del usuario que puede no estar fácilmente disponible para un servidor.",
        "Además, realizar búsquedas personalizadas en el lado del cliente es más escalable que en el lado del servidor, ya que la sobrecarga de cálculo y almacenamiento se distribuye entre los clientes.",
        "Como se muestra en la Figura 1, la barra de herramientas UCAIR tiene 3 componentes principales: (1) El módulo de modelado de usuario (implícito) captura el contexto de búsqueda de un usuario e información de historial, incluidas las consultas enviadas y los resultados de búsqueda clicados, e infiere los límites de la sesión de búsqueda. (2) El módulo de modificación de consultas mejora selectivamente la formulación de la consulta de acuerdo con el modelo de usuario actual. (3) El módulo de reordenamiento de resultados reordena inmediatamente cualquier resultado de búsqueda no visto cada vez que se actualiza el modelo de usuario.",
        "En UCAIR, consideramos cuatro acciones básicas de usuario: (1) enviar una consulta de palabras clave; (2) ver un documento; (3) hacer clic en el botón Atrás; (4) hacer clic en el enlace Siguiente en una página de resultados.",
        "Para cada una de estas cuatro acciones, el sistema responde con, respectivamente, (1) 1 UCAIR está disponible en: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Registro de Historial de Búsqueda del Motor de Búsqueda (por ejemplo, Google) (consultas pasadas, resultados clicados) Modificación de Consulta Resultado de Reclasificación Modelo de Usuario Buffer de Resultados de Consulta de Usuario UCAIR... Figura 1: arquitectura de UCAIR generando una lista clasificada de resultados enviando una consulta posiblemente ampliada a un motor de búsqueda; (2) actualizando el modelo de necesidad de información x; (3) reordenando los resultados no vistos en la página de resultados actual basándose en el modelo actual x; y (4) reordenando las páginas no vistas y generando la siguiente página de resultados basándose en el modelo actual x.",
        "Detrás de estas respuestas, hay tres tareas básicas: (1) Decidir si la consulta anterior está relacionada con la consulta actual y, de ser así, ampliar la consulta actual con términos útiles de la consulta anterior o los resultados de la consulta anterior. (2) Actualizar el modelo de necesidad de información x basado en un resumen de documento recién seleccionado. (3) Reordenar un conjunto de documentos no vistos basado en el modelo x actual.",
        "A continuación describimos nuestros algoritmos para cada uno de ellos. 4.2 Detección de límites de sesión y expansión de consultas Para explotar eficazmente las consultas anteriores y su información correspondiente de clics, UCAIR necesita determinar si dos consultas adyacentes pertenecen a la misma sesión de búsqueda (es decir, detectar los límites de sesión).",
        "El trabajo existente sobre la detección de límites de sesión se encuentra principalmente en el contexto del análisis de registros web (por ejemplo, [8]), y utiliza información estadística en lugar de características textuales.",
        "Dado que nuestro agente del lado del cliente no tiene acceso a los registros de consultas del servidor, tomamos decisiones sobre los límites de sesión basadas en la similitud textual entre dos consultas.",
        "Debido a que las consultas relacionadas no necesariamente comparten las mismas palabras (por ejemplo, isla de Java y viajar a Indonesia), no es suficiente utilizar solo el texto de la consulta.",
        "Por lo tanto, utilizamos los resultados de búsqueda de las dos consultas para ayudar a decidir si están relacionadas temáticamente.",
        "Por ejemplo, para las consultas anteriores \"java island\" y \"travel Indonesia\", las palabras \"java\", \"bali\", \"island\", \"indonesia\" y \"travel\" pueden aparecer con frecuencia en los resultados de búsqueda de ambas consultas, lo que produce un alto puntaje de similitud.",
        "Solo utilizamos los títulos y resúmenes de los resultados de búsqueda para calcular la similitud, ya que están disponibles en la página de resultados de búsqueda recuperada y obtener el texto completo de cada página de resultados ralentizaría significativamente el proceso.",
        "Para compensar la concisión de los títulos y resúmenes, recuperamos más resultados de los que un usuario normalmente vería con el propósito de detectar los límites de sesión (típicamente 50 resultados).",
        "La similitud entre la consulta anterior q y la consulta actual q se calcula de la siguiente manera.",
        "Sean {s1, s2, . . . , sn} y {s1, s2, . . . , sn} los conjuntos de resultados de las dos consultas.",
        "Utilizamos la fórmula de ponderación TF-IDF normalizada pivotada [24] para calcular un vector de peso de término si para cada resultado si.",
        "Definimos el resultado promedio savg como el centroide de todos los vectores de resultado, es decir, (s1 + s2 + . . . + sn)/n.",
        "La similitud del coseno entre los dos resultados promedio se calcula como s avg · savg/ s 2 avg · s2 avg. Si el valor de similitud supera un umbral predefinido, se considerará que las dos consultas están en la misma sesión de información.",
        "Si se determina que la consulta anterior y la consulta actual pertenecen a la misma sesión de búsqueda, UCAIR intentaría expandir la consulta actual con términos de la consulta anterior y sus resultados de búsqueda.",
        "Específicamente, para cada término en la consulta anterior o los resultados de búsqueda correspondientes, si su frecuencia en los resultados de la consulta actual es mayor que un umbral preestablecido (por ejemplo, 5 resultados de 50), el término se agregaría a la consulta actual para formar una consulta ampliada.",
        "En este caso, UCAIR enviaría esta consulta ampliada en lugar de la original al motor de búsqueda y devolvería los resultados correspondientes a la consulta ampliada.",
        "Actualmente, UCAIR solo utiliza la consulta inmediatamente anterior para la expansión de consultas; en principio, podríamos aprovechar todas las consultas pasadas relacionadas. 4.3 Actualización del modelo de necesidad de información Supongamos que en el tiempo t, hemos observado que el usuario ha visto k documentos cuyos resúmenes son s1, ..., sk.",
        "Actualizamos nuestro modelo de usuario calculando un nuevo vector de necesidad de información con un método estándar de retroalimentación en la recuperación de información (es decir, Rocchio [19]).",
        "Según el modelo de recuperación de espacio vectorial, cada resumen clicado si puede ser representado por un vector de pesos de términos si, con cada término ponderado por una fórmula de ponderación TF-IDF [21].",
        "Rocchio calcula el vector centroide de todos los resúmenes e interpola este con el vector de consulta original para obtener un vector de términos actualizado.",
        "Es decir, x = αq + (1 − α) 1 k k i=1 si donde q es el vector de consulta, k es el número de resúmenes que el usuario hace clic inmediatamente después de la consulta actual y α es un parámetro que controla la influencia de los resúmenes clicados en el modelo de necesidad de información inferida.",
        "En nuestros experimentos, α se establece en 0.5.",
        "Ten en cuenta que actualizamos el modelo de información necesario cada vez que el usuario ve un documento. 4.4 Reclasificación de resultados En general, queremos volver a clasificar todos los resultados no vistos tan pronto como se actualice el modelo de usuario.",
        "Actualmente, UCAIR implementa el reordenamiento en dos casos, correspondientes a cuando el usuario hace clic en el botón Atrás y en el enlace Siguiente en Internet Explorer.",
        "En ambos casos, el modelo de usuario actualizado se utilizaría para reordenar los resultados no vistos de manera que el usuario vea resultados de búsqueda mejorados de inmediato.",
        "Para volver a clasificar cualquier resumen de documento no visto, UCAIR utiliza el modelo estándar de recuperación de espacio vectorial y puntúa cada resumen en función de la similitud del resultado y el vector de necesidad de información actual del usuario x [21].",
        "Dado que la retroalimentación implícita no es completamente confiable, presentamos solo un pequeño número (por ejemplo, 5) de los resultados reordenados más altos para ser seguidos por cualquier resultado originalmente clasificado alto. 828 resultados de Google (consulta del usuario = mapa de Java) Resultados de UCAIR (consulta del usuario = mapa de Java) consulta anterior = viajar a Indonesia consulta anterior = tabla hash consulta del usuario ampliada = mapa de Java Indonesia consulta del usuario ampliada = clase de mapa de Java 1 Proyecciones de mapas de Java del mundo ... Lonely Planet - Mapa de Indonesia Mapa (Plataforma Java SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Proyecciones de mapas de Java del mundo ... TURISMO DE INDONESIA: JAVA CENTRAL - MAPA Plataforma Java SE v1.3.1: Interfaz de Mapa www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Mapa de Java TURISMO DE INDONESIA: JAVA OESTE - MAPA Una introducción a las clases de colección de mapas de Java java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Mapa de Tecnología Java IndoStreets - Mapa de Java Una introducción a las clases de colección de mapas de Java java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Regiones e islas de Indonesia Mapas, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 Una introducción a las clases de colección de mapas de Java Mapa de calles de la ciudad de Indonesia,... Hibernate simplifica el mapeo de herencia www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Mapa de Java Mapas de Indonesia jerarquía de clases de tmap 30.map www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Mapa de API de Java Mapas de Indonesia por Peter Loud Alcance de clases www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas: Mapas de Sam de Indonesia por Peter Loud PrintSafeHashMap de la clase www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 TURISMO DE INDONESIA: JAVA OESTE - MAPA indonesiaphoto.com Java Pro - Unión y mapeo vertical de clases www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Tabla 1: Resultados de muestra de la expansión de la consulta",
        "EVALUACIÓN DE UCAIR Ahora presentamos algunos resultados sobre la evaluación de las dos principales funciones de UCAIR: la expansión selectiva de consultas y la reordenación de resultados basada en los datos de clics de los usuarios. 5.1 Resultados de muestra La estrategia de expansión de consultas implementada en UCAIR es intencionalmente conservadora para evitar la interpretación errónea de los modelos implícitos de los usuarios.",
        "En la práctica, cada vez que decide expandir la consulta, la expansión suele tener sentido.",
        "En la Tabla 1, mostramos cómo UCAIR puede distinguir exitosamente dos contextos de búsqueda diferentes para la consulta java map, correspondientes a dos consultas previas distintas (es decir, viajar a Indonesia vs. hashtable).",
        "Debido a la modelización implícita del usuario, UCAIR descubre inteligentemente agregar Indonesia y clase, respectivamente, a la consulta de los usuarios sobre el mapa de Java, lo cual de otro modo sería ambiguo, como se muestra en los resultados originales de Google el 21 de marzo de 2005.",
        "Los resultados de UCAIR son mucho más precisos que los resultados de Google y reflejan la personalización en la búsqueda.",
        "El componente de retroalimentación implícita entusiasta está diseñado para responder inmediatamente a la actividad de un usuario, como por ejemplo, al visualizar un documento.",
        "En la Figura 2, mostramos cómo UCAIR puede desambiguar con éxito una consulta ambigua de jaguar al explotar un resumen del documento visualizado.",
        "En este caso, los resultados iniciales de recuperación utilizando \"jaguar\" (mostrados en el lado izquierdo) contienen dos resultados sobre los autos Jaguar seguidos por dos resultados sobre el software Jaguar.",
        "Sin embargo, después de que el usuario ve el contenido de la página web del segundo resultado (sobre el automóvil Jaguar) y regresa a la página de resultados de búsqueda haciendo clic en el botón Atrás, UCAIR automáticamente selecciona dos nuevos resultados de búsqueda sobre automóviles Jaguar (mostrados en el lado derecho), mientras que los dos resultados originales sobre software de Jaguar se desplazan hacia abajo en la lista (no se ven en la imagen). 5.2 Evaluación cuantitativa Para evaluar UCAIR de manera cuantitativa, realizamos un estudio de usuario sobre la efectividad del componente de retroalimentación implícita ansiosa.",
        "Es un desafío evaluar cuantitativamente la mejora potencial en el rendimiento de nuestro modelo propuesto y UCAIR sobre Google de manera imparcial [7].",
        "Aquí diseñamos un estudio de usuarios, en el cual los participantes realizarían una búsqueda web normal y evaluarían al azar y de forma anónima un conjunto de resultados mezclados de Google y UCAIR al final de la sesión de búsqueda; los participantes no saben si un resultado proviene de Google o de UCAIR.",
        "Reclutamos a 6 estudiantes de posgrado para este estudio de usuarios, quienes tienen diferentes antecedentes (3 en informática, 2 en biología y 1 en química).",
        "Los documentos que describen leyes para limitar el correo no deseado sin dar detalles de demandas judiciales o juicios penales no son relevantes.",
        "Utilizamos los temas de consulta de la pista Terabyte TREC 2 2004 [2] y la tarea de destilación de temas de la pista web TREC 2003 [4] de la manera que se describirá a continuación.",
        "Un ejemplo de tema del TREC 2004 Terabyte track aparece en la Figura 3.",
        "El título es una frase corta y puede ser utilizada como una consulta al sistema de recuperación.",
        "El campo de descripción proporciona una declaración ligeramente más larga del requisito del tema, generalmente expresado como una sola oración completa o pregunta.",
        "Finalmente, la narrativa proporciona información adicional necesaria para especificar completamente el requisito, expresado en forma de un breve párrafo.",
        "Inicialmente, cada participante exploraría 50 temas ya sea de la categoría Terabyte o de la categoría Web y elegiría los 5 o 7 temas más interesantes.",
        "Para cada tema seleccionado, el participante básicamente realizaría la búsqueda web normal utilizando UCAIR para encontrar muchas páginas web relevantes utilizando el título del tema de la consulta como la palabra clave inicial de la consulta.",
        "Durante este proceso, el participante puede ver los resultados de la búsqueda y posiblemente hacer clic en algunos interesantes para ver las páginas web, tal como en una búsqueda web normal.",
        "No hay ningún requisito o restricción sobre cuántas consultas debe enviar el participante o cuándo debe detener la búsqueda de un tema.",
        "Cuando el participante planea cambiar el tema de búsqueda, simplemente presionará un botón 2 de la Conferencia de Recuperación de Texto: http://trec.nist.gov/ 829 Figura 2: Capturas de pantalla para volver a clasificar los resultados y evaluar los resultados de búsqueda antes de cambiar al siguiente tema.",
        "En el momento de la evaluación, los 30 resultados mejor clasificados de Google y UCAIR (algunos se superponen) se mezclan aleatoriamente para que el participante no sepa si un resultado proviene de Google o de UCAIR.",
        "El participante luego juzgaría la relevancia de estos resultados.",
        "Medimos la precisión en los primeros n (n = 5, 10, 20, 30) documentos de Google y UCAIR.",
        "También evaluamos precisiones en diferentes niveles de recuperación.",
        "En total, 368 documentos fueron considerados relevantes a partir de los resultados de búsqueda de Google y 429 documentos fueron considerados relevantes por los participantes de UCAIR.",
        "Los diagramas de dispersión de precisión en los 10 y 20 documentos principales se muestran en la Figura 4 y la Figura 5 respectivamente (El diagrama de dispersión de precisión en los 30 documentos principales es muy similar al de los 20 documentos principales).",
        "Cada punto de los gráficos de dispersión representa las precisiones de Google y UCAIR en un tema de consulta.",
        "La Tabla 2 muestra la precisión promedio en los primeros n documentos entre 32 temas.",
        "A partir de la Figura 4, la Figura 5 y la Tabla 2, vemos que los resultados de búsqueda de UCAIR son consistentemente mejores que los de Google en todas las medidas.",
        "Además, la mejora en el rendimiento es más dramática para la precisión en los primeros 20 documentos que para la precisión en los primeros 10 documentos.",
        "Una explicación para esto es que cuanto más interacción tenga el usuario con el sistema, más datos de clics se espera que UCAIR pueda recopilar.",
        "Por lo tanto, el sistema de recuperación puede construir modelos de usuario implícitos más precisos, lo que conduce a una mayor precisión en la recuperación.",
        "El Método de Clasificación prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Mejora 8.0% 17.8% 20.2% 21.8% Tabla 2: Tabla de precisión promedio en los primeros n documentos para 32 temas de consulta El gráfico en la Figura 6 muestra las curvas de precisión-recuperación para UCAIR y Google, donde se observa claramente que el rendimiento de UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Gráfico de dispersión de Precisión en los 10 primeros documentos Figura 4: La precisión en los 10 primeros documentos de UCAIR y Google es consistentemente y considerablemente mejor que la de Google en todos los niveles de recuperación. 6.",
        "CONCLUSIONES En este artículo, estudiamos cómo aprovechar la modelización implícita del usuario para personalizar de manera inteligente la recuperación de información y mejorar la precisión de la búsqueda.",
        "A diferencia de la mayoría de trabajos anteriores, enfatizamos el uso del contexto de búsqueda inmediata y la información de retroalimentación implícita, así como la actualización rápida de los resultados de búsqueda para beneficiar al máximo a un usuario.",
        "Presentamos un marco de trabajo de toma de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad.",
        "Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos adecuados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para volver a clasificar inmediatamente cualquier documento que aún no haya sido visto por el usuario.",
        "Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente (UCAIR) sobre un motor de búsqueda popular (Google).",
        "Los experimentos en la búsqueda web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en más de un 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Gráfico de dispersión de Precisión en los 20 documentos principales Figura 5: Precisión en los 20 documentos principales de UCAIR y Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 precisión recall Curvas de Precisión-Recall Resultado de Google Resultado de UCAIR Figura 6: Precisión en los 20 resultados principales de UCAIR y Google Google.",
        "Dado que la información implícita que aprovechamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional.",
        "El agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin necesidad de esfuerzo adicional por parte del usuario.",
        "AGRADECIMIENTO Agradecemos a los seis participantes de nuestros experimentos de evaluación.",
        "Este trabajo fue apoyado en parte por las subvenciones de la Fundación Nacional de Ciencias IIS-0347933 e IIS-0428472.",
        "REFERENCIAS [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman y O. Frieder.",
        "Análisis por hora de un registro de consultas web muy grande categorizado por tema.",
        "En Actas de SIGIR 2004, páginas 321-328, 2004. [2] C. Clarke, N. Craswell e I. Soboroff.",
        "Resumen de la pista de terabyte TREC 2004.",
        "En Actas de TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda y D. Brown.",
        "Indicadores implícitos de interés.",
        "En Actas de Interfaces de Usuario Inteligentes 2001, páginas 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson y M. Wu.",
        "Resumen de la pista web TREC 2003.",
        "En Actas de TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend y V. Larvrenko.",
        "Retroalimentación de relevancia y personalización: Una perspectiva de modelado del lenguaje.",
        "En Actas del Segundo Taller DELOS: Personalización y Sistemas de Recomendación en Bibliotecas Digitales, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite y D. Harman.",
        "Resultados y desafíos en la evaluación de búsqueda en la web.",
        "Redes de Computadoras, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A.",
        "An, y D. Schuurmans.",
        "Identificación dinámica de sesiones de registro web con modelos de lenguaje estadístico.",
        "Revista de la Sociedad Americana de Ciencia de la Información y Tecnología, 55(14):1290-1303, 2004. [9] G. Jeh y J. Widom.",
        "Escalando la búsqueda web personalizada.",
        "En Actas de WWW 2003, páginas 271-279, 2003. [10] T. Joachims.",
        "Optimización de motores de búsqueda utilizando datos de clics.",
        "En Actas de SIGKDD 2002, páginas 133-142, 2002. [11] D. Kelly y J. Teevan.",
        "Retroalimentación implícita para inferir preferencias de usuario: Una bibliografía.",
        "SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty y C. Zhai.",
        "Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información.",
        "En Actas de SIGIR01, páginas 111-119, 2001. [13] T. Lau y E. Horvitz.",
        "Patrones de búsqueda: Análisis y modelado de la refinación de consultas web.",
        "En Actas de la Séptima Conferencia Internacional sobre Modelado de Usuarios (UM), páginas 145-152, 1999. [14] V. Lavrenko y B. Croft.",
        "Modelos de lenguaje basados en relevancia.",
        "En Actas de SIGIR01, páginas 120-127, 2001. [15] M. Mitra, A. Singhal y C. Buckley.",
        "Mejorando la expansión automática de consultas.",
        "En Actas de SIGIR 1998, páginas 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg.",
        "Según Google, así va la nación.",
        "New York Times, mayo de 2003. [18] S. E. Robertson.",
        "El principio de clasificación de probabilidad en ı˚.",
        "Revista de Documentación, 33(4):294-304, 1977. [19] J. J. Rocchio.",
        "Retroalimentación de relevancia en la recuperación de información.",
        "En el Sistema de Recuperación SMART: Experimentos en el Procesamiento Automático de Documentos, páginas 313-323.",
        "Prentice-Hall Inc., 1971. [20] G. Salton y C. Buckley.",
        "Mejorando el rendimiento de recuperación mediante retroalimentación de recuperación.",
        "Revista de la Sociedad Americana de Ciencia de la Información, 41(4):288-297, 1990. [21] G. Salton y M. J. McGill.",
        "Introducción a la Recuperación de Información Moderna.",
        "McGraw-Hill, 1983. [22] X. Shen, B. Tan y C. Zhai.",
        "Recuperación de información sensible al contexto utilizando retroalimentación implícita.",
        "En Actas de SIGIR 2005, páginas 43-50, 2005. [23] X. Shen y C. Zhai.",
        "Explotando el historial de consultas para la clasificación de documentos en la recuperación de información interactiva (Póster).",
        "En Actas de SIGIR 2003, páginas 377-378, 2003. [24] A. Singhal.",
        "Recuperación de información moderna: Una breve visión general.",
        "Boletín del Comité Técnico de Ingeniería de Datos de la Sociedad de Computación de IEEE, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano y M. Yoshikawa.",
        "Búsqueda web adaptativa basada en el perfil del usuario construido sin ningún esfuerzo por parte de los usuarios.",
        "En Actas de WWW 2004, páginas 675-684, 2004. [26] E. Volokh.",
        "Personalización y privacidad.",
        "Comunicaciones de la ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen e I. Ruthven.",
        "Un estudio simulado de modelos de retroalimentación implícita.",
        "En Actas de ECIR 2004, páginas 311-326, 2004. [28] J. Xu y W. B. Croft.",
        "Expansión de consultas utilizando análisis local y global de documentos.",
        "En Actas de SIGIR 1996, páginas 4-11, 1996. [29] C. Zhai y J. Lafferty.",
        "Modelo de retroalimentación basado en el modelo de recuperación de divergencia de KL.",
        "En Actas de la CIKM 2001, páginas 403-410, 2001. 831"
    ],
    "error_count": 8,
    "keys": {
        "information retrieval system": {
            "translated_key": "sistemas de recuperación de información",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Implicit User Modeling for Personalized Search Xuehua Shen, Bin Tan, ChengXiang Zhai Department of Computer Science University of Illinois at Urbana-Champaign ABSTRACT Information retrieval systems (e.g., web search engines) are critical for overcoming information overload.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users, resulting in inherently non-optimal retrieval performance.",
                "For example, a tourist and a programmer may use the same word java to search for different information, but the current search systems would return the same results.",
                "In this paper, we study how to infer a users interest from the users search context and use the inferred implicit user model for personalized search .",
                "We present a decision theoretic framework and develop techniques for implicit user modeling in information retrieval.",
                "We develop an intelligent client-side web search agent (UCAIR) that can perform eager implicit feedback, e.g., query expansion based on previous queries and immediate result reranking based on clickthrough information.",
                "Experiments on web search show that our search agent can improve search accuracy over the popular Google search engine.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models, Relevance feedback, Search Process General Terms Algorithms 1.",
                "INTRODUCTION Although many <br>information retrieval system</br>s (e.g., web search engines and digital library systems) have been successfully deployed, the current retrieval systems are far from optimal.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users [17].",
                "This inherent non-optimality is seen clearly in the following two cases: (1) Different users may use exactly the same query (e.g., Java) to search for different information (e.g., the Java island in Indonesia or the Java programming language), but existing IR systems return the same results for these users.",
                "Without considering the actual user, it is impossible to know which sense Java refers to in a query. (2) A users information needs may change over time.",
                "The same user may use Java sometimes to mean the Java island in Indonesia and some other times to mean the programming language.",
                "Without recognizing the search context, it would be again impossible to recognize the correct sense.",
                "In order to optimize retrieval accuracy, we clearly need to model the user appropriately and personalize search according to each individual user.",
                "The major goal of user modeling for information retrieval is to accurately model a users information need, which is, unfortunately, a very difficult task.",
                "Indeed, it is even hard for a user to precisely describe what his/her information need is.",
                "What information is available for a system to infer a users information need?",
                "Obviously, the users query provides the most direct evidence.",
                "Indeed, most existing retrieval systems rely solely on the query to model a users information need.",
                "However, since a query is often extremely short, the user model constructed based on a keyword query is inevitably impoverished .",
                "An effective way to improve user modeling in information retrieval is to ask the user to explicitly specify which documents are relevant (i.e., useful for satisfying his/her information need), and then to improve user modeling based on such examples of relevant documents.",
                "This is called relevance feedback, which has been proved to be quite effective for improving retrieval accuracy [19, 20].",
                "Unfortunately, in real world applications, users are usually reluctant to make the extra effort to provide relevant examples for feedback [11].",
                "It is thus very interesting to study how to infer a users information need based on any implicit feedback information, which naturally exists through user interactions and thus does not require any extra user effort.",
                "Indeed, several previous studies have shown that implicit user modeling can improve retrieval accuracy.",
                "In [3], a web browser (Curious Browser) is developed to record a users explicit relevance ratings of web pages (relevance feedback) and browsing behavior when viewing a page, such as dwelling time, mouse click, mouse movement and scrolling (implicit feedback).",
                "It is shown that the dwelling time on a page, amount of scrolling on a page and the combination of time and scrolling have a strong correlation with explicit relevance ratings, which suggests that implicit feedback may be helpful for inferring user information need.",
                "In [10], user clickthrough data is collected as training data to learn a retrieval function, which is used to produce a customized ranking of search results that suits a group of users preferences.",
                "In [25], the clickthrough data collected over a long time period is exploited through query expansion to improve retrieval accuracy. 824 While a user may have general long term interests and preferences for information, often he/she is searching for documents to satisfy an ad-hoc information need, which only lasts for a short period of time; once the information need is satisfied, the user would generally no longer be interested in such information.",
                "For example, a user may be looking for information about used cars in order to buy one, but once the user has bought a car, he/she is generally no longer interested in such information.",
                "In such cases, implicit feedback information collected over a long period of time is unlikely to be very useful, but the immediate search context and feedback information, such as which of the search results for the current information need are viewed, can be expected to be much more useful.",
                "Consider the query Java again.",
                "Any of the following immediate feedback information about the user could potentially help determine the intended meaning of Java in the query: (1) The previous query submitted by the user is hashtable (as opposed to, e.g., travel Indonesia). (2) In the search results, the user viewed a page where words such as programming, software, and applet occur many times.",
                "To the best of our knowledge, how to exploit such immediate and short-term search context to improve search has so far not been well addressed in the previous work.",
                "In this paper, we study how to construct and update a user model based on the immediate search context and implicit feedback information and use the model to improve the accuracy of ad-hoc retrieval.",
                "In order to maximally benefit the user of a retrieval system through implicit user modeling, we propose to perform eager implicit feedback.",
                "That is, as soon as we observe any new piece of evidence from the user, we would update the systems belief about the users information need and respond with improved retrieval results based on the updated user model.",
                "We present a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "In a traditional retrieval paradigm, the retrieval problem is to match a query with documents and rank documents according to their relevance values.",
                "As a result, the retrieval process is a simple independent cycle of query and result display.",
                "In the proposed new retrieval paradigm, the users search context plays an important role and the inferred implicit user model is exploited immediately to benefit the user.",
                "The new retrieval paradigm is thus fundamentally different from the traditional paradigm, and is inherently more general.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent UCAIR (User-Centered Adaptive Information Retrieval) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "Thus the developed search agent can improve existing web search performance without additional effort from the user.",
                "The remaining sections are organized as follows.",
                "In Section 2, we discuss the related work.",
                "In Section 3, we present a decisiontheoretic interactive retrieval framework for implicit user modeling.",
                "In Section 4, we present the design and implementation of an intelligent client-side web search agent (UCAIR) that performs eager implicit feedback.",
                "In Section 5, we report our experiment results using the search agent.",
                "Section 6 concludes our work. 2.",
                "RELATED WORK Implicit user modeling for personalized search has been studied in previous work, but our work differs from all previous work in several aspects: (1) We emphasize the exploitation of immediate search context such as the related immediately preceding query and the viewed documents in the same session, while most previous work relies on long-term collection of implicit feedback information [25]. (2) We perform eager feedback and bring the benefit of implicit user modeling as soon as any new implicit feedback information is available, while the previous work mostly exploits longterm implicit feedback [10]. (3) We propose a retrieval framework to integrate implicit user modeling with the interactive retrieval process, while the previous work either studies implicit user modeling separately from retrieval [3] or only studies specific retrieval models for exploiting implicit feedback to better match a query with documents [23, 27, 22]. (4) We develop and evaluate a personalized Web search agent with online user studies, while most existing work evaluates algorithms offline without real user interactions.",
                "Currently some search engines provide rudimentary personalization, such as Google Personalized web search [6], which allows users to explicitly describe their interests by selecting from predefined topics, so that those results that match their interests are brought to the top, and My Yahoo! search [16], which gives users the option to save web sites they like and block those they dislike.",
                "In contrast, UCAIR personalizes web search through implicit user modeling without any additional user efforts.",
                "Furthermore, the personalization of UCAIR is provided on the client side.",
                "There are two remarkable advantages on this.",
                "First, the user does not need to worry about the privacy infringement, which is a big concern for personalized search [26].",
                "Second, both the computation of personalization and the storage of the user profile are done at the client side so that the server load is reduced dramatically [9].",
                "There have been many works studying user query logs [1] or query dynamics [13].",
                "UCAIR makes direct use of a users query history to benefit the same user immediately in the same search session.",
                "UCAIR first judges whether two neighboring queries belong to the same information session and if so, it selects terms from the previous query to perform query expansion.",
                "Our query expansion approach is similar to automatic query expansion [28, 15, 5], but instead of using pseudo feedback to expand the query, we use users implicit feedback information to expand the current query.",
                "These two techniques may be combined. 3.",
                "OPTIMIZATION IN INTERACTIVE IR In interactive IR, a user interacts with the retrieval system through an action dialogue, in which the system responds to each user action with some system action.",
                "For example, the users action may be submitting a query and the systems response may be returning a list of 10 document summaries.",
                "In general, the space of user actions and system responses and their granularities would depend on the interface of a particular retrieval system.",
                "In principle, every action of the user can potentially provide new evidence to help the system better infer the users information need.",
                "Thus in order to respond optimally, the system should use all the evidence collected so far about the user when choosing a response.",
                "When viewed in this way, most existing search engines are clearly non-optimal.",
                "For example, if a user has viewed some documents on the first page of search results, when the user clicks on the Next link to fetch more results, an existing retrieval system would still return the next page of results retrieved based on the original query without considering the new evidence that a particular result has been viewed by the user. 825 We propose to optimize retrieval performance by adapting system responses based on every action that a user has taken, and cast the optimization problem as a decision task.",
                "Specifically, at any time, the system would attempt to do two tasks: (1) User model updating: Monitor any useful evidence from the user regarding his/her information need and update the user model as soon as such evidence is available; (2) Improving search results: Rerank immediately all the documents that the user has not yet seen, as soon as the user model is updated.",
                "We emphasize eager updating and reranking, which makes our work quite different from any existing work.",
                "Below we present a formal decision theoretic framework for optimizing retrieval performance through implicit user modeling in interactive information retrieval. 3.1 A decision-theoretic framework Let A be the set of all user actions and R(a) be the set of all possible system responses to a user action a ∈ A.",
                "At any time, let At = (a1, ..., at) be the observed sequence of user actions so far (up to time point t) and Rt−1 = (r1, ..., rt−1) be the responses that the system has made responding to the user actions.",
                "The systems goal is to choose an optimal response rt ∈ R(at) for the current user action at.",
                "Let M be the space of all possible user models.",
                "We further define a loss function L(a, r, m) ∈ , where a ∈ A is a user action, r ∈ R(a) is a system response, and m ∈ M is a user model.",
                "L(a, r, m) encodes our decision preferences and assesses the optimality of responding with r when the current user model is m and the current user action is a.",
                "According to Bayesian decision theory, the optimal decision at time t is to choose a response that minimizes the Bayes risk, i.e., r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) where P(mt|U, D, At, Rt−1) is the posterior probability of the user model mt given all the observations about the user U we have made up to time t. To simplify the computation of Equation 1, let us assume that the posterior probability mass P(mt|U, D, At, Rt−1) is mostly concentrated on the mode m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "We can then approximate the integral with the value of the loss function at m∗ t .",
                "That is, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) where m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "Leaving aside how to define and estimate these probabilistic models and the loss function, we can see that such a decision-theoretic formulation suggests that, in order to choose the optimal response to at, the system should perform two tasks: (1) compute the current user model and obtain m∗ t based on all the useful information. (2) choose a response rt to minimize the loss function value L(at, rt, m∗ t ).",
                "When at does not affect our belief about m∗ t , the first step can be omitted and we may reuse m∗ t−1 for m∗ t .",
                "Note that our framework is quite general since we can potentially model any kind of user actions and system responses.",
                "In most cases, as we may expect, the systems response is some ranking of documents, i.e., for most actions a, R(a) consists of all the possible rankings of the unseen documents, and the decision problem boils down to choosing the best ranking of unseen documents based on the most current user model.",
                "When a is the action of submitting a keyword query, such a response is exactly what a current retrieval system would do.",
                "However, we can easily imagine that a more intelligent web search engine would respond to a users clicking of the Next link (to fetch more unseen results) with a more optimized ranking of documents based on any viewed documents in the current page of results.",
                "In fact, according to our eager updating strategy, we may even allow a system to respond to a users clicking of browsers Back button after viewing a document in the same way, so that the user can maximally benefit from implicit feedback.",
                "These are precisely what our UCAIR system does. 3.2 User models A user model m ∈ M represents what we know about the user U, so in principle, it can contain any information about the user that we wish to model.",
                "We now discuss two important components in a user model.",
                "The first component is a component model of the users information need.",
                "Presumably, the most important factor affecting the optimality of the systems response is how well the response addresses the users information need.",
                "Indeed, at any time, we may assume that the system has some belief about what the user is interested in, which we model through a term vector x = (x1, ..., x|V |), where V = {w1, ..., w|V |} is the set of all terms (i.e., vocabulary) and xi is the weight of term wi.",
                "Such a term vector is commonly used in information retrieval to represent both queries and documents.",
                "For example, the vector-space model, assumes that both the query and the documents are represented as term vectors and the score of a document with respect to a query is computed based on the similarity between the query vector and the document vector [21].",
                "In a language modeling approach, we may also regard the query unigram language model [12, 29] or the relevance model [14] as a term vector representation of the users information need.",
                "Intuitively, x would assign high weights to terms that characterize the topics which the user is interested in.",
                "The second component we may include in our user model is the documents that the user has already viewed.",
                "Obviously, even if a document is relevant, if the user has already seen the document, it would not be useful to present the same document again.",
                "We thus introduce another variable S ⊂ D (D is the whole set of documents in the collection) to denote the subset of documents in the search results that the user has already seen/viewed.",
                "In general, at time t, we may represent a user model as mt = (S, x, At, Rt−1), where S is the seen documents, x is the systems understanding of the users information need, and (At, Rt−1) represents the users interaction history.",
                "Note that an even more general user model may also include other factors such as the users reading level and occupation.",
                "If we assume that the uncertainty of a user model mt is solely due to the uncertainty of x, the computation of our current estimate of user model m∗ t will mainly involve computing our best estimate of x.",
                "That is, the system would choose a response according to r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) where x∗ = argmaxx P(x|U, D, At, Rt−1).",
                "This is the decision mechanism implemented in the UCAIR system to be described later.",
                "In this system, we avoided specifying the probabilistic model P(x|U, D, At, Rt−1) by computing x∗ directly with some existing feedback method. 3.3 Loss functions The exact definition of loss function L depends on the responses, thus it is inevitably application-specific.",
                "We now briefly discuss some possibilities when the response is to rank all the unseen documents and present the top k of them.",
                "Let r = (d1, ..., dk) be the top k documents, S be the set of seen documents by the user, and x∗ be the systems best guess of the users information need.",
                "We 826 may simply define the loss associated with r as the negative sum of the probability that each of the di is relevant, i.e., L(a, r, m) = − k i=1 P(relevant|di, m).",
                "Clearly, in order to minimize this loss function, the optimal response r would contain the k documents with the highest probability of relevance, which is intuitively reasonable.",
                "One deficiency of this top-k loss function is that it is not sensitive to the internal order of the selected top k documents, so switching the ranking order of a non-relevant document and a relevant one would not affect the loss, which is unreasonable.",
                "To model ranking, we can introduce a factor of the user model - the probability of each of the k documents being viewed by the user, P(view|di), and define the following ranking loss function: L(a, r, m) = − k i=1 P(view|di)P(relevant|di, m) Since in general, if di is ranked above dj (i.e., i < j), P(view|di) > P(view|dj), this loss function would favor a decision to rank relevant documents above non-relevant ones, as otherwise, we could always switch di with dj to reduce the loss value.",
                "Thus the system should simply perform a regular retrieval and rank documents according to the probability of relevance [18].",
                "Depending on the users retrieval preferences, there can be many other possibilities.",
                "For example, if the user does not want to see redundant documents, the loss function should include some redundancy measure on r based on the already seen documents S. Of course, when the response is not to choose a ranked list of documents, we would need a different loss function.",
                "We discuss one such example that is relevant to the search agent that we implement.",
                "When a user enters a query qt (current action), our search agent relies on some existing search engine to actually carry out search.",
                "In such a case, even though the search agent does not have control of the retrieval algorithm, it can still attempt to optimize the search results through refining the query sent to the search engine and/or reranking the results obtained from the search engine.",
                "The loss functions for reranking are already discussed above; we now take a look at the loss functions for query refinement.",
                "Let f be the retrieval function of the search engine that our agent uses so that f(q) would give us the search results using query q.",
                "Given that the current action of the user is entering a query qt (i.e., at = qt), our response would be f(q) for some q.",
                "Since we have no choice of f, our decision is to choose a good q.",
                "Formally, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) which shows that our goal is to find q∗ = argminqL(qt, f(q), m), i.e., an optimal query that would give us the best f(q).",
                "A different choice of loss function L(qt, f(q), m) would lead to a different query refinement strategy.",
                "In UCAIR, we heuristically compute q∗ by expanding qt with terms extracted from rt−1 whenever qt−1 and qt have high similarity.",
                "Note that rt−1 and qt−1 are contained in m as part of the users interaction history. 3.4 Implicit user modeling Implicit user modeling is captured in our framework through the computation of x∗ = argmaxx P(x|U, D, At, Rt−1), i.e., the systems current belief of what the users information need is.",
                "Here again there may be many possibilities, leading to different algorithms for implicit user modeling.",
                "We now discuss a few of them.",
                "First, when two consecutive queries are related, the previous query can be exploited to enrich the current query and provide more search context to help disambiguation.",
                "For this purpose, instead of performing query expansion as we did in the previous section, we could also compute an updated x∗ based on the previous query and retrieval results.",
                "The computed new user model can then be used to rank the documents with a standard information retrieval model.",
                "Second, we can also infer a users interest based on the summaries of the viewed documents.",
                "When a user is presented with a list of summaries of top ranked documents, if the user chooses to skip the first n documents and to view the (n+1)-th document, we may infer that the user is not interested in the displayed summaries for the first n documents, but is attracted by the displayed summary of the (n + 1)-th document.",
                "We can thus use these summaries as negative and positive examples to learn a more accurate user model x∗ .",
                "Here many standard relevance feedback techniques can be exploited [19, 20].",
                "Note that we should use the displayed summaries, as opposed to the actual contents of those documents, since it is possible that the displayed summary of the viewed document is relevant, but the document content is actually not.",
                "Similarly, a displayed summary may mislead a user to skip a relevant document.",
                "Inferring user models based on such displayed information, rather than the actual content of a document is an important difference between UCAIR and some other similar systems.",
                "In UCAIR, both of these strategies for inferring an implicit user model are implemented. 4.",
                "UCAIR: A PERSONALIZED SEARCH AGENT 4.1 Design In this section, we present a client-side web search agent called UCAIR, in which we implement some of the methods discussed in the previous section for performing personalized search through implicit user modeling.",
                "UCAIR is a web browser plug-in 1 that acts as a proxy for web search engines.",
                "Currently, it is only implemented for Internet Explorer and Google, but it is a matter of engineering to make it run on other web browsers and interact with other search engines.",
                "The issue of privacy is a primary obstacle for deploying any real world applications involving serious user modeling, such as personalized search.",
                "For this reason, UCAIR is strictly running as a client-side search agent, as opposed to a server-side application.",
                "This way, the captured user information always resides on the computer that the user is using, thus the user does not need to release any information to the outside.",
                "Client-side personalization also allows the system to easily observe a lot of user information that may not be easily available to a server.",
                "Furthermore, performing personalized search on the client-side is more scalable than on the serverside, since the overhead of computation and storage is distributed among clients.",
                "As shown in Figure 1, the UCAIR toolbar has 3 major components: (1) The (implicit) user modeling module captures a users search context and history information, including the submitted queries and any clicked search results and infers search session boundaries. (2) The query modification module selectively improves the query formulation according to the current user model. (3) The result re-ranking module immediately re-ranks any unseen search results whenever the user model is updated.",
                "In UCAIR, we consider four basic user actions: (1) submitting a keyword query; (2) viewing a document; (3) clicking the Back button; (4) clicking the Next link on a result page.",
                "For each of these four actions, the system responds with, respectively, (1) 1 UCAIR is available at: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Search Engine (e.g., Google) Search History Log (e.g.,past queries, clicked results) Query Modification Result Re-Ranking User Modeling Result Buffer UCAIR Userquery results clickthrough… Figure 1: UCAIR architecture generating a ranked list of results by sending a possibly expanded query to a search engine; (2) updating the information need model x; (3) reranking the unseen results on the current result page based on the current model x; and (4) reranking the unseen pages and generating the next page of results based on the current model x.",
                "Behind these responses, there are three basic tasks: (1) Decide whether the previous query is related to the current query and if so expand the current query with useful terms from the previous query or the results of the previous query. (2) Update the information need model x based on a newly clicked document summary. (3) Rerank a set of unseen documents based on the current model x.",
                "Below we describe our algorithms for each of them. 4.2 Session boundary detection and query expansion To effectively exploit previous queries and their corresponding clickthrough information, UCAIR needs to judge whether two adjacent queries belong to the same search session (i.e., detect session boundaries).",
                "Existing work on session boundary detection is mostly in the context of web log analysis (e.g., [8]), and uses statistical information rather than textual features.",
                "Since our clientside agent does not have access to server query logs, we make session boundary decisions based on textual similarity between two queries.",
                "Because related queries do not necessarily share the same words (e.g., java island and travel Indonesia), it is insufficient to use only query text.",
                "Therefore we use the search results of the two queries to help decide whether they are topically related.",
                "For example, for the above queries java island and travel Indonesia, the words java, bali, island, indonesia and travel may occur frequently in both queries search results, yielding a high similarity score.",
                "We only use the titles and summaries of the search results to calculate the similarity since they are available in the retrieved search result page and fetching the full text of every result page would significantly slow down the process.",
                "To compensate for the terseness of titles and summaries, we retrieve more results than a user would normally view for the purpose of detecting session boundaries (typically 50 results).",
                "The similarity between the previous query q and the current query q is computed as follows.",
                "Let {s1, s2, . . . , sn } and {s1, s2, . . . , sn} be the result sets for the two queries.",
                "We use the pivoted normalization TF-IDF weighting formula [24] to compute a term weight vector si for each result si.",
                "We define the average result savg to be the centroid of all the result vectors, i.e., (s1 + s2 + . . . + sn)/n.",
                "The cosine similarity between the two average results is calculated as s avg · savg/ s 2 avg · s2 avg If the similarity value exceeds a predefined threshold, the two queries will be considered to be in the same information session.",
                "If the previous query and the current query are found to belong to the same search session, UCAIR would attempt to expand the current query with terms from the previous query and its search results.",
                "Specifically, for each term in the previous query or the corresponding search results, if its frequency in the results of the current query is greater than a preset threshold (e.g. 5 results out of 50), the term would be added to the current query to form an expanded query.",
                "In this case, UCAIR would send this expanded query rather than the original one to the search engine and return the results corresponding to the expanded query.",
                "Currently, UCAIR only uses the immediate preceding query for query expansion; in principle, we could exploit all related past queries. 4.3 Information need model updating Suppose at time t, we have observed that the user has viewed k documents whose summaries are s1, ..., sk.",
                "We update our user model by computing a new information need vector with a standard feedback method in information retrieval (i.e., Rocchio [19]).",
                "According to the vector space retrieval model, each clicked summary si can be represented by a term weight vector si with each term weighted by a TF-IDF weighting formula [21].",
                "Rocchio computes the centroid vector of all the summaries and interpolates it with the original query vector to obtain an updated term vector.",
                "That is, x = αq + (1 − α) 1 k k i=1 si where q is the query vector, k is the number of summaries the user clicks immediately following the current query and α is a parameter that controls the influence of the clicked summaries on the inferred information need model.",
                "In our experiments, α is set to 0.5.",
                "Note that we update the information need model whenever the user views a document. 4.4 Result reranking In general, we want to rerank all the unseen results as soon as the user model is updated.",
                "Currently, UCAIR implements reranking in two cases, corresponding to the user clicking the Back button and Next link in the Internet Explorer.",
                "In both cases, the current (updated) user model would be used to rerank the unseen results so that the user would see improved search results immediately.",
                "To rerank any unseen document summaries, UCAIR uses the standard vector space retrieval model and scores each summary based on the similarity of the result and the current user information need vector x [21].",
                "Since implicit feedback is not completely reliable, we bring up only a small number (e.g. 5) of highest reranked results to be followed by any originally high ranked results. 828 Google result (user query = java map) UCAIR result (user query =java map) previous query = travel Indonesia previous query = hashtable expanded user query = java map Indonesia expanded user query = java map class 1 Java map projections of the world ... Lonely Planet - Indonesia Map Map (Java 2 Platform SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Java map projections of the world ... INDONESIA TOURISM : CENTRAL JAVA - MAP Java 2 Platform SE v1.3.1: Interface Map www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Java Map INDONESIA TOURISM : WEST JAVA - MAP An Introduction to Java Map Collection Classes java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Java Technology Concept Map IndoStreets - Java Map An Introduction to Java Map Collection Classes java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Indonesia Regions and Islands Maps, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 An Introduction to Java Map Collection Classes Indonesia City Street Map,... Hibernate simplifies inheritance mapping www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Java Map Maps Of Indonesia tmap 30.map Class Hierarchy www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Java API Map Maps of Indonesia by Peter Loud Class Scope www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas : Sam Maps of Indonesia by Peter Loud Class PrintSafeHashMap www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 INDONESIA TOURISM : WEST JAVA - MAP indonesiaphoto.com Java Pro - Union and Vertical Mapping of Classes www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Table 1: Sample results of query expansion 5.",
                "EVALUATION OF UCAIR We now present some results on evaluating the two major UCAIR functions: selective query expansion and result reranking based on user clickthrough data. 5.1 Sample results The query expansion strategy implemented in UCAIR is intentionally conservative to avoid misinterpretation of implicit user models.",
                "In practice, whenever it chooses to expand the query, the expansion usually makes sense.",
                "In Table 1, we show how UCAIR can successfully distinguish two different search contexts for the query java map, corresponding to two different previous queries (i.e., travel Indonesia vs. hashtable).",
                "Due to implicit user modeling, UCAIR intelligently figures out to add Indonesia and class, respectively, to the users query java map, which would otherwise be ambiguous as shown in the original results from Google on March 21, 2005.",
                "UCAIRs results are much more accurate than Googles results and reflect personalization in search.",
                "The eager implicit feedback component is designed to immediately respond to a users activity such as viewing a document.",
                "In Figure 2, we show how UCAIR can successfully disambiguate an ambiguous query jaguar by exploiting a viewed document summary.",
                "In this case, the initial retrieval results using jaguar (shown on the left side) contain two results about the Jaguar cars followed by two results about the Jaguar software.",
                "However, after the user views the web page content of the second result (about Jaguar car) and returns to the search result page by clicking Back button, UCAIR automatically nominates two new search results about Jaguar cars (shown on the right side), while the original two results about Jaguar software are pushed down on the list (unseen from the picture). 5.2 Quantitative evaluation To further evaluate UCAIR quantitatively, we conduct a user study on the effectiveness of the eager implicit feedback component.",
                "It is a challenge to quantitatively evaluate the potential performance improvement of our proposed model and UCAIR over Google in an unbiased way [7].",
                "Here, we design a user study, in which participants would do normal web search and judge a randomly and anonymously mixed set of results from Google and UCAIR at the end of the search session; participants do not know whether a result comes from Google or UCAIR.",
                "We recruited 6 graduate students for this user study, who have different backgrounds (3 computer science, 2 biology, and 1 chem<top> <num> Number: 716 <title> Spammer arrest sue <desc> Description: Have any spammers been arrested or sued for sending unsolicited e-mail? <narr> Narrative: Instances of arrests, prosecutions, convictions, and punishments of spammers, and lawsuits against them are relevant.",
                "Documents which describe laws to limit spam without giving details of lawsuits or criminal trials are not relevant. </top> Figure 3: An example of TREC query topic, expressed in a form which might be given to a human assistant or librarian istry).",
                "We use query topics from TREC 2 2004 Terabyte track [2] and TREC 2003 Web track [4] topic distillation task in the way to be described below.",
                "An example topic from TREC 2004 Terabyte track appears in Figure 3.",
                "The title is a short phrase and may be used as a query to the retrieval system.",
                "The description field provides a slightly longer statement of the topic requirement, usually expressed as a single complete sentence or question.",
                "Finally the narrative supplies additional information necessary to fully specify the requirement, expressed in the form of a short paragraph.",
                "Initially, each participant would browse 50 topics either from Terabyte track or Web track and pick 5 or 7 most interesting topics.",
                "For each picked topic, the participant would essentially do the normal web search using UCAIR to find many relevant web pages by using the title of the query topic as the initial keyword query.",
                "During this process, the participant may view the search results and possibly click on some interesting ones to view the web pages, just as in a normal web search.",
                "There is no requirement or restriction on how many queries the participant must submit or when the participant should stop the search for one topic.",
                "When the participant plans to change the search topic, he/she will simply press a button 2 Text REtrieval Conference: http://trec.nist.gov/ 829 Figure 2: Screen shots for result reranking to evaluate the search results before actually switching to the next topic.",
                "At the time of evaluation, 30 top ranked results from Google and UCAIR (some are overlapping) are randomly mixed together so that the participant would not know whether a result comes from Google or UCAIR.",
                "The participant would then judge the relevance of these results.",
                "We measure precision at top n (n = 5, 10, 20, 30) documents of Google and UCAIR.",
                "We also evaluate precisions at different recall levels.",
                "Altogether, 368 documents judged as relevant from Google search results and 429 documents judged as relevant from UCAIR by participants.",
                "Scatter plots of precision at top 10 and top 20 documents are shown in Figure 4 and Figure 5 respectively (The scatter plot of precision at top 30 documents is very similar to precision at top 20 documents).",
                "Each point of the scatter plots represents the precisions of Google and UCAIR on one query topic.",
                "Table 2 shows the average precision at top n documents among 32 topics.",
                "From Figure 4, Figure 5 and Table 2, we see that the search results from UCAIR are consistently better than those from Google by all the measures.",
                "Moreover, the performance improvement is more dramatic for precision at top 20 documents than that at precision at top 10 documents.",
                "One explanation for this is that the more interaction the user has with the system, the more clickthrough data UCAIR can be expected to collect.",
                "Thus the retrieval system can build more precise implicit user models, which lead to better retrieval accuracy.",
                "Ranking Method prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Improvement 8.0% 17.8% 20.2% 21.8% Table 2: Table of average precision at top n documents for 32 query topics The plot in Figure 6 shows the precision-recall curves for UCAIR and Google, where it is clearly seen that the performance of UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Scatterplot of Precision at Top 10 Documents Figure 4: Precision at top 10 documents of UCAIR and Google is consistently and considerably better than that of Google at all levels of recall. 6.",
                "CONCLUSIONS In this paper, we studied how to exploit implicit user modeling to intelligently personalize information retrieval and improve search accuracy.",
                "Unlike most previous work, we emphasize the use of immediate search context and implicit feedback information as well as eager updating of search results to maximally benefit a user.",
                "We presented a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent (UCAIR) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Scatterplot of Precision at Top 20 documents Figure 5: Precision at top 20 documents of UCAIR and Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 recall precision Precision−Recall curves Google Result UCAIR Result Figure 6: Precision at top 20 result of UCAIR and Google Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "The developed search agent thus can improve existing web search performance without any additional effort from the user. 7.",
                "ACKNOWLEDGEMENT We thank the six participants of our evaluation experiments.",
                "This work was supported in part by the National Science Foundation grants IIS-0347933 and IIS-0428472. 8.",
                "REFERENCES [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman, and O. Frieder.",
                "Hourly analysis of a very large topically categorized web query log.",
                "In Proceedings of SIGIR 2004, pages 321-328, 2004. [2] C. Clarke, N. Craswell, and I. Soboroff.",
                "Overview of the TREC 2004 terabyte track.",
                "In Proceedings of TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda, and D. Brown.",
                "Implicit interest indicators.",
                "In Proceedings of Intelligent User Interfaces 2001, pages 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson, and M. Wu.",
                "Overview of the TREC 2003 web track.",
                "In Proceedings of TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend, and V. Larvrenko.",
                "Relevance feedback and personalization: A language modeling perspective.",
                "In Proeedings of Second DELOS Workshop: Personalisation and Recommender Systems in Digital Libraries, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite, and D. Harman.",
                "Results and challenges in web search evaluation.",
                "Computer Networks, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A.",
                "An, and D. Schuurmans.",
                "Dynamic web log session identification with statistical language models.",
                "Journal of the American Society for Information Science and Technology, 55(14):1290-1303, 2004. [9] G. Jeh and J. Widom.",
                "Scaling personalized web search.",
                "In Proceedings of WWW 2003, pages 271-279, 2003. [10] T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of SIGKDD 2002, pages 133-142, 2002. [11] D. Kelly and J. Teevan.",
                "Implicit feedback for inferring user preference: A bibliography.",
                "SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of SIGIR01, pages 111-119, 2001. [13] T. Lau and E. Horvitz.",
                "Patterns of search: Analyzing and modeling web query refinement.",
                "In Proceedings of the Seventh International Conference on User Modeling (UM), pages 145 -152, 1999. [14] V. Lavrenko and B. Croft.",
                "Relevance-based language models.",
                "In Proceedings of SIGIR01, pages 120-127, 2001. [15] M. Mitra, A. Singhal, and C. Buckley.",
                "Improving automatic query expansion.",
                "In Proceedings of SIGIR 1998, pages 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg.",
                "As google goes, so goes the nation.",
                "New York Times, May 2003. [18] S. E. Robertson.",
                "The probability ranking principle in ı˚.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] J. J. Rocchio.",
                "Relevance feedback in information retrieval.",
                "In The SMART Retrieval System: Experiments in Automatic Document Processing, pages 313-323.",
                "Prentice-Hall Inc., 1971. [20] G. Salton and C. Buckley.",
                "Improving retrieval performance by retrieval feedback.",
                "Journal of the American Society for Information Science, 41(4):288-297, 1990. [21] G. Salton and M. J. McGill.",
                "Introduction to Modern Information Retrieval.",
                "McGraw-Hill, 1983. [22] X. Shen, B. Tan, and C. Zhai.",
                "Context-sensitive information retrieval using implicit feedback.",
                "In Proceedings of SIGIR 2005, pages 43-50, 2005. [23] X. Shen and C. Zhai.",
                "Exploiting query history for document ranking in interactive information retrieval (Poster).",
                "In Proceedings of SIGIR 2003, pages 377-378, 2003. [24] A. Singhal.",
                "Modern information retrieval: A brief overview.",
                "Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano, and M. Yoshikawa.",
                "Adaptive web search based on user profile constructed without any effort from users.",
                "In Proceedings of WWW 2004, pages 675-684, 2004. [26] E. Volokh.",
                "Personalization and privacy.",
                "Communications of the ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen, and I. Ruthven.",
                "A simulated study of implicit feedback models.",
                "In Proceedings of ECIR 2004, pages 311-326, 2004. [28] J. Xu and W. B. Croft.",
                "Query expansion using local and global document analysis.",
                "In Proceedings of SIGIR 1996, pages 4-11, 1996. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in KL divergence retrieval model.",
                "In Proceedings of the CIKM 2001, pages 403-410, 2001. 831"
            ],
            "original_annotated_samples": [
                "INTRODUCTION Although many <br>information retrieval system</br>s (e.g., web search engines and digital library systems) have been successfully deployed, the current retrieval systems are far from optimal."
            ],
            "translated_annotated_samples": [
                "Aunque muchos <br>sistemas de recuperación de información</br> (por ejemplo, motores de búsqueda web y sistemas de biblioteca digital) se han implementado con éxito, los sistemas de recuperación actuales están lejos de ser óptimos."
            ],
            "translated_text": "Modelado implícito de usuarios para búsqueda personalizada Xuehua Shen, Bin Tan, ChengXiang Zhai Departamento de Ciencias de la Computación Universidad de Illinois en Urbana-Champaign RESUMEN Los sistemas de recuperación de información (por ejemplo, motores de búsqueda web) son críticos para superar la sobrecarga de información. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales, lo que resulta en un rendimiento de recuperación inherentemente no óptimo. Por ejemplo, un turista y un programador pueden usar la misma palabra \"java\" para buscar información diferente, pero los sistemas de búsqueda actuales devolverían los mismos resultados. En este artículo, estudiamos cómo inferir el interés de un usuario a partir del contexto de búsqueda del usuario y utilizar el modelo de usuario implícito inferido para la búsqueda personalizada. Presentamos un marco teórico de toma de decisiones y desarrollamos técnicas para el modelado implícito del usuario en la recuperación de información. Desarrollamos un agente de búsqueda web inteligente del lado del cliente (UCAIR) que puede realizar retroalimentación implícita ansiosa, por ejemplo, expansión de consultas basada en consultas anteriores y reordenamiento inmediato de resultados basado en información de clics. Los experimentos sobre la búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda sobre el popular motor de búsqueda Google. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación, Retroalimentación de relevancia, Proceso de búsqueda Términos Generales Algoritmos 1. Aunque muchos <br>sistemas de recuperación de información</br> (por ejemplo, motores de búsqueda web y sistemas de biblioteca digital) se han implementado con éxito, los sistemas de recuperación actuales están lejos de ser óptimos. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales [17]. Esta no optimalidad inherente se ve claramente en los siguientes dos casos: (1) Diferentes usuarios pueden utilizar exactamente la misma consulta (por ejemplo, Java) para buscar información diferente (por ejemplo, la isla de Java en Indonesia o el lenguaje de programación Java), pero los sistemas de IR existentes devuelven los mismos resultados para estos usuarios. Sin considerar al usuario actual, es imposible saber a qué sentido se refiere Java en una consulta. (2) Las necesidades de información de un usuario pueden cambiar con el tiempo. El mismo usuario puede usar Java a veces para referirse a la isla de Java en Indonesia y otras veces para referirse al lenguaje de programación. Sin reconocer el contexto de búsqueda, sería nuevamente imposible reconocer el sentido correcto. Para optimizar la precisión de la recuperación, claramente necesitamos modelar al usuario de manera adecuada y personalizar la búsqueda según cada usuario individual. El objetivo principal del modelado de usuario para la recuperación de información es modelar con precisión la necesidad de información de un usuario, lo cual, desafortunadamente, es una tarea muy difícil. De hecho, incluso resulta difícil para un usuario describir con precisión cuál es su necesidad de información. ¿Qué información está disponible para que un sistema pueda inferir la necesidad de información de un usuario? Obviamente, la consulta de los usuarios proporciona la evidencia más directa. De hecho, la mayoría de los sistemas de recuperación existentes se basan únicamente en la consulta para modelar la necesidad de información de los usuarios. Sin embargo, dado que una consulta suele ser extremadamente corta, el modelo de usuario construido basado en una consulta de palabras clave inevitablemente resulta empobrecido. Una forma efectiva de mejorar la modelización de usuarios en la recuperación de información es pedir al usuario que especifique explícitamente qué documentos son relevantes (es decir, útiles para satisfacer su necesidad de información) y luego mejorar la modelización de usuarios basándose en ejemplos de documentos relevantes. Esto se llama retroalimentación de relevancia, lo cual ha demostrado ser bastante efectivo para mejorar la precisión de recuperación [19, 20]. Desafortunadamente, en aplicaciones del mundo real, los usuarios suelen ser reacios a hacer el esfuerzo adicional de proporcionar ejemplos relevantes para retroalimentación [11]. Por lo tanto, es muy interesante estudiar cómo inferir la necesidad de información de un usuario basándose en cualquier información de retroalimentación implícita, la cual existe naturalmente a través de las interacciones del usuario y no requiere ningún esfuerzo adicional por parte del usuario. De hecho, varios estudios previos han demostrado que el modelado implícito del usuario puede mejorar la precisión de recuperación. En [3], se desarrolla un navegador web (Curious Browser) para registrar las calificaciones explícitas de relevancia de las páginas web por parte de los usuarios (retroalimentación de relevancia) y el comportamiento de navegación al ver una página, como el tiempo de permanencia, clics de ratón, movimiento del ratón y desplazamiento (retroalimentación implícita). Se muestra que el tiempo de permanencia en una página, la cantidad de desplazamiento en una página y la combinación de tiempo y desplazamiento tienen una fuerte correlación con las calificaciones de relevancia explícita, lo que sugiere que la retroalimentación implícita puede ser útil para inferir la necesidad de información del usuario. En [10], se recopilan datos de clics de usuario como datos de entrenamiento para aprender una función de recuperación, que se utiliza para producir un ranking personalizado de resultados de búsqueda que se adapte a las preferencias de un grupo de usuarios. En [25], los datos de clics recopilados durante un largo período de tiempo se utilizan a través de la expansión de consultas para mejorar la precisión de recuperación. Si bien un usuario puede tener intereses y preferencias generales a largo plazo para la información, a menudo está buscando documentos para satisfacer una necesidad de información ad-hoc, que solo dura un corto período de tiempo; una vez que se satisface la necesidad de información, el usuario generalmente ya no estaría interesado en esa información. Por ejemplo, un usuario puede estar buscando información sobre autos usados para comprar uno, pero una vez que el usuario ha comprado un auto, generalmente ya no está interesado en esa información. En tales casos, la información de retroalimentación implícita recopilada durante un largo período de tiempo es poco probable que sea muy útil, pero el contexto de búsqueda inmediato y la información de retroalimentación, como cuáles de los resultados de búsqueda para la necesidad de información actual son vistos, se espera que sean mucho más útiles. Considera la consulta de Java nuevamente. Cualquiera de la siguiente información de retroalimentación inmediata sobre el usuario podría potencialmente ayudar a determinar el significado previsto de Java en la consulta: (1) La consulta anterior enviada por el usuario es hashtable (en lugar de, por ejemplo, viajar a Indonesia). (2) En los resultados de búsqueda, el usuario visualizó una página donde palabras como programación, software y applet ocurren muchas veces. Hasta donde sabemos, cómo aprovechar este contexto de búsqueda inmediato y a corto plazo para mejorar la búsqueda aún no ha sido abordado de manera satisfactoria en trabajos anteriores. En este artículo, estudiamos cómo construir y actualizar un modelo de usuario basado en el contexto de búsqueda inmediato y la información de retroalimentación implícita, y utilizar el modelo para mejorar la precisión de la recuperación ad-hoc. Para beneficiar al máximo al usuario de un sistema de recuperación a través de modelado implícito del usuario, proponemos realizar retroalimentación implícita entusiasta. Es decir, tan pronto como observemos cualquier nueva pieza de evidencia del usuario, actualizaríamos la creencia del sistema sobre la necesidad de información del usuario y responderíamos con resultados de recuperación mejorados basados en el modelo de usuario actualizado. Presentamos un marco de trabajo de teoría de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. En un paradigma de recuperación tradicional, el problema de recuperación consiste en emparejar una consulta con documentos y clasificar los documentos según sus valores de relevancia. Como resultado, el proceso de recuperación es un ciclo independiente simple de consulta y visualización de resultados. En el nuevo paradigma de recuperación propuesto, el contexto de búsqueda de los usuarios juega un papel importante y el modelo de usuario implícito inferido se explota inmediatamente para beneficiar al usuario. El nuevo paradigma de recuperación es, por lo tanto, fundamentalmente diferente del paradigma tradicional y es inherentemente más general. Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos apropiados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para reordenar inmediatamente cualquier documento que aún no haya sido visto por el usuario. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente UCAIR (Recuperación de Información Adaptativa Centrada en el Usuario) sobre un motor de búsqueda popular (Google). Los experimentos sobre búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en comparación con Google. Dado que la información implícita que explotamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional. Por lo tanto, el agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin esfuerzo adicional por parte del usuario. Las secciones restantes están organizadas de la siguiente manera. En la Sección 2, discutimos el trabajo relacionado. En la Sección 3, presentamos un marco de recuperación interactiva basado en teoría de decisiones para modelado implícito de usuarios. En la Sección 4, presentamos el diseño e implementación de un agente de búsqueda web inteligente del lado del cliente (UCAIR) que realiza retroalimentación implícita ansiosa. En la Sección 5, informamos nuestros resultados experimentales utilizando el agente de búsqueda. La sección 6 concluye nuestro trabajo. 2. El modelado implícito del usuario para la búsqueda personalizada ha sido estudiado en trabajos anteriores, pero nuestro trabajo difiere de todos los trabajos anteriores en varios aspectos: (1) Enfatizamos la explotación del contexto de búsqueda inmediato, como la consulta inmediatamente anterior relacionada y los documentos vistos en la misma sesión, mientras que la mayoría de los trabajos anteriores se basan en la recopilación a largo plazo de información de retroalimentación implícita [25]. (2) Realizamos una retroalimentación activa y obtenemos el beneficio del modelado implícito del usuario tan pronto como esté disponible cualquier nueva información de retroalimentación implícita, mientras que el trabajo anterior mayormente explota la retroalimentación implícita a largo plazo [10]. (3) Proponemos un marco de recuperación para integrar el modelado implícito del usuario con el proceso interactivo de recuperación, mientras que el trabajo anterior estudia el modelado implícito del usuario por separado de la recuperación [3] o solo estudia modelos de recuperación específicos para explotar la retroalimentación implícita para mejorar la coincidencia de una consulta con documentos [23, 27, 22]. (4) Desarrollamos y evaluamos un agente de búsqueda web personalizado con estudios de usuario en línea, mientras que la mayoría de los trabajos existentes evalúan algoritmos fuera de línea sin interacciones reales de usuarios. Actualmente algunos motores de búsqueda ofrecen personalización rudimentaria, como la búsqueda web personalizada de Google [6], que permite a los usuarios describir explícitamente sus intereses seleccionando entre temas predefinidos, de modo que los resultados que coinciden con sus intereses se muestren en la parte superior, y la búsqueda de My Yahoo! [16], que brinda a los usuarios la opción de guardar los sitios web que les gustan y bloquear aquellos que no les gustan. Por el contrario, UCAIR personaliza la búsqueda web a través de la modelización implícita del usuario sin necesidad de esfuerzos adicionales por parte del usuario. Además, la personalización de UCAIR se proporciona en el lado del cliente. Hay dos ventajas notables en esto. Primero, el usuario no necesita preocuparse por la infracción de privacidad, que es una gran preocupación para la búsqueda personalizada [26]. En segundo lugar, tanto el cálculo de la personalización como el almacenamiento del perfil del usuario se realizan en el lado del cliente para reducir drásticamente la carga del servidor [9]. Ha habido muchos trabajos estudiando los registros de consultas de usuarios [1] o la dinámica de consultas [13]. UCAIR hace uso directo del historial de consultas de un usuario para beneficiar al mismo usuario de inmediato en la misma sesión de búsqueda. UCAIR primero determina si dos consultas vecinas pertenecen a la misma sesión de información y, de ser así, selecciona términos de la consulta anterior para realizar la expansión de la consulta. Nuestro enfoque de expansión de consultas es similar a la expansión automática de consultas [28, 15, 5], pero en lugar de utilizar retroalimentación pseudo para expandir la consulta, utilizamos la información de retroalimentación implícita de los usuarios para expandir la consulta actual. Estas dos técnicas pueden ser combinadas. 3. OPTIMIZACIÓN EN IR INTERACTIVO En IR interactivo, un usuario interactúa con el sistema de recuperación a través de un diálogo de acción, en el cual el sistema responde a cada acción del usuario con alguna acción del sistema. Por ejemplo, la acción de los usuarios puede ser enviar una consulta y la respuesta del sistema puede ser devolver una lista de 10 resúmenes de documentos. En general, el espacio de acciones del usuario y respuestas del sistema y sus granularidades dependerían de la interfaz de un sistema de recuperación particular. En principio, cada acción del usuario puede potencialmente proporcionar nuevas pruebas para ayudar al sistema a inferir mejor la necesidad de información del usuario. Por lo tanto, para responder de manera óptima, el sistema debería utilizar toda la evidencia recopilada hasta ahora sobre el usuario al elegir una respuesta. Cuando se ven de esta manera, la mayoría de los motores de búsqueda existentes son claramente no óptimos. Por ejemplo, si un usuario ha visto algunos documentos en la primera página de resultados de búsqueda, cuando el usuario hace clic en el enlace Siguiente para obtener más resultados, un sistema de recuperación existente seguiría devolviendo la siguiente página de resultados recuperados en función de la consulta original sin considerar la nueva evidencia de que un resultado en particular ha sido visto por el usuario. Proponemos optimizar el rendimiento de la recuperación adaptando las respuestas del sistema en función de cada acción que un usuario haya tomado, y planteamos el problema de optimización como una tarea de decisión. Específicamente, en cualquier momento, el sistema intentaría realizar dos tareas: (1) Actualización del modelo de usuario: Monitorear cualquier evidencia útil del usuario con respecto a su necesidad de información y actualizar el modelo de usuario tan pronto como esta evidencia esté disponible; (2) Mejorar los resultados de búsqueda: Reclasificar inmediatamente todos los documentos que el usuario aún no ha visto, tan pronto como se actualice el modelo de usuario. Enfatizamos la actualización y reordenamiento entusiastas, lo que hace que nuestro trabajo sea bastante diferente a cualquier trabajo existente. A continuación presentamos un marco formal de teoría de decisiones para optimizar el rendimiento de recuperación a través de la modelización implícita del usuario en la recuperación de información interactiva. 3.1 Un marco de teoría de decisiones Sea A el conjunto de todas las acciones del usuario y R(a) el conjunto de todas las posibles respuestas del sistema a una acción del usuario a ∈ A. En cualquier momento, sea At = (a1, ..., at) la secuencia observada de acciones de usuario hasta ahora (hasta el momento t) y Rt−1 = (r1, ..., rt−1) las respuestas que el sistema ha dado en respuesta a las acciones del usuario. El objetivo del sistema es elegir una respuesta óptima rt ∈ R(at) para la acción actual del usuario at. Sea M el espacio de todos los posibles modelos de usuario. Definimos además una función de pérdida L(a, r, m) ∈ , donde a ∈ A es una acción del usuario, r ∈ R(a) es una respuesta del sistema, y m ∈ M es un modelo de usuario. L(a, r, m) codifica nuestras preferencias de decisión y evalúa la optimalidad de responder con r cuando el modelo de usuario actual es m y la acción de usuario actual es a. Según la teoría de decisión bayesiana, la decisión óptima en el tiempo t es elegir una respuesta que minimice el riesgo de Bayes, es decir, r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) donde P(mt|U, D, At, Rt−1) es la probabilidad posterior del modelo de usuario mt dadas todas las observaciones sobre el usuario U que hemos realizado hasta el tiempo t. Para simplificar el cálculo de la Ecuación 1, asumamos que la masa de probabilidad posterior P(mt|U, D, At, Rt−1) está principalmente concentrada en el modo m∗ t = argmaxmt P(mt|U, D, At, Rt−1). Podemos entonces aproximar la integral con el valor de la función de pérdida en m∗ t. Es decir, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) donde m∗ t = argmaxmt P(mt|U, D, At, Rt−1). Dejando de lado cómo definir y estimar estos modelos probabilísticos y la función de pérdida, podemos ver que tal formulación de la teoría de decisiones sugiere que, para elegir la respuesta óptima a at, el sistema debería realizar dos tareas: (1) calcular el modelo de usuario actual y obtener m∗ t basado en toda la información útil. (2) elegir una respuesta rt para minimizar el valor de la función de pérdida L(at, rt, m∗ t). Cuando at no afecta nuestra creencia sobre m∗ t , el primer paso puede omitirse y podemos reutilizar m∗ t−1 para m∗ t . Ten en cuenta que nuestro marco de trabajo es bastante general, ya que potencialmente podemos modelar cualquier tipo de acciones de usuario y respuestas del sistema. En la mayoría de los casos, como podríamos esperar, la respuesta del sistema es algún tipo de clasificación de documentos, es decir, para la mayoría de las acciones a, R(a) consiste en todas las posibles clasificaciones de los documentos no vistos, y el problema de decisión se reduce a elegir la mejor clasificación de los documentos no vistos basándose en el modelo de usuario más actualizado. Cuando a es la acción de enviar una consulta de palabras clave, tal respuesta es exactamente lo que haría un sistema de recuperación actual. Sin embargo, fácilmente podemos imaginar que un motor de búsqueda web más inteligente respondería al clic del usuario en el enlace Siguiente (para obtener más resultados no vistos) con una clasificación más optimizada de documentos basada en cualquier documento visto en la página actual de resultados. De hecho, según nuestra estrategia de actualización entusiasta, incluso podríamos permitir que un sistema responda al clic del botón Atrás del navegador por parte de un usuario después de ver un documento de la misma manera, para que el usuario pueda beneficiarse al máximo de la retroalimentación implícita. Estos son precisamente lo que nuestro sistema UCAIR hace. 3.2 Modelos de usuario Un modelo de usuario m ∈ M representa lo que sabemos sobre el usuario U, por lo que en principio, puede contener cualquier información sobre el usuario que deseemos modelar. Ahora discutimos dos componentes importantes en un modelo de usuario. El primer componente es un modelo de componente de la necesidad de información de los usuarios. Presumiblemente, el factor más importante que afecta la optimalidad de la respuesta del sistema es qué tan bien la respuesta aborda la necesidad de información de los usuarios. De hecho, en cualquier momento, podemos asumir que el sistema tiene alguna creencia sobre lo que le interesa al usuario, la cual modelamos a través de un vector de términos x = (x1, ..., x|V|), donde V = {w1, ..., w|V|} es el conjunto de todos los términos (es decir, vocabulario) y xi es el peso del término wi. Un vector de términos de este tipo se utiliza comúnmente en la recuperación de información para representar tanto consultas como documentos. Por ejemplo, el modelo de espacio vectorial asume que tanto la consulta como los documentos se representan como vectores de términos y que la puntuación de un documento con respecto a una consulta se calcula en función de la similitud entre el vector de la consulta y el vector del documento [21]. En un enfoque de modelado de lenguaje, también podemos considerar el modelo de lenguaje unigrama de consulta [12, 29] o el modelo de relevancia [14] como una representación vectorial de términos de la necesidad de información de los usuarios. Intuitivamente, x asignaría pesos altos a los términos que caracterizan los temas que interesan al usuario. El segundo componente que podemos incluir en nuestro modelo de usuario son los documentos que el usuario ya ha visto. Obviamente, incluso si un documento es relevante, si el usuario ya ha visto el documento, no sería útil presentar el mismo documento de nuevo. Por lo tanto, introducimos otra variable S ⊂ D (D es el conjunto completo de documentos en la colección) para denotar el subconjunto de documentos en los resultados de búsqueda que el usuario ya ha visto. En general, en el tiempo t, podemos representar un modelo de usuario como mt = (S, x, At, Rt−1), donde S son los documentos vistos, x es la comprensión del sistema de la necesidad de información del usuario, y (At, Rt−1) representa el historial de interacción del usuario. Ten en cuenta que un modelo de usuario aún más general también puede incluir otros factores como el nivel de lectura y la ocupación de los usuarios. Si asumimos que la incertidumbre de un modelo de usuario mt se debe únicamente a la incertidumbre de x, el cálculo de nuestra estimación actual del modelo de usuario m∗ t implicará principalmente calcular nuestra mejor estimación de x. Es decir, el sistema elegiría una respuesta de acuerdo a r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) donde x∗ = argmaxx P(x|U, D, At, Rt−1). Este es el mecanismo de decisión implementado en el sistema UCAIR que se describirá más adelante. En este sistema, evitamos especificar el modelo probabilístico P(x|U, D, At, Rt−1) calculando x∗ directamente con algún método de retroalimentación existente. 3.3 Funciones de pérdida La definición exacta de la función de pérdida L depende de las respuestas, por lo que es inevitablemente específica de la aplicación. Ahora discutimos brevemente algunas posibilidades cuando la respuesta es clasificar todos los documentos no vistos y presentar los mejores k de ellos. Sea r = (d1, ..., dk) los k documentos principales, S el conjunto de documentos vistos por el usuario, y x∗ la mejor suposición del sistema sobre la necesidad de información del usuario. Podemos definir simplemente la pérdida asociada con r como la suma negativa de la probabilidad de que cada uno de los di sea relevante, es decir, L(a, r, m) = − k i=1 P(relevante|di, m). Claramente, para minimizar esta función de pérdida, la respuesta óptima r contendría los k documentos con la probabilidad más alta de relevancia, lo cual es intuitivamente razonable. Una deficiencia de esta función de pérdida top-k es que no es sensible al orden interno de los documentos top k seleccionados, por lo que cambiar el orden de clasificación de un documento no relevante y uno relevante no afectaría la pérdida, lo cual es irrazonable. Para modelar el ranking, podemos introducir un factor del modelo de usuario: la probabilidad de que cada uno de los k documentos sea visto por el usuario, P(vista|di), y definir la siguiente función de pérdida de ranking: L(a, r, m) = − k i=1 P(vista|di)P(relevante|di, m). Dado que, en general, si di está clasificado por encima de dj (es decir, i < j), P(vista|di) > P(vista|dj), esta función de pérdida favorecería una decisión de clasificar documentos relevantes por encima de los no relevantes, ya que de lo contrario, siempre podríamos intercambiar di con dj para reducir el valor de pérdida. Por lo tanto, el sistema simplemente debería realizar una recuperación regular y clasificar los documentos según la probabilidad de relevancia [18]. Dependiendo de las preferencias de recuperación de los usuarios, puede haber muchas otras posibilidades. Por ejemplo, si el usuario no desea ver documentos redundantes, la función de pérdida debería incluir alguna medida de redundancia en r basada en los documentos ya vistos S. Por supuesto, cuando la respuesta no es elegir una lista clasificada de documentos, necesitaríamos una función de pérdida diferente. Discutimos un ejemplo relevante para el agente de búsqueda que implementamos. Cuando un usuario ingresa una consulta qt (acción actual), nuestro agente de búsqueda se basa en algún motor de búsqueda existente para llevar a cabo la búsqueda en realidad. En tal caso, aunque el agente de búsqueda no tenga control sobre el algoritmo de recuperación, aún puede intentar optimizar los resultados de la búsqueda refinando la consulta enviada al motor de búsqueda y/o reordenando los resultados obtenidos del motor de búsqueda. Las funciones de pérdida para el reordenamiento ya fueron discutidas anteriormente; ahora echamos un vistazo a las funciones de pérdida para el refinamiento de consultas. Sea f la función de recuperación del motor de búsqueda que nuestro agente utiliza, de modo que f(q) nos daría los resultados de búsqueda utilizando la consulta q. Dado que la acción actual del usuario es ingresar una consulta qt (es decir, at = qt), nuestra respuesta sería f(q) para algún q. Dado que no tenemos elección de f, nuestra decisión es elegir un buen q. Formalmente, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) lo cual muestra que nuestro objetivo es encontrar q∗ = argminqL(qt, f(q), m), es decir, una consulta óptima que nos daría el mejor f(q). Una elección diferente de la función de pérdida L(qt, f(q), m) llevaría a una estrategia de refinamiento de consulta diferente. En UCAIR, calculamos heurísticamente q∗ expandiendo qt con términos extraídos de rt−1 siempre que qt−1 y qt tengan una alta similitud. Se debe tener en cuenta que rt−1 y qt−1 están contenidos en m como parte del historial de interacción de los usuarios. 3.4 Modelado implícito del usuario El modelado implícito del usuario se captura en nuestro marco a través del cálculo de x∗ = argmaxx P(x|U, D, At, Rt−1), es decir, la creencia actual del sistema sobre cuál es la necesidad de información del usuario. Aquí nuevamente puede haber muchas posibilidades, lo que lleva a diferentes algoritmos para la modelización implícita del usuario. Ahora discutimos algunos de ellos. Primero, cuando dos consultas consecutivas están relacionadas, la consulta anterior puede ser explotada para enriquecer la consulta actual y proporcionar más contexto de búsqueda para ayudar en la desambiguación. Para este propósito, en lugar de realizar una expansión de consulta como lo hicimos en la sección anterior, también podríamos calcular un x∗ actualizado basado en la consulta anterior y los resultados de recuperación. El modelo de usuario nuevo calculado puede luego ser utilizado para clasificar los documentos con un modelo estándar de recuperación de información. Segundo, también podemos inferir los intereses de un usuario basándonos en los resúmenes de los documentos visualizados. Cuando a un usuario se le presenta una lista de resúmenes de documentos mejor clasificados, si el usuario elige saltarse los primeros n documentos y ver el documento (n+1)-ésimo, podemos inferir que el usuario no está interesado en los resúmenes mostrados para los primeros n documentos, pero está atraído por el resumen mostrado del documento (n+1)-ésimo. Por lo tanto, podemos usar estos resúmenes como ejemplos negativos y positivos para aprender un modelo de usuario más preciso x∗. Aquí se pueden explotar muchas técnicas estándar de retroalimentación de relevancia [19, 20]. Ten en cuenta que debemos utilizar los resúmenes mostrados, en lugar de los contenidos reales de esos documentos, ya que es posible que el resumen mostrado del documento visto sea relevante, pero el contenido del documento en realidad no lo sea. Del mismo modo, un resumen mostrado puede llevar a un usuario a omitir un documento relevante. Inferir modelos de usuario basados en dicha información mostrada, en lugar del contenido real de un documento, es una diferencia importante entre UCAIR y algunos otros sistemas similares. En UCAIR, ambas estrategias para inferir un modelo de usuario implícito están implementadas. 4. UCAIR: Un agente de búsqueda personalizado 4.1 Diseño En esta sección, presentamos un agente de búsqueda web del lado del cliente llamado UCAIR, en el cual implementamos algunos de los métodos discutidos en la sección anterior para realizar búsquedas personalizadas a través de modelado implícito del usuario. UCAIR es un complemento del navegador web que actúa como proxy para los motores de búsqueda en la web. Actualmente, solo está implementado para Internet Explorer y Google, pero es cuestión de ingeniería hacer que funcione en otros navegadores web e interactúe con otros motores de búsqueda. El tema de la privacidad es un obstáculo principal para implementar cualquier aplicación del mundo real que involucre modelado de usuarios serio, como la búsqueda personalizada. Por esta razón, UCAIR funciona estrictamente como un agente de búsqueda del lado del cliente, en lugar de ser una aplicación del lado del servidor. De esta manera, la información del usuario capturada siempre permanece en la computadora que está utilizando el usuario, por lo tanto, el usuario no necesita revelar ninguna información al exterior. La personalización del lado del cliente también permite que el sistema observe fácilmente una gran cantidad de información del usuario que puede no estar fácilmente disponible para un servidor. Además, realizar búsquedas personalizadas en el lado del cliente es más escalable que en el lado del servidor, ya que la sobrecarga de cálculo y almacenamiento se distribuye entre los clientes. Como se muestra en la Figura 1, la barra de herramientas UCAIR tiene 3 componentes principales: (1) El módulo de modelado de usuario (implícito) captura el contexto de búsqueda de un usuario e información de historial, incluidas las consultas enviadas y los resultados de búsqueda clicados, e infiere los límites de la sesión de búsqueda. (2) El módulo de modificación de consultas mejora selectivamente la formulación de la consulta de acuerdo con el modelo de usuario actual. (3) El módulo de reordenamiento de resultados reordena inmediatamente cualquier resultado de búsqueda no visto cada vez que se actualiza el modelo de usuario. En UCAIR, consideramos cuatro acciones básicas de usuario: (1) enviar una consulta de palabras clave; (2) ver un documento; (3) hacer clic en el botón Atrás; (4) hacer clic en el enlace Siguiente en una página de resultados. Para cada una de estas cuatro acciones, el sistema responde con, respectivamente, (1) 1 UCAIR está disponible en: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Registro de Historial de Búsqueda del Motor de Búsqueda (por ejemplo, Google) (consultas pasadas, resultados clicados) Modificación de Consulta Resultado de Reclasificación Modelo de Usuario Buffer de Resultados de Consulta de Usuario UCAIR... Figura 1: arquitectura de UCAIR generando una lista clasificada de resultados enviando una consulta posiblemente ampliada a un motor de búsqueda; (2) actualizando el modelo de necesidad de información x; (3) reordenando los resultados no vistos en la página de resultados actual basándose en el modelo actual x; y (4) reordenando las páginas no vistas y generando la siguiente página de resultados basándose en el modelo actual x. Detrás de estas respuestas, hay tres tareas básicas: (1) Decidir si la consulta anterior está relacionada con la consulta actual y, de ser así, ampliar la consulta actual con términos útiles de la consulta anterior o los resultados de la consulta anterior. (2) Actualizar el modelo de necesidad de información x basado en un resumen de documento recién seleccionado. (3) Reordenar un conjunto de documentos no vistos basado en el modelo x actual. A continuación describimos nuestros algoritmos para cada uno de ellos. 4.2 Detección de límites de sesión y expansión de consultas Para explotar eficazmente las consultas anteriores y su información correspondiente de clics, UCAIR necesita determinar si dos consultas adyacentes pertenecen a la misma sesión de búsqueda (es decir, detectar los límites de sesión). El trabajo existente sobre la detección de límites de sesión se encuentra principalmente en el contexto del análisis de registros web (por ejemplo, [8]), y utiliza información estadística en lugar de características textuales. Dado que nuestro agente del lado del cliente no tiene acceso a los registros de consultas del servidor, tomamos decisiones sobre los límites de sesión basadas en la similitud textual entre dos consultas. Debido a que las consultas relacionadas no necesariamente comparten las mismas palabras (por ejemplo, isla de Java y viajar a Indonesia), no es suficiente utilizar solo el texto de la consulta. Por lo tanto, utilizamos los resultados de búsqueda de las dos consultas para ayudar a decidir si están relacionadas temáticamente. Por ejemplo, para las consultas anteriores \"java island\" y \"travel Indonesia\", las palabras \"java\", \"bali\", \"island\", \"indonesia\" y \"travel\" pueden aparecer con frecuencia en los resultados de búsqueda de ambas consultas, lo que produce un alto puntaje de similitud. Solo utilizamos los títulos y resúmenes de los resultados de búsqueda para calcular la similitud, ya que están disponibles en la página de resultados de búsqueda recuperada y obtener el texto completo de cada página de resultados ralentizaría significativamente el proceso. Para compensar la concisión de los títulos y resúmenes, recuperamos más resultados de los que un usuario normalmente vería con el propósito de detectar los límites de sesión (típicamente 50 resultados). La similitud entre la consulta anterior q y la consulta actual q se calcula de la siguiente manera. Sean {s1, s2, . . . , sn} y {s1, s2, . . . , sn} los conjuntos de resultados de las dos consultas. Utilizamos la fórmula de ponderación TF-IDF normalizada pivotada [24] para calcular un vector de peso de término si para cada resultado si. Definimos el resultado promedio savg como el centroide de todos los vectores de resultado, es decir, (s1 + s2 + . . . + sn)/n. La similitud del coseno entre los dos resultados promedio se calcula como s avg · savg/ s 2 avg · s2 avg. Si el valor de similitud supera un umbral predefinido, se considerará que las dos consultas están en la misma sesión de información. Si se determina que la consulta anterior y la consulta actual pertenecen a la misma sesión de búsqueda, UCAIR intentaría expandir la consulta actual con términos de la consulta anterior y sus resultados de búsqueda. Específicamente, para cada término en la consulta anterior o los resultados de búsqueda correspondientes, si su frecuencia en los resultados de la consulta actual es mayor que un umbral preestablecido (por ejemplo, 5 resultados de 50), el término se agregaría a la consulta actual para formar una consulta ampliada. En este caso, UCAIR enviaría esta consulta ampliada en lugar de la original al motor de búsqueda y devolvería los resultados correspondientes a la consulta ampliada. Actualmente, UCAIR solo utiliza la consulta inmediatamente anterior para la expansión de consultas; en principio, podríamos aprovechar todas las consultas pasadas relacionadas. 4.3 Actualización del modelo de necesidad de información Supongamos que en el tiempo t, hemos observado que el usuario ha visto k documentos cuyos resúmenes son s1, ..., sk. Actualizamos nuestro modelo de usuario calculando un nuevo vector de necesidad de información con un método estándar de retroalimentación en la recuperación de información (es decir, Rocchio [19]). Según el modelo de recuperación de espacio vectorial, cada resumen clicado si puede ser representado por un vector de pesos de términos si, con cada término ponderado por una fórmula de ponderación TF-IDF [21]. Rocchio calcula el vector centroide de todos los resúmenes e interpola este con el vector de consulta original para obtener un vector de términos actualizado. Es decir, x = αq + (1 − α) 1 k k i=1 si donde q es el vector de consulta, k es el número de resúmenes que el usuario hace clic inmediatamente después de la consulta actual y α es un parámetro que controla la influencia de los resúmenes clicados en el modelo de necesidad de información inferida. En nuestros experimentos, α se establece en 0.5. Ten en cuenta que actualizamos el modelo de información necesario cada vez que el usuario ve un documento. 4.4 Reclasificación de resultados En general, queremos volver a clasificar todos los resultados no vistos tan pronto como se actualice el modelo de usuario. Actualmente, UCAIR implementa el reordenamiento en dos casos, correspondientes a cuando el usuario hace clic en el botón Atrás y en el enlace Siguiente en Internet Explorer. En ambos casos, el modelo de usuario actualizado se utilizaría para reordenar los resultados no vistos de manera que el usuario vea resultados de búsqueda mejorados de inmediato. Para volver a clasificar cualquier resumen de documento no visto, UCAIR utiliza el modelo estándar de recuperación de espacio vectorial y puntúa cada resumen en función de la similitud del resultado y el vector de necesidad de información actual del usuario x [21]. Dado que la retroalimentación implícita no es completamente confiable, presentamos solo un pequeño número (por ejemplo, 5) de los resultados reordenados más altos para ser seguidos por cualquier resultado originalmente clasificado alto. 828 resultados de Google (consulta del usuario = mapa de Java) Resultados de UCAIR (consulta del usuario = mapa de Java) consulta anterior = viajar a Indonesia consulta anterior = tabla hash consulta del usuario ampliada = mapa de Java Indonesia consulta del usuario ampliada = clase de mapa de Java 1 Proyecciones de mapas de Java del mundo ... Lonely Planet - Mapa de Indonesia Mapa (Plataforma Java SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Proyecciones de mapas de Java del mundo ... TURISMO DE INDONESIA: JAVA CENTRAL - MAPA Plataforma Java SE v1.3.1: Interfaz de Mapa www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Mapa de Java TURISMO DE INDONESIA: JAVA OESTE - MAPA Una introducción a las clases de colección de mapas de Java java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Mapa de Tecnología Java IndoStreets - Mapa de Java Una introducción a las clases de colección de mapas de Java java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Regiones e islas de Indonesia Mapas, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 Una introducción a las clases de colección de mapas de Java Mapa de calles de la ciudad de Indonesia,... Hibernate simplifica el mapeo de herencia www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Mapa de Java Mapas de Indonesia jerarquía de clases de tmap 30.map www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Mapa de API de Java Mapas de Indonesia por Peter Loud Alcance de clases www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas: Mapas de Sam de Indonesia por Peter Loud PrintSafeHashMap de la clase www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 TURISMO DE INDONESIA: JAVA OESTE - MAPA indonesiaphoto.com Java Pro - Unión y mapeo vertical de clases www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Tabla 1: Resultados de muestra de la expansión de la consulta EVALUACIÓN DE UCAIR Ahora presentamos algunos resultados sobre la evaluación de las dos principales funciones de UCAIR: la expansión selectiva de consultas y la reordenación de resultados basada en los datos de clics de los usuarios. 5.1 Resultados de muestra La estrategia de expansión de consultas implementada en UCAIR es intencionalmente conservadora para evitar la interpretación errónea de los modelos implícitos de los usuarios. En la práctica, cada vez que decide expandir la consulta, la expansión suele tener sentido. En la Tabla 1, mostramos cómo UCAIR puede distinguir exitosamente dos contextos de búsqueda diferentes para la consulta java map, correspondientes a dos consultas previas distintas (es decir, viajar a Indonesia vs. hashtable). Debido a la modelización implícita del usuario, UCAIR descubre inteligentemente agregar Indonesia y clase, respectivamente, a la consulta de los usuarios sobre el mapa de Java, lo cual de otro modo sería ambiguo, como se muestra en los resultados originales de Google el 21 de marzo de 2005. Los resultados de UCAIR son mucho más precisos que los resultados de Google y reflejan la personalización en la búsqueda. El componente de retroalimentación implícita entusiasta está diseñado para responder inmediatamente a la actividad de un usuario, como por ejemplo, al visualizar un documento. En la Figura 2, mostramos cómo UCAIR puede desambiguar con éxito una consulta ambigua de jaguar al explotar un resumen del documento visualizado. En este caso, los resultados iniciales de recuperación utilizando \"jaguar\" (mostrados en el lado izquierdo) contienen dos resultados sobre los autos Jaguar seguidos por dos resultados sobre el software Jaguar. Sin embargo, después de que el usuario ve el contenido de la página web del segundo resultado (sobre el automóvil Jaguar) y regresa a la página de resultados de búsqueda haciendo clic en el botón Atrás, UCAIR automáticamente selecciona dos nuevos resultados de búsqueda sobre automóviles Jaguar (mostrados en el lado derecho), mientras que los dos resultados originales sobre software de Jaguar se desplazan hacia abajo en la lista (no se ven en la imagen). 5.2 Evaluación cuantitativa Para evaluar UCAIR de manera cuantitativa, realizamos un estudio de usuario sobre la efectividad del componente de retroalimentación implícita ansiosa. Es un desafío evaluar cuantitativamente la mejora potencial en el rendimiento de nuestro modelo propuesto y UCAIR sobre Google de manera imparcial [7]. Aquí diseñamos un estudio de usuarios, en el cual los participantes realizarían una búsqueda web normal y evaluarían al azar y de forma anónima un conjunto de resultados mezclados de Google y UCAIR al final de la sesión de búsqueda; los participantes no saben si un resultado proviene de Google o de UCAIR. Reclutamos a 6 estudiantes de posgrado para este estudio de usuarios, quienes tienen diferentes antecedentes (3 en informática, 2 en biología y 1 en química). Los documentos que describen leyes para limitar el correo no deseado sin dar detalles de demandas judiciales o juicios penales no son relevantes. Utilizamos los temas de consulta de la pista Terabyte TREC 2 2004 [2] y la tarea de destilación de temas de la pista web TREC 2003 [4] de la manera que se describirá a continuación. Un ejemplo de tema del TREC 2004 Terabyte track aparece en la Figura 3. El título es una frase corta y puede ser utilizada como una consulta al sistema de recuperación. El campo de descripción proporciona una declaración ligeramente más larga del requisito del tema, generalmente expresado como una sola oración completa o pregunta. Finalmente, la narrativa proporciona información adicional necesaria para especificar completamente el requisito, expresado en forma de un breve párrafo. Inicialmente, cada participante exploraría 50 temas ya sea de la categoría Terabyte o de la categoría Web y elegiría los 5 o 7 temas más interesantes. Para cada tema seleccionado, el participante básicamente realizaría la búsqueda web normal utilizando UCAIR para encontrar muchas páginas web relevantes utilizando el título del tema de la consulta como la palabra clave inicial de la consulta. Durante este proceso, el participante puede ver los resultados de la búsqueda y posiblemente hacer clic en algunos interesantes para ver las páginas web, tal como en una búsqueda web normal. No hay ningún requisito o restricción sobre cuántas consultas debe enviar el participante o cuándo debe detener la búsqueda de un tema. Cuando el participante planea cambiar el tema de búsqueda, simplemente presionará un botón 2 de la Conferencia de Recuperación de Texto: http://trec.nist.gov/ 829 Figura 2: Capturas de pantalla para volver a clasificar los resultados y evaluar los resultados de búsqueda antes de cambiar al siguiente tema. En el momento de la evaluación, los 30 resultados mejor clasificados de Google y UCAIR (algunos se superponen) se mezclan aleatoriamente para que el participante no sepa si un resultado proviene de Google o de UCAIR. El participante luego juzgaría la relevancia de estos resultados. Medimos la precisión en los primeros n (n = 5, 10, 20, 30) documentos de Google y UCAIR. También evaluamos precisiones en diferentes niveles de recuperación. En total, 368 documentos fueron considerados relevantes a partir de los resultados de búsqueda de Google y 429 documentos fueron considerados relevantes por los participantes de UCAIR. Los diagramas de dispersión de precisión en los 10 y 20 documentos principales se muestran en la Figura 4 y la Figura 5 respectivamente (El diagrama de dispersión de precisión en los 30 documentos principales es muy similar al de los 20 documentos principales). Cada punto de los gráficos de dispersión representa las precisiones de Google y UCAIR en un tema de consulta. La Tabla 2 muestra la precisión promedio en los primeros n documentos entre 32 temas. A partir de la Figura 4, la Figura 5 y la Tabla 2, vemos que los resultados de búsqueda de UCAIR son consistentemente mejores que los de Google en todas las medidas. Además, la mejora en el rendimiento es más dramática para la precisión en los primeros 20 documentos que para la precisión en los primeros 10 documentos. Una explicación para esto es que cuanto más interacción tenga el usuario con el sistema, más datos de clics se espera que UCAIR pueda recopilar. Por lo tanto, el sistema de recuperación puede construir modelos de usuario implícitos más precisos, lo que conduce a una mayor precisión en la recuperación. El Método de Clasificación prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Mejora 8.0% 17.8% 20.2% 21.8% Tabla 2: Tabla de precisión promedio en los primeros n documentos para 32 temas de consulta El gráfico en la Figura 6 muestra las curvas de precisión-recuperación para UCAIR y Google, donde se observa claramente que el rendimiento de UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Gráfico de dispersión de Precisión en los 10 primeros documentos Figura 4: La precisión en los 10 primeros documentos de UCAIR y Google es consistentemente y considerablemente mejor que la de Google en todos los niveles de recuperación. 6. CONCLUSIONES En este artículo, estudiamos cómo aprovechar la modelización implícita del usuario para personalizar de manera inteligente la recuperación de información y mejorar la precisión de la búsqueda. A diferencia de la mayoría de trabajos anteriores, enfatizamos el uso del contexto de búsqueda inmediata y la información de retroalimentación implícita, así como la actualización rápida de los resultados de búsqueda para beneficiar al máximo a un usuario. Presentamos un marco de trabajo de toma de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos adecuados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para volver a clasificar inmediatamente cualquier documento que aún no haya sido visto por el usuario. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente (UCAIR) sobre un motor de búsqueda popular (Google). Los experimentos en la búsqueda web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en más de un 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Gráfico de dispersión de Precisión en los 20 documentos principales Figura 5: Precisión en los 20 documentos principales de UCAIR y Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 precisión recall Curvas de Precisión-Recall Resultado de Google Resultado de UCAIR Figura 6: Precisión en los 20 resultados principales de UCAIR y Google Google. Dado que la información implícita que aprovechamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional. El agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin necesidad de esfuerzo adicional por parte del usuario. AGRADECIMIENTO Agradecemos a los seis participantes de nuestros experimentos de evaluación. Este trabajo fue apoyado en parte por las subvenciones de la Fundación Nacional de Ciencias IIS-0347933 e IIS-0428472. REFERENCIAS [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman y O. Frieder. Análisis por hora de un registro de consultas web muy grande categorizado por tema. En Actas de SIGIR 2004, páginas 321-328, 2004. [2] C. Clarke, N. Craswell e I. Soboroff. Resumen de la pista de terabyte TREC 2004. En Actas de TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda y D. Brown. Indicadores implícitos de interés. En Actas de Interfaces de Usuario Inteligentes 2001, páginas 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson y M. Wu. Resumen de la pista web TREC 2003. En Actas de TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend y V. Larvrenko. Retroalimentación de relevancia y personalización: Una perspectiva de modelado del lenguaje. En Actas del Segundo Taller DELOS: Personalización y Sistemas de Recomendación en Bibliotecas Digitales, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite y D. Harman. Resultados y desafíos en la evaluación de búsqueda en la web. Redes de Computadoras, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A. An, y D. Schuurmans. Identificación dinámica de sesiones de registro web con modelos de lenguaje estadístico. Revista de la Sociedad Americana de Ciencia de la Información y Tecnología, 55(14):1290-1303, 2004. [9] G. Jeh y J. Widom. Escalando la búsqueda web personalizada. En Actas de WWW 2003, páginas 271-279, 2003. [10] T. Joachims. Optimización de motores de búsqueda utilizando datos de clics. En Actas de SIGKDD 2002, páginas 133-142, 2002. [11] D. Kelly y J. Teevan. Retroalimentación implícita para inferir preferencias de usuario: Una bibliografía. SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En Actas de SIGIR01, páginas 111-119, 2001. [13] T. Lau y E. Horvitz. Patrones de búsqueda: Análisis y modelado de la refinación de consultas web. En Actas de la Séptima Conferencia Internacional sobre Modelado de Usuarios (UM), páginas 145-152, 1999. [14] V. Lavrenko y B. Croft. Modelos de lenguaje basados en relevancia. En Actas de SIGIR01, páginas 120-127, 2001. [15] M. Mitra, A. Singhal y C. Buckley. Mejorando la expansión automática de consultas. En Actas de SIGIR 1998, páginas 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg. Según Google, así va la nación. New York Times, mayo de 2003. [18] S. E. Robertson. El principio de clasificación de probabilidad en ı˚. Revista de Documentación, 33(4):294-304, 1977. [19] J. J. Rocchio. Retroalimentación de relevancia en la recuperación de información. En el Sistema de Recuperación SMART: Experimentos en el Procesamiento Automático de Documentos, páginas 313-323. Prentice-Hall Inc., 1971. [20] G. Salton y C. Buckley. Mejorando el rendimiento de recuperación mediante retroalimentación de recuperación. Revista de la Sociedad Americana de Ciencia de la Información, 41(4):288-297, 1990. [21] G. Salton y M. J. McGill. Introducción a la Recuperación de Información Moderna. McGraw-Hill, 1983. [22] X. Shen, B. Tan y C. Zhai. Recuperación de información sensible al contexto utilizando retroalimentación implícita. En Actas de SIGIR 2005, páginas 43-50, 2005. [23] X. Shen y C. Zhai. Explotando el historial de consultas para la clasificación de documentos en la recuperación de información interactiva (Póster). En Actas de SIGIR 2003, páginas 377-378, 2003. [24] A. Singhal. Recuperación de información moderna: Una breve visión general. Boletín del Comité Técnico de Ingeniería de Datos de la Sociedad de Computación de IEEE, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano y M. Yoshikawa. Búsqueda web adaptativa basada en el perfil del usuario construido sin ningún esfuerzo por parte de los usuarios. En Actas de WWW 2004, páginas 675-684, 2004. [26] E. Volokh. Personalización y privacidad. Comunicaciones de la ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen e I. Ruthven. Un estudio simulado de modelos de retroalimentación implícita. En Actas de ECIR 2004, páginas 311-326, 2004. [28] J. Xu y W. B. Croft. Expansión de consultas utilizando análisis local y global de documentos. En Actas de SIGIR 1996, páginas 4-11, 1996. [29] C. Zhai y J. Lafferty. Modelo de retroalimentación basado en el modelo de recuperación de divergencia de KL. En Actas de la CIKM 2001, páginas 403-410, 2001. 831 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "user-centered adaptive information retrieval": {
            "translated_key": "Recuperación de Información Adaptativa Centrada en el Usuario",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Implicit User Modeling for Personalized Search Xuehua Shen, Bin Tan, ChengXiang Zhai Department of Computer Science University of Illinois at Urbana-Champaign ABSTRACT Information retrieval systems (e.g., web search engines) are critical for overcoming information overload.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users, resulting in inherently non-optimal retrieval performance.",
                "For example, a tourist and a programmer may use the same word java to search for different information, but the current search systems would return the same results.",
                "In this paper, we study how to infer a users interest from the users search context and use the inferred implicit user model for personalized search .",
                "We present a decision theoretic framework and develop techniques for implicit user modeling in information retrieval.",
                "We develop an intelligent client-side web search agent (UCAIR) that can perform eager implicit feedback, e.g., query expansion based on previous queries and immediate result reranking based on clickthrough information.",
                "Experiments on web search show that our search agent can improve search accuracy over the popular Google search engine.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models, Relevance feedback, Search Process General Terms Algorithms 1.",
                "INTRODUCTION Although many information retrieval systems (e.g., web search engines and digital library systems) have been successfully deployed, the current retrieval systems are far from optimal.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users [17].",
                "This inherent non-optimality is seen clearly in the following two cases: (1) Different users may use exactly the same query (e.g., Java) to search for different information (e.g., the Java island in Indonesia or the Java programming language), but existing IR systems return the same results for these users.",
                "Without considering the actual user, it is impossible to know which sense Java refers to in a query. (2) A users information needs may change over time.",
                "The same user may use Java sometimes to mean the Java island in Indonesia and some other times to mean the programming language.",
                "Without recognizing the search context, it would be again impossible to recognize the correct sense.",
                "In order to optimize retrieval accuracy, we clearly need to model the user appropriately and personalize search according to each individual user.",
                "The major goal of user modeling for information retrieval is to accurately model a users information need, which is, unfortunately, a very difficult task.",
                "Indeed, it is even hard for a user to precisely describe what his/her information need is.",
                "What information is available for a system to infer a users information need?",
                "Obviously, the users query provides the most direct evidence.",
                "Indeed, most existing retrieval systems rely solely on the query to model a users information need.",
                "However, since a query is often extremely short, the user model constructed based on a keyword query is inevitably impoverished .",
                "An effective way to improve user modeling in information retrieval is to ask the user to explicitly specify which documents are relevant (i.e., useful for satisfying his/her information need), and then to improve user modeling based on such examples of relevant documents.",
                "This is called relevance feedback, which has been proved to be quite effective for improving retrieval accuracy [19, 20].",
                "Unfortunately, in real world applications, users are usually reluctant to make the extra effort to provide relevant examples for feedback [11].",
                "It is thus very interesting to study how to infer a users information need based on any implicit feedback information, which naturally exists through user interactions and thus does not require any extra user effort.",
                "Indeed, several previous studies have shown that implicit user modeling can improve retrieval accuracy.",
                "In [3], a web browser (Curious Browser) is developed to record a users explicit relevance ratings of web pages (relevance feedback) and browsing behavior when viewing a page, such as dwelling time, mouse click, mouse movement and scrolling (implicit feedback).",
                "It is shown that the dwelling time on a page, amount of scrolling on a page and the combination of time and scrolling have a strong correlation with explicit relevance ratings, which suggests that implicit feedback may be helpful for inferring user information need.",
                "In [10], user clickthrough data is collected as training data to learn a retrieval function, which is used to produce a customized ranking of search results that suits a group of users preferences.",
                "In [25], the clickthrough data collected over a long time period is exploited through query expansion to improve retrieval accuracy. 824 While a user may have general long term interests and preferences for information, often he/she is searching for documents to satisfy an ad-hoc information need, which only lasts for a short period of time; once the information need is satisfied, the user would generally no longer be interested in such information.",
                "For example, a user may be looking for information about used cars in order to buy one, but once the user has bought a car, he/she is generally no longer interested in such information.",
                "In such cases, implicit feedback information collected over a long period of time is unlikely to be very useful, but the immediate search context and feedback information, such as which of the search results for the current information need are viewed, can be expected to be much more useful.",
                "Consider the query Java again.",
                "Any of the following immediate feedback information about the user could potentially help determine the intended meaning of Java in the query: (1) The previous query submitted by the user is hashtable (as opposed to, e.g., travel Indonesia). (2) In the search results, the user viewed a page where words such as programming, software, and applet occur many times.",
                "To the best of our knowledge, how to exploit such immediate and short-term search context to improve search has so far not been well addressed in the previous work.",
                "In this paper, we study how to construct and update a user model based on the immediate search context and implicit feedback information and use the model to improve the accuracy of ad-hoc retrieval.",
                "In order to maximally benefit the user of a retrieval system through implicit user modeling, we propose to perform eager implicit feedback.",
                "That is, as soon as we observe any new piece of evidence from the user, we would update the systems belief about the users information need and respond with improved retrieval results based on the updated user model.",
                "We present a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "In a traditional retrieval paradigm, the retrieval problem is to match a query with documents and rank documents according to their relevance values.",
                "As a result, the retrieval process is a simple independent cycle of query and result display.",
                "In the proposed new retrieval paradigm, the users search context plays an important role and the inferred implicit user model is exploited immediately to benefit the user.",
                "The new retrieval paradigm is thus fundamentally different from the traditional paradigm, and is inherently more general.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent UCAIR (<br>user-centered adaptive information retrieval</br>) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "Thus the developed search agent can improve existing web search performance without additional effort from the user.",
                "The remaining sections are organized as follows.",
                "In Section 2, we discuss the related work.",
                "In Section 3, we present a decisiontheoretic interactive retrieval framework for implicit user modeling.",
                "In Section 4, we present the design and implementation of an intelligent client-side web search agent (UCAIR) that performs eager implicit feedback.",
                "In Section 5, we report our experiment results using the search agent.",
                "Section 6 concludes our work. 2.",
                "RELATED WORK Implicit user modeling for personalized search has been studied in previous work, but our work differs from all previous work in several aspects: (1) We emphasize the exploitation of immediate search context such as the related immediately preceding query and the viewed documents in the same session, while most previous work relies on long-term collection of implicit feedback information [25]. (2) We perform eager feedback and bring the benefit of implicit user modeling as soon as any new implicit feedback information is available, while the previous work mostly exploits longterm implicit feedback [10]. (3) We propose a retrieval framework to integrate implicit user modeling with the interactive retrieval process, while the previous work either studies implicit user modeling separately from retrieval [3] or only studies specific retrieval models for exploiting implicit feedback to better match a query with documents [23, 27, 22]. (4) We develop and evaluate a personalized Web search agent with online user studies, while most existing work evaluates algorithms offline without real user interactions.",
                "Currently some search engines provide rudimentary personalization, such as Google Personalized web search [6], which allows users to explicitly describe their interests by selecting from predefined topics, so that those results that match their interests are brought to the top, and My Yahoo! search [16], which gives users the option to save web sites they like and block those they dislike.",
                "In contrast, UCAIR personalizes web search through implicit user modeling without any additional user efforts.",
                "Furthermore, the personalization of UCAIR is provided on the client side.",
                "There are two remarkable advantages on this.",
                "First, the user does not need to worry about the privacy infringement, which is a big concern for personalized search [26].",
                "Second, both the computation of personalization and the storage of the user profile are done at the client side so that the server load is reduced dramatically [9].",
                "There have been many works studying user query logs [1] or query dynamics [13].",
                "UCAIR makes direct use of a users query history to benefit the same user immediately in the same search session.",
                "UCAIR first judges whether two neighboring queries belong to the same information session and if so, it selects terms from the previous query to perform query expansion.",
                "Our query expansion approach is similar to automatic query expansion [28, 15, 5], but instead of using pseudo feedback to expand the query, we use users implicit feedback information to expand the current query.",
                "These two techniques may be combined. 3.",
                "OPTIMIZATION IN INTERACTIVE IR In interactive IR, a user interacts with the retrieval system through an action dialogue, in which the system responds to each user action with some system action.",
                "For example, the users action may be submitting a query and the systems response may be returning a list of 10 document summaries.",
                "In general, the space of user actions and system responses and their granularities would depend on the interface of a particular retrieval system.",
                "In principle, every action of the user can potentially provide new evidence to help the system better infer the users information need.",
                "Thus in order to respond optimally, the system should use all the evidence collected so far about the user when choosing a response.",
                "When viewed in this way, most existing search engines are clearly non-optimal.",
                "For example, if a user has viewed some documents on the first page of search results, when the user clicks on the Next link to fetch more results, an existing retrieval system would still return the next page of results retrieved based on the original query without considering the new evidence that a particular result has been viewed by the user. 825 We propose to optimize retrieval performance by adapting system responses based on every action that a user has taken, and cast the optimization problem as a decision task.",
                "Specifically, at any time, the system would attempt to do two tasks: (1) User model updating: Monitor any useful evidence from the user regarding his/her information need and update the user model as soon as such evidence is available; (2) Improving search results: Rerank immediately all the documents that the user has not yet seen, as soon as the user model is updated.",
                "We emphasize eager updating and reranking, which makes our work quite different from any existing work.",
                "Below we present a formal decision theoretic framework for optimizing retrieval performance through implicit user modeling in interactive information retrieval. 3.1 A decision-theoretic framework Let A be the set of all user actions and R(a) be the set of all possible system responses to a user action a ∈ A.",
                "At any time, let At = (a1, ..., at) be the observed sequence of user actions so far (up to time point t) and Rt−1 = (r1, ..., rt−1) be the responses that the system has made responding to the user actions.",
                "The systems goal is to choose an optimal response rt ∈ R(at) for the current user action at.",
                "Let M be the space of all possible user models.",
                "We further define a loss function L(a, r, m) ∈ , where a ∈ A is a user action, r ∈ R(a) is a system response, and m ∈ M is a user model.",
                "L(a, r, m) encodes our decision preferences and assesses the optimality of responding with r when the current user model is m and the current user action is a.",
                "According to Bayesian decision theory, the optimal decision at time t is to choose a response that minimizes the Bayes risk, i.e., r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) where P(mt|U, D, At, Rt−1) is the posterior probability of the user model mt given all the observations about the user U we have made up to time t. To simplify the computation of Equation 1, let us assume that the posterior probability mass P(mt|U, D, At, Rt−1) is mostly concentrated on the mode m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "We can then approximate the integral with the value of the loss function at m∗ t .",
                "That is, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) where m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "Leaving aside how to define and estimate these probabilistic models and the loss function, we can see that such a decision-theoretic formulation suggests that, in order to choose the optimal response to at, the system should perform two tasks: (1) compute the current user model and obtain m∗ t based on all the useful information. (2) choose a response rt to minimize the loss function value L(at, rt, m∗ t ).",
                "When at does not affect our belief about m∗ t , the first step can be omitted and we may reuse m∗ t−1 for m∗ t .",
                "Note that our framework is quite general since we can potentially model any kind of user actions and system responses.",
                "In most cases, as we may expect, the systems response is some ranking of documents, i.e., for most actions a, R(a) consists of all the possible rankings of the unseen documents, and the decision problem boils down to choosing the best ranking of unseen documents based on the most current user model.",
                "When a is the action of submitting a keyword query, such a response is exactly what a current retrieval system would do.",
                "However, we can easily imagine that a more intelligent web search engine would respond to a users clicking of the Next link (to fetch more unseen results) with a more optimized ranking of documents based on any viewed documents in the current page of results.",
                "In fact, according to our eager updating strategy, we may even allow a system to respond to a users clicking of browsers Back button after viewing a document in the same way, so that the user can maximally benefit from implicit feedback.",
                "These are precisely what our UCAIR system does. 3.2 User models A user model m ∈ M represents what we know about the user U, so in principle, it can contain any information about the user that we wish to model.",
                "We now discuss two important components in a user model.",
                "The first component is a component model of the users information need.",
                "Presumably, the most important factor affecting the optimality of the systems response is how well the response addresses the users information need.",
                "Indeed, at any time, we may assume that the system has some belief about what the user is interested in, which we model through a term vector x = (x1, ..., x|V |), where V = {w1, ..., w|V |} is the set of all terms (i.e., vocabulary) and xi is the weight of term wi.",
                "Such a term vector is commonly used in information retrieval to represent both queries and documents.",
                "For example, the vector-space model, assumes that both the query and the documents are represented as term vectors and the score of a document with respect to a query is computed based on the similarity between the query vector and the document vector [21].",
                "In a language modeling approach, we may also regard the query unigram language model [12, 29] or the relevance model [14] as a term vector representation of the users information need.",
                "Intuitively, x would assign high weights to terms that characterize the topics which the user is interested in.",
                "The second component we may include in our user model is the documents that the user has already viewed.",
                "Obviously, even if a document is relevant, if the user has already seen the document, it would not be useful to present the same document again.",
                "We thus introduce another variable S ⊂ D (D is the whole set of documents in the collection) to denote the subset of documents in the search results that the user has already seen/viewed.",
                "In general, at time t, we may represent a user model as mt = (S, x, At, Rt−1), where S is the seen documents, x is the systems understanding of the users information need, and (At, Rt−1) represents the users interaction history.",
                "Note that an even more general user model may also include other factors such as the users reading level and occupation.",
                "If we assume that the uncertainty of a user model mt is solely due to the uncertainty of x, the computation of our current estimate of user model m∗ t will mainly involve computing our best estimate of x.",
                "That is, the system would choose a response according to r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) where x∗ = argmaxx P(x|U, D, At, Rt−1).",
                "This is the decision mechanism implemented in the UCAIR system to be described later.",
                "In this system, we avoided specifying the probabilistic model P(x|U, D, At, Rt−1) by computing x∗ directly with some existing feedback method. 3.3 Loss functions The exact definition of loss function L depends on the responses, thus it is inevitably application-specific.",
                "We now briefly discuss some possibilities when the response is to rank all the unseen documents and present the top k of them.",
                "Let r = (d1, ..., dk) be the top k documents, S be the set of seen documents by the user, and x∗ be the systems best guess of the users information need.",
                "We 826 may simply define the loss associated with r as the negative sum of the probability that each of the di is relevant, i.e., L(a, r, m) = − k i=1 P(relevant|di, m).",
                "Clearly, in order to minimize this loss function, the optimal response r would contain the k documents with the highest probability of relevance, which is intuitively reasonable.",
                "One deficiency of this top-k loss function is that it is not sensitive to the internal order of the selected top k documents, so switching the ranking order of a non-relevant document and a relevant one would not affect the loss, which is unreasonable.",
                "To model ranking, we can introduce a factor of the user model - the probability of each of the k documents being viewed by the user, P(view|di), and define the following ranking loss function: L(a, r, m) = − k i=1 P(view|di)P(relevant|di, m) Since in general, if di is ranked above dj (i.e., i < j), P(view|di) > P(view|dj), this loss function would favor a decision to rank relevant documents above non-relevant ones, as otherwise, we could always switch di with dj to reduce the loss value.",
                "Thus the system should simply perform a regular retrieval and rank documents according to the probability of relevance [18].",
                "Depending on the users retrieval preferences, there can be many other possibilities.",
                "For example, if the user does not want to see redundant documents, the loss function should include some redundancy measure on r based on the already seen documents S. Of course, when the response is not to choose a ranked list of documents, we would need a different loss function.",
                "We discuss one such example that is relevant to the search agent that we implement.",
                "When a user enters a query qt (current action), our search agent relies on some existing search engine to actually carry out search.",
                "In such a case, even though the search agent does not have control of the retrieval algorithm, it can still attempt to optimize the search results through refining the query sent to the search engine and/or reranking the results obtained from the search engine.",
                "The loss functions for reranking are already discussed above; we now take a look at the loss functions for query refinement.",
                "Let f be the retrieval function of the search engine that our agent uses so that f(q) would give us the search results using query q.",
                "Given that the current action of the user is entering a query qt (i.e., at = qt), our response would be f(q) for some q.",
                "Since we have no choice of f, our decision is to choose a good q.",
                "Formally, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) which shows that our goal is to find q∗ = argminqL(qt, f(q), m), i.e., an optimal query that would give us the best f(q).",
                "A different choice of loss function L(qt, f(q), m) would lead to a different query refinement strategy.",
                "In UCAIR, we heuristically compute q∗ by expanding qt with terms extracted from rt−1 whenever qt−1 and qt have high similarity.",
                "Note that rt−1 and qt−1 are contained in m as part of the users interaction history. 3.4 Implicit user modeling Implicit user modeling is captured in our framework through the computation of x∗ = argmaxx P(x|U, D, At, Rt−1), i.e., the systems current belief of what the users information need is.",
                "Here again there may be many possibilities, leading to different algorithms for implicit user modeling.",
                "We now discuss a few of them.",
                "First, when two consecutive queries are related, the previous query can be exploited to enrich the current query and provide more search context to help disambiguation.",
                "For this purpose, instead of performing query expansion as we did in the previous section, we could also compute an updated x∗ based on the previous query and retrieval results.",
                "The computed new user model can then be used to rank the documents with a standard information retrieval model.",
                "Second, we can also infer a users interest based on the summaries of the viewed documents.",
                "When a user is presented with a list of summaries of top ranked documents, if the user chooses to skip the first n documents and to view the (n+1)-th document, we may infer that the user is not interested in the displayed summaries for the first n documents, but is attracted by the displayed summary of the (n + 1)-th document.",
                "We can thus use these summaries as negative and positive examples to learn a more accurate user model x∗ .",
                "Here many standard relevance feedback techniques can be exploited [19, 20].",
                "Note that we should use the displayed summaries, as opposed to the actual contents of those documents, since it is possible that the displayed summary of the viewed document is relevant, but the document content is actually not.",
                "Similarly, a displayed summary may mislead a user to skip a relevant document.",
                "Inferring user models based on such displayed information, rather than the actual content of a document is an important difference between UCAIR and some other similar systems.",
                "In UCAIR, both of these strategies for inferring an implicit user model are implemented. 4.",
                "UCAIR: A PERSONALIZED SEARCH AGENT 4.1 Design In this section, we present a client-side web search agent called UCAIR, in which we implement some of the methods discussed in the previous section for performing personalized search through implicit user modeling.",
                "UCAIR is a web browser plug-in 1 that acts as a proxy for web search engines.",
                "Currently, it is only implemented for Internet Explorer and Google, but it is a matter of engineering to make it run on other web browsers and interact with other search engines.",
                "The issue of privacy is a primary obstacle for deploying any real world applications involving serious user modeling, such as personalized search.",
                "For this reason, UCAIR is strictly running as a client-side search agent, as opposed to a server-side application.",
                "This way, the captured user information always resides on the computer that the user is using, thus the user does not need to release any information to the outside.",
                "Client-side personalization also allows the system to easily observe a lot of user information that may not be easily available to a server.",
                "Furthermore, performing personalized search on the client-side is more scalable than on the serverside, since the overhead of computation and storage is distributed among clients.",
                "As shown in Figure 1, the UCAIR toolbar has 3 major components: (1) The (implicit) user modeling module captures a users search context and history information, including the submitted queries and any clicked search results and infers search session boundaries. (2) The query modification module selectively improves the query formulation according to the current user model. (3) The result re-ranking module immediately re-ranks any unseen search results whenever the user model is updated.",
                "In UCAIR, we consider four basic user actions: (1) submitting a keyword query; (2) viewing a document; (3) clicking the Back button; (4) clicking the Next link on a result page.",
                "For each of these four actions, the system responds with, respectively, (1) 1 UCAIR is available at: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Search Engine (e.g., Google) Search History Log (e.g.,past queries, clicked results) Query Modification Result Re-Ranking User Modeling Result Buffer UCAIR Userquery results clickthrough… Figure 1: UCAIR architecture generating a ranked list of results by sending a possibly expanded query to a search engine; (2) updating the information need model x; (3) reranking the unseen results on the current result page based on the current model x; and (4) reranking the unseen pages and generating the next page of results based on the current model x.",
                "Behind these responses, there are three basic tasks: (1) Decide whether the previous query is related to the current query and if so expand the current query with useful terms from the previous query or the results of the previous query. (2) Update the information need model x based on a newly clicked document summary. (3) Rerank a set of unseen documents based on the current model x.",
                "Below we describe our algorithms for each of them. 4.2 Session boundary detection and query expansion To effectively exploit previous queries and their corresponding clickthrough information, UCAIR needs to judge whether two adjacent queries belong to the same search session (i.e., detect session boundaries).",
                "Existing work on session boundary detection is mostly in the context of web log analysis (e.g., [8]), and uses statistical information rather than textual features.",
                "Since our clientside agent does not have access to server query logs, we make session boundary decisions based on textual similarity between two queries.",
                "Because related queries do not necessarily share the same words (e.g., java island and travel Indonesia), it is insufficient to use only query text.",
                "Therefore we use the search results of the two queries to help decide whether they are topically related.",
                "For example, for the above queries java island and travel Indonesia, the words java, bali, island, indonesia and travel may occur frequently in both queries search results, yielding a high similarity score.",
                "We only use the titles and summaries of the search results to calculate the similarity since they are available in the retrieved search result page and fetching the full text of every result page would significantly slow down the process.",
                "To compensate for the terseness of titles and summaries, we retrieve more results than a user would normally view for the purpose of detecting session boundaries (typically 50 results).",
                "The similarity between the previous query q and the current query q is computed as follows.",
                "Let {s1, s2, . . . , sn } and {s1, s2, . . . , sn} be the result sets for the two queries.",
                "We use the pivoted normalization TF-IDF weighting formula [24] to compute a term weight vector si for each result si.",
                "We define the average result savg to be the centroid of all the result vectors, i.e., (s1 + s2 + . . . + sn)/n.",
                "The cosine similarity between the two average results is calculated as s avg · savg/ s 2 avg · s2 avg If the similarity value exceeds a predefined threshold, the two queries will be considered to be in the same information session.",
                "If the previous query and the current query are found to belong to the same search session, UCAIR would attempt to expand the current query with terms from the previous query and its search results.",
                "Specifically, for each term in the previous query or the corresponding search results, if its frequency in the results of the current query is greater than a preset threshold (e.g. 5 results out of 50), the term would be added to the current query to form an expanded query.",
                "In this case, UCAIR would send this expanded query rather than the original one to the search engine and return the results corresponding to the expanded query.",
                "Currently, UCAIR only uses the immediate preceding query for query expansion; in principle, we could exploit all related past queries. 4.3 Information need model updating Suppose at time t, we have observed that the user has viewed k documents whose summaries are s1, ..., sk.",
                "We update our user model by computing a new information need vector with a standard feedback method in information retrieval (i.e., Rocchio [19]).",
                "According to the vector space retrieval model, each clicked summary si can be represented by a term weight vector si with each term weighted by a TF-IDF weighting formula [21].",
                "Rocchio computes the centroid vector of all the summaries and interpolates it with the original query vector to obtain an updated term vector.",
                "That is, x = αq + (1 − α) 1 k k i=1 si where q is the query vector, k is the number of summaries the user clicks immediately following the current query and α is a parameter that controls the influence of the clicked summaries on the inferred information need model.",
                "In our experiments, α is set to 0.5.",
                "Note that we update the information need model whenever the user views a document. 4.4 Result reranking In general, we want to rerank all the unseen results as soon as the user model is updated.",
                "Currently, UCAIR implements reranking in two cases, corresponding to the user clicking the Back button and Next link in the Internet Explorer.",
                "In both cases, the current (updated) user model would be used to rerank the unseen results so that the user would see improved search results immediately.",
                "To rerank any unseen document summaries, UCAIR uses the standard vector space retrieval model and scores each summary based on the similarity of the result and the current user information need vector x [21].",
                "Since implicit feedback is not completely reliable, we bring up only a small number (e.g. 5) of highest reranked results to be followed by any originally high ranked results. 828 Google result (user query = java map) UCAIR result (user query =java map) previous query = travel Indonesia previous query = hashtable expanded user query = java map Indonesia expanded user query = java map class 1 Java map projections of the world ... Lonely Planet - Indonesia Map Map (Java 2 Platform SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Java map projections of the world ... INDONESIA TOURISM : CENTRAL JAVA - MAP Java 2 Platform SE v1.3.1: Interface Map www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Java Map INDONESIA TOURISM : WEST JAVA - MAP An Introduction to Java Map Collection Classes java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Java Technology Concept Map IndoStreets - Java Map An Introduction to Java Map Collection Classes java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Indonesia Regions and Islands Maps, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 An Introduction to Java Map Collection Classes Indonesia City Street Map,... Hibernate simplifies inheritance mapping www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Java Map Maps Of Indonesia tmap 30.map Class Hierarchy www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Java API Map Maps of Indonesia by Peter Loud Class Scope www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas : Sam Maps of Indonesia by Peter Loud Class PrintSafeHashMap www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 INDONESIA TOURISM : WEST JAVA - MAP indonesiaphoto.com Java Pro - Union and Vertical Mapping of Classes www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Table 1: Sample results of query expansion 5.",
                "EVALUATION OF UCAIR We now present some results on evaluating the two major UCAIR functions: selective query expansion and result reranking based on user clickthrough data. 5.1 Sample results The query expansion strategy implemented in UCAIR is intentionally conservative to avoid misinterpretation of implicit user models.",
                "In practice, whenever it chooses to expand the query, the expansion usually makes sense.",
                "In Table 1, we show how UCAIR can successfully distinguish two different search contexts for the query java map, corresponding to two different previous queries (i.e., travel Indonesia vs. hashtable).",
                "Due to implicit user modeling, UCAIR intelligently figures out to add Indonesia and class, respectively, to the users query java map, which would otherwise be ambiguous as shown in the original results from Google on March 21, 2005.",
                "UCAIRs results are much more accurate than Googles results and reflect personalization in search.",
                "The eager implicit feedback component is designed to immediately respond to a users activity such as viewing a document.",
                "In Figure 2, we show how UCAIR can successfully disambiguate an ambiguous query jaguar by exploiting a viewed document summary.",
                "In this case, the initial retrieval results using jaguar (shown on the left side) contain two results about the Jaguar cars followed by two results about the Jaguar software.",
                "However, after the user views the web page content of the second result (about Jaguar car) and returns to the search result page by clicking Back button, UCAIR automatically nominates two new search results about Jaguar cars (shown on the right side), while the original two results about Jaguar software are pushed down on the list (unseen from the picture). 5.2 Quantitative evaluation To further evaluate UCAIR quantitatively, we conduct a user study on the effectiveness of the eager implicit feedback component.",
                "It is a challenge to quantitatively evaluate the potential performance improvement of our proposed model and UCAIR over Google in an unbiased way [7].",
                "Here, we design a user study, in which participants would do normal web search and judge a randomly and anonymously mixed set of results from Google and UCAIR at the end of the search session; participants do not know whether a result comes from Google or UCAIR.",
                "We recruited 6 graduate students for this user study, who have different backgrounds (3 computer science, 2 biology, and 1 chem<top> <num> Number: 716 <title> Spammer arrest sue <desc> Description: Have any spammers been arrested or sued for sending unsolicited e-mail? <narr> Narrative: Instances of arrests, prosecutions, convictions, and punishments of spammers, and lawsuits against them are relevant.",
                "Documents which describe laws to limit spam without giving details of lawsuits or criminal trials are not relevant. </top> Figure 3: An example of TREC query topic, expressed in a form which might be given to a human assistant or librarian istry).",
                "We use query topics from TREC 2 2004 Terabyte track [2] and TREC 2003 Web track [4] topic distillation task in the way to be described below.",
                "An example topic from TREC 2004 Terabyte track appears in Figure 3.",
                "The title is a short phrase and may be used as a query to the retrieval system.",
                "The description field provides a slightly longer statement of the topic requirement, usually expressed as a single complete sentence or question.",
                "Finally the narrative supplies additional information necessary to fully specify the requirement, expressed in the form of a short paragraph.",
                "Initially, each participant would browse 50 topics either from Terabyte track or Web track and pick 5 or 7 most interesting topics.",
                "For each picked topic, the participant would essentially do the normal web search using UCAIR to find many relevant web pages by using the title of the query topic as the initial keyword query.",
                "During this process, the participant may view the search results and possibly click on some interesting ones to view the web pages, just as in a normal web search.",
                "There is no requirement or restriction on how many queries the participant must submit or when the participant should stop the search for one topic.",
                "When the participant plans to change the search topic, he/she will simply press a button 2 Text REtrieval Conference: http://trec.nist.gov/ 829 Figure 2: Screen shots for result reranking to evaluate the search results before actually switching to the next topic.",
                "At the time of evaluation, 30 top ranked results from Google and UCAIR (some are overlapping) are randomly mixed together so that the participant would not know whether a result comes from Google or UCAIR.",
                "The participant would then judge the relevance of these results.",
                "We measure precision at top n (n = 5, 10, 20, 30) documents of Google and UCAIR.",
                "We also evaluate precisions at different recall levels.",
                "Altogether, 368 documents judged as relevant from Google search results and 429 documents judged as relevant from UCAIR by participants.",
                "Scatter plots of precision at top 10 and top 20 documents are shown in Figure 4 and Figure 5 respectively (The scatter plot of precision at top 30 documents is very similar to precision at top 20 documents).",
                "Each point of the scatter plots represents the precisions of Google and UCAIR on one query topic.",
                "Table 2 shows the average precision at top n documents among 32 topics.",
                "From Figure 4, Figure 5 and Table 2, we see that the search results from UCAIR are consistently better than those from Google by all the measures.",
                "Moreover, the performance improvement is more dramatic for precision at top 20 documents than that at precision at top 10 documents.",
                "One explanation for this is that the more interaction the user has with the system, the more clickthrough data UCAIR can be expected to collect.",
                "Thus the retrieval system can build more precise implicit user models, which lead to better retrieval accuracy.",
                "Ranking Method prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Improvement 8.0% 17.8% 20.2% 21.8% Table 2: Table of average precision at top n documents for 32 query topics The plot in Figure 6 shows the precision-recall curves for UCAIR and Google, where it is clearly seen that the performance of UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Scatterplot of Precision at Top 10 Documents Figure 4: Precision at top 10 documents of UCAIR and Google is consistently and considerably better than that of Google at all levels of recall. 6.",
                "CONCLUSIONS In this paper, we studied how to exploit implicit user modeling to intelligently personalize information retrieval and improve search accuracy.",
                "Unlike most previous work, we emphasize the use of immediate search context and implicit feedback information as well as eager updating of search results to maximally benefit a user.",
                "We presented a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent (UCAIR) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Scatterplot of Precision at Top 20 documents Figure 5: Precision at top 20 documents of UCAIR and Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 recall precision Precision−Recall curves Google Result UCAIR Result Figure 6: Precision at top 20 result of UCAIR and Google Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "The developed search agent thus can improve existing web search performance without any additional effort from the user. 7.",
                "ACKNOWLEDGEMENT We thank the six participants of our evaluation experiments.",
                "This work was supported in part by the National Science Foundation grants IIS-0347933 and IIS-0428472. 8.",
                "REFERENCES [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman, and O. Frieder.",
                "Hourly analysis of a very large topically categorized web query log.",
                "In Proceedings of SIGIR 2004, pages 321-328, 2004. [2] C. Clarke, N. Craswell, and I. Soboroff.",
                "Overview of the TREC 2004 terabyte track.",
                "In Proceedings of TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda, and D. Brown.",
                "Implicit interest indicators.",
                "In Proceedings of Intelligent User Interfaces 2001, pages 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson, and M. Wu.",
                "Overview of the TREC 2003 web track.",
                "In Proceedings of TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend, and V. Larvrenko.",
                "Relevance feedback and personalization: A language modeling perspective.",
                "In Proeedings of Second DELOS Workshop: Personalisation and Recommender Systems in Digital Libraries, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite, and D. Harman.",
                "Results and challenges in web search evaluation.",
                "Computer Networks, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A.",
                "An, and D. Schuurmans.",
                "Dynamic web log session identification with statistical language models.",
                "Journal of the American Society for Information Science and Technology, 55(14):1290-1303, 2004. [9] G. Jeh and J. Widom.",
                "Scaling personalized web search.",
                "In Proceedings of WWW 2003, pages 271-279, 2003. [10] T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of SIGKDD 2002, pages 133-142, 2002. [11] D. Kelly and J. Teevan.",
                "Implicit feedback for inferring user preference: A bibliography.",
                "SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of SIGIR01, pages 111-119, 2001. [13] T. Lau and E. Horvitz.",
                "Patterns of search: Analyzing and modeling web query refinement.",
                "In Proceedings of the Seventh International Conference on User Modeling (UM), pages 145 -152, 1999. [14] V. Lavrenko and B. Croft.",
                "Relevance-based language models.",
                "In Proceedings of SIGIR01, pages 120-127, 2001. [15] M. Mitra, A. Singhal, and C. Buckley.",
                "Improving automatic query expansion.",
                "In Proceedings of SIGIR 1998, pages 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg.",
                "As google goes, so goes the nation.",
                "New York Times, May 2003. [18] S. E. Robertson.",
                "The probability ranking principle in ı˚.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] J. J. Rocchio.",
                "Relevance feedback in information retrieval.",
                "In The SMART Retrieval System: Experiments in Automatic Document Processing, pages 313-323.",
                "Prentice-Hall Inc., 1971. [20] G. Salton and C. Buckley.",
                "Improving retrieval performance by retrieval feedback.",
                "Journal of the American Society for Information Science, 41(4):288-297, 1990. [21] G. Salton and M. J. McGill.",
                "Introduction to Modern Information Retrieval.",
                "McGraw-Hill, 1983. [22] X. Shen, B. Tan, and C. Zhai.",
                "Context-sensitive information retrieval using implicit feedback.",
                "In Proceedings of SIGIR 2005, pages 43-50, 2005. [23] X. Shen and C. Zhai.",
                "Exploiting query history for document ranking in interactive information retrieval (Poster).",
                "In Proceedings of SIGIR 2003, pages 377-378, 2003. [24] A. Singhal.",
                "Modern information retrieval: A brief overview.",
                "Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano, and M. Yoshikawa.",
                "Adaptive web search based on user profile constructed without any effort from users.",
                "In Proceedings of WWW 2004, pages 675-684, 2004. [26] E. Volokh.",
                "Personalization and privacy.",
                "Communications of the ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen, and I. Ruthven.",
                "A simulated study of implicit feedback models.",
                "In Proceedings of ECIR 2004, pages 311-326, 2004. [28] J. Xu and W. B. Croft.",
                "Query expansion using local and global document analysis.",
                "In Proceedings of SIGIR 1996, pages 4-11, 1996. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in KL divergence retrieval model.",
                "In Proceedings of the CIKM 2001, pages 403-410, 2001. 831"
            ],
            "original_annotated_samples": [
                "Using these techniques, we develop a client-side web search agent UCAIR (<br>user-centered adaptive information retrieval</br>) on top of a popular search engine (Google)."
            ],
            "translated_annotated_samples": [
                "Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente UCAIR (<br>Recuperación de Información Adaptativa Centrada en el Usuario</br>) sobre un motor de búsqueda popular (Google)."
            ],
            "translated_text": "Modelado implícito de usuarios para búsqueda personalizada Xuehua Shen, Bin Tan, ChengXiang Zhai Departamento de Ciencias de la Computación Universidad de Illinois en Urbana-Champaign RESUMEN Los sistemas de recuperación de información (por ejemplo, motores de búsqueda web) son críticos para superar la sobrecarga de información. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales, lo que resulta en un rendimiento de recuperación inherentemente no óptimo. Por ejemplo, un turista y un programador pueden usar la misma palabra \"java\" para buscar información diferente, pero los sistemas de búsqueda actuales devolverían los mismos resultados. En este artículo, estudiamos cómo inferir el interés de un usuario a partir del contexto de búsqueda del usuario y utilizar el modelo de usuario implícito inferido para la búsqueda personalizada. Presentamos un marco teórico de toma de decisiones y desarrollamos técnicas para el modelado implícito del usuario en la recuperación de información. Desarrollamos un agente de búsqueda web inteligente del lado del cliente (UCAIR) que puede realizar retroalimentación implícita ansiosa, por ejemplo, expansión de consultas basada en consultas anteriores y reordenamiento inmediato de resultados basado en información de clics. Los experimentos sobre la búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda sobre el popular motor de búsqueda Google. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación, Retroalimentación de relevancia, Proceso de búsqueda Términos Generales Algoritmos 1. Aunque muchos sistemas de recuperación de información (por ejemplo, motores de búsqueda web y sistemas de biblioteca digital) se han implementado con éxito, los sistemas de recuperación actuales están lejos de ser óptimos. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales [17]. Esta no optimalidad inherente se ve claramente en los siguientes dos casos: (1) Diferentes usuarios pueden utilizar exactamente la misma consulta (por ejemplo, Java) para buscar información diferente (por ejemplo, la isla de Java en Indonesia o el lenguaje de programación Java), pero los sistemas de IR existentes devuelven los mismos resultados para estos usuarios. Sin considerar al usuario actual, es imposible saber a qué sentido se refiere Java en una consulta. (2) Las necesidades de información de un usuario pueden cambiar con el tiempo. El mismo usuario puede usar Java a veces para referirse a la isla de Java en Indonesia y otras veces para referirse al lenguaje de programación. Sin reconocer el contexto de búsqueda, sería nuevamente imposible reconocer el sentido correcto. Para optimizar la precisión de la recuperación, claramente necesitamos modelar al usuario de manera adecuada y personalizar la búsqueda según cada usuario individual. El objetivo principal del modelado de usuario para la recuperación de información es modelar con precisión la necesidad de información de un usuario, lo cual, desafortunadamente, es una tarea muy difícil. De hecho, incluso resulta difícil para un usuario describir con precisión cuál es su necesidad de información. ¿Qué información está disponible para que un sistema pueda inferir la necesidad de información de un usuario? Obviamente, la consulta de los usuarios proporciona la evidencia más directa. De hecho, la mayoría de los sistemas de recuperación existentes se basan únicamente en la consulta para modelar la necesidad de información de los usuarios. Sin embargo, dado que una consulta suele ser extremadamente corta, el modelo de usuario construido basado en una consulta de palabras clave inevitablemente resulta empobrecido. Una forma efectiva de mejorar la modelización de usuarios en la recuperación de información es pedir al usuario que especifique explícitamente qué documentos son relevantes (es decir, útiles para satisfacer su necesidad de información) y luego mejorar la modelización de usuarios basándose en ejemplos de documentos relevantes. Esto se llama retroalimentación de relevancia, lo cual ha demostrado ser bastante efectivo para mejorar la precisión de recuperación [19, 20]. Desafortunadamente, en aplicaciones del mundo real, los usuarios suelen ser reacios a hacer el esfuerzo adicional de proporcionar ejemplos relevantes para retroalimentación [11]. Por lo tanto, es muy interesante estudiar cómo inferir la necesidad de información de un usuario basándose en cualquier información de retroalimentación implícita, la cual existe naturalmente a través de las interacciones del usuario y no requiere ningún esfuerzo adicional por parte del usuario. De hecho, varios estudios previos han demostrado que el modelado implícito del usuario puede mejorar la precisión de recuperación. En [3], se desarrolla un navegador web (Curious Browser) para registrar las calificaciones explícitas de relevancia de las páginas web por parte de los usuarios (retroalimentación de relevancia) y el comportamiento de navegación al ver una página, como el tiempo de permanencia, clics de ratón, movimiento del ratón y desplazamiento (retroalimentación implícita). Se muestra que el tiempo de permanencia en una página, la cantidad de desplazamiento en una página y la combinación de tiempo y desplazamiento tienen una fuerte correlación con las calificaciones de relevancia explícita, lo que sugiere que la retroalimentación implícita puede ser útil para inferir la necesidad de información del usuario. En [10], se recopilan datos de clics de usuario como datos de entrenamiento para aprender una función de recuperación, que se utiliza para producir un ranking personalizado de resultados de búsqueda que se adapte a las preferencias de un grupo de usuarios. En [25], los datos de clics recopilados durante un largo período de tiempo se utilizan a través de la expansión de consultas para mejorar la precisión de recuperación. Si bien un usuario puede tener intereses y preferencias generales a largo plazo para la información, a menudo está buscando documentos para satisfacer una necesidad de información ad-hoc, que solo dura un corto período de tiempo; una vez que se satisface la necesidad de información, el usuario generalmente ya no estaría interesado en esa información. Por ejemplo, un usuario puede estar buscando información sobre autos usados para comprar uno, pero una vez que el usuario ha comprado un auto, generalmente ya no está interesado en esa información. En tales casos, la información de retroalimentación implícita recopilada durante un largo período de tiempo es poco probable que sea muy útil, pero el contexto de búsqueda inmediato y la información de retroalimentación, como cuáles de los resultados de búsqueda para la necesidad de información actual son vistos, se espera que sean mucho más útiles. Considera la consulta de Java nuevamente. Cualquiera de la siguiente información de retroalimentación inmediata sobre el usuario podría potencialmente ayudar a determinar el significado previsto de Java en la consulta: (1) La consulta anterior enviada por el usuario es hashtable (en lugar de, por ejemplo, viajar a Indonesia). (2) En los resultados de búsqueda, el usuario visualizó una página donde palabras como programación, software y applet ocurren muchas veces. Hasta donde sabemos, cómo aprovechar este contexto de búsqueda inmediato y a corto plazo para mejorar la búsqueda aún no ha sido abordado de manera satisfactoria en trabajos anteriores. En este artículo, estudiamos cómo construir y actualizar un modelo de usuario basado en el contexto de búsqueda inmediato y la información de retroalimentación implícita, y utilizar el modelo para mejorar la precisión de la recuperación ad-hoc. Para beneficiar al máximo al usuario de un sistema de recuperación a través de modelado implícito del usuario, proponemos realizar retroalimentación implícita entusiasta. Es decir, tan pronto como observemos cualquier nueva pieza de evidencia del usuario, actualizaríamos la creencia del sistema sobre la necesidad de información del usuario y responderíamos con resultados de recuperación mejorados basados en el modelo de usuario actualizado. Presentamos un marco de trabajo de teoría de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. En un paradigma de recuperación tradicional, el problema de recuperación consiste en emparejar una consulta con documentos y clasificar los documentos según sus valores de relevancia. Como resultado, el proceso de recuperación es un ciclo independiente simple de consulta y visualización de resultados. En el nuevo paradigma de recuperación propuesto, el contexto de búsqueda de los usuarios juega un papel importante y el modelo de usuario implícito inferido se explota inmediatamente para beneficiar al usuario. El nuevo paradigma de recuperación es, por lo tanto, fundamentalmente diferente del paradigma tradicional y es inherentemente más general. Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos apropiados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para reordenar inmediatamente cualquier documento que aún no haya sido visto por el usuario. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente UCAIR (<br>Recuperación de Información Adaptativa Centrada en el Usuario</br>) sobre un motor de búsqueda popular (Google). Los experimentos sobre búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en comparación con Google. Dado que la información implícita que explotamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional. Por lo tanto, el agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin esfuerzo adicional por parte del usuario. Las secciones restantes están organizadas de la siguiente manera. En la Sección 2, discutimos el trabajo relacionado. En la Sección 3, presentamos un marco de recuperación interactiva basado en teoría de decisiones para modelado implícito de usuarios. En la Sección 4, presentamos el diseño e implementación de un agente de búsqueda web inteligente del lado del cliente (UCAIR) que realiza retroalimentación implícita ansiosa. En la Sección 5, informamos nuestros resultados experimentales utilizando el agente de búsqueda. La sección 6 concluye nuestro trabajo. 2. El modelado implícito del usuario para la búsqueda personalizada ha sido estudiado en trabajos anteriores, pero nuestro trabajo difiere de todos los trabajos anteriores en varios aspectos: (1) Enfatizamos la explotación del contexto de búsqueda inmediato, como la consulta inmediatamente anterior relacionada y los documentos vistos en la misma sesión, mientras que la mayoría de los trabajos anteriores se basan en la recopilación a largo plazo de información de retroalimentación implícita [25]. (2) Realizamos una retroalimentación activa y obtenemos el beneficio del modelado implícito del usuario tan pronto como esté disponible cualquier nueva información de retroalimentación implícita, mientras que el trabajo anterior mayormente explota la retroalimentación implícita a largo plazo [10]. (3) Proponemos un marco de recuperación para integrar el modelado implícito del usuario con el proceso interactivo de recuperación, mientras que el trabajo anterior estudia el modelado implícito del usuario por separado de la recuperación [3] o solo estudia modelos de recuperación específicos para explotar la retroalimentación implícita para mejorar la coincidencia de una consulta con documentos [23, 27, 22]. (4) Desarrollamos y evaluamos un agente de búsqueda web personalizado con estudios de usuario en línea, mientras que la mayoría de los trabajos existentes evalúan algoritmos fuera de línea sin interacciones reales de usuarios. Actualmente algunos motores de búsqueda ofrecen personalización rudimentaria, como la búsqueda web personalizada de Google [6], que permite a los usuarios describir explícitamente sus intereses seleccionando entre temas predefinidos, de modo que los resultados que coinciden con sus intereses se muestren en la parte superior, y la búsqueda de My Yahoo! [16], que brinda a los usuarios la opción de guardar los sitios web que les gustan y bloquear aquellos que no les gustan. Por el contrario, UCAIR personaliza la búsqueda web a través de la modelización implícita del usuario sin necesidad de esfuerzos adicionales por parte del usuario. Además, la personalización de UCAIR se proporciona en el lado del cliente. Hay dos ventajas notables en esto. Primero, el usuario no necesita preocuparse por la infracción de privacidad, que es una gran preocupación para la búsqueda personalizada [26]. En segundo lugar, tanto el cálculo de la personalización como el almacenamiento del perfil del usuario se realizan en el lado del cliente para reducir drásticamente la carga del servidor [9]. Ha habido muchos trabajos estudiando los registros de consultas de usuarios [1] o la dinámica de consultas [13]. UCAIR hace uso directo del historial de consultas de un usuario para beneficiar al mismo usuario de inmediato en la misma sesión de búsqueda. UCAIR primero determina si dos consultas vecinas pertenecen a la misma sesión de información y, de ser así, selecciona términos de la consulta anterior para realizar la expansión de la consulta. Nuestro enfoque de expansión de consultas es similar a la expansión automática de consultas [28, 15, 5], pero en lugar de utilizar retroalimentación pseudo para expandir la consulta, utilizamos la información de retroalimentación implícita de los usuarios para expandir la consulta actual. Estas dos técnicas pueden ser combinadas. 3. OPTIMIZACIÓN EN IR INTERACTIVO En IR interactivo, un usuario interactúa con el sistema de recuperación a través de un diálogo de acción, en el cual el sistema responde a cada acción del usuario con alguna acción del sistema. Por ejemplo, la acción de los usuarios puede ser enviar una consulta y la respuesta del sistema puede ser devolver una lista de 10 resúmenes de documentos. En general, el espacio de acciones del usuario y respuestas del sistema y sus granularidades dependerían de la interfaz de un sistema de recuperación particular. En principio, cada acción del usuario puede potencialmente proporcionar nuevas pruebas para ayudar al sistema a inferir mejor la necesidad de información del usuario. Por lo tanto, para responder de manera óptima, el sistema debería utilizar toda la evidencia recopilada hasta ahora sobre el usuario al elegir una respuesta. Cuando se ven de esta manera, la mayoría de los motores de búsqueda existentes son claramente no óptimos. Por ejemplo, si un usuario ha visto algunos documentos en la primera página de resultados de búsqueda, cuando el usuario hace clic en el enlace Siguiente para obtener más resultados, un sistema de recuperación existente seguiría devolviendo la siguiente página de resultados recuperados en función de la consulta original sin considerar la nueva evidencia de que un resultado en particular ha sido visto por el usuario. Proponemos optimizar el rendimiento de la recuperación adaptando las respuestas del sistema en función de cada acción que un usuario haya tomado, y planteamos el problema de optimización como una tarea de decisión. Específicamente, en cualquier momento, el sistema intentaría realizar dos tareas: (1) Actualización del modelo de usuario: Monitorear cualquier evidencia útil del usuario con respecto a su necesidad de información y actualizar el modelo de usuario tan pronto como esta evidencia esté disponible; (2) Mejorar los resultados de búsqueda: Reclasificar inmediatamente todos los documentos que el usuario aún no ha visto, tan pronto como se actualice el modelo de usuario. Enfatizamos la actualización y reordenamiento entusiastas, lo que hace que nuestro trabajo sea bastante diferente a cualquier trabajo existente. A continuación presentamos un marco formal de teoría de decisiones para optimizar el rendimiento de recuperación a través de la modelización implícita del usuario en la recuperación de información interactiva. 3.1 Un marco de teoría de decisiones Sea A el conjunto de todas las acciones del usuario y R(a) el conjunto de todas las posibles respuestas del sistema a una acción del usuario a ∈ A. En cualquier momento, sea At = (a1, ..., at) la secuencia observada de acciones de usuario hasta ahora (hasta el momento t) y Rt−1 = (r1, ..., rt−1) las respuestas que el sistema ha dado en respuesta a las acciones del usuario. El objetivo del sistema es elegir una respuesta óptima rt ∈ R(at) para la acción actual del usuario at. Sea M el espacio de todos los posibles modelos de usuario. Definimos además una función de pérdida L(a, r, m) ∈ , donde a ∈ A es una acción del usuario, r ∈ R(a) es una respuesta del sistema, y m ∈ M es un modelo de usuario. L(a, r, m) codifica nuestras preferencias de decisión y evalúa la optimalidad de responder con r cuando el modelo de usuario actual es m y la acción de usuario actual es a. Según la teoría de decisión bayesiana, la decisión óptima en el tiempo t es elegir una respuesta que minimice el riesgo de Bayes, es decir, r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) donde P(mt|U, D, At, Rt−1) es la probabilidad posterior del modelo de usuario mt dadas todas las observaciones sobre el usuario U que hemos realizado hasta el tiempo t. Para simplificar el cálculo de la Ecuación 1, asumamos que la masa de probabilidad posterior P(mt|U, D, At, Rt−1) está principalmente concentrada en el modo m∗ t = argmaxmt P(mt|U, D, At, Rt−1). Podemos entonces aproximar la integral con el valor de la función de pérdida en m∗ t. Es decir, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) donde m∗ t = argmaxmt P(mt|U, D, At, Rt−1). Dejando de lado cómo definir y estimar estos modelos probabilísticos y la función de pérdida, podemos ver que tal formulación de la teoría de decisiones sugiere que, para elegir la respuesta óptima a at, el sistema debería realizar dos tareas: (1) calcular el modelo de usuario actual y obtener m∗ t basado en toda la información útil. (2) elegir una respuesta rt para minimizar el valor de la función de pérdida L(at, rt, m∗ t). Cuando at no afecta nuestra creencia sobre m∗ t , el primer paso puede omitirse y podemos reutilizar m∗ t−1 para m∗ t . Ten en cuenta que nuestro marco de trabajo es bastante general, ya que potencialmente podemos modelar cualquier tipo de acciones de usuario y respuestas del sistema. En la mayoría de los casos, como podríamos esperar, la respuesta del sistema es algún tipo de clasificación de documentos, es decir, para la mayoría de las acciones a, R(a) consiste en todas las posibles clasificaciones de los documentos no vistos, y el problema de decisión se reduce a elegir la mejor clasificación de los documentos no vistos basándose en el modelo de usuario más actualizado. Cuando a es la acción de enviar una consulta de palabras clave, tal respuesta es exactamente lo que haría un sistema de recuperación actual. Sin embargo, fácilmente podemos imaginar que un motor de búsqueda web más inteligente respondería al clic del usuario en el enlace Siguiente (para obtener más resultados no vistos) con una clasificación más optimizada de documentos basada en cualquier documento visto en la página actual de resultados. De hecho, según nuestra estrategia de actualización entusiasta, incluso podríamos permitir que un sistema responda al clic del botón Atrás del navegador por parte de un usuario después de ver un documento de la misma manera, para que el usuario pueda beneficiarse al máximo de la retroalimentación implícita. Estos son precisamente lo que nuestro sistema UCAIR hace. 3.2 Modelos de usuario Un modelo de usuario m ∈ M representa lo que sabemos sobre el usuario U, por lo que en principio, puede contener cualquier información sobre el usuario que deseemos modelar. Ahora discutimos dos componentes importantes en un modelo de usuario. El primer componente es un modelo de componente de la necesidad de información de los usuarios. Presumiblemente, el factor más importante que afecta la optimalidad de la respuesta del sistema es qué tan bien la respuesta aborda la necesidad de información de los usuarios. De hecho, en cualquier momento, podemos asumir que el sistema tiene alguna creencia sobre lo que le interesa al usuario, la cual modelamos a través de un vector de términos x = (x1, ..., x|V|), donde V = {w1, ..., w|V|} es el conjunto de todos los términos (es decir, vocabulario) y xi es el peso del término wi. Un vector de términos de este tipo se utiliza comúnmente en la recuperación de información para representar tanto consultas como documentos. Por ejemplo, el modelo de espacio vectorial asume que tanto la consulta como los documentos se representan como vectores de términos y que la puntuación de un documento con respecto a una consulta se calcula en función de la similitud entre el vector de la consulta y el vector del documento [21]. En un enfoque de modelado de lenguaje, también podemos considerar el modelo de lenguaje unigrama de consulta [12, 29] o el modelo de relevancia [14] como una representación vectorial de términos de la necesidad de información de los usuarios. Intuitivamente, x asignaría pesos altos a los términos que caracterizan los temas que interesan al usuario. El segundo componente que podemos incluir en nuestro modelo de usuario son los documentos que el usuario ya ha visto. Obviamente, incluso si un documento es relevante, si el usuario ya ha visto el documento, no sería útil presentar el mismo documento de nuevo. Por lo tanto, introducimos otra variable S ⊂ D (D es el conjunto completo de documentos en la colección) para denotar el subconjunto de documentos en los resultados de búsqueda que el usuario ya ha visto. En general, en el tiempo t, podemos representar un modelo de usuario como mt = (S, x, At, Rt−1), donde S son los documentos vistos, x es la comprensión del sistema de la necesidad de información del usuario, y (At, Rt−1) representa el historial de interacción del usuario. Ten en cuenta que un modelo de usuario aún más general también puede incluir otros factores como el nivel de lectura y la ocupación de los usuarios. Si asumimos que la incertidumbre de un modelo de usuario mt se debe únicamente a la incertidumbre de x, el cálculo de nuestra estimación actual del modelo de usuario m∗ t implicará principalmente calcular nuestra mejor estimación de x. Es decir, el sistema elegiría una respuesta de acuerdo a r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) donde x∗ = argmaxx P(x|U, D, At, Rt−1). Este es el mecanismo de decisión implementado en el sistema UCAIR que se describirá más adelante. En este sistema, evitamos especificar el modelo probabilístico P(x|U, D, At, Rt−1) calculando x∗ directamente con algún método de retroalimentación existente. 3.3 Funciones de pérdida La definición exacta de la función de pérdida L depende de las respuestas, por lo que es inevitablemente específica de la aplicación. Ahora discutimos brevemente algunas posibilidades cuando la respuesta es clasificar todos los documentos no vistos y presentar los mejores k de ellos. Sea r = (d1, ..., dk) los k documentos principales, S el conjunto de documentos vistos por el usuario, y x∗ la mejor suposición del sistema sobre la necesidad de información del usuario. Podemos definir simplemente la pérdida asociada con r como la suma negativa de la probabilidad de que cada uno de los di sea relevante, es decir, L(a, r, m) = − k i=1 P(relevante|di, m). Claramente, para minimizar esta función de pérdida, la respuesta óptima r contendría los k documentos con la probabilidad más alta de relevancia, lo cual es intuitivamente razonable. Una deficiencia de esta función de pérdida top-k es que no es sensible al orden interno de los documentos top k seleccionados, por lo que cambiar el orden de clasificación de un documento no relevante y uno relevante no afectaría la pérdida, lo cual es irrazonable. Para modelar el ranking, podemos introducir un factor del modelo de usuario: la probabilidad de que cada uno de los k documentos sea visto por el usuario, P(vista|di), y definir la siguiente función de pérdida de ranking: L(a, r, m) = − k i=1 P(vista|di)P(relevante|di, m). Dado que, en general, si di está clasificado por encima de dj (es decir, i < j), P(vista|di) > P(vista|dj), esta función de pérdida favorecería una decisión de clasificar documentos relevantes por encima de los no relevantes, ya que de lo contrario, siempre podríamos intercambiar di con dj para reducir el valor de pérdida. Por lo tanto, el sistema simplemente debería realizar una recuperación regular y clasificar los documentos según la probabilidad de relevancia [18]. Dependiendo de las preferencias de recuperación de los usuarios, puede haber muchas otras posibilidades. Por ejemplo, si el usuario no desea ver documentos redundantes, la función de pérdida debería incluir alguna medida de redundancia en r basada en los documentos ya vistos S. Por supuesto, cuando la respuesta no es elegir una lista clasificada de documentos, necesitaríamos una función de pérdida diferente. Discutimos un ejemplo relevante para el agente de búsqueda que implementamos. Cuando un usuario ingresa una consulta qt (acción actual), nuestro agente de búsqueda se basa en algún motor de búsqueda existente para llevar a cabo la búsqueda en realidad. En tal caso, aunque el agente de búsqueda no tenga control sobre el algoritmo de recuperación, aún puede intentar optimizar los resultados de la búsqueda refinando la consulta enviada al motor de búsqueda y/o reordenando los resultados obtenidos del motor de búsqueda. Las funciones de pérdida para el reordenamiento ya fueron discutidas anteriormente; ahora echamos un vistazo a las funciones de pérdida para el refinamiento de consultas. Sea f la función de recuperación del motor de búsqueda que nuestro agente utiliza, de modo que f(q) nos daría los resultados de búsqueda utilizando la consulta q. Dado que la acción actual del usuario es ingresar una consulta qt (es decir, at = qt), nuestra respuesta sería f(q) para algún q. Dado que no tenemos elección de f, nuestra decisión es elegir un buen q. Formalmente, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) lo cual muestra que nuestro objetivo es encontrar q∗ = argminqL(qt, f(q), m), es decir, una consulta óptima que nos daría el mejor f(q). Una elección diferente de la función de pérdida L(qt, f(q), m) llevaría a una estrategia de refinamiento de consulta diferente. En UCAIR, calculamos heurísticamente q∗ expandiendo qt con términos extraídos de rt−1 siempre que qt−1 y qt tengan una alta similitud. Se debe tener en cuenta que rt−1 y qt−1 están contenidos en m como parte del historial de interacción de los usuarios. 3.4 Modelado implícito del usuario El modelado implícito del usuario se captura en nuestro marco a través del cálculo de x∗ = argmaxx P(x|U, D, At, Rt−1), es decir, la creencia actual del sistema sobre cuál es la necesidad de información del usuario. Aquí nuevamente puede haber muchas posibilidades, lo que lleva a diferentes algoritmos para la modelización implícita del usuario. Ahora discutimos algunos de ellos. Primero, cuando dos consultas consecutivas están relacionadas, la consulta anterior puede ser explotada para enriquecer la consulta actual y proporcionar más contexto de búsqueda para ayudar en la desambiguación. Para este propósito, en lugar de realizar una expansión de consulta como lo hicimos en la sección anterior, también podríamos calcular un x∗ actualizado basado en la consulta anterior y los resultados de recuperación. El modelo de usuario nuevo calculado puede luego ser utilizado para clasificar los documentos con un modelo estándar de recuperación de información. Segundo, también podemos inferir los intereses de un usuario basándonos en los resúmenes de los documentos visualizados. Cuando a un usuario se le presenta una lista de resúmenes de documentos mejor clasificados, si el usuario elige saltarse los primeros n documentos y ver el documento (n+1)-ésimo, podemos inferir que el usuario no está interesado en los resúmenes mostrados para los primeros n documentos, pero está atraído por el resumen mostrado del documento (n+1)-ésimo. Por lo tanto, podemos usar estos resúmenes como ejemplos negativos y positivos para aprender un modelo de usuario más preciso x∗. Aquí se pueden explotar muchas técnicas estándar de retroalimentación de relevancia [19, 20]. Ten en cuenta que debemos utilizar los resúmenes mostrados, en lugar de los contenidos reales de esos documentos, ya que es posible que el resumen mostrado del documento visto sea relevante, pero el contenido del documento en realidad no lo sea. Del mismo modo, un resumen mostrado puede llevar a un usuario a omitir un documento relevante. Inferir modelos de usuario basados en dicha información mostrada, en lugar del contenido real de un documento, es una diferencia importante entre UCAIR y algunos otros sistemas similares. En UCAIR, ambas estrategias para inferir un modelo de usuario implícito están implementadas. 4. UCAIR: Un agente de búsqueda personalizado 4.1 Diseño En esta sección, presentamos un agente de búsqueda web del lado del cliente llamado UCAIR, en el cual implementamos algunos de los métodos discutidos en la sección anterior para realizar búsquedas personalizadas a través de modelado implícito del usuario. UCAIR es un complemento del navegador web que actúa como proxy para los motores de búsqueda en la web. Actualmente, solo está implementado para Internet Explorer y Google, pero es cuestión de ingeniería hacer que funcione en otros navegadores web e interactúe con otros motores de búsqueda. El tema de la privacidad es un obstáculo principal para implementar cualquier aplicación del mundo real que involucre modelado de usuarios serio, como la búsqueda personalizada. Por esta razón, UCAIR funciona estrictamente como un agente de búsqueda del lado del cliente, en lugar de ser una aplicación del lado del servidor. De esta manera, la información del usuario capturada siempre permanece en la computadora que está utilizando el usuario, por lo tanto, el usuario no necesita revelar ninguna información al exterior. La personalización del lado del cliente también permite que el sistema observe fácilmente una gran cantidad de información del usuario que puede no estar fácilmente disponible para un servidor. Además, realizar búsquedas personalizadas en el lado del cliente es más escalable que en el lado del servidor, ya que la sobrecarga de cálculo y almacenamiento se distribuye entre los clientes. Como se muestra en la Figura 1, la barra de herramientas UCAIR tiene 3 componentes principales: (1) El módulo de modelado de usuario (implícito) captura el contexto de búsqueda de un usuario e información de historial, incluidas las consultas enviadas y los resultados de búsqueda clicados, e infiere los límites de la sesión de búsqueda. (2) El módulo de modificación de consultas mejora selectivamente la formulación de la consulta de acuerdo con el modelo de usuario actual. (3) El módulo de reordenamiento de resultados reordena inmediatamente cualquier resultado de búsqueda no visto cada vez que se actualiza el modelo de usuario. En UCAIR, consideramos cuatro acciones básicas de usuario: (1) enviar una consulta de palabras clave; (2) ver un documento; (3) hacer clic en el botón Atrás; (4) hacer clic en el enlace Siguiente en una página de resultados. Para cada una de estas cuatro acciones, el sistema responde con, respectivamente, (1) 1 UCAIR está disponible en: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Registro de Historial de Búsqueda del Motor de Búsqueda (por ejemplo, Google) (consultas pasadas, resultados clicados) Modificación de Consulta Resultado de Reclasificación Modelo de Usuario Buffer de Resultados de Consulta de Usuario UCAIR... Figura 1: arquitectura de UCAIR generando una lista clasificada de resultados enviando una consulta posiblemente ampliada a un motor de búsqueda; (2) actualizando el modelo de necesidad de información x; (3) reordenando los resultados no vistos en la página de resultados actual basándose en el modelo actual x; y (4) reordenando las páginas no vistas y generando la siguiente página de resultados basándose en el modelo actual x. Detrás de estas respuestas, hay tres tareas básicas: (1) Decidir si la consulta anterior está relacionada con la consulta actual y, de ser así, ampliar la consulta actual con términos útiles de la consulta anterior o los resultados de la consulta anterior. (2) Actualizar el modelo de necesidad de información x basado en un resumen de documento recién seleccionado. (3) Reordenar un conjunto de documentos no vistos basado en el modelo x actual. A continuación describimos nuestros algoritmos para cada uno de ellos. 4.2 Detección de límites de sesión y expansión de consultas Para explotar eficazmente las consultas anteriores y su información correspondiente de clics, UCAIR necesita determinar si dos consultas adyacentes pertenecen a la misma sesión de búsqueda (es decir, detectar los límites de sesión). El trabajo existente sobre la detección de límites de sesión se encuentra principalmente en el contexto del análisis de registros web (por ejemplo, [8]), y utiliza información estadística en lugar de características textuales. Dado que nuestro agente del lado del cliente no tiene acceso a los registros de consultas del servidor, tomamos decisiones sobre los límites de sesión basadas en la similitud textual entre dos consultas. Debido a que las consultas relacionadas no necesariamente comparten las mismas palabras (por ejemplo, isla de Java y viajar a Indonesia), no es suficiente utilizar solo el texto de la consulta. Por lo tanto, utilizamos los resultados de búsqueda de las dos consultas para ayudar a decidir si están relacionadas temáticamente. Por ejemplo, para las consultas anteriores \"java island\" y \"travel Indonesia\", las palabras \"java\", \"bali\", \"island\", \"indonesia\" y \"travel\" pueden aparecer con frecuencia en los resultados de búsqueda de ambas consultas, lo que produce un alto puntaje de similitud. Solo utilizamos los títulos y resúmenes de los resultados de búsqueda para calcular la similitud, ya que están disponibles en la página de resultados de búsqueda recuperada y obtener el texto completo de cada página de resultados ralentizaría significativamente el proceso. Para compensar la concisión de los títulos y resúmenes, recuperamos más resultados de los que un usuario normalmente vería con el propósito de detectar los límites de sesión (típicamente 50 resultados). La similitud entre la consulta anterior q y la consulta actual q se calcula de la siguiente manera. Sean {s1, s2, . . . , sn} y {s1, s2, . . . , sn} los conjuntos de resultados de las dos consultas. Utilizamos la fórmula de ponderación TF-IDF normalizada pivotada [24] para calcular un vector de peso de término si para cada resultado si. Definimos el resultado promedio savg como el centroide de todos los vectores de resultado, es decir, (s1 + s2 + . . . + sn)/n. La similitud del coseno entre los dos resultados promedio se calcula como s avg · savg/ s 2 avg · s2 avg. Si el valor de similitud supera un umbral predefinido, se considerará que las dos consultas están en la misma sesión de información. Si se determina que la consulta anterior y la consulta actual pertenecen a la misma sesión de búsqueda, UCAIR intentaría expandir la consulta actual con términos de la consulta anterior y sus resultados de búsqueda. Específicamente, para cada término en la consulta anterior o los resultados de búsqueda correspondientes, si su frecuencia en los resultados de la consulta actual es mayor que un umbral preestablecido (por ejemplo, 5 resultados de 50), el término se agregaría a la consulta actual para formar una consulta ampliada. En este caso, UCAIR enviaría esta consulta ampliada en lugar de la original al motor de búsqueda y devolvería los resultados correspondientes a la consulta ampliada. Actualmente, UCAIR solo utiliza la consulta inmediatamente anterior para la expansión de consultas; en principio, podríamos aprovechar todas las consultas pasadas relacionadas. 4.3 Actualización del modelo de necesidad de información Supongamos que en el tiempo t, hemos observado que el usuario ha visto k documentos cuyos resúmenes son s1, ..., sk. Actualizamos nuestro modelo de usuario calculando un nuevo vector de necesidad de información con un método estándar de retroalimentación en la recuperación de información (es decir, Rocchio [19]). Según el modelo de recuperación de espacio vectorial, cada resumen clicado si puede ser representado por un vector de pesos de términos si, con cada término ponderado por una fórmula de ponderación TF-IDF [21]. Rocchio calcula el vector centroide de todos los resúmenes e interpola este con el vector de consulta original para obtener un vector de términos actualizado. Es decir, x = αq + (1 − α) 1 k k i=1 si donde q es el vector de consulta, k es el número de resúmenes que el usuario hace clic inmediatamente después de la consulta actual y α es un parámetro que controla la influencia de los resúmenes clicados en el modelo de necesidad de información inferida. En nuestros experimentos, α se establece en 0.5. Ten en cuenta que actualizamos el modelo de información necesario cada vez que el usuario ve un documento. 4.4 Reclasificación de resultados En general, queremos volver a clasificar todos los resultados no vistos tan pronto como se actualice el modelo de usuario. Actualmente, UCAIR implementa el reordenamiento en dos casos, correspondientes a cuando el usuario hace clic en el botón Atrás y en el enlace Siguiente en Internet Explorer. En ambos casos, el modelo de usuario actualizado se utilizaría para reordenar los resultados no vistos de manera que el usuario vea resultados de búsqueda mejorados de inmediato. Para volver a clasificar cualquier resumen de documento no visto, UCAIR utiliza el modelo estándar de recuperación de espacio vectorial y puntúa cada resumen en función de la similitud del resultado y el vector de necesidad de información actual del usuario x [21]. Dado que la retroalimentación implícita no es completamente confiable, presentamos solo un pequeño número (por ejemplo, 5) de los resultados reordenados más altos para ser seguidos por cualquier resultado originalmente clasificado alto. 828 resultados de Google (consulta del usuario = mapa de Java) Resultados de UCAIR (consulta del usuario = mapa de Java) consulta anterior = viajar a Indonesia consulta anterior = tabla hash consulta del usuario ampliada = mapa de Java Indonesia consulta del usuario ampliada = clase de mapa de Java 1 Proyecciones de mapas de Java del mundo ... Lonely Planet - Mapa de Indonesia Mapa (Plataforma Java SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Proyecciones de mapas de Java del mundo ... TURISMO DE INDONESIA: JAVA CENTRAL - MAPA Plataforma Java SE v1.3.1: Interfaz de Mapa www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Mapa de Java TURISMO DE INDONESIA: JAVA OESTE - MAPA Una introducción a las clases de colección de mapas de Java java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Mapa de Tecnología Java IndoStreets - Mapa de Java Una introducción a las clases de colección de mapas de Java java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Regiones e islas de Indonesia Mapas, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 Una introducción a las clases de colección de mapas de Java Mapa de calles de la ciudad de Indonesia,... Hibernate simplifica el mapeo de herencia www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Mapa de Java Mapas de Indonesia jerarquía de clases de tmap 30.map www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Mapa de API de Java Mapas de Indonesia por Peter Loud Alcance de clases www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas: Mapas de Sam de Indonesia por Peter Loud PrintSafeHashMap de la clase www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 TURISMO DE INDONESIA: JAVA OESTE - MAPA indonesiaphoto.com Java Pro - Unión y mapeo vertical de clases www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Tabla 1: Resultados de muestra de la expansión de la consulta EVALUACIÓN DE UCAIR Ahora presentamos algunos resultados sobre la evaluación de las dos principales funciones de UCAIR: la expansión selectiva de consultas y la reordenación de resultados basada en los datos de clics de los usuarios. 5.1 Resultados de muestra La estrategia de expansión de consultas implementada en UCAIR es intencionalmente conservadora para evitar la interpretación errónea de los modelos implícitos de los usuarios. En la práctica, cada vez que decide expandir la consulta, la expansión suele tener sentido. En la Tabla 1, mostramos cómo UCAIR puede distinguir exitosamente dos contextos de búsqueda diferentes para la consulta java map, correspondientes a dos consultas previas distintas (es decir, viajar a Indonesia vs. hashtable). Debido a la modelización implícita del usuario, UCAIR descubre inteligentemente agregar Indonesia y clase, respectivamente, a la consulta de los usuarios sobre el mapa de Java, lo cual de otro modo sería ambiguo, como se muestra en los resultados originales de Google el 21 de marzo de 2005. Los resultados de UCAIR son mucho más precisos que los resultados de Google y reflejan la personalización en la búsqueda. El componente de retroalimentación implícita entusiasta está diseñado para responder inmediatamente a la actividad de un usuario, como por ejemplo, al visualizar un documento. En la Figura 2, mostramos cómo UCAIR puede desambiguar con éxito una consulta ambigua de jaguar al explotar un resumen del documento visualizado. En este caso, los resultados iniciales de recuperación utilizando \"jaguar\" (mostrados en el lado izquierdo) contienen dos resultados sobre los autos Jaguar seguidos por dos resultados sobre el software Jaguar. Sin embargo, después de que el usuario ve el contenido de la página web del segundo resultado (sobre el automóvil Jaguar) y regresa a la página de resultados de búsqueda haciendo clic en el botón Atrás, UCAIR automáticamente selecciona dos nuevos resultados de búsqueda sobre automóviles Jaguar (mostrados en el lado derecho), mientras que los dos resultados originales sobre software de Jaguar se desplazan hacia abajo en la lista (no se ven en la imagen). 5.2 Evaluación cuantitativa Para evaluar UCAIR de manera cuantitativa, realizamos un estudio de usuario sobre la efectividad del componente de retroalimentación implícita ansiosa. Es un desafío evaluar cuantitativamente la mejora potencial en el rendimiento de nuestro modelo propuesto y UCAIR sobre Google de manera imparcial [7]. Aquí diseñamos un estudio de usuarios, en el cual los participantes realizarían una búsqueda web normal y evaluarían al azar y de forma anónima un conjunto de resultados mezclados de Google y UCAIR al final de la sesión de búsqueda; los participantes no saben si un resultado proviene de Google o de UCAIR. Reclutamos a 6 estudiantes de posgrado para este estudio de usuarios, quienes tienen diferentes antecedentes (3 en informática, 2 en biología y 1 en química). Los documentos que describen leyes para limitar el correo no deseado sin dar detalles de demandas judiciales o juicios penales no son relevantes. Utilizamos los temas de consulta de la pista Terabyte TREC 2 2004 [2] y la tarea de destilación de temas de la pista web TREC 2003 [4] de la manera que se describirá a continuación. Un ejemplo de tema del TREC 2004 Terabyte track aparece en la Figura 3. El título es una frase corta y puede ser utilizada como una consulta al sistema de recuperación. El campo de descripción proporciona una declaración ligeramente más larga del requisito del tema, generalmente expresado como una sola oración completa o pregunta. Finalmente, la narrativa proporciona información adicional necesaria para especificar completamente el requisito, expresado en forma de un breve párrafo. Inicialmente, cada participante exploraría 50 temas ya sea de la categoría Terabyte o de la categoría Web y elegiría los 5 o 7 temas más interesantes. Para cada tema seleccionado, el participante básicamente realizaría la búsqueda web normal utilizando UCAIR para encontrar muchas páginas web relevantes utilizando el título del tema de la consulta como la palabra clave inicial de la consulta. Durante este proceso, el participante puede ver los resultados de la búsqueda y posiblemente hacer clic en algunos interesantes para ver las páginas web, tal como en una búsqueda web normal. No hay ningún requisito o restricción sobre cuántas consultas debe enviar el participante o cuándo debe detener la búsqueda de un tema. Cuando el participante planea cambiar el tema de búsqueda, simplemente presionará un botón 2 de la Conferencia de Recuperación de Texto: http://trec.nist.gov/ 829 Figura 2: Capturas de pantalla para volver a clasificar los resultados y evaluar los resultados de búsqueda antes de cambiar al siguiente tema. En el momento de la evaluación, los 30 resultados mejor clasificados de Google y UCAIR (algunos se superponen) se mezclan aleatoriamente para que el participante no sepa si un resultado proviene de Google o de UCAIR. El participante luego juzgaría la relevancia de estos resultados. Medimos la precisión en los primeros n (n = 5, 10, 20, 30) documentos de Google y UCAIR. También evaluamos precisiones en diferentes niveles de recuperación. En total, 368 documentos fueron considerados relevantes a partir de los resultados de búsqueda de Google y 429 documentos fueron considerados relevantes por los participantes de UCAIR. Los diagramas de dispersión de precisión en los 10 y 20 documentos principales se muestran en la Figura 4 y la Figura 5 respectivamente (El diagrama de dispersión de precisión en los 30 documentos principales es muy similar al de los 20 documentos principales). Cada punto de los gráficos de dispersión representa las precisiones de Google y UCAIR en un tema de consulta. La Tabla 2 muestra la precisión promedio en los primeros n documentos entre 32 temas. A partir de la Figura 4, la Figura 5 y la Tabla 2, vemos que los resultados de búsqueda de UCAIR son consistentemente mejores que los de Google en todas las medidas. Además, la mejora en el rendimiento es más dramática para la precisión en los primeros 20 documentos que para la precisión en los primeros 10 documentos. Una explicación para esto es que cuanto más interacción tenga el usuario con el sistema, más datos de clics se espera que UCAIR pueda recopilar. Por lo tanto, el sistema de recuperación puede construir modelos de usuario implícitos más precisos, lo que conduce a una mayor precisión en la recuperación. El Método de Clasificación prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Mejora 8.0% 17.8% 20.2% 21.8% Tabla 2: Tabla de precisión promedio en los primeros n documentos para 32 temas de consulta El gráfico en la Figura 6 muestra las curvas de precisión-recuperación para UCAIR y Google, donde se observa claramente que el rendimiento de UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Gráfico de dispersión de Precisión en los 10 primeros documentos Figura 4: La precisión en los 10 primeros documentos de UCAIR y Google es consistentemente y considerablemente mejor que la de Google en todos los niveles de recuperación. 6. CONCLUSIONES En este artículo, estudiamos cómo aprovechar la modelización implícita del usuario para personalizar de manera inteligente la recuperación de información y mejorar la precisión de la búsqueda. A diferencia de la mayoría de trabajos anteriores, enfatizamos el uso del contexto de búsqueda inmediata y la información de retroalimentación implícita, así como la actualización rápida de los resultados de búsqueda para beneficiar al máximo a un usuario. Presentamos un marco de trabajo de toma de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos adecuados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para volver a clasificar inmediatamente cualquier documento que aún no haya sido visto por el usuario. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente (UCAIR) sobre un motor de búsqueda popular (Google). Los experimentos en la búsqueda web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en más de un 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Gráfico de dispersión de Precisión en los 20 documentos principales Figura 5: Precisión en los 20 documentos principales de UCAIR y Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 precisión recall Curvas de Precisión-Recall Resultado de Google Resultado de UCAIR Figura 6: Precisión en los 20 resultados principales de UCAIR y Google Google. Dado que la información implícita que aprovechamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional. El agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin necesidad de esfuerzo adicional por parte del usuario. AGRADECIMIENTO Agradecemos a los seis participantes de nuestros experimentos de evaluación. Este trabajo fue apoyado en parte por las subvenciones de la Fundación Nacional de Ciencias IIS-0347933 e IIS-0428472. REFERENCIAS [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman y O. Frieder. Análisis por hora de un registro de consultas web muy grande categorizado por tema. En Actas de SIGIR 2004, páginas 321-328, 2004. [2] C. Clarke, N. Craswell e I. Soboroff. Resumen de la pista de terabyte TREC 2004. En Actas de TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda y D. Brown. Indicadores implícitos de interés. En Actas de Interfaces de Usuario Inteligentes 2001, páginas 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson y M. Wu. Resumen de la pista web TREC 2003. En Actas de TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend y V. Larvrenko. Retroalimentación de relevancia y personalización: Una perspectiva de modelado del lenguaje. En Actas del Segundo Taller DELOS: Personalización y Sistemas de Recomendación en Bibliotecas Digitales, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite y D. Harman. Resultados y desafíos en la evaluación de búsqueda en la web. Redes de Computadoras, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A. An, y D. Schuurmans. Identificación dinámica de sesiones de registro web con modelos de lenguaje estadístico. Revista de la Sociedad Americana de Ciencia de la Información y Tecnología, 55(14):1290-1303, 2004. [9] G. Jeh y J. Widom. Escalando la búsqueda web personalizada. En Actas de WWW 2003, páginas 271-279, 2003. [10] T. Joachims. Optimización de motores de búsqueda utilizando datos de clics. En Actas de SIGKDD 2002, páginas 133-142, 2002. [11] D. Kelly y J. Teevan. Retroalimentación implícita para inferir preferencias de usuario: Una bibliografía. SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En Actas de SIGIR01, páginas 111-119, 2001. [13] T. Lau y E. Horvitz. Patrones de búsqueda: Análisis y modelado de la refinación de consultas web. En Actas de la Séptima Conferencia Internacional sobre Modelado de Usuarios (UM), páginas 145-152, 1999. [14] V. Lavrenko y B. Croft. Modelos de lenguaje basados en relevancia. En Actas de SIGIR01, páginas 120-127, 2001. [15] M. Mitra, A. Singhal y C. Buckley. Mejorando la expansión automática de consultas. En Actas de SIGIR 1998, páginas 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg. Según Google, así va la nación. New York Times, mayo de 2003. [18] S. E. Robertson. El principio de clasificación de probabilidad en ı˚. Revista de Documentación, 33(4):294-304, 1977. [19] J. J. Rocchio. Retroalimentación de relevancia en la recuperación de información. En el Sistema de Recuperación SMART: Experimentos en el Procesamiento Automático de Documentos, páginas 313-323. Prentice-Hall Inc., 1971. [20] G. Salton y C. Buckley. Mejorando el rendimiento de recuperación mediante retroalimentación de recuperación. Revista de la Sociedad Americana de Ciencia de la Información, 41(4):288-297, 1990. [21] G. Salton y M. J. McGill. Introducción a la Recuperación de Información Moderna. McGraw-Hill, 1983. [22] X. Shen, B. Tan y C. Zhai. Recuperación de información sensible al contexto utilizando retroalimentación implícita. En Actas de SIGIR 2005, páginas 43-50, 2005. [23] X. Shen y C. Zhai. Explotando el historial de consultas para la clasificación de documentos en la recuperación de información interactiva (Póster). En Actas de SIGIR 2003, páginas 377-378, 2003. [24] A. Singhal. Recuperación de información moderna: Una breve visión general. Boletín del Comité Técnico de Ingeniería de Datos de la Sociedad de Computación de IEEE, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano y M. Yoshikawa. Búsqueda web adaptativa basada en el perfil del usuario construido sin ningún esfuerzo por parte de los usuarios. En Actas de WWW 2004, páginas 675-684, 2004. [26] E. Volokh. Personalización y privacidad. Comunicaciones de la ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen e I. Ruthven. Un estudio simulado de modelos de retroalimentación implícita. En Actas de ECIR 2004, páginas 311-326, 2004. [28] J. Xu y W. B. Croft. Expansión de consultas utilizando análisis local y global de documentos. En Actas de SIGIR 1996, páginas 4-11, 1996. [29] C. Zhai y J. Lafferty. Modelo de retroalimentación basado en el modelo de recuperación de divergencia de KL. En Actas de la CIKM 2001, páginas 403-410, 2001. 831 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "personalized web search": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Implicit User Modeling for Personalized Search Xuehua Shen, Bin Tan, ChengXiang Zhai Department of Computer Science University of Illinois at Urbana-Champaign ABSTRACT Information retrieval systems (e.g., web search engines) are critical for overcoming information overload.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users, resulting in inherently non-optimal retrieval performance.",
                "For example, a tourist and a programmer may use the same word java to search for different information, but the current search systems would return the same results.",
                "In this paper, we study how to infer a users interest from the users search context and use the inferred implicit user model for personalized search .",
                "We present a decision theoretic framework and develop techniques for implicit user modeling in information retrieval.",
                "We develop an intelligent client-side web search agent (UCAIR) that can perform eager implicit feedback, e.g., query expansion based on previous queries and immediate result reranking based on clickthrough information.",
                "Experiments on web search show that our search agent can improve search accuracy over the popular Google search engine.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models, Relevance feedback, Search Process General Terms Algorithms 1.",
                "INTRODUCTION Although many information retrieval systems (e.g., web search engines and digital library systems) have been successfully deployed, the current retrieval systems are far from optimal.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users [17].",
                "This inherent non-optimality is seen clearly in the following two cases: (1) Different users may use exactly the same query (e.g., Java) to search for different information (e.g., the Java island in Indonesia or the Java programming language), but existing IR systems return the same results for these users.",
                "Without considering the actual user, it is impossible to know which sense Java refers to in a query. (2) A users information needs may change over time.",
                "The same user may use Java sometimes to mean the Java island in Indonesia and some other times to mean the programming language.",
                "Without recognizing the search context, it would be again impossible to recognize the correct sense.",
                "In order to optimize retrieval accuracy, we clearly need to model the user appropriately and personalize search according to each individual user.",
                "The major goal of user modeling for information retrieval is to accurately model a users information need, which is, unfortunately, a very difficult task.",
                "Indeed, it is even hard for a user to precisely describe what his/her information need is.",
                "What information is available for a system to infer a users information need?",
                "Obviously, the users query provides the most direct evidence.",
                "Indeed, most existing retrieval systems rely solely on the query to model a users information need.",
                "However, since a query is often extremely short, the user model constructed based on a keyword query is inevitably impoverished .",
                "An effective way to improve user modeling in information retrieval is to ask the user to explicitly specify which documents are relevant (i.e., useful for satisfying his/her information need), and then to improve user modeling based on such examples of relevant documents.",
                "This is called relevance feedback, which has been proved to be quite effective for improving retrieval accuracy [19, 20].",
                "Unfortunately, in real world applications, users are usually reluctant to make the extra effort to provide relevant examples for feedback [11].",
                "It is thus very interesting to study how to infer a users information need based on any implicit feedback information, which naturally exists through user interactions and thus does not require any extra user effort.",
                "Indeed, several previous studies have shown that implicit user modeling can improve retrieval accuracy.",
                "In [3], a web browser (Curious Browser) is developed to record a users explicit relevance ratings of web pages (relevance feedback) and browsing behavior when viewing a page, such as dwelling time, mouse click, mouse movement and scrolling (implicit feedback).",
                "It is shown that the dwelling time on a page, amount of scrolling on a page and the combination of time and scrolling have a strong correlation with explicit relevance ratings, which suggests that implicit feedback may be helpful for inferring user information need.",
                "In [10], user clickthrough data is collected as training data to learn a retrieval function, which is used to produce a customized ranking of search results that suits a group of users preferences.",
                "In [25], the clickthrough data collected over a long time period is exploited through query expansion to improve retrieval accuracy. 824 While a user may have general long term interests and preferences for information, often he/she is searching for documents to satisfy an ad-hoc information need, which only lasts for a short period of time; once the information need is satisfied, the user would generally no longer be interested in such information.",
                "For example, a user may be looking for information about used cars in order to buy one, but once the user has bought a car, he/she is generally no longer interested in such information.",
                "In such cases, implicit feedback information collected over a long period of time is unlikely to be very useful, but the immediate search context and feedback information, such as which of the search results for the current information need are viewed, can be expected to be much more useful.",
                "Consider the query Java again.",
                "Any of the following immediate feedback information about the user could potentially help determine the intended meaning of Java in the query: (1) The previous query submitted by the user is hashtable (as opposed to, e.g., travel Indonesia). (2) In the search results, the user viewed a page where words such as programming, software, and applet occur many times.",
                "To the best of our knowledge, how to exploit such immediate and short-term search context to improve search has so far not been well addressed in the previous work.",
                "In this paper, we study how to construct and update a user model based on the immediate search context and implicit feedback information and use the model to improve the accuracy of ad-hoc retrieval.",
                "In order to maximally benefit the user of a retrieval system through implicit user modeling, we propose to perform eager implicit feedback.",
                "That is, as soon as we observe any new piece of evidence from the user, we would update the systems belief about the users information need and respond with improved retrieval results based on the updated user model.",
                "We present a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "In a traditional retrieval paradigm, the retrieval problem is to match a query with documents and rank documents according to their relevance values.",
                "As a result, the retrieval process is a simple independent cycle of query and result display.",
                "In the proposed new retrieval paradigm, the users search context plays an important role and the inferred implicit user model is exploited immediately to benefit the user.",
                "The new retrieval paradigm is thus fundamentally different from the traditional paradigm, and is inherently more general.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent UCAIR (User-Centered Adaptive Information Retrieval) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "Thus the developed search agent can improve existing web search performance without additional effort from the user.",
                "The remaining sections are organized as follows.",
                "In Section 2, we discuss the related work.",
                "In Section 3, we present a decisiontheoretic interactive retrieval framework for implicit user modeling.",
                "In Section 4, we present the design and implementation of an intelligent client-side web search agent (UCAIR) that performs eager implicit feedback.",
                "In Section 5, we report our experiment results using the search agent.",
                "Section 6 concludes our work. 2.",
                "RELATED WORK Implicit user modeling for personalized search has been studied in previous work, but our work differs from all previous work in several aspects: (1) We emphasize the exploitation of immediate search context such as the related immediately preceding query and the viewed documents in the same session, while most previous work relies on long-term collection of implicit feedback information [25]. (2) We perform eager feedback and bring the benefit of implicit user modeling as soon as any new implicit feedback information is available, while the previous work mostly exploits longterm implicit feedback [10]. (3) We propose a retrieval framework to integrate implicit user modeling with the interactive retrieval process, while the previous work either studies implicit user modeling separately from retrieval [3] or only studies specific retrieval models for exploiting implicit feedback to better match a query with documents [23, 27, 22]. (4) We develop and evaluate a <br>personalized web search</br> agent with online user studies, while most existing work evaluates algorithms offline without real user interactions.",
                "Currently some search engines provide rudimentary personalization, such as Google <br>personalized web search</br> [6], which allows users to explicitly describe their interests by selecting from predefined topics, so that those results that match their interests are brought to the top, and My Yahoo! search [16], which gives users the option to save web sites they like and block those they dislike.",
                "In contrast, UCAIR personalizes web search through implicit user modeling without any additional user efforts.",
                "Furthermore, the personalization of UCAIR is provided on the client side.",
                "There are two remarkable advantages on this.",
                "First, the user does not need to worry about the privacy infringement, which is a big concern for personalized search [26].",
                "Second, both the computation of personalization and the storage of the user profile are done at the client side so that the server load is reduced dramatically [9].",
                "There have been many works studying user query logs [1] or query dynamics [13].",
                "UCAIR makes direct use of a users query history to benefit the same user immediately in the same search session.",
                "UCAIR first judges whether two neighboring queries belong to the same information session and if so, it selects terms from the previous query to perform query expansion.",
                "Our query expansion approach is similar to automatic query expansion [28, 15, 5], but instead of using pseudo feedback to expand the query, we use users implicit feedback information to expand the current query.",
                "These two techniques may be combined. 3.",
                "OPTIMIZATION IN INTERACTIVE IR In interactive IR, a user interacts with the retrieval system through an action dialogue, in which the system responds to each user action with some system action.",
                "For example, the users action may be submitting a query and the systems response may be returning a list of 10 document summaries.",
                "In general, the space of user actions and system responses and their granularities would depend on the interface of a particular retrieval system.",
                "In principle, every action of the user can potentially provide new evidence to help the system better infer the users information need.",
                "Thus in order to respond optimally, the system should use all the evidence collected so far about the user when choosing a response.",
                "When viewed in this way, most existing search engines are clearly non-optimal.",
                "For example, if a user has viewed some documents on the first page of search results, when the user clicks on the Next link to fetch more results, an existing retrieval system would still return the next page of results retrieved based on the original query without considering the new evidence that a particular result has been viewed by the user. 825 We propose to optimize retrieval performance by adapting system responses based on every action that a user has taken, and cast the optimization problem as a decision task.",
                "Specifically, at any time, the system would attempt to do two tasks: (1) User model updating: Monitor any useful evidence from the user regarding his/her information need and update the user model as soon as such evidence is available; (2) Improving search results: Rerank immediately all the documents that the user has not yet seen, as soon as the user model is updated.",
                "We emphasize eager updating and reranking, which makes our work quite different from any existing work.",
                "Below we present a formal decision theoretic framework for optimizing retrieval performance through implicit user modeling in interactive information retrieval. 3.1 A decision-theoretic framework Let A be the set of all user actions and R(a) be the set of all possible system responses to a user action a ∈ A.",
                "At any time, let At = (a1, ..., at) be the observed sequence of user actions so far (up to time point t) and Rt−1 = (r1, ..., rt−1) be the responses that the system has made responding to the user actions.",
                "The systems goal is to choose an optimal response rt ∈ R(at) for the current user action at.",
                "Let M be the space of all possible user models.",
                "We further define a loss function L(a, r, m) ∈ , where a ∈ A is a user action, r ∈ R(a) is a system response, and m ∈ M is a user model.",
                "L(a, r, m) encodes our decision preferences and assesses the optimality of responding with r when the current user model is m and the current user action is a.",
                "According to Bayesian decision theory, the optimal decision at time t is to choose a response that minimizes the Bayes risk, i.e., r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) where P(mt|U, D, At, Rt−1) is the posterior probability of the user model mt given all the observations about the user U we have made up to time t. To simplify the computation of Equation 1, let us assume that the posterior probability mass P(mt|U, D, At, Rt−1) is mostly concentrated on the mode m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "We can then approximate the integral with the value of the loss function at m∗ t .",
                "That is, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) where m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "Leaving aside how to define and estimate these probabilistic models and the loss function, we can see that such a decision-theoretic formulation suggests that, in order to choose the optimal response to at, the system should perform two tasks: (1) compute the current user model and obtain m∗ t based on all the useful information. (2) choose a response rt to minimize the loss function value L(at, rt, m∗ t ).",
                "When at does not affect our belief about m∗ t , the first step can be omitted and we may reuse m∗ t−1 for m∗ t .",
                "Note that our framework is quite general since we can potentially model any kind of user actions and system responses.",
                "In most cases, as we may expect, the systems response is some ranking of documents, i.e., for most actions a, R(a) consists of all the possible rankings of the unseen documents, and the decision problem boils down to choosing the best ranking of unseen documents based on the most current user model.",
                "When a is the action of submitting a keyword query, such a response is exactly what a current retrieval system would do.",
                "However, we can easily imagine that a more intelligent web search engine would respond to a users clicking of the Next link (to fetch more unseen results) with a more optimized ranking of documents based on any viewed documents in the current page of results.",
                "In fact, according to our eager updating strategy, we may even allow a system to respond to a users clicking of browsers Back button after viewing a document in the same way, so that the user can maximally benefit from implicit feedback.",
                "These are precisely what our UCAIR system does. 3.2 User models A user model m ∈ M represents what we know about the user U, so in principle, it can contain any information about the user that we wish to model.",
                "We now discuss two important components in a user model.",
                "The first component is a component model of the users information need.",
                "Presumably, the most important factor affecting the optimality of the systems response is how well the response addresses the users information need.",
                "Indeed, at any time, we may assume that the system has some belief about what the user is interested in, which we model through a term vector x = (x1, ..., x|V |), where V = {w1, ..., w|V |} is the set of all terms (i.e., vocabulary) and xi is the weight of term wi.",
                "Such a term vector is commonly used in information retrieval to represent both queries and documents.",
                "For example, the vector-space model, assumes that both the query and the documents are represented as term vectors and the score of a document with respect to a query is computed based on the similarity between the query vector and the document vector [21].",
                "In a language modeling approach, we may also regard the query unigram language model [12, 29] or the relevance model [14] as a term vector representation of the users information need.",
                "Intuitively, x would assign high weights to terms that characterize the topics which the user is interested in.",
                "The second component we may include in our user model is the documents that the user has already viewed.",
                "Obviously, even if a document is relevant, if the user has already seen the document, it would not be useful to present the same document again.",
                "We thus introduce another variable S ⊂ D (D is the whole set of documents in the collection) to denote the subset of documents in the search results that the user has already seen/viewed.",
                "In general, at time t, we may represent a user model as mt = (S, x, At, Rt−1), where S is the seen documents, x is the systems understanding of the users information need, and (At, Rt−1) represents the users interaction history.",
                "Note that an even more general user model may also include other factors such as the users reading level and occupation.",
                "If we assume that the uncertainty of a user model mt is solely due to the uncertainty of x, the computation of our current estimate of user model m∗ t will mainly involve computing our best estimate of x.",
                "That is, the system would choose a response according to r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) where x∗ = argmaxx P(x|U, D, At, Rt−1).",
                "This is the decision mechanism implemented in the UCAIR system to be described later.",
                "In this system, we avoided specifying the probabilistic model P(x|U, D, At, Rt−1) by computing x∗ directly with some existing feedback method. 3.3 Loss functions The exact definition of loss function L depends on the responses, thus it is inevitably application-specific.",
                "We now briefly discuss some possibilities when the response is to rank all the unseen documents and present the top k of them.",
                "Let r = (d1, ..., dk) be the top k documents, S be the set of seen documents by the user, and x∗ be the systems best guess of the users information need.",
                "We 826 may simply define the loss associated with r as the negative sum of the probability that each of the di is relevant, i.e., L(a, r, m) = − k i=1 P(relevant|di, m).",
                "Clearly, in order to minimize this loss function, the optimal response r would contain the k documents with the highest probability of relevance, which is intuitively reasonable.",
                "One deficiency of this top-k loss function is that it is not sensitive to the internal order of the selected top k documents, so switching the ranking order of a non-relevant document and a relevant one would not affect the loss, which is unreasonable.",
                "To model ranking, we can introduce a factor of the user model - the probability of each of the k documents being viewed by the user, P(view|di), and define the following ranking loss function: L(a, r, m) = − k i=1 P(view|di)P(relevant|di, m) Since in general, if di is ranked above dj (i.e., i < j), P(view|di) > P(view|dj), this loss function would favor a decision to rank relevant documents above non-relevant ones, as otherwise, we could always switch di with dj to reduce the loss value.",
                "Thus the system should simply perform a regular retrieval and rank documents according to the probability of relevance [18].",
                "Depending on the users retrieval preferences, there can be many other possibilities.",
                "For example, if the user does not want to see redundant documents, the loss function should include some redundancy measure on r based on the already seen documents S. Of course, when the response is not to choose a ranked list of documents, we would need a different loss function.",
                "We discuss one such example that is relevant to the search agent that we implement.",
                "When a user enters a query qt (current action), our search agent relies on some existing search engine to actually carry out search.",
                "In such a case, even though the search agent does not have control of the retrieval algorithm, it can still attempt to optimize the search results through refining the query sent to the search engine and/or reranking the results obtained from the search engine.",
                "The loss functions for reranking are already discussed above; we now take a look at the loss functions for query refinement.",
                "Let f be the retrieval function of the search engine that our agent uses so that f(q) would give us the search results using query q.",
                "Given that the current action of the user is entering a query qt (i.e., at = qt), our response would be f(q) for some q.",
                "Since we have no choice of f, our decision is to choose a good q.",
                "Formally, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) which shows that our goal is to find q∗ = argminqL(qt, f(q), m), i.e., an optimal query that would give us the best f(q).",
                "A different choice of loss function L(qt, f(q), m) would lead to a different query refinement strategy.",
                "In UCAIR, we heuristically compute q∗ by expanding qt with terms extracted from rt−1 whenever qt−1 and qt have high similarity.",
                "Note that rt−1 and qt−1 are contained in m as part of the users interaction history. 3.4 Implicit user modeling Implicit user modeling is captured in our framework through the computation of x∗ = argmaxx P(x|U, D, At, Rt−1), i.e., the systems current belief of what the users information need is.",
                "Here again there may be many possibilities, leading to different algorithms for implicit user modeling.",
                "We now discuss a few of them.",
                "First, when two consecutive queries are related, the previous query can be exploited to enrich the current query and provide more search context to help disambiguation.",
                "For this purpose, instead of performing query expansion as we did in the previous section, we could also compute an updated x∗ based on the previous query and retrieval results.",
                "The computed new user model can then be used to rank the documents with a standard information retrieval model.",
                "Second, we can also infer a users interest based on the summaries of the viewed documents.",
                "When a user is presented with a list of summaries of top ranked documents, if the user chooses to skip the first n documents and to view the (n+1)-th document, we may infer that the user is not interested in the displayed summaries for the first n documents, but is attracted by the displayed summary of the (n + 1)-th document.",
                "We can thus use these summaries as negative and positive examples to learn a more accurate user model x∗ .",
                "Here many standard relevance feedback techniques can be exploited [19, 20].",
                "Note that we should use the displayed summaries, as opposed to the actual contents of those documents, since it is possible that the displayed summary of the viewed document is relevant, but the document content is actually not.",
                "Similarly, a displayed summary may mislead a user to skip a relevant document.",
                "Inferring user models based on such displayed information, rather than the actual content of a document is an important difference between UCAIR and some other similar systems.",
                "In UCAIR, both of these strategies for inferring an implicit user model are implemented. 4.",
                "UCAIR: A PERSONALIZED SEARCH AGENT 4.1 Design In this section, we present a client-side web search agent called UCAIR, in which we implement some of the methods discussed in the previous section for performing personalized search through implicit user modeling.",
                "UCAIR is a web browser plug-in 1 that acts as a proxy for web search engines.",
                "Currently, it is only implemented for Internet Explorer and Google, but it is a matter of engineering to make it run on other web browsers and interact with other search engines.",
                "The issue of privacy is a primary obstacle for deploying any real world applications involving serious user modeling, such as personalized search.",
                "For this reason, UCAIR is strictly running as a client-side search agent, as opposed to a server-side application.",
                "This way, the captured user information always resides on the computer that the user is using, thus the user does not need to release any information to the outside.",
                "Client-side personalization also allows the system to easily observe a lot of user information that may not be easily available to a server.",
                "Furthermore, performing personalized search on the client-side is more scalable than on the serverside, since the overhead of computation and storage is distributed among clients.",
                "As shown in Figure 1, the UCAIR toolbar has 3 major components: (1) The (implicit) user modeling module captures a users search context and history information, including the submitted queries and any clicked search results and infers search session boundaries. (2) The query modification module selectively improves the query formulation according to the current user model. (3) The result re-ranking module immediately re-ranks any unseen search results whenever the user model is updated.",
                "In UCAIR, we consider four basic user actions: (1) submitting a keyword query; (2) viewing a document; (3) clicking the Back button; (4) clicking the Next link on a result page.",
                "For each of these four actions, the system responds with, respectively, (1) 1 UCAIR is available at: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Search Engine (e.g., Google) Search History Log (e.g.,past queries, clicked results) Query Modification Result Re-Ranking User Modeling Result Buffer UCAIR Userquery results clickthrough… Figure 1: UCAIR architecture generating a ranked list of results by sending a possibly expanded query to a search engine; (2) updating the information need model x; (3) reranking the unseen results on the current result page based on the current model x; and (4) reranking the unseen pages and generating the next page of results based on the current model x.",
                "Behind these responses, there are three basic tasks: (1) Decide whether the previous query is related to the current query and if so expand the current query with useful terms from the previous query or the results of the previous query. (2) Update the information need model x based on a newly clicked document summary. (3) Rerank a set of unseen documents based on the current model x.",
                "Below we describe our algorithms for each of them. 4.2 Session boundary detection and query expansion To effectively exploit previous queries and their corresponding clickthrough information, UCAIR needs to judge whether two adjacent queries belong to the same search session (i.e., detect session boundaries).",
                "Existing work on session boundary detection is mostly in the context of web log analysis (e.g., [8]), and uses statistical information rather than textual features.",
                "Since our clientside agent does not have access to server query logs, we make session boundary decisions based on textual similarity between two queries.",
                "Because related queries do not necessarily share the same words (e.g., java island and travel Indonesia), it is insufficient to use only query text.",
                "Therefore we use the search results of the two queries to help decide whether they are topically related.",
                "For example, for the above queries java island and travel Indonesia, the words java, bali, island, indonesia and travel may occur frequently in both queries search results, yielding a high similarity score.",
                "We only use the titles and summaries of the search results to calculate the similarity since they are available in the retrieved search result page and fetching the full text of every result page would significantly slow down the process.",
                "To compensate for the terseness of titles and summaries, we retrieve more results than a user would normally view for the purpose of detecting session boundaries (typically 50 results).",
                "The similarity between the previous query q and the current query q is computed as follows.",
                "Let {s1, s2, . . . , sn } and {s1, s2, . . . , sn} be the result sets for the two queries.",
                "We use the pivoted normalization TF-IDF weighting formula [24] to compute a term weight vector si for each result si.",
                "We define the average result savg to be the centroid of all the result vectors, i.e., (s1 + s2 + . . . + sn)/n.",
                "The cosine similarity between the two average results is calculated as s avg · savg/ s 2 avg · s2 avg If the similarity value exceeds a predefined threshold, the two queries will be considered to be in the same information session.",
                "If the previous query and the current query are found to belong to the same search session, UCAIR would attempt to expand the current query with terms from the previous query and its search results.",
                "Specifically, for each term in the previous query or the corresponding search results, if its frequency in the results of the current query is greater than a preset threshold (e.g. 5 results out of 50), the term would be added to the current query to form an expanded query.",
                "In this case, UCAIR would send this expanded query rather than the original one to the search engine and return the results corresponding to the expanded query.",
                "Currently, UCAIR only uses the immediate preceding query for query expansion; in principle, we could exploit all related past queries. 4.3 Information need model updating Suppose at time t, we have observed that the user has viewed k documents whose summaries are s1, ..., sk.",
                "We update our user model by computing a new information need vector with a standard feedback method in information retrieval (i.e., Rocchio [19]).",
                "According to the vector space retrieval model, each clicked summary si can be represented by a term weight vector si with each term weighted by a TF-IDF weighting formula [21].",
                "Rocchio computes the centroid vector of all the summaries and interpolates it with the original query vector to obtain an updated term vector.",
                "That is, x = αq + (1 − α) 1 k k i=1 si where q is the query vector, k is the number of summaries the user clicks immediately following the current query and α is a parameter that controls the influence of the clicked summaries on the inferred information need model.",
                "In our experiments, α is set to 0.5.",
                "Note that we update the information need model whenever the user views a document. 4.4 Result reranking In general, we want to rerank all the unseen results as soon as the user model is updated.",
                "Currently, UCAIR implements reranking in two cases, corresponding to the user clicking the Back button and Next link in the Internet Explorer.",
                "In both cases, the current (updated) user model would be used to rerank the unseen results so that the user would see improved search results immediately.",
                "To rerank any unseen document summaries, UCAIR uses the standard vector space retrieval model and scores each summary based on the similarity of the result and the current user information need vector x [21].",
                "Since implicit feedback is not completely reliable, we bring up only a small number (e.g. 5) of highest reranked results to be followed by any originally high ranked results. 828 Google result (user query = java map) UCAIR result (user query =java map) previous query = travel Indonesia previous query = hashtable expanded user query = java map Indonesia expanded user query = java map class 1 Java map projections of the world ... Lonely Planet - Indonesia Map Map (Java 2 Platform SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Java map projections of the world ... INDONESIA TOURISM : CENTRAL JAVA - MAP Java 2 Platform SE v1.3.1: Interface Map www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Java Map INDONESIA TOURISM : WEST JAVA - MAP An Introduction to Java Map Collection Classes java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Java Technology Concept Map IndoStreets - Java Map An Introduction to Java Map Collection Classes java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Indonesia Regions and Islands Maps, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 An Introduction to Java Map Collection Classes Indonesia City Street Map,... Hibernate simplifies inheritance mapping www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Java Map Maps Of Indonesia tmap 30.map Class Hierarchy www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Java API Map Maps of Indonesia by Peter Loud Class Scope www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas : Sam Maps of Indonesia by Peter Loud Class PrintSafeHashMap www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 INDONESIA TOURISM : WEST JAVA - MAP indonesiaphoto.com Java Pro - Union and Vertical Mapping of Classes www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Table 1: Sample results of query expansion 5.",
                "EVALUATION OF UCAIR We now present some results on evaluating the two major UCAIR functions: selective query expansion and result reranking based on user clickthrough data. 5.1 Sample results The query expansion strategy implemented in UCAIR is intentionally conservative to avoid misinterpretation of implicit user models.",
                "In practice, whenever it chooses to expand the query, the expansion usually makes sense.",
                "In Table 1, we show how UCAIR can successfully distinguish two different search contexts for the query java map, corresponding to two different previous queries (i.e., travel Indonesia vs. hashtable).",
                "Due to implicit user modeling, UCAIR intelligently figures out to add Indonesia and class, respectively, to the users query java map, which would otherwise be ambiguous as shown in the original results from Google on March 21, 2005.",
                "UCAIRs results are much more accurate than Googles results and reflect personalization in search.",
                "The eager implicit feedback component is designed to immediately respond to a users activity such as viewing a document.",
                "In Figure 2, we show how UCAIR can successfully disambiguate an ambiguous query jaguar by exploiting a viewed document summary.",
                "In this case, the initial retrieval results using jaguar (shown on the left side) contain two results about the Jaguar cars followed by two results about the Jaguar software.",
                "However, after the user views the web page content of the second result (about Jaguar car) and returns to the search result page by clicking Back button, UCAIR automatically nominates two new search results about Jaguar cars (shown on the right side), while the original two results about Jaguar software are pushed down on the list (unseen from the picture). 5.2 Quantitative evaluation To further evaluate UCAIR quantitatively, we conduct a user study on the effectiveness of the eager implicit feedback component.",
                "It is a challenge to quantitatively evaluate the potential performance improvement of our proposed model and UCAIR over Google in an unbiased way [7].",
                "Here, we design a user study, in which participants would do normal web search and judge a randomly and anonymously mixed set of results from Google and UCAIR at the end of the search session; participants do not know whether a result comes from Google or UCAIR.",
                "We recruited 6 graduate students for this user study, who have different backgrounds (3 computer science, 2 biology, and 1 chem<top> <num> Number: 716 <title> Spammer arrest sue <desc> Description: Have any spammers been arrested or sued for sending unsolicited e-mail? <narr> Narrative: Instances of arrests, prosecutions, convictions, and punishments of spammers, and lawsuits against them are relevant.",
                "Documents which describe laws to limit spam without giving details of lawsuits or criminal trials are not relevant. </top> Figure 3: An example of TREC query topic, expressed in a form which might be given to a human assistant or librarian istry).",
                "We use query topics from TREC 2 2004 Terabyte track [2] and TREC 2003 Web track [4] topic distillation task in the way to be described below.",
                "An example topic from TREC 2004 Terabyte track appears in Figure 3.",
                "The title is a short phrase and may be used as a query to the retrieval system.",
                "The description field provides a slightly longer statement of the topic requirement, usually expressed as a single complete sentence or question.",
                "Finally the narrative supplies additional information necessary to fully specify the requirement, expressed in the form of a short paragraph.",
                "Initially, each participant would browse 50 topics either from Terabyte track or Web track and pick 5 or 7 most interesting topics.",
                "For each picked topic, the participant would essentially do the normal web search using UCAIR to find many relevant web pages by using the title of the query topic as the initial keyword query.",
                "During this process, the participant may view the search results and possibly click on some interesting ones to view the web pages, just as in a normal web search.",
                "There is no requirement or restriction on how many queries the participant must submit or when the participant should stop the search for one topic.",
                "When the participant plans to change the search topic, he/she will simply press a button 2 Text REtrieval Conference: http://trec.nist.gov/ 829 Figure 2: Screen shots for result reranking to evaluate the search results before actually switching to the next topic.",
                "At the time of evaluation, 30 top ranked results from Google and UCAIR (some are overlapping) are randomly mixed together so that the participant would not know whether a result comes from Google or UCAIR.",
                "The participant would then judge the relevance of these results.",
                "We measure precision at top n (n = 5, 10, 20, 30) documents of Google and UCAIR.",
                "We also evaluate precisions at different recall levels.",
                "Altogether, 368 documents judged as relevant from Google search results and 429 documents judged as relevant from UCAIR by participants.",
                "Scatter plots of precision at top 10 and top 20 documents are shown in Figure 4 and Figure 5 respectively (The scatter plot of precision at top 30 documents is very similar to precision at top 20 documents).",
                "Each point of the scatter plots represents the precisions of Google and UCAIR on one query topic.",
                "Table 2 shows the average precision at top n documents among 32 topics.",
                "From Figure 4, Figure 5 and Table 2, we see that the search results from UCAIR are consistently better than those from Google by all the measures.",
                "Moreover, the performance improvement is more dramatic for precision at top 20 documents than that at precision at top 10 documents.",
                "One explanation for this is that the more interaction the user has with the system, the more clickthrough data UCAIR can be expected to collect.",
                "Thus the retrieval system can build more precise implicit user models, which lead to better retrieval accuracy.",
                "Ranking Method prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Improvement 8.0% 17.8% 20.2% 21.8% Table 2: Table of average precision at top n documents for 32 query topics The plot in Figure 6 shows the precision-recall curves for UCAIR and Google, where it is clearly seen that the performance of UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Scatterplot of Precision at Top 10 Documents Figure 4: Precision at top 10 documents of UCAIR and Google is consistently and considerably better than that of Google at all levels of recall. 6.",
                "CONCLUSIONS In this paper, we studied how to exploit implicit user modeling to intelligently personalize information retrieval and improve search accuracy.",
                "Unlike most previous work, we emphasize the use of immediate search context and implicit feedback information as well as eager updating of search results to maximally benefit a user.",
                "We presented a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent (UCAIR) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Scatterplot of Precision at Top 20 documents Figure 5: Precision at top 20 documents of UCAIR and Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 recall precision Precision−Recall curves Google Result UCAIR Result Figure 6: Precision at top 20 result of UCAIR and Google Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "The developed search agent thus can improve existing web search performance without any additional effort from the user. 7.",
                "ACKNOWLEDGEMENT We thank the six participants of our evaluation experiments.",
                "This work was supported in part by the National Science Foundation grants IIS-0347933 and IIS-0428472. 8.",
                "REFERENCES [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman, and O. Frieder.",
                "Hourly analysis of a very large topically categorized web query log.",
                "In Proceedings of SIGIR 2004, pages 321-328, 2004. [2] C. Clarke, N. Craswell, and I. Soboroff.",
                "Overview of the TREC 2004 terabyte track.",
                "In Proceedings of TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda, and D. Brown.",
                "Implicit interest indicators.",
                "In Proceedings of Intelligent User Interfaces 2001, pages 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson, and M. Wu.",
                "Overview of the TREC 2003 web track.",
                "In Proceedings of TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend, and V. Larvrenko.",
                "Relevance feedback and personalization: A language modeling perspective.",
                "In Proeedings of Second DELOS Workshop: Personalisation and Recommender Systems in Digital Libraries, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite, and D. Harman.",
                "Results and challenges in web search evaluation.",
                "Computer Networks, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A.",
                "An, and D. Schuurmans.",
                "Dynamic web log session identification with statistical language models.",
                "Journal of the American Society for Information Science and Technology, 55(14):1290-1303, 2004. [9] G. Jeh and J. Widom.",
                "Scaling <br>personalized web search</br>.",
                "In Proceedings of WWW 2003, pages 271-279, 2003. [10] T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of SIGKDD 2002, pages 133-142, 2002. [11] D. Kelly and J. Teevan.",
                "Implicit feedback for inferring user preference: A bibliography.",
                "SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of SIGIR01, pages 111-119, 2001. [13] T. Lau and E. Horvitz.",
                "Patterns of search: Analyzing and modeling web query refinement.",
                "In Proceedings of the Seventh International Conference on User Modeling (UM), pages 145 -152, 1999. [14] V. Lavrenko and B. Croft.",
                "Relevance-based language models.",
                "In Proceedings of SIGIR01, pages 120-127, 2001. [15] M. Mitra, A. Singhal, and C. Buckley.",
                "Improving automatic query expansion.",
                "In Proceedings of SIGIR 1998, pages 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg.",
                "As google goes, so goes the nation.",
                "New York Times, May 2003. [18] S. E. Robertson.",
                "The probability ranking principle in ı˚.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] J. J. Rocchio.",
                "Relevance feedback in information retrieval.",
                "In The SMART Retrieval System: Experiments in Automatic Document Processing, pages 313-323.",
                "Prentice-Hall Inc., 1971. [20] G. Salton and C. Buckley.",
                "Improving retrieval performance by retrieval feedback.",
                "Journal of the American Society for Information Science, 41(4):288-297, 1990. [21] G. Salton and M. J. McGill.",
                "Introduction to Modern Information Retrieval.",
                "McGraw-Hill, 1983. [22] X. Shen, B. Tan, and C. Zhai.",
                "Context-sensitive information retrieval using implicit feedback.",
                "In Proceedings of SIGIR 2005, pages 43-50, 2005. [23] X. Shen and C. Zhai.",
                "Exploiting query history for document ranking in interactive information retrieval (Poster).",
                "In Proceedings of SIGIR 2003, pages 377-378, 2003. [24] A. Singhal.",
                "Modern information retrieval: A brief overview.",
                "Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano, and M. Yoshikawa.",
                "Adaptive web search based on user profile constructed without any effort from users.",
                "In Proceedings of WWW 2004, pages 675-684, 2004. [26] E. Volokh.",
                "Personalization and privacy.",
                "Communications of the ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen, and I. Ruthven.",
                "A simulated study of implicit feedback models.",
                "In Proceedings of ECIR 2004, pages 311-326, 2004. [28] J. Xu and W. B. Croft.",
                "Query expansion using local and global document analysis.",
                "In Proceedings of SIGIR 1996, pages 4-11, 1996. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in KL divergence retrieval model.",
                "In Proceedings of the CIKM 2001, pages 403-410, 2001. 831"
            ],
            "original_annotated_samples": [
                "RELATED WORK Implicit user modeling for personalized search has been studied in previous work, but our work differs from all previous work in several aspects: (1) We emphasize the exploitation of immediate search context such as the related immediately preceding query and the viewed documents in the same session, while most previous work relies on long-term collection of implicit feedback information [25]. (2) We perform eager feedback and bring the benefit of implicit user modeling as soon as any new implicit feedback information is available, while the previous work mostly exploits longterm implicit feedback [10]. (3) We propose a retrieval framework to integrate implicit user modeling with the interactive retrieval process, while the previous work either studies implicit user modeling separately from retrieval [3] or only studies specific retrieval models for exploiting implicit feedback to better match a query with documents [23, 27, 22]. (4) We develop and evaluate a <br>personalized web search</br> agent with online user studies, while most existing work evaluates algorithms offline without real user interactions.",
                "Currently some search engines provide rudimentary personalization, such as Google <br>personalized web search</br> [6], which allows users to explicitly describe their interests by selecting from predefined topics, so that those results that match their interests are brought to the top, and My Yahoo! search [16], which gives users the option to save web sites they like and block those they dislike.",
                "Scaling <br>personalized web search</br>."
            ],
            "translated_annotated_samples": [
                "El modelado implícito del usuario para la búsqueda personalizada ha sido estudiado en trabajos anteriores, pero nuestro trabajo difiere de todos los trabajos anteriores en varios aspectos: (1) Enfatizamos la explotación del contexto de búsqueda inmediato, como la consulta inmediatamente anterior relacionada y los documentos vistos en la misma sesión, mientras que la mayoría de los trabajos anteriores se basan en la recopilación a largo plazo de información de retroalimentación implícita [25]. (2) Realizamos una retroalimentación activa y obtenemos el beneficio del modelado implícito del usuario tan pronto como esté disponible cualquier nueva información de retroalimentación implícita, mientras que el trabajo anterior mayormente explota la retroalimentación implícita a largo plazo [10]. (3) Proponemos un marco de recuperación para integrar el modelado implícito del usuario con el proceso interactivo de recuperación, mientras que el trabajo anterior estudia el modelado implícito del usuario por separado de la recuperación [3] o solo estudia modelos de recuperación específicos para explotar la retroalimentación implícita para mejorar la coincidencia de una consulta con documentos [23, 27, 22]. (4) Desarrollamos y evaluamos un agente de <br>búsqueda web personalizado</br> con estudios de usuario en línea, mientras que la mayoría de los trabajos existentes evalúan algoritmos fuera de línea sin interacciones reales de usuarios.",
                "Actualmente algunos motores de búsqueda ofrecen personalización rudimentaria, como la <br>búsqueda web personalizada</br> de Google [6], que permite a los usuarios describir explícitamente sus intereses seleccionando entre temas predefinidos, de modo que los resultados que coinciden con sus intereses se muestren en la parte superior, y la búsqueda de My Yahoo! [16], que brinda a los usuarios la opción de guardar los sitios web que les gustan y bloquear aquellos que no les gustan.",
                "Escalando la <br>búsqueda web personalizada</br>."
            ],
            "translated_text": "Modelado implícito de usuarios para búsqueda personalizada Xuehua Shen, Bin Tan, ChengXiang Zhai Departamento de Ciencias de la Computación Universidad de Illinois en Urbana-Champaign RESUMEN Los sistemas de recuperación de información (por ejemplo, motores de búsqueda web) son críticos para superar la sobrecarga de información. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales, lo que resulta en un rendimiento de recuperación inherentemente no óptimo. Por ejemplo, un turista y un programador pueden usar la misma palabra \"java\" para buscar información diferente, pero los sistemas de búsqueda actuales devolverían los mismos resultados. En este artículo, estudiamos cómo inferir el interés de un usuario a partir del contexto de búsqueda del usuario y utilizar el modelo de usuario implícito inferido para la búsqueda personalizada. Presentamos un marco teórico de toma de decisiones y desarrollamos técnicas para el modelado implícito del usuario en la recuperación de información. Desarrollamos un agente de búsqueda web inteligente del lado del cliente (UCAIR) que puede realizar retroalimentación implícita ansiosa, por ejemplo, expansión de consultas basada en consultas anteriores y reordenamiento inmediato de resultados basado en información de clics. Los experimentos sobre la búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda sobre el popular motor de búsqueda Google. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación, Retroalimentación de relevancia, Proceso de búsqueda Términos Generales Algoritmos 1. Aunque muchos sistemas de recuperación de información (por ejemplo, motores de búsqueda web y sistemas de biblioteca digital) se han implementado con éxito, los sistemas de recuperación actuales están lejos de ser óptimos. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales [17]. Esta no optimalidad inherente se ve claramente en los siguientes dos casos: (1) Diferentes usuarios pueden utilizar exactamente la misma consulta (por ejemplo, Java) para buscar información diferente (por ejemplo, la isla de Java en Indonesia o el lenguaje de programación Java), pero los sistemas de IR existentes devuelven los mismos resultados para estos usuarios. Sin considerar al usuario actual, es imposible saber a qué sentido se refiere Java en una consulta. (2) Las necesidades de información de un usuario pueden cambiar con el tiempo. El mismo usuario puede usar Java a veces para referirse a la isla de Java en Indonesia y otras veces para referirse al lenguaje de programación. Sin reconocer el contexto de búsqueda, sería nuevamente imposible reconocer el sentido correcto. Para optimizar la precisión de la recuperación, claramente necesitamos modelar al usuario de manera adecuada y personalizar la búsqueda según cada usuario individual. El objetivo principal del modelado de usuario para la recuperación de información es modelar con precisión la necesidad de información de un usuario, lo cual, desafortunadamente, es una tarea muy difícil. De hecho, incluso resulta difícil para un usuario describir con precisión cuál es su necesidad de información. ¿Qué información está disponible para que un sistema pueda inferir la necesidad de información de un usuario? Obviamente, la consulta de los usuarios proporciona la evidencia más directa. De hecho, la mayoría de los sistemas de recuperación existentes se basan únicamente en la consulta para modelar la necesidad de información de los usuarios. Sin embargo, dado que una consulta suele ser extremadamente corta, el modelo de usuario construido basado en una consulta de palabras clave inevitablemente resulta empobrecido. Una forma efectiva de mejorar la modelización de usuarios en la recuperación de información es pedir al usuario que especifique explícitamente qué documentos son relevantes (es decir, útiles para satisfacer su necesidad de información) y luego mejorar la modelización de usuarios basándose en ejemplos de documentos relevantes. Esto se llama retroalimentación de relevancia, lo cual ha demostrado ser bastante efectivo para mejorar la precisión de recuperación [19, 20]. Desafortunadamente, en aplicaciones del mundo real, los usuarios suelen ser reacios a hacer el esfuerzo adicional de proporcionar ejemplos relevantes para retroalimentación [11]. Por lo tanto, es muy interesante estudiar cómo inferir la necesidad de información de un usuario basándose en cualquier información de retroalimentación implícita, la cual existe naturalmente a través de las interacciones del usuario y no requiere ningún esfuerzo adicional por parte del usuario. De hecho, varios estudios previos han demostrado que el modelado implícito del usuario puede mejorar la precisión de recuperación. En [3], se desarrolla un navegador web (Curious Browser) para registrar las calificaciones explícitas de relevancia de las páginas web por parte de los usuarios (retroalimentación de relevancia) y el comportamiento de navegación al ver una página, como el tiempo de permanencia, clics de ratón, movimiento del ratón y desplazamiento (retroalimentación implícita). Se muestra que el tiempo de permanencia en una página, la cantidad de desplazamiento en una página y la combinación de tiempo y desplazamiento tienen una fuerte correlación con las calificaciones de relevancia explícita, lo que sugiere que la retroalimentación implícita puede ser útil para inferir la necesidad de información del usuario. En [10], se recopilan datos de clics de usuario como datos de entrenamiento para aprender una función de recuperación, que se utiliza para producir un ranking personalizado de resultados de búsqueda que se adapte a las preferencias de un grupo de usuarios. En [25], los datos de clics recopilados durante un largo período de tiempo se utilizan a través de la expansión de consultas para mejorar la precisión de recuperación. Si bien un usuario puede tener intereses y preferencias generales a largo plazo para la información, a menudo está buscando documentos para satisfacer una necesidad de información ad-hoc, que solo dura un corto período de tiempo; una vez que se satisface la necesidad de información, el usuario generalmente ya no estaría interesado en esa información. Por ejemplo, un usuario puede estar buscando información sobre autos usados para comprar uno, pero una vez que el usuario ha comprado un auto, generalmente ya no está interesado en esa información. En tales casos, la información de retroalimentación implícita recopilada durante un largo período de tiempo es poco probable que sea muy útil, pero el contexto de búsqueda inmediato y la información de retroalimentación, como cuáles de los resultados de búsqueda para la necesidad de información actual son vistos, se espera que sean mucho más útiles. Considera la consulta de Java nuevamente. Cualquiera de la siguiente información de retroalimentación inmediata sobre el usuario podría potencialmente ayudar a determinar el significado previsto de Java en la consulta: (1) La consulta anterior enviada por el usuario es hashtable (en lugar de, por ejemplo, viajar a Indonesia). (2) En los resultados de búsqueda, el usuario visualizó una página donde palabras como programación, software y applet ocurren muchas veces. Hasta donde sabemos, cómo aprovechar este contexto de búsqueda inmediato y a corto plazo para mejorar la búsqueda aún no ha sido abordado de manera satisfactoria en trabajos anteriores. En este artículo, estudiamos cómo construir y actualizar un modelo de usuario basado en el contexto de búsqueda inmediato y la información de retroalimentación implícita, y utilizar el modelo para mejorar la precisión de la recuperación ad-hoc. Para beneficiar al máximo al usuario de un sistema de recuperación a través de modelado implícito del usuario, proponemos realizar retroalimentación implícita entusiasta. Es decir, tan pronto como observemos cualquier nueva pieza de evidencia del usuario, actualizaríamos la creencia del sistema sobre la necesidad de información del usuario y responderíamos con resultados de recuperación mejorados basados en el modelo de usuario actualizado. Presentamos un marco de trabajo de teoría de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. En un paradigma de recuperación tradicional, el problema de recuperación consiste en emparejar una consulta con documentos y clasificar los documentos según sus valores de relevancia. Como resultado, el proceso de recuperación es un ciclo independiente simple de consulta y visualización de resultados. En el nuevo paradigma de recuperación propuesto, el contexto de búsqueda de los usuarios juega un papel importante y el modelo de usuario implícito inferido se explota inmediatamente para beneficiar al usuario. El nuevo paradigma de recuperación es, por lo tanto, fundamentalmente diferente del paradigma tradicional y es inherentemente más general. Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos apropiados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para reordenar inmediatamente cualquier documento que aún no haya sido visto por el usuario. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente UCAIR (Recuperación de Información Adaptativa Centrada en el Usuario) sobre un motor de búsqueda popular (Google). Los experimentos sobre búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en comparación con Google. Dado que la información implícita que explotamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional. Por lo tanto, el agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin esfuerzo adicional por parte del usuario. Las secciones restantes están organizadas de la siguiente manera. En la Sección 2, discutimos el trabajo relacionado. En la Sección 3, presentamos un marco de recuperación interactiva basado en teoría de decisiones para modelado implícito de usuarios. En la Sección 4, presentamos el diseño e implementación de un agente de búsqueda web inteligente del lado del cliente (UCAIR) que realiza retroalimentación implícita ansiosa. En la Sección 5, informamos nuestros resultados experimentales utilizando el agente de búsqueda. La sección 6 concluye nuestro trabajo. 2. El modelado implícito del usuario para la búsqueda personalizada ha sido estudiado en trabajos anteriores, pero nuestro trabajo difiere de todos los trabajos anteriores en varios aspectos: (1) Enfatizamos la explotación del contexto de búsqueda inmediato, como la consulta inmediatamente anterior relacionada y los documentos vistos en la misma sesión, mientras que la mayoría de los trabajos anteriores se basan en la recopilación a largo plazo de información de retroalimentación implícita [25]. (2) Realizamos una retroalimentación activa y obtenemos el beneficio del modelado implícito del usuario tan pronto como esté disponible cualquier nueva información de retroalimentación implícita, mientras que el trabajo anterior mayormente explota la retroalimentación implícita a largo plazo [10]. (3) Proponemos un marco de recuperación para integrar el modelado implícito del usuario con el proceso interactivo de recuperación, mientras que el trabajo anterior estudia el modelado implícito del usuario por separado de la recuperación [3] o solo estudia modelos de recuperación específicos para explotar la retroalimentación implícita para mejorar la coincidencia de una consulta con documentos [23, 27, 22]. (4) Desarrollamos y evaluamos un agente de <br>búsqueda web personalizado</br> con estudios de usuario en línea, mientras que la mayoría de los trabajos existentes evalúan algoritmos fuera de línea sin interacciones reales de usuarios. Actualmente algunos motores de búsqueda ofrecen personalización rudimentaria, como la <br>búsqueda web personalizada</br> de Google [6], que permite a los usuarios describir explícitamente sus intereses seleccionando entre temas predefinidos, de modo que los resultados que coinciden con sus intereses se muestren en la parte superior, y la búsqueda de My Yahoo! [16], que brinda a los usuarios la opción de guardar los sitios web que les gustan y bloquear aquellos que no les gustan. Por el contrario, UCAIR personaliza la búsqueda web a través de la modelización implícita del usuario sin necesidad de esfuerzos adicionales por parte del usuario. Además, la personalización de UCAIR se proporciona en el lado del cliente. Hay dos ventajas notables en esto. Primero, el usuario no necesita preocuparse por la infracción de privacidad, que es una gran preocupación para la búsqueda personalizada [26]. En segundo lugar, tanto el cálculo de la personalización como el almacenamiento del perfil del usuario se realizan en el lado del cliente para reducir drásticamente la carga del servidor [9]. Ha habido muchos trabajos estudiando los registros de consultas de usuarios [1] o la dinámica de consultas [13]. UCAIR hace uso directo del historial de consultas de un usuario para beneficiar al mismo usuario de inmediato en la misma sesión de búsqueda. UCAIR primero determina si dos consultas vecinas pertenecen a la misma sesión de información y, de ser así, selecciona términos de la consulta anterior para realizar la expansión de la consulta. Nuestro enfoque de expansión de consultas es similar a la expansión automática de consultas [28, 15, 5], pero en lugar de utilizar retroalimentación pseudo para expandir la consulta, utilizamos la información de retroalimentación implícita de los usuarios para expandir la consulta actual. Estas dos técnicas pueden ser combinadas. 3. OPTIMIZACIÓN EN IR INTERACTIVO En IR interactivo, un usuario interactúa con el sistema de recuperación a través de un diálogo de acción, en el cual el sistema responde a cada acción del usuario con alguna acción del sistema. Por ejemplo, la acción de los usuarios puede ser enviar una consulta y la respuesta del sistema puede ser devolver una lista de 10 resúmenes de documentos. En general, el espacio de acciones del usuario y respuestas del sistema y sus granularidades dependerían de la interfaz de un sistema de recuperación particular. En principio, cada acción del usuario puede potencialmente proporcionar nuevas pruebas para ayudar al sistema a inferir mejor la necesidad de información del usuario. Por lo tanto, para responder de manera óptima, el sistema debería utilizar toda la evidencia recopilada hasta ahora sobre el usuario al elegir una respuesta. Cuando se ven de esta manera, la mayoría de los motores de búsqueda existentes son claramente no óptimos. Por ejemplo, si un usuario ha visto algunos documentos en la primera página de resultados de búsqueda, cuando el usuario hace clic en el enlace Siguiente para obtener más resultados, un sistema de recuperación existente seguiría devolviendo la siguiente página de resultados recuperados en función de la consulta original sin considerar la nueva evidencia de que un resultado en particular ha sido visto por el usuario. Proponemos optimizar el rendimiento de la recuperación adaptando las respuestas del sistema en función de cada acción que un usuario haya tomado, y planteamos el problema de optimización como una tarea de decisión. Específicamente, en cualquier momento, el sistema intentaría realizar dos tareas: (1) Actualización del modelo de usuario: Monitorear cualquier evidencia útil del usuario con respecto a su necesidad de información y actualizar el modelo de usuario tan pronto como esta evidencia esté disponible; (2) Mejorar los resultados de búsqueda: Reclasificar inmediatamente todos los documentos que el usuario aún no ha visto, tan pronto como se actualice el modelo de usuario. Enfatizamos la actualización y reordenamiento entusiastas, lo que hace que nuestro trabajo sea bastante diferente a cualquier trabajo existente. A continuación presentamos un marco formal de teoría de decisiones para optimizar el rendimiento de recuperación a través de la modelización implícita del usuario en la recuperación de información interactiva. 3.1 Un marco de teoría de decisiones Sea A el conjunto de todas las acciones del usuario y R(a) el conjunto de todas las posibles respuestas del sistema a una acción del usuario a ∈ A. En cualquier momento, sea At = (a1, ..., at) la secuencia observada de acciones de usuario hasta ahora (hasta el momento t) y Rt−1 = (r1, ..., rt−1) las respuestas que el sistema ha dado en respuesta a las acciones del usuario. El objetivo del sistema es elegir una respuesta óptima rt ∈ R(at) para la acción actual del usuario at. Sea M el espacio de todos los posibles modelos de usuario. Definimos además una función de pérdida L(a, r, m) ∈ , donde a ∈ A es una acción del usuario, r ∈ R(a) es una respuesta del sistema, y m ∈ M es un modelo de usuario. L(a, r, m) codifica nuestras preferencias de decisión y evalúa la optimalidad de responder con r cuando el modelo de usuario actual es m y la acción de usuario actual es a. Según la teoría de decisión bayesiana, la decisión óptima en el tiempo t es elegir una respuesta que minimice el riesgo de Bayes, es decir, r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) donde P(mt|U, D, At, Rt−1) es la probabilidad posterior del modelo de usuario mt dadas todas las observaciones sobre el usuario U que hemos realizado hasta el tiempo t. Para simplificar el cálculo de la Ecuación 1, asumamos que la masa de probabilidad posterior P(mt|U, D, At, Rt−1) está principalmente concentrada en el modo m∗ t = argmaxmt P(mt|U, D, At, Rt−1). Podemos entonces aproximar la integral con el valor de la función de pérdida en m∗ t. Es decir, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) donde m∗ t = argmaxmt P(mt|U, D, At, Rt−1). Dejando de lado cómo definir y estimar estos modelos probabilísticos y la función de pérdida, podemos ver que tal formulación de la teoría de decisiones sugiere que, para elegir la respuesta óptima a at, el sistema debería realizar dos tareas: (1) calcular el modelo de usuario actual y obtener m∗ t basado en toda la información útil. (2) elegir una respuesta rt para minimizar el valor de la función de pérdida L(at, rt, m∗ t). Cuando at no afecta nuestra creencia sobre m∗ t , el primer paso puede omitirse y podemos reutilizar m∗ t−1 para m∗ t . Ten en cuenta que nuestro marco de trabajo es bastante general, ya que potencialmente podemos modelar cualquier tipo de acciones de usuario y respuestas del sistema. En la mayoría de los casos, como podríamos esperar, la respuesta del sistema es algún tipo de clasificación de documentos, es decir, para la mayoría de las acciones a, R(a) consiste en todas las posibles clasificaciones de los documentos no vistos, y el problema de decisión se reduce a elegir la mejor clasificación de los documentos no vistos basándose en el modelo de usuario más actualizado. Cuando a es la acción de enviar una consulta de palabras clave, tal respuesta es exactamente lo que haría un sistema de recuperación actual. Sin embargo, fácilmente podemos imaginar que un motor de búsqueda web más inteligente respondería al clic del usuario en el enlace Siguiente (para obtener más resultados no vistos) con una clasificación más optimizada de documentos basada en cualquier documento visto en la página actual de resultados. De hecho, según nuestra estrategia de actualización entusiasta, incluso podríamos permitir que un sistema responda al clic del botón Atrás del navegador por parte de un usuario después de ver un documento de la misma manera, para que el usuario pueda beneficiarse al máximo de la retroalimentación implícita. Estos son precisamente lo que nuestro sistema UCAIR hace. 3.2 Modelos de usuario Un modelo de usuario m ∈ M representa lo que sabemos sobre el usuario U, por lo que en principio, puede contener cualquier información sobre el usuario que deseemos modelar. Ahora discutimos dos componentes importantes en un modelo de usuario. El primer componente es un modelo de componente de la necesidad de información de los usuarios. Presumiblemente, el factor más importante que afecta la optimalidad de la respuesta del sistema es qué tan bien la respuesta aborda la necesidad de información de los usuarios. De hecho, en cualquier momento, podemos asumir que el sistema tiene alguna creencia sobre lo que le interesa al usuario, la cual modelamos a través de un vector de términos x = (x1, ..., x|V|), donde V = {w1, ..., w|V|} es el conjunto de todos los términos (es decir, vocabulario) y xi es el peso del término wi. Un vector de términos de este tipo se utiliza comúnmente en la recuperación de información para representar tanto consultas como documentos. Por ejemplo, el modelo de espacio vectorial asume que tanto la consulta como los documentos se representan como vectores de términos y que la puntuación de un documento con respecto a una consulta se calcula en función de la similitud entre el vector de la consulta y el vector del documento [21]. En un enfoque de modelado de lenguaje, también podemos considerar el modelo de lenguaje unigrama de consulta [12, 29] o el modelo de relevancia [14] como una representación vectorial de términos de la necesidad de información de los usuarios. Intuitivamente, x asignaría pesos altos a los términos que caracterizan los temas que interesan al usuario. El segundo componente que podemos incluir en nuestro modelo de usuario son los documentos que el usuario ya ha visto. Obviamente, incluso si un documento es relevante, si el usuario ya ha visto el documento, no sería útil presentar el mismo documento de nuevo. Por lo tanto, introducimos otra variable S ⊂ D (D es el conjunto completo de documentos en la colección) para denotar el subconjunto de documentos en los resultados de búsqueda que el usuario ya ha visto. En general, en el tiempo t, podemos representar un modelo de usuario como mt = (S, x, At, Rt−1), donde S son los documentos vistos, x es la comprensión del sistema de la necesidad de información del usuario, y (At, Rt−1) representa el historial de interacción del usuario. Ten en cuenta que un modelo de usuario aún más general también puede incluir otros factores como el nivel de lectura y la ocupación de los usuarios. Si asumimos que la incertidumbre de un modelo de usuario mt se debe únicamente a la incertidumbre de x, el cálculo de nuestra estimación actual del modelo de usuario m∗ t implicará principalmente calcular nuestra mejor estimación de x. Es decir, el sistema elegiría una respuesta de acuerdo a r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) donde x∗ = argmaxx P(x|U, D, At, Rt−1). Este es el mecanismo de decisión implementado en el sistema UCAIR que se describirá más adelante. En este sistema, evitamos especificar el modelo probabilístico P(x|U, D, At, Rt−1) calculando x∗ directamente con algún método de retroalimentación existente. 3.3 Funciones de pérdida La definición exacta de la función de pérdida L depende de las respuestas, por lo que es inevitablemente específica de la aplicación. Ahora discutimos brevemente algunas posibilidades cuando la respuesta es clasificar todos los documentos no vistos y presentar los mejores k de ellos. Sea r = (d1, ..., dk) los k documentos principales, S el conjunto de documentos vistos por el usuario, y x∗ la mejor suposición del sistema sobre la necesidad de información del usuario. Podemos definir simplemente la pérdida asociada con r como la suma negativa de la probabilidad de que cada uno de los di sea relevante, es decir, L(a, r, m) = − k i=1 P(relevante|di, m). Claramente, para minimizar esta función de pérdida, la respuesta óptima r contendría los k documentos con la probabilidad más alta de relevancia, lo cual es intuitivamente razonable. Una deficiencia de esta función de pérdida top-k es que no es sensible al orden interno de los documentos top k seleccionados, por lo que cambiar el orden de clasificación de un documento no relevante y uno relevante no afectaría la pérdida, lo cual es irrazonable. Para modelar el ranking, podemos introducir un factor del modelo de usuario: la probabilidad de que cada uno de los k documentos sea visto por el usuario, P(vista|di), y definir la siguiente función de pérdida de ranking: L(a, r, m) = − k i=1 P(vista|di)P(relevante|di, m). Dado que, en general, si di está clasificado por encima de dj (es decir, i < j), P(vista|di) > P(vista|dj), esta función de pérdida favorecería una decisión de clasificar documentos relevantes por encima de los no relevantes, ya que de lo contrario, siempre podríamos intercambiar di con dj para reducir el valor de pérdida. Por lo tanto, el sistema simplemente debería realizar una recuperación regular y clasificar los documentos según la probabilidad de relevancia [18]. Dependiendo de las preferencias de recuperación de los usuarios, puede haber muchas otras posibilidades. Por ejemplo, si el usuario no desea ver documentos redundantes, la función de pérdida debería incluir alguna medida de redundancia en r basada en los documentos ya vistos S. Por supuesto, cuando la respuesta no es elegir una lista clasificada de documentos, necesitaríamos una función de pérdida diferente. Discutimos un ejemplo relevante para el agente de búsqueda que implementamos. Cuando un usuario ingresa una consulta qt (acción actual), nuestro agente de búsqueda se basa en algún motor de búsqueda existente para llevar a cabo la búsqueda en realidad. En tal caso, aunque el agente de búsqueda no tenga control sobre el algoritmo de recuperación, aún puede intentar optimizar los resultados de la búsqueda refinando la consulta enviada al motor de búsqueda y/o reordenando los resultados obtenidos del motor de búsqueda. Las funciones de pérdida para el reordenamiento ya fueron discutidas anteriormente; ahora echamos un vistazo a las funciones de pérdida para el refinamiento de consultas. Sea f la función de recuperación del motor de búsqueda que nuestro agente utiliza, de modo que f(q) nos daría los resultados de búsqueda utilizando la consulta q. Dado que la acción actual del usuario es ingresar una consulta qt (es decir, at = qt), nuestra respuesta sería f(q) para algún q. Dado que no tenemos elección de f, nuestra decisión es elegir un buen q. Formalmente, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) lo cual muestra que nuestro objetivo es encontrar q∗ = argminqL(qt, f(q), m), es decir, una consulta óptima que nos daría el mejor f(q). Una elección diferente de la función de pérdida L(qt, f(q), m) llevaría a una estrategia de refinamiento de consulta diferente. En UCAIR, calculamos heurísticamente q∗ expandiendo qt con términos extraídos de rt−1 siempre que qt−1 y qt tengan una alta similitud. Se debe tener en cuenta que rt−1 y qt−1 están contenidos en m como parte del historial de interacción de los usuarios. 3.4 Modelado implícito del usuario El modelado implícito del usuario se captura en nuestro marco a través del cálculo de x∗ = argmaxx P(x|U, D, At, Rt−1), es decir, la creencia actual del sistema sobre cuál es la necesidad de información del usuario. Aquí nuevamente puede haber muchas posibilidades, lo que lleva a diferentes algoritmos para la modelización implícita del usuario. Ahora discutimos algunos de ellos. Primero, cuando dos consultas consecutivas están relacionadas, la consulta anterior puede ser explotada para enriquecer la consulta actual y proporcionar más contexto de búsqueda para ayudar en la desambiguación. Para este propósito, en lugar de realizar una expansión de consulta como lo hicimos en la sección anterior, también podríamos calcular un x∗ actualizado basado en la consulta anterior y los resultados de recuperación. El modelo de usuario nuevo calculado puede luego ser utilizado para clasificar los documentos con un modelo estándar de recuperación de información. Segundo, también podemos inferir los intereses de un usuario basándonos en los resúmenes de los documentos visualizados. Cuando a un usuario se le presenta una lista de resúmenes de documentos mejor clasificados, si el usuario elige saltarse los primeros n documentos y ver el documento (n+1)-ésimo, podemos inferir que el usuario no está interesado en los resúmenes mostrados para los primeros n documentos, pero está atraído por el resumen mostrado del documento (n+1)-ésimo. Por lo tanto, podemos usar estos resúmenes como ejemplos negativos y positivos para aprender un modelo de usuario más preciso x∗. Aquí se pueden explotar muchas técnicas estándar de retroalimentación de relevancia [19, 20]. Ten en cuenta que debemos utilizar los resúmenes mostrados, en lugar de los contenidos reales de esos documentos, ya que es posible que el resumen mostrado del documento visto sea relevante, pero el contenido del documento en realidad no lo sea. Del mismo modo, un resumen mostrado puede llevar a un usuario a omitir un documento relevante. Inferir modelos de usuario basados en dicha información mostrada, en lugar del contenido real de un documento, es una diferencia importante entre UCAIR y algunos otros sistemas similares. En UCAIR, ambas estrategias para inferir un modelo de usuario implícito están implementadas. 4. UCAIR: Un agente de búsqueda personalizado 4.1 Diseño En esta sección, presentamos un agente de búsqueda web del lado del cliente llamado UCAIR, en el cual implementamos algunos de los métodos discutidos en la sección anterior para realizar búsquedas personalizadas a través de modelado implícito del usuario. UCAIR es un complemento del navegador web que actúa como proxy para los motores de búsqueda en la web. Actualmente, solo está implementado para Internet Explorer y Google, pero es cuestión de ingeniería hacer que funcione en otros navegadores web e interactúe con otros motores de búsqueda. El tema de la privacidad es un obstáculo principal para implementar cualquier aplicación del mundo real que involucre modelado de usuarios serio, como la búsqueda personalizada. Por esta razón, UCAIR funciona estrictamente como un agente de búsqueda del lado del cliente, en lugar de ser una aplicación del lado del servidor. De esta manera, la información del usuario capturada siempre permanece en la computadora que está utilizando el usuario, por lo tanto, el usuario no necesita revelar ninguna información al exterior. La personalización del lado del cliente también permite que el sistema observe fácilmente una gran cantidad de información del usuario que puede no estar fácilmente disponible para un servidor. Además, realizar búsquedas personalizadas en el lado del cliente es más escalable que en el lado del servidor, ya que la sobrecarga de cálculo y almacenamiento se distribuye entre los clientes. Como se muestra en la Figura 1, la barra de herramientas UCAIR tiene 3 componentes principales: (1) El módulo de modelado de usuario (implícito) captura el contexto de búsqueda de un usuario e información de historial, incluidas las consultas enviadas y los resultados de búsqueda clicados, e infiere los límites de la sesión de búsqueda. (2) El módulo de modificación de consultas mejora selectivamente la formulación de la consulta de acuerdo con el modelo de usuario actual. (3) El módulo de reordenamiento de resultados reordena inmediatamente cualquier resultado de búsqueda no visto cada vez que se actualiza el modelo de usuario. En UCAIR, consideramos cuatro acciones básicas de usuario: (1) enviar una consulta de palabras clave; (2) ver un documento; (3) hacer clic en el botón Atrás; (4) hacer clic en el enlace Siguiente en una página de resultados. Para cada una de estas cuatro acciones, el sistema responde con, respectivamente, (1) 1 UCAIR está disponible en: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Registro de Historial de Búsqueda del Motor de Búsqueda (por ejemplo, Google) (consultas pasadas, resultados clicados) Modificación de Consulta Resultado de Reclasificación Modelo de Usuario Buffer de Resultados de Consulta de Usuario UCAIR... Figura 1: arquitectura de UCAIR generando una lista clasificada de resultados enviando una consulta posiblemente ampliada a un motor de búsqueda; (2) actualizando el modelo de necesidad de información x; (3) reordenando los resultados no vistos en la página de resultados actual basándose en el modelo actual x; y (4) reordenando las páginas no vistas y generando la siguiente página de resultados basándose en el modelo actual x. Detrás de estas respuestas, hay tres tareas básicas: (1) Decidir si la consulta anterior está relacionada con la consulta actual y, de ser así, ampliar la consulta actual con términos útiles de la consulta anterior o los resultados de la consulta anterior. (2) Actualizar el modelo de necesidad de información x basado en un resumen de documento recién seleccionado. (3) Reordenar un conjunto de documentos no vistos basado en el modelo x actual. A continuación describimos nuestros algoritmos para cada uno de ellos. 4.2 Detección de límites de sesión y expansión de consultas Para explotar eficazmente las consultas anteriores y su información correspondiente de clics, UCAIR necesita determinar si dos consultas adyacentes pertenecen a la misma sesión de búsqueda (es decir, detectar los límites de sesión). El trabajo existente sobre la detección de límites de sesión se encuentra principalmente en el contexto del análisis de registros web (por ejemplo, [8]), y utiliza información estadística en lugar de características textuales. Dado que nuestro agente del lado del cliente no tiene acceso a los registros de consultas del servidor, tomamos decisiones sobre los límites de sesión basadas en la similitud textual entre dos consultas. Debido a que las consultas relacionadas no necesariamente comparten las mismas palabras (por ejemplo, isla de Java y viajar a Indonesia), no es suficiente utilizar solo el texto de la consulta. Por lo tanto, utilizamos los resultados de búsqueda de las dos consultas para ayudar a decidir si están relacionadas temáticamente. Por ejemplo, para las consultas anteriores \"java island\" y \"travel Indonesia\", las palabras \"java\", \"bali\", \"island\", \"indonesia\" y \"travel\" pueden aparecer con frecuencia en los resultados de búsqueda de ambas consultas, lo que produce un alto puntaje de similitud. Solo utilizamos los títulos y resúmenes de los resultados de búsqueda para calcular la similitud, ya que están disponibles en la página de resultados de búsqueda recuperada y obtener el texto completo de cada página de resultados ralentizaría significativamente el proceso. Para compensar la concisión de los títulos y resúmenes, recuperamos más resultados de los que un usuario normalmente vería con el propósito de detectar los límites de sesión (típicamente 50 resultados). La similitud entre la consulta anterior q y la consulta actual q se calcula de la siguiente manera. Sean {s1, s2, . . . , sn} y {s1, s2, . . . , sn} los conjuntos de resultados de las dos consultas. Utilizamos la fórmula de ponderación TF-IDF normalizada pivotada [24] para calcular un vector de peso de término si para cada resultado si. Definimos el resultado promedio savg como el centroide de todos los vectores de resultado, es decir, (s1 + s2 + . . . + sn)/n. La similitud del coseno entre los dos resultados promedio se calcula como s avg · savg/ s 2 avg · s2 avg. Si el valor de similitud supera un umbral predefinido, se considerará que las dos consultas están en la misma sesión de información. Si se determina que la consulta anterior y la consulta actual pertenecen a la misma sesión de búsqueda, UCAIR intentaría expandir la consulta actual con términos de la consulta anterior y sus resultados de búsqueda. Específicamente, para cada término en la consulta anterior o los resultados de búsqueda correspondientes, si su frecuencia en los resultados de la consulta actual es mayor que un umbral preestablecido (por ejemplo, 5 resultados de 50), el término se agregaría a la consulta actual para formar una consulta ampliada. En este caso, UCAIR enviaría esta consulta ampliada en lugar de la original al motor de búsqueda y devolvería los resultados correspondientes a la consulta ampliada. Actualmente, UCAIR solo utiliza la consulta inmediatamente anterior para la expansión de consultas; en principio, podríamos aprovechar todas las consultas pasadas relacionadas. 4.3 Actualización del modelo de necesidad de información Supongamos que en el tiempo t, hemos observado que el usuario ha visto k documentos cuyos resúmenes son s1, ..., sk. Actualizamos nuestro modelo de usuario calculando un nuevo vector de necesidad de información con un método estándar de retroalimentación en la recuperación de información (es decir, Rocchio [19]). Según el modelo de recuperación de espacio vectorial, cada resumen clicado si puede ser representado por un vector de pesos de términos si, con cada término ponderado por una fórmula de ponderación TF-IDF [21]. Rocchio calcula el vector centroide de todos los resúmenes e interpola este con el vector de consulta original para obtener un vector de términos actualizado. Es decir, x = αq + (1 − α) 1 k k i=1 si donde q es el vector de consulta, k es el número de resúmenes que el usuario hace clic inmediatamente después de la consulta actual y α es un parámetro que controla la influencia de los resúmenes clicados en el modelo de necesidad de información inferida. En nuestros experimentos, α se establece en 0.5. Ten en cuenta que actualizamos el modelo de información necesario cada vez que el usuario ve un documento. 4.4 Reclasificación de resultados En general, queremos volver a clasificar todos los resultados no vistos tan pronto como se actualice el modelo de usuario. Actualmente, UCAIR implementa el reordenamiento en dos casos, correspondientes a cuando el usuario hace clic en el botón Atrás y en el enlace Siguiente en Internet Explorer. En ambos casos, el modelo de usuario actualizado se utilizaría para reordenar los resultados no vistos de manera que el usuario vea resultados de búsqueda mejorados de inmediato. Para volver a clasificar cualquier resumen de documento no visto, UCAIR utiliza el modelo estándar de recuperación de espacio vectorial y puntúa cada resumen en función de la similitud del resultado y el vector de necesidad de información actual del usuario x [21]. Dado que la retroalimentación implícita no es completamente confiable, presentamos solo un pequeño número (por ejemplo, 5) de los resultados reordenados más altos para ser seguidos por cualquier resultado originalmente clasificado alto. 828 resultados de Google (consulta del usuario = mapa de Java) Resultados de UCAIR (consulta del usuario = mapa de Java) consulta anterior = viajar a Indonesia consulta anterior = tabla hash consulta del usuario ampliada = mapa de Java Indonesia consulta del usuario ampliada = clase de mapa de Java 1 Proyecciones de mapas de Java del mundo ... Lonely Planet - Mapa de Indonesia Mapa (Plataforma Java SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Proyecciones de mapas de Java del mundo ... TURISMO DE INDONESIA: JAVA CENTRAL - MAPA Plataforma Java SE v1.3.1: Interfaz de Mapa www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Mapa de Java TURISMO DE INDONESIA: JAVA OESTE - MAPA Una introducción a las clases de colección de mapas de Java java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Mapa de Tecnología Java IndoStreets - Mapa de Java Una introducción a las clases de colección de mapas de Java java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Regiones e islas de Indonesia Mapas, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 Una introducción a las clases de colección de mapas de Java Mapa de calles de la ciudad de Indonesia,... Hibernate simplifica el mapeo de herencia www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Mapa de Java Mapas de Indonesia jerarquía de clases de tmap 30.map www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Mapa de API de Java Mapas de Indonesia por Peter Loud Alcance de clases www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas: Mapas de Sam de Indonesia por Peter Loud PrintSafeHashMap de la clase www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 TURISMO DE INDONESIA: JAVA OESTE - MAPA indonesiaphoto.com Java Pro - Unión y mapeo vertical de clases www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Tabla 1: Resultados de muestra de la expansión de la consulta EVALUACIÓN DE UCAIR Ahora presentamos algunos resultados sobre la evaluación de las dos principales funciones de UCAIR: la expansión selectiva de consultas y la reordenación de resultados basada en los datos de clics de los usuarios. 5.1 Resultados de muestra La estrategia de expansión de consultas implementada en UCAIR es intencionalmente conservadora para evitar la interpretación errónea de los modelos implícitos de los usuarios. En la práctica, cada vez que decide expandir la consulta, la expansión suele tener sentido. En la Tabla 1, mostramos cómo UCAIR puede distinguir exitosamente dos contextos de búsqueda diferentes para la consulta java map, correspondientes a dos consultas previas distintas (es decir, viajar a Indonesia vs. hashtable). Debido a la modelización implícita del usuario, UCAIR descubre inteligentemente agregar Indonesia y clase, respectivamente, a la consulta de los usuarios sobre el mapa de Java, lo cual de otro modo sería ambiguo, como se muestra en los resultados originales de Google el 21 de marzo de 2005. Los resultados de UCAIR son mucho más precisos que los resultados de Google y reflejan la personalización en la búsqueda. El componente de retroalimentación implícita entusiasta está diseñado para responder inmediatamente a la actividad de un usuario, como por ejemplo, al visualizar un documento. En la Figura 2, mostramos cómo UCAIR puede desambiguar con éxito una consulta ambigua de jaguar al explotar un resumen del documento visualizado. En este caso, los resultados iniciales de recuperación utilizando \"jaguar\" (mostrados en el lado izquierdo) contienen dos resultados sobre los autos Jaguar seguidos por dos resultados sobre el software Jaguar. Sin embargo, después de que el usuario ve el contenido de la página web del segundo resultado (sobre el automóvil Jaguar) y regresa a la página de resultados de búsqueda haciendo clic en el botón Atrás, UCAIR automáticamente selecciona dos nuevos resultados de búsqueda sobre automóviles Jaguar (mostrados en el lado derecho), mientras que los dos resultados originales sobre software de Jaguar se desplazan hacia abajo en la lista (no se ven en la imagen). 5.2 Evaluación cuantitativa Para evaluar UCAIR de manera cuantitativa, realizamos un estudio de usuario sobre la efectividad del componente de retroalimentación implícita ansiosa. Es un desafío evaluar cuantitativamente la mejora potencial en el rendimiento de nuestro modelo propuesto y UCAIR sobre Google de manera imparcial [7]. Aquí diseñamos un estudio de usuarios, en el cual los participantes realizarían una búsqueda web normal y evaluarían al azar y de forma anónima un conjunto de resultados mezclados de Google y UCAIR al final de la sesión de búsqueda; los participantes no saben si un resultado proviene de Google o de UCAIR. Reclutamos a 6 estudiantes de posgrado para este estudio de usuarios, quienes tienen diferentes antecedentes (3 en informática, 2 en biología y 1 en química). Los documentos que describen leyes para limitar el correo no deseado sin dar detalles de demandas judiciales o juicios penales no son relevantes. Utilizamos los temas de consulta de la pista Terabyte TREC 2 2004 [2] y la tarea de destilación de temas de la pista web TREC 2003 [4] de la manera que se describirá a continuación. Un ejemplo de tema del TREC 2004 Terabyte track aparece en la Figura 3. El título es una frase corta y puede ser utilizada como una consulta al sistema de recuperación. El campo de descripción proporciona una declaración ligeramente más larga del requisito del tema, generalmente expresado como una sola oración completa o pregunta. Finalmente, la narrativa proporciona información adicional necesaria para especificar completamente el requisito, expresado en forma de un breve párrafo. Inicialmente, cada participante exploraría 50 temas ya sea de la categoría Terabyte o de la categoría Web y elegiría los 5 o 7 temas más interesantes. Para cada tema seleccionado, el participante básicamente realizaría la búsqueda web normal utilizando UCAIR para encontrar muchas páginas web relevantes utilizando el título del tema de la consulta como la palabra clave inicial de la consulta. Durante este proceso, el participante puede ver los resultados de la búsqueda y posiblemente hacer clic en algunos interesantes para ver las páginas web, tal como en una búsqueda web normal. No hay ningún requisito o restricción sobre cuántas consultas debe enviar el participante o cuándo debe detener la búsqueda de un tema. Cuando el participante planea cambiar el tema de búsqueda, simplemente presionará un botón 2 de la Conferencia de Recuperación de Texto: http://trec.nist.gov/ 829 Figura 2: Capturas de pantalla para volver a clasificar los resultados y evaluar los resultados de búsqueda antes de cambiar al siguiente tema. En el momento de la evaluación, los 30 resultados mejor clasificados de Google y UCAIR (algunos se superponen) se mezclan aleatoriamente para que el participante no sepa si un resultado proviene de Google o de UCAIR. El participante luego juzgaría la relevancia de estos resultados. Medimos la precisión en los primeros n (n = 5, 10, 20, 30) documentos de Google y UCAIR. También evaluamos precisiones en diferentes niveles de recuperación. En total, 368 documentos fueron considerados relevantes a partir de los resultados de búsqueda de Google y 429 documentos fueron considerados relevantes por los participantes de UCAIR. Los diagramas de dispersión de precisión en los 10 y 20 documentos principales se muestran en la Figura 4 y la Figura 5 respectivamente (El diagrama de dispersión de precisión en los 30 documentos principales es muy similar al de los 20 documentos principales). Cada punto de los gráficos de dispersión representa las precisiones de Google y UCAIR en un tema de consulta. La Tabla 2 muestra la precisión promedio en los primeros n documentos entre 32 temas. A partir de la Figura 4, la Figura 5 y la Tabla 2, vemos que los resultados de búsqueda de UCAIR son consistentemente mejores que los de Google en todas las medidas. Además, la mejora en el rendimiento es más dramática para la precisión en los primeros 20 documentos que para la precisión en los primeros 10 documentos. Una explicación para esto es que cuanto más interacción tenga el usuario con el sistema, más datos de clics se espera que UCAIR pueda recopilar. Por lo tanto, el sistema de recuperación puede construir modelos de usuario implícitos más precisos, lo que conduce a una mayor precisión en la recuperación. El Método de Clasificación prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Mejora 8.0% 17.8% 20.2% 21.8% Tabla 2: Tabla de precisión promedio en los primeros n documentos para 32 temas de consulta El gráfico en la Figura 6 muestra las curvas de precisión-recuperación para UCAIR y Google, donde se observa claramente que el rendimiento de UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Gráfico de dispersión de Precisión en los 10 primeros documentos Figura 4: La precisión en los 10 primeros documentos de UCAIR y Google es consistentemente y considerablemente mejor que la de Google en todos los niveles de recuperación. 6. CONCLUSIONES En este artículo, estudiamos cómo aprovechar la modelización implícita del usuario para personalizar de manera inteligente la recuperación de información y mejorar la precisión de la búsqueda. A diferencia de la mayoría de trabajos anteriores, enfatizamos el uso del contexto de búsqueda inmediata y la información de retroalimentación implícita, así como la actualización rápida de los resultados de búsqueda para beneficiar al máximo a un usuario. Presentamos un marco de trabajo de toma de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos adecuados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para volver a clasificar inmediatamente cualquier documento que aún no haya sido visto por el usuario. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente (UCAIR) sobre un motor de búsqueda popular (Google). Los experimentos en la búsqueda web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en más de un 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Gráfico de dispersión de Precisión en los 20 documentos principales Figura 5: Precisión en los 20 documentos principales de UCAIR y Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 precisión recall Curvas de Precisión-Recall Resultado de Google Resultado de UCAIR Figura 6: Precisión en los 20 resultados principales de UCAIR y Google Google. Dado que la información implícita que aprovechamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional. El agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin necesidad de esfuerzo adicional por parte del usuario. AGRADECIMIENTO Agradecemos a los seis participantes de nuestros experimentos de evaluación. Este trabajo fue apoyado en parte por las subvenciones de la Fundación Nacional de Ciencias IIS-0347933 e IIS-0428472. REFERENCIAS [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman y O. Frieder. Análisis por hora de un registro de consultas web muy grande categorizado por tema. En Actas de SIGIR 2004, páginas 321-328, 2004. [2] C. Clarke, N. Craswell e I. Soboroff. Resumen de la pista de terabyte TREC 2004. En Actas de TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda y D. Brown. Indicadores implícitos de interés. En Actas de Interfaces de Usuario Inteligentes 2001, páginas 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson y M. Wu. Resumen de la pista web TREC 2003. En Actas de TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend y V. Larvrenko. Retroalimentación de relevancia y personalización: Una perspectiva de modelado del lenguaje. En Actas del Segundo Taller DELOS: Personalización y Sistemas de Recomendación en Bibliotecas Digitales, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite y D. Harman. Resultados y desafíos en la evaluación de búsqueda en la web. Redes de Computadoras, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A. An, y D. Schuurmans. Identificación dinámica de sesiones de registro web con modelos de lenguaje estadístico. Revista de la Sociedad Americana de Ciencia de la Información y Tecnología, 55(14):1290-1303, 2004. [9] G. Jeh y J. Widom. Escalando la <br>búsqueda web personalizada</br>. En Actas de WWW 2003, páginas 271-279, 2003. [10] T. Joachims. Optimización de motores de búsqueda utilizando datos de clics. En Actas de SIGKDD 2002, páginas 133-142, 2002. [11] D. Kelly y J. Teevan. Retroalimentación implícita para inferir preferencias de usuario: Una bibliografía. SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En Actas de SIGIR01, páginas 111-119, 2001. [13] T. Lau y E. Horvitz. Patrones de búsqueda: Análisis y modelado de la refinación de consultas web. En Actas de la Séptima Conferencia Internacional sobre Modelado de Usuarios (UM), páginas 145-152, 1999. [14] V. Lavrenko y B. Croft. Modelos de lenguaje basados en relevancia. En Actas de SIGIR01, páginas 120-127, 2001. [15] M. Mitra, A. Singhal y C. Buckley. Mejorando la expansión automática de consultas. En Actas de SIGIR 1998, páginas 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg. Según Google, así va la nación. New York Times, mayo de 2003. [18] S. E. Robertson. El principio de clasificación de probabilidad en ı˚. Revista de Documentación, 33(4):294-304, 1977. [19] J. J. Rocchio. Retroalimentación de relevancia en la recuperación de información. En el Sistema de Recuperación SMART: Experimentos en el Procesamiento Automático de Documentos, páginas 313-323. Prentice-Hall Inc., 1971. [20] G. Salton y C. Buckley. Mejorando el rendimiento de recuperación mediante retroalimentación de recuperación. Revista de la Sociedad Americana de Ciencia de la Información, 41(4):288-297, 1990. [21] G. Salton y M. J. McGill. Introducción a la Recuperación de Información Moderna. McGraw-Hill, 1983. [22] X. Shen, B. Tan y C. Zhai. Recuperación de información sensible al contexto utilizando retroalimentación implícita. En Actas de SIGIR 2005, páginas 43-50, 2005. [23] X. Shen y C. Zhai. Explotando el historial de consultas para la clasificación de documentos en la recuperación de información interactiva (Póster). En Actas de SIGIR 2003, páginas 377-378, 2003. [24] A. Singhal. Recuperación de información moderna: Una breve visión general. Boletín del Comité Técnico de Ingeniería de Datos de la Sociedad de Computación de IEEE, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano y M. Yoshikawa. Búsqueda web adaptativa basada en el perfil del usuario construido sin ningún esfuerzo por parte de los usuarios. En Actas de WWW 2004, páginas 675-684, 2004. [26] E. Volokh. Personalización y privacidad. Comunicaciones de la ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen e I. Ruthven. Un estudio simulado de modelos de retroalimentación implícita. En Actas de ECIR 2004, páginas 311-326, 2004. [28] J. Xu y W. B. Croft. Expansión de consultas utilizando análisis local y global de documentos. En Actas de SIGIR 1996, páginas 4-11, 1996. [29] C. Zhai y J. Lafferty. Modelo de retroalimentación basado en el modelo de recuperación de divergencia de KL. En Actas de la CIKM 2001, páginas 403-410, 2001. 831 ",
            "candidates": [],
            "error": [
                [
                    "búsqueda web personalizado",
                    "búsqueda web personalizada",
                    "búsqueda web personalizada"
                ]
            ]
        },
        "interactive ir": {
            "translated_key": "IR interactivo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Implicit User Modeling for Personalized Search Xuehua Shen, Bin Tan, ChengXiang Zhai Department of Computer Science University of Illinois at Urbana-Champaign ABSTRACT Information retrieval systems (e.g., web search engines) are critical for overcoming information overload.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users, resulting in inherently non-optimal retrieval performance.",
                "For example, a tourist and a programmer may use the same word java to search for different information, but the current search systems would return the same results.",
                "In this paper, we study how to infer a users interest from the users search context and use the inferred implicit user model for personalized search .",
                "We present a decision theoretic framework and develop techniques for implicit user modeling in information retrieval.",
                "We develop an intelligent client-side web search agent (UCAIR) that can perform eager implicit feedback, e.g., query expansion based on previous queries and immediate result reranking based on clickthrough information.",
                "Experiments on web search show that our search agent can improve search accuracy over the popular Google search engine.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models, Relevance feedback, Search Process General Terms Algorithms 1.",
                "INTRODUCTION Although many information retrieval systems (e.g., web search engines and digital library systems) have been successfully deployed, the current retrieval systems are far from optimal.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users [17].",
                "This inherent non-optimality is seen clearly in the following two cases: (1) Different users may use exactly the same query (e.g., Java) to search for different information (e.g., the Java island in Indonesia or the Java programming language), but existing IR systems return the same results for these users.",
                "Without considering the actual user, it is impossible to know which sense Java refers to in a query. (2) A users information needs may change over time.",
                "The same user may use Java sometimes to mean the Java island in Indonesia and some other times to mean the programming language.",
                "Without recognizing the search context, it would be again impossible to recognize the correct sense.",
                "In order to optimize retrieval accuracy, we clearly need to model the user appropriately and personalize search according to each individual user.",
                "The major goal of user modeling for information retrieval is to accurately model a users information need, which is, unfortunately, a very difficult task.",
                "Indeed, it is even hard for a user to precisely describe what his/her information need is.",
                "What information is available for a system to infer a users information need?",
                "Obviously, the users query provides the most direct evidence.",
                "Indeed, most existing retrieval systems rely solely on the query to model a users information need.",
                "However, since a query is often extremely short, the user model constructed based on a keyword query is inevitably impoverished .",
                "An effective way to improve user modeling in information retrieval is to ask the user to explicitly specify which documents are relevant (i.e., useful for satisfying his/her information need), and then to improve user modeling based on such examples of relevant documents.",
                "This is called relevance feedback, which has been proved to be quite effective for improving retrieval accuracy [19, 20].",
                "Unfortunately, in real world applications, users are usually reluctant to make the extra effort to provide relevant examples for feedback [11].",
                "It is thus very interesting to study how to infer a users information need based on any implicit feedback information, which naturally exists through user interactions and thus does not require any extra user effort.",
                "Indeed, several previous studies have shown that implicit user modeling can improve retrieval accuracy.",
                "In [3], a web browser (Curious Browser) is developed to record a users explicit relevance ratings of web pages (relevance feedback) and browsing behavior when viewing a page, such as dwelling time, mouse click, mouse movement and scrolling (implicit feedback).",
                "It is shown that the dwelling time on a page, amount of scrolling on a page and the combination of time and scrolling have a strong correlation with explicit relevance ratings, which suggests that implicit feedback may be helpful for inferring user information need.",
                "In [10], user clickthrough data is collected as training data to learn a retrieval function, which is used to produce a customized ranking of search results that suits a group of users preferences.",
                "In [25], the clickthrough data collected over a long time period is exploited through query expansion to improve retrieval accuracy. 824 While a user may have general long term interests and preferences for information, often he/she is searching for documents to satisfy an ad-hoc information need, which only lasts for a short period of time; once the information need is satisfied, the user would generally no longer be interested in such information.",
                "For example, a user may be looking for information about used cars in order to buy one, but once the user has bought a car, he/she is generally no longer interested in such information.",
                "In such cases, implicit feedback information collected over a long period of time is unlikely to be very useful, but the immediate search context and feedback information, such as which of the search results for the current information need are viewed, can be expected to be much more useful.",
                "Consider the query Java again.",
                "Any of the following immediate feedback information about the user could potentially help determine the intended meaning of Java in the query: (1) The previous query submitted by the user is hashtable (as opposed to, e.g., travel Indonesia). (2) In the search results, the user viewed a page where words such as programming, software, and applet occur many times.",
                "To the best of our knowledge, how to exploit such immediate and short-term search context to improve search has so far not been well addressed in the previous work.",
                "In this paper, we study how to construct and update a user model based on the immediate search context and implicit feedback information and use the model to improve the accuracy of ad-hoc retrieval.",
                "In order to maximally benefit the user of a retrieval system through implicit user modeling, we propose to perform eager implicit feedback.",
                "That is, as soon as we observe any new piece of evidence from the user, we would update the systems belief about the users information need and respond with improved retrieval results based on the updated user model.",
                "We present a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "In a traditional retrieval paradigm, the retrieval problem is to match a query with documents and rank documents according to their relevance values.",
                "As a result, the retrieval process is a simple independent cycle of query and result display.",
                "In the proposed new retrieval paradigm, the users search context plays an important role and the inferred implicit user model is exploited immediately to benefit the user.",
                "The new retrieval paradigm is thus fundamentally different from the traditional paradigm, and is inherently more general.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent UCAIR (User-Centered Adaptive Information Retrieval) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "Thus the developed search agent can improve existing web search performance without additional effort from the user.",
                "The remaining sections are organized as follows.",
                "In Section 2, we discuss the related work.",
                "In Section 3, we present a decisiontheoretic interactive retrieval framework for implicit user modeling.",
                "In Section 4, we present the design and implementation of an intelligent client-side web search agent (UCAIR) that performs eager implicit feedback.",
                "In Section 5, we report our experiment results using the search agent.",
                "Section 6 concludes our work. 2.",
                "RELATED WORK Implicit user modeling for personalized search has been studied in previous work, but our work differs from all previous work in several aspects: (1) We emphasize the exploitation of immediate search context such as the related immediately preceding query and the viewed documents in the same session, while most previous work relies on long-term collection of implicit feedback information [25]. (2) We perform eager feedback and bring the benefit of implicit user modeling as soon as any new implicit feedback information is available, while the previous work mostly exploits longterm implicit feedback [10]. (3) We propose a retrieval framework to integrate implicit user modeling with the interactive retrieval process, while the previous work either studies implicit user modeling separately from retrieval [3] or only studies specific retrieval models for exploiting implicit feedback to better match a query with documents [23, 27, 22]. (4) We develop and evaluate a personalized Web search agent with online user studies, while most existing work evaluates algorithms offline without real user interactions.",
                "Currently some search engines provide rudimentary personalization, such as Google Personalized web search [6], which allows users to explicitly describe their interests by selecting from predefined topics, so that those results that match their interests are brought to the top, and My Yahoo! search [16], which gives users the option to save web sites they like and block those they dislike.",
                "In contrast, UCAIR personalizes web search through implicit user modeling without any additional user efforts.",
                "Furthermore, the personalization of UCAIR is provided on the client side.",
                "There are two remarkable advantages on this.",
                "First, the user does not need to worry about the privacy infringement, which is a big concern for personalized search [26].",
                "Second, both the computation of personalization and the storage of the user profile are done at the client side so that the server load is reduced dramatically [9].",
                "There have been many works studying user query logs [1] or query dynamics [13].",
                "UCAIR makes direct use of a users query history to benefit the same user immediately in the same search session.",
                "UCAIR first judges whether two neighboring queries belong to the same information session and if so, it selects terms from the previous query to perform query expansion.",
                "Our query expansion approach is similar to automatic query expansion [28, 15, 5], but instead of using pseudo feedback to expand the query, we use users implicit feedback information to expand the current query.",
                "These two techniques may be combined. 3.",
                "OPTIMIZATION IN <br>interactive ir</br> In <br>interactive ir</br>, a user interacts with the retrieval system through an action dialogue, in which the system responds to each user action with some system action.",
                "For example, the users action may be submitting a query and the systems response may be returning a list of 10 document summaries.",
                "In general, the space of user actions and system responses and their granularities would depend on the interface of a particular retrieval system.",
                "In principle, every action of the user can potentially provide new evidence to help the system better infer the users information need.",
                "Thus in order to respond optimally, the system should use all the evidence collected so far about the user when choosing a response.",
                "When viewed in this way, most existing search engines are clearly non-optimal.",
                "For example, if a user has viewed some documents on the first page of search results, when the user clicks on the Next link to fetch more results, an existing retrieval system would still return the next page of results retrieved based on the original query without considering the new evidence that a particular result has been viewed by the user. 825 We propose to optimize retrieval performance by adapting system responses based on every action that a user has taken, and cast the optimization problem as a decision task.",
                "Specifically, at any time, the system would attempt to do two tasks: (1) User model updating: Monitor any useful evidence from the user regarding his/her information need and update the user model as soon as such evidence is available; (2) Improving search results: Rerank immediately all the documents that the user has not yet seen, as soon as the user model is updated.",
                "We emphasize eager updating and reranking, which makes our work quite different from any existing work.",
                "Below we present a formal decision theoretic framework for optimizing retrieval performance through implicit user modeling in interactive information retrieval. 3.1 A decision-theoretic framework Let A be the set of all user actions and R(a) be the set of all possible system responses to a user action a ∈ A.",
                "At any time, let At = (a1, ..., at) be the observed sequence of user actions so far (up to time point t) and Rt−1 = (r1, ..., rt−1) be the responses that the system has made responding to the user actions.",
                "The systems goal is to choose an optimal response rt ∈ R(at) for the current user action at.",
                "Let M be the space of all possible user models.",
                "We further define a loss function L(a, r, m) ∈ , where a ∈ A is a user action, r ∈ R(a) is a system response, and m ∈ M is a user model.",
                "L(a, r, m) encodes our decision preferences and assesses the optimality of responding with r when the current user model is m and the current user action is a.",
                "According to Bayesian decision theory, the optimal decision at time t is to choose a response that minimizes the Bayes risk, i.e., r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) where P(mt|U, D, At, Rt−1) is the posterior probability of the user model mt given all the observations about the user U we have made up to time t. To simplify the computation of Equation 1, let us assume that the posterior probability mass P(mt|U, D, At, Rt−1) is mostly concentrated on the mode m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "We can then approximate the integral with the value of the loss function at m∗ t .",
                "That is, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) where m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "Leaving aside how to define and estimate these probabilistic models and the loss function, we can see that such a decision-theoretic formulation suggests that, in order to choose the optimal response to at, the system should perform two tasks: (1) compute the current user model and obtain m∗ t based on all the useful information. (2) choose a response rt to minimize the loss function value L(at, rt, m∗ t ).",
                "When at does not affect our belief about m∗ t , the first step can be omitted and we may reuse m∗ t−1 for m∗ t .",
                "Note that our framework is quite general since we can potentially model any kind of user actions and system responses.",
                "In most cases, as we may expect, the systems response is some ranking of documents, i.e., for most actions a, R(a) consists of all the possible rankings of the unseen documents, and the decision problem boils down to choosing the best ranking of unseen documents based on the most current user model.",
                "When a is the action of submitting a keyword query, such a response is exactly what a current retrieval system would do.",
                "However, we can easily imagine that a more intelligent web search engine would respond to a users clicking of the Next link (to fetch more unseen results) with a more optimized ranking of documents based on any viewed documents in the current page of results.",
                "In fact, according to our eager updating strategy, we may even allow a system to respond to a users clicking of browsers Back button after viewing a document in the same way, so that the user can maximally benefit from implicit feedback.",
                "These are precisely what our UCAIR system does. 3.2 User models A user model m ∈ M represents what we know about the user U, so in principle, it can contain any information about the user that we wish to model.",
                "We now discuss two important components in a user model.",
                "The first component is a component model of the users information need.",
                "Presumably, the most important factor affecting the optimality of the systems response is how well the response addresses the users information need.",
                "Indeed, at any time, we may assume that the system has some belief about what the user is interested in, which we model through a term vector x = (x1, ..., x|V |), where V = {w1, ..., w|V |} is the set of all terms (i.e., vocabulary) and xi is the weight of term wi.",
                "Such a term vector is commonly used in information retrieval to represent both queries and documents.",
                "For example, the vector-space model, assumes that both the query and the documents are represented as term vectors and the score of a document with respect to a query is computed based on the similarity between the query vector and the document vector [21].",
                "In a language modeling approach, we may also regard the query unigram language model [12, 29] or the relevance model [14] as a term vector representation of the users information need.",
                "Intuitively, x would assign high weights to terms that characterize the topics which the user is interested in.",
                "The second component we may include in our user model is the documents that the user has already viewed.",
                "Obviously, even if a document is relevant, if the user has already seen the document, it would not be useful to present the same document again.",
                "We thus introduce another variable S ⊂ D (D is the whole set of documents in the collection) to denote the subset of documents in the search results that the user has already seen/viewed.",
                "In general, at time t, we may represent a user model as mt = (S, x, At, Rt−1), where S is the seen documents, x is the systems understanding of the users information need, and (At, Rt−1) represents the users interaction history.",
                "Note that an even more general user model may also include other factors such as the users reading level and occupation.",
                "If we assume that the uncertainty of a user model mt is solely due to the uncertainty of x, the computation of our current estimate of user model m∗ t will mainly involve computing our best estimate of x.",
                "That is, the system would choose a response according to r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) where x∗ = argmaxx P(x|U, D, At, Rt−1).",
                "This is the decision mechanism implemented in the UCAIR system to be described later.",
                "In this system, we avoided specifying the probabilistic model P(x|U, D, At, Rt−1) by computing x∗ directly with some existing feedback method. 3.3 Loss functions The exact definition of loss function L depends on the responses, thus it is inevitably application-specific.",
                "We now briefly discuss some possibilities when the response is to rank all the unseen documents and present the top k of them.",
                "Let r = (d1, ..., dk) be the top k documents, S be the set of seen documents by the user, and x∗ be the systems best guess of the users information need.",
                "We 826 may simply define the loss associated with r as the negative sum of the probability that each of the di is relevant, i.e., L(a, r, m) = − k i=1 P(relevant|di, m).",
                "Clearly, in order to minimize this loss function, the optimal response r would contain the k documents with the highest probability of relevance, which is intuitively reasonable.",
                "One deficiency of this top-k loss function is that it is not sensitive to the internal order of the selected top k documents, so switching the ranking order of a non-relevant document and a relevant one would not affect the loss, which is unreasonable.",
                "To model ranking, we can introduce a factor of the user model - the probability of each of the k documents being viewed by the user, P(view|di), and define the following ranking loss function: L(a, r, m) = − k i=1 P(view|di)P(relevant|di, m) Since in general, if di is ranked above dj (i.e., i < j), P(view|di) > P(view|dj), this loss function would favor a decision to rank relevant documents above non-relevant ones, as otherwise, we could always switch di with dj to reduce the loss value.",
                "Thus the system should simply perform a regular retrieval and rank documents according to the probability of relevance [18].",
                "Depending on the users retrieval preferences, there can be many other possibilities.",
                "For example, if the user does not want to see redundant documents, the loss function should include some redundancy measure on r based on the already seen documents S. Of course, when the response is not to choose a ranked list of documents, we would need a different loss function.",
                "We discuss one such example that is relevant to the search agent that we implement.",
                "When a user enters a query qt (current action), our search agent relies on some existing search engine to actually carry out search.",
                "In such a case, even though the search agent does not have control of the retrieval algorithm, it can still attempt to optimize the search results through refining the query sent to the search engine and/or reranking the results obtained from the search engine.",
                "The loss functions for reranking are already discussed above; we now take a look at the loss functions for query refinement.",
                "Let f be the retrieval function of the search engine that our agent uses so that f(q) would give us the search results using query q.",
                "Given that the current action of the user is entering a query qt (i.e., at = qt), our response would be f(q) for some q.",
                "Since we have no choice of f, our decision is to choose a good q.",
                "Formally, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) which shows that our goal is to find q∗ = argminqL(qt, f(q), m), i.e., an optimal query that would give us the best f(q).",
                "A different choice of loss function L(qt, f(q), m) would lead to a different query refinement strategy.",
                "In UCAIR, we heuristically compute q∗ by expanding qt with terms extracted from rt−1 whenever qt−1 and qt have high similarity.",
                "Note that rt−1 and qt−1 are contained in m as part of the users interaction history. 3.4 Implicit user modeling Implicit user modeling is captured in our framework through the computation of x∗ = argmaxx P(x|U, D, At, Rt−1), i.e., the systems current belief of what the users information need is.",
                "Here again there may be many possibilities, leading to different algorithms for implicit user modeling.",
                "We now discuss a few of them.",
                "First, when two consecutive queries are related, the previous query can be exploited to enrich the current query and provide more search context to help disambiguation.",
                "For this purpose, instead of performing query expansion as we did in the previous section, we could also compute an updated x∗ based on the previous query and retrieval results.",
                "The computed new user model can then be used to rank the documents with a standard information retrieval model.",
                "Second, we can also infer a users interest based on the summaries of the viewed documents.",
                "When a user is presented with a list of summaries of top ranked documents, if the user chooses to skip the first n documents and to view the (n+1)-th document, we may infer that the user is not interested in the displayed summaries for the first n documents, but is attracted by the displayed summary of the (n + 1)-th document.",
                "We can thus use these summaries as negative and positive examples to learn a more accurate user model x∗ .",
                "Here many standard relevance feedback techniques can be exploited [19, 20].",
                "Note that we should use the displayed summaries, as opposed to the actual contents of those documents, since it is possible that the displayed summary of the viewed document is relevant, but the document content is actually not.",
                "Similarly, a displayed summary may mislead a user to skip a relevant document.",
                "Inferring user models based on such displayed information, rather than the actual content of a document is an important difference between UCAIR and some other similar systems.",
                "In UCAIR, both of these strategies for inferring an implicit user model are implemented. 4.",
                "UCAIR: A PERSONALIZED SEARCH AGENT 4.1 Design In this section, we present a client-side web search agent called UCAIR, in which we implement some of the methods discussed in the previous section for performing personalized search through implicit user modeling.",
                "UCAIR is a web browser plug-in 1 that acts as a proxy for web search engines.",
                "Currently, it is only implemented for Internet Explorer and Google, but it is a matter of engineering to make it run on other web browsers and interact with other search engines.",
                "The issue of privacy is a primary obstacle for deploying any real world applications involving serious user modeling, such as personalized search.",
                "For this reason, UCAIR is strictly running as a client-side search agent, as opposed to a server-side application.",
                "This way, the captured user information always resides on the computer that the user is using, thus the user does not need to release any information to the outside.",
                "Client-side personalization also allows the system to easily observe a lot of user information that may not be easily available to a server.",
                "Furthermore, performing personalized search on the client-side is more scalable than on the serverside, since the overhead of computation and storage is distributed among clients.",
                "As shown in Figure 1, the UCAIR toolbar has 3 major components: (1) The (implicit) user modeling module captures a users search context and history information, including the submitted queries and any clicked search results and infers search session boundaries. (2) The query modification module selectively improves the query formulation according to the current user model. (3) The result re-ranking module immediately re-ranks any unseen search results whenever the user model is updated.",
                "In UCAIR, we consider four basic user actions: (1) submitting a keyword query; (2) viewing a document; (3) clicking the Back button; (4) clicking the Next link on a result page.",
                "For each of these four actions, the system responds with, respectively, (1) 1 UCAIR is available at: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Search Engine (e.g., Google) Search History Log (e.g.,past queries, clicked results) Query Modification Result Re-Ranking User Modeling Result Buffer UCAIR Userquery results clickthrough… Figure 1: UCAIR architecture generating a ranked list of results by sending a possibly expanded query to a search engine; (2) updating the information need model x; (3) reranking the unseen results on the current result page based on the current model x; and (4) reranking the unseen pages and generating the next page of results based on the current model x.",
                "Behind these responses, there are three basic tasks: (1) Decide whether the previous query is related to the current query and if so expand the current query with useful terms from the previous query or the results of the previous query. (2) Update the information need model x based on a newly clicked document summary. (3) Rerank a set of unseen documents based on the current model x.",
                "Below we describe our algorithms for each of them. 4.2 Session boundary detection and query expansion To effectively exploit previous queries and their corresponding clickthrough information, UCAIR needs to judge whether two adjacent queries belong to the same search session (i.e., detect session boundaries).",
                "Existing work on session boundary detection is mostly in the context of web log analysis (e.g., [8]), and uses statistical information rather than textual features.",
                "Since our clientside agent does not have access to server query logs, we make session boundary decisions based on textual similarity between two queries.",
                "Because related queries do not necessarily share the same words (e.g., java island and travel Indonesia), it is insufficient to use only query text.",
                "Therefore we use the search results of the two queries to help decide whether they are topically related.",
                "For example, for the above queries java island and travel Indonesia, the words java, bali, island, indonesia and travel may occur frequently in both queries search results, yielding a high similarity score.",
                "We only use the titles and summaries of the search results to calculate the similarity since they are available in the retrieved search result page and fetching the full text of every result page would significantly slow down the process.",
                "To compensate for the terseness of titles and summaries, we retrieve more results than a user would normally view for the purpose of detecting session boundaries (typically 50 results).",
                "The similarity between the previous query q and the current query q is computed as follows.",
                "Let {s1, s2, . . . , sn } and {s1, s2, . . . , sn} be the result sets for the two queries.",
                "We use the pivoted normalization TF-IDF weighting formula [24] to compute a term weight vector si for each result si.",
                "We define the average result savg to be the centroid of all the result vectors, i.e., (s1 + s2 + . . . + sn)/n.",
                "The cosine similarity between the two average results is calculated as s avg · savg/ s 2 avg · s2 avg If the similarity value exceeds a predefined threshold, the two queries will be considered to be in the same information session.",
                "If the previous query and the current query are found to belong to the same search session, UCAIR would attempt to expand the current query with terms from the previous query and its search results.",
                "Specifically, for each term in the previous query or the corresponding search results, if its frequency in the results of the current query is greater than a preset threshold (e.g. 5 results out of 50), the term would be added to the current query to form an expanded query.",
                "In this case, UCAIR would send this expanded query rather than the original one to the search engine and return the results corresponding to the expanded query.",
                "Currently, UCAIR only uses the immediate preceding query for query expansion; in principle, we could exploit all related past queries. 4.3 Information need model updating Suppose at time t, we have observed that the user has viewed k documents whose summaries are s1, ..., sk.",
                "We update our user model by computing a new information need vector with a standard feedback method in information retrieval (i.e., Rocchio [19]).",
                "According to the vector space retrieval model, each clicked summary si can be represented by a term weight vector si with each term weighted by a TF-IDF weighting formula [21].",
                "Rocchio computes the centroid vector of all the summaries and interpolates it with the original query vector to obtain an updated term vector.",
                "That is, x = αq + (1 − α) 1 k k i=1 si where q is the query vector, k is the number of summaries the user clicks immediately following the current query and α is a parameter that controls the influence of the clicked summaries on the inferred information need model.",
                "In our experiments, α is set to 0.5.",
                "Note that we update the information need model whenever the user views a document. 4.4 Result reranking In general, we want to rerank all the unseen results as soon as the user model is updated.",
                "Currently, UCAIR implements reranking in two cases, corresponding to the user clicking the Back button and Next link in the Internet Explorer.",
                "In both cases, the current (updated) user model would be used to rerank the unseen results so that the user would see improved search results immediately.",
                "To rerank any unseen document summaries, UCAIR uses the standard vector space retrieval model and scores each summary based on the similarity of the result and the current user information need vector x [21].",
                "Since implicit feedback is not completely reliable, we bring up only a small number (e.g. 5) of highest reranked results to be followed by any originally high ranked results. 828 Google result (user query = java map) UCAIR result (user query =java map) previous query = travel Indonesia previous query = hashtable expanded user query = java map Indonesia expanded user query = java map class 1 Java map projections of the world ... Lonely Planet - Indonesia Map Map (Java 2 Platform SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Java map projections of the world ... INDONESIA TOURISM : CENTRAL JAVA - MAP Java 2 Platform SE v1.3.1: Interface Map www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Java Map INDONESIA TOURISM : WEST JAVA - MAP An Introduction to Java Map Collection Classes java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Java Technology Concept Map IndoStreets - Java Map An Introduction to Java Map Collection Classes java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Indonesia Regions and Islands Maps, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 An Introduction to Java Map Collection Classes Indonesia City Street Map,... Hibernate simplifies inheritance mapping www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Java Map Maps Of Indonesia tmap 30.map Class Hierarchy www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Java API Map Maps of Indonesia by Peter Loud Class Scope www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas : Sam Maps of Indonesia by Peter Loud Class PrintSafeHashMap www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 INDONESIA TOURISM : WEST JAVA - MAP indonesiaphoto.com Java Pro - Union and Vertical Mapping of Classes www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Table 1: Sample results of query expansion 5.",
                "EVALUATION OF UCAIR We now present some results on evaluating the two major UCAIR functions: selective query expansion and result reranking based on user clickthrough data. 5.1 Sample results The query expansion strategy implemented in UCAIR is intentionally conservative to avoid misinterpretation of implicit user models.",
                "In practice, whenever it chooses to expand the query, the expansion usually makes sense.",
                "In Table 1, we show how UCAIR can successfully distinguish two different search contexts for the query java map, corresponding to two different previous queries (i.e., travel Indonesia vs. hashtable).",
                "Due to implicit user modeling, UCAIR intelligently figures out to add Indonesia and class, respectively, to the users query java map, which would otherwise be ambiguous as shown in the original results from Google on March 21, 2005.",
                "UCAIRs results are much more accurate than Googles results and reflect personalization in search.",
                "The eager implicit feedback component is designed to immediately respond to a users activity such as viewing a document.",
                "In Figure 2, we show how UCAIR can successfully disambiguate an ambiguous query jaguar by exploiting a viewed document summary.",
                "In this case, the initial retrieval results using jaguar (shown on the left side) contain two results about the Jaguar cars followed by two results about the Jaguar software.",
                "However, after the user views the web page content of the second result (about Jaguar car) and returns to the search result page by clicking Back button, UCAIR automatically nominates two new search results about Jaguar cars (shown on the right side), while the original two results about Jaguar software are pushed down on the list (unseen from the picture). 5.2 Quantitative evaluation To further evaluate UCAIR quantitatively, we conduct a user study on the effectiveness of the eager implicit feedback component.",
                "It is a challenge to quantitatively evaluate the potential performance improvement of our proposed model and UCAIR over Google in an unbiased way [7].",
                "Here, we design a user study, in which participants would do normal web search and judge a randomly and anonymously mixed set of results from Google and UCAIR at the end of the search session; participants do not know whether a result comes from Google or UCAIR.",
                "We recruited 6 graduate students for this user study, who have different backgrounds (3 computer science, 2 biology, and 1 chem<top> <num> Number: 716 <title> Spammer arrest sue <desc> Description: Have any spammers been arrested or sued for sending unsolicited e-mail? <narr> Narrative: Instances of arrests, prosecutions, convictions, and punishments of spammers, and lawsuits against them are relevant.",
                "Documents which describe laws to limit spam without giving details of lawsuits or criminal trials are not relevant. </top> Figure 3: An example of TREC query topic, expressed in a form which might be given to a human assistant or librarian istry).",
                "We use query topics from TREC 2 2004 Terabyte track [2] and TREC 2003 Web track [4] topic distillation task in the way to be described below.",
                "An example topic from TREC 2004 Terabyte track appears in Figure 3.",
                "The title is a short phrase and may be used as a query to the retrieval system.",
                "The description field provides a slightly longer statement of the topic requirement, usually expressed as a single complete sentence or question.",
                "Finally the narrative supplies additional information necessary to fully specify the requirement, expressed in the form of a short paragraph.",
                "Initially, each participant would browse 50 topics either from Terabyte track or Web track and pick 5 or 7 most interesting topics.",
                "For each picked topic, the participant would essentially do the normal web search using UCAIR to find many relevant web pages by using the title of the query topic as the initial keyword query.",
                "During this process, the participant may view the search results and possibly click on some interesting ones to view the web pages, just as in a normal web search.",
                "There is no requirement or restriction on how many queries the participant must submit or when the participant should stop the search for one topic.",
                "When the participant plans to change the search topic, he/she will simply press a button 2 Text REtrieval Conference: http://trec.nist.gov/ 829 Figure 2: Screen shots for result reranking to evaluate the search results before actually switching to the next topic.",
                "At the time of evaluation, 30 top ranked results from Google and UCAIR (some are overlapping) are randomly mixed together so that the participant would not know whether a result comes from Google or UCAIR.",
                "The participant would then judge the relevance of these results.",
                "We measure precision at top n (n = 5, 10, 20, 30) documents of Google and UCAIR.",
                "We also evaluate precisions at different recall levels.",
                "Altogether, 368 documents judged as relevant from Google search results and 429 documents judged as relevant from UCAIR by participants.",
                "Scatter plots of precision at top 10 and top 20 documents are shown in Figure 4 and Figure 5 respectively (The scatter plot of precision at top 30 documents is very similar to precision at top 20 documents).",
                "Each point of the scatter plots represents the precisions of Google and UCAIR on one query topic.",
                "Table 2 shows the average precision at top n documents among 32 topics.",
                "From Figure 4, Figure 5 and Table 2, we see that the search results from UCAIR are consistently better than those from Google by all the measures.",
                "Moreover, the performance improvement is more dramatic for precision at top 20 documents than that at precision at top 10 documents.",
                "One explanation for this is that the more interaction the user has with the system, the more clickthrough data UCAIR can be expected to collect.",
                "Thus the retrieval system can build more precise implicit user models, which lead to better retrieval accuracy.",
                "Ranking Method prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Improvement 8.0% 17.8% 20.2% 21.8% Table 2: Table of average precision at top n documents for 32 query topics The plot in Figure 6 shows the precision-recall curves for UCAIR and Google, where it is clearly seen that the performance of UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Scatterplot of Precision at Top 10 Documents Figure 4: Precision at top 10 documents of UCAIR and Google is consistently and considerably better than that of Google at all levels of recall. 6.",
                "CONCLUSIONS In this paper, we studied how to exploit implicit user modeling to intelligently personalize information retrieval and improve search accuracy.",
                "Unlike most previous work, we emphasize the use of immediate search context and implicit feedback information as well as eager updating of search results to maximally benefit a user.",
                "We presented a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent (UCAIR) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Scatterplot of Precision at Top 20 documents Figure 5: Precision at top 20 documents of UCAIR and Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 recall precision Precision−Recall curves Google Result UCAIR Result Figure 6: Precision at top 20 result of UCAIR and Google Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "The developed search agent thus can improve existing web search performance without any additional effort from the user. 7.",
                "ACKNOWLEDGEMENT We thank the six participants of our evaluation experiments.",
                "This work was supported in part by the National Science Foundation grants IIS-0347933 and IIS-0428472. 8.",
                "REFERENCES [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman, and O. Frieder.",
                "Hourly analysis of a very large topically categorized web query log.",
                "In Proceedings of SIGIR 2004, pages 321-328, 2004. [2] C. Clarke, N. Craswell, and I. Soboroff.",
                "Overview of the TREC 2004 terabyte track.",
                "In Proceedings of TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda, and D. Brown.",
                "Implicit interest indicators.",
                "In Proceedings of Intelligent User Interfaces 2001, pages 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson, and M. Wu.",
                "Overview of the TREC 2003 web track.",
                "In Proceedings of TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend, and V. Larvrenko.",
                "Relevance feedback and personalization: A language modeling perspective.",
                "In Proeedings of Second DELOS Workshop: Personalisation and Recommender Systems in Digital Libraries, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite, and D. Harman.",
                "Results and challenges in web search evaluation.",
                "Computer Networks, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A.",
                "An, and D. Schuurmans.",
                "Dynamic web log session identification with statistical language models.",
                "Journal of the American Society for Information Science and Technology, 55(14):1290-1303, 2004. [9] G. Jeh and J. Widom.",
                "Scaling personalized web search.",
                "In Proceedings of WWW 2003, pages 271-279, 2003. [10] T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of SIGKDD 2002, pages 133-142, 2002. [11] D. Kelly and J. Teevan.",
                "Implicit feedback for inferring user preference: A bibliography.",
                "SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of SIGIR01, pages 111-119, 2001. [13] T. Lau and E. Horvitz.",
                "Patterns of search: Analyzing and modeling web query refinement.",
                "In Proceedings of the Seventh International Conference on User Modeling (UM), pages 145 -152, 1999. [14] V. Lavrenko and B. Croft.",
                "Relevance-based language models.",
                "In Proceedings of SIGIR01, pages 120-127, 2001. [15] M. Mitra, A. Singhal, and C. Buckley.",
                "Improving automatic query expansion.",
                "In Proceedings of SIGIR 1998, pages 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg.",
                "As google goes, so goes the nation.",
                "New York Times, May 2003. [18] S. E. Robertson.",
                "The probability ranking principle in ı˚.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] J. J. Rocchio.",
                "Relevance feedback in information retrieval.",
                "In The SMART Retrieval System: Experiments in Automatic Document Processing, pages 313-323.",
                "Prentice-Hall Inc., 1971. [20] G. Salton and C. Buckley.",
                "Improving retrieval performance by retrieval feedback.",
                "Journal of the American Society for Information Science, 41(4):288-297, 1990. [21] G. Salton and M. J. McGill.",
                "Introduction to Modern Information Retrieval.",
                "McGraw-Hill, 1983. [22] X. Shen, B. Tan, and C. Zhai.",
                "Context-sensitive information retrieval using implicit feedback.",
                "In Proceedings of SIGIR 2005, pages 43-50, 2005. [23] X. Shen and C. Zhai.",
                "Exploiting query history for document ranking in interactive information retrieval (Poster).",
                "In Proceedings of SIGIR 2003, pages 377-378, 2003. [24] A. Singhal.",
                "Modern information retrieval: A brief overview.",
                "Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano, and M. Yoshikawa.",
                "Adaptive web search based on user profile constructed without any effort from users.",
                "In Proceedings of WWW 2004, pages 675-684, 2004. [26] E. Volokh.",
                "Personalization and privacy.",
                "Communications of the ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen, and I. Ruthven.",
                "A simulated study of implicit feedback models.",
                "In Proceedings of ECIR 2004, pages 311-326, 2004. [28] J. Xu and W. B. Croft.",
                "Query expansion using local and global document analysis.",
                "In Proceedings of SIGIR 1996, pages 4-11, 1996. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in KL divergence retrieval model.",
                "In Proceedings of the CIKM 2001, pages 403-410, 2001. 831"
            ],
            "original_annotated_samples": [
                "OPTIMIZATION IN <br>interactive ir</br> In <br>interactive ir</br>, a user interacts with the retrieval system through an action dialogue, in which the system responds to each user action with some system action."
            ],
            "translated_annotated_samples": [
                "OPTIMIZACIÓN EN IR INTERACTIVO En <br>IR interactivo</br>, un usuario interactúa con el sistema de recuperación a través de un diálogo de acción, en el cual el sistema responde a cada acción del usuario con alguna acción del sistema."
            ],
            "translated_text": "Modelado implícito de usuarios para búsqueda personalizada Xuehua Shen, Bin Tan, ChengXiang Zhai Departamento de Ciencias de la Computación Universidad de Illinois en Urbana-Champaign RESUMEN Los sistemas de recuperación de información (por ejemplo, motores de búsqueda web) son críticos para superar la sobrecarga de información. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales, lo que resulta en un rendimiento de recuperación inherentemente no óptimo. Por ejemplo, un turista y un programador pueden usar la misma palabra \"java\" para buscar información diferente, pero los sistemas de búsqueda actuales devolverían los mismos resultados. En este artículo, estudiamos cómo inferir el interés de un usuario a partir del contexto de búsqueda del usuario y utilizar el modelo de usuario implícito inferido para la búsqueda personalizada. Presentamos un marco teórico de toma de decisiones y desarrollamos técnicas para el modelado implícito del usuario en la recuperación de información. Desarrollamos un agente de búsqueda web inteligente del lado del cliente (UCAIR) que puede realizar retroalimentación implícita ansiosa, por ejemplo, expansión de consultas basada en consultas anteriores y reordenamiento inmediato de resultados basado en información de clics. Los experimentos sobre la búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda sobre el popular motor de búsqueda Google. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación, Retroalimentación de relevancia, Proceso de búsqueda Términos Generales Algoritmos 1. Aunque muchos sistemas de recuperación de información (por ejemplo, motores de búsqueda web y sistemas de biblioteca digital) se han implementado con éxito, los sistemas de recuperación actuales están lejos de ser óptimos. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales [17]. Esta no optimalidad inherente se ve claramente en los siguientes dos casos: (1) Diferentes usuarios pueden utilizar exactamente la misma consulta (por ejemplo, Java) para buscar información diferente (por ejemplo, la isla de Java en Indonesia o el lenguaje de programación Java), pero los sistemas de IR existentes devuelven los mismos resultados para estos usuarios. Sin considerar al usuario actual, es imposible saber a qué sentido se refiere Java en una consulta. (2) Las necesidades de información de un usuario pueden cambiar con el tiempo. El mismo usuario puede usar Java a veces para referirse a la isla de Java en Indonesia y otras veces para referirse al lenguaje de programación. Sin reconocer el contexto de búsqueda, sería nuevamente imposible reconocer el sentido correcto. Para optimizar la precisión de la recuperación, claramente necesitamos modelar al usuario de manera adecuada y personalizar la búsqueda según cada usuario individual. El objetivo principal del modelado de usuario para la recuperación de información es modelar con precisión la necesidad de información de un usuario, lo cual, desafortunadamente, es una tarea muy difícil. De hecho, incluso resulta difícil para un usuario describir con precisión cuál es su necesidad de información. ¿Qué información está disponible para que un sistema pueda inferir la necesidad de información de un usuario? Obviamente, la consulta de los usuarios proporciona la evidencia más directa. De hecho, la mayoría de los sistemas de recuperación existentes se basan únicamente en la consulta para modelar la necesidad de información de los usuarios. Sin embargo, dado que una consulta suele ser extremadamente corta, el modelo de usuario construido basado en una consulta de palabras clave inevitablemente resulta empobrecido. Una forma efectiva de mejorar la modelización de usuarios en la recuperación de información es pedir al usuario que especifique explícitamente qué documentos son relevantes (es decir, útiles para satisfacer su necesidad de información) y luego mejorar la modelización de usuarios basándose en ejemplos de documentos relevantes. Esto se llama retroalimentación de relevancia, lo cual ha demostrado ser bastante efectivo para mejorar la precisión de recuperación [19, 20]. Desafortunadamente, en aplicaciones del mundo real, los usuarios suelen ser reacios a hacer el esfuerzo adicional de proporcionar ejemplos relevantes para retroalimentación [11]. Por lo tanto, es muy interesante estudiar cómo inferir la necesidad de información de un usuario basándose en cualquier información de retroalimentación implícita, la cual existe naturalmente a través de las interacciones del usuario y no requiere ningún esfuerzo adicional por parte del usuario. De hecho, varios estudios previos han demostrado que el modelado implícito del usuario puede mejorar la precisión de recuperación. En [3], se desarrolla un navegador web (Curious Browser) para registrar las calificaciones explícitas de relevancia de las páginas web por parte de los usuarios (retroalimentación de relevancia) y el comportamiento de navegación al ver una página, como el tiempo de permanencia, clics de ratón, movimiento del ratón y desplazamiento (retroalimentación implícita). Se muestra que el tiempo de permanencia en una página, la cantidad de desplazamiento en una página y la combinación de tiempo y desplazamiento tienen una fuerte correlación con las calificaciones de relevancia explícita, lo que sugiere que la retroalimentación implícita puede ser útil para inferir la necesidad de información del usuario. En [10], se recopilan datos de clics de usuario como datos de entrenamiento para aprender una función de recuperación, que se utiliza para producir un ranking personalizado de resultados de búsqueda que se adapte a las preferencias de un grupo de usuarios. En [25], los datos de clics recopilados durante un largo período de tiempo se utilizan a través de la expansión de consultas para mejorar la precisión de recuperación. Si bien un usuario puede tener intereses y preferencias generales a largo plazo para la información, a menudo está buscando documentos para satisfacer una necesidad de información ad-hoc, que solo dura un corto período de tiempo; una vez que se satisface la necesidad de información, el usuario generalmente ya no estaría interesado en esa información. Por ejemplo, un usuario puede estar buscando información sobre autos usados para comprar uno, pero una vez que el usuario ha comprado un auto, generalmente ya no está interesado en esa información. En tales casos, la información de retroalimentación implícita recopilada durante un largo período de tiempo es poco probable que sea muy útil, pero el contexto de búsqueda inmediato y la información de retroalimentación, como cuáles de los resultados de búsqueda para la necesidad de información actual son vistos, se espera que sean mucho más útiles. Considera la consulta de Java nuevamente. Cualquiera de la siguiente información de retroalimentación inmediata sobre el usuario podría potencialmente ayudar a determinar el significado previsto de Java en la consulta: (1) La consulta anterior enviada por el usuario es hashtable (en lugar de, por ejemplo, viajar a Indonesia). (2) En los resultados de búsqueda, el usuario visualizó una página donde palabras como programación, software y applet ocurren muchas veces. Hasta donde sabemos, cómo aprovechar este contexto de búsqueda inmediato y a corto plazo para mejorar la búsqueda aún no ha sido abordado de manera satisfactoria en trabajos anteriores. En este artículo, estudiamos cómo construir y actualizar un modelo de usuario basado en el contexto de búsqueda inmediato y la información de retroalimentación implícita, y utilizar el modelo para mejorar la precisión de la recuperación ad-hoc. Para beneficiar al máximo al usuario de un sistema de recuperación a través de modelado implícito del usuario, proponemos realizar retroalimentación implícita entusiasta. Es decir, tan pronto como observemos cualquier nueva pieza de evidencia del usuario, actualizaríamos la creencia del sistema sobre la necesidad de información del usuario y responderíamos con resultados de recuperación mejorados basados en el modelo de usuario actualizado. Presentamos un marco de trabajo de teoría de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. En un paradigma de recuperación tradicional, el problema de recuperación consiste en emparejar una consulta con documentos y clasificar los documentos según sus valores de relevancia. Como resultado, el proceso de recuperación es un ciclo independiente simple de consulta y visualización de resultados. En el nuevo paradigma de recuperación propuesto, el contexto de búsqueda de los usuarios juega un papel importante y el modelo de usuario implícito inferido se explota inmediatamente para beneficiar al usuario. El nuevo paradigma de recuperación es, por lo tanto, fundamentalmente diferente del paradigma tradicional y es inherentemente más general. Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos apropiados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para reordenar inmediatamente cualquier documento que aún no haya sido visto por el usuario. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente UCAIR (Recuperación de Información Adaptativa Centrada en el Usuario) sobre un motor de búsqueda popular (Google). Los experimentos sobre búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en comparación con Google. Dado que la información implícita que explotamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional. Por lo tanto, el agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin esfuerzo adicional por parte del usuario. Las secciones restantes están organizadas de la siguiente manera. En la Sección 2, discutimos el trabajo relacionado. En la Sección 3, presentamos un marco de recuperación interactiva basado en teoría de decisiones para modelado implícito de usuarios. En la Sección 4, presentamos el diseño e implementación de un agente de búsqueda web inteligente del lado del cliente (UCAIR) que realiza retroalimentación implícita ansiosa. En la Sección 5, informamos nuestros resultados experimentales utilizando el agente de búsqueda. La sección 6 concluye nuestro trabajo. 2. El modelado implícito del usuario para la búsqueda personalizada ha sido estudiado en trabajos anteriores, pero nuestro trabajo difiere de todos los trabajos anteriores en varios aspectos: (1) Enfatizamos la explotación del contexto de búsqueda inmediato, como la consulta inmediatamente anterior relacionada y los documentos vistos en la misma sesión, mientras que la mayoría de los trabajos anteriores se basan en la recopilación a largo plazo de información de retroalimentación implícita [25]. (2) Realizamos una retroalimentación activa y obtenemos el beneficio del modelado implícito del usuario tan pronto como esté disponible cualquier nueva información de retroalimentación implícita, mientras que el trabajo anterior mayormente explota la retroalimentación implícita a largo plazo [10]. (3) Proponemos un marco de recuperación para integrar el modelado implícito del usuario con el proceso interactivo de recuperación, mientras que el trabajo anterior estudia el modelado implícito del usuario por separado de la recuperación [3] o solo estudia modelos de recuperación específicos para explotar la retroalimentación implícita para mejorar la coincidencia de una consulta con documentos [23, 27, 22]. (4) Desarrollamos y evaluamos un agente de búsqueda web personalizado con estudios de usuario en línea, mientras que la mayoría de los trabajos existentes evalúan algoritmos fuera de línea sin interacciones reales de usuarios. Actualmente algunos motores de búsqueda ofrecen personalización rudimentaria, como la búsqueda web personalizada de Google [6], que permite a los usuarios describir explícitamente sus intereses seleccionando entre temas predefinidos, de modo que los resultados que coinciden con sus intereses se muestren en la parte superior, y la búsqueda de My Yahoo! [16], que brinda a los usuarios la opción de guardar los sitios web que les gustan y bloquear aquellos que no les gustan. Por el contrario, UCAIR personaliza la búsqueda web a través de la modelización implícita del usuario sin necesidad de esfuerzos adicionales por parte del usuario. Además, la personalización de UCAIR se proporciona en el lado del cliente. Hay dos ventajas notables en esto. Primero, el usuario no necesita preocuparse por la infracción de privacidad, que es una gran preocupación para la búsqueda personalizada [26]. En segundo lugar, tanto el cálculo de la personalización como el almacenamiento del perfil del usuario se realizan en el lado del cliente para reducir drásticamente la carga del servidor [9]. Ha habido muchos trabajos estudiando los registros de consultas de usuarios [1] o la dinámica de consultas [13]. UCAIR hace uso directo del historial de consultas de un usuario para beneficiar al mismo usuario de inmediato en la misma sesión de búsqueda. UCAIR primero determina si dos consultas vecinas pertenecen a la misma sesión de información y, de ser así, selecciona términos de la consulta anterior para realizar la expansión de la consulta. Nuestro enfoque de expansión de consultas es similar a la expansión automática de consultas [28, 15, 5], pero en lugar de utilizar retroalimentación pseudo para expandir la consulta, utilizamos la información de retroalimentación implícita de los usuarios para expandir la consulta actual. Estas dos técnicas pueden ser combinadas. 3. OPTIMIZACIÓN EN IR INTERACTIVO En <br>IR interactivo</br>, un usuario interactúa con el sistema de recuperación a través de un diálogo de acción, en el cual el sistema responde a cada acción del usuario con alguna acción del sistema. Por ejemplo, la acción de los usuarios puede ser enviar una consulta y la respuesta del sistema puede ser devolver una lista de 10 resúmenes de documentos. En general, el espacio de acciones del usuario y respuestas del sistema y sus granularidades dependerían de la interfaz de un sistema de recuperación particular. En principio, cada acción del usuario puede potencialmente proporcionar nuevas pruebas para ayudar al sistema a inferir mejor la necesidad de información del usuario. Por lo tanto, para responder de manera óptima, el sistema debería utilizar toda la evidencia recopilada hasta ahora sobre el usuario al elegir una respuesta. Cuando se ven de esta manera, la mayoría de los motores de búsqueda existentes son claramente no óptimos. Por ejemplo, si un usuario ha visto algunos documentos en la primera página de resultados de búsqueda, cuando el usuario hace clic en el enlace Siguiente para obtener más resultados, un sistema de recuperación existente seguiría devolviendo la siguiente página de resultados recuperados en función de la consulta original sin considerar la nueva evidencia de que un resultado en particular ha sido visto por el usuario. Proponemos optimizar el rendimiento de la recuperación adaptando las respuestas del sistema en función de cada acción que un usuario haya tomado, y planteamos el problema de optimización como una tarea de decisión. Específicamente, en cualquier momento, el sistema intentaría realizar dos tareas: (1) Actualización del modelo de usuario: Monitorear cualquier evidencia útil del usuario con respecto a su necesidad de información y actualizar el modelo de usuario tan pronto como esta evidencia esté disponible; (2) Mejorar los resultados de búsqueda: Reclasificar inmediatamente todos los documentos que el usuario aún no ha visto, tan pronto como se actualice el modelo de usuario. Enfatizamos la actualización y reordenamiento entusiastas, lo que hace que nuestro trabajo sea bastante diferente a cualquier trabajo existente. A continuación presentamos un marco formal de teoría de decisiones para optimizar el rendimiento de recuperación a través de la modelización implícita del usuario en la recuperación de información interactiva. 3.1 Un marco de teoría de decisiones Sea A el conjunto de todas las acciones del usuario y R(a) el conjunto de todas las posibles respuestas del sistema a una acción del usuario a ∈ A. En cualquier momento, sea At = (a1, ..., at) la secuencia observada de acciones de usuario hasta ahora (hasta el momento t) y Rt−1 = (r1, ..., rt−1) las respuestas que el sistema ha dado en respuesta a las acciones del usuario. El objetivo del sistema es elegir una respuesta óptima rt ∈ R(at) para la acción actual del usuario at. Sea M el espacio de todos los posibles modelos de usuario. Definimos además una función de pérdida L(a, r, m) ∈ , donde a ∈ A es una acción del usuario, r ∈ R(a) es una respuesta del sistema, y m ∈ M es un modelo de usuario. L(a, r, m) codifica nuestras preferencias de decisión y evalúa la optimalidad de responder con r cuando el modelo de usuario actual es m y la acción de usuario actual es a. Según la teoría de decisión bayesiana, la decisión óptima en el tiempo t es elegir una respuesta que minimice el riesgo de Bayes, es decir, r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) donde P(mt|U, D, At, Rt−1) es la probabilidad posterior del modelo de usuario mt dadas todas las observaciones sobre el usuario U que hemos realizado hasta el tiempo t. Para simplificar el cálculo de la Ecuación 1, asumamos que la masa de probabilidad posterior P(mt|U, D, At, Rt−1) está principalmente concentrada en el modo m∗ t = argmaxmt P(mt|U, D, At, Rt−1). Podemos entonces aproximar la integral con el valor de la función de pérdida en m∗ t. Es decir, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) donde m∗ t = argmaxmt P(mt|U, D, At, Rt−1). Dejando de lado cómo definir y estimar estos modelos probabilísticos y la función de pérdida, podemos ver que tal formulación de la teoría de decisiones sugiere que, para elegir la respuesta óptima a at, el sistema debería realizar dos tareas: (1) calcular el modelo de usuario actual y obtener m∗ t basado en toda la información útil. (2) elegir una respuesta rt para minimizar el valor de la función de pérdida L(at, rt, m∗ t). Cuando at no afecta nuestra creencia sobre m∗ t , el primer paso puede omitirse y podemos reutilizar m∗ t−1 para m∗ t . Ten en cuenta que nuestro marco de trabajo es bastante general, ya que potencialmente podemos modelar cualquier tipo de acciones de usuario y respuestas del sistema. En la mayoría de los casos, como podríamos esperar, la respuesta del sistema es algún tipo de clasificación de documentos, es decir, para la mayoría de las acciones a, R(a) consiste en todas las posibles clasificaciones de los documentos no vistos, y el problema de decisión se reduce a elegir la mejor clasificación de los documentos no vistos basándose en el modelo de usuario más actualizado. Cuando a es la acción de enviar una consulta de palabras clave, tal respuesta es exactamente lo que haría un sistema de recuperación actual. Sin embargo, fácilmente podemos imaginar que un motor de búsqueda web más inteligente respondería al clic del usuario en el enlace Siguiente (para obtener más resultados no vistos) con una clasificación más optimizada de documentos basada en cualquier documento visto en la página actual de resultados. De hecho, según nuestra estrategia de actualización entusiasta, incluso podríamos permitir que un sistema responda al clic del botón Atrás del navegador por parte de un usuario después de ver un documento de la misma manera, para que el usuario pueda beneficiarse al máximo de la retroalimentación implícita. Estos son precisamente lo que nuestro sistema UCAIR hace. 3.2 Modelos de usuario Un modelo de usuario m ∈ M representa lo que sabemos sobre el usuario U, por lo que en principio, puede contener cualquier información sobre el usuario que deseemos modelar. Ahora discutimos dos componentes importantes en un modelo de usuario. El primer componente es un modelo de componente de la necesidad de información de los usuarios. Presumiblemente, el factor más importante que afecta la optimalidad de la respuesta del sistema es qué tan bien la respuesta aborda la necesidad de información de los usuarios. De hecho, en cualquier momento, podemos asumir que el sistema tiene alguna creencia sobre lo que le interesa al usuario, la cual modelamos a través de un vector de términos x = (x1, ..., x|V|), donde V = {w1, ..., w|V|} es el conjunto de todos los términos (es decir, vocabulario) y xi es el peso del término wi. Un vector de términos de este tipo se utiliza comúnmente en la recuperación de información para representar tanto consultas como documentos. Por ejemplo, el modelo de espacio vectorial asume que tanto la consulta como los documentos se representan como vectores de términos y que la puntuación de un documento con respecto a una consulta se calcula en función de la similitud entre el vector de la consulta y el vector del documento [21]. En un enfoque de modelado de lenguaje, también podemos considerar el modelo de lenguaje unigrama de consulta [12, 29] o el modelo de relevancia [14] como una representación vectorial de términos de la necesidad de información de los usuarios. Intuitivamente, x asignaría pesos altos a los términos que caracterizan los temas que interesan al usuario. El segundo componente que podemos incluir en nuestro modelo de usuario son los documentos que el usuario ya ha visto. Obviamente, incluso si un documento es relevante, si el usuario ya ha visto el documento, no sería útil presentar el mismo documento de nuevo. Por lo tanto, introducimos otra variable S ⊂ D (D es el conjunto completo de documentos en la colección) para denotar el subconjunto de documentos en los resultados de búsqueda que el usuario ya ha visto. En general, en el tiempo t, podemos representar un modelo de usuario como mt = (S, x, At, Rt−1), donde S son los documentos vistos, x es la comprensión del sistema de la necesidad de información del usuario, y (At, Rt−1) representa el historial de interacción del usuario. Ten en cuenta que un modelo de usuario aún más general también puede incluir otros factores como el nivel de lectura y la ocupación de los usuarios. Si asumimos que la incertidumbre de un modelo de usuario mt se debe únicamente a la incertidumbre de x, el cálculo de nuestra estimación actual del modelo de usuario m∗ t implicará principalmente calcular nuestra mejor estimación de x. Es decir, el sistema elegiría una respuesta de acuerdo a r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) donde x∗ = argmaxx P(x|U, D, At, Rt−1). Este es el mecanismo de decisión implementado en el sistema UCAIR que se describirá más adelante. En este sistema, evitamos especificar el modelo probabilístico P(x|U, D, At, Rt−1) calculando x∗ directamente con algún método de retroalimentación existente. 3.3 Funciones de pérdida La definición exacta de la función de pérdida L depende de las respuestas, por lo que es inevitablemente específica de la aplicación. Ahora discutimos brevemente algunas posibilidades cuando la respuesta es clasificar todos los documentos no vistos y presentar los mejores k de ellos. Sea r = (d1, ..., dk) los k documentos principales, S el conjunto de documentos vistos por el usuario, y x∗ la mejor suposición del sistema sobre la necesidad de información del usuario. Podemos definir simplemente la pérdida asociada con r como la suma negativa de la probabilidad de que cada uno de los di sea relevante, es decir, L(a, r, m) = − k i=1 P(relevante|di, m). Claramente, para minimizar esta función de pérdida, la respuesta óptima r contendría los k documentos con la probabilidad más alta de relevancia, lo cual es intuitivamente razonable. Una deficiencia de esta función de pérdida top-k es que no es sensible al orden interno de los documentos top k seleccionados, por lo que cambiar el orden de clasificación de un documento no relevante y uno relevante no afectaría la pérdida, lo cual es irrazonable. Para modelar el ranking, podemos introducir un factor del modelo de usuario: la probabilidad de que cada uno de los k documentos sea visto por el usuario, P(vista|di), y definir la siguiente función de pérdida de ranking: L(a, r, m) = − k i=1 P(vista|di)P(relevante|di, m). Dado que, en general, si di está clasificado por encima de dj (es decir, i < j), P(vista|di) > P(vista|dj), esta función de pérdida favorecería una decisión de clasificar documentos relevantes por encima de los no relevantes, ya que de lo contrario, siempre podríamos intercambiar di con dj para reducir el valor de pérdida. Por lo tanto, el sistema simplemente debería realizar una recuperación regular y clasificar los documentos según la probabilidad de relevancia [18]. Dependiendo de las preferencias de recuperación de los usuarios, puede haber muchas otras posibilidades. Por ejemplo, si el usuario no desea ver documentos redundantes, la función de pérdida debería incluir alguna medida de redundancia en r basada en los documentos ya vistos S. Por supuesto, cuando la respuesta no es elegir una lista clasificada de documentos, necesitaríamos una función de pérdida diferente. Discutimos un ejemplo relevante para el agente de búsqueda que implementamos. Cuando un usuario ingresa una consulta qt (acción actual), nuestro agente de búsqueda se basa en algún motor de búsqueda existente para llevar a cabo la búsqueda en realidad. En tal caso, aunque el agente de búsqueda no tenga control sobre el algoritmo de recuperación, aún puede intentar optimizar los resultados de la búsqueda refinando la consulta enviada al motor de búsqueda y/o reordenando los resultados obtenidos del motor de búsqueda. Las funciones de pérdida para el reordenamiento ya fueron discutidas anteriormente; ahora echamos un vistazo a las funciones de pérdida para el refinamiento de consultas. Sea f la función de recuperación del motor de búsqueda que nuestro agente utiliza, de modo que f(q) nos daría los resultados de búsqueda utilizando la consulta q. Dado que la acción actual del usuario es ingresar una consulta qt (es decir, at = qt), nuestra respuesta sería f(q) para algún q. Dado que no tenemos elección de f, nuestra decisión es elegir un buen q. Formalmente, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) lo cual muestra que nuestro objetivo es encontrar q∗ = argminqL(qt, f(q), m), es decir, una consulta óptima que nos daría el mejor f(q). Una elección diferente de la función de pérdida L(qt, f(q), m) llevaría a una estrategia de refinamiento de consulta diferente. En UCAIR, calculamos heurísticamente q∗ expandiendo qt con términos extraídos de rt−1 siempre que qt−1 y qt tengan una alta similitud. Se debe tener en cuenta que rt−1 y qt−1 están contenidos en m como parte del historial de interacción de los usuarios. 3.4 Modelado implícito del usuario El modelado implícito del usuario se captura en nuestro marco a través del cálculo de x∗ = argmaxx P(x|U, D, At, Rt−1), es decir, la creencia actual del sistema sobre cuál es la necesidad de información del usuario. Aquí nuevamente puede haber muchas posibilidades, lo que lleva a diferentes algoritmos para la modelización implícita del usuario. Ahora discutimos algunos de ellos. Primero, cuando dos consultas consecutivas están relacionadas, la consulta anterior puede ser explotada para enriquecer la consulta actual y proporcionar más contexto de búsqueda para ayudar en la desambiguación. Para este propósito, en lugar de realizar una expansión de consulta como lo hicimos en la sección anterior, también podríamos calcular un x∗ actualizado basado en la consulta anterior y los resultados de recuperación. El modelo de usuario nuevo calculado puede luego ser utilizado para clasificar los documentos con un modelo estándar de recuperación de información. Segundo, también podemos inferir los intereses de un usuario basándonos en los resúmenes de los documentos visualizados. Cuando a un usuario se le presenta una lista de resúmenes de documentos mejor clasificados, si el usuario elige saltarse los primeros n documentos y ver el documento (n+1)-ésimo, podemos inferir que el usuario no está interesado en los resúmenes mostrados para los primeros n documentos, pero está atraído por el resumen mostrado del documento (n+1)-ésimo. Por lo tanto, podemos usar estos resúmenes como ejemplos negativos y positivos para aprender un modelo de usuario más preciso x∗. Aquí se pueden explotar muchas técnicas estándar de retroalimentación de relevancia [19, 20]. Ten en cuenta que debemos utilizar los resúmenes mostrados, en lugar de los contenidos reales de esos documentos, ya que es posible que el resumen mostrado del documento visto sea relevante, pero el contenido del documento en realidad no lo sea. Del mismo modo, un resumen mostrado puede llevar a un usuario a omitir un documento relevante. Inferir modelos de usuario basados en dicha información mostrada, en lugar del contenido real de un documento, es una diferencia importante entre UCAIR y algunos otros sistemas similares. En UCAIR, ambas estrategias para inferir un modelo de usuario implícito están implementadas. 4. UCAIR: Un agente de búsqueda personalizado 4.1 Diseño En esta sección, presentamos un agente de búsqueda web del lado del cliente llamado UCAIR, en el cual implementamos algunos de los métodos discutidos en la sección anterior para realizar búsquedas personalizadas a través de modelado implícito del usuario. UCAIR es un complemento del navegador web que actúa como proxy para los motores de búsqueda en la web. Actualmente, solo está implementado para Internet Explorer y Google, pero es cuestión de ingeniería hacer que funcione en otros navegadores web e interactúe con otros motores de búsqueda. El tema de la privacidad es un obstáculo principal para implementar cualquier aplicación del mundo real que involucre modelado de usuarios serio, como la búsqueda personalizada. Por esta razón, UCAIR funciona estrictamente como un agente de búsqueda del lado del cliente, en lugar de ser una aplicación del lado del servidor. De esta manera, la información del usuario capturada siempre permanece en la computadora que está utilizando el usuario, por lo tanto, el usuario no necesita revelar ninguna información al exterior. La personalización del lado del cliente también permite que el sistema observe fácilmente una gran cantidad de información del usuario que puede no estar fácilmente disponible para un servidor. Además, realizar búsquedas personalizadas en el lado del cliente es más escalable que en el lado del servidor, ya que la sobrecarga de cálculo y almacenamiento se distribuye entre los clientes. Como se muestra en la Figura 1, la barra de herramientas UCAIR tiene 3 componentes principales: (1) El módulo de modelado de usuario (implícito) captura el contexto de búsqueda de un usuario e información de historial, incluidas las consultas enviadas y los resultados de búsqueda clicados, e infiere los límites de la sesión de búsqueda. (2) El módulo de modificación de consultas mejora selectivamente la formulación de la consulta de acuerdo con el modelo de usuario actual. (3) El módulo de reordenamiento de resultados reordena inmediatamente cualquier resultado de búsqueda no visto cada vez que se actualiza el modelo de usuario. En UCAIR, consideramos cuatro acciones básicas de usuario: (1) enviar una consulta de palabras clave; (2) ver un documento; (3) hacer clic en el botón Atrás; (4) hacer clic en el enlace Siguiente en una página de resultados. Para cada una de estas cuatro acciones, el sistema responde con, respectivamente, (1) 1 UCAIR está disponible en: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Registro de Historial de Búsqueda del Motor de Búsqueda (por ejemplo, Google) (consultas pasadas, resultados clicados) Modificación de Consulta Resultado de Reclasificación Modelo de Usuario Buffer de Resultados de Consulta de Usuario UCAIR... Figura 1: arquitectura de UCAIR generando una lista clasificada de resultados enviando una consulta posiblemente ampliada a un motor de búsqueda; (2) actualizando el modelo de necesidad de información x; (3) reordenando los resultados no vistos en la página de resultados actual basándose en el modelo actual x; y (4) reordenando las páginas no vistas y generando la siguiente página de resultados basándose en el modelo actual x. Detrás de estas respuestas, hay tres tareas básicas: (1) Decidir si la consulta anterior está relacionada con la consulta actual y, de ser así, ampliar la consulta actual con términos útiles de la consulta anterior o los resultados de la consulta anterior. (2) Actualizar el modelo de necesidad de información x basado en un resumen de documento recién seleccionado. (3) Reordenar un conjunto de documentos no vistos basado en el modelo x actual. A continuación describimos nuestros algoritmos para cada uno de ellos. 4.2 Detección de límites de sesión y expansión de consultas Para explotar eficazmente las consultas anteriores y su información correspondiente de clics, UCAIR necesita determinar si dos consultas adyacentes pertenecen a la misma sesión de búsqueda (es decir, detectar los límites de sesión). El trabajo existente sobre la detección de límites de sesión se encuentra principalmente en el contexto del análisis de registros web (por ejemplo, [8]), y utiliza información estadística en lugar de características textuales. Dado que nuestro agente del lado del cliente no tiene acceso a los registros de consultas del servidor, tomamos decisiones sobre los límites de sesión basadas en la similitud textual entre dos consultas. Debido a que las consultas relacionadas no necesariamente comparten las mismas palabras (por ejemplo, isla de Java y viajar a Indonesia), no es suficiente utilizar solo el texto de la consulta. Por lo tanto, utilizamos los resultados de búsqueda de las dos consultas para ayudar a decidir si están relacionadas temáticamente. Por ejemplo, para las consultas anteriores \"java island\" y \"travel Indonesia\", las palabras \"java\", \"bali\", \"island\", \"indonesia\" y \"travel\" pueden aparecer con frecuencia en los resultados de búsqueda de ambas consultas, lo que produce un alto puntaje de similitud. Solo utilizamos los títulos y resúmenes de los resultados de búsqueda para calcular la similitud, ya que están disponibles en la página de resultados de búsqueda recuperada y obtener el texto completo de cada página de resultados ralentizaría significativamente el proceso. Para compensar la concisión de los títulos y resúmenes, recuperamos más resultados de los que un usuario normalmente vería con el propósito de detectar los límites de sesión (típicamente 50 resultados). La similitud entre la consulta anterior q y la consulta actual q se calcula de la siguiente manera. Sean {s1, s2, . . . , sn} y {s1, s2, . . . , sn} los conjuntos de resultados de las dos consultas. Utilizamos la fórmula de ponderación TF-IDF normalizada pivotada [24] para calcular un vector de peso de término si para cada resultado si. Definimos el resultado promedio savg como el centroide de todos los vectores de resultado, es decir, (s1 + s2 + . . . + sn)/n. La similitud del coseno entre los dos resultados promedio se calcula como s avg · savg/ s 2 avg · s2 avg. Si el valor de similitud supera un umbral predefinido, se considerará que las dos consultas están en la misma sesión de información. Si se determina que la consulta anterior y la consulta actual pertenecen a la misma sesión de búsqueda, UCAIR intentaría expandir la consulta actual con términos de la consulta anterior y sus resultados de búsqueda. Específicamente, para cada término en la consulta anterior o los resultados de búsqueda correspondientes, si su frecuencia en los resultados de la consulta actual es mayor que un umbral preestablecido (por ejemplo, 5 resultados de 50), el término se agregaría a la consulta actual para formar una consulta ampliada. En este caso, UCAIR enviaría esta consulta ampliada en lugar de la original al motor de búsqueda y devolvería los resultados correspondientes a la consulta ampliada. Actualmente, UCAIR solo utiliza la consulta inmediatamente anterior para la expansión de consultas; en principio, podríamos aprovechar todas las consultas pasadas relacionadas. 4.3 Actualización del modelo de necesidad de información Supongamos que en el tiempo t, hemos observado que el usuario ha visto k documentos cuyos resúmenes son s1, ..., sk. Actualizamos nuestro modelo de usuario calculando un nuevo vector de necesidad de información con un método estándar de retroalimentación en la recuperación de información (es decir, Rocchio [19]). Según el modelo de recuperación de espacio vectorial, cada resumen clicado si puede ser representado por un vector de pesos de términos si, con cada término ponderado por una fórmula de ponderación TF-IDF [21]. Rocchio calcula el vector centroide de todos los resúmenes e interpola este con el vector de consulta original para obtener un vector de términos actualizado. Es decir, x = αq + (1 − α) 1 k k i=1 si donde q es el vector de consulta, k es el número de resúmenes que el usuario hace clic inmediatamente después de la consulta actual y α es un parámetro que controla la influencia de los resúmenes clicados en el modelo de necesidad de información inferida. En nuestros experimentos, α se establece en 0.5. Ten en cuenta que actualizamos el modelo de información necesario cada vez que el usuario ve un documento. 4.4 Reclasificación de resultados En general, queremos volver a clasificar todos los resultados no vistos tan pronto como se actualice el modelo de usuario. Actualmente, UCAIR implementa el reordenamiento en dos casos, correspondientes a cuando el usuario hace clic en el botón Atrás y en el enlace Siguiente en Internet Explorer. En ambos casos, el modelo de usuario actualizado se utilizaría para reordenar los resultados no vistos de manera que el usuario vea resultados de búsqueda mejorados de inmediato. Para volver a clasificar cualquier resumen de documento no visto, UCAIR utiliza el modelo estándar de recuperación de espacio vectorial y puntúa cada resumen en función de la similitud del resultado y el vector de necesidad de información actual del usuario x [21]. Dado que la retroalimentación implícita no es completamente confiable, presentamos solo un pequeño número (por ejemplo, 5) de los resultados reordenados más altos para ser seguidos por cualquier resultado originalmente clasificado alto. 828 resultados de Google (consulta del usuario = mapa de Java) Resultados de UCAIR (consulta del usuario = mapa de Java) consulta anterior = viajar a Indonesia consulta anterior = tabla hash consulta del usuario ampliada = mapa de Java Indonesia consulta del usuario ampliada = clase de mapa de Java 1 Proyecciones de mapas de Java del mundo ... Lonely Planet - Mapa de Indonesia Mapa (Plataforma Java SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Proyecciones de mapas de Java del mundo ... TURISMO DE INDONESIA: JAVA CENTRAL - MAPA Plataforma Java SE v1.3.1: Interfaz de Mapa www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Mapa de Java TURISMO DE INDONESIA: JAVA OESTE - MAPA Una introducción a las clases de colección de mapas de Java java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Mapa de Tecnología Java IndoStreets - Mapa de Java Una introducción a las clases de colección de mapas de Java java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Regiones e islas de Indonesia Mapas, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 Una introducción a las clases de colección de mapas de Java Mapa de calles de la ciudad de Indonesia,... Hibernate simplifica el mapeo de herencia www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Mapa de Java Mapas de Indonesia jerarquía de clases de tmap 30.map www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Mapa de API de Java Mapas de Indonesia por Peter Loud Alcance de clases www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas: Mapas de Sam de Indonesia por Peter Loud PrintSafeHashMap de la clase www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 TURISMO DE INDONESIA: JAVA OESTE - MAPA indonesiaphoto.com Java Pro - Unión y mapeo vertical de clases www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Tabla 1: Resultados de muestra de la expansión de la consulta EVALUACIÓN DE UCAIR Ahora presentamos algunos resultados sobre la evaluación de las dos principales funciones de UCAIR: la expansión selectiva de consultas y la reordenación de resultados basada en los datos de clics de los usuarios. 5.1 Resultados de muestra La estrategia de expansión de consultas implementada en UCAIR es intencionalmente conservadora para evitar la interpretación errónea de los modelos implícitos de los usuarios. En la práctica, cada vez que decide expandir la consulta, la expansión suele tener sentido. En la Tabla 1, mostramos cómo UCAIR puede distinguir exitosamente dos contextos de búsqueda diferentes para la consulta java map, correspondientes a dos consultas previas distintas (es decir, viajar a Indonesia vs. hashtable). Debido a la modelización implícita del usuario, UCAIR descubre inteligentemente agregar Indonesia y clase, respectivamente, a la consulta de los usuarios sobre el mapa de Java, lo cual de otro modo sería ambiguo, como se muestra en los resultados originales de Google el 21 de marzo de 2005. Los resultados de UCAIR son mucho más precisos que los resultados de Google y reflejan la personalización en la búsqueda. El componente de retroalimentación implícita entusiasta está diseñado para responder inmediatamente a la actividad de un usuario, como por ejemplo, al visualizar un documento. En la Figura 2, mostramos cómo UCAIR puede desambiguar con éxito una consulta ambigua de jaguar al explotar un resumen del documento visualizado. En este caso, los resultados iniciales de recuperación utilizando \"jaguar\" (mostrados en el lado izquierdo) contienen dos resultados sobre los autos Jaguar seguidos por dos resultados sobre el software Jaguar. Sin embargo, después de que el usuario ve el contenido de la página web del segundo resultado (sobre el automóvil Jaguar) y regresa a la página de resultados de búsqueda haciendo clic en el botón Atrás, UCAIR automáticamente selecciona dos nuevos resultados de búsqueda sobre automóviles Jaguar (mostrados en el lado derecho), mientras que los dos resultados originales sobre software de Jaguar se desplazan hacia abajo en la lista (no se ven en la imagen). 5.2 Evaluación cuantitativa Para evaluar UCAIR de manera cuantitativa, realizamos un estudio de usuario sobre la efectividad del componente de retroalimentación implícita ansiosa. Es un desafío evaluar cuantitativamente la mejora potencial en el rendimiento de nuestro modelo propuesto y UCAIR sobre Google de manera imparcial [7]. Aquí diseñamos un estudio de usuarios, en el cual los participantes realizarían una búsqueda web normal y evaluarían al azar y de forma anónima un conjunto de resultados mezclados de Google y UCAIR al final de la sesión de búsqueda; los participantes no saben si un resultado proviene de Google o de UCAIR. Reclutamos a 6 estudiantes de posgrado para este estudio de usuarios, quienes tienen diferentes antecedentes (3 en informática, 2 en biología y 1 en química). Los documentos que describen leyes para limitar el correo no deseado sin dar detalles de demandas judiciales o juicios penales no son relevantes. Utilizamos los temas de consulta de la pista Terabyte TREC 2 2004 [2] y la tarea de destilación de temas de la pista web TREC 2003 [4] de la manera que se describirá a continuación. Un ejemplo de tema del TREC 2004 Terabyte track aparece en la Figura 3. El título es una frase corta y puede ser utilizada como una consulta al sistema de recuperación. El campo de descripción proporciona una declaración ligeramente más larga del requisito del tema, generalmente expresado como una sola oración completa o pregunta. Finalmente, la narrativa proporciona información adicional necesaria para especificar completamente el requisito, expresado en forma de un breve párrafo. Inicialmente, cada participante exploraría 50 temas ya sea de la categoría Terabyte o de la categoría Web y elegiría los 5 o 7 temas más interesantes. Para cada tema seleccionado, el participante básicamente realizaría la búsqueda web normal utilizando UCAIR para encontrar muchas páginas web relevantes utilizando el título del tema de la consulta como la palabra clave inicial de la consulta. Durante este proceso, el participante puede ver los resultados de la búsqueda y posiblemente hacer clic en algunos interesantes para ver las páginas web, tal como en una búsqueda web normal. No hay ningún requisito o restricción sobre cuántas consultas debe enviar el participante o cuándo debe detener la búsqueda de un tema. Cuando el participante planea cambiar el tema de búsqueda, simplemente presionará un botón 2 de la Conferencia de Recuperación de Texto: http://trec.nist.gov/ 829 Figura 2: Capturas de pantalla para volver a clasificar los resultados y evaluar los resultados de búsqueda antes de cambiar al siguiente tema. En el momento de la evaluación, los 30 resultados mejor clasificados de Google y UCAIR (algunos se superponen) se mezclan aleatoriamente para que el participante no sepa si un resultado proviene de Google o de UCAIR. El participante luego juzgaría la relevancia de estos resultados. Medimos la precisión en los primeros n (n = 5, 10, 20, 30) documentos de Google y UCAIR. También evaluamos precisiones en diferentes niveles de recuperación. En total, 368 documentos fueron considerados relevantes a partir de los resultados de búsqueda de Google y 429 documentos fueron considerados relevantes por los participantes de UCAIR. Los diagramas de dispersión de precisión en los 10 y 20 documentos principales se muestran en la Figura 4 y la Figura 5 respectivamente (El diagrama de dispersión de precisión en los 30 documentos principales es muy similar al de los 20 documentos principales). Cada punto de los gráficos de dispersión representa las precisiones de Google y UCAIR en un tema de consulta. La Tabla 2 muestra la precisión promedio en los primeros n documentos entre 32 temas. A partir de la Figura 4, la Figura 5 y la Tabla 2, vemos que los resultados de búsqueda de UCAIR son consistentemente mejores que los de Google en todas las medidas. Además, la mejora en el rendimiento es más dramática para la precisión en los primeros 20 documentos que para la precisión en los primeros 10 documentos. Una explicación para esto es que cuanto más interacción tenga el usuario con el sistema, más datos de clics se espera que UCAIR pueda recopilar. Por lo tanto, el sistema de recuperación puede construir modelos de usuario implícitos más precisos, lo que conduce a una mayor precisión en la recuperación. El Método de Clasificación prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Mejora 8.0% 17.8% 20.2% 21.8% Tabla 2: Tabla de precisión promedio en los primeros n documentos para 32 temas de consulta El gráfico en la Figura 6 muestra las curvas de precisión-recuperación para UCAIR y Google, donde se observa claramente que el rendimiento de UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Gráfico de dispersión de Precisión en los 10 primeros documentos Figura 4: La precisión en los 10 primeros documentos de UCAIR y Google es consistentemente y considerablemente mejor que la de Google en todos los niveles de recuperación. 6. CONCLUSIONES En este artículo, estudiamos cómo aprovechar la modelización implícita del usuario para personalizar de manera inteligente la recuperación de información y mejorar la precisión de la búsqueda. A diferencia de la mayoría de trabajos anteriores, enfatizamos el uso del contexto de búsqueda inmediata y la información de retroalimentación implícita, así como la actualización rápida de los resultados de búsqueda para beneficiar al máximo a un usuario. Presentamos un marco de trabajo de toma de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos adecuados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para volver a clasificar inmediatamente cualquier documento que aún no haya sido visto por el usuario. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente (UCAIR) sobre un motor de búsqueda popular (Google). Los experimentos en la búsqueda web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en más de un 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Gráfico de dispersión de Precisión en los 20 documentos principales Figura 5: Precisión en los 20 documentos principales de UCAIR y Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 precisión recall Curvas de Precisión-Recall Resultado de Google Resultado de UCAIR Figura 6: Precisión en los 20 resultados principales de UCAIR y Google Google. Dado que la información implícita que aprovechamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional. El agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin necesidad de esfuerzo adicional por parte del usuario. AGRADECIMIENTO Agradecemos a los seis participantes de nuestros experimentos de evaluación. Este trabajo fue apoyado en parte por las subvenciones de la Fundación Nacional de Ciencias IIS-0347933 e IIS-0428472. REFERENCIAS [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman y O. Frieder. Análisis por hora de un registro de consultas web muy grande categorizado por tema. En Actas de SIGIR 2004, páginas 321-328, 2004. [2] C. Clarke, N. Craswell e I. Soboroff. Resumen de la pista de terabyte TREC 2004. En Actas de TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda y D. Brown. Indicadores implícitos de interés. En Actas de Interfaces de Usuario Inteligentes 2001, páginas 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson y M. Wu. Resumen de la pista web TREC 2003. En Actas de TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend y V. Larvrenko. Retroalimentación de relevancia y personalización: Una perspectiva de modelado del lenguaje. En Actas del Segundo Taller DELOS: Personalización y Sistemas de Recomendación en Bibliotecas Digitales, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite y D. Harman. Resultados y desafíos en la evaluación de búsqueda en la web. Redes de Computadoras, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A. An, y D. Schuurmans. Identificación dinámica de sesiones de registro web con modelos de lenguaje estadístico. Revista de la Sociedad Americana de Ciencia de la Información y Tecnología, 55(14):1290-1303, 2004. [9] G. Jeh y J. Widom. Escalando la búsqueda web personalizada. En Actas de WWW 2003, páginas 271-279, 2003. [10] T. Joachims. Optimización de motores de búsqueda utilizando datos de clics. En Actas de SIGKDD 2002, páginas 133-142, 2002. [11] D. Kelly y J. Teevan. Retroalimentación implícita para inferir preferencias de usuario: Una bibliografía. SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En Actas de SIGIR01, páginas 111-119, 2001. [13] T. Lau y E. Horvitz. Patrones de búsqueda: Análisis y modelado de la refinación de consultas web. En Actas de la Séptima Conferencia Internacional sobre Modelado de Usuarios (UM), páginas 145-152, 1999. [14] V. Lavrenko y B. Croft. Modelos de lenguaje basados en relevancia. En Actas de SIGIR01, páginas 120-127, 2001. [15] M. Mitra, A. Singhal y C. Buckley. Mejorando la expansión automática de consultas. En Actas de SIGIR 1998, páginas 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg. Según Google, así va la nación. New York Times, mayo de 2003. [18] S. E. Robertson. El principio de clasificación de probabilidad en ı˚. Revista de Documentación, 33(4):294-304, 1977. [19] J. J. Rocchio. Retroalimentación de relevancia en la recuperación de información. En el Sistema de Recuperación SMART: Experimentos en el Procesamiento Automático de Documentos, páginas 313-323. Prentice-Hall Inc., 1971. [20] G. Salton y C. Buckley. Mejorando el rendimiento de recuperación mediante retroalimentación de recuperación. Revista de la Sociedad Americana de Ciencia de la Información, 41(4):288-297, 1990. [21] G. Salton y M. J. McGill. Introducción a la Recuperación de Información Moderna. McGraw-Hill, 1983. [22] X. Shen, B. Tan y C. Zhai. Recuperación de información sensible al contexto utilizando retroalimentación implícita. En Actas de SIGIR 2005, páginas 43-50, 2005. [23] X. Shen y C. Zhai. Explotando el historial de consultas para la clasificación de documentos en la recuperación de información interactiva (Póster). En Actas de SIGIR 2003, páginas 377-378, 2003. [24] A. Singhal. Recuperación de información moderna: Una breve visión general. Boletín del Comité Técnico de Ingeniería de Datos de la Sociedad de Computación de IEEE, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano y M. Yoshikawa. Búsqueda web adaptativa basada en el perfil del usuario construido sin ningún esfuerzo por parte de los usuarios. En Actas de WWW 2004, páginas 675-684, 2004. [26] E. Volokh. Personalización y privacidad. Comunicaciones de la ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen e I. Ruthven. Un estudio simulado de modelos de retroalimentación implícita. En Actas de ECIR 2004, páginas 311-326, 2004. [28] J. Xu y W. B. Croft. Expansión de consultas utilizando análisis local y global de documentos. En Actas de SIGIR 1996, páginas 4-11, 1996. [29] C. Zhai y J. Lafferty. Modelo de retroalimentación basado en el modelo de recuperación de divergencia de KL. En Actas de la CIKM 2001, páginas 403-410, 2001. 831 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "retrieval performance": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Implicit User Modeling for Personalized Search Xuehua Shen, Bin Tan, ChengXiang Zhai Department of Computer Science University of Illinois at Urbana-Champaign ABSTRACT Information retrieval systems (e.g., web search engines) are critical for overcoming information overload.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users, resulting in inherently non-optimal <br>retrieval performance</br>.",
                "For example, a tourist and a programmer may use the same word java to search for different information, but the current search systems would return the same results.",
                "In this paper, we study how to infer a users interest from the users search context and use the inferred implicit user model for personalized search .",
                "We present a decision theoretic framework and develop techniques for implicit user modeling in information retrieval.",
                "We develop an intelligent client-side web search agent (UCAIR) that can perform eager implicit feedback, e.g., query expansion based on previous queries and immediate result reranking based on clickthrough information.",
                "Experiments on web search show that our search agent can improve search accuracy over the popular Google search engine.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models, Relevance feedback, Search Process General Terms Algorithms 1.",
                "INTRODUCTION Although many information retrieval systems (e.g., web search engines and digital library systems) have been successfully deployed, the current retrieval systems are far from optimal.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users [17].",
                "This inherent non-optimality is seen clearly in the following two cases: (1) Different users may use exactly the same query (e.g., Java) to search for different information (e.g., the Java island in Indonesia or the Java programming language), but existing IR systems return the same results for these users.",
                "Without considering the actual user, it is impossible to know which sense Java refers to in a query. (2) A users information needs may change over time.",
                "The same user may use Java sometimes to mean the Java island in Indonesia and some other times to mean the programming language.",
                "Without recognizing the search context, it would be again impossible to recognize the correct sense.",
                "In order to optimize retrieval accuracy, we clearly need to model the user appropriately and personalize search according to each individual user.",
                "The major goal of user modeling for information retrieval is to accurately model a users information need, which is, unfortunately, a very difficult task.",
                "Indeed, it is even hard for a user to precisely describe what his/her information need is.",
                "What information is available for a system to infer a users information need?",
                "Obviously, the users query provides the most direct evidence.",
                "Indeed, most existing retrieval systems rely solely on the query to model a users information need.",
                "However, since a query is often extremely short, the user model constructed based on a keyword query is inevitably impoverished .",
                "An effective way to improve user modeling in information retrieval is to ask the user to explicitly specify which documents are relevant (i.e., useful for satisfying his/her information need), and then to improve user modeling based on such examples of relevant documents.",
                "This is called relevance feedback, which has been proved to be quite effective for improving retrieval accuracy [19, 20].",
                "Unfortunately, in real world applications, users are usually reluctant to make the extra effort to provide relevant examples for feedback [11].",
                "It is thus very interesting to study how to infer a users information need based on any implicit feedback information, which naturally exists through user interactions and thus does not require any extra user effort.",
                "Indeed, several previous studies have shown that implicit user modeling can improve retrieval accuracy.",
                "In [3], a web browser (Curious Browser) is developed to record a users explicit relevance ratings of web pages (relevance feedback) and browsing behavior when viewing a page, such as dwelling time, mouse click, mouse movement and scrolling (implicit feedback).",
                "It is shown that the dwelling time on a page, amount of scrolling on a page and the combination of time and scrolling have a strong correlation with explicit relevance ratings, which suggests that implicit feedback may be helpful for inferring user information need.",
                "In [10], user clickthrough data is collected as training data to learn a retrieval function, which is used to produce a customized ranking of search results that suits a group of users preferences.",
                "In [25], the clickthrough data collected over a long time period is exploited through query expansion to improve retrieval accuracy. 824 While a user may have general long term interests and preferences for information, often he/she is searching for documents to satisfy an ad-hoc information need, which only lasts for a short period of time; once the information need is satisfied, the user would generally no longer be interested in such information.",
                "For example, a user may be looking for information about used cars in order to buy one, but once the user has bought a car, he/she is generally no longer interested in such information.",
                "In such cases, implicit feedback information collected over a long period of time is unlikely to be very useful, but the immediate search context and feedback information, such as which of the search results for the current information need are viewed, can be expected to be much more useful.",
                "Consider the query Java again.",
                "Any of the following immediate feedback information about the user could potentially help determine the intended meaning of Java in the query: (1) The previous query submitted by the user is hashtable (as opposed to, e.g., travel Indonesia). (2) In the search results, the user viewed a page where words such as programming, software, and applet occur many times.",
                "To the best of our knowledge, how to exploit such immediate and short-term search context to improve search has so far not been well addressed in the previous work.",
                "In this paper, we study how to construct and update a user model based on the immediate search context and implicit feedback information and use the model to improve the accuracy of ad-hoc retrieval.",
                "In order to maximally benefit the user of a retrieval system through implicit user modeling, we propose to perform eager implicit feedback.",
                "That is, as soon as we observe any new piece of evidence from the user, we would update the systems belief about the users information need and respond with improved retrieval results based on the updated user model.",
                "We present a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "In a traditional retrieval paradigm, the retrieval problem is to match a query with documents and rank documents according to their relevance values.",
                "As a result, the retrieval process is a simple independent cycle of query and result display.",
                "In the proposed new retrieval paradigm, the users search context plays an important role and the inferred implicit user model is exploited immediately to benefit the user.",
                "The new retrieval paradigm is thus fundamentally different from the traditional paradigm, and is inherently more general.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent UCAIR (User-Centered Adaptive Information Retrieval) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "Thus the developed search agent can improve existing web search performance without additional effort from the user.",
                "The remaining sections are organized as follows.",
                "In Section 2, we discuss the related work.",
                "In Section 3, we present a decisiontheoretic interactive retrieval framework for implicit user modeling.",
                "In Section 4, we present the design and implementation of an intelligent client-side web search agent (UCAIR) that performs eager implicit feedback.",
                "In Section 5, we report our experiment results using the search agent.",
                "Section 6 concludes our work. 2.",
                "RELATED WORK Implicit user modeling for personalized search has been studied in previous work, but our work differs from all previous work in several aspects: (1) We emphasize the exploitation of immediate search context such as the related immediately preceding query and the viewed documents in the same session, while most previous work relies on long-term collection of implicit feedback information [25]. (2) We perform eager feedback and bring the benefit of implicit user modeling as soon as any new implicit feedback information is available, while the previous work mostly exploits longterm implicit feedback [10]. (3) We propose a retrieval framework to integrate implicit user modeling with the interactive retrieval process, while the previous work either studies implicit user modeling separately from retrieval [3] or only studies specific retrieval models for exploiting implicit feedback to better match a query with documents [23, 27, 22]. (4) We develop and evaluate a personalized Web search agent with online user studies, while most existing work evaluates algorithms offline without real user interactions.",
                "Currently some search engines provide rudimentary personalization, such as Google Personalized web search [6], which allows users to explicitly describe their interests by selecting from predefined topics, so that those results that match their interests are brought to the top, and My Yahoo! search [16], which gives users the option to save web sites they like and block those they dislike.",
                "In contrast, UCAIR personalizes web search through implicit user modeling without any additional user efforts.",
                "Furthermore, the personalization of UCAIR is provided on the client side.",
                "There are two remarkable advantages on this.",
                "First, the user does not need to worry about the privacy infringement, which is a big concern for personalized search [26].",
                "Second, both the computation of personalization and the storage of the user profile are done at the client side so that the server load is reduced dramatically [9].",
                "There have been many works studying user query logs [1] or query dynamics [13].",
                "UCAIR makes direct use of a users query history to benefit the same user immediately in the same search session.",
                "UCAIR first judges whether two neighboring queries belong to the same information session and if so, it selects terms from the previous query to perform query expansion.",
                "Our query expansion approach is similar to automatic query expansion [28, 15, 5], but instead of using pseudo feedback to expand the query, we use users implicit feedback information to expand the current query.",
                "These two techniques may be combined. 3.",
                "OPTIMIZATION IN INTERACTIVE IR In interactive IR, a user interacts with the retrieval system through an action dialogue, in which the system responds to each user action with some system action.",
                "For example, the users action may be submitting a query and the systems response may be returning a list of 10 document summaries.",
                "In general, the space of user actions and system responses and their granularities would depend on the interface of a particular retrieval system.",
                "In principle, every action of the user can potentially provide new evidence to help the system better infer the users information need.",
                "Thus in order to respond optimally, the system should use all the evidence collected so far about the user when choosing a response.",
                "When viewed in this way, most existing search engines are clearly non-optimal.",
                "For example, if a user has viewed some documents on the first page of search results, when the user clicks on the Next link to fetch more results, an existing retrieval system would still return the next page of results retrieved based on the original query without considering the new evidence that a particular result has been viewed by the user. 825 We propose to optimize <br>retrieval performance</br> by adapting system responses based on every action that a user has taken, and cast the optimization problem as a decision task.",
                "Specifically, at any time, the system would attempt to do two tasks: (1) User model updating: Monitor any useful evidence from the user regarding his/her information need and update the user model as soon as such evidence is available; (2) Improving search results: Rerank immediately all the documents that the user has not yet seen, as soon as the user model is updated.",
                "We emphasize eager updating and reranking, which makes our work quite different from any existing work.",
                "Below we present a formal decision theoretic framework for optimizing <br>retrieval performance</br> through implicit user modeling in interactive information retrieval. 3.1 A decision-theoretic framework Let A be the set of all user actions and R(a) be the set of all possible system responses to a user action a ∈ A.",
                "At any time, let At = (a1, ..., at) be the observed sequence of user actions so far (up to time point t) and Rt−1 = (r1, ..., rt−1) be the responses that the system has made responding to the user actions.",
                "The systems goal is to choose an optimal response rt ∈ R(at) for the current user action at.",
                "Let M be the space of all possible user models.",
                "We further define a loss function L(a, r, m) ∈ , where a ∈ A is a user action, r ∈ R(a) is a system response, and m ∈ M is a user model.",
                "L(a, r, m) encodes our decision preferences and assesses the optimality of responding with r when the current user model is m and the current user action is a.",
                "According to Bayesian decision theory, the optimal decision at time t is to choose a response that minimizes the Bayes risk, i.e., r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) where P(mt|U, D, At, Rt−1) is the posterior probability of the user model mt given all the observations about the user U we have made up to time t. To simplify the computation of Equation 1, let us assume that the posterior probability mass P(mt|U, D, At, Rt−1) is mostly concentrated on the mode m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "We can then approximate the integral with the value of the loss function at m∗ t .",
                "That is, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) where m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "Leaving aside how to define and estimate these probabilistic models and the loss function, we can see that such a decision-theoretic formulation suggests that, in order to choose the optimal response to at, the system should perform two tasks: (1) compute the current user model and obtain m∗ t based on all the useful information. (2) choose a response rt to minimize the loss function value L(at, rt, m∗ t ).",
                "When at does not affect our belief about m∗ t , the first step can be omitted and we may reuse m∗ t−1 for m∗ t .",
                "Note that our framework is quite general since we can potentially model any kind of user actions and system responses.",
                "In most cases, as we may expect, the systems response is some ranking of documents, i.e., for most actions a, R(a) consists of all the possible rankings of the unseen documents, and the decision problem boils down to choosing the best ranking of unseen documents based on the most current user model.",
                "When a is the action of submitting a keyword query, such a response is exactly what a current retrieval system would do.",
                "However, we can easily imagine that a more intelligent web search engine would respond to a users clicking of the Next link (to fetch more unseen results) with a more optimized ranking of documents based on any viewed documents in the current page of results.",
                "In fact, according to our eager updating strategy, we may even allow a system to respond to a users clicking of browsers Back button after viewing a document in the same way, so that the user can maximally benefit from implicit feedback.",
                "These are precisely what our UCAIR system does. 3.2 User models A user model m ∈ M represents what we know about the user U, so in principle, it can contain any information about the user that we wish to model.",
                "We now discuss two important components in a user model.",
                "The first component is a component model of the users information need.",
                "Presumably, the most important factor affecting the optimality of the systems response is how well the response addresses the users information need.",
                "Indeed, at any time, we may assume that the system has some belief about what the user is interested in, which we model through a term vector x = (x1, ..., x|V |), where V = {w1, ..., w|V |} is the set of all terms (i.e., vocabulary) and xi is the weight of term wi.",
                "Such a term vector is commonly used in information retrieval to represent both queries and documents.",
                "For example, the vector-space model, assumes that both the query and the documents are represented as term vectors and the score of a document with respect to a query is computed based on the similarity between the query vector and the document vector [21].",
                "In a language modeling approach, we may also regard the query unigram language model [12, 29] or the relevance model [14] as a term vector representation of the users information need.",
                "Intuitively, x would assign high weights to terms that characterize the topics which the user is interested in.",
                "The second component we may include in our user model is the documents that the user has already viewed.",
                "Obviously, even if a document is relevant, if the user has already seen the document, it would not be useful to present the same document again.",
                "We thus introduce another variable S ⊂ D (D is the whole set of documents in the collection) to denote the subset of documents in the search results that the user has already seen/viewed.",
                "In general, at time t, we may represent a user model as mt = (S, x, At, Rt−1), where S is the seen documents, x is the systems understanding of the users information need, and (At, Rt−1) represents the users interaction history.",
                "Note that an even more general user model may also include other factors such as the users reading level and occupation.",
                "If we assume that the uncertainty of a user model mt is solely due to the uncertainty of x, the computation of our current estimate of user model m∗ t will mainly involve computing our best estimate of x.",
                "That is, the system would choose a response according to r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) where x∗ = argmaxx P(x|U, D, At, Rt−1).",
                "This is the decision mechanism implemented in the UCAIR system to be described later.",
                "In this system, we avoided specifying the probabilistic model P(x|U, D, At, Rt−1) by computing x∗ directly with some existing feedback method. 3.3 Loss functions The exact definition of loss function L depends on the responses, thus it is inevitably application-specific.",
                "We now briefly discuss some possibilities when the response is to rank all the unseen documents and present the top k of them.",
                "Let r = (d1, ..., dk) be the top k documents, S be the set of seen documents by the user, and x∗ be the systems best guess of the users information need.",
                "We 826 may simply define the loss associated with r as the negative sum of the probability that each of the di is relevant, i.e., L(a, r, m) = − k i=1 P(relevant|di, m).",
                "Clearly, in order to minimize this loss function, the optimal response r would contain the k documents with the highest probability of relevance, which is intuitively reasonable.",
                "One deficiency of this top-k loss function is that it is not sensitive to the internal order of the selected top k documents, so switching the ranking order of a non-relevant document and a relevant one would not affect the loss, which is unreasonable.",
                "To model ranking, we can introduce a factor of the user model - the probability of each of the k documents being viewed by the user, P(view|di), and define the following ranking loss function: L(a, r, m) = − k i=1 P(view|di)P(relevant|di, m) Since in general, if di is ranked above dj (i.e., i < j), P(view|di) > P(view|dj), this loss function would favor a decision to rank relevant documents above non-relevant ones, as otherwise, we could always switch di with dj to reduce the loss value.",
                "Thus the system should simply perform a regular retrieval and rank documents according to the probability of relevance [18].",
                "Depending on the users retrieval preferences, there can be many other possibilities.",
                "For example, if the user does not want to see redundant documents, the loss function should include some redundancy measure on r based on the already seen documents S. Of course, when the response is not to choose a ranked list of documents, we would need a different loss function.",
                "We discuss one such example that is relevant to the search agent that we implement.",
                "When a user enters a query qt (current action), our search agent relies on some existing search engine to actually carry out search.",
                "In such a case, even though the search agent does not have control of the retrieval algorithm, it can still attempt to optimize the search results through refining the query sent to the search engine and/or reranking the results obtained from the search engine.",
                "The loss functions for reranking are already discussed above; we now take a look at the loss functions for query refinement.",
                "Let f be the retrieval function of the search engine that our agent uses so that f(q) would give us the search results using query q.",
                "Given that the current action of the user is entering a query qt (i.e., at = qt), our response would be f(q) for some q.",
                "Since we have no choice of f, our decision is to choose a good q.",
                "Formally, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) which shows that our goal is to find q∗ = argminqL(qt, f(q), m), i.e., an optimal query that would give us the best f(q).",
                "A different choice of loss function L(qt, f(q), m) would lead to a different query refinement strategy.",
                "In UCAIR, we heuristically compute q∗ by expanding qt with terms extracted from rt−1 whenever qt−1 and qt have high similarity.",
                "Note that rt−1 and qt−1 are contained in m as part of the users interaction history. 3.4 Implicit user modeling Implicit user modeling is captured in our framework through the computation of x∗ = argmaxx P(x|U, D, At, Rt−1), i.e., the systems current belief of what the users information need is.",
                "Here again there may be many possibilities, leading to different algorithms for implicit user modeling.",
                "We now discuss a few of them.",
                "First, when two consecutive queries are related, the previous query can be exploited to enrich the current query and provide more search context to help disambiguation.",
                "For this purpose, instead of performing query expansion as we did in the previous section, we could also compute an updated x∗ based on the previous query and retrieval results.",
                "The computed new user model can then be used to rank the documents with a standard information retrieval model.",
                "Second, we can also infer a users interest based on the summaries of the viewed documents.",
                "When a user is presented with a list of summaries of top ranked documents, if the user chooses to skip the first n documents and to view the (n+1)-th document, we may infer that the user is not interested in the displayed summaries for the first n documents, but is attracted by the displayed summary of the (n + 1)-th document.",
                "We can thus use these summaries as negative and positive examples to learn a more accurate user model x∗ .",
                "Here many standard relevance feedback techniques can be exploited [19, 20].",
                "Note that we should use the displayed summaries, as opposed to the actual contents of those documents, since it is possible that the displayed summary of the viewed document is relevant, but the document content is actually not.",
                "Similarly, a displayed summary may mislead a user to skip a relevant document.",
                "Inferring user models based on such displayed information, rather than the actual content of a document is an important difference between UCAIR and some other similar systems.",
                "In UCAIR, both of these strategies for inferring an implicit user model are implemented. 4.",
                "UCAIR: A PERSONALIZED SEARCH AGENT 4.1 Design In this section, we present a client-side web search agent called UCAIR, in which we implement some of the methods discussed in the previous section for performing personalized search through implicit user modeling.",
                "UCAIR is a web browser plug-in 1 that acts as a proxy for web search engines.",
                "Currently, it is only implemented for Internet Explorer and Google, but it is a matter of engineering to make it run on other web browsers and interact with other search engines.",
                "The issue of privacy is a primary obstacle for deploying any real world applications involving serious user modeling, such as personalized search.",
                "For this reason, UCAIR is strictly running as a client-side search agent, as opposed to a server-side application.",
                "This way, the captured user information always resides on the computer that the user is using, thus the user does not need to release any information to the outside.",
                "Client-side personalization also allows the system to easily observe a lot of user information that may not be easily available to a server.",
                "Furthermore, performing personalized search on the client-side is more scalable than on the serverside, since the overhead of computation and storage is distributed among clients.",
                "As shown in Figure 1, the UCAIR toolbar has 3 major components: (1) The (implicit) user modeling module captures a users search context and history information, including the submitted queries and any clicked search results and infers search session boundaries. (2) The query modification module selectively improves the query formulation according to the current user model. (3) The result re-ranking module immediately re-ranks any unseen search results whenever the user model is updated.",
                "In UCAIR, we consider four basic user actions: (1) submitting a keyword query; (2) viewing a document; (3) clicking the Back button; (4) clicking the Next link on a result page.",
                "For each of these four actions, the system responds with, respectively, (1) 1 UCAIR is available at: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Search Engine (e.g., Google) Search History Log (e.g.,past queries, clicked results) Query Modification Result Re-Ranking User Modeling Result Buffer UCAIR Userquery results clickthrough… Figure 1: UCAIR architecture generating a ranked list of results by sending a possibly expanded query to a search engine; (2) updating the information need model x; (3) reranking the unseen results on the current result page based on the current model x; and (4) reranking the unseen pages and generating the next page of results based on the current model x.",
                "Behind these responses, there are three basic tasks: (1) Decide whether the previous query is related to the current query and if so expand the current query with useful terms from the previous query or the results of the previous query. (2) Update the information need model x based on a newly clicked document summary. (3) Rerank a set of unseen documents based on the current model x.",
                "Below we describe our algorithms for each of them. 4.2 Session boundary detection and query expansion To effectively exploit previous queries and their corresponding clickthrough information, UCAIR needs to judge whether two adjacent queries belong to the same search session (i.e., detect session boundaries).",
                "Existing work on session boundary detection is mostly in the context of web log analysis (e.g., [8]), and uses statistical information rather than textual features.",
                "Since our clientside agent does not have access to server query logs, we make session boundary decisions based on textual similarity between two queries.",
                "Because related queries do not necessarily share the same words (e.g., java island and travel Indonesia), it is insufficient to use only query text.",
                "Therefore we use the search results of the two queries to help decide whether they are topically related.",
                "For example, for the above queries java island and travel Indonesia, the words java, bali, island, indonesia and travel may occur frequently in both queries search results, yielding a high similarity score.",
                "We only use the titles and summaries of the search results to calculate the similarity since they are available in the retrieved search result page and fetching the full text of every result page would significantly slow down the process.",
                "To compensate for the terseness of titles and summaries, we retrieve more results than a user would normally view for the purpose of detecting session boundaries (typically 50 results).",
                "The similarity between the previous query q and the current query q is computed as follows.",
                "Let {s1, s2, . . . , sn } and {s1, s2, . . . , sn} be the result sets for the two queries.",
                "We use the pivoted normalization TF-IDF weighting formula [24] to compute a term weight vector si for each result si.",
                "We define the average result savg to be the centroid of all the result vectors, i.e., (s1 + s2 + . . . + sn)/n.",
                "The cosine similarity between the two average results is calculated as s avg · savg/ s 2 avg · s2 avg If the similarity value exceeds a predefined threshold, the two queries will be considered to be in the same information session.",
                "If the previous query and the current query are found to belong to the same search session, UCAIR would attempt to expand the current query with terms from the previous query and its search results.",
                "Specifically, for each term in the previous query or the corresponding search results, if its frequency in the results of the current query is greater than a preset threshold (e.g. 5 results out of 50), the term would be added to the current query to form an expanded query.",
                "In this case, UCAIR would send this expanded query rather than the original one to the search engine and return the results corresponding to the expanded query.",
                "Currently, UCAIR only uses the immediate preceding query for query expansion; in principle, we could exploit all related past queries. 4.3 Information need model updating Suppose at time t, we have observed that the user has viewed k documents whose summaries are s1, ..., sk.",
                "We update our user model by computing a new information need vector with a standard feedback method in information retrieval (i.e., Rocchio [19]).",
                "According to the vector space retrieval model, each clicked summary si can be represented by a term weight vector si with each term weighted by a TF-IDF weighting formula [21].",
                "Rocchio computes the centroid vector of all the summaries and interpolates it with the original query vector to obtain an updated term vector.",
                "That is, x = αq + (1 − α) 1 k k i=1 si where q is the query vector, k is the number of summaries the user clicks immediately following the current query and α is a parameter that controls the influence of the clicked summaries on the inferred information need model.",
                "In our experiments, α is set to 0.5.",
                "Note that we update the information need model whenever the user views a document. 4.4 Result reranking In general, we want to rerank all the unseen results as soon as the user model is updated.",
                "Currently, UCAIR implements reranking in two cases, corresponding to the user clicking the Back button and Next link in the Internet Explorer.",
                "In both cases, the current (updated) user model would be used to rerank the unseen results so that the user would see improved search results immediately.",
                "To rerank any unseen document summaries, UCAIR uses the standard vector space retrieval model and scores each summary based on the similarity of the result and the current user information need vector x [21].",
                "Since implicit feedback is not completely reliable, we bring up only a small number (e.g. 5) of highest reranked results to be followed by any originally high ranked results. 828 Google result (user query = java map) UCAIR result (user query =java map) previous query = travel Indonesia previous query = hashtable expanded user query = java map Indonesia expanded user query = java map class 1 Java map projections of the world ... Lonely Planet - Indonesia Map Map (Java 2 Platform SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Java map projections of the world ... INDONESIA TOURISM : CENTRAL JAVA - MAP Java 2 Platform SE v1.3.1: Interface Map www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Java Map INDONESIA TOURISM : WEST JAVA - MAP An Introduction to Java Map Collection Classes java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Java Technology Concept Map IndoStreets - Java Map An Introduction to Java Map Collection Classes java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Indonesia Regions and Islands Maps, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 An Introduction to Java Map Collection Classes Indonesia City Street Map,... Hibernate simplifies inheritance mapping www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Java Map Maps Of Indonesia tmap 30.map Class Hierarchy www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Java API Map Maps of Indonesia by Peter Loud Class Scope www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas : Sam Maps of Indonesia by Peter Loud Class PrintSafeHashMap www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 INDONESIA TOURISM : WEST JAVA - MAP indonesiaphoto.com Java Pro - Union and Vertical Mapping of Classes www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Table 1: Sample results of query expansion 5.",
                "EVALUATION OF UCAIR We now present some results on evaluating the two major UCAIR functions: selective query expansion and result reranking based on user clickthrough data. 5.1 Sample results The query expansion strategy implemented in UCAIR is intentionally conservative to avoid misinterpretation of implicit user models.",
                "In practice, whenever it chooses to expand the query, the expansion usually makes sense.",
                "In Table 1, we show how UCAIR can successfully distinguish two different search contexts for the query java map, corresponding to two different previous queries (i.e., travel Indonesia vs. hashtable).",
                "Due to implicit user modeling, UCAIR intelligently figures out to add Indonesia and class, respectively, to the users query java map, which would otherwise be ambiguous as shown in the original results from Google on March 21, 2005.",
                "UCAIRs results are much more accurate than Googles results and reflect personalization in search.",
                "The eager implicit feedback component is designed to immediately respond to a users activity such as viewing a document.",
                "In Figure 2, we show how UCAIR can successfully disambiguate an ambiguous query jaguar by exploiting a viewed document summary.",
                "In this case, the initial retrieval results using jaguar (shown on the left side) contain two results about the Jaguar cars followed by two results about the Jaguar software.",
                "However, after the user views the web page content of the second result (about Jaguar car) and returns to the search result page by clicking Back button, UCAIR automatically nominates two new search results about Jaguar cars (shown on the right side), while the original two results about Jaguar software are pushed down on the list (unseen from the picture). 5.2 Quantitative evaluation To further evaluate UCAIR quantitatively, we conduct a user study on the effectiveness of the eager implicit feedback component.",
                "It is a challenge to quantitatively evaluate the potential performance improvement of our proposed model and UCAIR over Google in an unbiased way [7].",
                "Here, we design a user study, in which participants would do normal web search and judge a randomly and anonymously mixed set of results from Google and UCAIR at the end of the search session; participants do not know whether a result comes from Google or UCAIR.",
                "We recruited 6 graduate students for this user study, who have different backgrounds (3 computer science, 2 biology, and 1 chem<top> <num> Number: 716 <title> Spammer arrest sue <desc> Description: Have any spammers been arrested or sued for sending unsolicited e-mail? <narr> Narrative: Instances of arrests, prosecutions, convictions, and punishments of spammers, and lawsuits against them are relevant.",
                "Documents which describe laws to limit spam without giving details of lawsuits or criminal trials are not relevant. </top> Figure 3: An example of TREC query topic, expressed in a form which might be given to a human assistant or librarian istry).",
                "We use query topics from TREC 2 2004 Terabyte track [2] and TREC 2003 Web track [4] topic distillation task in the way to be described below.",
                "An example topic from TREC 2004 Terabyte track appears in Figure 3.",
                "The title is a short phrase and may be used as a query to the retrieval system.",
                "The description field provides a slightly longer statement of the topic requirement, usually expressed as a single complete sentence or question.",
                "Finally the narrative supplies additional information necessary to fully specify the requirement, expressed in the form of a short paragraph.",
                "Initially, each participant would browse 50 topics either from Terabyte track or Web track and pick 5 or 7 most interesting topics.",
                "For each picked topic, the participant would essentially do the normal web search using UCAIR to find many relevant web pages by using the title of the query topic as the initial keyword query.",
                "During this process, the participant may view the search results and possibly click on some interesting ones to view the web pages, just as in a normal web search.",
                "There is no requirement or restriction on how many queries the participant must submit or when the participant should stop the search for one topic.",
                "When the participant plans to change the search topic, he/she will simply press a button 2 Text REtrieval Conference: http://trec.nist.gov/ 829 Figure 2: Screen shots for result reranking to evaluate the search results before actually switching to the next topic.",
                "At the time of evaluation, 30 top ranked results from Google and UCAIR (some are overlapping) are randomly mixed together so that the participant would not know whether a result comes from Google or UCAIR.",
                "The participant would then judge the relevance of these results.",
                "We measure precision at top n (n = 5, 10, 20, 30) documents of Google and UCAIR.",
                "We also evaluate precisions at different recall levels.",
                "Altogether, 368 documents judged as relevant from Google search results and 429 documents judged as relevant from UCAIR by participants.",
                "Scatter plots of precision at top 10 and top 20 documents are shown in Figure 4 and Figure 5 respectively (The scatter plot of precision at top 30 documents is very similar to precision at top 20 documents).",
                "Each point of the scatter plots represents the precisions of Google and UCAIR on one query topic.",
                "Table 2 shows the average precision at top n documents among 32 topics.",
                "From Figure 4, Figure 5 and Table 2, we see that the search results from UCAIR are consistently better than those from Google by all the measures.",
                "Moreover, the performance improvement is more dramatic for precision at top 20 documents than that at precision at top 10 documents.",
                "One explanation for this is that the more interaction the user has with the system, the more clickthrough data UCAIR can be expected to collect.",
                "Thus the retrieval system can build more precise implicit user models, which lead to better retrieval accuracy.",
                "Ranking Method prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Improvement 8.0% 17.8% 20.2% 21.8% Table 2: Table of average precision at top n documents for 32 query topics The plot in Figure 6 shows the precision-recall curves for UCAIR and Google, where it is clearly seen that the performance of UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Scatterplot of Precision at Top 10 Documents Figure 4: Precision at top 10 documents of UCAIR and Google is consistently and considerably better than that of Google at all levels of recall. 6.",
                "CONCLUSIONS In this paper, we studied how to exploit implicit user modeling to intelligently personalize information retrieval and improve search accuracy.",
                "Unlike most previous work, we emphasize the use of immediate search context and implicit feedback information as well as eager updating of search results to maximally benefit a user.",
                "We presented a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent (UCAIR) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Scatterplot of Precision at Top 20 documents Figure 5: Precision at top 20 documents of UCAIR and Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 recall precision Precision−Recall curves Google Result UCAIR Result Figure 6: Precision at top 20 result of UCAIR and Google Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "The developed search agent thus can improve existing web search performance without any additional effort from the user. 7.",
                "ACKNOWLEDGEMENT We thank the six participants of our evaluation experiments.",
                "This work was supported in part by the National Science Foundation grants IIS-0347933 and IIS-0428472. 8.",
                "REFERENCES [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman, and O. Frieder.",
                "Hourly analysis of a very large topically categorized web query log.",
                "In Proceedings of SIGIR 2004, pages 321-328, 2004. [2] C. Clarke, N. Craswell, and I. Soboroff.",
                "Overview of the TREC 2004 terabyte track.",
                "In Proceedings of TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda, and D. Brown.",
                "Implicit interest indicators.",
                "In Proceedings of Intelligent User Interfaces 2001, pages 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson, and M. Wu.",
                "Overview of the TREC 2003 web track.",
                "In Proceedings of TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend, and V. Larvrenko.",
                "Relevance feedback and personalization: A language modeling perspective.",
                "In Proeedings of Second DELOS Workshop: Personalisation and Recommender Systems in Digital Libraries, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite, and D. Harman.",
                "Results and challenges in web search evaluation.",
                "Computer Networks, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A.",
                "An, and D. Schuurmans.",
                "Dynamic web log session identification with statistical language models.",
                "Journal of the American Society for Information Science and Technology, 55(14):1290-1303, 2004. [9] G. Jeh and J. Widom.",
                "Scaling personalized web search.",
                "In Proceedings of WWW 2003, pages 271-279, 2003. [10] T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of SIGKDD 2002, pages 133-142, 2002. [11] D. Kelly and J. Teevan.",
                "Implicit feedback for inferring user preference: A bibliography.",
                "SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of SIGIR01, pages 111-119, 2001. [13] T. Lau and E. Horvitz.",
                "Patterns of search: Analyzing and modeling web query refinement.",
                "In Proceedings of the Seventh International Conference on User Modeling (UM), pages 145 -152, 1999. [14] V. Lavrenko and B. Croft.",
                "Relevance-based language models.",
                "In Proceedings of SIGIR01, pages 120-127, 2001. [15] M. Mitra, A. Singhal, and C. Buckley.",
                "Improving automatic query expansion.",
                "In Proceedings of SIGIR 1998, pages 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg.",
                "As google goes, so goes the nation.",
                "New York Times, May 2003. [18] S. E. Robertson.",
                "The probability ranking principle in ı˚.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] J. J. Rocchio.",
                "Relevance feedback in information retrieval.",
                "In The SMART Retrieval System: Experiments in Automatic Document Processing, pages 313-323.",
                "Prentice-Hall Inc., 1971. [20] G. Salton and C. Buckley.",
                "Improving <br>retrieval performance</br> by retrieval feedback.",
                "Journal of the American Society for Information Science, 41(4):288-297, 1990. [21] G. Salton and M. J. McGill.",
                "Introduction to Modern Information Retrieval.",
                "McGraw-Hill, 1983. [22] X. Shen, B. Tan, and C. Zhai.",
                "Context-sensitive information retrieval using implicit feedback.",
                "In Proceedings of SIGIR 2005, pages 43-50, 2005. [23] X. Shen and C. Zhai.",
                "Exploiting query history for document ranking in interactive information retrieval (Poster).",
                "In Proceedings of SIGIR 2003, pages 377-378, 2003. [24] A. Singhal.",
                "Modern information retrieval: A brief overview.",
                "Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano, and M. Yoshikawa.",
                "Adaptive web search based on user profile constructed without any effort from users.",
                "In Proceedings of WWW 2004, pages 675-684, 2004. [26] E. Volokh.",
                "Personalization and privacy.",
                "Communications of the ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen, and I. Ruthven.",
                "A simulated study of implicit feedback models.",
                "In Proceedings of ECIR 2004, pages 311-326, 2004. [28] J. Xu and W. B. Croft.",
                "Query expansion using local and global document analysis.",
                "In Proceedings of SIGIR 1996, pages 4-11, 1996. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in KL divergence retrieval model.",
                "In Proceedings of the CIKM 2001, pages 403-410, 2001. 831"
            ],
            "original_annotated_samples": [
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users, resulting in inherently non-optimal <br>retrieval performance</br>.",
                "For example, if a user has viewed some documents on the first page of search results, when the user clicks on the Next link to fetch more results, an existing retrieval system would still return the next page of results retrieved based on the original query without considering the new evidence that a particular result has been viewed by the user. 825 We propose to optimize <br>retrieval performance</br> by adapting system responses based on every action that a user has taken, and cast the optimization problem as a decision task.",
                "Below we present a formal decision theoretic framework for optimizing <br>retrieval performance</br> through implicit user modeling in interactive information retrieval. 3.1 A decision-theoretic framework Let A be the set of all user actions and R(a) be the set of all possible system responses to a user action a ∈ A.",
                "Improving <br>retrieval performance</br> by retrieval feedback."
            ],
            "translated_annotated_samples": [
                "Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales, lo que resulta en un <br>rendimiento de recuperación</br> inherentemente no óptimo.",
                "Por ejemplo, si un usuario ha visto algunos documentos en la primera página de resultados de búsqueda, cuando el usuario hace clic en el enlace Siguiente para obtener más resultados, un sistema de recuperación existente seguiría devolviendo la siguiente página de resultados recuperados en función de la consulta original sin considerar la nueva evidencia de que un resultado en particular ha sido visto por el usuario. Proponemos optimizar el <br>rendimiento de la recuperación</br> adaptando las respuestas del sistema en función de cada acción que un usuario haya tomado, y planteamos el problema de optimización como una tarea de decisión.",
                "A continuación presentamos un marco formal de teoría de decisiones para optimizar el <br>rendimiento de recuperación</br> a través de la modelización implícita del usuario en la recuperación de información interactiva. 3.1 Un marco de teoría de decisiones Sea A el conjunto de todas las acciones del usuario y R(a) el conjunto de todas las posibles respuestas del sistema a una acción del usuario a ∈ A.",
                "Mejorando el <br>rendimiento de recuperación</br> mediante retroalimentación de recuperación."
            ],
            "translated_text": "Modelado implícito de usuarios para búsqueda personalizada Xuehua Shen, Bin Tan, ChengXiang Zhai Departamento de Ciencias de la Computación Universidad de Illinois en Urbana-Champaign RESUMEN Los sistemas de recuperación de información (por ejemplo, motores de búsqueda web) son críticos para superar la sobrecarga de información. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales, lo que resulta en un <br>rendimiento de recuperación</br> inherentemente no óptimo. Por ejemplo, un turista y un programador pueden usar la misma palabra \"java\" para buscar información diferente, pero los sistemas de búsqueda actuales devolverían los mismos resultados. En este artículo, estudiamos cómo inferir el interés de un usuario a partir del contexto de búsqueda del usuario y utilizar el modelo de usuario implícito inferido para la búsqueda personalizada. Presentamos un marco teórico de toma de decisiones y desarrollamos técnicas para el modelado implícito del usuario en la recuperación de información. Desarrollamos un agente de búsqueda web inteligente del lado del cliente (UCAIR) que puede realizar retroalimentación implícita ansiosa, por ejemplo, expansión de consultas basada en consultas anteriores y reordenamiento inmediato de resultados basado en información de clics. Los experimentos sobre la búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda sobre el popular motor de búsqueda Google. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación, Retroalimentación de relevancia, Proceso de búsqueda Términos Generales Algoritmos 1. Aunque muchos sistemas de recuperación de información (por ejemplo, motores de búsqueda web y sistemas de biblioteca digital) se han implementado con éxito, los sistemas de recuperación actuales están lejos de ser óptimos. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales [17]. Esta no optimalidad inherente se ve claramente en los siguientes dos casos: (1) Diferentes usuarios pueden utilizar exactamente la misma consulta (por ejemplo, Java) para buscar información diferente (por ejemplo, la isla de Java en Indonesia o el lenguaje de programación Java), pero los sistemas de IR existentes devuelven los mismos resultados para estos usuarios. Sin considerar al usuario actual, es imposible saber a qué sentido se refiere Java en una consulta. (2) Las necesidades de información de un usuario pueden cambiar con el tiempo. El mismo usuario puede usar Java a veces para referirse a la isla de Java en Indonesia y otras veces para referirse al lenguaje de programación. Sin reconocer el contexto de búsqueda, sería nuevamente imposible reconocer el sentido correcto. Para optimizar la precisión de la recuperación, claramente necesitamos modelar al usuario de manera adecuada y personalizar la búsqueda según cada usuario individual. El objetivo principal del modelado de usuario para la recuperación de información es modelar con precisión la necesidad de información de un usuario, lo cual, desafortunadamente, es una tarea muy difícil. De hecho, incluso resulta difícil para un usuario describir con precisión cuál es su necesidad de información. ¿Qué información está disponible para que un sistema pueda inferir la necesidad de información de un usuario? Obviamente, la consulta de los usuarios proporciona la evidencia más directa. De hecho, la mayoría de los sistemas de recuperación existentes se basan únicamente en la consulta para modelar la necesidad de información de los usuarios. Sin embargo, dado que una consulta suele ser extremadamente corta, el modelo de usuario construido basado en una consulta de palabras clave inevitablemente resulta empobrecido. Una forma efectiva de mejorar la modelización de usuarios en la recuperación de información es pedir al usuario que especifique explícitamente qué documentos son relevantes (es decir, útiles para satisfacer su necesidad de información) y luego mejorar la modelización de usuarios basándose en ejemplos de documentos relevantes. Esto se llama retroalimentación de relevancia, lo cual ha demostrado ser bastante efectivo para mejorar la precisión de recuperación [19, 20]. Desafortunadamente, en aplicaciones del mundo real, los usuarios suelen ser reacios a hacer el esfuerzo adicional de proporcionar ejemplos relevantes para retroalimentación [11]. Por lo tanto, es muy interesante estudiar cómo inferir la necesidad de información de un usuario basándose en cualquier información de retroalimentación implícita, la cual existe naturalmente a través de las interacciones del usuario y no requiere ningún esfuerzo adicional por parte del usuario. De hecho, varios estudios previos han demostrado que el modelado implícito del usuario puede mejorar la precisión de recuperación. En [3], se desarrolla un navegador web (Curious Browser) para registrar las calificaciones explícitas de relevancia de las páginas web por parte de los usuarios (retroalimentación de relevancia) y el comportamiento de navegación al ver una página, como el tiempo de permanencia, clics de ratón, movimiento del ratón y desplazamiento (retroalimentación implícita). Se muestra que el tiempo de permanencia en una página, la cantidad de desplazamiento en una página y la combinación de tiempo y desplazamiento tienen una fuerte correlación con las calificaciones de relevancia explícita, lo que sugiere que la retroalimentación implícita puede ser útil para inferir la necesidad de información del usuario. En [10], se recopilan datos de clics de usuario como datos de entrenamiento para aprender una función de recuperación, que se utiliza para producir un ranking personalizado de resultados de búsqueda que se adapte a las preferencias de un grupo de usuarios. En [25], los datos de clics recopilados durante un largo período de tiempo se utilizan a través de la expansión de consultas para mejorar la precisión de recuperación. Si bien un usuario puede tener intereses y preferencias generales a largo plazo para la información, a menudo está buscando documentos para satisfacer una necesidad de información ad-hoc, que solo dura un corto período de tiempo; una vez que se satisface la necesidad de información, el usuario generalmente ya no estaría interesado en esa información. Por ejemplo, un usuario puede estar buscando información sobre autos usados para comprar uno, pero una vez que el usuario ha comprado un auto, generalmente ya no está interesado en esa información. En tales casos, la información de retroalimentación implícita recopilada durante un largo período de tiempo es poco probable que sea muy útil, pero el contexto de búsqueda inmediato y la información de retroalimentación, como cuáles de los resultados de búsqueda para la necesidad de información actual son vistos, se espera que sean mucho más útiles. Considera la consulta de Java nuevamente. Cualquiera de la siguiente información de retroalimentación inmediata sobre el usuario podría potencialmente ayudar a determinar el significado previsto de Java en la consulta: (1) La consulta anterior enviada por el usuario es hashtable (en lugar de, por ejemplo, viajar a Indonesia). (2) En los resultados de búsqueda, el usuario visualizó una página donde palabras como programación, software y applet ocurren muchas veces. Hasta donde sabemos, cómo aprovechar este contexto de búsqueda inmediato y a corto plazo para mejorar la búsqueda aún no ha sido abordado de manera satisfactoria en trabajos anteriores. En este artículo, estudiamos cómo construir y actualizar un modelo de usuario basado en el contexto de búsqueda inmediato y la información de retroalimentación implícita, y utilizar el modelo para mejorar la precisión de la recuperación ad-hoc. Para beneficiar al máximo al usuario de un sistema de recuperación a través de modelado implícito del usuario, proponemos realizar retroalimentación implícita entusiasta. Es decir, tan pronto como observemos cualquier nueva pieza de evidencia del usuario, actualizaríamos la creencia del sistema sobre la necesidad de información del usuario y responderíamos con resultados de recuperación mejorados basados en el modelo de usuario actualizado. Presentamos un marco de trabajo de teoría de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. En un paradigma de recuperación tradicional, el problema de recuperación consiste en emparejar una consulta con documentos y clasificar los documentos según sus valores de relevancia. Como resultado, el proceso de recuperación es un ciclo independiente simple de consulta y visualización de resultados. En el nuevo paradigma de recuperación propuesto, el contexto de búsqueda de los usuarios juega un papel importante y el modelo de usuario implícito inferido se explota inmediatamente para beneficiar al usuario. El nuevo paradigma de recuperación es, por lo tanto, fundamentalmente diferente del paradigma tradicional y es inherentemente más general. Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos apropiados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para reordenar inmediatamente cualquier documento que aún no haya sido visto por el usuario. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente UCAIR (Recuperación de Información Adaptativa Centrada en el Usuario) sobre un motor de búsqueda popular (Google). Los experimentos sobre búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en comparación con Google. Dado que la información implícita que explotamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional. Por lo tanto, el agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin esfuerzo adicional por parte del usuario. Las secciones restantes están organizadas de la siguiente manera. En la Sección 2, discutimos el trabajo relacionado. En la Sección 3, presentamos un marco de recuperación interactiva basado en teoría de decisiones para modelado implícito de usuarios. En la Sección 4, presentamos el diseño e implementación de un agente de búsqueda web inteligente del lado del cliente (UCAIR) que realiza retroalimentación implícita ansiosa. En la Sección 5, informamos nuestros resultados experimentales utilizando el agente de búsqueda. La sección 6 concluye nuestro trabajo. 2. El modelado implícito del usuario para la búsqueda personalizada ha sido estudiado en trabajos anteriores, pero nuestro trabajo difiere de todos los trabajos anteriores en varios aspectos: (1) Enfatizamos la explotación del contexto de búsqueda inmediato, como la consulta inmediatamente anterior relacionada y los documentos vistos en la misma sesión, mientras que la mayoría de los trabajos anteriores se basan en la recopilación a largo plazo de información de retroalimentación implícita [25]. (2) Realizamos una retroalimentación activa y obtenemos el beneficio del modelado implícito del usuario tan pronto como esté disponible cualquier nueva información de retroalimentación implícita, mientras que el trabajo anterior mayormente explota la retroalimentación implícita a largo plazo [10]. (3) Proponemos un marco de recuperación para integrar el modelado implícito del usuario con el proceso interactivo de recuperación, mientras que el trabajo anterior estudia el modelado implícito del usuario por separado de la recuperación [3] o solo estudia modelos de recuperación específicos para explotar la retroalimentación implícita para mejorar la coincidencia de una consulta con documentos [23, 27, 22]. (4) Desarrollamos y evaluamos un agente de búsqueda web personalizado con estudios de usuario en línea, mientras que la mayoría de los trabajos existentes evalúan algoritmos fuera de línea sin interacciones reales de usuarios. Actualmente algunos motores de búsqueda ofrecen personalización rudimentaria, como la búsqueda web personalizada de Google [6], que permite a los usuarios describir explícitamente sus intereses seleccionando entre temas predefinidos, de modo que los resultados que coinciden con sus intereses se muestren en la parte superior, y la búsqueda de My Yahoo! [16], que brinda a los usuarios la opción de guardar los sitios web que les gustan y bloquear aquellos que no les gustan. Por el contrario, UCAIR personaliza la búsqueda web a través de la modelización implícita del usuario sin necesidad de esfuerzos adicionales por parte del usuario. Además, la personalización de UCAIR se proporciona en el lado del cliente. Hay dos ventajas notables en esto. Primero, el usuario no necesita preocuparse por la infracción de privacidad, que es una gran preocupación para la búsqueda personalizada [26]. En segundo lugar, tanto el cálculo de la personalización como el almacenamiento del perfil del usuario se realizan en el lado del cliente para reducir drásticamente la carga del servidor [9]. Ha habido muchos trabajos estudiando los registros de consultas de usuarios [1] o la dinámica de consultas [13]. UCAIR hace uso directo del historial de consultas de un usuario para beneficiar al mismo usuario de inmediato en la misma sesión de búsqueda. UCAIR primero determina si dos consultas vecinas pertenecen a la misma sesión de información y, de ser así, selecciona términos de la consulta anterior para realizar la expansión de la consulta. Nuestro enfoque de expansión de consultas es similar a la expansión automática de consultas [28, 15, 5], pero en lugar de utilizar retroalimentación pseudo para expandir la consulta, utilizamos la información de retroalimentación implícita de los usuarios para expandir la consulta actual. Estas dos técnicas pueden ser combinadas. 3. OPTIMIZACIÓN EN IR INTERACTIVO En IR interactivo, un usuario interactúa con el sistema de recuperación a través de un diálogo de acción, en el cual el sistema responde a cada acción del usuario con alguna acción del sistema. Por ejemplo, la acción de los usuarios puede ser enviar una consulta y la respuesta del sistema puede ser devolver una lista de 10 resúmenes de documentos. En general, el espacio de acciones del usuario y respuestas del sistema y sus granularidades dependerían de la interfaz de un sistema de recuperación particular. En principio, cada acción del usuario puede potencialmente proporcionar nuevas pruebas para ayudar al sistema a inferir mejor la necesidad de información del usuario. Por lo tanto, para responder de manera óptima, el sistema debería utilizar toda la evidencia recopilada hasta ahora sobre el usuario al elegir una respuesta. Cuando se ven de esta manera, la mayoría de los motores de búsqueda existentes son claramente no óptimos. Por ejemplo, si un usuario ha visto algunos documentos en la primera página de resultados de búsqueda, cuando el usuario hace clic en el enlace Siguiente para obtener más resultados, un sistema de recuperación existente seguiría devolviendo la siguiente página de resultados recuperados en función de la consulta original sin considerar la nueva evidencia de que un resultado en particular ha sido visto por el usuario. Proponemos optimizar el <br>rendimiento de la recuperación</br> adaptando las respuestas del sistema en función de cada acción que un usuario haya tomado, y planteamos el problema de optimización como una tarea de decisión. Específicamente, en cualquier momento, el sistema intentaría realizar dos tareas: (1) Actualización del modelo de usuario: Monitorear cualquier evidencia útil del usuario con respecto a su necesidad de información y actualizar el modelo de usuario tan pronto como esta evidencia esté disponible; (2) Mejorar los resultados de búsqueda: Reclasificar inmediatamente todos los documentos que el usuario aún no ha visto, tan pronto como se actualice el modelo de usuario. Enfatizamos la actualización y reordenamiento entusiastas, lo que hace que nuestro trabajo sea bastante diferente a cualquier trabajo existente. A continuación presentamos un marco formal de teoría de decisiones para optimizar el <br>rendimiento de recuperación</br> a través de la modelización implícita del usuario en la recuperación de información interactiva. 3.1 Un marco de teoría de decisiones Sea A el conjunto de todas las acciones del usuario y R(a) el conjunto de todas las posibles respuestas del sistema a una acción del usuario a ∈ A. En cualquier momento, sea At = (a1, ..., at) la secuencia observada de acciones de usuario hasta ahora (hasta el momento t) y Rt−1 = (r1, ..., rt−1) las respuestas que el sistema ha dado en respuesta a las acciones del usuario. El objetivo del sistema es elegir una respuesta óptima rt ∈ R(at) para la acción actual del usuario at. Sea M el espacio de todos los posibles modelos de usuario. Definimos además una función de pérdida L(a, r, m) ∈ , donde a ∈ A es una acción del usuario, r ∈ R(a) es una respuesta del sistema, y m ∈ M es un modelo de usuario. L(a, r, m) codifica nuestras preferencias de decisión y evalúa la optimalidad de responder con r cuando el modelo de usuario actual es m y la acción de usuario actual es a. Según la teoría de decisión bayesiana, la decisión óptima en el tiempo t es elegir una respuesta que minimice el riesgo de Bayes, es decir, r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) donde P(mt|U, D, At, Rt−1) es la probabilidad posterior del modelo de usuario mt dadas todas las observaciones sobre el usuario U que hemos realizado hasta el tiempo t. Para simplificar el cálculo de la Ecuación 1, asumamos que la masa de probabilidad posterior P(mt|U, D, At, Rt−1) está principalmente concentrada en el modo m∗ t = argmaxmt P(mt|U, D, At, Rt−1). Podemos entonces aproximar la integral con el valor de la función de pérdida en m∗ t. Es decir, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) donde m∗ t = argmaxmt P(mt|U, D, At, Rt−1). Dejando de lado cómo definir y estimar estos modelos probabilísticos y la función de pérdida, podemos ver que tal formulación de la teoría de decisiones sugiere que, para elegir la respuesta óptima a at, el sistema debería realizar dos tareas: (1) calcular el modelo de usuario actual y obtener m∗ t basado en toda la información útil. (2) elegir una respuesta rt para minimizar el valor de la función de pérdida L(at, rt, m∗ t). Cuando at no afecta nuestra creencia sobre m∗ t , el primer paso puede omitirse y podemos reutilizar m∗ t−1 para m∗ t . Ten en cuenta que nuestro marco de trabajo es bastante general, ya que potencialmente podemos modelar cualquier tipo de acciones de usuario y respuestas del sistema. En la mayoría de los casos, como podríamos esperar, la respuesta del sistema es algún tipo de clasificación de documentos, es decir, para la mayoría de las acciones a, R(a) consiste en todas las posibles clasificaciones de los documentos no vistos, y el problema de decisión se reduce a elegir la mejor clasificación de los documentos no vistos basándose en el modelo de usuario más actualizado. Cuando a es la acción de enviar una consulta de palabras clave, tal respuesta es exactamente lo que haría un sistema de recuperación actual. Sin embargo, fácilmente podemos imaginar que un motor de búsqueda web más inteligente respondería al clic del usuario en el enlace Siguiente (para obtener más resultados no vistos) con una clasificación más optimizada de documentos basada en cualquier documento visto en la página actual de resultados. De hecho, según nuestra estrategia de actualización entusiasta, incluso podríamos permitir que un sistema responda al clic del botón Atrás del navegador por parte de un usuario después de ver un documento de la misma manera, para que el usuario pueda beneficiarse al máximo de la retroalimentación implícita. Estos son precisamente lo que nuestro sistema UCAIR hace. 3.2 Modelos de usuario Un modelo de usuario m ∈ M representa lo que sabemos sobre el usuario U, por lo que en principio, puede contener cualquier información sobre el usuario que deseemos modelar. Ahora discutimos dos componentes importantes en un modelo de usuario. El primer componente es un modelo de componente de la necesidad de información de los usuarios. Presumiblemente, el factor más importante que afecta la optimalidad de la respuesta del sistema es qué tan bien la respuesta aborda la necesidad de información de los usuarios. De hecho, en cualquier momento, podemos asumir que el sistema tiene alguna creencia sobre lo que le interesa al usuario, la cual modelamos a través de un vector de términos x = (x1, ..., x|V|), donde V = {w1, ..., w|V|} es el conjunto de todos los términos (es decir, vocabulario) y xi es el peso del término wi. Un vector de términos de este tipo se utiliza comúnmente en la recuperación de información para representar tanto consultas como documentos. Por ejemplo, el modelo de espacio vectorial asume que tanto la consulta como los documentos se representan como vectores de términos y que la puntuación de un documento con respecto a una consulta se calcula en función de la similitud entre el vector de la consulta y el vector del documento [21]. En un enfoque de modelado de lenguaje, también podemos considerar el modelo de lenguaje unigrama de consulta [12, 29] o el modelo de relevancia [14] como una representación vectorial de términos de la necesidad de información de los usuarios. Intuitivamente, x asignaría pesos altos a los términos que caracterizan los temas que interesan al usuario. El segundo componente que podemos incluir en nuestro modelo de usuario son los documentos que el usuario ya ha visto. Obviamente, incluso si un documento es relevante, si el usuario ya ha visto el documento, no sería útil presentar el mismo documento de nuevo. Por lo tanto, introducimos otra variable S ⊂ D (D es el conjunto completo de documentos en la colección) para denotar el subconjunto de documentos en los resultados de búsqueda que el usuario ya ha visto. En general, en el tiempo t, podemos representar un modelo de usuario como mt = (S, x, At, Rt−1), donde S son los documentos vistos, x es la comprensión del sistema de la necesidad de información del usuario, y (At, Rt−1) representa el historial de interacción del usuario. Ten en cuenta que un modelo de usuario aún más general también puede incluir otros factores como el nivel de lectura y la ocupación de los usuarios. Si asumimos que la incertidumbre de un modelo de usuario mt se debe únicamente a la incertidumbre de x, el cálculo de nuestra estimación actual del modelo de usuario m∗ t implicará principalmente calcular nuestra mejor estimación de x. Es decir, el sistema elegiría una respuesta de acuerdo a r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) donde x∗ = argmaxx P(x|U, D, At, Rt−1). Este es el mecanismo de decisión implementado en el sistema UCAIR que se describirá más adelante. En este sistema, evitamos especificar el modelo probabilístico P(x|U, D, At, Rt−1) calculando x∗ directamente con algún método de retroalimentación existente. 3.3 Funciones de pérdida La definición exacta de la función de pérdida L depende de las respuestas, por lo que es inevitablemente específica de la aplicación. Ahora discutimos brevemente algunas posibilidades cuando la respuesta es clasificar todos los documentos no vistos y presentar los mejores k de ellos. Sea r = (d1, ..., dk) los k documentos principales, S el conjunto de documentos vistos por el usuario, y x∗ la mejor suposición del sistema sobre la necesidad de información del usuario. Podemos definir simplemente la pérdida asociada con r como la suma negativa de la probabilidad de que cada uno de los di sea relevante, es decir, L(a, r, m) = − k i=1 P(relevante|di, m). Claramente, para minimizar esta función de pérdida, la respuesta óptima r contendría los k documentos con la probabilidad más alta de relevancia, lo cual es intuitivamente razonable. Una deficiencia de esta función de pérdida top-k es que no es sensible al orden interno de los documentos top k seleccionados, por lo que cambiar el orden de clasificación de un documento no relevante y uno relevante no afectaría la pérdida, lo cual es irrazonable. Para modelar el ranking, podemos introducir un factor del modelo de usuario: la probabilidad de que cada uno de los k documentos sea visto por el usuario, P(vista|di), y definir la siguiente función de pérdida de ranking: L(a, r, m) = − k i=1 P(vista|di)P(relevante|di, m). Dado que, en general, si di está clasificado por encima de dj (es decir, i < j), P(vista|di) > P(vista|dj), esta función de pérdida favorecería una decisión de clasificar documentos relevantes por encima de los no relevantes, ya que de lo contrario, siempre podríamos intercambiar di con dj para reducir el valor de pérdida. Por lo tanto, el sistema simplemente debería realizar una recuperación regular y clasificar los documentos según la probabilidad de relevancia [18]. Dependiendo de las preferencias de recuperación de los usuarios, puede haber muchas otras posibilidades. Por ejemplo, si el usuario no desea ver documentos redundantes, la función de pérdida debería incluir alguna medida de redundancia en r basada en los documentos ya vistos S. Por supuesto, cuando la respuesta no es elegir una lista clasificada de documentos, necesitaríamos una función de pérdida diferente. Discutimos un ejemplo relevante para el agente de búsqueda que implementamos. Cuando un usuario ingresa una consulta qt (acción actual), nuestro agente de búsqueda se basa en algún motor de búsqueda existente para llevar a cabo la búsqueda en realidad. En tal caso, aunque el agente de búsqueda no tenga control sobre el algoritmo de recuperación, aún puede intentar optimizar los resultados de la búsqueda refinando la consulta enviada al motor de búsqueda y/o reordenando los resultados obtenidos del motor de búsqueda. Las funciones de pérdida para el reordenamiento ya fueron discutidas anteriormente; ahora echamos un vistazo a las funciones de pérdida para el refinamiento de consultas. Sea f la función de recuperación del motor de búsqueda que nuestro agente utiliza, de modo que f(q) nos daría los resultados de búsqueda utilizando la consulta q. Dado que la acción actual del usuario es ingresar una consulta qt (es decir, at = qt), nuestra respuesta sería f(q) para algún q. Dado que no tenemos elección de f, nuestra decisión es elegir un buen q. Formalmente, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) lo cual muestra que nuestro objetivo es encontrar q∗ = argminqL(qt, f(q), m), es decir, una consulta óptima que nos daría el mejor f(q). Una elección diferente de la función de pérdida L(qt, f(q), m) llevaría a una estrategia de refinamiento de consulta diferente. En UCAIR, calculamos heurísticamente q∗ expandiendo qt con términos extraídos de rt−1 siempre que qt−1 y qt tengan una alta similitud. Se debe tener en cuenta que rt−1 y qt−1 están contenidos en m como parte del historial de interacción de los usuarios. 3.4 Modelado implícito del usuario El modelado implícito del usuario se captura en nuestro marco a través del cálculo de x∗ = argmaxx P(x|U, D, At, Rt−1), es decir, la creencia actual del sistema sobre cuál es la necesidad de información del usuario. Aquí nuevamente puede haber muchas posibilidades, lo que lleva a diferentes algoritmos para la modelización implícita del usuario. Ahora discutimos algunos de ellos. Primero, cuando dos consultas consecutivas están relacionadas, la consulta anterior puede ser explotada para enriquecer la consulta actual y proporcionar más contexto de búsqueda para ayudar en la desambiguación. Para este propósito, en lugar de realizar una expansión de consulta como lo hicimos en la sección anterior, también podríamos calcular un x∗ actualizado basado en la consulta anterior y los resultados de recuperación. El modelo de usuario nuevo calculado puede luego ser utilizado para clasificar los documentos con un modelo estándar de recuperación de información. Segundo, también podemos inferir los intereses de un usuario basándonos en los resúmenes de los documentos visualizados. Cuando a un usuario se le presenta una lista de resúmenes de documentos mejor clasificados, si el usuario elige saltarse los primeros n documentos y ver el documento (n+1)-ésimo, podemos inferir que el usuario no está interesado en los resúmenes mostrados para los primeros n documentos, pero está atraído por el resumen mostrado del documento (n+1)-ésimo. Por lo tanto, podemos usar estos resúmenes como ejemplos negativos y positivos para aprender un modelo de usuario más preciso x∗. Aquí se pueden explotar muchas técnicas estándar de retroalimentación de relevancia [19, 20]. Ten en cuenta que debemos utilizar los resúmenes mostrados, en lugar de los contenidos reales de esos documentos, ya que es posible que el resumen mostrado del documento visto sea relevante, pero el contenido del documento en realidad no lo sea. Del mismo modo, un resumen mostrado puede llevar a un usuario a omitir un documento relevante. Inferir modelos de usuario basados en dicha información mostrada, en lugar del contenido real de un documento, es una diferencia importante entre UCAIR y algunos otros sistemas similares. En UCAIR, ambas estrategias para inferir un modelo de usuario implícito están implementadas. 4. UCAIR: Un agente de búsqueda personalizado 4.1 Diseño En esta sección, presentamos un agente de búsqueda web del lado del cliente llamado UCAIR, en el cual implementamos algunos de los métodos discutidos en la sección anterior para realizar búsquedas personalizadas a través de modelado implícito del usuario. UCAIR es un complemento del navegador web que actúa como proxy para los motores de búsqueda en la web. Actualmente, solo está implementado para Internet Explorer y Google, pero es cuestión de ingeniería hacer que funcione en otros navegadores web e interactúe con otros motores de búsqueda. El tema de la privacidad es un obstáculo principal para implementar cualquier aplicación del mundo real que involucre modelado de usuarios serio, como la búsqueda personalizada. Por esta razón, UCAIR funciona estrictamente como un agente de búsqueda del lado del cliente, en lugar de ser una aplicación del lado del servidor. De esta manera, la información del usuario capturada siempre permanece en la computadora que está utilizando el usuario, por lo tanto, el usuario no necesita revelar ninguna información al exterior. La personalización del lado del cliente también permite que el sistema observe fácilmente una gran cantidad de información del usuario que puede no estar fácilmente disponible para un servidor. Además, realizar búsquedas personalizadas en el lado del cliente es más escalable que en el lado del servidor, ya que la sobrecarga de cálculo y almacenamiento se distribuye entre los clientes. Como se muestra en la Figura 1, la barra de herramientas UCAIR tiene 3 componentes principales: (1) El módulo de modelado de usuario (implícito) captura el contexto de búsqueda de un usuario e información de historial, incluidas las consultas enviadas y los resultados de búsqueda clicados, e infiere los límites de la sesión de búsqueda. (2) El módulo de modificación de consultas mejora selectivamente la formulación de la consulta de acuerdo con el modelo de usuario actual. (3) El módulo de reordenamiento de resultados reordena inmediatamente cualquier resultado de búsqueda no visto cada vez que se actualiza el modelo de usuario. En UCAIR, consideramos cuatro acciones básicas de usuario: (1) enviar una consulta de palabras clave; (2) ver un documento; (3) hacer clic en el botón Atrás; (4) hacer clic en el enlace Siguiente en una página de resultados. Para cada una de estas cuatro acciones, el sistema responde con, respectivamente, (1) 1 UCAIR está disponible en: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Registro de Historial de Búsqueda del Motor de Búsqueda (por ejemplo, Google) (consultas pasadas, resultados clicados) Modificación de Consulta Resultado de Reclasificación Modelo de Usuario Buffer de Resultados de Consulta de Usuario UCAIR... Figura 1: arquitectura de UCAIR generando una lista clasificada de resultados enviando una consulta posiblemente ampliada a un motor de búsqueda; (2) actualizando el modelo de necesidad de información x; (3) reordenando los resultados no vistos en la página de resultados actual basándose en el modelo actual x; y (4) reordenando las páginas no vistas y generando la siguiente página de resultados basándose en el modelo actual x. Detrás de estas respuestas, hay tres tareas básicas: (1) Decidir si la consulta anterior está relacionada con la consulta actual y, de ser así, ampliar la consulta actual con términos útiles de la consulta anterior o los resultados de la consulta anterior. (2) Actualizar el modelo de necesidad de información x basado en un resumen de documento recién seleccionado. (3) Reordenar un conjunto de documentos no vistos basado en el modelo x actual. A continuación describimos nuestros algoritmos para cada uno de ellos. 4.2 Detección de límites de sesión y expansión de consultas Para explotar eficazmente las consultas anteriores y su información correspondiente de clics, UCAIR necesita determinar si dos consultas adyacentes pertenecen a la misma sesión de búsqueda (es decir, detectar los límites de sesión). El trabajo existente sobre la detección de límites de sesión se encuentra principalmente en el contexto del análisis de registros web (por ejemplo, [8]), y utiliza información estadística en lugar de características textuales. Dado que nuestro agente del lado del cliente no tiene acceso a los registros de consultas del servidor, tomamos decisiones sobre los límites de sesión basadas en la similitud textual entre dos consultas. Debido a que las consultas relacionadas no necesariamente comparten las mismas palabras (por ejemplo, isla de Java y viajar a Indonesia), no es suficiente utilizar solo el texto de la consulta. Por lo tanto, utilizamos los resultados de búsqueda de las dos consultas para ayudar a decidir si están relacionadas temáticamente. Por ejemplo, para las consultas anteriores \"java island\" y \"travel Indonesia\", las palabras \"java\", \"bali\", \"island\", \"indonesia\" y \"travel\" pueden aparecer con frecuencia en los resultados de búsqueda de ambas consultas, lo que produce un alto puntaje de similitud. Solo utilizamos los títulos y resúmenes de los resultados de búsqueda para calcular la similitud, ya que están disponibles en la página de resultados de búsqueda recuperada y obtener el texto completo de cada página de resultados ralentizaría significativamente el proceso. Para compensar la concisión de los títulos y resúmenes, recuperamos más resultados de los que un usuario normalmente vería con el propósito de detectar los límites de sesión (típicamente 50 resultados). La similitud entre la consulta anterior q y la consulta actual q se calcula de la siguiente manera. Sean {s1, s2, . . . , sn} y {s1, s2, . . . , sn} los conjuntos de resultados de las dos consultas. Utilizamos la fórmula de ponderación TF-IDF normalizada pivotada [24] para calcular un vector de peso de término si para cada resultado si. Definimos el resultado promedio savg como el centroide de todos los vectores de resultado, es decir, (s1 + s2 + . . . + sn)/n. La similitud del coseno entre los dos resultados promedio se calcula como s avg · savg/ s 2 avg · s2 avg. Si el valor de similitud supera un umbral predefinido, se considerará que las dos consultas están en la misma sesión de información. Si se determina que la consulta anterior y la consulta actual pertenecen a la misma sesión de búsqueda, UCAIR intentaría expandir la consulta actual con términos de la consulta anterior y sus resultados de búsqueda. Específicamente, para cada término en la consulta anterior o los resultados de búsqueda correspondientes, si su frecuencia en los resultados de la consulta actual es mayor que un umbral preestablecido (por ejemplo, 5 resultados de 50), el término se agregaría a la consulta actual para formar una consulta ampliada. En este caso, UCAIR enviaría esta consulta ampliada en lugar de la original al motor de búsqueda y devolvería los resultados correspondientes a la consulta ampliada. Actualmente, UCAIR solo utiliza la consulta inmediatamente anterior para la expansión de consultas; en principio, podríamos aprovechar todas las consultas pasadas relacionadas. 4.3 Actualización del modelo de necesidad de información Supongamos que en el tiempo t, hemos observado que el usuario ha visto k documentos cuyos resúmenes son s1, ..., sk. Actualizamos nuestro modelo de usuario calculando un nuevo vector de necesidad de información con un método estándar de retroalimentación en la recuperación de información (es decir, Rocchio [19]). Según el modelo de recuperación de espacio vectorial, cada resumen clicado si puede ser representado por un vector de pesos de términos si, con cada término ponderado por una fórmula de ponderación TF-IDF [21]. Rocchio calcula el vector centroide de todos los resúmenes e interpola este con el vector de consulta original para obtener un vector de términos actualizado. Es decir, x = αq + (1 − α) 1 k k i=1 si donde q es el vector de consulta, k es el número de resúmenes que el usuario hace clic inmediatamente después de la consulta actual y α es un parámetro que controla la influencia de los resúmenes clicados en el modelo de necesidad de información inferida. En nuestros experimentos, α se establece en 0.5. Ten en cuenta que actualizamos el modelo de información necesario cada vez que el usuario ve un documento. 4.4 Reclasificación de resultados En general, queremos volver a clasificar todos los resultados no vistos tan pronto como se actualice el modelo de usuario. Actualmente, UCAIR implementa el reordenamiento en dos casos, correspondientes a cuando el usuario hace clic en el botón Atrás y en el enlace Siguiente en Internet Explorer. En ambos casos, el modelo de usuario actualizado se utilizaría para reordenar los resultados no vistos de manera que el usuario vea resultados de búsqueda mejorados de inmediato. Para volver a clasificar cualquier resumen de documento no visto, UCAIR utiliza el modelo estándar de recuperación de espacio vectorial y puntúa cada resumen en función de la similitud del resultado y el vector de necesidad de información actual del usuario x [21]. Dado que la retroalimentación implícita no es completamente confiable, presentamos solo un pequeño número (por ejemplo, 5) de los resultados reordenados más altos para ser seguidos por cualquier resultado originalmente clasificado alto. 828 resultados de Google (consulta del usuario = mapa de Java) Resultados de UCAIR (consulta del usuario = mapa de Java) consulta anterior = viajar a Indonesia consulta anterior = tabla hash consulta del usuario ampliada = mapa de Java Indonesia consulta del usuario ampliada = clase de mapa de Java 1 Proyecciones de mapas de Java del mundo ... Lonely Planet - Mapa de Indonesia Mapa (Plataforma Java SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Proyecciones de mapas de Java del mundo ... TURISMO DE INDONESIA: JAVA CENTRAL - MAPA Plataforma Java SE v1.3.1: Interfaz de Mapa www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Mapa de Java TURISMO DE INDONESIA: JAVA OESTE - MAPA Una introducción a las clases de colección de mapas de Java java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Mapa de Tecnología Java IndoStreets - Mapa de Java Una introducción a las clases de colección de mapas de Java java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Regiones e islas de Indonesia Mapas, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 Una introducción a las clases de colección de mapas de Java Mapa de calles de la ciudad de Indonesia,... Hibernate simplifica el mapeo de herencia www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Mapa de Java Mapas de Indonesia jerarquía de clases de tmap 30.map www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Mapa de API de Java Mapas de Indonesia por Peter Loud Alcance de clases www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas: Mapas de Sam de Indonesia por Peter Loud PrintSafeHashMap de la clase www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 TURISMO DE INDONESIA: JAVA OESTE - MAPA indonesiaphoto.com Java Pro - Unión y mapeo vertical de clases www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Tabla 1: Resultados de muestra de la expansión de la consulta EVALUACIÓN DE UCAIR Ahora presentamos algunos resultados sobre la evaluación de las dos principales funciones de UCAIR: la expansión selectiva de consultas y la reordenación de resultados basada en los datos de clics de los usuarios. 5.1 Resultados de muestra La estrategia de expansión de consultas implementada en UCAIR es intencionalmente conservadora para evitar la interpretación errónea de los modelos implícitos de los usuarios. En la práctica, cada vez que decide expandir la consulta, la expansión suele tener sentido. En la Tabla 1, mostramos cómo UCAIR puede distinguir exitosamente dos contextos de búsqueda diferentes para la consulta java map, correspondientes a dos consultas previas distintas (es decir, viajar a Indonesia vs. hashtable). Debido a la modelización implícita del usuario, UCAIR descubre inteligentemente agregar Indonesia y clase, respectivamente, a la consulta de los usuarios sobre el mapa de Java, lo cual de otro modo sería ambiguo, como se muestra en los resultados originales de Google el 21 de marzo de 2005. Los resultados de UCAIR son mucho más precisos que los resultados de Google y reflejan la personalización en la búsqueda. El componente de retroalimentación implícita entusiasta está diseñado para responder inmediatamente a la actividad de un usuario, como por ejemplo, al visualizar un documento. En la Figura 2, mostramos cómo UCAIR puede desambiguar con éxito una consulta ambigua de jaguar al explotar un resumen del documento visualizado. En este caso, los resultados iniciales de recuperación utilizando \"jaguar\" (mostrados en el lado izquierdo) contienen dos resultados sobre los autos Jaguar seguidos por dos resultados sobre el software Jaguar. Sin embargo, después de que el usuario ve el contenido de la página web del segundo resultado (sobre el automóvil Jaguar) y regresa a la página de resultados de búsqueda haciendo clic en el botón Atrás, UCAIR automáticamente selecciona dos nuevos resultados de búsqueda sobre automóviles Jaguar (mostrados en el lado derecho), mientras que los dos resultados originales sobre software de Jaguar se desplazan hacia abajo en la lista (no se ven en la imagen). 5.2 Evaluación cuantitativa Para evaluar UCAIR de manera cuantitativa, realizamos un estudio de usuario sobre la efectividad del componente de retroalimentación implícita ansiosa. Es un desafío evaluar cuantitativamente la mejora potencial en el rendimiento de nuestro modelo propuesto y UCAIR sobre Google de manera imparcial [7]. Aquí diseñamos un estudio de usuarios, en el cual los participantes realizarían una búsqueda web normal y evaluarían al azar y de forma anónima un conjunto de resultados mezclados de Google y UCAIR al final de la sesión de búsqueda; los participantes no saben si un resultado proviene de Google o de UCAIR. Reclutamos a 6 estudiantes de posgrado para este estudio de usuarios, quienes tienen diferentes antecedentes (3 en informática, 2 en biología y 1 en química). Los documentos que describen leyes para limitar el correo no deseado sin dar detalles de demandas judiciales o juicios penales no son relevantes. Utilizamos los temas de consulta de la pista Terabyte TREC 2 2004 [2] y la tarea de destilación de temas de la pista web TREC 2003 [4] de la manera que se describirá a continuación. Un ejemplo de tema del TREC 2004 Terabyte track aparece en la Figura 3. El título es una frase corta y puede ser utilizada como una consulta al sistema de recuperación. El campo de descripción proporciona una declaración ligeramente más larga del requisito del tema, generalmente expresado como una sola oración completa o pregunta. Finalmente, la narrativa proporciona información adicional necesaria para especificar completamente el requisito, expresado en forma de un breve párrafo. Inicialmente, cada participante exploraría 50 temas ya sea de la categoría Terabyte o de la categoría Web y elegiría los 5 o 7 temas más interesantes. Para cada tema seleccionado, el participante básicamente realizaría la búsqueda web normal utilizando UCAIR para encontrar muchas páginas web relevantes utilizando el título del tema de la consulta como la palabra clave inicial de la consulta. Durante este proceso, el participante puede ver los resultados de la búsqueda y posiblemente hacer clic en algunos interesantes para ver las páginas web, tal como en una búsqueda web normal. No hay ningún requisito o restricción sobre cuántas consultas debe enviar el participante o cuándo debe detener la búsqueda de un tema. Cuando el participante planea cambiar el tema de búsqueda, simplemente presionará un botón 2 de la Conferencia de Recuperación de Texto: http://trec.nist.gov/ 829 Figura 2: Capturas de pantalla para volver a clasificar los resultados y evaluar los resultados de búsqueda antes de cambiar al siguiente tema. En el momento de la evaluación, los 30 resultados mejor clasificados de Google y UCAIR (algunos se superponen) se mezclan aleatoriamente para que el participante no sepa si un resultado proviene de Google o de UCAIR. El participante luego juzgaría la relevancia de estos resultados. Medimos la precisión en los primeros n (n = 5, 10, 20, 30) documentos de Google y UCAIR. También evaluamos precisiones en diferentes niveles de recuperación. En total, 368 documentos fueron considerados relevantes a partir de los resultados de búsqueda de Google y 429 documentos fueron considerados relevantes por los participantes de UCAIR. Los diagramas de dispersión de precisión en los 10 y 20 documentos principales se muestran en la Figura 4 y la Figura 5 respectivamente (El diagrama de dispersión de precisión en los 30 documentos principales es muy similar al de los 20 documentos principales). Cada punto de los gráficos de dispersión representa las precisiones de Google y UCAIR en un tema de consulta. La Tabla 2 muestra la precisión promedio en los primeros n documentos entre 32 temas. A partir de la Figura 4, la Figura 5 y la Tabla 2, vemos que los resultados de búsqueda de UCAIR son consistentemente mejores que los de Google en todas las medidas. Además, la mejora en el rendimiento es más dramática para la precisión en los primeros 20 documentos que para la precisión en los primeros 10 documentos. Una explicación para esto es que cuanto más interacción tenga el usuario con el sistema, más datos de clics se espera que UCAIR pueda recopilar. Por lo tanto, el sistema de recuperación puede construir modelos de usuario implícitos más precisos, lo que conduce a una mayor precisión en la recuperación. El Método de Clasificación prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Mejora 8.0% 17.8% 20.2% 21.8% Tabla 2: Tabla de precisión promedio en los primeros n documentos para 32 temas de consulta El gráfico en la Figura 6 muestra las curvas de precisión-recuperación para UCAIR y Google, donde se observa claramente que el rendimiento de UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Gráfico de dispersión de Precisión en los 10 primeros documentos Figura 4: La precisión en los 10 primeros documentos de UCAIR y Google es consistentemente y considerablemente mejor que la de Google en todos los niveles de recuperación. 6. CONCLUSIONES En este artículo, estudiamos cómo aprovechar la modelización implícita del usuario para personalizar de manera inteligente la recuperación de información y mejorar la precisión de la búsqueda. A diferencia de la mayoría de trabajos anteriores, enfatizamos el uso del contexto de búsqueda inmediata y la información de retroalimentación implícita, así como la actualización rápida de los resultados de búsqueda para beneficiar al máximo a un usuario. Presentamos un marco de trabajo de toma de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos adecuados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para volver a clasificar inmediatamente cualquier documento que aún no haya sido visto por el usuario. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente (UCAIR) sobre un motor de búsqueda popular (Google). Los experimentos en la búsqueda web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en más de un 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Gráfico de dispersión de Precisión en los 20 documentos principales Figura 5: Precisión en los 20 documentos principales de UCAIR y Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 precisión recall Curvas de Precisión-Recall Resultado de Google Resultado de UCAIR Figura 6: Precisión en los 20 resultados principales de UCAIR y Google Google. Dado que la información implícita que aprovechamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional. El agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin necesidad de esfuerzo adicional por parte del usuario. AGRADECIMIENTO Agradecemos a los seis participantes de nuestros experimentos de evaluación. Este trabajo fue apoyado en parte por las subvenciones de la Fundación Nacional de Ciencias IIS-0347933 e IIS-0428472. REFERENCIAS [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman y O. Frieder. Análisis por hora de un registro de consultas web muy grande categorizado por tema. En Actas de SIGIR 2004, páginas 321-328, 2004. [2] C. Clarke, N. Craswell e I. Soboroff. Resumen de la pista de terabyte TREC 2004. En Actas de TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda y D. Brown. Indicadores implícitos de interés. En Actas de Interfaces de Usuario Inteligentes 2001, páginas 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson y M. Wu. Resumen de la pista web TREC 2003. En Actas de TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend y V. Larvrenko. Retroalimentación de relevancia y personalización: Una perspectiva de modelado del lenguaje. En Actas del Segundo Taller DELOS: Personalización y Sistemas de Recomendación en Bibliotecas Digitales, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite y D. Harman. Resultados y desafíos en la evaluación de búsqueda en la web. Redes de Computadoras, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A. An, y D. Schuurmans. Identificación dinámica de sesiones de registro web con modelos de lenguaje estadístico. Revista de la Sociedad Americana de Ciencia de la Información y Tecnología, 55(14):1290-1303, 2004. [9] G. Jeh y J. Widom. Escalando la búsqueda web personalizada. En Actas de WWW 2003, páginas 271-279, 2003. [10] T. Joachims. Optimización de motores de búsqueda utilizando datos de clics. En Actas de SIGKDD 2002, páginas 133-142, 2002. [11] D. Kelly y J. Teevan. Retroalimentación implícita para inferir preferencias de usuario: Una bibliografía. SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En Actas de SIGIR01, páginas 111-119, 2001. [13] T. Lau y E. Horvitz. Patrones de búsqueda: Análisis y modelado de la refinación de consultas web. En Actas de la Séptima Conferencia Internacional sobre Modelado de Usuarios (UM), páginas 145-152, 1999. [14] V. Lavrenko y B. Croft. Modelos de lenguaje basados en relevancia. En Actas de SIGIR01, páginas 120-127, 2001. [15] M. Mitra, A. Singhal y C. Buckley. Mejorando la expansión automática de consultas. En Actas de SIGIR 1998, páginas 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg. Según Google, así va la nación. New York Times, mayo de 2003. [18] S. E. Robertson. El principio de clasificación de probabilidad en ı˚. Revista de Documentación, 33(4):294-304, 1977. [19] J. J. Rocchio. Retroalimentación de relevancia en la recuperación de información. En el Sistema de Recuperación SMART: Experimentos en el Procesamiento Automático de Documentos, páginas 313-323. Prentice-Hall Inc., 1971. [20] G. Salton y C. Buckley. Mejorando el <br>rendimiento de recuperación</br> mediante retroalimentación de recuperación. Revista de la Sociedad Americana de Ciencia de la Información, 41(4):288-297, 1990. [21] G. Salton y M. J. McGill. Introducción a la Recuperación de Información Moderna. McGraw-Hill, 1983. [22] X. Shen, B. Tan y C. Zhai. Recuperación de información sensible al contexto utilizando retroalimentación implícita. En Actas de SIGIR 2005, páginas 43-50, 2005. [23] X. Shen y C. Zhai. Explotando el historial de consultas para la clasificación de documentos en la recuperación de información interactiva (Póster). En Actas de SIGIR 2003, páginas 377-378, 2003. [24] A. Singhal. Recuperación de información moderna: Una breve visión general. Boletín del Comité Técnico de Ingeniería de Datos de la Sociedad de Computación de IEEE, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano y M. Yoshikawa. Búsqueda web adaptativa basada en el perfil del usuario construido sin ningún esfuerzo por parte de los usuarios. En Actas de WWW 2004, páginas 675-684, 2004. [26] E. Volokh. Personalización y privacidad. Comunicaciones de la ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen e I. Ruthven. Un estudio simulado de modelos de retroalimentación implícita. En Actas de ECIR 2004, páginas 311-326, 2004. [28] J. Xu y W. B. Croft. Expansión de consultas utilizando análisis local y global de documentos. En Actas de SIGIR 1996, páginas 4-11, 1996. [29] C. Zhai y J. Lafferty. Modelo de retroalimentación basado en el modelo de recuperación de divergencia de KL. En Actas de la CIKM 2001, páginas 403-410, 2001. 831 ",
            "candidates": [],
            "error": [
                [
                    "rendimiento de recuperación",
                    "rendimiento de la recuperación",
                    "rendimiento de recuperación",
                    "rendimiento de recuperación"
                ]
            ]
        },
        "query refinement": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Implicit User Modeling for Personalized Search Xuehua Shen, Bin Tan, ChengXiang Zhai Department of Computer Science University of Illinois at Urbana-Champaign ABSTRACT Information retrieval systems (e.g., web search engines) are critical for overcoming information overload.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users, resulting in inherently non-optimal retrieval performance.",
                "For example, a tourist and a programmer may use the same word java to search for different information, but the current search systems would return the same results.",
                "In this paper, we study how to infer a users interest from the users search context and use the inferred implicit user model for personalized search .",
                "We present a decision theoretic framework and develop techniques for implicit user modeling in information retrieval.",
                "We develop an intelligent client-side web search agent (UCAIR) that can perform eager implicit feedback, e.g., query expansion based on previous queries and immediate result reranking based on clickthrough information.",
                "Experiments on web search show that our search agent can improve search accuracy over the popular Google search engine.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models, Relevance feedback, Search Process General Terms Algorithms 1.",
                "INTRODUCTION Although many information retrieval systems (e.g., web search engines and digital library systems) have been successfully deployed, the current retrieval systems are far from optimal.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users [17].",
                "This inherent non-optimality is seen clearly in the following two cases: (1) Different users may use exactly the same query (e.g., Java) to search for different information (e.g., the Java island in Indonesia or the Java programming language), but existing IR systems return the same results for these users.",
                "Without considering the actual user, it is impossible to know which sense Java refers to in a query. (2) A users information needs may change over time.",
                "The same user may use Java sometimes to mean the Java island in Indonesia and some other times to mean the programming language.",
                "Without recognizing the search context, it would be again impossible to recognize the correct sense.",
                "In order to optimize retrieval accuracy, we clearly need to model the user appropriately and personalize search according to each individual user.",
                "The major goal of user modeling for information retrieval is to accurately model a users information need, which is, unfortunately, a very difficult task.",
                "Indeed, it is even hard for a user to precisely describe what his/her information need is.",
                "What information is available for a system to infer a users information need?",
                "Obviously, the users query provides the most direct evidence.",
                "Indeed, most existing retrieval systems rely solely on the query to model a users information need.",
                "However, since a query is often extremely short, the user model constructed based on a keyword query is inevitably impoverished .",
                "An effective way to improve user modeling in information retrieval is to ask the user to explicitly specify which documents are relevant (i.e., useful for satisfying his/her information need), and then to improve user modeling based on such examples of relevant documents.",
                "This is called relevance feedback, which has been proved to be quite effective for improving retrieval accuracy [19, 20].",
                "Unfortunately, in real world applications, users are usually reluctant to make the extra effort to provide relevant examples for feedback [11].",
                "It is thus very interesting to study how to infer a users information need based on any implicit feedback information, which naturally exists through user interactions and thus does not require any extra user effort.",
                "Indeed, several previous studies have shown that implicit user modeling can improve retrieval accuracy.",
                "In [3], a web browser (Curious Browser) is developed to record a users explicit relevance ratings of web pages (relevance feedback) and browsing behavior when viewing a page, such as dwelling time, mouse click, mouse movement and scrolling (implicit feedback).",
                "It is shown that the dwelling time on a page, amount of scrolling on a page and the combination of time and scrolling have a strong correlation with explicit relevance ratings, which suggests that implicit feedback may be helpful for inferring user information need.",
                "In [10], user clickthrough data is collected as training data to learn a retrieval function, which is used to produce a customized ranking of search results that suits a group of users preferences.",
                "In [25], the clickthrough data collected over a long time period is exploited through query expansion to improve retrieval accuracy. 824 While a user may have general long term interests and preferences for information, often he/she is searching for documents to satisfy an ad-hoc information need, which only lasts for a short period of time; once the information need is satisfied, the user would generally no longer be interested in such information.",
                "For example, a user may be looking for information about used cars in order to buy one, but once the user has bought a car, he/she is generally no longer interested in such information.",
                "In such cases, implicit feedback information collected over a long period of time is unlikely to be very useful, but the immediate search context and feedback information, such as which of the search results for the current information need are viewed, can be expected to be much more useful.",
                "Consider the query Java again.",
                "Any of the following immediate feedback information about the user could potentially help determine the intended meaning of Java in the query: (1) The previous query submitted by the user is hashtable (as opposed to, e.g., travel Indonesia). (2) In the search results, the user viewed a page where words such as programming, software, and applet occur many times.",
                "To the best of our knowledge, how to exploit such immediate and short-term search context to improve search has so far not been well addressed in the previous work.",
                "In this paper, we study how to construct and update a user model based on the immediate search context and implicit feedback information and use the model to improve the accuracy of ad-hoc retrieval.",
                "In order to maximally benefit the user of a retrieval system through implicit user modeling, we propose to perform eager implicit feedback.",
                "That is, as soon as we observe any new piece of evidence from the user, we would update the systems belief about the users information need and respond with improved retrieval results based on the updated user model.",
                "We present a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "In a traditional retrieval paradigm, the retrieval problem is to match a query with documents and rank documents according to their relevance values.",
                "As a result, the retrieval process is a simple independent cycle of query and result display.",
                "In the proposed new retrieval paradigm, the users search context plays an important role and the inferred implicit user model is exploited immediately to benefit the user.",
                "The new retrieval paradigm is thus fundamentally different from the traditional paradigm, and is inherently more general.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent UCAIR (User-Centered Adaptive Information Retrieval) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "Thus the developed search agent can improve existing web search performance without additional effort from the user.",
                "The remaining sections are organized as follows.",
                "In Section 2, we discuss the related work.",
                "In Section 3, we present a decisiontheoretic interactive retrieval framework for implicit user modeling.",
                "In Section 4, we present the design and implementation of an intelligent client-side web search agent (UCAIR) that performs eager implicit feedback.",
                "In Section 5, we report our experiment results using the search agent.",
                "Section 6 concludes our work. 2.",
                "RELATED WORK Implicit user modeling for personalized search has been studied in previous work, but our work differs from all previous work in several aspects: (1) We emphasize the exploitation of immediate search context such as the related immediately preceding query and the viewed documents in the same session, while most previous work relies on long-term collection of implicit feedback information [25]. (2) We perform eager feedback and bring the benefit of implicit user modeling as soon as any new implicit feedback information is available, while the previous work mostly exploits longterm implicit feedback [10]. (3) We propose a retrieval framework to integrate implicit user modeling with the interactive retrieval process, while the previous work either studies implicit user modeling separately from retrieval [3] or only studies specific retrieval models for exploiting implicit feedback to better match a query with documents [23, 27, 22]. (4) We develop and evaluate a personalized Web search agent with online user studies, while most existing work evaluates algorithms offline without real user interactions.",
                "Currently some search engines provide rudimentary personalization, such as Google Personalized web search [6], which allows users to explicitly describe their interests by selecting from predefined topics, so that those results that match their interests are brought to the top, and My Yahoo! search [16], which gives users the option to save web sites they like and block those they dislike.",
                "In contrast, UCAIR personalizes web search through implicit user modeling without any additional user efforts.",
                "Furthermore, the personalization of UCAIR is provided on the client side.",
                "There are two remarkable advantages on this.",
                "First, the user does not need to worry about the privacy infringement, which is a big concern for personalized search [26].",
                "Second, both the computation of personalization and the storage of the user profile are done at the client side so that the server load is reduced dramatically [9].",
                "There have been many works studying user query logs [1] or query dynamics [13].",
                "UCAIR makes direct use of a users query history to benefit the same user immediately in the same search session.",
                "UCAIR first judges whether two neighboring queries belong to the same information session and if so, it selects terms from the previous query to perform query expansion.",
                "Our query expansion approach is similar to automatic query expansion [28, 15, 5], but instead of using pseudo feedback to expand the query, we use users implicit feedback information to expand the current query.",
                "These two techniques may be combined. 3.",
                "OPTIMIZATION IN INTERACTIVE IR In interactive IR, a user interacts with the retrieval system through an action dialogue, in which the system responds to each user action with some system action.",
                "For example, the users action may be submitting a query and the systems response may be returning a list of 10 document summaries.",
                "In general, the space of user actions and system responses and their granularities would depend on the interface of a particular retrieval system.",
                "In principle, every action of the user can potentially provide new evidence to help the system better infer the users information need.",
                "Thus in order to respond optimally, the system should use all the evidence collected so far about the user when choosing a response.",
                "When viewed in this way, most existing search engines are clearly non-optimal.",
                "For example, if a user has viewed some documents on the first page of search results, when the user clicks on the Next link to fetch more results, an existing retrieval system would still return the next page of results retrieved based on the original query without considering the new evidence that a particular result has been viewed by the user. 825 We propose to optimize retrieval performance by adapting system responses based on every action that a user has taken, and cast the optimization problem as a decision task.",
                "Specifically, at any time, the system would attempt to do two tasks: (1) User model updating: Monitor any useful evidence from the user regarding his/her information need and update the user model as soon as such evidence is available; (2) Improving search results: Rerank immediately all the documents that the user has not yet seen, as soon as the user model is updated.",
                "We emphasize eager updating and reranking, which makes our work quite different from any existing work.",
                "Below we present a formal decision theoretic framework for optimizing retrieval performance through implicit user modeling in interactive information retrieval. 3.1 A decision-theoretic framework Let A be the set of all user actions and R(a) be the set of all possible system responses to a user action a ∈ A.",
                "At any time, let At = (a1, ..., at) be the observed sequence of user actions so far (up to time point t) and Rt−1 = (r1, ..., rt−1) be the responses that the system has made responding to the user actions.",
                "The systems goal is to choose an optimal response rt ∈ R(at) for the current user action at.",
                "Let M be the space of all possible user models.",
                "We further define a loss function L(a, r, m) ∈ , where a ∈ A is a user action, r ∈ R(a) is a system response, and m ∈ M is a user model.",
                "L(a, r, m) encodes our decision preferences and assesses the optimality of responding with r when the current user model is m and the current user action is a.",
                "According to Bayesian decision theory, the optimal decision at time t is to choose a response that minimizes the Bayes risk, i.e., r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) where P(mt|U, D, At, Rt−1) is the posterior probability of the user model mt given all the observations about the user U we have made up to time t. To simplify the computation of Equation 1, let us assume that the posterior probability mass P(mt|U, D, At, Rt−1) is mostly concentrated on the mode m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "We can then approximate the integral with the value of the loss function at m∗ t .",
                "That is, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) where m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "Leaving aside how to define and estimate these probabilistic models and the loss function, we can see that such a decision-theoretic formulation suggests that, in order to choose the optimal response to at, the system should perform two tasks: (1) compute the current user model and obtain m∗ t based on all the useful information. (2) choose a response rt to minimize the loss function value L(at, rt, m∗ t ).",
                "When at does not affect our belief about m∗ t , the first step can be omitted and we may reuse m∗ t−1 for m∗ t .",
                "Note that our framework is quite general since we can potentially model any kind of user actions and system responses.",
                "In most cases, as we may expect, the systems response is some ranking of documents, i.e., for most actions a, R(a) consists of all the possible rankings of the unseen documents, and the decision problem boils down to choosing the best ranking of unseen documents based on the most current user model.",
                "When a is the action of submitting a keyword query, such a response is exactly what a current retrieval system would do.",
                "However, we can easily imagine that a more intelligent web search engine would respond to a users clicking of the Next link (to fetch more unseen results) with a more optimized ranking of documents based on any viewed documents in the current page of results.",
                "In fact, according to our eager updating strategy, we may even allow a system to respond to a users clicking of browsers Back button after viewing a document in the same way, so that the user can maximally benefit from implicit feedback.",
                "These are precisely what our UCAIR system does. 3.2 User models A user model m ∈ M represents what we know about the user U, so in principle, it can contain any information about the user that we wish to model.",
                "We now discuss two important components in a user model.",
                "The first component is a component model of the users information need.",
                "Presumably, the most important factor affecting the optimality of the systems response is how well the response addresses the users information need.",
                "Indeed, at any time, we may assume that the system has some belief about what the user is interested in, which we model through a term vector x = (x1, ..., x|V |), where V = {w1, ..., w|V |} is the set of all terms (i.e., vocabulary) and xi is the weight of term wi.",
                "Such a term vector is commonly used in information retrieval to represent both queries and documents.",
                "For example, the vector-space model, assumes that both the query and the documents are represented as term vectors and the score of a document with respect to a query is computed based on the similarity between the query vector and the document vector [21].",
                "In a language modeling approach, we may also regard the query unigram language model [12, 29] or the relevance model [14] as a term vector representation of the users information need.",
                "Intuitively, x would assign high weights to terms that characterize the topics which the user is interested in.",
                "The second component we may include in our user model is the documents that the user has already viewed.",
                "Obviously, even if a document is relevant, if the user has already seen the document, it would not be useful to present the same document again.",
                "We thus introduce another variable S ⊂ D (D is the whole set of documents in the collection) to denote the subset of documents in the search results that the user has already seen/viewed.",
                "In general, at time t, we may represent a user model as mt = (S, x, At, Rt−1), where S is the seen documents, x is the systems understanding of the users information need, and (At, Rt−1) represents the users interaction history.",
                "Note that an even more general user model may also include other factors such as the users reading level and occupation.",
                "If we assume that the uncertainty of a user model mt is solely due to the uncertainty of x, the computation of our current estimate of user model m∗ t will mainly involve computing our best estimate of x.",
                "That is, the system would choose a response according to r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) where x∗ = argmaxx P(x|U, D, At, Rt−1).",
                "This is the decision mechanism implemented in the UCAIR system to be described later.",
                "In this system, we avoided specifying the probabilistic model P(x|U, D, At, Rt−1) by computing x∗ directly with some existing feedback method. 3.3 Loss functions The exact definition of loss function L depends on the responses, thus it is inevitably application-specific.",
                "We now briefly discuss some possibilities when the response is to rank all the unseen documents and present the top k of them.",
                "Let r = (d1, ..., dk) be the top k documents, S be the set of seen documents by the user, and x∗ be the systems best guess of the users information need.",
                "We 826 may simply define the loss associated with r as the negative sum of the probability that each of the di is relevant, i.e., L(a, r, m) = − k i=1 P(relevant|di, m).",
                "Clearly, in order to minimize this loss function, the optimal response r would contain the k documents with the highest probability of relevance, which is intuitively reasonable.",
                "One deficiency of this top-k loss function is that it is not sensitive to the internal order of the selected top k documents, so switching the ranking order of a non-relevant document and a relevant one would not affect the loss, which is unreasonable.",
                "To model ranking, we can introduce a factor of the user model - the probability of each of the k documents being viewed by the user, P(view|di), and define the following ranking loss function: L(a, r, m) = − k i=1 P(view|di)P(relevant|di, m) Since in general, if di is ranked above dj (i.e., i < j), P(view|di) > P(view|dj), this loss function would favor a decision to rank relevant documents above non-relevant ones, as otherwise, we could always switch di with dj to reduce the loss value.",
                "Thus the system should simply perform a regular retrieval and rank documents according to the probability of relevance [18].",
                "Depending on the users retrieval preferences, there can be many other possibilities.",
                "For example, if the user does not want to see redundant documents, the loss function should include some redundancy measure on r based on the already seen documents S. Of course, when the response is not to choose a ranked list of documents, we would need a different loss function.",
                "We discuss one such example that is relevant to the search agent that we implement.",
                "When a user enters a query qt (current action), our search agent relies on some existing search engine to actually carry out search.",
                "In such a case, even though the search agent does not have control of the retrieval algorithm, it can still attempt to optimize the search results through refining the query sent to the search engine and/or reranking the results obtained from the search engine.",
                "The loss functions for reranking are already discussed above; we now take a look at the loss functions for <br>query refinement</br>.",
                "Let f be the retrieval function of the search engine that our agent uses so that f(q) would give us the search results using query q.",
                "Given that the current action of the user is entering a query qt (i.e., at = qt), our response would be f(q) for some q.",
                "Since we have no choice of f, our decision is to choose a good q.",
                "Formally, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) which shows that our goal is to find q∗ = argminqL(qt, f(q), m), i.e., an optimal query that would give us the best f(q).",
                "A different choice of loss function L(qt, f(q), m) would lead to a different <br>query refinement</br> strategy.",
                "In UCAIR, we heuristically compute q∗ by expanding qt with terms extracted from rt−1 whenever qt−1 and qt have high similarity.",
                "Note that rt−1 and qt−1 are contained in m as part of the users interaction history. 3.4 Implicit user modeling Implicit user modeling is captured in our framework through the computation of x∗ = argmaxx P(x|U, D, At, Rt−1), i.e., the systems current belief of what the users information need is.",
                "Here again there may be many possibilities, leading to different algorithms for implicit user modeling.",
                "We now discuss a few of them.",
                "First, when two consecutive queries are related, the previous query can be exploited to enrich the current query and provide more search context to help disambiguation.",
                "For this purpose, instead of performing query expansion as we did in the previous section, we could also compute an updated x∗ based on the previous query and retrieval results.",
                "The computed new user model can then be used to rank the documents with a standard information retrieval model.",
                "Second, we can also infer a users interest based on the summaries of the viewed documents.",
                "When a user is presented with a list of summaries of top ranked documents, if the user chooses to skip the first n documents and to view the (n+1)-th document, we may infer that the user is not interested in the displayed summaries for the first n documents, but is attracted by the displayed summary of the (n + 1)-th document.",
                "We can thus use these summaries as negative and positive examples to learn a more accurate user model x∗ .",
                "Here many standard relevance feedback techniques can be exploited [19, 20].",
                "Note that we should use the displayed summaries, as opposed to the actual contents of those documents, since it is possible that the displayed summary of the viewed document is relevant, but the document content is actually not.",
                "Similarly, a displayed summary may mislead a user to skip a relevant document.",
                "Inferring user models based on such displayed information, rather than the actual content of a document is an important difference between UCAIR and some other similar systems.",
                "In UCAIR, both of these strategies for inferring an implicit user model are implemented. 4.",
                "UCAIR: A PERSONALIZED SEARCH AGENT 4.1 Design In this section, we present a client-side web search agent called UCAIR, in which we implement some of the methods discussed in the previous section for performing personalized search through implicit user modeling.",
                "UCAIR is a web browser plug-in 1 that acts as a proxy for web search engines.",
                "Currently, it is only implemented for Internet Explorer and Google, but it is a matter of engineering to make it run on other web browsers and interact with other search engines.",
                "The issue of privacy is a primary obstacle for deploying any real world applications involving serious user modeling, such as personalized search.",
                "For this reason, UCAIR is strictly running as a client-side search agent, as opposed to a server-side application.",
                "This way, the captured user information always resides on the computer that the user is using, thus the user does not need to release any information to the outside.",
                "Client-side personalization also allows the system to easily observe a lot of user information that may not be easily available to a server.",
                "Furthermore, performing personalized search on the client-side is more scalable than on the serverside, since the overhead of computation and storage is distributed among clients.",
                "As shown in Figure 1, the UCAIR toolbar has 3 major components: (1) The (implicit) user modeling module captures a users search context and history information, including the submitted queries and any clicked search results and infers search session boundaries. (2) The query modification module selectively improves the query formulation according to the current user model. (3) The result re-ranking module immediately re-ranks any unseen search results whenever the user model is updated.",
                "In UCAIR, we consider four basic user actions: (1) submitting a keyword query; (2) viewing a document; (3) clicking the Back button; (4) clicking the Next link on a result page.",
                "For each of these four actions, the system responds with, respectively, (1) 1 UCAIR is available at: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Search Engine (e.g., Google) Search History Log (e.g.,past queries, clicked results) Query Modification Result Re-Ranking User Modeling Result Buffer UCAIR Userquery results clickthrough… Figure 1: UCAIR architecture generating a ranked list of results by sending a possibly expanded query to a search engine; (2) updating the information need model x; (3) reranking the unseen results on the current result page based on the current model x; and (4) reranking the unseen pages and generating the next page of results based on the current model x.",
                "Behind these responses, there are three basic tasks: (1) Decide whether the previous query is related to the current query and if so expand the current query with useful terms from the previous query or the results of the previous query. (2) Update the information need model x based on a newly clicked document summary. (3) Rerank a set of unseen documents based on the current model x.",
                "Below we describe our algorithms for each of them. 4.2 Session boundary detection and query expansion To effectively exploit previous queries and their corresponding clickthrough information, UCAIR needs to judge whether two adjacent queries belong to the same search session (i.e., detect session boundaries).",
                "Existing work on session boundary detection is mostly in the context of web log analysis (e.g., [8]), and uses statistical information rather than textual features.",
                "Since our clientside agent does not have access to server query logs, we make session boundary decisions based on textual similarity between two queries.",
                "Because related queries do not necessarily share the same words (e.g., java island and travel Indonesia), it is insufficient to use only query text.",
                "Therefore we use the search results of the two queries to help decide whether they are topically related.",
                "For example, for the above queries java island and travel Indonesia, the words java, bali, island, indonesia and travel may occur frequently in both queries search results, yielding a high similarity score.",
                "We only use the titles and summaries of the search results to calculate the similarity since they are available in the retrieved search result page and fetching the full text of every result page would significantly slow down the process.",
                "To compensate for the terseness of titles and summaries, we retrieve more results than a user would normally view for the purpose of detecting session boundaries (typically 50 results).",
                "The similarity between the previous query q and the current query q is computed as follows.",
                "Let {s1, s2, . . . , sn } and {s1, s2, . . . , sn} be the result sets for the two queries.",
                "We use the pivoted normalization TF-IDF weighting formula [24] to compute a term weight vector si for each result si.",
                "We define the average result savg to be the centroid of all the result vectors, i.e., (s1 + s2 + . . . + sn)/n.",
                "The cosine similarity between the two average results is calculated as s avg · savg/ s 2 avg · s2 avg If the similarity value exceeds a predefined threshold, the two queries will be considered to be in the same information session.",
                "If the previous query and the current query are found to belong to the same search session, UCAIR would attempt to expand the current query with terms from the previous query and its search results.",
                "Specifically, for each term in the previous query or the corresponding search results, if its frequency in the results of the current query is greater than a preset threshold (e.g. 5 results out of 50), the term would be added to the current query to form an expanded query.",
                "In this case, UCAIR would send this expanded query rather than the original one to the search engine and return the results corresponding to the expanded query.",
                "Currently, UCAIR only uses the immediate preceding query for query expansion; in principle, we could exploit all related past queries. 4.3 Information need model updating Suppose at time t, we have observed that the user has viewed k documents whose summaries are s1, ..., sk.",
                "We update our user model by computing a new information need vector with a standard feedback method in information retrieval (i.e., Rocchio [19]).",
                "According to the vector space retrieval model, each clicked summary si can be represented by a term weight vector si with each term weighted by a TF-IDF weighting formula [21].",
                "Rocchio computes the centroid vector of all the summaries and interpolates it with the original query vector to obtain an updated term vector.",
                "That is, x = αq + (1 − α) 1 k k i=1 si where q is the query vector, k is the number of summaries the user clicks immediately following the current query and α is a parameter that controls the influence of the clicked summaries on the inferred information need model.",
                "In our experiments, α is set to 0.5.",
                "Note that we update the information need model whenever the user views a document. 4.4 Result reranking In general, we want to rerank all the unseen results as soon as the user model is updated.",
                "Currently, UCAIR implements reranking in two cases, corresponding to the user clicking the Back button and Next link in the Internet Explorer.",
                "In both cases, the current (updated) user model would be used to rerank the unseen results so that the user would see improved search results immediately.",
                "To rerank any unseen document summaries, UCAIR uses the standard vector space retrieval model and scores each summary based on the similarity of the result and the current user information need vector x [21].",
                "Since implicit feedback is not completely reliable, we bring up only a small number (e.g. 5) of highest reranked results to be followed by any originally high ranked results. 828 Google result (user query = java map) UCAIR result (user query =java map) previous query = travel Indonesia previous query = hashtable expanded user query = java map Indonesia expanded user query = java map class 1 Java map projections of the world ... Lonely Planet - Indonesia Map Map (Java 2 Platform SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Java map projections of the world ... INDONESIA TOURISM : CENTRAL JAVA - MAP Java 2 Platform SE v1.3.1: Interface Map www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Java Map INDONESIA TOURISM : WEST JAVA - MAP An Introduction to Java Map Collection Classes java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Java Technology Concept Map IndoStreets - Java Map An Introduction to Java Map Collection Classes java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Indonesia Regions and Islands Maps, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 An Introduction to Java Map Collection Classes Indonesia City Street Map,... Hibernate simplifies inheritance mapping www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Java Map Maps Of Indonesia tmap 30.map Class Hierarchy www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Java API Map Maps of Indonesia by Peter Loud Class Scope www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas : Sam Maps of Indonesia by Peter Loud Class PrintSafeHashMap www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 INDONESIA TOURISM : WEST JAVA - MAP indonesiaphoto.com Java Pro - Union and Vertical Mapping of Classes www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Table 1: Sample results of query expansion 5.",
                "EVALUATION OF UCAIR We now present some results on evaluating the two major UCAIR functions: selective query expansion and result reranking based on user clickthrough data. 5.1 Sample results The query expansion strategy implemented in UCAIR is intentionally conservative to avoid misinterpretation of implicit user models.",
                "In practice, whenever it chooses to expand the query, the expansion usually makes sense.",
                "In Table 1, we show how UCAIR can successfully distinguish two different search contexts for the query java map, corresponding to two different previous queries (i.e., travel Indonesia vs. hashtable).",
                "Due to implicit user modeling, UCAIR intelligently figures out to add Indonesia and class, respectively, to the users query java map, which would otherwise be ambiguous as shown in the original results from Google on March 21, 2005.",
                "UCAIRs results are much more accurate than Googles results and reflect personalization in search.",
                "The eager implicit feedback component is designed to immediately respond to a users activity such as viewing a document.",
                "In Figure 2, we show how UCAIR can successfully disambiguate an ambiguous query jaguar by exploiting a viewed document summary.",
                "In this case, the initial retrieval results using jaguar (shown on the left side) contain two results about the Jaguar cars followed by two results about the Jaguar software.",
                "However, after the user views the web page content of the second result (about Jaguar car) and returns to the search result page by clicking Back button, UCAIR automatically nominates two new search results about Jaguar cars (shown on the right side), while the original two results about Jaguar software are pushed down on the list (unseen from the picture). 5.2 Quantitative evaluation To further evaluate UCAIR quantitatively, we conduct a user study on the effectiveness of the eager implicit feedback component.",
                "It is a challenge to quantitatively evaluate the potential performance improvement of our proposed model and UCAIR over Google in an unbiased way [7].",
                "Here, we design a user study, in which participants would do normal web search and judge a randomly and anonymously mixed set of results from Google and UCAIR at the end of the search session; participants do not know whether a result comes from Google or UCAIR.",
                "We recruited 6 graduate students for this user study, who have different backgrounds (3 computer science, 2 biology, and 1 chem<top> <num> Number: 716 <title> Spammer arrest sue <desc> Description: Have any spammers been arrested or sued for sending unsolicited e-mail? <narr> Narrative: Instances of arrests, prosecutions, convictions, and punishments of spammers, and lawsuits against them are relevant.",
                "Documents which describe laws to limit spam without giving details of lawsuits or criminal trials are not relevant. </top> Figure 3: An example of TREC query topic, expressed in a form which might be given to a human assistant or librarian istry).",
                "We use query topics from TREC 2 2004 Terabyte track [2] and TREC 2003 Web track [4] topic distillation task in the way to be described below.",
                "An example topic from TREC 2004 Terabyte track appears in Figure 3.",
                "The title is a short phrase and may be used as a query to the retrieval system.",
                "The description field provides a slightly longer statement of the topic requirement, usually expressed as a single complete sentence or question.",
                "Finally the narrative supplies additional information necessary to fully specify the requirement, expressed in the form of a short paragraph.",
                "Initially, each participant would browse 50 topics either from Terabyte track or Web track and pick 5 or 7 most interesting topics.",
                "For each picked topic, the participant would essentially do the normal web search using UCAIR to find many relevant web pages by using the title of the query topic as the initial keyword query.",
                "During this process, the participant may view the search results and possibly click on some interesting ones to view the web pages, just as in a normal web search.",
                "There is no requirement or restriction on how many queries the participant must submit or when the participant should stop the search for one topic.",
                "When the participant plans to change the search topic, he/she will simply press a button 2 Text REtrieval Conference: http://trec.nist.gov/ 829 Figure 2: Screen shots for result reranking to evaluate the search results before actually switching to the next topic.",
                "At the time of evaluation, 30 top ranked results from Google and UCAIR (some are overlapping) are randomly mixed together so that the participant would not know whether a result comes from Google or UCAIR.",
                "The participant would then judge the relevance of these results.",
                "We measure precision at top n (n = 5, 10, 20, 30) documents of Google and UCAIR.",
                "We also evaluate precisions at different recall levels.",
                "Altogether, 368 documents judged as relevant from Google search results and 429 documents judged as relevant from UCAIR by participants.",
                "Scatter plots of precision at top 10 and top 20 documents are shown in Figure 4 and Figure 5 respectively (The scatter plot of precision at top 30 documents is very similar to precision at top 20 documents).",
                "Each point of the scatter plots represents the precisions of Google and UCAIR on one query topic.",
                "Table 2 shows the average precision at top n documents among 32 topics.",
                "From Figure 4, Figure 5 and Table 2, we see that the search results from UCAIR are consistently better than those from Google by all the measures.",
                "Moreover, the performance improvement is more dramatic for precision at top 20 documents than that at precision at top 10 documents.",
                "One explanation for this is that the more interaction the user has with the system, the more clickthrough data UCAIR can be expected to collect.",
                "Thus the retrieval system can build more precise implicit user models, which lead to better retrieval accuracy.",
                "Ranking Method prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Improvement 8.0% 17.8% 20.2% 21.8% Table 2: Table of average precision at top n documents for 32 query topics The plot in Figure 6 shows the precision-recall curves for UCAIR and Google, where it is clearly seen that the performance of UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Scatterplot of Precision at Top 10 Documents Figure 4: Precision at top 10 documents of UCAIR and Google is consistently and considerably better than that of Google at all levels of recall. 6.",
                "CONCLUSIONS In this paper, we studied how to exploit implicit user modeling to intelligently personalize information retrieval and improve search accuracy.",
                "Unlike most previous work, we emphasize the use of immediate search context and implicit feedback information as well as eager updating of search results to maximally benefit a user.",
                "We presented a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent (UCAIR) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Scatterplot of Precision at Top 20 documents Figure 5: Precision at top 20 documents of UCAIR and Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 recall precision Precision−Recall curves Google Result UCAIR Result Figure 6: Precision at top 20 result of UCAIR and Google Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "The developed search agent thus can improve existing web search performance without any additional effort from the user. 7.",
                "ACKNOWLEDGEMENT We thank the six participants of our evaluation experiments.",
                "This work was supported in part by the National Science Foundation grants IIS-0347933 and IIS-0428472. 8.",
                "REFERENCES [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman, and O. Frieder.",
                "Hourly analysis of a very large topically categorized web query log.",
                "In Proceedings of SIGIR 2004, pages 321-328, 2004. [2] C. Clarke, N. Craswell, and I. Soboroff.",
                "Overview of the TREC 2004 terabyte track.",
                "In Proceedings of TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda, and D. Brown.",
                "Implicit interest indicators.",
                "In Proceedings of Intelligent User Interfaces 2001, pages 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson, and M. Wu.",
                "Overview of the TREC 2003 web track.",
                "In Proceedings of TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend, and V. Larvrenko.",
                "Relevance feedback and personalization: A language modeling perspective.",
                "In Proeedings of Second DELOS Workshop: Personalisation and Recommender Systems in Digital Libraries, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite, and D. Harman.",
                "Results and challenges in web search evaluation.",
                "Computer Networks, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A.",
                "An, and D. Schuurmans.",
                "Dynamic web log session identification with statistical language models.",
                "Journal of the American Society for Information Science and Technology, 55(14):1290-1303, 2004. [9] G. Jeh and J. Widom.",
                "Scaling personalized web search.",
                "In Proceedings of WWW 2003, pages 271-279, 2003. [10] T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of SIGKDD 2002, pages 133-142, 2002. [11] D. Kelly and J. Teevan.",
                "Implicit feedback for inferring user preference: A bibliography.",
                "SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of SIGIR01, pages 111-119, 2001. [13] T. Lau and E. Horvitz.",
                "Patterns of search: Analyzing and modeling web <br>query refinement</br>.",
                "In Proceedings of the Seventh International Conference on User Modeling (UM), pages 145 -152, 1999. [14] V. Lavrenko and B. Croft.",
                "Relevance-based language models.",
                "In Proceedings of SIGIR01, pages 120-127, 2001. [15] M. Mitra, A. Singhal, and C. Buckley.",
                "Improving automatic query expansion.",
                "In Proceedings of SIGIR 1998, pages 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg.",
                "As google goes, so goes the nation.",
                "New York Times, May 2003. [18] S. E. Robertson.",
                "The probability ranking principle in ı˚.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] J. J. Rocchio.",
                "Relevance feedback in information retrieval.",
                "In The SMART Retrieval System: Experiments in Automatic Document Processing, pages 313-323.",
                "Prentice-Hall Inc., 1971. [20] G. Salton and C. Buckley.",
                "Improving retrieval performance by retrieval feedback.",
                "Journal of the American Society for Information Science, 41(4):288-297, 1990. [21] G. Salton and M. J. McGill.",
                "Introduction to Modern Information Retrieval.",
                "McGraw-Hill, 1983. [22] X. Shen, B. Tan, and C. Zhai.",
                "Context-sensitive information retrieval using implicit feedback.",
                "In Proceedings of SIGIR 2005, pages 43-50, 2005. [23] X. Shen and C. Zhai.",
                "Exploiting query history for document ranking in interactive information retrieval (Poster).",
                "In Proceedings of SIGIR 2003, pages 377-378, 2003. [24] A. Singhal.",
                "Modern information retrieval: A brief overview.",
                "Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano, and M. Yoshikawa.",
                "Adaptive web search based on user profile constructed without any effort from users.",
                "In Proceedings of WWW 2004, pages 675-684, 2004. [26] E. Volokh.",
                "Personalization and privacy.",
                "Communications of the ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen, and I. Ruthven.",
                "A simulated study of implicit feedback models.",
                "In Proceedings of ECIR 2004, pages 311-326, 2004. [28] J. Xu and W. B. Croft.",
                "Query expansion using local and global document analysis.",
                "In Proceedings of SIGIR 1996, pages 4-11, 1996. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in KL divergence retrieval model.",
                "In Proceedings of the CIKM 2001, pages 403-410, 2001. 831"
            ],
            "original_annotated_samples": [
                "The loss functions for reranking are already discussed above; we now take a look at the loss functions for <br>query refinement</br>.",
                "A different choice of loss function L(qt, f(q), m) would lead to a different <br>query refinement</br> strategy.",
                "Patterns of search: Analyzing and modeling web <br>query refinement</br>."
            ],
            "translated_annotated_samples": [
                "Las funciones de pérdida para el reordenamiento ya fueron discutidas anteriormente; ahora echamos un vistazo a las funciones de pérdida para el <br>refinamiento de consultas</br>.",
                "Una elección diferente de la función de pérdida L(qt, f(q), m) llevaría a una estrategia de <br>refinamiento de consulta</br> diferente.",
                "Patrones de búsqueda: Análisis y modelado de la <br>refinación de consultas</br> web."
            ],
            "translated_text": "Modelado implícito de usuarios para búsqueda personalizada Xuehua Shen, Bin Tan, ChengXiang Zhai Departamento de Ciencias de la Computación Universidad de Illinois en Urbana-Champaign RESUMEN Los sistemas de recuperación de información (por ejemplo, motores de búsqueda web) son críticos para superar la sobrecarga de información. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales, lo que resulta en un rendimiento de recuperación inherentemente no óptimo. Por ejemplo, un turista y un programador pueden usar la misma palabra \"java\" para buscar información diferente, pero los sistemas de búsqueda actuales devolverían los mismos resultados. En este artículo, estudiamos cómo inferir el interés de un usuario a partir del contexto de búsqueda del usuario y utilizar el modelo de usuario implícito inferido para la búsqueda personalizada. Presentamos un marco teórico de toma de decisiones y desarrollamos técnicas para el modelado implícito del usuario en la recuperación de información. Desarrollamos un agente de búsqueda web inteligente del lado del cliente (UCAIR) que puede realizar retroalimentación implícita ansiosa, por ejemplo, expansión de consultas basada en consultas anteriores y reordenamiento inmediato de resultados basado en información de clics. Los experimentos sobre la búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda sobre el popular motor de búsqueda Google. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación, Retroalimentación de relevancia, Proceso de búsqueda Términos Generales Algoritmos 1. Aunque muchos sistemas de recuperación de información (por ejemplo, motores de búsqueda web y sistemas de biblioteca digital) se han implementado con éxito, los sistemas de recuperación actuales están lejos de ser óptimos. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales [17]. Esta no optimalidad inherente se ve claramente en los siguientes dos casos: (1) Diferentes usuarios pueden utilizar exactamente la misma consulta (por ejemplo, Java) para buscar información diferente (por ejemplo, la isla de Java en Indonesia o el lenguaje de programación Java), pero los sistemas de IR existentes devuelven los mismos resultados para estos usuarios. Sin considerar al usuario actual, es imposible saber a qué sentido se refiere Java en una consulta. (2) Las necesidades de información de un usuario pueden cambiar con el tiempo. El mismo usuario puede usar Java a veces para referirse a la isla de Java en Indonesia y otras veces para referirse al lenguaje de programación. Sin reconocer el contexto de búsqueda, sería nuevamente imposible reconocer el sentido correcto. Para optimizar la precisión de la recuperación, claramente necesitamos modelar al usuario de manera adecuada y personalizar la búsqueda según cada usuario individual. El objetivo principal del modelado de usuario para la recuperación de información es modelar con precisión la necesidad de información de un usuario, lo cual, desafortunadamente, es una tarea muy difícil. De hecho, incluso resulta difícil para un usuario describir con precisión cuál es su necesidad de información. ¿Qué información está disponible para que un sistema pueda inferir la necesidad de información de un usuario? Obviamente, la consulta de los usuarios proporciona la evidencia más directa. De hecho, la mayoría de los sistemas de recuperación existentes se basan únicamente en la consulta para modelar la necesidad de información de los usuarios. Sin embargo, dado que una consulta suele ser extremadamente corta, el modelo de usuario construido basado en una consulta de palabras clave inevitablemente resulta empobrecido. Una forma efectiva de mejorar la modelización de usuarios en la recuperación de información es pedir al usuario que especifique explícitamente qué documentos son relevantes (es decir, útiles para satisfacer su necesidad de información) y luego mejorar la modelización de usuarios basándose en ejemplos de documentos relevantes. Esto se llama retroalimentación de relevancia, lo cual ha demostrado ser bastante efectivo para mejorar la precisión de recuperación [19, 20]. Desafortunadamente, en aplicaciones del mundo real, los usuarios suelen ser reacios a hacer el esfuerzo adicional de proporcionar ejemplos relevantes para retroalimentación [11]. Por lo tanto, es muy interesante estudiar cómo inferir la necesidad de información de un usuario basándose en cualquier información de retroalimentación implícita, la cual existe naturalmente a través de las interacciones del usuario y no requiere ningún esfuerzo adicional por parte del usuario. De hecho, varios estudios previos han demostrado que el modelado implícito del usuario puede mejorar la precisión de recuperación. En [3], se desarrolla un navegador web (Curious Browser) para registrar las calificaciones explícitas de relevancia de las páginas web por parte de los usuarios (retroalimentación de relevancia) y el comportamiento de navegación al ver una página, como el tiempo de permanencia, clics de ratón, movimiento del ratón y desplazamiento (retroalimentación implícita). Se muestra que el tiempo de permanencia en una página, la cantidad de desplazamiento en una página y la combinación de tiempo y desplazamiento tienen una fuerte correlación con las calificaciones de relevancia explícita, lo que sugiere que la retroalimentación implícita puede ser útil para inferir la necesidad de información del usuario. En [10], se recopilan datos de clics de usuario como datos de entrenamiento para aprender una función de recuperación, que se utiliza para producir un ranking personalizado de resultados de búsqueda que se adapte a las preferencias de un grupo de usuarios. En [25], los datos de clics recopilados durante un largo período de tiempo se utilizan a través de la expansión de consultas para mejorar la precisión de recuperación. Si bien un usuario puede tener intereses y preferencias generales a largo plazo para la información, a menudo está buscando documentos para satisfacer una necesidad de información ad-hoc, que solo dura un corto período de tiempo; una vez que se satisface la necesidad de información, el usuario generalmente ya no estaría interesado en esa información. Por ejemplo, un usuario puede estar buscando información sobre autos usados para comprar uno, pero una vez que el usuario ha comprado un auto, generalmente ya no está interesado en esa información. En tales casos, la información de retroalimentación implícita recopilada durante un largo período de tiempo es poco probable que sea muy útil, pero el contexto de búsqueda inmediato y la información de retroalimentación, como cuáles de los resultados de búsqueda para la necesidad de información actual son vistos, se espera que sean mucho más útiles. Considera la consulta de Java nuevamente. Cualquiera de la siguiente información de retroalimentación inmediata sobre el usuario podría potencialmente ayudar a determinar el significado previsto de Java en la consulta: (1) La consulta anterior enviada por el usuario es hashtable (en lugar de, por ejemplo, viajar a Indonesia). (2) En los resultados de búsqueda, el usuario visualizó una página donde palabras como programación, software y applet ocurren muchas veces. Hasta donde sabemos, cómo aprovechar este contexto de búsqueda inmediato y a corto plazo para mejorar la búsqueda aún no ha sido abordado de manera satisfactoria en trabajos anteriores. En este artículo, estudiamos cómo construir y actualizar un modelo de usuario basado en el contexto de búsqueda inmediato y la información de retroalimentación implícita, y utilizar el modelo para mejorar la precisión de la recuperación ad-hoc. Para beneficiar al máximo al usuario de un sistema de recuperación a través de modelado implícito del usuario, proponemos realizar retroalimentación implícita entusiasta. Es decir, tan pronto como observemos cualquier nueva pieza de evidencia del usuario, actualizaríamos la creencia del sistema sobre la necesidad de información del usuario y responderíamos con resultados de recuperación mejorados basados en el modelo de usuario actualizado. Presentamos un marco de trabajo de teoría de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. En un paradigma de recuperación tradicional, el problema de recuperación consiste en emparejar una consulta con documentos y clasificar los documentos según sus valores de relevancia. Como resultado, el proceso de recuperación es un ciclo independiente simple de consulta y visualización de resultados. En el nuevo paradigma de recuperación propuesto, el contexto de búsqueda de los usuarios juega un papel importante y el modelo de usuario implícito inferido se explota inmediatamente para beneficiar al usuario. El nuevo paradigma de recuperación es, por lo tanto, fundamentalmente diferente del paradigma tradicional y es inherentemente más general. Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos apropiados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para reordenar inmediatamente cualquier documento que aún no haya sido visto por el usuario. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente UCAIR (Recuperación de Información Adaptativa Centrada en el Usuario) sobre un motor de búsqueda popular (Google). Los experimentos sobre búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en comparación con Google. Dado que la información implícita que explotamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional. Por lo tanto, el agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin esfuerzo adicional por parte del usuario. Las secciones restantes están organizadas de la siguiente manera. En la Sección 2, discutimos el trabajo relacionado. En la Sección 3, presentamos un marco de recuperación interactiva basado en teoría de decisiones para modelado implícito de usuarios. En la Sección 4, presentamos el diseño e implementación de un agente de búsqueda web inteligente del lado del cliente (UCAIR) que realiza retroalimentación implícita ansiosa. En la Sección 5, informamos nuestros resultados experimentales utilizando el agente de búsqueda. La sección 6 concluye nuestro trabajo. 2. El modelado implícito del usuario para la búsqueda personalizada ha sido estudiado en trabajos anteriores, pero nuestro trabajo difiere de todos los trabajos anteriores en varios aspectos: (1) Enfatizamos la explotación del contexto de búsqueda inmediato, como la consulta inmediatamente anterior relacionada y los documentos vistos en la misma sesión, mientras que la mayoría de los trabajos anteriores se basan en la recopilación a largo plazo de información de retroalimentación implícita [25]. (2) Realizamos una retroalimentación activa y obtenemos el beneficio del modelado implícito del usuario tan pronto como esté disponible cualquier nueva información de retroalimentación implícita, mientras que el trabajo anterior mayormente explota la retroalimentación implícita a largo plazo [10]. (3) Proponemos un marco de recuperación para integrar el modelado implícito del usuario con el proceso interactivo de recuperación, mientras que el trabajo anterior estudia el modelado implícito del usuario por separado de la recuperación [3] o solo estudia modelos de recuperación específicos para explotar la retroalimentación implícita para mejorar la coincidencia de una consulta con documentos [23, 27, 22]. (4) Desarrollamos y evaluamos un agente de búsqueda web personalizado con estudios de usuario en línea, mientras que la mayoría de los trabajos existentes evalúan algoritmos fuera de línea sin interacciones reales de usuarios. Actualmente algunos motores de búsqueda ofrecen personalización rudimentaria, como la búsqueda web personalizada de Google [6], que permite a los usuarios describir explícitamente sus intereses seleccionando entre temas predefinidos, de modo que los resultados que coinciden con sus intereses se muestren en la parte superior, y la búsqueda de My Yahoo! [16], que brinda a los usuarios la opción de guardar los sitios web que les gustan y bloquear aquellos que no les gustan. Por el contrario, UCAIR personaliza la búsqueda web a través de la modelización implícita del usuario sin necesidad de esfuerzos adicionales por parte del usuario. Además, la personalización de UCAIR se proporciona en el lado del cliente. Hay dos ventajas notables en esto. Primero, el usuario no necesita preocuparse por la infracción de privacidad, que es una gran preocupación para la búsqueda personalizada [26]. En segundo lugar, tanto el cálculo de la personalización como el almacenamiento del perfil del usuario se realizan en el lado del cliente para reducir drásticamente la carga del servidor [9]. Ha habido muchos trabajos estudiando los registros de consultas de usuarios [1] o la dinámica de consultas [13]. UCAIR hace uso directo del historial de consultas de un usuario para beneficiar al mismo usuario de inmediato en la misma sesión de búsqueda. UCAIR primero determina si dos consultas vecinas pertenecen a la misma sesión de información y, de ser así, selecciona términos de la consulta anterior para realizar la expansión de la consulta. Nuestro enfoque de expansión de consultas es similar a la expansión automática de consultas [28, 15, 5], pero en lugar de utilizar retroalimentación pseudo para expandir la consulta, utilizamos la información de retroalimentación implícita de los usuarios para expandir la consulta actual. Estas dos técnicas pueden ser combinadas. 3. OPTIMIZACIÓN EN IR INTERACTIVO En IR interactivo, un usuario interactúa con el sistema de recuperación a través de un diálogo de acción, en el cual el sistema responde a cada acción del usuario con alguna acción del sistema. Por ejemplo, la acción de los usuarios puede ser enviar una consulta y la respuesta del sistema puede ser devolver una lista de 10 resúmenes de documentos. En general, el espacio de acciones del usuario y respuestas del sistema y sus granularidades dependerían de la interfaz de un sistema de recuperación particular. En principio, cada acción del usuario puede potencialmente proporcionar nuevas pruebas para ayudar al sistema a inferir mejor la necesidad de información del usuario. Por lo tanto, para responder de manera óptima, el sistema debería utilizar toda la evidencia recopilada hasta ahora sobre el usuario al elegir una respuesta. Cuando se ven de esta manera, la mayoría de los motores de búsqueda existentes son claramente no óptimos. Por ejemplo, si un usuario ha visto algunos documentos en la primera página de resultados de búsqueda, cuando el usuario hace clic en el enlace Siguiente para obtener más resultados, un sistema de recuperación existente seguiría devolviendo la siguiente página de resultados recuperados en función de la consulta original sin considerar la nueva evidencia de que un resultado en particular ha sido visto por el usuario. Proponemos optimizar el rendimiento de la recuperación adaptando las respuestas del sistema en función de cada acción que un usuario haya tomado, y planteamos el problema de optimización como una tarea de decisión. Específicamente, en cualquier momento, el sistema intentaría realizar dos tareas: (1) Actualización del modelo de usuario: Monitorear cualquier evidencia útil del usuario con respecto a su necesidad de información y actualizar el modelo de usuario tan pronto como esta evidencia esté disponible; (2) Mejorar los resultados de búsqueda: Reclasificar inmediatamente todos los documentos que el usuario aún no ha visto, tan pronto como se actualice el modelo de usuario. Enfatizamos la actualización y reordenamiento entusiastas, lo que hace que nuestro trabajo sea bastante diferente a cualquier trabajo existente. A continuación presentamos un marco formal de teoría de decisiones para optimizar el rendimiento de recuperación a través de la modelización implícita del usuario en la recuperación de información interactiva. 3.1 Un marco de teoría de decisiones Sea A el conjunto de todas las acciones del usuario y R(a) el conjunto de todas las posibles respuestas del sistema a una acción del usuario a ∈ A. En cualquier momento, sea At = (a1, ..., at) la secuencia observada de acciones de usuario hasta ahora (hasta el momento t) y Rt−1 = (r1, ..., rt−1) las respuestas que el sistema ha dado en respuesta a las acciones del usuario. El objetivo del sistema es elegir una respuesta óptima rt ∈ R(at) para la acción actual del usuario at. Sea M el espacio de todos los posibles modelos de usuario. Definimos además una función de pérdida L(a, r, m) ∈ , donde a ∈ A es una acción del usuario, r ∈ R(a) es una respuesta del sistema, y m ∈ M es un modelo de usuario. L(a, r, m) codifica nuestras preferencias de decisión y evalúa la optimalidad de responder con r cuando el modelo de usuario actual es m y la acción de usuario actual es a. Según la teoría de decisión bayesiana, la decisión óptima en el tiempo t es elegir una respuesta que minimice el riesgo de Bayes, es decir, r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) donde P(mt|U, D, At, Rt−1) es la probabilidad posterior del modelo de usuario mt dadas todas las observaciones sobre el usuario U que hemos realizado hasta el tiempo t. Para simplificar el cálculo de la Ecuación 1, asumamos que la masa de probabilidad posterior P(mt|U, D, At, Rt−1) está principalmente concentrada en el modo m∗ t = argmaxmt P(mt|U, D, At, Rt−1). Podemos entonces aproximar la integral con el valor de la función de pérdida en m∗ t. Es decir, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) donde m∗ t = argmaxmt P(mt|U, D, At, Rt−1). Dejando de lado cómo definir y estimar estos modelos probabilísticos y la función de pérdida, podemos ver que tal formulación de la teoría de decisiones sugiere que, para elegir la respuesta óptima a at, el sistema debería realizar dos tareas: (1) calcular el modelo de usuario actual y obtener m∗ t basado en toda la información útil. (2) elegir una respuesta rt para minimizar el valor de la función de pérdida L(at, rt, m∗ t). Cuando at no afecta nuestra creencia sobre m∗ t , el primer paso puede omitirse y podemos reutilizar m∗ t−1 para m∗ t . Ten en cuenta que nuestro marco de trabajo es bastante general, ya que potencialmente podemos modelar cualquier tipo de acciones de usuario y respuestas del sistema. En la mayoría de los casos, como podríamos esperar, la respuesta del sistema es algún tipo de clasificación de documentos, es decir, para la mayoría de las acciones a, R(a) consiste en todas las posibles clasificaciones de los documentos no vistos, y el problema de decisión se reduce a elegir la mejor clasificación de los documentos no vistos basándose en el modelo de usuario más actualizado. Cuando a es la acción de enviar una consulta de palabras clave, tal respuesta es exactamente lo que haría un sistema de recuperación actual. Sin embargo, fácilmente podemos imaginar que un motor de búsqueda web más inteligente respondería al clic del usuario en el enlace Siguiente (para obtener más resultados no vistos) con una clasificación más optimizada de documentos basada en cualquier documento visto en la página actual de resultados. De hecho, según nuestra estrategia de actualización entusiasta, incluso podríamos permitir que un sistema responda al clic del botón Atrás del navegador por parte de un usuario después de ver un documento de la misma manera, para que el usuario pueda beneficiarse al máximo de la retroalimentación implícita. Estos son precisamente lo que nuestro sistema UCAIR hace. 3.2 Modelos de usuario Un modelo de usuario m ∈ M representa lo que sabemos sobre el usuario U, por lo que en principio, puede contener cualquier información sobre el usuario que deseemos modelar. Ahora discutimos dos componentes importantes en un modelo de usuario. El primer componente es un modelo de componente de la necesidad de información de los usuarios. Presumiblemente, el factor más importante que afecta la optimalidad de la respuesta del sistema es qué tan bien la respuesta aborda la necesidad de información de los usuarios. De hecho, en cualquier momento, podemos asumir que el sistema tiene alguna creencia sobre lo que le interesa al usuario, la cual modelamos a través de un vector de términos x = (x1, ..., x|V|), donde V = {w1, ..., w|V|} es el conjunto de todos los términos (es decir, vocabulario) y xi es el peso del término wi. Un vector de términos de este tipo se utiliza comúnmente en la recuperación de información para representar tanto consultas como documentos. Por ejemplo, el modelo de espacio vectorial asume que tanto la consulta como los documentos se representan como vectores de términos y que la puntuación de un documento con respecto a una consulta se calcula en función de la similitud entre el vector de la consulta y el vector del documento [21]. En un enfoque de modelado de lenguaje, también podemos considerar el modelo de lenguaje unigrama de consulta [12, 29] o el modelo de relevancia [14] como una representación vectorial de términos de la necesidad de información de los usuarios. Intuitivamente, x asignaría pesos altos a los términos que caracterizan los temas que interesan al usuario. El segundo componente que podemos incluir en nuestro modelo de usuario son los documentos que el usuario ya ha visto. Obviamente, incluso si un documento es relevante, si el usuario ya ha visto el documento, no sería útil presentar el mismo documento de nuevo. Por lo tanto, introducimos otra variable S ⊂ D (D es el conjunto completo de documentos en la colección) para denotar el subconjunto de documentos en los resultados de búsqueda que el usuario ya ha visto. En general, en el tiempo t, podemos representar un modelo de usuario como mt = (S, x, At, Rt−1), donde S son los documentos vistos, x es la comprensión del sistema de la necesidad de información del usuario, y (At, Rt−1) representa el historial de interacción del usuario. Ten en cuenta que un modelo de usuario aún más general también puede incluir otros factores como el nivel de lectura y la ocupación de los usuarios. Si asumimos que la incertidumbre de un modelo de usuario mt se debe únicamente a la incertidumbre de x, el cálculo de nuestra estimación actual del modelo de usuario m∗ t implicará principalmente calcular nuestra mejor estimación de x. Es decir, el sistema elegiría una respuesta de acuerdo a r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) donde x∗ = argmaxx P(x|U, D, At, Rt−1). Este es el mecanismo de decisión implementado en el sistema UCAIR que se describirá más adelante. En este sistema, evitamos especificar el modelo probabilístico P(x|U, D, At, Rt−1) calculando x∗ directamente con algún método de retroalimentación existente. 3.3 Funciones de pérdida La definición exacta de la función de pérdida L depende de las respuestas, por lo que es inevitablemente específica de la aplicación. Ahora discutimos brevemente algunas posibilidades cuando la respuesta es clasificar todos los documentos no vistos y presentar los mejores k de ellos. Sea r = (d1, ..., dk) los k documentos principales, S el conjunto de documentos vistos por el usuario, y x∗ la mejor suposición del sistema sobre la necesidad de información del usuario. Podemos definir simplemente la pérdida asociada con r como la suma negativa de la probabilidad de que cada uno de los di sea relevante, es decir, L(a, r, m) = − k i=1 P(relevante|di, m). Claramente, para minimizar esta función de pérdida, la respuesta óptima r contendría los k documentos con la probabilidad más alta de relevancia, lo cual es intuitivamente razonable. Una deficiencia de esta función de pérdida top-k es que no es sensible al orden interno de los documentos top k seleccionados, por lo que cambiar el orden de clasificación de un documento no relevante y uno relevante no afectaría la pérdida, lo cual es irrazonable. Para modelar el ranking, podemos introducir un factor del modelo de usuario: la probabilidad de que cada uno de los k documentos sea visto por el usuario, P(vista|di), y definir la siguiente función de pérdida de ranking: L(a, r, m) = − k i=1 P(vista|di)P(relevante|di, m). Dado que, en general, si di está clasificado por encima de dj (es decir, i < j), P(vista|di) > P(vista|dj), esta función de pérdida favorecería una decisión de clasificar documentos relevantes por encima de los no relevantes, ya que de lo contrario, siempre podríamos intercambiar di con dj para reducir el valor de pérdida. Por lo tanto, el sistema simplemente debería realizar una recuperación regular y clasificar los documentos según la probabilidad de relevancia [18]. Dependiendo de las preferencias de recuperación de los usuarios, puede haber muchas otras posibilidades. Por ejemplo, si el usuario no desea ver documentos redundantes, la función de pérdida debería incluir alguna medida de redundancia en r basada en los documentos ya vistos S. Por supuesto, cuando la respuesta no es elegir una lista clasificada de documentos, necesitaríamos una función de pérdida diferente. Discutimos un ejemplo relevante para el agente de búsqueda que implementamos. Cuando un usuario ingresa una consulta qt (acción actual), nuestro agente de búsqueda se basa en algún motor de búsqueda existente para llevar a cabo la búsqueda en realidad. En tal caso, aunque el agente de búsqueda no tenga control sobre el algoritmo de recuperación, aún puede intentar optimizar los resultados de la búsqueda refinando la consulta enviada al motor de búsqueda y/o reordenando los resultados obtenidos del motor de búsqueda. Las funciones de pérdida para el reordenamiento ya fueron discutidas anteriormente; ahora echamos un vistazo a las funciones de pérdida para el <br>refinamiento de consultas</br>. Sea f la función de recuperación del motor de búsqueda que nuestro agente utiliza, de modo que f(q) nos daría los resultados de búsqueda utilizando la consulta q. Dado que la acción actual del usuario es ingresar una consulta qt (es decir, at = qt), nuestra respuesta sería f(q) para algún q. Dado que no tenemos elección de f, nuestra decisión es elegir un buen q. Formalmente, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) lo cual muestra que nuestro objetivo es encontrar q∗ = argminqL(qt, f(q), m), es decir, una consulta óptima que nos daría el mejor f(q). Una elección diferente de la función de pérdida L(qt, f(q), m) llevaría a una estrategia de <br>refinamiento de consulta</br> diferente. En UCAIR, calculamos heurísticamente q∗ expandiendo qt con términos extraídos de rt−1 siempre que qt−1 y qt tengan una alta similitud. Se debe tener en cuenta que rt−1 y qt−1 están contenidos en m como parte del historial de interacción de los usuarios. 3.4 Modelado implícito del usuario El modelado implícito del usuario se captura en nuestro marco a través del cálculo de x∗ = argmaxx P(x|U, D, At, Rt−1), es decir, la creencia actual del sistema sobre cuál es la necesidad de información del usuario. Aquí nuevamente puede haber muchas posibilidades, lo que lleva a diferentes algoritmos para la modelización implícita del usuario. Ahora discutimos algunos de ellos. Primero, cuando dos consultas consecutivas están relacionadas, la consulta anterior puede ser explotada para enriquecer la consulta actual y proporcionar más contexto de búsqueda para ayudar en la desambiguación. Para este propósito, en lugar de realizar una expansión de consulta como lo hicimos en la sección anterior, también podríamos calcular un x∗ actualizado basado en la consulta anterior y los resultados de recuperación. El modelo de usuario nuevo calculado puede luego ser utilizado para clasificar los documentos con un modelo estándar de recuperación de información. Segundo, también podemos inferir los intereses de un usuario basándonos en los resúmenes de los documentos visualizados. Cuando a un usuario se le presenta una lista de resúmenes de documentos mejor clasificados, si el usuario elige saltarse los primeros n documentos y ver el documento (n+1)-ésimo, podemos inferir que el usuario no está interesado en los resúmenes mostrados para los primeros n documentos, pero está atraído por el resumen mostrado del documento (n+1)-ésimo. Por lo tanto, podemos usar estos resúmenes como ejemplos negativos y positivos para aprender un modelo de usuario más preciso x∗. Aquí se pueden explotar muchas técnicas estándar de retroalimentación de relevancia [19, 20]. Ten en cuenta que debemos utilizar los resúmenes mostrados, en lugar de los contenidos reales de esos documentos, ya que es posible que el resumen mostrado del documento visto sea relevante, pero el contenido del documento en realidad no lo sea. Del mismo modo, un resumen mostrado puede llevar a un usuario a omitir un documento relevante. Inferir modelos de usuario basados en dicha información mostrada, en lugar del contenido real de un documento, es una diferencia importante entre UCAIR y algunos otros sistemas similares. En UCAIR, ambas estrategias para inferir un modelo de usuario implícito están implementadas. 4. UCAIR: Un agente de búsqueda personalizado 4.1 Diseño En esta sección, presentamos un agente de búsqueda web del lado del cliente llamado UCAIR, en el cual implementamos algunos de los métodos discutidos en la sección anterior para realizar búsquedas personalizadas a través de modelado implícito del usuario. UCAIR es un complemento del navegador web que actúa como proxy para los motores de búsqueda en la web. Actualmente, solo está implementado para Internet Explorer y Google, pero es cuestión de ingeniería hacer que funcione en otros navegadores web e interactúe con otros motores de búsqueda. El tema de la privacidad es un obstáculo principal para implementar cualquier aplicación del mundo real que involucre modelado de usuarios serio, como la búsqueda personalizada. Por esta razón, UCAIR funciona estrictamente como un agente de búsqueda del lado del cliente, en lugar de ser una aplicación del lado del servidor. De esta manera, la información del usuario capturada siempre permanece en la computadora que está utilizando el usuario, por lo tanto, el usuario no necesita revelar ninguna información al exterior. La personalización del lado del cliente también permite que el sistema observe fácilmente una gran cantidad de información del usuario que puede no estar fácilmente disponible para un servidor. Además, realizar búsquedas personalizadas en el lado del cliente es más escalable que en el lado del servidor, ya que la sobrecarga de cálculo y almacenamiento se distribuye entre los clientes. Como se muestra en la Figura 1, la barra de herramientas UCAIR tiene 3 componentes principales: (1) El módulo de modelado de usuario (implícito) captura el contexto de búsqueda de un usuario e información de historial, incluidas las consultas enviadas y los resultados de búsqueda clicados, e infiere los límites de la sesión de búsqueda. (2) El módulo de modificación de consultas mejora selectivamente la formulación de la consulta de acuerdo con el modelo de usuario actual. (3) El módulo de reordenamiento de resultados reordena inmediatamente cualquier resultado de búsqueda no visto cada vez que se actualiza el modelo de usuario. En UCAIR, consideramos cuatro acciones básicas de usuario: (1) enviar una consulta de palabras clave; (2) ver un documento; (3) hacer clic en el botón Atrás; (4) hacer clic en el enlace Siguiente en una página de resultados. Para cada una de estas cuatro acciones, el sistema responde con, respectivamente, (1) 1 UCAIR está disponible en: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Registro de Historial de Búsqueda del Motor de Búsqueda (por ejemplo, Google) (consultas pasadas, resultados clicados) Modificación de Consulta Resultado de Reclasificación Modelo de Usuario Buffer de Resultados de Consulta de Usuario UCAIR... Figura 1: arquitectura de UCAIR generando una lista clasificada de resultados enviando una consulta posiblemente ampliada a un motor de búsqueda; (2) actualizando el modelo de necesidad de información x; (3) reordenando los resultados no vistos en la página de resultados actual basándose en el modelo actual x; y (4) reordenando las páginas no vistas y generando la siguiente página de resultados basándose en el modelo actual x. Detrás de estas respuestas, hay tres tareas básicas: (1) Decidir si la consulta anterior está relacionada con la consulta actual y, de ser así, ampliar la consulta actual con términos útiles de la consulta anterior o los resultados de la consulta anterior. (2) Actualizar el modelo de necesidad de información x basado en un resumen de documento recién seleccionado. (3) Reordenar un conjunto de documentos no vistos basado en el modelo x actual. A continuación describimos nuestros algoritmos para cada uno de ellos. 4.2 Detección de límites de sesión y expansión de consultas Para explotar eficazmente las consultas anteriores y su información correspondiente de clics, UCAIR necesita determinar si dos consultas adyacentes pertenecen a la misma sesión de búsqueda (es decir, detectar los límites de sesión). El trabajo existente sobre la detección de límites de sesión se encuentra principalmente en el contexto del análisis de registros web (por ejemplo, [8]), y utiliza información estadística en lugar de características textuales. Dado que nuestro agente del lado del cliente no tiene acceso a los registros de consultas del servidor, tomamos decisiones sobre los límites de sesión basadas en la similitud textual entre dos consultas. Debido a que las consultas relacionadas no necesariamente comparten las mismas palabras (por ejemplo, isla de Java y viajar a Indonesia), no es suficiente utilizar solo el texto de la consulta. Por lo tanto, utilizamos los resultados de búsqueda de las dos consultas para ayudar a decidir si están relacionadas temáticamente. Por ejemplo, para las consultas anteriores \"java island\" y \"travel Indonesia\", las palabras \"java\", \"bali\", \"island\", \"indonesia\" y \"travel\" pueden aparecer con frecuencia en los resultados de búsqueda de ambas consultas, lo que produce un alto puntaje de similitud. Solo utilizamos los títulos y resúmenes de los resultados de búsqueda para calcular la similitud, ya que están disponibles en la página de resultados de búsqueda recuperada y obtener el texto completo de cada página de resultados ralentizaría significativamente el proceso. Para compensar la concisión de los títulos y resúmenes, recuperamos más resultados de los que un usuario normalmente vería con el propósito de detectar los límites de sesión (típicamente 50 resultados). La similitud entre la consulta anterior q y la consulta actual q se calcula de la siguiente manera. Sean {s1, s2, . . . , sn} y {s1, s2, . . . , sn} los conjuntos de resultados de las dos consultas. Utilizamos la fórmula de ponderación TF-IDF normalizada pivotada [24] para calcular un vector de peso de término si para cada resultado si. Definimos el resultado promedio savg como el centroide de todos los vectores de resultado, es decir, (s1 + s2 + . . . + sn)/n. La similitud del coseno entre los dos resultados promedio se calcula como s avg · savg/ s 2 avg · s2 avg. Si el valor de similitud supera un umbral predefinido, se considerará que las dos consultas están en la misma sesión de información. Si se determina que la consulta anterior y la consulta actual pertenecen a la misma sesión de búsqueda, UCAIR intentaría expandir la consulta actual con términos de la consulta anterior y sus resultados de búsqueda. Específicamente, para cada término en la consulta anterior o los resultados de búsqueda correspondientes, si su frecuencia en los resultados de la consulta actual es mayor que un umbral preestablecido (por ejemplo, 5 resultados de 50), el término se agregaría a la consulta actual para formar una consulta ampliada. En este caso, UCAIR enviaría esta consulta ampliada en lugar de la original al motor de búsqueda y devolvería los resultados correspondientes a la consulta ampliada. Actualmente, UCAIR solo utiliza la consulta inmediatamente anterior para la expansión de consultas; en principio, podríamos aprovechar todas las consultas pasadas relacionadas. 4.3 Actualización del modelo de necesidad de información Supongamos que en el tiempo t, hemos observado que el usuario ha visto k documentos cuyos resúmenes son s1, ..., sk. Actualizamos nuestro modelo de usuario calculando un nuevo vector de necesidad de información con un método estándar de retroalimentación en la recuperación de información (es decir, Rocchio [19]). Según el modelo de recuperación de espacio vectorial, cada resumen clicado si puede ser representado por un vector de pesos de términos si, con cada término ponderado por una fórmula de ponderación TF-IDF [21]. Rocchio calcula el vector centroide de todos los resúmenes e interpola este con el vector de consulta original para obtener un vector de términos actualizado. Es decir, x = αq + (1 − α) 1 k k i=1 si donde q es el vector de consulta, k es el número de resúmenes que el usuario hace clic inmediatamente después de la consulta actual y α es un parámetro que controla la influencia de los resúmenes clicados en el modelo de necesidad de información inferida. En nuestros experimentos, α se establece en 0.5. Ten en cuenta que actualizamos el modelo de información necesario cada vez que el usuario ve un documento. 4.4 Reclasificación de resultados En general, queremos volver a clasificar todos los resultados no vistos tan pronto como se actualice el modelo de usuario. Actualmente, UCAIR implementa el reordenamiento en dos casos, correspondientes a cuando el usuario hace clic en el botón Atrás y en el enlace Siguiente en Internet Explorer. En ambos casos, el modelo de usuario actualizado se utilizaría para reordenar los resultados no vistos de manera que el usuario vea resultados de búsqueda mejorados de inmediato. Para volver a clasificar cualquier resumen de documento no visto, UCAIR utiliza el modelo estándar de recuperación de espacio vectorial y puntúa cada resumen en función de la similitud del resultado y el vector de necesidad de información actual del usuario x [21]. Dado que la retroalimentación implícita no es completamente confiable, presentamos solo un pequeño número (por ejemplo, 5) de los resultados reordenados más altos para ser seguidos por cualquier resultado originalmente clasificado alto. 828 resultados de Google (consulta del usuario = mapa de Java) Resultados de UCAIR (consulta del usuario = mapa de Java) consulta anterior = viajar a Indonesia consulta anterior = tabla hash consulta del usuario ampliada = mapa de Java Indonesia consulta del usuario ampliada = clase de mapa de Java 1 Proyecciones de mapas de Java del mundo ... Lonely Planet - Mapa de Indonesia Mapa (Plataforma Java SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Proyecciones de mapas de Java del mundo ... TURISMO DE INDONESIA: JAVA CENTRAL - MAPA Plataforma Java SE v1.3.1: Interfaz de Mapa www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Mapa de Java TURISMO DE INDONESIA: JAVA OESTE - MAPA Una introducción a las clases de colección de mapas de Java java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Mapa de Tecnología Java IndoStreets - Mapa de Java Una introducción a las clases de colección de mapas de Java java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Regiones e islas de Indonesia Mapas, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 Una introducción a las clases de colección de mapas de Java Mapa de calles de la ciudad de Indonesia,... Hibernate simplifica el mapeo de herencia www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Mapa de Java Mapas de Indonesia jerarquía de clases de tmap 30.map www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Mapa de API de Java Mapas de Indonesia por Peter Loud Alcance de clases www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas: Mapas de Sam de Indonesia por Peter Loud PrintSafeHashMap de la clase www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 TURISMO DE INDONESIA: JAVA OESTE - MAPA indonesiaphoto.com Java Pro - Unión y mapeo vertical de clases www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Tabla 1: Resultados de muestra de la expansión de la consulta EVALUACIÓN DE UCAIR Ahora presentamos algunos resultados sobre la evaluación de las dos principales funciones de UCAIR: la expansión selectiva de consultas y la reordenación de resultados basada en los datos de clics de los usuarios. 5.1 Resultados de muestra La estrategia de expansión de consultas implementada en UCAIR es intencionalmente conservadora para evitar la interpretación errónea de los modelos implícitos de los usuarios. En la práctica, cada vez que decide expandir la consulta, la expansión suele tener sentido. En la Tabla 1, mostramos cómo UCAIR puede distinguir exitosamente dos contextos de búsqueda diferentes para la consulta java map, correspondientes a dos consultas previas distintas (es decir, viajar a Indonesia vs. hashtable). Debido a la modelización implícita del usuario, UCAIR descubre inteligentemente agregar Indonesia y clase, respectivamente, a la consulta de los usuarios sobre el mapa de Java, lo cual de otro modo sería ambiguo, como se muestra en los resultados originales de Google el 21 de marzo de 2005. Los resultados de UCAIR son mucho más precisos que los resultados de Google y reflejan la personalización en la búsqueda. El componente de retroalimentación implícita entusiasta está diseñado para responder inmediatamente a la actividad de un usuario, como por ejemplo, al visualizar un documento. En la Figura 2, mostramos cómo UCAIR puede desambiguar con éxito una consulta ambigua de jaguar al explotar un resumen del documento visualizado. En este caso, los resultados iniciales de recuperación utilizando \"jaguar\" (mostrados en el lado izquierdo) contienen dos resultados sobre los autos Jaguar seguidos por dos resultados sobre el software Jaguar. Sin embargo, después de que el usuario ve el contenido de la página web del segundo resultado (sobre el automóvil Jaguar) y regresa a la página de resultados de búsqueda haciendo clic en el botón Atrás, UCAIR automáticamente selecciona dos nuevos resultados de búsqueda sobre automóviles Jaguar (mostrados en el lado derecho), mientras que los dos resultados originales sobre software de Jaguar se desplazan hacia abajo en la lista (no se ven en la imagen). 5.2 Evaluación cuantitativa Para evaluar UCAIR de manera cuantitativa, realizamos un estudio de usuario sobre la efectividad del componente de retroalimentación implícita ansiosa. Es un desafío evaluar cuantitativamente la mejora potencial en el rendimiento de nuestro modelo propuesto y UCAIR sobre Google de manera imparcial [7]. Aquí diseñamos un estudio de usuarios, en el cual los participantes realizarían una búsqueda web normal y evaluarían al azar y de forma anónima un conjunto de resultados mezclados de Google y UCAIR al final de la sesión de búsqueda; los participantes no saben si un resultado proviene de Google o de UCAIR. Reclutamos a 6 estudiantes de posgrado para este estudio de usuarios, quienes tienen diferentes antecedentes (3 en informática, 2 en biología y 1 en química). Los documentos que describen leyes para limitar el correo no deseado sin dar detalles de demandas judiciales o juicios penales no son relevantes. Utilizamos los temas de consulta de la pista Terabyte TREC 2 2004 [2] y la tarea de destilación de temas de la pista web TREC 2003 [4] de la manera que se describirá a continuación. Un ejemplo de tema del TREC 2004 Terabyte track aparece en la Figura 3. El título es una frase corta y puede ser utilizada como una consulta al sistema de recuperación. El campo de descripción proporciona una declaración ligeramente más larga del requisito del tema, generalmente expresado como una sola oración completa o pregunta. Finalmente, la narrativa proporciona información adicional necesaria para especificar completamente el requisito, expresado en forma de un breve párrafo. Inicialmente, cada participante exploraría 50 temas ya sea de la categoría Terabyte o de la categoría Web y elegiría los 5 o 7 temas más interesantes. Para cada tema seleccionado, el participante básicamente realizaría la búsqueda web normal utilizando UCAIR para encontrar muchas páginas web relevantes utilizando el título del tema de la consulta como la palabra clave inicial de la consulta. Durante este proceso, el participante puede ver los resultados de la búsqueda y posiblemente hacer clic en algunos interesantes para ver las páginas web, tal como en una búsqueda web normal. No hay ningún requisito o restricción sobre cuántas consultas debe enviar el participante o cuándo debe detener la búsqueda de un tema. Cuando el participante planea cambiar el tema de búsqueda, simplemente presionará un botón 2 de la Conferencia de Recuperación de Texto: http://trec.nist.gov/ 829 Figura 2: Capturas de pantalla para volver a clasificar los resultados y evaluar los resultados de búsqueda antes de cambiar al siguiente tema. En el momento de la evaluación, los 30 resultados mejor clasificados de Google y UCAIR (algunos se superponen) se mezclan aleatoriamente para que el participante no sepa si un resultado proviene de Google o de UCAIR. El participante luego juzgaría la relevancia de estos resultados. Medimos la precisión en los primeros n (n = 5, 10, 20, 30) documentos de Google y UCAIR. También evaluamos precisiones en diferentes niveles de recuperación. En total, 368 documentos fueron considerados relevantes a partir de los resultados de búsqueda de Google y 429 documentos fueron considerados relevantes por los participantes de UCAIR. Los diagramas de dispersión de precisión en los 10 y 20 documentos principales se muestran en la Figura 4 y la Figura 5 respectivamente (El diagrama de dispersión de precisión en los 30 documentos principales es muy similar al de los 20 documentos principales). Cada punto de los gráficos de dispersión representa las precisiones de Google y UCAIR en un tema de consulta. La Tabla 2 muestra la precisión promedio en los primeros n documentos entre 32 temas. A partir de la Figura 4, la Figura 5 y la Tabla 2, vemos que los resultados de búsqueda de UCAIR son consistentemente mejores que los de Google en todas las medidas. Además, la mejora en el rendimiento es más dramática para la precisión en los primeros 20 documentos que para la precisión en los primeros 10 documentos. Una explicación para esto es que cuanto más interacción tenga el usuario con el sistema, más datos de clics se espera que UCAIR pueda recopilar. Por lo tanto, el sistema de recuperación puede construir modelos de usuario implícitos más precisos, lo que conduce a una mayor precisión en la recuperación. El Método de Clasificación prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Mejora 8.0% 17.8% 20.2% 21.8% Tabla 2: Tabla de precisión promedio en los primeros n documentos para 32 temas de consulta El gráfico en la Figura 6 muestra las curvas de precisión-recuperación para UCAIR y Google, donde se observa claramente que el rendimiento de UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Gráfico de dispersión de Precisión en los 10 primeros documentos Figura 4: La precisión en los 10 primeros documentos de UCAIR y Google es consistentemente y considerablemente mejor que la de Google en todos los niveles de recuperación. 6. CONCLUSIONES En este artículo, estudiamos cómo aprovechar la modelización implícita del usuario para personalizar de manera inteligente la recuperación de información y mejorar la precisión de la búsqueda. A diferencia de la mayoría de trabajos anteriores, enfatizamos el uso del contexto de búsqueda inmediata y la información de retroalimentación implícita, así como la actualización rápida de los resultados de búsqueda para beneficiar al máximo a un usuario. Presentamos un marco de trabajo de toma de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos adecuados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para volver a clasificar inmediatamente cualquier documento que aún no haya sido visto por el usuario. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente (UCAIR) sobre un motor de búsqueda popular (Google). Los experimentos en la búsqueda web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en más de un 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Gráfico de dispersión de Precisión en los 20 documentos principales Figura 5: Precisión en los 20 documentos principales de UCAIR y Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 precisión recall Curvas de Precisión-Recall Resultado de Google Resultado de UCAIR Figura 6: Precisión en los 20 resultados principales de UCAIR y Google Google. Dado que la información implícita que aprovechamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional. El agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin necesidad de esfuerzo adicional por parte del usuario. AGRADECIMIENTO Agradecemos a los seis participantes de nuestros experimentos de evaluación. Este trabajo fue apoyado en parte por las subvenciones de la Fundación Nacional de Ciencias IIS-0347933 e IIS-0428472. REFERENCIAS [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman y O. Frieder. Análisis por hora de un registro de consultas web muy grande categorizado por tema. En Actas de SIGIR 2004, páginas 321-328, 2004. [2] C. Clarke, N. Craswell e I. Soboroff. Resumen de la pista de terabyte TREC 2004. En Actas de TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda y D. Brown. Indicadores implícitos de interés. En Actas de Interfaces de Usuario Inteligentes 2001, páginas 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson y M. Wu. Resumen de la pista web TREC 2003. En Actas de TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend y V. Larvrenko. Retroalimentación de relevancia y personalización: Una perspectiva de modelado del lenguaje. En Actas del Segundo Taller DELOS: Personalización y Sistemas de Recomendación en Bibliotecas Digitales, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite y D. Harman. Resultados y desafíos en la evaluación de búsqueda en la web. Redes de Computadoras, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A. An, y D. Schuurmans. Identificación dinámica de sesiones de registro web con modelos de lenguaje estadístico. Revista de la Sociedad Americana de Ciencia de la Información y Tecnología, 55(14):1290-1303, 2004. [9] G. Jeh y J. Widom. Escalando la búsqueda web personalizada. En Actas de WWW 2003, páginas 271-279, 2003. [10] T. Joachims. Optimización de motores de búsqueda utilizando datos de clics. En Actas de SIGKDD 2002, páginas 133-142, 2002. [11] D. Kelly y J. Teevan. Retroalimentación implícita para inferir preferencias de usuario: Una bibliografía. SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En Actas de SIGIR01, páginas 111-119, 2001. [13] T. Lau y E. Horvitz. Patrones de búsqueda: Análisis y modelado de la <br>refinación de consultas</br> web. En Actas de la Séptima Conferencia Internacional sobre Modelado de Usuarios (UM), páginas 145-152, 1999. [14] V. Lavrenko y B. Croft. Modelos de lenguaje basados en relevancia. En Actas de SIGIR01, páginas 120-127, 2001. [15] M. Mitra, A. Singhal y C. Buckley. Mejorando la expansión automática de consultas. En Actas de SIGIR 1998, páginas 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg. Según Google, así va la nación. New York Times, mayo de 2003. [18] S. E. Robertson. El principio de clasificación de probabilidad en ı˚. Revista de Documentación, 33(4):294-304, 1977. [19] J. J. Rocchio. Retroalimentación de relevancia en la recuperación de información. En el Sistema de Recuperación SMART: Experimentos en el Procesamiento Automático de Documentos, páginas 313-323. Prentice-Hall Inc., 1971. [20] G. Salton y C. Buckley. Mejorando el rendimiento de recuperación mediante retroalimentación de recuperación. Revista de la Sociedad Americana de Ciencia de la Información, 41(4):288-297, 1990. [21] G. Salton y M. J. McGill. Introducción a la Recuperación de Información Moderna. McGraw-Hill, 1983. [22] X. Shen, B. Tan y C. Zhai. Recuperación de información sensible al contexto utilizando retroalimentación implícita. En Actas de SIGIR 2005, páginas 43-50, 2005. [23] X. Shen y C. Zhai. Explotando el historial de consultas para la clasificación de documentos en la recuperación de información interactiva (Póster). En Actas de SIGIR 2003, páginas 377-378, 2003. [24] A. Singhal. Recuperación de información moderna: Una breve visión general. Boletín del Comité Técnico de Ingeniería de Datos de la Sociedad de Computación de IEEE, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano y M. Yoshikawa. Búsqueda web adaptativa basada en el perfil del usuario construido sin ningún esfuerzo por parte de los usuarios. En Actas de WWW 2004, páginas 675-684, 2004. [26] E. Volokh. Personalización y privacidad. Comunicaciones de la ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen e I. Ruthven. Un estudio simulado de modelos de retroalimentación implícita. En Actas de ECIR 2004, páginas 311-326, 2004. [28] J. Xu y W. B. Croft. Expansión de consultas utilizando análisis local y global de documentos. En Actas de SIGIR 1996, páginas 4-11, 1996. [29] C. Zhai y J. Lafferty. Modelo de retroalimentación basado en el modelo de recuperación de divergencia de KL. En Actas de la CIKM 2001, páginas 403-410, 2001. 831 ",
            "candidates": [],
            "error": [
                [
                    "refinamiento de consultas",
                    "refinamiento de consulta",
                    "refinación de consultas"
                ]
            ]
        },
        "implicit user modeling": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "<br>implicit user modeling</br> for Personalized Search Xuehua Shen, Bin Tan, ChengXiang Zhai Department of Computer Science University of Illinois at Urbana-Champaign ABSTRACT Information retrieval systems (e.g., web search engines) are critical for overcoming information overload.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users, resulting in inherently non-optimal retrieval performance.",
                "For example, a tourist and a programmer may use the same word java to search for different information, but the current search systems would return the same results.",
                "In this paper, we study how to infer a users interest from the users search context and use the inferred implicit user model for personalized search .",
                "We present a decision theoretic framework and develop techniques for <br>implicit user modeling</br> in information retrieval.",
                "We develop an intelligent client-side web search agent (UCAIR) that can perform eager implicit feedback, e.g., query expansion based on previous queries and immediate result reranking based on clickthrough information.",
                "Experiments on web search show that our search agent can improve search accuracy over the popular Google search engine.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models, Relevance feedback, Search Process General Terms Algorithms 1.",
                "INTRODUCTION Although many information retrieval systems (e.g., web search engines and digital library systems) have been successfully deployed, the current retrieval systems are far from optimal.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users [17].",
                "This inherent non-optimality is seen clearly in the following two cases: (1) Different users may use exactly the same query (e.g., Java) to search for different information (e.g., the Java island in Indonesia or the Java programming language), but existing IR systems return the same results for these users.",
                "Without considering the actual user, it is impossible to know which sense Java refers to in a query. (2) A users information needs may change over time.",
                "The same user may use Java sometimes to mean the Java island in Indonesia and some other times to mean the programming language.",
                "Without recognizing the search context, it would be again impossible to recognize the correct sense.",
                "In order to optimize retrieval accuracy, we clearly need to model the user appropriately and personalize search according to each individual user.",
                "The major goal of user modeling for information retrieval is to accurately model a users information need, which is, unfortunately, a very difficult task.",
                "Indeed, it is even hard for a user to precisely describe what his/her information need is.",
                "What information is available for a system to infer a users information need?",
                "Obviously, the users query provides the most direct evidence.",
                "Indeed, most existing retrieval systems rely solely on the query to model a users information need.",
                "However, since a query is often extremely short, the user model constructed based on a keyword query is inevitably impoverished .",
                "An effective way to improve user modeling in information retrieval is to ask the user to explicitly specify which documents are relevant (i.e., useful for satisfying his/her information need), and then to improve user modeling based on such examples of relevant documents.",
                "This is called relevance feedback, which has been proved to be quite effective for improving retrieval accuracy [19, 20].",
                "Unfortunately, in real world applications, users are usually reluctant to make the extra effort to provide relevant examples for feedback [11].",
                "It is thus very interesting to study how to infer a users information need based on any implicit feedback information, which naturally exists through user interactions and thus does not require any extra user effort.",
                "Indeed, several previous studies have shown that <br>implicit user modeling</br> can improve retrieval accuracy.",
                "In [3], a web browser (Curious Browser) is developed to record a users explicit relevance ratings of web pages (relevance feedback) and browsing behavior when viewing a page, such as dwelling time, mouse click, mouse movement and scrolling (implicit feedback).",
                "It is shown that the dwelling time on a page, amount of scrolling on a page and the combination of time and scrolling have a strong correlation with explicit relevance ratings, which suggests that implicit feedback may be helpful for inferring user information need.",
                "In [10], user clickthrough data is collected as training data to learn a retrieval function, which is used to produce a customized ranking of search results that suits a group of users preferences.",
                "In [25], the clickthrough data collected over a long time period is exploited through query expansion to improve retrieval accuracy. 824 While a user may have general long term interests and preferences for information, often he/she is searching for documents to satisfy an ad-hoc information need, which only lasts for a short period of time; once the information need is satisfied, the user would generally no longer be interested in such information.",
                "For example, a user may be looking for information about used cars in order to buy one, but once the user has bought a car, he/she is generally no longer interested in such information.",
                "In such cases, implicit feedback information collected over a long period of time is unlikely to be very useful, but the immediate search context and feedback information, such as which of the search results for the current information need are viewed, can be expected to be much more useful.",
                "Consider the query Java again.",
                "Any of the following immediate feedback information about the user could potentially help determine the intended meaning of Java in the query: (1) The previous query submitted by the user is hashtable (as opposed to, e.g., travel Indonesia). (2) In the search results, the user viewed a page where words such as programming, software, and applet occur many times.",
                "To the best of our knowledge, how to exploit such immediate and short-term search context to improve search has so far not been well addressed in the previous work.",
                "In this paper, we study how to construct and update a user model based on the immediate search context and implicit feedback information and use the model to improve the accuracy of ad-hoc retrieval.",
                "In order to maximally benefit the user of a retrieval system through <br>implicit user modeling</br>, we propose to perform eager implicit feedback.",
                "That is, as soon as we observe any new piece of evidence from the user, we would update the systems belief about the users information need and respond with improved retrieval results based on the updated user model.",
                "We present a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "In a traditional retrieval paradigm, the retrieval problem is to match a query with documents and rank documents according to their relevance values.",
                "As a result, the retrieval process is a simple independent cycle of query and result display.",
                "In the proposed new retrieval paradigm, the users search context plays an important role and the inferred implicit user model is exploited immediately to benefit the user.",
                "The new retrieval paradigm is thus fundamentally different from the traditional paradigm, and is inherently more general.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent UCAIR (User-Centered Adaptive Information Retrieval) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "Thus the developed search agent can improve existing web search performance without additional effort from the user.",
                "The remaining sections are organized as follows.",
                "In Section 2, we discuss the related work.",
                "In Section 3, we present a decisiontheoretic interactive retrieval framework for <br>implicit user modeling</br>.",
                "In Section 4, we present the design and implementation of an intelligent client-side web search agent (UCAIR) that performs eager implicit feedback.",
                "In Section 5, we report our experiment results using the search agent.",
                "Section 6 concludes our work. 2.",
                "RELATED WORK <br>implicit user modeling</br> for personalized search has been studied in previous work, but our work differs from all previous work in several aspects: (1) We emphasize the exploitation of immediate search context such as the related immediately preceding query and the viewed documents in the same session, while most previous work relies on long-term collection of implicit feedback information [25]. (2) We perform eager feedback and bring the benefit of <br>implicit user modeling</br> as soon as any new implicit feedback information is available, while the previous work mostly exploits longterm implicit feedback [10]. (3) We propose a retrieval framework to integrate implicit user modeling with the interactive retrieval process, while the previous work either studies implicit user modeling separately from retrieval [3] or only studies specific retrieval models for exploiting implicit feedback to better match a query with documents [23, 27, 22]. (4) We develop and evaluate a personalized Web search agent with online user studies, while most existing work evaluates algorithms offline without real user interactions.",
                "Currently some search engines provide rudimentary personalization, such as Google Personalized web search [6], which allows users to explicitly describe their interests by selecting from predefined topics, so that those results that match their interests are brought to the top, and My Yahoo! search [16], which gives users the option to save web sites they like and block those they dislike.",
                "In contrast, UCAIR personalizes web search through <br>implicit user modeling</br> without any additional user efforts.",
                "Furthermore, the personalization of UCAIR is provided on the client side.",
                "There are two remarkable advantages on this.",
                "First, the user does not need to worry about the privacy infringement, which is a big concern for personalized search [26].",
                "Second, both the computation of personalization and the storage of the user profile are done at the client side so that the server load is reduced dramatically [9].",
                "There have been many works studying user query logs [1] or query dynamics [13].",
                "UCAIR makes direct use of a users query history to benefit the same user immediately in the same search session.",
                "UCAIR first judges whether two neighboring queries belong to the same information session and if so, it selects terms from the previous query to perform query expansion.",
                "Our query expansion approach is similar to automatic query expansion [28, 15, 5], but instead of using pseudo feedback to expand the query, we use users implicit feedback information to expand the current query.",
                "These two techniques may be combined. 3.",
                "OPTIMIZATION IN INTERACTIVE IR In interactive IR, a user interacts with the retrieval system through an action dialogue, in which the system responds to each user action with some system action.",
                "For example, the users action may be submitting a query and the systems response may be returning a list of 10 document summaries.",
                "In general, the space of user actions and system responses and their granularities would depend on the interface of a particular retrieval system.",
                "In principle, every action of the user can potentially provide new evidence to help the system better infer the users information need.",
                "Thus in order to respond optimally, the system should use all the evidence collected so far about the user when choosing a response.",
                "When viewed in this way, most existing search engines are clearly non-optimal.",
                "For example, if a user has viewed some documents on the first page of search results, when the user clicks on the Next link to fetch more results, an existing retrieval system would still return the next page of results retrieved based on the original query without considering the new evidence that a particular result has been viewed by the user. 825 We propose to optimize retrieval performance by adapting system responses based on every action that a user has taken, and cast the optimization problem as a decision task.",
                "Specifically, at any time, the system would attempt to do two tasks: (1) User model updating: Monitor any useful evidence from the user regarding his/her information need and update the user model as soon as such evidence is available; (2) Improving search results: Rerank immediately all the documents that the user has not yet seen, as soon as the user model is updated.",
                "We emphasize eager updating and reranking, which makes our work quite different from any existing work.",
                "Below we present a formal decision theoretic framework for optimizing retrieval performance through <br>implicit user modeling</br> in interactive information retrieval. 3.1 A decision-theoretic framework Let A be the set of all user actions and R(a) be the set of all possible system responses to a user action a ∈ A.",
                "At any time, let At = (a1, ..., at) be the observed sequence of user actions so far (up to time point t) and Rt−1 = (r1, ..., rt−1) be the responses that the system has made responding to the user actions.",
                "The systems goal is to choose an optimal response rt ∈ R(at) for the current user action at.",
                "Let M be the space of all possible user models.",
                "We further define a loss function L(a, r, m) ∈ , where a ∈ A is a user action, r ∈ R(a) is a system response, and m ∈ M is a user model.",
                "L(a, r, m) encodes our decision preferences and assesses the optimality of responding with r when the current user model is m and the current user action is a.",
                "According to Bayesian decision theory, the optimal decision at time t is to choose a response that minimizes the Bayes risk, i.e., r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) where P(mt|U, D, At, Rt−1) is the posterior probability of the user model mt given all the observations about the user U we have made up to time t. To simplify the computation of Equation 1, let us assume that the posterior probability mass P(mt|U, D, At, Rt−1) is mostly concentrated on the mode m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "We can then approximate the integral with the value of the loss function at m∗ t .",
                "That is, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) where m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "Leaving aside how to define and estimate these probabilistic models and the loss function, we can see that such a decision-theoretic formulation suggests that, in order to choose the optimal response to at, the system should perform two tasks: (1) compute the current user model and obtain m∗ t based on all the useful information. (2) choose a response rt to minimize the loss function value L(at, rt, m∗ t ).",
                "When at does not affect our belief about m∗ t , the first step can be omitted and we may reuse m∗ t−1 for m∗ t .",
                "Note that our framework is quite general since we can potentially model any kind of user actions and system responses.",
                "In most cases, as we may expect, the systems response is some ranking of documents, i.e., for most actions a, R(a) consists of all the possible rankings of the unseen documents, and the decision problem boils down to choosing the best ranking of unseen documents based on the most current user model.",
                "When a is the action of submitting a keyword query, such a response is exactly what a current retrieval system would do.",
                "However, we can easily imagine that a more intelligent web search engine would respond to a users clicking of the Next link (to fetch more unseen results) with a more optimized ranking of documents based on any viewed documents in the current page of results.",
                "In fact, according to our eager updating strategy, we may even allow a system to respond to a users clicking of browsers Back button after viewing a document in the same way, so that the user can maximally benefit from implicit feedback.",
                "These are precisely what our UCAIR system does. 3.2 User models A user model m ∈ M represents what we know about the user U, so in principle, it can contain any information about the user that we wish to model.",
                "We now discuss two important components in a user model.",
                "The first component is a component model of the users information need.",
                "Presumably, the most important factor affecting the optimality of the systems response is how well the response addresses the users information need.",
                "Indeed, at any time, we may assume that the system has some belief about what the user is interested in, which we model through a term vector x = (x1, ..., x|V |), where V = {w1, ..., w|V |} is the set of all terms (i.e., vocabulary) and xi is the weight of term wi.",
                "Such a term vector is commonly used in information retrieval to represent both queries and documents.",
                "For example, the vector-space model, assumes that both the query and the documents are represented as term vectors and the score of a document with respect to a query is computed based on the similarity between the query vector and the document vector [21].",
                "In a language modeling approach, we may also regard the query unigram language model [12, 29] or the relevance model [14] as a term vector representation of the users information need.",
                "Intuitively, x would assign high weights to terms that characterize the topics which the user is interested in.",
                "The second component we may include in our user model is the documents that the user has already viewed.",
                "Obviously, even if a document is relevant, if the user has already seen the document, it would not be useful to present the same document again.",
                "We thus introduce another variable S ⊂ D (D is the whole set of documents in the collection) to denote the subset of documents in the search results that the user has already seen/viewed.",
                "In general, at time t, we may represent a user model as mt = (S, x, At, Rt−1), where S is the seen documents, x is the systems understanding of the users information need, and (At, Rt−1) represents the users interaction history.",
                "Note that an even more general user model may also include other factors such as the users reading level and occupation.",
                "If we assume that the uncertainty of a user model mt is solely due to the uncertainty of x, the computation of our current estimate of user model m∗ t will mainly involve computing our best estimate of x.",
                "That is, the system would choose a response according to r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) where x∗ = argmaxx P(x|U, D, At, Rt−1).",
                "This is the decision mechanism implemented in the UCAIR system to be described later.",
                "In this system, we avoided specifying the probabilistic model P(x|U, D, At, Rt−1) by computing x∗ directly with some existing feedback method. 3.3 Loss functions The exact definition of loss function L depends on the responses, thus it is inevitably application-specific.",
                "We now briefly discuss some possibilities when the response is to rank all the unseen documents and present the top k of them.",
                "Let r = (d1, ..., dk) be the top k documents, S be the set of seen documents by the user, and x∗ be the systems best guess of the users information need.",
                "We 826 may simply define the loss associated with r as the negative sum of the probability that each of the di is relevant, i.e., L(a, r, m) = − k i=1 P(relevant|di, m).",
                "Clearly, in order to minimize this loss function, the optimal response r would contain the k documents with the highest probability of relevance, which is intuitively reasonable.",
                "One deficiency of this top-k loss function is that it is not sensitive to the internal order of the selected top k documents, so switching the ranking order of a non-relevant document and a relevant one would not affect the loss, which is unreasonable.",
                "To model ranking, we can introduce a factor of the user model - the probability of each of the k documents being viewed by the user, P(view|di), and define the following ranking loss function: L(a, r, m) = − k i=1 P(view|di)P(relevant|di, m) Since in general, if di is ranked above dj (i.e., i < j), P(view|di) > P(view|dj), this loss function would favor a decision to rank relevant documents above non-relevant ones, as otherwise, we could always switch di with dj to reduce the loss value.",
                "Thus the system should simply perform a regular retrieval and rank documents according to the probability of relevance [18].",
                "Depending on the users retrieval preferences, there can be many other possibilities.",
                "For example, if the user does not want to see redundant documents, the loss function should include some redundancy measure on r based on the already seen documents S. Of course, when the response is not to choose a ranked list of documents, we would need a different loss function.",
                "We discuss one such example that is relevant to the search agent that we implement.",
                "When a user enters a query qt (current action), our search agent relies on some existing search engine to actually carry out search.",
                "In such a case, even though the search agent does not have control of the retrieval algorithm, it can still attempt to optimize the search results through refining the query sent to the search engine and/or reranking the results obtained from the search engine.",
                "The loss functions for reranking are already discussed above; we now take a look at the loss functions for query refinement.",
                "Let f be the retrieval function of the search engine that our agent uses so that f(q) would give us the search results using query q.",
                "Given that the current action of the user is entering a query qt (i.e., at = qt), our response would be f(q) for some q.",
                "Since we have no choice of f, our decision is to choose a good q.",
                "Formally, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) which shows that our goal is to find q∗ = argminqL(qt, f(q), m), i.e., an optimal query that would give us the best f(q).",
                "A different choice of loss function L(qt, f(q), m) would lead to a different query refinement strategy.",
                "In UCAIR, we heuristically compute q∗ by expanding qt with terms extracted from rt−1 whenever qt−1 and qt have high similarity.",
                "Note that rt−1 and qt−1 are contained in m as part of the users interaction history. 3.4 <br>implicit user modeling</br> <br>implicit user modeling</br> is captured in our framework through the computation of x∗ = argmaxx P(x|U, D, At, Rt−1), i.e., the systems current belief of what the users information need is.",
                "Here again there may be many possibilities, leading to different algorithms for <br>implicit user modeling</br>.",
                "We now discuss a few of them.",
                "First, when two consecutive queries are related, the previous query can be exploited to enrich the current query and provide more search context to help disambiguation.",
                "For this purpose, instead of performing query expansion as we did in the previous section, we could also compute an updated x∗ based on the previous query and retrieval results.",
                "The computed new user model can then be used to rank the documents with a standard information retrieval model.",
                "Second, we can also infer a users interest based on the summaries of the viewed documents.",
                "When a user is presented with a list of summaries of top ranked documents, if the user chooses to skip the first n documents and to view the (n+1)-th document, we may infer that the user is not interested in the displayed summaries for the first n documents, but is attracted by the displayed summary of the (n + 1)-th document.",
                "We can thus use these summaries as negative and positive examples to learn a more accurate user model x∗ .",
                "Here many standard relevance feedback techniques can be exploited [19, 20].",
                "Note that we should use the displayed summaries, as opposed to the actual contents of those documents, since it is possible that the displayed summary of the viewed document is relevant, but the document content is actually not.",
                "Similarly, a displayed summary may mislead a user to skip a relevant document.",
                "Inferring user models based on such displayed information, rather than the actual content of a document is an important difference between UCAIR and some other similar systems.",
                "In UCAIR, both of these strategies for inferring an implicit user model are implemented. 4.",
                "UCAIR: A PERSONALIZED SEARCH AGENT 4.1 Design In this section, we present a client-side web search agent called UCAIR, in which we implement some of the methods discussed in the previous section for performing personalized search through <br>implicit user modeling</br>.",
                "UCAIR is a web browser plug-in 1 that acts as a proxy for web search engines.",
                "Currently, it is only implemented for Internet Explorer and Google, but it is a matter of engineering to make it run on other web browsers and interact with other search engines.",
                "The issue of privacy is a primary obstacle for deploying any real world applications involving serious user modeling, such as personalized search.",
                "For this reason, UCAIR is strictly running as a client-side search agent, as opposed to a server-side application.",
                "This way, the captured user information always resides on the computer that the user is using, thus the user does not need to release any information to the outside.",
                "Client-side personalization also allows the system to easily observe a lot of user information that may not be easily available to a server.",
                "Furthermore, performing personalized search on the client-side is more scalable than on the serverside, since the overhead of computation and storage is distributed among clients.",
                "As shown in Figure 1, the UCAIR toolbar has 3 major components: (1) The (implicit) user modeling module captures a users search context and history information, including the submitted queries and any clicked search results and infers search session boundaries. (2) The query modification module selectively improves the query formulation according to the current user model. (3) The result re-ranking module immediately re-ranks any unseen search results whenever the user model is updated.",
                "In UCAIR, we consider four basic user actions: (1) submitting a keyword query; (2) viewing a document; (3) clicking the Back button; (4) clicking the Next link on a result page.",
                "For each of these four actions, the system responds with, respectively, (1) 1 UCAIR is available at: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Search Engine (e.g., Google) Search History Log (e.g.,past queries, clicked results) Query Modification Result Re-Ranking User Modeling Result Buffer UCAIR Userquery results clickthrough… Figure 1: UCAIR architecture generating a ranked list of results by sending a possibly expanded query to a search engine; (2) updating the information need model x; (3) reranking the unseen results on the current result page based on the current model x; and (4) reranking the unseen pages and generating the next page of results based on the current model x.",
                "Behind these responses, there are three basic tasks: (1) Decide whether the previous query is related to the current query and if so expand the current query with useful terms from the previous query or the results of the previous query. (2) Update the information need model x based on a newly clicked document summary. (3) Rerank a set of unseen documents based on the current model x.",
                "Below we describe our algorithms for each of them. 4.2 Session boundary detection and query expansion To effectively exploit previous queries and their corresponding clickthrough information, UCAIR needs to judge whether two adjacent queries belong to the same search session (i.e., detect session boundaries).",
                "Existing work on session boundary detection is mostly in the context of web log analysis (e.g., [8]), and uses statistical information rather than textual features.",
                "Since our clientside agent does not have access to server query logs, we make session boundary decisions based on textual similarity between two queries.",
                "Because related queries do not necessarily share the same words (e.g., java island and travel Indonesia), it is insufficient to use only query text.",
                "Therefore we use the search results of the two queries to help decide whether they are topically related.",
                "For example, for the above queries java island and travel Indonesia, the words java, bali, island, indonesia and travel may occur frequently in both queries search results, yielding a high similarity score.",
                "We only use the titles and summaries of the search results to calculate the similarity since they are available in the retrieved search result page and fetching the full text of every result page would significantly slow down the process.",
                "To compensate for the terseness of titles and summaries, we retrieve more results than a user would normally view for the purpose of detecting session boundaries (typically 50 results).",
                "The similarity between the previous query q and the current query q is computed as follows.",
                "Let {s1, s2, . . . , sn } and {s1, s2, . . . , sn} be the result sets for the two queries.",
                "We use the pivoted normalization TF-IDF weighting formula [24] to compute a term weight vector si for each result si.",
                "We define the average result savg to be the centroid of all the result vectors, i.e., (s1 + s2 + . . . + sn)/n.",
                "The cosine similarity between the two average results is calculated as s avg · savg/ s 2 avg · s2 avg If the similarity value exceeds a predefined threshold, the two queries will be considered to be in the same information session.",
                "If the previous query and the current query are found to belong to the same search session, UCAIR would attempt to expand the current query with terms from the previous query and its search results.",
                "Specifically, for each term in the previous query or the corresponding search results, if its frequency in the results of the current query is greater than a preset threshold (e.g. 5 results out of 50), the term would be added to the current query to form an expanded query.",
                "In this case, UCAIR would send this expanded query rather than the original one to the search engine and return the results corresponding to the expanded query.",
                "Currently, UCAIR only uses the immediate preceding query for query expansion; in principle, we could exploit all related past queries. 4.3 Information need model updating Suppose at time t, we have observed that the user has viewed k documents whose summaries are s1, ..., sk.",
                "We update our user model by computing a new information need vector with a standard feedback method in information retrieval (i.e., Rocchio [19]).",
                "According to the vector space retrieval model, each clicked summary si can be represented by a term weight vector si with each term weighted by a TF-IDF weighting formula [21].",
                "Rocchio computes the centroid vector of all the summaries and interpolates it with the original query vector to obtain an updated term vector.",
                "That is, x = αq + (1 − α) 1 k k i=1 si where q is the query vector, k is the number of summaries the user clicks immediately following the current query and α is a parameter that controls the influence of the clicked summaries on the inferred information need model.",
                "In our experiments, α is set to 0.5.",
                "Note that we update the information need model whenever the user views a document. 4.4 Result reranking In general, we want to rerank all the unseen results as soon as the user model is updated.",
                "Currently, UCAIR implements reranking in two cases, corresponding to the user clicking the Back button and Next link in the Internet Explorer.",
                "In both cases, the current (updated) user model would be used to rerank the unseen results so that the user would see improved search results immediately.",
                "To rerank any unseen document summaries, UCAIR uses the standard vector space retrieval model and scores each summary based on the similarity of the result and the current user information need vector x [21].",
                "Since implicit feedback is not completely reliable, we bring up only a small number (e.g. 5) of highest reranked results to be followed by any originally high ranked results. 828 Google result (user query = java map) UCAIR result (user query =java map) previous query = travel Indonesia previous query = hashtable expanded user query = java map Indonesia expanded user query = java map class 1 Java map projections of the world ... Lonely Planet - Indonesia Map Map (Java 2 Platform SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Java map projections of the world ... INDONESIA TOURISM : CENTRAL JAVA - MAP Java 2 Platform SE v1.3.1: Interface Map www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Java Map INDONESIA TOURISM : WEST JAVA - MAP An Introduction to Java Map Collection Classes java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Java Technology Concept Map IndoStreets - Java Map An Introduction to Java Map Collection Classes java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Indonesia Regions and Islands Maps, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 An Introduction to Java Map Collection Classes Indonesia City Street Map,... Hibernate simplifies inheritance mapping www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Java Map Maps Of Indonesia tmap 30.map Class Hierarchy www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Java API Map Maps of Indonesia by Peter Loud Class Scope www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas : Sam Maps of Indonesia by Peter Loud Class PrintSafeHashMap www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 INDONESIA TOURISM : WEST JAVA - MAP indonesiaphoto.com Java Pro - Union and Vertical Mapping of Classes www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Table 1: Sample results of query expansion 5.",
                "EVALUATION OF UCAIR We now present some results on evaluating the two major UCAIR functions: selective query expansion and result reranking based on user clickthrough data. 5.1 Sample results The query expansion strategy implemented in UCAIR is intentionally conservative to avoid misinterpretation of implicit user models.",
                "In practice, whenever it chooses to expand the query, the expansion usually makes sense.",
                "In Table 1, we show how UCAIR can successfully distinguish two different search contexts for the query java map, corresponding to two different previous queries (i.e., travel Indonesia vs. hashtable).",
                "Due to <br>implicit user modeling</br>, UCAIR intelligently figures out to add Indonesia and class, respectively, to the users query java map, which would otherwise be ambiguous as shown in the original results from Google on March 21, 2005.",
                "UCAIRs results are much more accurate than Googles results and reflect personalization in search.",
                "The eager implicit feedback component is designed to immediately respond to a users activity such as viewing a document.",
                "In Figure 2, we show how UCAIR can successfully disambiguate an ambiguous query jaguar by exploiting a viewed document summary.",
                "In this case, the initial retrieval results using jaguar (shown on the left side) contain two results about the Jaguar cars followed by two results about the Jaguar software.",
                "However, after the user views the web page content of the second result (about Jaguar car) and returns to the search result page by clicking Back button, UCAIR automatically nominates two new search results about Jaguar cars (shown on the right side), while the original two results about Jaguar software are pushed down on the list (unseen from the picture). 5.2 Quantitative evaluation To further evaluate UCAIR quantitatively, we conduct a user study on the effectiveness of the eager implicit feedback component.",
                "It is a challenge to quantitatively evaluate the potential performance improvement of our proposed model and UCAIR over Google in an unbiased way [7].",
                "Here, we design a user study, in which participants would do normal web search and judge a randomly and anonymously mixed set of results from Google and UCAIR at the end of the search session; participants do not know whether a result comes from Google or UCAIR.",
                "We recruited 6 graduate students for this user study, who have different backgrounds (3 computer science, 2 biology, and 1 chem<top> <num> Number: 716 <title> Spammer arrest sue <desc> Description: Have any spammers been arrested or sued for sending unsolicited e-mail? <narr> Narrative: Instances of arrests, prosecutions, convictions, and punishments of spammers, and lawsuits against them are relevant.",
                "Documents which describe laws to limit spam without giving details of lawsuits or criminal trials are not relevant. </top> Figure 3: An example of TREC query topic, expressed in a form which might be given to a human assistant or librarian istry).",
                "We use query topics from TREC 2 2004 Terabyte track [2] and TREC 2003 Web track [4] topic distillation task in the way to be described below.",
                "An example topic from TREC 2004 Terabyte track appears in Figure 3.",
                "The title is a short phrase and may be used as a query to the retrieval system.",
                "The description field provides a slightly longer statement of the topic requirement, usually expressed as a single complete sentence or question.",
                "Finally the narrative supplies additional information necessary to fully specify the requirement, expressed in the form of a short paragraph.",
                "Initially, each participant would browse 50 topics either from Terabyte track or Web track and pick 5 or 7 most interesting topics.",
                "For each picked topic, the participant would essentially do the normal web search using UCAIR to find many relevant web pages by using the title of the query topic as the initial keyword query.",
                "During this process, the participant may view the search results and possibly click on some interesting ones to view the web pages, just as in a normal web search.",
                "There is no requirement or restriction on how many queries the participant must submit or when the participant should stop the search for one topic.",
                "When the participant plans to change the search topic, he/she will simply press a button 2 Text REtrieval Conference: http://trec.nist.gov/ 829 Figure 2: Screen shots for result reranking to evaluate the search results before actually switching to the next topic.",
                "At the time of evaluation, 30 top ranked results from Google and UCAIR (some are overlapping) are randomly mixed together so that the participant would not know whether a result comes from Google or UCAIR.",
                "The participant would then judge the relevance of these results.",
                "We measure precision at top n (n = 5, 10, 20, 30) documents of Google and UCAIR.",
                "We also evaluate precisions at different recall levels.",
                "Altogether, 368 documents judged as relevant from Google search results and 429 documents judged as relevant from UCAIR by participants.",
                "Scatter plots of precision at top 10 and top 20 documents are shown in Figure 4 and Figure 5 respectively (The scatter plot of precision at top 30 documents is very similar to precision at top 20 documents).",
                "Each point of the scatter plots represents the precisions of Google and UCAIR on one query topic.",
                "Table 2 shows the average precision at top n documents among 32 topics.",
                "From Figure 4, Figure 5 and Table 2, we see that the search results from UCAIR are consistently better than those from Google by all the measures.",
                "Moreover, the performance improvement is more dramatic for precision at top 20 documents than that at precision at top 10 documents.",
                "One explanation for this is that the more interaction the user has with the system, the more clickthrough data UCAIR can be expected to collect.",
                "Thus the retrieval system can build more precise implicit user models, which lead to better retrieval accuracy.",
                "Ranking Method prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Improvement 8.0% 17.8% 20.2% 21.8% Table 2: Table of average precision at top n documents for 32 query topics The plot in Figure 6 shows the precision-recall curves for UCAIR and Google, where it is clearly seen that the performance of UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Scatterplot of Precision at Top 10 Documents Figure 4: Precision at top 10 documents of UCAIR and Google is consistently and considerably better than that of Google at all levels of recall. 6.",
                "CONCLUSIONS In this paper, we studied how to exploit <br>implicit user modeling</br> to intelligently personalize information retrieval and improve search accuracy.",
                "Unlike most previous work, we emphasize the use of immediate search context and implicit feedback information as well as eager updating of search results to maximally benefit a user.",
                "We presented a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent (UCAIR) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Scatterplot of Precision at Top 20 documents Figure 5: Precision at top 20 documents of UCAIR and Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 recall precision Precision−Recall curves Google Result UCAIR Result Figure 6: Precision at top 20 result of UCAIR and Google Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "The developed search agent thus can improve existing web search performance without any additional effort from the user. 7.",
                "ACKNOWLEDGEMENT We thank the six participants of our evaluation experiments.",
                "This work was supported in part by the National Science Foundation grants IIS-0347933 and IIS-0428472. 8.",
                "REFERENCES [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman, and O. Frieder.",
                "Hourly analysis of a very large topically categorized web query log.",
                "In Proceedings of SIGIR 2004, pages 321-328, 2004. [2] C. Clarke, N. Craswell, and I. Soboroff.",
                "Overview of the TREC 2004 terabyte track.",
                "In Proceedings of TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda, and D. Brown.",
                "Implicit interest indicators.",
                "In Proceedings of Intelligent User Interfaces 2001, pages 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson, and M. Wu.",
                "Overview of the TREC 2003 web track.",
                "In Proceedings of TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend, and V. Larvrenko.",
                "Relevance feedback and personalization: A language modeling perspective.",
                "In Proeedings of Second DELOS Workshop: Personalisation and Recommender Systems in Digital Libraries, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite, and D. Harman.",
                "Results and challenges in web search evaluation.",
                "Computer Networks, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A.",
                "An, and D. Schuurmans.",
                "Dynamic web log session identification with statistical language models.",
                "Journal of the American Society for Information Science and Technology, 55(14):1290-1303, 2004. [9] G. Jeh and J. Widom.",
                "Scaling personalized web search.",
                "In Proceedings of WWW 2003, pages 271-279, 2003. [10] T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of SIGKDD 2002, pages 133-142, 2002. [11] D. Kelly and J. Teevan.",
                "Implicit feedback for inferring user preference: A bibliography.",
                "SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of SIGIR01, pages 111-119, 2001. [13] T. Lau and E. Horvitz.",
                "Patterns of search: Analyzing and modeling web query refinement.",
                "In Proceedings of the Seventh International Conference on User Modeling (UM), pages 145 -152, 1999. [14] V. Lavrenko and B. Croft.",
                "Relevance-based language models.",
                "In Proceedings of SIGIR01, pages 120-127, 2001. [15] M. Mitra, A. Singhal, and C. Buckley.",
                "Improving automatic query expansion.",
                "In Proceedings of SIGIR 1998, pages 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg.",
                "As google goes, so goes the nation.",
                "New York Times, May 2003. [18] S. E. Robertson.",
                "The probability ranking principle in ı˚.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] J. J. Rocchio.",
                "Relevance feedback in information retrieval.",
                "In The SMART Retrieval System: Experiments in Automatic Document Processing, pages 313-323.",
                "Prentice-Hall Inc., 1971. [20] G. Salton and C. Buckley.",
                "Improving retrieval performance by retrieval feedback.",
                "Journal of the American Society for Information Science, 41(4):288-297, 1990. [21] G. Salton and M. J. McGill.",
                "Introduction to Modern Information Retrieval.",
                "McGraw-Hill, 1983. [22] X. Shen, B. Tan, and C. Zhai.",
                "Context-sensitive information retrieval using implicit feedback.",
                "In Proceedings of SIGIR 2005, pages 43-50, 2005. [23] X. Shen and C. Zhai.",
                "Exploiting query history for document ranking in interactive information retrieval (Poster).",
                "In Proceedings of SIGIR 2003, pages 377-378, 2003. [24] A. Singhal.",
                "Modern information retrieval: A brief overview.",
                "Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano, and M. Yoshikawa.",
                "Adaptive web search based on user profile constructed without any effort from users.",
                "In Proceedings of WWW 2004, pages 675-684, 2004. [26] E. Volokh.",
                "Personalization and privacy.",
                "Communications of the ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen, and I. Ruthven.",
                "A simulated study of implicit feedback models.",
                "In Proceedings of ECIR 2004, pages 311-326, 2004. [28] J. Xu and W. B. Croft.",
                "Query expansion using local and global document analysis.",
                "In Proceedings of SIGIR 1996, pages 4-11, 1996. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in KL divergence retrieval model.",
                "In Proceedings of the CIKM 2001, pages 403-410, 2001. 831"
            ],
            "original_annotated_samples": [
                "<br>implicit user modeling</br> for Personalized Search Xuehua Shen, Bin Tan, ChengXiang Zhai Department of Computer Science University of Illinois at Urbana-Champaign ABSTRACT Information retrieval systems (e.g., web search engines) are critical for overcoming information overload.",
                "We present a decision theoretic framework and develop techniques for <br>implicit user modeling</br> in information retrieval.",
                "Indeed, several previous studies have shown that <br>implicit user modeling</br> can improve retrieval accuracy.",
                "In order to maximally benefit the user of a retrieval system through <br>implicit user modeling</br>, we propose to perform eager implicit feedback.",
                "In Section 3, we present a decisiontheoretic interactive retrieval framework for <br>implicit user modeling</br>."
            ],
            "translated_annotated_samples": [
                "Modelado implícito de usuarios para búsqueda personalizada Xuehua Shen, Bin Tan, ChengXiang Zhai Departamento de Ciencias de la Computación Universidad de Illinois en Urbana-Champaign RESUMEN Los sistemas de recuperación de información (por ejemplo, motores de búsqueda web) son críticos para superar la sobrecarga de información.",
                "Presentamos un marco teórico de toma de decisiones y desarrollamos técnicas para el <br>modelado implícito del usuario</br> en la recuperación de información.",
                "De hecho, varios estudios previos han demostrado que el <br>modelado implícito del usuario</br> puede mejorar la precisión de recuperación.",
                "Para beneficiar al máximo al usuario de un sistema de recuperación a través de <br>modelado implícito del usuario</br>, proponemos realizar retroalimentación implícita entusiasta.",
                "En la Sección 3, presentamos un marco de recuperación interactiva basado en teoría de decisiones para <br>modelado implícito de usuarios</br>."
            ],
            "translated_text": "Modelado implícito de usuarios para búsqueda personalizada Xuehua Shen, Bin Tan, ChengXiang Zhai Departamento de Ciencias de la Computación Universidad de Illinois en Urbana-Champaign RESUMEN Los sistemas de recuperación de información (por ejemplo, motores de búsqueda web) son críticos para superar la sobrecarga de información. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales, lo que resulta en un rendimiento de recuperación inherentemente no óptimo. Por ejemplo, un turista y un programador pueden usar la misma palabra \"java\" para buscar información diferente, pero los sistemas de búsqueda actuales devolverían los mismos resultados. En este artículo, estudiamos cómo inferir el interés de un usuario a partir del contexto de búsqueda del usuario y utilizar el modelo de usuario implícito inferido para la búsqueda personalizada. Presentamos un marco teórico de toma de decisiones y desarrollamos técnicas para el <br>modelado implícito del usuario</br> en la recuperación de información. Desarrollamos un agente de búsqueda web inteligente del lado del cliente (UCAIR) que puede realizar retroalimentación implícita ansiosa, por ejemplo, expansión de consultas basada en consultas anteriores y reordenamiento inmediato de resultados basado en información de clics. Los experimentos sobre la búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda sobre el popular motor de búsqueda Google. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación, Retroalimentación de relevancia, Proceso de búsqueda Términos Generales Algoritmos 1. Aunque muchos sistemas de recuperación de información (por ejemplo, motores de búsqueda web y sistemas de biblioteca digital) se han implementado con éxito, los sistemas de recuperación actuales están lejos de ser óptimos. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales [17]. Esta no optimalidad inherente se ve claramente en los siguientes dos casos: (1) Diferentes usuarios pueden utilizar exactamente la misma consulta (por ejemplo, Java) para buscar información diferente (por ejemplo, la isla de Java en Indonesia o el lenguaje de programación Java), pero los sistemas de IR existentes devuelven los mismos resultados para estos usuarios. Sin considerar al usuario actual, es imposible saber a qué sentido se refiere Java en una consulta. (2) Las necesidades de información de un usuario pueden cambiar con el tiempo. El mismo usuario puede usar Java a veces para referirse a la isla de Java en Indonesia y otras veces para referirse al lenguaje de programación. Sin reconocer el contexto de búsqueda, sería nuevamente imposible reconocer el sentido correcto. Para optimizar la precisión de la recuperación, claramente necesitamos modelar al usuario de manera adecuada y personalizar la búsqueda según cada usuario individual. El objetivo principal del modelado de usuario para la recuperación de información es modelar con precisión la necesidad de información de un usuario, lo cual, desafortunadamente, es una tarea muy difícil. De hecho, incluso resulta difícil para un usuario describir con precisión cuál es su necesidad de información. ¿Qué información está disponible para que un sistema pueda inferir la necesidad de información de un usuario? Obviamente, la consulta de los usuarios proporciona la evidencia más directa. De hecho, la mayoría de los sistemas de recuperación existentes se basan únicamente en la consulta para modelar la necesidad de información de los usuarios. Sin embargo, dado que una consulta suele ser extremadamente corta, el modelo de usuario construido basado en una consulta de palabras clave inevitablemente resulta empobrecido. Una forma efectiva de mejorar la modelización de usuarios en la recuperación de información es pedir al usuario que especifique explícitamente qué documentos son relevantes (es decir, útiles para satisfacer su necesidad de información) y luego mejorar la modelización de usuarios basándose en ejemplos de documentos relevantes. Esto se llama retroalimentación de relevancia, lo cual ha demostrado ser bastante efectivo para mejorar la precisión de recuperación [19, 20]. Desafortunadamente, en aplicaciones del mundo real, los usuarios suelen ser reacios a hacer el esfuerzo adicional de proporcionar ejemplos relevantes para retroalimentación [11]. Por lo tanto, es muy interesante estudiar cómo inferir la necesidad de información de un usuario basándose en cualquier información de retroalimentación implícita, la cual existe naturalmente a través de las interacciones del usuario y no requiere ningún esfuerzo adicional por parte del usuario. De hecho, varios estudios previos han demostrado que el <br>modelado implícito del usuario</br> puede mejorar la precisión de recuperación. En [3], se desarrolla un navegador web (Curious Browser) para registrar las calificaciones explícitas de relevancia de las páginas web por parte de los usuarios (retroalimentación de relevancia) y el comportamiento de navegación al ver una página, como el tiempo de permanencia, clics de ratón, movimiento del ratón y desplazamiento (retroalimentación implícita). Se muestra que el tiempo de permanencia en una página, la cantidad de desplazamiento en una página y la combinación de tiempo y desplazamiento tienen una fuerte correlación con las calificaciones de relevancia explícita, lo que sugiere que la retroalimentación implícita puede ser útil para inferir la necesidad de información del usuario. En [10], se recopilan datos de clics de usuario como datos de entrenamiento para aprender una función de recuperación, que se utiliza para producir un ranking personalizado de resultados de búsqueda que se adapte a las preferencias de un grupo de usuarios. En [25], los datos de clics recopilados durante un largo período de tiempo se utilizan a través de la expansión de consultas para mejorar la precisión de recuperación. Si bien un usuario puede tener intereses y preferencias generales a largo plazo para la información, a menudo está buscando documentos para satisfacer una necesidad de información ad-hoc, que solo dura un corto período de tiempo; una vez que se satisface la necesidad de información, el usuario generalmente ya no estaría interesado en esa información. Por ejemplo, un usuario puede estar buscando información sobre autos usados para comprar uno, pero una vez que el usuario ha comprado un auto, generalmente ya no está interesado en esa información. En tales casos, la información de retroalimentación implícita recopilada durante un largo período de tiempo es poco probable que sea muy útil, pero el contexto de búsqueda inmediato y la información de retroalimentación, como cuáles de los resultados de búsqueda para la necesidad de información actual son vistos, se espera que sean mucho más útiles. Considera la consulta de Java nuevamente. Cualquiera de la siguiente información de retroalimentación inmediata sobre el usuario podría potencialmente ayudar a determinar el significado previsto de Java en la consulta: (1) La consulta anterior enviada por el usuario es hashtable (en lugar de, por ejemplo, viajar a Indonesia). (2) En los resultados de búsqueda, el usuario visualizó una página donde palabras como programación, software y applet ocurren muchas veces. Hasta donde sabemos, cómo aprovechar este contexto de búsqueda inmediato y a corto plazo para mejorar la búsqueda aún no ha sido abordado de manera satisfactoria en trabajos anteriores. En este artículo, estudiamos cómo construir y actualizar un modelo de usuario basado en el contexto de búsqueda inmediato y la información de retroalimentación implícita, y utilizar el modelo para mejorar la precisión de la recuperación ad-hoc. Para beneficiar al máximo al usuario de un sistema de recuperación a través de <br>modelado implícito del usuario</br>, proponemos realizar retroalimentación implícita entusiasta. Es decir, tan pronto como observemos cualquier nueva pieza de evidencia del usuario, actualizaríamos la creencia del sistema sobre la necesidad de información del usuario y responderíamos con resultados de recuperación mejorados basados en el modelo de usuario actualizado. Presentamos un marco de trabajo de teoría de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. En un paradigma de recuperación tradicional, el problema de recuperación consiste en emparejar una consulta con documentos y clasificar los documentos según sus valores de relevancia. Como resultado, el proceso de recuperación es un ciclo independiente simple de consulta y visualización de resultados. En el nuevo paradigma de recuperación propuesto, el contexto de búsqueda de los usuarios juega un papel importante y el modelo de usuario implícito inferido se explota inmediatamente para beneficiar al usuario. El nuevo paradigma de recuperación es, por lo tanto, fundamentalmente diferente del paradigma tradicional y es inherentemente más general. Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos apropiados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para reordenar inmediatamente cualquier documento que aún no haya sido visto por el usuario. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente UCAIR (Recuperación de Información Adaptativa Centrada en el Usuario) sobre un motor de búsqueda popular (Google). Los experimentos sobre búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en comparación con Google. Dado que la información implícita que explotamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional. Por lo tanto, el agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin esfuerzo adicional por parte del usuario. Las secciones restantes están organizadas de la siguiente manera. En la Sección 2, discutimos el trabajo relacionado. En la Sección 3, presentamos un marco de recuperación interactiva basado en teoría de decisiones para <br>modelado implícito de usuarios</br>. ",
            "candidates": [],
            "error": [
                [
                    "modelado implícito del usuario",
                    "modelado implícito del usuario",
                    "modelado implícito del usuario",
                    "modelado implícito de usuarios"
                ]
            ]
        },
        "query expansion": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Implicit User Modeling for Personalized Search Xuehua Shen, Bin Tan, ChengXiang Zhai Department of Computer Science University of Illinois at Urbana-Champaign ABSTRACT Information retrieval systems (e.g., web search engines) are critical for overcoming information overload.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users, resulting in inherently non-optimal retrieval performance.",
                "For example, a tourist and a programmer may use the same word java to search for different information, but the current search systems would return the same results.",
                "In this paper, we study how to infer a users interest from the users search context and use the inferred implicit user model for personalized search .",
                "We present a decision theoretic framework and develop techniques for implicit user modeling in information retrieval.",
                "We develop an intelligent client-side web search agent (UCAIR) that can perform eager implicit feedback, e.g., <br>query expansion</br> based on previous queries and immediate result reranking based on clickthrough information.",
                "Experiments on web search show that our search agent can improve search accuracy over the popular Google search engine.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models, Relevance feedback, Search Process General Terms Algorithms 1.",
                "INTRODUCTION Although many information retrieval systems (e.g., web search engines and digital library systems) have been successfully deployed, the current retrieval systems are far from optimal.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users [17].",
                "This inherent non-optimality is seen clearly in the following two cases: (1) Different users may use exactly the same query (e.g., Java) to search for different information (e.g., the Java island in Indonesia or the Java programming language), but existing IR systems return the same results for these users.",
                "Without considering the actual user, it is impossible to know which sense Java refers to in a query. (2) A users information needs may change over time.",
                "The same user may use Java sometimes to mean the Java island in Indonesia and some other times to mean the programming language.",
                "Without recognizing the search context, it would be again impossible to recognize the correct sense.",
                "In order to optimize retrieval accuracy, we clearly need to model the user appropriately and personalize search according to each individual user.",
                "The major goal of user modeling for information retrieval is to accurately model a users information need, which is, unfortunately, a very difficult task.",
                "Indeed, it is even hard for a user to precisely describe what his/her information need is.",
                "What information is available for a system to infer a users information need?",
                "Obviously, the users query provides the most direct evidence.",
                "Indeed, most existing retrieval systems rely solely on the query to model a users information need.",
                "However, since a query is often extremely short, the user model constructed based on a keyword query is inevitably impoverished .",
                "An effective way to improve user modeling in information retrieval is to ask the user to explicitly specify which documents are relevant (i.e., useful for satisfying his/her information need), and then to improve user modeling based on such examples of relevant documents.",
                "This is called relevance feedback, which has been proved to be quite effective for improving retrieval accuracy [19, 20].",
                "Unfortunately, in real world applications, users are usually reluctant to make the extra effort to provide relevant examples for feedback [11].",
                "It is thus very interesting to study how to infer a users information need based on any implicit feedback information, which naturally exists through user interactions and thus does not require any extra user effort.",
                "Indeed, several previous studies have shown that implicit user modeling can improve retrieval accuracy.",
                "In [3], a web browser (Curious Browser) is developed to record a users explicit relevance ratings of web pages (relevance feedback) and browsing behavior when viewing a page, such as dwelling time, mouse click, mouse movement and scrolling (implicit feedback).",
                "It is shown that the dwelling time on a page, amount of scrolling on a page and the combination of time and scrolling have a strong correlation with explicit relevance ratings, which suggests that implicit feedback may be helpful for inferring user information need.",
                "In [10], user clickthrough data is collected as training data to learn a retrieval function, which is used to produce a customized ranking of search results that suits a group of users preferences.",
                "In [25], the clickthrough data collected over a long time period is exploited through <br>query expansion</br> to improve retrieval accuracy. 824 While a user may have general long term interests and preferences for information, often he/she is searching for documents to satisfy an ad-hoc information need, which only lasts for a short period of time; once the information need is satisfied, the user would generally no longer be interested in such information.",
                "For example, a user may be looking for information about used cars in order to buy one, but once the user has bought a car, he/she is generally no longer interested in such information.",
                "In such cases, implicit feedback information collected over a long period of time is unlikely to be very useful, but the immediate search context and feedback information, such as which of the search results for the current information need are viewed, can be expected to be much more useful.",
                "Consider the query Java again.",
                "Any of the following immediate feedback information about the user could potentially help determine the intended meaning of Java in the query: (1) The previous query submitted by the user is hashtable (as opposed to, e.g., travel Indonesia). (2) In the search results, the user viewed a page where words such as programming, software, and applet occur many times.",
                "To the best of our knowledge, how to exploit such immediate and short-term search context to improve search has so far not been well addressed in the previous work.",
                "In this paper, we study how to construct and update a user model based on the immediate search context and implicit feedback information and use the model to improve the accuracy of ad-hoc retrieval.",
                "In order to maximally benefit the user of a retrieval system through implicit user modeling, we propose to perform eager implicit feedback.",
                "That is, as soon as we observe any new piece of evidence from the user, we would update the systems belief about the users information need and respond with improved retrieval results based on the updated user model.",
                "We present a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "In a traditional retrieval paradigm, the retrieval problem is to match a query with documents and rank documents according to their relevance values.",
                "As a result, the retrieval process is a simple independent cycle of query and result display.",
                "In the proposed new retrieval paradigm, the users search context plays an important role and the inferred implicit user model is exploited immediately to benefit the user.",
                "The new retrieval paradigm is thus fundamentally different from the traditional paradigm, and is inherently more general.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent UCAIR (User-Centered Adaptive Information Retrieval) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "Thus the developed search agent can improve existing web search performance without additional effort from the user.",
                "The remaining sections are organized as follows.",
                "In Section 2, we discuss the related work.",
                "In Section 3, we present a decisiontheoretic interactive retrieval framework for implicit user modeling.",
                "In Section 4, we present the design and implementation of an intelligent client-side web search agent (UCAIR) that performs eager implicit feedback.",
                "In Section 5, we report our experiment results using the search agent.",
                "Section 6 concludes our work. 2.",
                "RELATED WORK Implicit user modeling for personalized search has been studied in previous work, but our work differs from all previous work in several aspects: (1) We emphasize the exploitation of immediate search context such as the related immediately preceding query and the viewed documents in the same session, while most previous work relies on long-term collection of implicit feedback information [25]. (2) We perform eager feedback and bring the benefit of implicit user modeling as soon as any new implicit feedback information is available, while the previous work mostly exploits longterm implicit feedback [10]. (3) We propose a retrieval framework to integrate implicit user modeling with the interactive retrieval process, while the previous work either studies implicit user modeling separately from retrieval [3] or only studies specific retrieval models for exploiting implicit feedback to better match a query with documents [23, 27, 22]. (4) We develop and evaluate a personalized Web search agent with online user studies, while most existing work evaluates algorithms offline without real user interactions.",
                "Currently some search engines provide rudimentary personalization, such as Google Personalized web search [6], which allows users to explicitly describe their interests by selecting from predefined topics, so that those results that match their interests are brought to the top, and My Yahoo! search [16], which gives users the option to save web sites they like and block those they dislike.",
                "In contrast, UCAIR personalizes web search through implicit user modeling without any additional user efforts.",
                "Furthermore, the personalization of UCAIR is provided on the client side.",
                "There are two remarkable advantages on this.",
                "First, the user does not need to worry about the privacy infringement, which is a big concern for personalized search [26].",
                "Second, both the computation of personalization and the storage of the user profile are done at the client side so that the server load is reduced dramatically [9].",
                "There have been many works studying user query logs [1] or query dynamics [13].",
                "UCAIR makes direct use of a users query history to benefit the same user immediately in the same search session.",
                "UCAIR first judges whether two neighboring queries belong to the same information session and if so, it selects terms from the previous query to perform <br>query expansion</br>.",
                "Our <br>query expansion</br> approach is similar to automatic <br>query expansion</br> [28, 15, 5], but instead of using pseudo feedback to expand the query, we use users implicit feedback information to expand the current query.",
                "These two techniques may be combined. 3.",
                "OPTIMIZATION IN INTERACTIVE IR In interactive IR, a user interacts with the retrieval system through an action dialogue, in which the system responds to each user action with some system action.",
                "For example, the users action may be submitting a query and the systems response may be returning a list of 10 document summaries.",
                "In general, the space of user actions and system responses and their granularities would depend on the interface of a particular retrieval system.",
                "In principle, every action of the user can potentially provide new evidence to help the system better infer the users information need.",
                "Thus in order to respond optimally, the system should use all the evidence collected so far about the user when choosing a response.",
                "When viewed in this way, most existing search engines are clearly non-optimal.",
                "For example, if a user has viewed some documents on the first page of search results, when the user clicks on the Next link to fetch more results, an existing retrieval system would still return the next page of results retrieved based on the original query without considering the new evidence that a particular result has been viewed by the user. 825 We propose to optimize retrieval performance by adapting system responses based on every action that a user has taken, and cast the optimization problem as a decision task.",
                "Specifically, at any time, the system would attempt to do two tasks: (1) User model updating: Monitor any useful evidence from the user regarding his/her information need and update the user model as soon as such evidence is available; (2) Improving search results: Rerank immediately all the documents that the user has not yet seen, as soon as the user model is updated.",
                "We emphasize eager updating and reranking, which makes our work quite different from any existing work.",
                "Below we present a formal decision theoretic framework for optimizing retrieval performance through implicit user modeling in interactive information retrieval. 3.1 A decision-theoretic framework Let A be the set of all user actions and R(a) be the set of all possible system responses to a user action a ∈ A.",
                "At any time, let At = (a1, ..., at) be the observed sequence of user actions so far (up to time point t) and Rt−1 = (r1, ..., rt−1) be the responses that the system has made responding to the user actions.",
                "The systems goal is to choose an optimal response rt ∈ R(at) for the current user action at.",
                "Let M be the space of all possible user models.",
                "We further define a loss function L(a, r, m) ∈ , where a ∈ A is a user action, r ∈ R(a) is a system response, and m ∈ M is a user model.",
                "L(a, r, m) encodes our decision preferences and assesses the optimality of responding with r when the current user model is m and the current user action is a.",
                "According to Bayesian decision theory, the optimal decision at time t is to choose a response that minimizes the Bayes risk, i.e., r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) where P(mt|U, D, At, Rt−1) is the posterior probability of the user model mt given all the observations about the user U we have made up to time t. To simplify the computation of Equation 1, let us assume that the posterior probability mass P(mt|U, D, At, Rt−1) is mostly concentrated on the mode m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "We can then approximate the integral with the value of the loss function at m∗ t .",
                "That is, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) where m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "Leaving aside how to define and estimate these probabilistic models and the loss function, we can see that such a decision-theoretic formulation suggests that, in order to choose the optimal response to at, the system should perform two tasks: (1) compute the current user model and obtain m∗ t based on all the useful information. (2) choose a response rt to minimize the loss function value L(at, rt, m∗ t ).",
                "When at does not affect our belief about m∗ t , the first step can be omitted and we may reuse m∗ t−1 for m∗ t .",
                "Note that our framework is quite general since we can potentially model any kind of user actions and system responses.",
                "In most cases, as we may expect, the systems response is some ranking of documents, i.e., for most actions a, R(a) consists of all the possible rankings of the unseen documents, and the decision problem boils down to choosing the best ranking of unseen documents based on the most current user model.",
                "When a is the action of submitting a keyword query, such a response is exactly what a current retrieval system would do.",
                "However, we can easily imagine that a more intelligent web search engine would respond to a users clicking of the Next link (to fetch more unseen results) with a more optimized ranking of documents based on any viewed documents in the current page of results.",
                "In fact, according to our eager updating strategy, we may even allow a system to respond to a users clicking of browsers Back button after viewing a document in the same way, so that the user can maximally benefit from implicit feedback.",
                "These are precisely what our UCAIR system does. 3.2 User models A user model m ∈ M represents what we know about the user U, so in principle, it can contain any information about the user that we wish to model.",
                "We now discuss two important components in a user model.",
                "The first component is a component model of the users information need.",
                "Presumably, the most important factor affecting the optimality of the systems response is how well the response addresses the users information need.",
                "Indeed, at any time, we may assume that the system has some belief about what the user is interested in, which we model through a term vector x = (x1, ..., x|V |), where V = {w1, ..., w|V |} is the set of all terms (i.e., vocabulary) and xi is the weight of term wi.",
                "Such a term vector is commonly used in information retrieval to represent both queries and documents.",
                "For example, the vector-space model, assumes that both the query and the documents are represented as term vectors and the score of a document with respect to a query is computed based on the similarity between the query vector and the document vector [21].",
                "In a language modeling approach, we may also regard the query unigram language model [12, 29] or the relevance model [14] as a term vector representation of the users information need.",
                "Intuitively, x would assign high weights to terms that characterize the topics which the user is interested in.",
                "The second component we may include in our user model is the documents that the user has already viewed.",
                "Obviously, even if a document is relevant, if the user has already seen the document, it would not be useful to present the same document again.",
                "We thus introduce another variable S ⊂ D (D is the whole set of documents in the collection) to denote the subset of documents in the search results that the user has already seen/viewed.",
                "In general, at time t, we may represent a user model as mt = (S, x, At, Rt−1), where S is the seen documents, x is the systems understanding of the users information need, and (At, Rt−1) represents the users interaction history.",
                "Note that an even more general user model may also include other factors such as the users reading level and occupation.",
                "If we assume that the uncertainty of a user model mt is solely due to the uncertainty of x, the computation of our current estimate of user model m∗ t will mainly involve computing our best estimate of x.",
                "That is, the system would choose a response according to r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) where x∗ = argmaxx P(x|U, D, At, Rt−1).",
                "This is the decision mechanism implemented in the UCAIR system to be described later.",
                "In this system, we avoided specifying the probabilistic model P(x|U, D, At, Rt−1) by computing x∗ directly with some existing feedback method. 3.3 Loss functions The exact definition of loss function L depends on the responses, thus it is inevitably application-specific.",
                "We now briefly discuss some possibilities when the response is to rank all the unseen documents and present the top k of them.",
                "Let r = (d1, ..., dk) be the top k documents, S be the set of seen documents by the user, and x∗ be the systems best guess of the users information need.",
                "We 826 may simply define the loss associated with r as the negative sum of the probability that each of the di is relevant, i.e., L(a, r, m) = − k i=1 P(relevant|di, m).",
                "Clearly, in order to minimize this loss function, the optimal response r would contain the k documents with the highest probability of relevance, which is intuitively reasonable.",
                "One deficiency of this top-k loss function is that it is not sensitive to the internal order of the selected top k documents, so switching the ranking order of a non-relevant document and a relevant one would not affect the loss, which is unreasonable.",
                "To model ranking, we can introduce a factor of the user model - the probability of each of the k documents being viewed by the user, P(view|di), and define the following ranking loss function: L(a, r, m) = − k i=1 P(view|di)P(relevant|di, m) Since in general, if di is ranked above dj (i.e., i < j), P(view|di) > P(view|dj), this loss function would favor a decision to rank relevant documents above non-relevant ones, as otherwise, we could always switch di with dj to reduce the loss value.",
                "Thus the system should simply perform a regular retrieval and rank documents according to the probability of relevance [18].",
                "Depending on the users retrieval preferences, there can be many other possibilities.",
                "For example, if the user does not want to see redundant documents, the loss function should include some redundancy measure on r based on the already seen documents S. Of course, when the response is not to choose a ranked list of documents, we would need a different loss function.",
                "We discuss one such example that is relevant to the search agent that we implement.",
                "When a user enters a query qt (current action), our search agent relies on some existing search engine to actually carry out search.",
                "In such a case, even though the search agent does not have control of the retrieval algorithm, it can still attempt to optimize the search results through refining the query sent to the search engine and/or reranking the results obtained from the search engine.",
                "The loss functions for reranking are already discussed above; we now take a look at the loss functions for query refinement.",
                "Let f be the retrieval function of the search engine that our agent uses so that f(q) would give us the search results using query q.",
                "Given that the current action of the user is entering a query qt (i.e., at = qt), our response would be f(q) for some q.",
                "Since we have no choice of f, our decision is to choose a good q.",
                "Formally, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) which shows that our goal is to find q∗ = argminqL(qt, f(q), m), i.e., an optimal query that would give us the best f(q).",
                "A different choice of loss function L(qt, f(q), m) would lead to a different query refinement strategy.",
                "In UCAIR, we heuristically compute q∗ by expanding qt with terms extracted from rt−1 whenever qt−1 and qt have high similarity.",
                "Note that rt−1 and qt−1 are contained in m as part of the users interaction history. 3.4 Implicit user modeling Implicit user modeling is captured in our framework through the computation of x∗ = argmaxx P(x|U, D, At, Rt−1), i.e., the systems current belief of what the users information need is.",
                "Here again there may be many possibilities, leading to different algorithms for implicit user modeling.",
                "We now discuss a few of them.",
                "First, when two consecutive queries are related, the previous query can be exploited to enrich the current query and provide more search context to help disambiguation.",
                "For this purpose, instead of performing <br>query expansion</br> as we did in the previous section, we could also compute an updated x∗ based on the previous query and retrieval results.",
                "The computed new user model can then be used to rank the documents with a standard information retrieval model.",
                "Second, we can also infer a users interest based on the summaries of the viewed documents.",
                "When a user is presented with a list of summaries of top ranked documents, if the user chooses to skip the first n documents and to view the (n+1)-th document, we may infer that the user is not interested in the displayed summaries for the first n documents, but is attracted by the displayed summary of the (n + 1)-th document.",
                "We can thus use these summaries as negative and positive examples to learn a more accurate user model x∗ .",
                "Here many standard relevance feedback techniques can be exploited [19, 20].",
                "Note that we should use the displayed summaries, as opposed to the actual contents of those documents, since it is possible that the displayed summary of the viewed document is relevant, but the document content is actually not.",
                "Similarly, a displayed summary may mislead a user to skip a relevant document.",
                "Inferring user models based on such displayed information, rather than the actual content of a document is an important difference between UCAIR and some other similar systems.",
                "In UCAIR, both of these strategies for inferring an implicit user model are implemented. 4.",
                "UCAIR: A PERSONALIZED SEARCH AGENT 4.1 Design In this section, we present a client-side web search agent called UCAIR, in which we implement some of the methods discussed in the previous section for performing personalized search through implicit user modeling.",
                "UCAIR is a web browser plug-in 1 that acts as a proxy for web search engines.",
                "Currently, it is only implemented for Internet Explorer and Google, but it is a matter of engineering to make it run on other web browsers and interact with other search engines.",
                "The issue of privacy is a primary obstacle for deploying any real world applications involving serious user modeling, such as personalized search.",
                "For this reason, UCAIR is strictly running as a client-side search agent, as opposed to a server-side application.",
                "This way, the captured user information always resides on the computer that the user is using, thus the user does not need to release any information to the outside.",
                "Client-side personalization also allows the system to easily observe a lot of user information that may not be easily available to a server.",
                "Furthermore, performing personalized search on the client-side is more scalable than on the serverside, since the overhead of computation and storage is distributed among clients.",
                "As shown in Figure 1, the UCAIR toolbar has 3 major components: (1) The (implicit) user modeling module captures a users search context and history information, including the submitted queries and any clicked search results and infers search session boundaries. (2) The query modification module selectively improves the query formulation according to the current user model. (3) The result re-ranking module immediately re-ranks any unseen search results whenever the user model is updated.",
                "In UCAIR, we consider four basic user actions: (1) submitting a keyword query; (2) viewing a document; (3) clicking the Back button; (4) clicking the Next link on a result page.",
                "For each of these four actions, the system responds with, respectively, (1) 1 UCAIR is available at: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Search Engine (e.g., Google) Search History Log (e.g.,past queries, clicked results) Query Modification Result Re-Ranking User Modeling Result Buffer UCAIR Userquery results clickthrough… Figure 1: UCAIR architecture generating a ranked list of results by sending a possibly expanded query to a search engine; (2) updating the information need model x; (3) reranking the unseen results on the current result page based on the current model x; and (4) reranking the unseen pages and generating the next page of results based on the current model x.",
                "Behind these responses, there are three basic tasks: (1) Decide whether the previous query is related to the current query and if so expand the current query with useful terms from the previous query or the results of the previous query. (2) Update the information need model x based on a newly clicked document summary. (3) Rerank a set of unseen documents based on the current model x.",
                "Below we describe our algorithms for each of them. 4.2 Session boundary detection and <br>query expansion</br> To effectively exploit previous queries and their corresponding clickthrough information, UCAIR needs to judge whether two adjacent queries belong to the same search session (i.e., detect session boundaries).",
                "Existing work on session boundary detection is mostly in the context of web log analysis (e.g., [8]), and uses statistical information rather than textual features.",
                "Since our clientside agent does not have access to server query logs, we make session boundary decisions based on textual similarity between two queries.",
                "Because related queries do not necessarily share the same words (e.g., java island and travel Indonesia), it is insufficient to use only query text.",
                "Therefore we use the search results of the two queries to help decide whether they are topically related.",
                "For example, for the above queries java island and travel Indonesia, the words java, bali, island, indonesia and travel may occur frequently in both queries search results, yielding a high similarity score.",
                "We only use the titles and summaries of the search results to calculate the similarity since they are available in the retrieved search result page and fetching the full text of every result page would significantly slow down the process.",
                "To compensate for the terseness of titles and summaries, we retrieve more results than a user would normally view for the purpose of detecting session boundaries (typically 50 results).",
                "The similarity between the previous query q and the current query q is computed as follows.",
                "Let {s1, s2, . . . , sn } and {s1, s2, . . . , sn} be the result sets for the two queries.",
                "We use the pivoted normalization TF-IDF weighting formula [24] to compute a term weight vector si for each result si.",
                "We define the average result savg to be the centroid of all the result vectors, i.e., (s1 + s2 + . . . + sn)/n.",
                "The cosine similarity between the two average results is calculated as s avg · savg/ s 2 avg · s2 avg If the similarity value exceeds a predefined threshold, the two queries will be considered to be in the same information session.",
                "If the previous query and the current query are found to belong to the same search session, UCAIR would attempt to expand the current query with terms from the previous query and its search results.",
                "Specifically, for each term in the previous query or the corresponding search results, if its frequency in the results of the current query is greater than a preset threshold (e.g. 5 results out of 50), the term would be added to the current query to form an expanded query.",
                "In this case, UCAIR would send this expanded query rather than the original one to the search engine and return the results corresponding to the expanded query.",
                "Currently, UCAIR only uses the immediate preceding query for <br>query expansion</br>; in principle, we could exploit all related past queries. 4.3 Information need model updating Suppose at time t, we have observed that the user has viewed k documents whose summaries are s1, ..., sk.",
                "We update our user model by computing a new information need vector with a standard feedback method in information retrieval (i.e., Rocchio [19]).",
                "According to the vector space retrieval model, each clicked summary si can be represented by a term weight vector si with each term weighted by a TF-IDF weighting formula [21].",
                "Rocchio computes the centroid vector of all the summaries and interpolates it with the original query vector to obtain an updated term vector.",
                "That is, x = αq + (1 − α) 1 k k i=1 si where q is the query vector, k is the number of summaries the user clicks immediately following the current query and α is a parameter that controls the influence of the clicked summaries on the inferred information need model.",
                "In our experiments, α is set to 0.5.",
                "Note that we update the information need model whenever the user views a document. 4.4 Result reranking In general, we want to rerank all the unseen results as soon as the user model is updated.",
                "Currently, UCAIR implements reranking in two cases, corresponding to the user clicking the Back button and Next link in the Internet Explorer.",
                "In both cases, the current (updated) user model would be used to rerank the unseen results so that the user would see improved search results immediately.",
                "To rerank any unseen document summaries, UCAIR uses the standard vector space retrieval model and scores each summary based on the similarity of the result and the current user information need vector x [21].",
                "Since implicit feedback is not completely reliable, we bring up only a small number (e.g. 5) of highest reranked results to be followed by any originally high ranked results. 828 Google result (user query = java map) UCAIR result (user query =java map) previous query = travel Indonesia previous query = hashtable expanded user query = java map Indonesia expanded user query = java map class 1 Java map projections of the world ... Lonely Planet - Indonesia Map Map (Java 2 Platform SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Java map projections of the world ... INDONESIA TOURISM : CENTRAL JAVA - MAP Java 2 Platform SE v1.3.1: Interface Map www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Java Map INDONESIA TOURISM : WEST JAVA - MAP An Introduction to Java Map Collection Classes java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Java Technology Concept Map IndoStreets - Java Map An Introduction to Java Map Collection Classes java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Indonesia Regions and Islands Maps, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 An Introduction to Java Map Collection Classes Indonesia City Street Map,... Hibernate simplifies inheritance mapping www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Java Map Maps Of Indonesia tmap 30.map Class Hierarchy www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Java API Map Maps of Indonesia by Peter Loud Class Scope www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas : Sam Maps of Indonesia by Peter Loud Class PrintSafeHashMap www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 INDONESIA TOURISM : WEST JAVA - MAP indonesiaphoto.com Java Pro - Union and Vertical Mapping of Classes www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Table 1: Sample results of <br>query expansion</br> 5.",
                "EVALUATION OF UCAIR We now present some results on evaluating the two major UCAIR functions: selective <br>query expansion</br> and result reranking based on user clickthrough data. 5.1 Sample results The <br>query expansion</br> strategy implemented in UCAIR is intentionally conservative to avoid misinterpretation of implicit user models.",
                "In practice, whenever it chooses to expand the query, the expansion usually makes sense.",
                "In Table 1, we show how UCAIR can successfully distinguish two different search contexts for the query java map, corresponding to two different previous queries (i.e., travel Indonesia vs. hashtable).",
                "Due to implicit user modeling, UCAIR intelligently figures out to add Indonesia and class, respectively, to the users query java map, which would otherwise be ambiguous as shown in the original results from Google on March 21, 2005.",
                "UCAIRs results are much more accurate than Googles results and reflect personalization in search.",
                "The eager implicit feedback component is designed to immediately respond to a users activity such as viewing a document.",
                "In Figure 2, we show how UCAIR can successfully disambiguate an ambiguous query jaguar by exploiting a viewed document summary.",
                "In this case, the initial retrieval results using jaguar (shown on the left side) contain two results about the Jaguar cars followed by two results about the Jaguar software.",
                "However, after the user views the web page content of the second result (about Jaguar car) and returns to the search result page by clicking Back button, UCAIR automatically nominates two new search results about Jaguar cars (shown on the right side), while the original two results about Jaguar software are pushed down on the list (unseen from the picture). 5.2 Quantitative evaluation To further evaluate UCAIR quantitatively, we conduct a user study on the effectiveness of the eager implicit feedback component.",
                "It is a challenge to quantitatively evaluate the potential performance improvement of our proposed model and UCAIR over Google in an unbiased way [7].",
                "Here, we design a user study, in which participants would do normal web search and judge a randomly and anonymously mixed set of results from Google and UCAIR at the end of the search session; participants do not know whether a result comes from Google or UCAIR.",
                "We recruited 6 graduate students for this user study, who have different backgrounds (3 computer science, 2 biology, and 1 chem<top> <num> Number: 716 <title> Spammer arrest sue <desc> Description: Have any spammers been arrested or sued for sending unsolicited e-mail? <narr> Narrative: Instances of arrests, prosecutions, convictions, and punishments of spammers, and lawsuits against them are relevant.",
                "Documents which describe laws to limit spam without giving details of lawsuits or criminal trials are not relevant. </top> Figure 3: An example of TREC query topic, expressed in a form which might be given to a human assistant or librarian istry).",
                "We use query topics from TREC 2 2004 Terabyte track [2] and TREC 2003 Web track [4] topic distillation task in the way to be described below.",
                "An example topic from TREC 2004 Terabyte track appears in Figure 3.",
                "The title is a short phrase and may be used as a query to the retrieval system.",
                "The description field provides a slightly longer statement of the topic requirement, usually expressed as a single complete sentence or question.",
                "Finally the narrative supplies additional information necessary to fully specify the requirement, expressed in the form of a short paragraph.",
                "Initially, each participant would browse 50 topics either from Terabyte track or Web track and pick 5 or 7 most interesting topics.",
                "For each picked topic, the participant would essentially do the normal web search using UCAIR to find many relevant web pages by using the title of the query topic as the initial keyword query.",
                "During this process, the participant may view the search results and possibly click on some interesting ones to view the web pages, just as in a normal web search.",
                "There is no requirement or restriction on how many queries the participant must submit or when the participant should stop the search for one topic.",
                "When the participant plans to change the search topic, he/she will simply press a button 2 Text REtrieval Conference: http://trec.nist.gov/ 829 Figure 2: Screen shots for result reranking to evaluate the search results before actually switching to the next topic.",
                "At the time of evaluation, 30 top ranked results from Google and UCAIR (some are overlapping) are randomly mixed together so that the participant would not know whether a result comes from Google or UCAIR.",
                "The participant would then judge the relevance of these results.",
                "We measure precision at top n (n = 5, 10, 20, 30) documents of Google and UCAIR.",
                "We also evaluate precisions at different recall levels.",
                "Altogether, 368 documents judged as relevant from Google search results and 429 documents judged as relevant from UCAIR by participants.",
                "Scatter plots of precision at top 10 and top 20 documents are shown in Figure 4 and Figure 5 respectively (The scatter plot of precision at top 30 documents is very similar to precision at top 20 documents).",
                "Each point of the scatter plots represents the precisions of Google and UCAIR on one query topic.",
                "Table 2 shows the average precision at top n documents among 32 topics.",
                "From Figure 4, Figure 5 and Table 2, we see that the search results from UCAIR are consistently better than those from Google by all the measures.",
                "Moreover, the performance improvement is more dramatic for precision at top 20 documents than that at precision at top 10 documents.",
                "One explanation for this is that the more interaction the user has with the system, the more clickthrough data UCAIR can be expected to collect.",
                "Thus the retrieval system can build more precise implicit user models, which lead to better retrieval accuracy.",
                "Ranking Method prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Improvement 8.0% 17.8% 20.2% 21.8% Table 2: Table of average precision at top n documents for 32 query topics The plot in Figure 6 shows the precision-recall curves for UCAIR and Google, where it is clearly seen that the performance of UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Scatterplot of Precision at Top 10 Documents Figure 4: Precision at top 10 documents of UCAIR and Google is consistently and considerably better than that of Google at all levels of recall. 6.",
                "CONCLUSIONS In this paper, we studied how to exploit implicit user modeling to intelligently personalize information retrieval and improve search accuracy.",
                "Unlike most previous work, we emphasize the use of immediate search context and implicit feedback information as well as eager updating of search results to maximally benefit a user.",
                "We presented a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent (UCAIR) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Scatterplot of Precision at Top 20 documents Figure 5: Precision at top 20 documents of UCAIR and Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 recall precision Precision−Recall curves Google Result UCAIR Result Figure 6: Precision at top 20 result of UCAIR and Google Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "The developed search agent thus can improve existing web search performance without any additional effort from the user. 7.",
                "ACKNOWLEDGEMENT We thank the six participants of our evaluation experiments.",
                "This work was supported in part by the National Science Foundation grants IIS-0347933 and IIS-0428472. 8.",
                "REFERENCES [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman, and O. Frieder.",
                "Hourly analysis of a very large topically categorized web query log.",
                "In Proceedings of SIGIR 2004, pages 321-328, 2004. [2] C. Clarke, N. Craswell, and I. Soboroff.",
                "Overview of the TREC 2004 terabyte track.",
                "In Proceedings of TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda, and D. Brown.",
                "Implicit interest indicators.",
                "In Proceedings of Intelligent User Interfaces 2001, pages 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson, and M. Wu.",
                "Overview of the TREC 2003 web track.",
                "In Proceedings of TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend, and V. Larvrenko.",
                "Relevance feedback and personalization: A language modeling perspective.",
                "In Proeedings of Second DELOS Workshop: Personalisation and Recommender Systems in Digital Libraries, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite, and D. Harman.",
                "Results and challenges in web search evaluation.",
                "Computer Networks, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A.",
                "An, and D. Schuurmans.",
                "Dynamic web log session identification with statistical language models.",
                "Journal of the American Society for Information Science and Technology, 55(14):1290-1303, 2004. [9] G. Jeh and J. Widom.",
                "Scaling personalized web search.",
                "In Proceedings of WWW 2003, pages 271-279, 2003. [10] T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of SIGKDD 2002, pages 133-142, 2002. [11] D. Kelly and J. Teevan.",
                "Implicit feedback for inferring user preference: A bibliography.",
                "SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of SIGIR01, pages 111-119, 2001. [13] T. Lau and E. Horvitz.",
                "Patterns of search: Analyzing and modeling web query refinement.",
                "In Proceedings of the Seventh International Conference on User Modeling (UM), pages 145 -152, 1999. [14] V. Lavrenko and B. Croft.",
                "Relevance-based language models.",
                "In Proceedings of SIGIR01, pages 120-127, 2001. [15] M. Mitra, A. Singhal, and C. Buckley.",
                "Improving automatic <br>query expansion</br>.",
                "In Proceedings of SIGIR 1998, pages 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg.",
                "As google goes, so goes the nation.",
                "New York Times, May 2003. [18] S. E. Robertson.",
                "The probability ranking principle in ı˚.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] J. J. Rocchio.",
                "Relevance feedback in information retrieval.",
                "In The SMART Retrieval System: Experiments in Automatic Document Processing, pages 313-323.",
                "Prentice-Hall Inc., 1971. [20] G. Salton and C. Buckley.",
                "Improving retrieval performance by retrieval feedback.",
                "Journal of the American Society for Information Science, 41(4):288-297, 1990. [21] G. Salton and M. J. McGill.",
                "Introduction to Modern Information Retrieval.",
                "McGraw-Hill, 1983. [22] X. Shen, B. Tan, and C. Zhai.",
                "Context-sensitive information retrieval using implicit feedback.",
                "In Proceedings of SIGIR 2005, pages 43-50, 2005. [23] X. Shen and C. Zhai.",
                "Exploiting query history for document ranking in interactive information retrieval (Poster).",
                "In Proceedings of SIGIR 2003, pages 377-378, 2003. [24] A. Singhal.",
                "Modern information retrieval: A brief overview.",
                "Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano, and M. Yoshikawa.",
                "Adaptive web search based on user profile constructed without any effort from users.",
                "In Proceedings of WWW 2004, pages 675-684, 2004. [26] E. Volokh.",
                "Personalization and privacy.",
                "Communications of the ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen, and I. Ruthven.",
                "A simulated study of implicit feedback models.",
                "In Proceedings of ECIR 2004, pages 311-326, 2004. [28] J. Xu and W. B. Croft.",
                "<br>query expansion</br> using local and global document analysis.",
                "In Proceedings of SIGIR 1996, pages 4-11, 1996. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in KL divergence retrieval model.",
                "In Proceedings of the CIKM 2001, pages 403-410, 2001. 831"
            ],
            "original_annotated_samples": [
                "We develop an intelligent client-side web search agent (UCAIR) that can perform eager implicit feedback, e.g., <br>query expansion</br> based on previous queries and immediate result reranking based on clickthrough information.",
                "In [25], the clickthrough data collected over a long time period is exploited through <br>query expansion</br> to improve retrieval accuracy. 824 While a user may have general long term interests and preferences for information, often he/she is searching for documents to satisfy an ad-hoc information need, which only lasts for a short period of time; once the information need is satisfied, the user would generally no longer be interested in such information.",
                "UCAIR first judges whether two neighboring queries belong to the same information session and if so, it selects terms from the previous query to perform <br>query expansion</br>.",
                "Our <br>query expansion</br> approach is similar to automatic <br>query expansion</br> [28, 15, 5], but instead of using pseudo feedback to expand the query, we use users implicit feedback information to expand the current query.",
                "For this purpose, instead of performing <br>query expansion</br> as we did in the previous section, we could also compute an updated x∗ based on the previous query and retrieval results."
            ],
            "translated_annotated_samples": [
                "Desarrollamos un agente de búsqueda web inteligente del lado del cliente (UCAIR) que puede realizar retroalimentación implícita ansiosa, por ejemplo, <br>expansión de consultas</br> basada en consultas anteriores y reordenamiento inmediato de resultados basado en información de clics.",
                "En [25], los datos de clics recopilados durante un largo período de tiempo se utilizan a través de la <br>expansión de consultas</br> para mejorar la precisión de recuperación. Si bien un usuario puede tener intereses y preferencias generales a largo plazo para la información, a menudo está buscando documentos para satisfacer una necesidad de información ad-hoc, que solo dura un corto período de tiempo; una vez que se satisface la necesidad de información, el usuario generalmente ya no estaría interesado en esa información.",
                "UCAIR primero determina si dos consultas vecinas pertenecen a la misma sesión de información y, de ser así, selecciona términos de la consulta anterior para realizar la <br>expansión de la consulta</br>.",
                "Nuestro enfoque de <br>expansión de consultas</br> es similar a la expansión automática de consultas [28, 15, 5], pero en lugar de utilizar retroalimentación pseudo para expandir la consulta, utilizamos la información de retroalimentación implícita de los usuarios para expandir la consulta actual.",
                "Para este propósito, en lugar de realizar una <br>expansión de consulta</br> como lo hicimos en la sección anterior, también podríamos calcular un x∗ actualizado basado en la consulta anterior y los resultados de recuperación."
            ],
            "translated_text": "Modelado implícito de usuarios para búsqueda personalizada Xuehua Shen, Bin Tan, ChengXiang Zhai Departamento de Ciencias de la Computación Universidad de Illinois en Urbana-Champaign RESUMEN Los sistemas de recuperación de información (por ejemplo, motores de búsqueda web) son críticos para superar la sobrecarga de información. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales, lo que resulta en un rendimiento de recuperación inherentemente no óptimo. Por ejemplo, un turista y un programador pueden usar la misma palabra \"java\" para buscar información diferente, pero los sistemas de búsqueda actuales devolverían los mismos resultados. En este artículo, estudiamos cómo inferir el interés de un usuario a partir del contexto de búsqueda del usuario y utilizar el modelo de usuario implícito inferido para la búsqueda personalizada. Presentamos un marco teórico de toma de decisiones y desarrollamos técnicas para el modelado implícito del usuario en la recuperación de información. Desarrollamos un agente de búsqueda web inteligente del lado del cliente (UCAIR) que puede realizar retroalimentación implícita ansiosa, por ejemplo, <br>expansión de consultas</br> basada en consultas anteriores y reordenamiento inmediato de resultados basado en información de clics. Los experimentos sobre la búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda sobre el popular motor de búsqueda Google. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación, Retroalimentación de relevancia, Proceso de búsqueda Términos Generales Algoritmos 1. Aunque muchos sistemas de recuperación de información (por ejemplo, motores de búsqueda web y sistemas de biblioteca digital) se han implementado con éxito, los sistemas de recuperación actuales están lejos de ser óptimos. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales [17]. Esta no optimalidad inherente se ve claramente en los siguientes dos casos: (1) Diferentes usuarios pueden utilizar exactamente la misma consulta (por ejemplo, Java) para buscar información diferente (por ejemplo, la isla de Java en Indonesia o el lenguaje de programación Java), pero los sistemas de IR existentes devuelven los mismos resultados para estos usuarios. Sin considerar al usuario actual, es imposible saber a qué sentido se refiere Java en una consulta. (2) Las necesidades de información de un usuario pueden cambiar con el tiempo. El mismo usuario puede usar Java a veces para referirse a la isla de Java en Indonesia y otras veces para referirse al lenguaje de programación. Sin reconocer el contexto de búsqueda, sería nuevamente imposible reconocer el sentido correcto. Para optimizar la precisión de la recuperación, claramente necesitamos modelar al usuario de manera adecuada y personalizar la búsqueda según cada usuario individual. El objetivo principal del modelado de usuario para la recuperación de información es modelar con precisión la necesidad de información de un usuario, lo cual, desafortunadamente, es una tarea muy difícil. De hecho, incluso resulta difícil para un usuario describir con precisión cuál es su necesidad de información. ¿Qué información está disponible para que un sistema pueda inferir la necesidad de información de un usuario? Obviamente, la consulta de los usuarios proporciona la evidencia más directa. De hecho, la mayoría de los sistemas de recuperación existentes se basan únicamente en la consulta para modelar la necesidad de información de los usuarios. Sin embargo, dado que una consulta suele ser extremadamente corta, el modelo de usuario construido basado en una consulta de palabras clave inevitablemente resulta empobrecido. Una forma efectiva de mejorar la modelización de usuarios en la recuperación de información es pedir al usuario que especifique explícitamente qué documentos son relevantes (es decir, útiles para satisfacer su necesidad de información) y luego mejorar la modelización de usuarios basándose en ejemplos de documentos relevantes. Esto se llama retroalimentación de relevancia, lo cual ha demostrado ser bastante efectivo para mejorar la precisión de recuperación [19, 20]. Desafortunadamente, en aplicaciones del mundo real, los usuarios suelen ser reacios a hacer el esfuerzo adicional de proporcionar ejemplos relevantes para retroalimentación [11]. Por lo tanto, es muy interesante estudiar cómo inferir la necesidad de información de un usuario basándose en cualquier información de retroalimentación implícita, la cual existe naturalmente a través de las interacciones del usuario y no requiere ningún esfuerzo adicional por parte del usuario. De hecho, varios estudios previos han demostrado que el modelado implícito del usuario puede mejorar la precisión de recuperación. En [3], se desarrolla un navegador web (Curious Browser) para registrar las calificaciones explícitas de relevancia de las páginas web por parte de los usuarios (retroalimentación de relevancia) y el comportamiento de navegación al ver una página, como el tiempo de permanencia, clics de ratón, movimiento del ratón y desplazamiento (retroalimentación implícita). Se muestra que el tiempo de permanencia en una página, la cantidad de desplazamiento en una página y la combinación de tiempo y desplazamiento tienen una fuerte correlación con las calificaciones de relevancia explícita, lo que sugiere que la retroalimentación implícita puede ser útil para inferir la necesidad de información del usuario. En [10], se recopilan datos de clics de usuario como datos de entrenamiento para aprender una función de recuperación, que se utiliza para producir un ranking personalizado de resultados de búsqueda que se adapte a las preferencias de un grupo de usuarios. En [25], los datos de clics recopilados durante un largo período de tiempo se utilizan a través de la <br>expansión de consultas</br> para mejorar la precisión de recuperación. Si bien un usuario puede tener intereses y preferencias generales a largo plazo para la información, a menudo está buscando documentos para satisfacer una necesidad de información ad-hoc, que solo dura un corto período de tiempo; una vez que se satisface la necesidad de información, el usuario generalmente ya no estaría interesado en esa información. Por ejemplo, un usuario puede estar buscando información sobre autos usados para comprar uno, pero una vez que el usuario ha comprado un auto, generalmente ya no está interesado en esa información. En tales casos, la información de retroalimentación implícita recopilada durante un largo período de tiempo es poco probable que sea muy útil, pero el contexto de búsqueda inmediato y la información de retroalimentación, como cuáles de los resultados de búsqueda para la necesidad de información actual son vistos, se espera que sean mucho más útiles. Considera la consulta de Java nuevamente. Cualquiera de la siguiente información de retroalimentación inmediata sobre el usuario podría potencialmente ayudar a determinar el significado previsto de Java en la consulta: (1) La consulta anterior enviada por el usuario es hashtable (en lugar de, por ejemplo, viajar a Indonesia). (2) En los resultados de búsqueda, el usuario visualizó una página donde palabras como programación, software y applet ocurren muchas veces. Hasta donde sabemos, cómo aprovechar este contexto de búsqueda inmediato y a corto plazo para mejorar la búsqueda aún no ha sido abordado de manera satisfactoria en trabajos anteriores. En este artículo, estudiamos cómo construir y actualizar un modelo de usuario basado en el contexto de búsqueda inmediato y la información de retroalimentación implícita, y utilizar el modelo para mejorar la precisión de la recuperación ad-hoc. Para beneficiar al máximo al usuario de un sistema de recuperación a través de modelado implícito del usuario, proponemos realizar retroalimentación implícita entusiasta. Es decir, tan pronto como observemos cualquier nueva pieza de evidencia del usuario, actualizaríamos la creencia del sistema sobre la necesidad de información del usuario y responderíamos con resultados de recuperación mejorados basados en el modelo de usuario actualizado. Presentamos un marco de trabajo de teoría de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. En un paradigma de recuperación tradicional, el problema de recuperación consiste en emparejar una consulta con documentos y clasificar los documentos según sus valores de relevancia. Como resultado, el proceso de recuperación es un ciclo independiente simple de consulta y visualización de resultados. En el nuevo paradigma de recuperación propuesto, el contexto de búsqueda de los usuarios juega un papel importante y el modelo de usuario implícito inferido se explota inmediatamente para beneficiar al usuario. El nuevo paradigma de recuperación es, por lo tanto, fundamentalmente diferente del paradigma tradicional y es inherentemente más general. Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos apropiados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para reordenar inmediatamente cualquier documento que aún no haya sido visto por el usuario. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente UCAIR (Recuperación de Información Adaptativa Centrada en el Usuario) sobre un motor de búsqueda popular (Google). Los experimentos sobre búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en comparación con Google. Dado que la información implícita que explotamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional. Por lo tanto, el agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin esfuerzo adicional por parte del usuario. Las secciones restantes están organizadas de la siguiente manera. En la Sección 2, discutimos el trabajo relacionado. En la Sección 3, presentamos un marco de recuperación interactiva basado en teoría de decisiones para modelado implícito de usuarios. En la Sección 4, presentamos el diseño e implementación de un agente de búsqueda web inteligente del lado del cliente (UCAIR) que realiza retroalimentación implícita ansiosa. En la Sección 5, informamos nuestros resultados experimentales utilizando el agente de búsqueda. La sección 6 concluye nuestro trabajo. 2. El modelado implícito del usuario para la búsqueda personalizada ha sido estudiado en trabajos anteriores, pero nuestro trabajo difiere de todos los trabajos anteriores en varios aspectos: (1) Enfatizamos la explotación del contexto de búsqueda inmediato, como la consulta inmediatamente anterior relacionada y los documentos vistos en la misma sesión, mientras que la mayoría de los trabajos anteriores se basan en la recopilación a largo plazo de información de retroalimentación implícita [25]. (2) Realizamos una retroalimentación activa y obtenemos el beneficio del modelado implícito del usuario tan pronto como esté disponible cualquier nueva información de retroalimentación implícita, mientras que el trabajo anterior mayormente explota la retroalimentación implícita a largo plazo [10]. (3) Proponemos un marco de recuperación para integrar el modelado implícito del usuario con el proceso interactivo de recuperación, mientras que el trabajo anterior estudia el modelado implícito del usuario por separado de la recuperación [3] o solo estudia modelos de recuperación específicos para explotar la retroalimentación implícita para mejorar la coincidencia de una consulta con documentos [23, 27, 22]. (4) Desarrollamos y evaluamos un agente de búsqueda web personalizado con estudios de usuario en línea, mientras que la mayoría de los trabajos existentes evalúan algoritmos fuera de línea sin interacciones reales de usuarios. Actualmente algunos motores de búsqueda ofrecen personalización rudimentaria, como la búsqueda web personalizada de Google [6], que permite a los usuarios describir explícitamente sus intereses seleccionando entre temas predefinidos, de modo que los resultados que coinciden con sus intereses se muestren en la parte superior, y la búsqueda de My Yahoo! [16], que brinda a los usuarios la opción de guardar los sitios web que les gustan y bloquear aquellos que no les gustan. Por el contrario, UCAIR personaliza la búsqueda web a través de la modelización implícita del usuario sin necesidad de esfuerzos adicionales por parte del usuario. Además, la personalización de UCAIR se proporciona en el lado del cliente. Hay dos ventajas notables en esto. Primero, el usuario no necesita preocuparse por la infracción de privacidad, que es una gran preocupación para la búsqueda personalizada [26]. En segundo lugar, tanto el cálculo de la personalización como el almacenamiento del perfil del usuario se realizan en el lado del cliente para reducir drásticamente la carga del servidor [9]. Ha habido muchos trabajos estudiando los registros de consultas de usuarios [1] o la dinámica de consultas [13]. UCAIR hace uso directo del historial de consultas de un usuario para beneficiar al mismo usuario de inmediato en la misma sesión de búsqueda. UCAIR primero determina si dos consultas vecinas pertenecen a la misma sesión de información y, de ser así, selecciona términos de la consulta anterior para realizar la <br>expansión de la consulta</br>. Nuestro enfoque de <br>expansión de consultas</br> es similar a la expansión automática de consultas [28, 15, 5], pero en lugar de utilizar retroalimentación pseudo para expandir la consulta, utilizamos la información de retroalimentación implícita de los usuarios para expandir la consulta actual. Estas dos técnicas pueden ser combinadas. 3. OPTIMIZACIÓN EN IR INTERACTIVO En IR interactivo, un usuario interactúa con el sistema de recuperación a través de un diálogo de acción, en el cual el sistema responde a cada acción del usuario con alguna acción del sistema. Por ejemplo, la acción de los usuarios puede ser enviar una consulta y la respuesta del sistema puede ser devolver una lista de 10 resúmenes de documentos. En general, el espacio de acciones del usuario y respuestas del sistema y sus granularidades dependerían de la interfaz de un sistema de recuperación particular. En principio, cada acción del usuario puede potencialmente proporcionar nuevas pruebas para ayudar al sistema a inferir mejor la necesidad de información del usuario. Por lo tanto, para responder de manera óptima, el sistema debería utilizar toda la evidencia recopilada hasta ahora sobre el usuario al elegir una respuesta. Cuando se ven de esta manera, la mayoría de los motores de búsqueda existentes son claramente no óptimos. Por ejemplo, si un usuario ha visto algunos documentos en la primera página de resultados de búsqueda, cuando el usuario hace clic en el enlace Siguiente para obtener más resultados, un sistema de recuperación existente seguiría devolviendo la siguiente página de resultados recuperados en función de la consulta original sin considerar la nueva evidencia de que un resultado en particular ha sido visto por el usuario. Proponemos optimizar el rendimiento de la recuperación adaptando las respuestas del sistema en función de cada acción que un usuario haya tomado, y planteamos el problema de optimización como una tarea de decisión. Específicamente, en cualquier momento, el sistema intentaría realizar dos tareas: (1) Actualización del modelo de usuario: Monitorear cualquier evidencia útil del usuario con respecto a su necesidad de información y actualizar el modelo de usuario tan pronto como esta evidencia esté disponible; (2) Mejorar los resultados de búsqueda: Reclasificar inmediatamente todos los documentos que el usuario aún no ha visto, tan pronto como se actualice el modelo de usuario. Enfatizamos la actualización y reordenamiento entusiastas, lo que hace que nuestro trabajo sea bastante diferente a cualquier trabajo existente. A continuación presentamos un marco formal de teoría de decisiones para optimizar el rendimiento de recuperación a través de la modelización implícita del usuario en la recuperación de información interactiva. 3.1 Un marco de teoría de decisiones Sea A el conjunto de todas las acciones del usuario y R(a) el conjunto de todas las posibles respuestas del sistema a una acción del usuario a ∈ A. En cualquier momento, sea At = (a1, ..., at) la secuencia observada de acciones de usuario hasta ahora (hasta el momento t) y Rt−1 = (r1, ..., rt−1) las respuestas que el sistema ha dado en respuesta a las acciones del usuario. El objetivo del sistema es elegir una respuesta óptima rt ∈ R(at) para la acción actual del usuario at. Sea M el espacio de todos los posibles modelos de usuario. Definimos además una función de pérdida L(a, r, m) ∈ , donde a ∈ A es una acción del usuario, r ∈ R(a) es una respuesta del sistema, y m ∈ M es un modelo de usuario. L(a, r, m) codifica nuestras preferencias de decisión y evalúa la optimalidad de responder con r cuando el modelo de usuario actual es m y la acción de usuario actual es a. Según la teoría de decisión bayesiana, la decisión óptima en el tiempo t es elegir una respuesta que minimice el riesgo de Bayes, es decir, r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) donde P(mt|U, D, At, Rt−1) es la probabilidad posterior del modelo de usuario mt dadas todas las observaciones sobre el usuario U que hemos realizado hasta el tiempo t. Para simplificar el cálculo de la Ecuación 1, asumamos que la masa de probabilidad posterior P(mt|U, D, At, Rt−1) está principalmente concentrada en el modo m∗ t = argmaxmt P(mt|U, D, At, Rt−1). Podemos entonces aproximar la integral con el valor de la función de pérdida en m∗ t. Es decir, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) donde m∗ t = argmaxmt P(mt|U, D, At, Rt−1). Dejando de lado cómo definir y estimar estos modelos probabilísticos y la función de pérdida, podemos ver que tal formulación de la teoría de decisiones sugiere que, para elegir la respuesta óptima a at, el sistema debería realizar dos tareas: (1) calcular el modelo de usuario actual y obtener m∗ t basado en toda la información útil. (2) elegir una respuesta rt para minimizar el valor de la función de pérdida L(at, rt, m∗ t). Cuando at no afecta nuestra creencia sobre m∗ t , el primer paso puede omitirse y podemos reutilizar m∗ t−1 para m∗ t . Ten en cuenta que nuestro marco de trabajo es bastante general, ya que potencialmente podemos modelar cualquier tipo de acciones de usuario y respuestas del sistema. En la mayoría de los casos, como podríamos esperar, la respuesta del sistema es algún tipo de clasificación de documentos, es decir, para la mayoría de las acciones a, R(a) consiste en todas las posibles clasificaciones de los documentos no vistos, y el problema de decisión se reduce a elegir la mejor clasificación de los documentos no vistos basándose en el modelo de usuario más actualizado. Cuando a es la acción de enviar una consulta de palabras clave, tal respuesta es exactamente lo que haría un sistema de recuperación actual. Sin embargo, fácilmente podemos imaginar que un motor de búsqueda web más inteligente respondería al clic del usuario en el enlace Siguiente (para obtener más resultados no vistos) con una clasificación más optimizada de documentos basada en cualquier documento visto en la página actual de resultados. De hecho, según nuestra estrategia de actualización entusiasta, incluso podríamos permitir que un sistema responda al clic del botón Atrás del navegador por parte de un usuario después de ver un documento de la misma manera, para que el usuario pueda beneficiarse al máximo de la retroalimentación implícita. Estos son precisamente lo que nuestro sistema UCAIR hace. 3.2 Modelos de usuario Un modelo de usuario m ∈ M representa lo que sabemos sobre el usuario U, por lo que en principio, puede contener cualquier información sobre el usuario que deseemos modelar. Ahora discutimos dos componentes importantes en un modelo de usuario. El primer componente es un modelo de componente de la necesidad de información de los usuarios. Presumiblemente, el factor más importante que afecta la optimalidad de la respuesta del sistema es qué tan bien la respuesta aborda la necesidad de información de los usuarios. De hecho, en cualquier momento, podemos asumir que el sistema tiene alguna creencia sobre lo que le interesa al usuario, la cual modelamos a través de un vector de términos x = (x1, ..., x|V|), donde V = {w1, ..., w|V|} es el conjunto de todos los términos (es decir, vocabulario) y xi es el peso del término wi. Un vector de términos de este tipo se utiliza comúnmente en la recuperación de información para representar tanto consultas como documentos. Por ejemplo, el modelo de espacio vectorial asume que tanto la consulta como los documentos se representan como vectores de términos y que la puntuación de un documento con respecto a una consulta se calcula en función de la similitud entre el vector de la consulta y el vector del documento [21]. En un enfoque de modelado de lenguaje, también podemos considerar el modelo de lenguaje unigrama de consulta [12, 29] o el modelo de relevancia [14] como una representación vectorial de términos de la necesidad de información de los usuarios. Intuitivamente, x asignaría pesos altos a los términos que caracterizan los temas que interesan al usuario. El segundo componente que podemos incluir en nuestro modelo de usuario son los documentos que el usuario ya ha visto. Obviamente, incluso si un documento es relevante, si el usuario ya ha visto el documento, no sería útil presentar el mismo documento de nuevo. Por lo tanto, introducimos otra variable S ⊂ D (D es el conjunto completo de documentos en la colección) para denotar el subconjunto de documentos en los resultados de búsqueda que el usuario ya ha visto. En general, en el tiempo t, podemos representar un modelo de usuario como mt = (S, x, At, Rt−1), donde S son los documentos vistos, x es la comprensión del sistema de la necesidad de información del usuario, y (At, Rt−1) representa el historial de interacción del usuario. Ten en cuenta que un modelo de usuario aún más general también puede incluir otros factores como el nivel de lectura y la ocupación de los usuarios. Si asumimos que la incertidumbre de un modelo de usuario mt se debe únicamente a la incertidumbre de x, el cálculo de nuestra estimación actual del modelo de usuario m∗ t implicará principalmente calcular nuestra mejor estimación de x. Es decir, el sistema elegiría una respuesta de acuerdo a r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) donde x∗ = argmaxx P(x|U, D, At, Rt−1). Este es el mecanismo de decisión implementado en el sistema UCAIR que se describirá más adelante. En este sistema, evitamos especificar el modelo probabilístico P(x|U, D, At, Rt−1) calculando x∗ directamente con algún método de retroalimentación existente. 3.3 Funciones de pérdida La definición exacta de la función de pérdida L depende de las respuestas, por lo que es inevitablemente específica de la aplicación. Ahora discutimos brevemente algunas posibilidades cuando la respuesta es clasificar todos los documentos no vistos y presentar los mejores k de ellos. Sea r = (d1, ..., dk) los k documentos principales, S el conjunto de documentos vistos por el usuario, y x∗ la mejor suposición del sistema sobre la necesidad de información del usuario. Podemos definir simplemente la pérdida asociada con r como la suma negativa de la probabilidad de que cada uno de los di sea relevante, es decir, L(a, r, m) = − k i=1 P(relevante|di, m). Claramente, para minimizar esta función de pérdida, la respuesta óptima r contendría los k documentos con la probabilidad más alta de relevancia, lo cual es intuitivamente razonable. Una deficiencia de esta función de pérdida top-k es que no es sensible al orden interno de los documentos top k seleccionados, por lo que cambiar el orden de clasificación de un documento no relevante y uno relevante no afectaría la pérdida, lo cual es irrazonable. Para modelar el ranking, podemos introducir un factor del modelo de usuario: la probabilidad de que cada uno de los k documentos sea visto por el usuario, P(vista|di), y definir la siguiente función de pérdida de ranking: L(a, r, m) = − k i=1 P(vista|di)P(relevante|di, m). Dado que, en general, si di está clasificado por encima de dj (es decir, i < j), P(vista|di) > P(vista|dj), esta función de pérdida favorecería una decisión de clasificar documentos relevantes por encima de los no relevantes, ya que de lo contrario, siempre podríamos intercambiar di con dj para reducir el valor de pérdida. Por lo tanto, el sistema simplemente debería realizar una recuperación regular y clasificar los documentos según la probabilidad de relevancia [18]. Dependiendo de las preferencias de recuperación de los usuarios, puede haber muchas otras posibilidades. Por ejemplo, si el usuario no desea ver documentos redundantes, la función de pérdida debería incluir alguna medida de redundancia en r basada en los documentos ya vistos S. Por supuesto, cuando la respuesta no es elegir una lista clasificada de documentos, necesitaríamos una función de pérdida diferente. Discutimos un ejemplo relevante para el agente de búsqueda que implementamos. Cuando un usuario ingresa una consulta qt (acción actual), nuestro agente de búsqueda se basa en algún motor de búsqueda existente para llevar a cabo la búsqueda en realidad. En tal caso, aunque el agente de búsqueda no tenga control sobre el algoritmo de recuperación, aún puede intentar optimizar los resultados de la búsqueda refinando la consulta enviada al motor de búsqueda y/o reordenando los resultados obtenidos del motor de búsqueda. Las funciones de pérdida para el reordenamiento ya fueron discutidas anteriormente; ahora echamos un vistazo a las funciones de pérdida para el refinamiento de consultas. Sea f la función de recuperación del motor de búsqueda que nuestro agente utiliza, de modo que f(q) nos daría los resultados de búsqueda utilizando la consulta q. Dado que la acción actual del usuario es ingresar una consulta qt (es decir, at = qt), nuestra respuesta sería f(q) para algún q. Dado que no tenemos elección de f, nuestra decisión es elegir un buen q. Formalmente, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) lo cual muestra que nuestro objetivo es encontrar q∗ = argminqL(qt, f(q), m), es decir, una consulta óptima que nos daría el mejor f(q). Una elección diferente de la función de pérdida L(qt, f(q), m) llevaría a una estrategia de refinamiento de consulta diferente. En UCAIR, calculamos heurísticamente q∗ expandiendo qt con términos extraídos de rt−1 siempre que qt−1 y qt tengan una alta similitud. Se debe tener en cuenta que rt−1 y qt−1 están contenidos en m como parte del historial de interacción de los usuarios. 3.4 Modelado implícito del usuario El modelado implícito del usuario se captura en nuestro marco a través del cálculo de x∗ = argmaxx P(x|U, D, At, Rt−1), es decir, la creencia actual del sistema sobre cuál es la necesidad de información del usuario. Aquí nuevamente puede haber muchas posibilidades, lo que lleva a diferentes algoritmos para la modelización implícita del usuario. Ahora discutimos algunos de ellos. Primero, cuando dos consultas consecutivas están relacionadas, la consulta anterior puede ser explotada para enriquecer la consulta actual y proporcionar más contexto de búsqueda para ayudar en la desambiguación. Para este propósito, en lugar de realizar una <br>expansión de consulta</br> como lo hicimos en la sección anterior, también podríamos calcular un x∗ actualizado basado en la consulta anterior y los resultados de recuperación. ",
            "candidates": [],
            "error": [
                [
                    "expansión de consultas",
                    "expansión de consultas",
                    "expansión de la consulta",
                    "expansión de consultas",
                    "expansión de consulta"
                ]
            ]
        },
        "search accuracy": {
            "translated_key": "precisión de la búsqueda",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Implicit User Modeling for Personalized Search Xuehua Shen, Bin Tan, ChengXiang Zhai Department of Computer Science University of Illinois at Urbana-Champaign ABSTRACT Information retrieval systems (e.g., web search engines) are critical for overcoming information overload.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users, resulting in inherently non-optimal retrieval performance.",
                "For example, a tourist and a programmer may use the same word java to search for different information, but the current search systems would return the same results.",
                "In this paper, we study how to infer a users interest from the users search context and use the inferred implicit user model for personalized search .",
                "We present a decision theoretic framework and develop techniques for implicit user modeling in information retrieval.",
                "We develop an intelligent client-side web search agent (UCAIR) that can perform eager implicit feedback, e.g., query expansion based on previous queries and immediate result reranking based on clickthrough information.",
                "Experiments on web search show that our search agent can improve <br>search accuracy</br> over the popular Google search engine.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models, Relevance feedback, Search Process General Terms Algorithms 1.",
                "INTRODUCTION Although many information retrieval systems (e.g., web search engines and digital library systems) have been successfully deployed, the current retrieval systems are far from optimal.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users [17].",
                "This inherent non-optimality is seen clearly in the following two cases: (1) Different users may use exactly the same query (e.g., Java) to search for different information (e.g., the Java island in Indonesia or the Java programming language), but existing IR systems return the same results for these users.",
                "Without considering the actual user, it is impossible to know which sense Java refers to in a query. (2) A users information needs may change over time.",
                "The same user may use Java sometimes to mean the Java island in Indonesia and some other times to mean the programming language.",
                "Without recognizing the search context, it would be again impossible to recognize the correct sense.",
                "In order to optimize retrieval accuracy, we clearly need to model the user appropriately and personalize search according to each individual user.",
                "The major goal of user modeling for information retrieval is to accurately model a users information need, which is, unfortunately, a very difficult task.",
                "Indeed, it is even hard for a user to precisely describe what his/her information need is.",
                "What information is available for a system to infer a users information need?",
                "Obviously, the users query provides the most direct evidence.",
                "Indeed, most existing retrieval systems rely solely on the query to model a users information need.",
                "However, since a query is often extremely short, the user model constructed based on a keyword query is inevitably impoverished .",
                "An effective way to improve user modeling in information retrieval is to ask the user to explicitly specify which documents are relevant (i.e., useful for satisfying his/her information need), and then to improve user modeling based on such examples of relevant documents.",
                "This is called relevance feedback, which has been proved to be quite effective for improving retrieval accuracy [19, 20].",
                "Unfortunately, in real world applications, users are usually reluctant to make the extra effort to provide relevant examples for feedback [11].",
                "It is thus very interesting to study how to infer a users information need based on any implicit feedback information, which naturally exists through user interactions and thus does not require any extra user effort.",
                "Indeed, several previous studies have shown that implicit user modeling can improve retrieval accuracy.",
                "In [3], a web browser (Curious Browser) is developed to record a users explicit relevance ratings of web pages (relevance feedback) and browsing behavior when viewing a page, such as dwelling time, mouse click, mouse movement and scrolling (implicit feedback).",
                "It is shown that the dwelling time on a page, amount of scrolling on a page and the combination of time and scrolling have a strong correlation with explicit relevance ratings, which suggests that implicit feedback may be helpful for inferring user information need.",
                "In [10], user clickthrough data is collected as training data to learn a retrieval function, which is used to produce a customized ranking of search results that suits a group of users preferences.",
                "In [25], the clickthrough data collected over a long time period is exploited through query expansion to improve retrieval accuracy. 824 While a user may have general long term interests and preferences for information, often he/she is searching for documents to satisfy an ad-hoc information need, which only lasts for a short period of time; once the information need is satisfied, the user would generally no longer be interested in such information.",
                "For example, a user may be looking for information about used cars in order to buy one, but once the user has bought a car, he/she is generally no longer interested in such information.",
                "In such cases, implicit feedback information collected over a long period of time is unlikely to be very useful, but the immediate search context and feedback information, such as which of the search results for the current information need are viewed, can be expected to be much more useful.",
                "Consider the query Java again.",
                "Any of the following immediate feedback information about the user could potentially help determine the intended meaning of Java in the query: (1) The previous query submitted by the user is hashtable (as opposed to, e.g., travel Indonesia). (2) In the search results, the user viewed a page where words such as programming, software, and applet occur many times.",
                "To the best of our knowledge, how to exploit such immediate and short-term search context to improve search has so far not been well addressed in the previous work.",
                "In this paper, we study how to construct and update a user model based on the immediate search context and implicit feedback information and use the model to improve the accuracy of ad-hoc retrieval.",
                "In order to maximally benefit the user of a retrieval system through implicit user modeling, we propose to perform eager implicit feedback.",
                "That is, as soon as we observe any new piece of evidence from the user, we would update the systems belief about the users information need and respond with improved retrieval results based on the updated user model.",
                "We present a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "In a traditional retrieval paradigm, the retrieval problem is to match a query with documents and rank documents according to their relevance values.",
                "As a result, the retrieval process is a simple independent cycle of query and result display.",
                "In the proposed new retrieval paradigm, the users search context plays an important role and the inferred implicit user model is exploited immediately to benefit the user.",
                "The new retrieval paradigm is thus fundamentally different from the traditional paradigm, and is inherently more general.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent UCAIR (User-Centered Adaptive Information Retrieval) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve <br>search accuracy</br> over Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "Thus the developed search agent can improve existing web search performance without additional effort from the user.",
                "The remaining sections are organized as follows.",
                "In Section 2, we discuss the related work.",
                "In Section 3, we present a decisiontheoretic interactive retrieval framework for implicit user modeling.",
                "In Section 4, we present the design and implementation of an intelligent client-side web search agent (UCAIR) that performs eager implicit feedback.",
                "In Section 5, we report our experiment results using the search agent.",
                "Section 6 concludes our work. 2.",
                "RELATED WORK Implicit user modeling for personalized search has been studied in previous work, but our work differs from all previous work in several aspects: (1) We emphasize the exploitation of immediate search context such as the related immediately preceding query and the viewed documents in the same session, while most previous work relies on long-term collection of implicit feedback information [25]. (2) We perform eager feedback and bring the benefit of implicit user modeling as soon as any new implicit feedback information is available, while the previous work mostly exploits longterm implicit feedback [10]. (3) We propose a retrieval framework to integrate implicit user modeling with the interactive retrieval process, while the previous work either studies implicit user modeling separately from retrieval [3] or only studies specific retrieval models for exploiting implicit feedback to better match a query with documents [23, 27, 22]. (4) We develop and evaluate a personalized Web search agent with online user studies, while most existing work evaluates algorithms offline without real user interactions.",
                "Currently some search engines provide rudimentary personalization, such as Google Personalized web search [6], which allows users to explicitly describe their interests by selecting from predefined topics, so that those results that match their interests are brought to the top, and My Yahoo! search [16], which gives users the option to save web sites they like and block those they dislike.",
                "In contrast, UCAIR personalizes web search through implicit user modeling without any additional user efforts.",
                "Furthermore, the personalization of UCAIR is provided on the client side.",
                "There are two remarkable advantages on this.",
                "First, the user does not need to worry about the privacy infringement, which is a big concern for personalized search [26].",
                "Second, both the computation of personalization and the storage of the user profile are done at the client side so that the server load is reduced dramatically [9].",
                "There have been many works studying user query logs [1] or query dynamics [13].",
                "UCAIR makes direct use of a users query history to benefit the same user immediately in the same search session.",
                "UCAIR first judges whether two neighboring queries belong to the same information session and if so, it selects terms from the previous query to perform query expansion.",
                "Our query expansion approach is similar to automatic query expansion [28, 15, 5], but instead of using pseudo feedback to expand the query, we use users implicit feedback information to expand the current query.",
                "These two techniques may be combined. 3.",
                "OPTIMIZATION IN INTERACTIVE IR In interactive IR, a user interacts with the retrieval system through an action dialogue, in which the system responds to each user action with some system action.",
                "For example, the users action may be submitting a query and the systems response may be returning a list of 10 document summaries.",
                "In general, the space of user actions and system responses and their granularities would depend on the interface of a particular retrieval system.",
                "In principle, every action of the user can potentially provide new evidence to help the system better infer the users information need.",
                "Thus in order to respond optimally, the system should use all the evidence collected so far about the user when choosing a response.",
                "When viewed in this way, most existing search engines are clearly non-optimal.",
                "For example, if a user has viewed some documents on the first page of search results, when the user clicks on the Next link to fetch more results, an existing retrieval system would still return the next page of results retrieved based on the original query without considering the new evidence that a particular result has been viewed by the user. 825 We propose to optimize retrieval performance by adapting system responses based on every action that a user has taken, and cast the optimization problem as a decision task.",
                "Specifically, at any time, the system would attempt to do two tasks: (1) User model updating: Monitor any useful evidence from the user regarding his/her information need and update the user model as soon as such evidence is available; (2) Improving search results: Rerank immediately all the documents that the user has not yet seen, as soon as the user model is updated.",
                "We emphasize eager updating and reranking, which makes our work quite different from any existing work.",
                "Below we present a formal decision theoretic framework for optimizing retrieval performance through implicit user modeling in interactive information retrieval. 3.1 A decision-theoretic framework Let A be the set of all user actions and R(a) be the set of all possible system responses to a user action a ∈ A.",
                "At any time, let At = (a1, ..., at) be the observed sequence of user actions so far (up to time point t) and Rt−1 = (r1, ..., rt−1) be the responses that the system has made responding to the user actions.",
                "The systems goal is to choose an optimal response rt ∈ R(at) for the current user action at.",
                "Let M be the space of all possible user models.",
                "We further define a loss function L(a, r, m) ∈ , where a ∈ A is a user action, r ∈ R(a) is a system response, and m ∈ M is a user model.",
                "L(a, r, m) encodes our decision preferences and assesses the optimality of responding with r when the current user model is m and the current user action is a.",
                "According to Bayesian decision theory, the optimal decision at time t is to choose a response that minimizes the Bayes risk, i.e., r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) where P(mt|U, D, At, Rt−1) is the posterior probability of the user model mt given all the observations about the user U we have made up to time t. To simplify the computation of Equation 1, let us assume that the posterior probability mass P(mt|U, D, At, Rt−1) is mostly concentrated on the mode m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "We can then approximate the integral with the value of the loss function at m∗ t .",
                "That is, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) where m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "Leaving aside how to define and estimate these probabilistic models and the loss function, we can see that such a decision-theoretic formulation suggests that, in order to choose the optimal response to at, the system should perform two tasks: (1) compute the current user model and obtain m∗ t based on all the useful information. (2) choose a response rt to minimize the loss function value L(at, rt, m∗ t ).",
                "When at does not affect our belief about m∗ t , the first step can be omitted and we may reuse m∗ t−1 for m∗ t .",
                "Note that our framework is quite general since we can potentially model any kind of user actions and system responses.",
                "In most cases, as we may expect, the systems response is some ranking of documents, i.e., for most actions a, R(a) consists of all the possible rankings of the unseen documents, and the decision problem boils down to choosing the best ranking of unseen documents based on the most current user model.",
                "When a is the action of submitting a keyword query, such a response is exactly what a current retrieval system would do.",
                "However, we can easily imagine that a more intelligent web search engine would respond to a users clicking of the Next link (to fetch more unseen results) with a more optimized ranking of documents based on any viewed documents in the current page of results.",
                "In fact, according to our eager updating strategy, we may even allow a system to respond to a users clicking of browsers Back button after viewing a document in the same way, so that the user can maximally benefit from implicit feedback.",
                "These are precisely what our UCAIR system does. 3.2 User models A user model m ∈ M represents what we know about the user U, so in principle, it can contain any information about the user that we wish to model.",
                "We now discuss two important components in a user model.",
                "The first component is a component model of the users information need.",
                "Presumably, the most important factor affecting the optimality of the systems response is how well the response addresses the users information need.",
                "Indeed, at any time, we may assume that the system has some belief about what the user is interested in, which we model through a term vector x = (x1, ..., x|V |), where V = {w1, ..., w|V |} is the set of all terms (i.e., vocabulary) and xi is the weight of term wi.",
                "Such a term vector is commonly used in information retrieval to represent both queries and documents.",
                "For example, the vector-space model, assumes that both the query and the documents are represented as term vectors and the score of a document with respect to a query is computed based on the similarity between the query vector and the document vector [21].",
                "In a language modeling approach, we may also regard the query unigram language model [12, 29] or the relevance model [14] as a term vector representation of the users information need.",
                "Intuitively, x would assign high weights to terms that characterize the topics which the user is interested in.",
                "The second component we may include in our user model is the documents that the user has already viewed.",
                "Obviously, even if a document is relevant, if the user has already seen the document, it would not be useful to present the same document again.",
                "We thus introduce another variable S ⊂ D (D is the whole set of documents in the collection) to denote the subset of documents in the search results that the user has already seen/viewed.",
                "In general, at time t, we may represent a user model as mt = (S, x, At, Rt−1), where S is the seen documents, x is the systems understanding of the users information need, and (At, Rt−1) represents the users interaction history.",
                "Note that an even more general user model may also include other factors such as the users reading level and occupation.",
                "If we assume that the uncertainty of a user model mt is solely due to the uncertainty of x, the computation of our current estimate of user model m∗ t will mainly involve computing our best estimate of x.",
                "That is, the system would choose a response according to r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) where x∗ = argmaxx P(x|U, D, At, Rt−1).",
                "This is the decision mechanism implemented in the UCAIR system to be described later.",
                "In this system, we avoided specifying the probabilistic model P(x|U, D, At, Rt−1) by computing x∗ directly with some existing feedback method. 3.3 Loss functions The exact definition of loss function L depends on the responses, thus it is inevitably application-specific.",
                "We now briefly discuss some possibilities when the response is to rank all the unseen documents and present the top k of them.",
                "Let r = (d1, ..., dk) be the top k documents, S be the set of seen documents by the user, and x∗ be the systems best guess of the users information need.",
                "We 826 may simply define the loss associated with r as the negative sum of the probability that each of the di is relevant, i.e., L(a, r, m) = − k i=1 P(relevant|di, m).",
                "Clearly, in order to minimize this loss function, the optimal response r would contain the k documents with the highest probability of relevance, which is intuitively reasonable.",
                "One deficiency of this top-k loss function is that it is not sensitive to the internal order of the selected top k documents, so switching the ranking order of a non-relevant document and a relevant one would not affect the loss, which is unreasonable.",
                "To model ranking, we can introduce a factor of the user model - the probability of each of the k documents being viewed by the user, P(view|di), and define the following ranking loss function: L(a, r, m) = − k i=1 P(view|di)P(relevant|di, m) Since in general, if di is ranked above dj (i.e., i < j), P(view|di) > P(view|dj), this loss function would favor a decision to rank relevant documents above non-relevant ones, as otherwise, we could always switch di with dj to reduce the loss value.",
                "Thus the system should simply perform a regular retrieval and rank documents according to the probability of relevance [18].",
                "Depending on the users retrieval preferences, there can be many other possibilities.",
                "For example, if the user does not want to see redundant documents, the loss function should include some redundancy measure on r based on the already seen documents S. Of course, when the response is not to choose a ranked list of documents, we would need a different loss function.",
                "We discuss one such example that is relevant to the search agent that we implement.",
                "When a user enters a query qt (current action), our search agent relies on some existing search engine to actually carry out search.",
                "In such a case, even though the search agent does not have control of the retrieval algorithm, it can still attempt to optimize the search results through refining the query sent to the search engine and/or reranking the results obtained from the search engine.",
                "The loss functions for reranking are already discussed above; we now take a look at the loss functions for query refinement.",
                "Let f be the retrieval function of the search engine that our agent uses so that f(q) would give us the search results using query q.",
                "Given that the current action of the user is entering a query qt (i.e., at = qt), our response would be f(q) for some q.",
                "Since we have no choice of f, our decision is to choose a good q.",
                "Formally, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) which shows that our goal is to find q∗ = argminqL(qt, f(q), m), i.e., an optimal query that would give us the best f(q).",
                "A different choice of loss function L(qt, f(q), m) would lead to a different query refinement strategy.",
                "In UCAIR, we heuristically compute q∗ by expanding qt with terms extracted from rt−1 whenever qt−1 and qt have high similarity.",
                "Note that rt−1 and qt−1 are contained in m as part of the users interaction history. 3.4 Implicit user modeling Implicit user modeling is captured in our framework through the computation of x∗ = argmaxx P(x|U, D, At, Rt−1), i.e., the systems current belief of what the users information need is.",
                "Here again there may be many possibilities, leading to different algorithms for implicit user modeling.",
                "We now discuss a few of them.",
                "First, when two consecutive queries are related, the previous query can be exploited to enrich the current query and provide more search context to help disambiguation.",
                "For this purpose, instead of performing query expansion as we did in the previous section, we could also compute an updated x∗ based on the previous query and retrieval results.",
                "The computed new user model can then be used to rank the documents with a standard information retrieval model.",
                "Second, we can also infer a users interest based on the summaries of the viewed documents.",
                "When a user is presented with a list of summaries of top ranked documents, if the user chooses to skip the first n documents and to view the (n+1)-th document, we may infer that the user is not interested in the displayed summaries for the first n documents, but is attracted by the displayed summary of the (n + 1)-th document.",
                "We can thus use these summaries as negative and positive examples to learn a more accurate user model x∗ .",
                "Here many standard relevance feedback techniques can be exploited [19, 20].",
                "Note that we should use the displayed summaries, as opposed to the actual contents of those documents, since it is possible that the displayed summary of the viewed document is relevant, but the document content is actually not.",
                "Similarly, a displayed summary may mislead a user to skip a relevant document.",
                "Inferring user models based on such displayed information, rather than the actual content of a document is an important difference between UCAIR and some other similar systems.",
                "In UCAIR, both of these strategies for inferring an implicit user model are implemented. 4.",
                "UCAIR: A PERSONALIZED SEARCH AGENT 4.1 Design In this section, we present a client-side web search agent called UCAIR, in which we implement some of the methods discussed in the previous section for performing personalized search through implicit user modeling.",
                "UCAIR is a web browser plug-in 1 that acts as a proxy for web search engines.",
                "Currently, it is only implemented for Internet Explorer and Google, but it is a matter of engineering to make it run on other web browsers and interact with other search engines.",
                "The issue of privacy is a primary obstacle for deploying any real world applications involving serious user modeling, such as personalized search.",
                "For this reason, UCAIR is strictly running as a client-side search agent, as opposed to a server-side application.",
                "This way, the captured user information always resides on the computer that the user is using, thus the user does not need to release any information to the outside.",
                "Client-side personalization also allows the system to easily observe a lot of user information that may not be easily available to a server.",
                "Furthermore, performing personalized search on the client-side is more scalable than on the serverside, since the overhead of computation and storage is distributed among clients.",
                "As shown in Figure 1, the UCAIR toolbar has 3 major components: (1) The (implicit) user modeling module captures a users search context and history information, including the submitted queries and any clicked search results and infers search session boundaries. (2) The query modification module selectively improves the query formulation according to the current user model. (3) The result re-ranking module immediately re-ranks any unseen search results whenever the user model is updated.",
                "In UCAIR, we consider four basic user actions: (1) submitting a keyword query; (2) viewing a document; (3) clicking the Back button; (4) clicking the Next link on a result page.",
                "For each of these four actions, the system responds with, respectively, (1) 1 UCAIR is available at: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Search Engine (e.g., Google) Search History Log (e.g.,past queries, clicked results) Query Modification Result Re-Ranking User Modeling Result Buffer UCAIR Userquery results clickthrough… Figure 1: UCAIR architecture generating a ranked list of results by sending a possibly expanded query to a search engine; (2) updating the information need model x; (3) reranking the unseen results on the current result page based on the current model x; and (4) reranking the unseen pages and generating the next page of results based on the current model x.",
                "Behind these responses, there are three basic tasks: (1) Decide whether the previous query is related to the current query and if so expand the current query with useful terms from the previous query or the results of the previous query. (2) Update the information need model x based on a newly clicked document summary. (3) Rerank a set of unseen documents based on the current model x.",
                "Below we describe our algorithms for each of them. 4.2 Session boundary detection and query expansion To effectively exploit previous queries and their corresponding clickthrough information, UCAIR needs to judge whether two adjacent queries belong to the same search session (i.e., detect session boundaries).",
                "Existing work on session boundary detection is mostly in the context of web log analysis (e.g., [8]), and uses statistical information rather than textual features.",
                "Since our clientside agent does not have access to server query logs, we make session boundary decisions based on textual similarity between two queries.",
                "Because related queries do not necessarily share the same words (e.g., java island and travel Indonesia), it is insufficient to use only query text.",
                "Therefore we use the search results of the two queries to help decide whether they are topically related.",
                "For example, for the above queries java island and travel Indonesia, the words java, bali, island, indonesia and travel may occur frequently in both queries search results, yielding a high similarity score.",
                "We only use the titles and summaries of the search results to calculate the similarity since they are available in the retrieved search result page and fetching the full text of every result page would significantly slow down the process.",
                "To compensate for the terseness of titles and summaries, we retrieve more results than a user would normally view for the purpose of detecting session boundaries (typically 50 results).",
                "The similarity between the previous query q and the current query q is computed as follows.",
                "Let {s1, s2, . . . , sn } and {s1, s2, . . . , sn} be the result sets for the two queries.",
                "We use the pivoted normalization TF-IDF weighting formula [24] to compute a term weight vector si for each result si.",
                "We define the average result savg to be the centroid of all the result vectors, i.e., (s1 + s2 + . . . + sn)/n.",
                "The cosine similarity between the two average results is calculated as s avg · savg/ s 2 avg · s2 avg If the similarity value exceeds a predefined threshold, the two queries will be considered to be in the same information session.",
                "If the previous query and the current query are found to belong to the same search session, UCAIR would attempt to expand the current query with terms from the previous query and its search results.",
                "Specifically, for each term in the previous query or the corresponding search results, if its frequency in the results of the current query is greater than a preset threshold (e.g. 5 results out of 50), the term would be added to the current query to form an expanded query.",
                "In this case, UCAIR would send this expanded query rather than the original one to the search engine and return the results corresponding to the expanded query.",
                "Currently, UCAIR only uses the immediate preceding query for query expansion; in principle, we could exploit all related past queries. 4.3 Information need model updating Suppose at time t, we have observed that the user has viewed k documents whose summaries are s1, ..., sk.",
                "We update our user model by computing a new information need vector with a standard feedback method in information retrieval (i.e., Rocchio [19]).",
                "According to the vector space retrieval model, each clicked summary si can be represented by a term weight vector si with each term weighted by a TF-IDF weighting formula [21].",
                "Rocchio computes the centroid vector of all the summaries and interpolates it with the original query vector to obtain an updated term vector.",
                "That is, x = αq + (1 − α) 1 k k i=1 si where q is the query vector, k is the number of summaries the user clicks immediately following the current query and α is a parameter that controls the influence of the clicked summaries on the inferred information need model.",
                "In our experiments, α is set to 0.5.",
                "Note that we update the information need model whenever the user views a document. 4.4 Result reranking In general, we want to rerank all the unseen results as soon as the user model is updated.",
                "Currently, UCAIR implements reranking in two cases, corresponding to the user clicking the Back button and Next link in the Internet Explorer.",
                "In both cases, the current (updated) user model would be used to rerank the unseen results so that the user would see improved search results immediately.",
                "To rerank any unseen document summaries, UCAIR uses the standard vector space retrieval model and scores each summary based on the similarity of the result and the current user information need vector x [21].",
                "Since implicit feedback is not completely reliable, we bring up only a small number (e.g. 5) of highest reranked results to be followed by any originally high ranked results. 828 Google result (user query = java map) UCAIR result (user query =java map) previous query = travel Indonesia previous query = hashtable expanded user query = java map Indonesia expanded user query = java map class 1 Java map projections of the world ... Lonely Planet - Indonesia Map Map (Java 2 Platform SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Java map projections of the world ... INDONESIA TOURISM : CENTRAL JAVA - MAP Java 2 Platform SE v1.3.1: Interface Map www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Java Map INDONESIA TOURISM : WEST JAVA - MAP An Introduction to Java Map Collection Classes java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Java Technology Concept Map IndoStreets - Java Map An Introduction to Java Map Collection Classes java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Indonesia Regions and Islands Maps, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 An Introduction to Java Map Collection Classes Indonesia City Street Map,... Hibernate simplifies inheritance mapping www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Java Map Maps Of Indonesia tmap 30.map Class Hierarchy www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Java API Map Maps of Indonesia by Peter Loud Class Scope www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas : Sam Maps of Indonesia by Peter Loud Class PrintSafeHashMap www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 INDONESIA TOURISM : WEST JAVA - MAP indonesiaphoto.com Java Pro - Union and Vertical Mapping of Classes www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Table 1: Sample results of query expansion 5.",
                "EVALUATION OF UCAIR We now present some results on evaluating the two major UCAIR functions: selective query expansion and result reranking based on user clickthrough data. 5.1 Sample results The query expansion strategy implemented in UCAIR is intentionally conservative to avoid misinterpretation of implicit user models.",
                "In practice, whenever it chooses to expand the query, the expansion usually makes sense.",
                "In Table 1, we show how UCAIR can successfully distinguish two different search contexts for the query java map, corresponding to two different previous queries (i.e., travel Indonesia vs. hashtable).",
                "Due to implicit user modeling, UCAIR intelligently figures out to add Indonesia and class, respectively, to the users query java map, which would otherwise be ambiguous as shown in the original results from Google on March 21, 2005.",
                "UCAIRs results are much more accurate than Googles results and reflect personalization in search.",
                "The eager implicit feedback component is designed to immediately respond to a users activity such as viewing a document.",
                "In Figure 2, we show how UCAIR can successfully disambiguate an ambiguous query jaguar by exploiting a viewed document summary.",
                "In this case, the initial retrieval results using jaguar (shown on the left side) contain two results about the Jaguar cars followed by two results about the Jaguar software.",
                "However, after the user views the web page content of the second result (about Jaguar car) and returns to the search result page by clicking Back button, UCAIR automatically nominates two new search results about Jaguar cars (shown on the right side), while the original two results about Jaguar software are pushed down on the list (unseen from the picture). 5.2 Quantitative evaluation To further evaluate UCAIR quantitatively, we conduct a user study on the effectiveness of the eager implicit feedback component.",
                "It is a challenge to quantitatively evaluate the potential performance improvement of our proposed model and UCAIR over Google in an unbiased way [7].",
                "Here, we design a user study, in which participants would do normal web search and judge a randomly and anonymously mixed set of results from Google and UCAIR at the end of the search session; participants do not know whether a result comes from Google or UCAIR.",
                "We recruited 6 graduate students for this user study, who have different backgrounds (3 computer science, 2 biology, and 1 chem<top> <num> Number: 716 <title> Spammer arrest sue <desc> Description: Have any spammers been arrested or sued for sending unsolicited e-mail? <narr> Narrative: Instances of arrests, prosecutions, convictions, and punishments of spammers, and lawsuits against them are relevant.",
                "Documents which describe laws to limit spam without giving details of lawsuits or criminal trials are not relevant. </top> Figure 3: An example of TREC query topic, expressed in a form which might be given to a human assistant or librarian istry).",
                "We use query topics from TREC 2 2004 Terabyte track [2] and TREC 2003 Web track [4] topic distillation task in the way to be described below.",
                "An example topic from TREC 2004 Terabyte track appears in Figure 3.",
                "The title is a short phrase and may be used as a query to the retrieval system.",
                "The description field provides a slightly longer statement of the topic requirement, usually expressed as a single complete sentence or question.",
                "Finally the narrative supplies additional information necessary to fully specify the requirement, expressed in the form of a short paragraph.",
                "Initially, each participant would browse 50 topics either from Terabyte track or Web track and pick 5 or 7 most interesting topics.",
                "For each picked topic, the participant would essentially do the normal web search using UCAIR to find many relevant web pages by using the title of the query topic as the initial keyword query.",
                "During this process, the participant may view the search results and possibly click on some interesting ones to view the web pages, just as in a normal web search.",
                "There is no requirement or restriction on how many queries the participant must submit or when the participant should stop the search for one topic.",
                "When the participant plans to change the search topic, he/she will simply press a button 2 Text REtrieval Conference: http://trec.nist.gov/ 829 Figure 2: Screen shots for result reranking to evaluate the search results before actually switching to the next topic.",
                "At the time of evaluation, 30 top ranked results from Google and UCAIR (some are overlapping) are randomly mixed together so that the participant would not know whether a result comes from Google or UCAIR.",
                "The participant would then judge the relevance of these results.",
                "We measure precision at top n (n = 5, 10, 20, 30) documents of Google and UCAIR.",
                "We also evaluate precisions at different recall levels.",
                "Altogether, 368 documents judged as relevant from Google search results and 429 documents judged as relevant from UCAIR by participants.",
                "Scatter plots of precision at top 10 and top 20 documents are shown in Figure 4 and Figure 5 respectively (The scatter plot of precision at top 30 documents is very similar to precision at top 20 documents).",
                "Each point of the scatter plots represents the precisions of Google and UCAIR on one query topic.",
                "Table 2 shows the average precision at top n documents among 32 topics.",
                "From Figure 4, Figure 5 and Table 2, we see that the search results from UCAIR are consistently better than those from Google by all the measures.",
                "Moreover, the performance improvement is more dramatic for precision at top 20 documents than that at precision at top 10 documents.",
                "One explanation for this is that the more interaction the user has with the system, the more clickthrough data UCAIR can be expected to collect.",
                "Thus the retrieval system can build more precise implicit user models, which lead to better retrieval accuracy.",
                "Ranking Method prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Improvement 8.0% 17.8% 20.2% 21.8% Table 2: Table of average precision at top n documents for 32 query topics The plot in Figure 6 shows the precision-recall curves for UCAIR and Google, where it is clearly seen that the performance of UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Scatterplot of Precision at Top 10 Documents Figure 4: Precision at top 10 documents of UCAIR and Google is consistently and considerably better than that of Google at all levels of recall. 6.",
                "CONCLUSIONS In this paper, we studied how to exploit implicit user modeling to intelligently personalize information retrieval and improve <br>search accuracy</br>.",
                "Unlike most previous work, we emphasize the use of immediate search context and implicit feedback information as well as eager updating of search results to maximally benefit a user.",
                "We presented a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent (UCAIR) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve <br>search accuracy</br> over 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Scatterplot of Precision at Top 20 documents Figure 5: Precision at top 20 documents of UCAIR and Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 recall precision Precision−Recall curves Google Result UCAIR Result Figure 6: Precision at top 20 result of UCAIR and Google Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "The developed search agent thus can improve existing web search performance without any additional effort from the user. 7.",
                "ACKNOWLEDGEMENT We thank the six participants of our evaluation experiments.",
                "This work was supported in part by the National Science Foundation grants IIS-0347933 and IIS-0428472. 8.",
                "REFERENCES [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman, and O. Frieder.",
                "Hourly analysis of a very large topically categorized web query log.",
                "In Proceedings of SIGIR 2004, pages 321-328, 2004. [2] C. Clarke, N. Craswell, and I. Soboroff.",
                "Overview of the TREC 2004 terabyte track.",
                "In Proceedings of TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda, and D. Brown.",
                "Implicit interest indicators.",
                "In Proceedings of Intelligent User Interfaces 2001, pages 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson, and M. Wu.",
                "Overview of the TREC 2003 web track.",
                "In Proceedings of TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend, and V. Larvrenko.",
                "Relevance feedback and personalization: A language modeling perspective.",
                "In Proeedings of Second DELOS Workshop: Personalisation and Recommender Systems in Digital Libraries, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite, and D. Harman.",
                "Results and challenges in web search evaluation.",
                "Computer Networks, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A.",
                "An, and D. Schuurmans.",
                "Dynamic web log session identification with statistical language models.",
                "Journal of the American Society for Information Science and Technology, 55(14):1290-1303, 2004. [9] G. Jeh and J. Widom.",
                "Scaling personalized web search.",
                "In Proceedings of WWW 2003, pages 271-279, 2003. [10] T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of SIGKDD 2002, pages 133-142, 2002. [11] D. Kelly and J. Teevan.",
                "Implicit feedback for inferring user preference: A bibliography.",
                "SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of SIGIR01, pages 111-119, 2001. [13] T. Lau and E. Horvitz.",
                "Patterns of search: Analyzing and modeling web query refinement.",
                "In Proceedings of the Seventh International Conference on User Modeling (UM), pages 145 -152, 1999. [14] V. Lavrenko and B. Croft.",
                "Relevance-based language models.",
                "In Proceedings of SIGIR01, pages 120-127, 2001. [15] M. Mitra, A. Singhal, and C. Buckley.",
                "Improving automatic query expansion.",
                "In Proceedings of SIGIR 1998, pages 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg.",
                "As google goes, so goes the nation.",
                "New York Times, May 2003. [18] S. E. Robertson.",
                "The probability ranking principle in ı˚.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] J. J. Rocchio.",
                "Relevance feedback in information retrieval.",
                "In The SMART Retrieval System: Experiments in Automatic Document Processing, pages 313-323.",
                "Prentice-Hall Inc., 1971. [20] G. Salton and C. Buckley.",
                "Improving retrieval performance by retrieval feedback.",
                "Journal of the American Society for Information Science, 41(4):288-297, 1990. [21] G. Salton and M. J. McGill.",
                "Introduction to Modern Information Retrieval.",
                "McGraw-Hill, 1983. [22] X. Shen, B. Tan, and C. Zhai.",
                "Context-sensitive information retrieval using implicit feedback.",
                "In Proceedings of SIGIR 2005, pages 43-50, 2005. [23] X. Shen and C. Zhai.",
                "Exploiting query history for document ranking in interactive information retrieval (Poster).",
                "In Proceedings of SIGIR 2003, pages 377-378, 2003. [24] A. Singhal.",
                "Modern information retrieval: A brief overview.",
                "Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano, and M. Yoshikawa.",
                "Adaptive web search based on user profile constructed without any effort from users.",
                "In Proceedings of WWW 2004, pages 675-684, 2004. [26] E. Volokh.",
                "Personalization and privacy.",
                "Communications of the ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen, and I. Ruthven.",
                "A simulated study of implicit feedback models.",
                "In Proceedings of ECIR 2004, pages 311-326, 2004. [28] J. Xu and W. B. Croft.",
                "Query expansion using local and global document analysis.",
                "In Proceedings of SIGIR 1996, pages 4-11, 1996. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in KL divergence retrieval model.",
                "In Proceedings of the CIKM 2001, pages 403-410, 2001. 831"
            ],
            "original_annotated_samples": [
                "Experiments on web search show that our search agent can improve <br>search accuracy</br> over the popular Google search engine.",
                "Experiments on web search show that our search agent can improve <br>search accuracy</br> over Google.",
                "CONCLUSIONS In this paper, we studied how to exploit implicit user modeling to intelligently personalize information retrieval and improve <br>search accuracy</br>.",
                "Experiments on web search show that our search agent can improve <br>search accuracy</br> over 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Scatterplot of Precision at Top 20 documents Figure 5: Precision at top 20 documents of UCAIR and Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 recall precision Precision−Recall curves Google Result UCAIR Result Figure 6: Precision at top 20 result of UCAIR and Google Google."
            ],
            "translated_annotated_samples": [
                "Los experimentos sobre la búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la <br>precisión de la búsqueda</br> sobre el popular motor de búsqueda Google.",
                "Los experimentos sobre búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la <br>precisión de la búsqueda</br> en comparación con Google.",
                "CONCLUSIONES En este artículo, estudiamos cómo aprovechar la modelización implícita del usuario para personalizar de manera inteligente la recuperación de información y mejorar la <br>precisión de la búsqueda</br>.",
                "Los experimentos en la búsqueda web muestran que nuestro agente de búsqueda puede mejorar la <br>precisión de la búsqueda</br> en más de un 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Gráfico de dispersión de Precisión en los 20 documentos principales Figura 5: Precisión en los 20 documentos principales de UCAIR y Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 precisión recall Curvas de Precisión-Recall Resultado de Google Resultado de UCAIR Figura 6: Precisión en los 20 resultados principales de UCAIR y Google Google."
            ],
            "translated_text": "Modelado implícito de usuarios para búsqueda personalizada Xuehua Shen, Bin Tan, ChengXiang Zhai Departamento de Ciencias de la Computación Universidad de Illinois en Urbana-Champaign RESUMEN Los sistemas de recuperación de información (por ejemplo, motores de búsqueda web) son críticos para superar la sobrecarga de información. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales, lo que resulta en un rendimiento de recuperación inherentemente no óptimo. Por ejemplo, un turista y un programador pueden usar la misma palabra \"java\" para buscar información diferente, pero los sistemas de búsqueda actuales devolverían los mismos resultados. En este artículo, estudiamos cómo inferir el interés de un usuario a partir del contexto de búsqueda del usuario y utilizar el modelo de usuario implícito inferido para la búsqueda personalizada. Presentamos un marco teórico de toma de decisiones y desarrollamos técnicas para el modelado implícito del usuario en la recuperación de información. Desarrollamos un agente de búsqueda web inteligente del lado del cliente (UCAIR) que puede realizar retroalimentación implícita ansiosa, por ejemplo, expansión de consultas basada en consultas anteriores y reordenamiento inmediato de resultados basado en información de clics. Los experimentos sobre la búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la <br>precisión de la búsqueda</br> sobre el popular motor de búsqueda Google. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación, Retroalimentación de relevancia, Proceso de búsqueda Términos Generales Algoritmos 1. Aunque muchos sistemas de recuperación de información (por ejemplo, motores de búsqueda web y sistemas de biblioteca digital) se han implementado con éxito, los sistemas de recuperación actuales están lejos de ser óptimos. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales [17]. Esta no optimalidad inherente se ve claramente en los siguientes dos casos: (1) Diferentes usuarios pueden utilizar exactamente la misma consulta (por ejemplo, Java) para buscar información diferente (por ejemplo, la isla de Java en Indonesia o el lenguaje de programación Java), pero los sistemas de IR existentes devuelven los mismos resultados para estos usuarios. Sin considerar al usuario actual, es imposible saber a qué sentido se refiere Java en una consulta. (2) Las necesidades de información de un usuario pueden cambiar con el tiempo. El mismo usuario puede usar Java a veces para referirse a la isla de Java en Indonesia y otras veces para referirse al lenguaje de programación. Sin reconocer el contexto de búsqueda, sería nuevamente imposible reconocer el sentido correcto. Para optimizar la precisión de la recuperación, claramente necesitamos modelar al usuario de manera adecuada y personalizar la búsqueda según cada usuario individual. El objetivo principal del modelado de usuario para la recuperación de información es modelar con precisión la necesidad de información de un usuario, lo cual, desafortunadamente, es una tarea muy difícil. De hecho, incluso resulta difícil para un usuario describir con precisión cuál es su necesidad de información. ¿Qué información está disponible para que un sistema pueda inferir la necesidad de información de un usuario? Obviamente, la consulta de los usuarios proporciona la evidencia más directa. De hecho, la mayoría de los sistemas de recuperación existentes se basan únicamente en la consulta para modelar la necesidad de información de los usuarios. Sin embargo, dado que una consulta suele ser extremadamente corta, el modelo de usuario construido basado en una consulta de palabras clave inevitablemente resulta empobrecido. Una forma efectiva de mejorar la modelización de usuarios en la recuperación de información es pedir al usuario que especifique explícitamente qué documentos son relevantes (es decir, útiles para satisfacer su necesidad de información) y luego mejorar la modelización de usuarios basándose en ejemplos de documentos relevantes. Esto se llama retroalimentación de relevancia, lo cual ha demostrado ser bastante efectivo para mejorar la precisión de recuperación [19, 20]. Desafortunadamente, en aplicaciones del mundo real, los usuarios suelen ser reacios a hacer el esfuerzo adicional de proporcionar ejemplos relevantes para retroalimentación [11]. Por lo tanto, es muy interesante estudiar cómo inferir la necesidad de información de un usuario basándose en cualquier información de retroalimentación implícita, la cual existe naturalmente a través de las interacciones del usuario y no requiere ningún esfuerzo adicional por parte del usuario. De hecho, varios estudios previos han demostrado que el modelado implícito del usuario puede mejorar la precisión de recuperación. En [3], se desarrolla un navegador web (Curious Browser) para registrar las calificaciones explícitas de relevancia de las páginas web por parte de los usuarios (retroalimentación de relevancia) y el comportamiento de navegación al ver una página, como el tiempo de permanencia, clics de ratón, movimiento del ratón y desplazamiento (retroalimentación implícita). Se muestra que el tiempo de permanencia en una página, la cantidad de desplazamiento en una página y la combinación de tiempo y desplazamiento tienen una fuerte correlación con las calificaciones de relevancia explícita, lo que sugiere que la retroalimentación implícita puede ser útil para inferir la necesidad de información del usuario. En [10], se recopilan datos de clics de usuario como datos de entrenamiento para aprender una función de recuperación, que se utiliza para producir un ranking personalizado de resultados de búsqueda que se adapte a las preferencias de un grupo de usuarios. En [25], los datos de clics recopilados durante un largo período de tiempo se utilizan a través de la expansión de consultas para mejorar la precisión de recuperación. Si bien un usuario puede tener intereses y preferencias generales a largo plazo para la información, a menudo está buscando documentos para satisfacer una necesidad de información ad-hoc, que solo dura un corto período de tiempo; una vez que se satisface la necesidad de información, el usuario generalmente ya no estaría interesado en esa información. Por ejemplo, un usuario puede estar buscando información sobre autos usados para comprar uno, pero una vez que el usuario ha comprado un auto, generalmente ya no está interesado en esa información. En tales casos, la información de retroalimentación implícita recopilada durante un largo período de tiempo es poco probable que sea muy útil, pero el contexto de búsqueda inmediato y la información de retroalimentación, como cuáles de los resultados de búsqueda para la necesidad de información actual son vistos, se espera que sean mucho más útiles. Considera la consulta de Java nuevamente. Cualquiera de la siguiente información de retroalimentación inmediata sobre el usuario podría potencialmente ayudar a determinar el significado previsto de Java en la consulta: (1) La consulta anterior enviada por el usuario es hashtable (en lugar de, por ejemplo, viajar a Indonesia). (2) En los resultados de búsqueda, el usuario visualizó una página donde palabras como programación, software y applet ocurren muchas veces. Hasta donde sabemos, cómo aprovechar este contexto de búsqueda inmediato y a corto plazo para mejorar la búsqueda aún no ha sido abordado de manera satisfactoria en trabajos anteriores. En este artículo, estudiamos cómo construir y actualizar un modelo de usuario basado en el contexto de búsqueda inmediato y la información de retroalimentación implícita, y utilizar el modelo para mejorar la precisión de la recuperación ad-hoc. Para beneficiar al máximo al usuario de un sistema de recuperación a través de modelado implícito del usuario, proponemos realizar retroalimentación implícita entusiasta. Es decir, tan pronto como observemos cualquier nueva pieza de evidencia del usuario, actualizaríamos la creencia del sistema sobre la necesidad de información del usuario y responderíamos con resultados de recuperación mejorados basados en el modelo de usuario actualizado. Presentamos un marco de trabajo de teoría de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. En un paradigma de recuperación tradicional, el problema de recuperación consiste en emparejar una consulta con documentos y clasificar los documentos según sus valores de relevancia. Como resultado, el proceso de recuperación es un ciclo independiente simple de consulta y visualización de resultados. En el nuevo paradigma de recuperación propuesto, el contexto de búsqueda de los usuarios juega un papel importante y el modelo de usuario implícito inferido se explota inmediatamente para beneficiar al usuario. El nuevo paradigma de recuperación es, por lo tanto, fundamentalmente diferente del paradigma tradicional y es inherentemente más general. Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos apropiados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para reordenar inmediatamente cualquier documento que aún no haya sido visto por el usuario. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente UCAIR (Recuperación de Información Adaptativa Centrada en el Usuario) sobre un motor de búsqueda popular (Google). Los experimentos sobre búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la <br>precisión de la búsqueda</br> en comparación con Google. Dado que la información implícita que explotamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional. Por lo tanto, el agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin esfuerzo adicional por parte del usuario. Las secciones restantes están organizadas de la siguiente manera. En la Sección 2, discutimos el trabajo relacionado. En la Sección 3, presentamos un marco de recuperación interactiva basado en teoría de decisiones para modelado implícito de usuarios. En la Sección 4, presentamos el diseño e implementación de un agente de búsqueda web inteligente del lado del cliente (UCAIR) que realiza retroalimentación implícita ansiosa. En la Sección 5, informamos nuestros resultados experimentales utilizando el agente de búsqueda. La sección 6 concluye nuestro trabajo. 2. El modelado implícito del usuario para la búsqueda personalizada ha sido estudiado en trabajos anteriores, pero nuestro trabajo difiere de todos los trabajos anteriores en varios aspectos: (1) Enfatizamos la explotación del contexto de búsqueda inmediato, como la consulta inmediatamente anterior relacionada y los documentos vistos en la misma sesión, mientras que la mayoría de los trabajos anteriores se basan en la recopilación a largo plazo de información de retroalimentación implícita [25]. (2) Realizamos una retroalimentación activa y obtenemos el beneficio del modelado implícito del usuario tan pronto como esté disponible cualquier nueva información de retroalimentación implícita, mientras que el trabajo anterior mayormente explota la retroalimentación implícita a largo plazo [10]. (3) Proponemos un marco de recuperación para integrar el modelado implícito del usuario con el proceso interactivo de recuperación, mientras que el trabajo anterior estudia el modelado implícito del usuario por separado de la recuperación [3] o solo estudia modelos de recuperación específicos para explotar la retroalimentación implícita para mejorar la coincidencia de una consulta con documentos [23, 27, 22]. (4) Desarrollamos y evaluamos un agente de búsqueda web personalizado con estudios de usuario en línea, mientras que la mayoría de los trabajos existentes evalúan algoritmos fuera de línea sin interacciones reales de usuarios. Actualmente algunos motores de búsqueda ofrecen personalización rudimentaria, como la búsqueda web personalizada de Google [6], que permite a los usuarios describir explícitamente sus intereses seleccionando entre temas predefinidos, de modo que los resultados que coinciden con sus intereses se muestren en la parte superior, y la búsqueda de My Yahoo! [16], que brinda a los usuarios la opción de guardar los sitios web que les gustan y bloquear aquellos que no les gustan. Por el contrario, UCAIR personaliza la búsqueda web a través de la modelización implícita del usuario sin necesidad de esfuerzos adicionales por parte del usuario. Además, la personalización de UCAIR se proporciona en el lado del cliente. Hay dos ventajas notables en esto. Primero, el usuario no necesita preocuparse por la infracción de privacidad, que es una gran preocupación para la búsqueda personalizada [26]. En segundo lugar, tanto el cálculo de la personalización como el almacenamiento del perfil del usuario se realizan en el lado del cliente para reducir drásticamente la carga del servidor [9]. Ha habido muchos trabajos estudiando los registros de consultas de usuarios [1] o la dinámica de consultas [13]. UCAIR hace uso directo del historial de consultas de un usuario para beneficiar al mismo usuario de inmediato en la misma sesión de búsqueda. UCAIR primero determina si dos consultas vecinas pertenecen a la misma sesión de información y, de ser así, selecciona términos de la consulta anterior para realizar la expansión de la consulta. Nuestro enfoque de expansión de consultas es similar a la expansión automática de consultas [28, 15, 5], pero en lugar de utilizar retroalimentación pseudo para expandir la consulta, utilizamos la información de retroalimentación implícita de los usuarios para expandir la consulta actual. Estas dos técnicas pueden ser combinadas. 3. OPTIMIZACIÓN EN IR INTERACTIVO En IR interactivo, un usuario interactúa con el sistema de recuperación a través de un diálogo de acción, en el cual el sistema responde a cada acción del usuario con alguna acción del sistema. Por ejemplo, la acción de los usuarios puede ser enviar una consulta y la respuesta del sistema puede ser devolver una lista de 10 resúmenes de documentos. En general, el espacio de acciones del usuario y respuestas del sistema y sus granularidades dependerían de la interfaz de un sistema de recuperación particular. En principio, cada acción del usuario puede potencialmente proporcionar nuevas pruebas para ayudar al sistema a inferir mejor la necesidad de información del usuario. Por lo tanto, para responder de manera óptima, el sistema debería utilizar toda la evidencia recopilada hasta ahora sobre el usuario al elegir una respuesta. Cuando se ven de esta manera, la mayoría de los motores de búsqueda existentes son claramente no óptimos. Por ejemplo, si un usuario ha visto algunos documentos en la primera página de resultados de búsqueda, cuando el usuario hace clic en el enlace Siguiente para obtener más resultados, un sistema de recuperación existente seguiría devolviendo la siguiente página de resultados recuperados en función de la consulta original sin considerar la nueva evidencia de que un resultado en particular ha sido visto por el usuario. Proponemos optimizar el rendimiento de la recuperación adaptando las respuestas del sistema en función de cada acción que un usuario haya tomado, y planteamos el problema de optimización como una tarea de decisión. Específicamente, en cualquier momento, el sistema intentaría realizar dos tareas: (1) Actualización del modelo de usuario: Monitorear cualquier evidencia útil del usuario con respecto a su necesidad de información y actualizar el modelo de usuario tan pronto como esta evidencia esté disponible; (2) Mejorar los resultados de búsqueda: Reclasificar inmediatamente todos los documentos que el usuario aún no ha visto, tan pronto como se actualice el modelo de usuario. Enfatizamos la actualización y reordenamiento entusiastas, lo que hace que nuestro trabajo sea bastante diferente a cualquier trabajo existente. A continuación presentamos un marco formal de teoría de decisiones para optimizar el rendimiento de recuperación a través de la modelización implícita del usuario en la recuperación de información interactiva. 3.1 Un marco de teoría de decisiones Sea A el conjunto de todas las acciones del usuario y R(a) el conjunto de todas las posibles respuestas del sistema a una acción del usuario a ∈ A. En cualquier momento, sea At = (a1, ..., at) la secuencia observada de acciones de usuario hasta ahora (hasta el momento t) y Rt−1 = (r1, ..., rt−1) las respuestas que el sistema ha dado en respuesta a las acciones del usuario. El objetivo del sistema es elegir una respuesta óptima rt ∈ R(at) para la acción actual del usuario at. Sea M el espacio de todos los posibles modelos de usuario. Definimos además una función de pérdida L(a, r, m) ∈ , donde a ∈ A es una acción del usuario, r ∈ R(a) es una respuesta del sistema, y m ∈ M es un modelo de usuario. L(a, r, m) codifica nuestras preferencias de decisión y evalúa la optimalidad de responder con r cuando el modelo de usuario actual es m y la acción de usuario actual es a. Según la teoría de decisión bayesiana, la decisión óptima en el tiempo t es elegir una respuesta que minimice el riesgo de Bayes, es decir, r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) donde P(mt|U, D, At, Rt−1) es la probabilidad posterior del modelo de usuario mt dadas todas las observaciones sobre el usuario U que hemos realizado hasta el tiempo t. Para simplificar el cálculo de la Ecuación 1, asumamos que la masa de probabilidad posterior P(mt|U, D, At, Rt−1) está principalmente concentrada en el modo m∗ t = argmaxmt P(mt|U, D, At, Rt−1). Podemos entonces aproximar la integral con el valor de la función de pérdida en m∗ t. Es decir, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) donde m∗ t = argmaxmt P(mt|U, D, At, Rt−1). Dejando de lado cómo definir y estimar estos modelos probabilísticos y la función de pérdida, podemos ver que tal formulación de la teoría de decisiones sugiere que, para elegir la respuesta óptima a at, el sistema debería realizar dos tareas: (1) calcular el modelo de usuario actual y obtener m∗ t basado en toda la información útil. (2) elegir una respuesta rt para minimizar el valor de la función de pérdida L(at, rt, m∗ t). Cuando at no afecta nuestra creencia sobre m∗ t , el primer paso puede omitirse y podemos reutilizar m∗ t−1 para m∗ t . Ten en cuenta que nuestro marco de trabajo es bastante general, ya que potencialmente podemos modelar cualquier tipo de acciones de usuario y respuestas del sistema. En la mayoría de los casos, como podríamos esperar, la respuesta del sistema es algún tipo de clasificación de documentos, es decir, para la mayoría de las acciones a, R(a) consiste en todas las posibles clasificaciones de los documentos no vistos, y el problema de decisión se reduce a elegir la mejor clasificación de los documentos no vistos basándose en el modelo de usuario más actualizado. Cuando a es la acción de enviar una consulta de palabras clave, tal respuesta es exactamente lo que haría un sistema de recuperación actual. Sin embargo, fácilmente podemos imaginar que un motor de búsqueda web más inteligente respondería al clic del usuario en el enlace Siguiente (para obtener más resultados no vistos) con una clasificación más optimizada de documentos basada en cualquier documento visto en la página actual de resultados. De hecho, según nuestra estrategia de actualización entusiasta, incluso podríamos permitir que un sistema responda al clic del botón Atrás del navegador por parte de un usuario después de ver un documento de la misma manera, para que el usuario pueda beneficiarse al máximo de la retroalimentación implícita. Estos son precisamente lo que nuestro sistema UCAIR hace. 3.2 Modelos de usuario Un modelo de usuario m ∈ M representa lo que sabemos sobre el usuario U, por lo que en principio, puede contener cualquier información sobre el usuario que deseemos modelar. Ahora discutimos dos componentes importantes en un modelo de usuario. El primer componente es un modelo de componente de la necesidad de información de los usuarios. Presumiblemente, el factor más importante que afecta la optimalidad de la respuesta del sistema es qué tan bien la respuesta aborda la necesidad de información de los usuarios. De hecho, en cualquier momento, podemos asumir que el sistema tiene alguna creencia sobre lo que le interesa al usuario, la cual modelamos a través de un vector de términos x = (x1, ..., x|V|), donde V = {w1, ..., w|V|} es el conjunto de todos los términos (es decir, vocabulario) y xi es el peso del término wi. Un vector de términos de este tipo se utiliza comúnmente en la recuperación de información para representar tanto consultas como documentos. Por ejemplo, el modelo de espacio vectorial asume que tanto la consulta como los documentos se representan como vectores de términos y que la puntuación de un documento con respecto a una consulta se calcula en función de la similitud entre el vector de la consulta y el vector del documento [21]. En un enfoque de modelado de lenguaje, también podemos considerar el modelo de lenguaje unigrama de consulta [12, 29] o el modelo de relevancia [14] como una representación vectorial de términos de la necesidad de información de los usuarios. Intuitivamente, x asignaría pesos altos a los términos que caracterizan los temas que interesan al usuario. El segundo componente que podemos incluir en nuestro modelo de usuario son los documentos que el usuario ya ha visto. Obviamente, incluso si un documento es relevante, si el usuario ya ha visto el documento, no sería útil presentar el mismo documento de nuevo. Por lo tanto, introducimos otra variable S ⊂ D (D es el conjunto completo de documentos en la colección) para denotar el subconjunto de documentos en los resultados de búsqueda que el usuario ya ha visto. En general, en el tiempo t, podemos representar un modelo de usuario como mt = (S, x, At, Rt−1), donde S son los documentos vistos, x es la comprensión del sistema de la necesidad de información del usuario, y (At, Rt−1) representa el historial de interacción del usuario. Ten en cuenta que un modelo de usuario aún más general también puede incluir otros factores como el nivel de lectura y la ocupación de los usuarios. Si asumimos que la incertidumbre de un modelo de usuario mt se debe únicamente a la incertidumbre de x, el cálculo de nuestra estimación actual del modelo de usuario m∗ t implicará principalmente calcular nuestra mejor estimación de x. Es decir, el sistema elegiría una respuesta de acuerdo a r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) donde x∗ = argmaxx P(x|U, D, At, Rt−1). Este es el mecanismo de decisión implementado en el sistema UCAIR que se describirá más adelante. En este sistema, evitamos especificar el modelo probabilístico P(x|U, D, At, Rt−1) calculando x∗ directamente con algún método de retroalimentación existente. 3.3 Funciones de pérdida La definición exacta de la función de pérdida L depende de las respuestas, por lo que es inevitablemente específica de la aplicación. Ahora discutimos brevemente algunas posibilidades cuando la respuesta es clasificar todos los documentos no vistos y presentar los mejores k de ellos. Sea r = (d1, ..., dk) los k documentos principales, S el conjunto de documentos vistos por el usuario, y x∗ la mejor suposición del sistema sobre la necesidad de información del usuario. Podemos definir simplemente la pérdida asociada con r como la suma negativa de la probabilidad de que cada uno de los di sea relevante, es decir, L(a, r, m) = − k i=1 P(relevante|di, m). Claramente, para minimizar esta función de pérdida, la respuesta óptima r contendría los k documentos con la probabilidad más alta de relevancia, lo cual es intuitivamente razonable. Una deficiencia de esta función de pérdida top-k es que no es sensible al orden interno de los documentos top k seleccionados, por lo que cambiar el orden de clasificación de un documento no relevante y uno relevante no afectaría la pérdida, lo cual es irrazonable. Para modelar el ranking, podemos introducir un factor del modelo de usuario: la probabilidad de que cada uno de los k documentos sea visto por el usuario, P(vista|di), y definir la siguiente función de pérdida de ranking: L(a, r, m) = − k i=1 P(vista|di)P(relevante|di, m). Dado que, en general, si di está clasificado por encima de dj (es decir, i < j), P(vista|di) > P(vista|dj), esta función de pérdida favorecería una decisión de clasificar documentos relevantes por encima de los no relevantes, ya que de lo contrario, siempre podríamos intercambiar di con dj para reducir el valor de pérdida. Por lo tanto, el sistema simplemente debería realizar una recuperación regular y clasificar los documentos según la probabilidad de relevancia [18]. Dependiendo de las preferencias de recuperación de los usuarios, puede haber muchas otras posibilidades. Por ejemplo, si el usuario no desea ver documentos redundantes, la función de pérdida debería incluir alguna medida de redundancia en r basada en los documentos ya vistos S. Por supuesto, cuando la respuesta no es elegir una lista clasificada de documentos, necesitaríamos una función de pérdida diferente. Discutimos un ejemplo relevante para el agente de búsqueda que implementamos. Cuando un usuario ingresa una consulta qt (acción actual), nuestro agente de búsqueda se basa en algún motor de búsqueda existente para llevar a cabo la búsqueda en realidad. En tal caso, aunque el agente de búsqueda no tenga control sobre el algoritmo de recuperación, aún puede intentar optimizar los resultados de la búsqueda refinando la consulta enviada al motor de búsqueda y/o reordenando los resultados obtenidos del motor de búsqueda. Las funciones de pérdida para el reordenamiento ya fueron discutidas anteriormente; ahora echamos un vistazo a las funciones de pérdida para el refinamiento de consultas. Sea f la función de recuperación del motor de búsqueda que nuestro agente utiliza, de modo que f(q) nos daría los resultados de búsqueda utilizando la consulta q. Dado que la acción actual del usuario es ingresar una consulta qt (es decir, at = qt), nuestra respuesta sería f(q) para algún q. Dado que no tenemos elección de f, nuestra decisión es elegir un buen q. Formalmente, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) lo cual muestra que nuestro objetivo es encontrar q∗ = argminqL(qt, f(q), m), es decir, una consulta óptima que nos daría el mejor f(q). Una elección diferente de la función de pérdida L(qt, f(q), m) llevaría a una estrategia de refinamiento de consulta diferente. En UCAIR, calculamos heurísticamente q∗ expandiendo qt con términos extraídos de rt−1 siempre que qt−1 y qt tengan una alta similitud. Se debe tener en cuenta que rt−1 y qt−1 están contenidos en m como parte del historial de interacción de los usuarios. 3.4 Modelado implícito del usuario El modelado implícito del usuario se captura en nuestro marco a través del cálculo de x∗ = argmaxx P(x|U, D, At, Rt−1), es decir, la creencia actual del sistema sobre cuál es la necesidad de información del usuario. Aquí nuevamente puede haber muchas posibilidades, lo que lleva a diferentes algoritmos para la modelización implícita del usuario. Ahora discutimos algunos de ellos. Primero, cuando dos consultas consecutivas están relacionadas, la consulta anterior puede ser explotada para enriquecer la consulta actual y proporcionar más contexto de búsqueda para ayudar en la desambiguación. Para este propósito, en lugar de realizar una expansión de consulta como lo hicimos en la sección anterior, también podríamos calcular un x∗ actualizado basado en la consulta anterior y los resultados de recuperación. El modelo de usuario nuevo calculado puede luego ser utilizado para clasificar los documentos con un modelo estándar de recuperación de información. Segundo, también podemos inferir los intereses de un usuario basándonos en los resúmenes de los documentos visualizados. Cuando a un usuario se le presenta una lista de resúmenes de documentos mejor clasificados, si el usuario elige saltarse los primeros n documentos y ver el documento (n+1)-ésimo, podemos inferir que el usuario no está interesado en los resúmenes mostrados para los primeros n documentos, pero está atraído por el resumen mostrado del documento (n+1)-ésimo. Por lo tanto, podemos usar estos resúmenes como ejemplos negativos y positivos para aprender un modelo de usuario más preciso x∗. Aquí se pueden explotar muchas técnicas estándar de retroalimentación de relevancia [19, 20]. Ten en cuenta que debemos utilizar los resúmenes mostrados, en lugar de los contenidos reales de esos documentos, ya que es posible que el resumen mostrado del documento visto sea relevante, pero el contenido del documento en realidad no lo sea. Del mismo modo, un resumen mostrado puede llevar a un usuario a omitir un documento relevante. Inferir modelos de usuario basados en dicha información mostrada, en lugar del contenido real de un documento, es una diferencia importante entre UCAIR y algunos otros sistemas similares. En UCAIR, ambas estrategias para inferir un modelo de usuario implícito están implementadas. 4. UCAIR: Un agente de búsqueda personalizado 4.1 Diseño En esta sección, presentamos un agente de búsqueda web del lado del cliente llamado UCAIR, en el cual implementamos algunos de los métodos discutidos en la sección anterior para realizar búsquedas personalizadas a través de modelado implícito del usuario. UCAIR es un complemento del navegador web que actúa como proxy para los motores de búsqueda en la web. Actualmente, solo está implementado para Internet Explorer y Google, pero es cuestión de ingeniería hacer que funcione en otros navegadores web e interactúe con otros motores de búsqueda. El tema de la privacidad es un obstáculo principal para implementar cualquier aplicación del mundo real que involucre modelado de usuarios serio, como la búsqueda personalizada. Por esta razón, UCAIR funciona estrictamente como un agente de búsqueda del lado del cliente, en lugar de ser una aplicación del lado del servidor. De esta manera, la información del usuario capturada siempre permanece en la computadora que está utilizando el usuario, por lo tanto, el usuario no necesita revelar ninguna información al exterior. La personalización del lado del cliente también permite que el sistema observe fácilmente una gran cantidad de información del usuario que puede no estar fácilmente disponible para un servidor. Además, realizar búsquedas personalizadas en el lado del cliente es más escalable que en el lado del servidor, ya que la sobrecarga de cálculo y almacenamiento se distribuye entre los clientes. Como se muestra en la Figura 1, la barra de herramientas UCAIR tiene 3 componentes principales: (1) El módulo de modelado de usuario (implícito) captura el contexto de búsqueda de un usuario e información de historial, incluidas las consultas enviadas y los resultados de búsqueda clicados, e infiere los límites de la sesión de búsqueda. (2) El módulo de modificación de consultas mejora selectivamente la formulación de la consulta de acuerdo con el modelo de usuario actual. (3) El módulo de reordenamiento de resultados reordena inmediatamente cualquier resultado de búsqueda no visto cada vez que se actualiza el modelo de usuario. En UCAIR, consideramos cuatro acciones básicas de usuario: (1) enviar una consulta de palabras clave; (2) ver un documento; (3) hacer clic en el botón Atrás; (4) hacer clic en el enlace Siguiente en una página de resultados. Para cada una de estas cuatro acciones, el sistema responde con, respectivamente, (1) 1 UCAIR está disponible en: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Registro de Historial de Búsqueda del Motor de Búsqueda (por ejemplo, Google) (consultas pasadas, resultados clicados) Modificación de Consulta Resultado de Reclasificación Modelo de Usuario Buffer de Resultados de Consulta de Usuario UCAIR... Figura 1: arquitectura de UCAIR generando una lista clasificada de resultados enviando una consulta posiblemente ampliada a un motor de búsqueda; (2) actualizando el modelo de necesidad de información x; (3) reordenando los resultados no vistos en la página de resultados actual basándose en el modelo actual x; y (4) reordenando las páginas no vistas y generando la siguiente página de resultados basándose en el modelo actual x. Detrás de estas respuestas, hay tres tareas básicas: (1) Decidir si la consulta anterior está relacionada con la consulta actual y, de ser así, ampliar la consulta actual con términos útiles de la consulta anterior o los resultados de la consulta anterior. (2) Actualizar el modelo de necesidad de información x basado en un resumen de documento recién seleccionado. (3) Reordenar un conjunto de documentos no vistos basado en el modelo x actual. A continuación describimos nuestros algoritmos para cada uno de ellos. 4.2 Detección de límites de sesión y expansión de consultas Para explotar eficazmente las consultas anteriores y su información correspondiente de clics, UCAIR necesita determinar si dos consultas adyacentes pertenecen a la misma sesión de búsqueda (es decir, detectar los límites de sesión). El trabajo existente sobre la detección de límites de sesión se encuentra principalmente en el contexto del análisis de registros web (por ejemplo, [8]), y utiliza información estadística en lugar de características textuales. Dado que nuestro agente del lado del cliente no tiene acceso a los registros de consultas del servidor, tomamos decisiones sobre los límites de sesión basadas en la similitud textual entre dos consultas. Debido a que las consultas relacionadas no necesariamente comparten las mismas palabras (por ejemplo, isla de Java y viajar a Indonesia), no es suficiente utilizar solo el texto de la consulta. Por lo tanto, utilizamos los resultados de búsqueda de las dos consultas para ayudar a decidir si están relacionadas temáticamente. Por ejemplo, para las consultas anteriores \"java island\" y \"travel Indonesia\", las palabras \"java\", \"bali\", \"island\", \"indonesia\" y \"travel\" pueden aparecer con frecuencia en los resultados de búsqueda de ambas consultas, lo que produce un alto puntaje de similitud. Solo utilizamos los títulos y resúmenes de los resultados de búsqueda para calcular la similitud, ya que están disponibles en la página de resultados de búsqueda recuperada y obtener el texto completo de cada página de resultados ralentizaría significativamente el proceso. Para compensar la concisión de los títulos y resúmenes, recuperamos más resultados de los que un usuario normalmente vería con el propósito de detectar los límites de sesión (típicamente 50 resultados). La similitud entre la consulta anterior q y la consulta actual q se calcula de la siguiente manera. Sean {s1, s2, . . . , sn} y {s1, s2, . . . , sn} los conjuntos de resultados de las dos consultas. Utilizamos la fórmula de ponderación TF-IDF normalizada pivotada [24] para calcular un vector de peso de término si para cada resultado si. Definimos el resultado promedio savg como el centroide de todos los vectores de resultado, es decir, (s1 + s2 + . . . + sn)/n. La similitud del coseno entre los dos resultados promedio se calcula como s avg · savg/ s 2 avg · s2 avg. Si el valor de similitud supera un umbral predefinido, se considerará que las dos consultas están en la misma sesión de información. Si se determina que la consulta anterior y la consulta actual pertenecen a la misma sesión de búsqueda, UCAIR intentaría expandir la consulta actual con términos de la consulta anterior y sus resultados de búsqueda. Específicamente, para cada término en la consulta anterior o los resultados de búsqueda correspondientes, si su frecuencia en los resultados de la consulta actual es mayor que un umbral preestablecido (por ejemplo, 5 resultados de 50), el término se agregaría a la consulta actual para formar una consulta ampliada. En este caso, UCAIR enviaría esta consulta ampliada en lugar de la original al motor de búsqueda y devolvería los resultados correspondientes a la consulta ampliada. Actualmente, UCAIR solo utiliza la consulta inmediatamente anterior para la expansión de consultas; en principio, podríamos aprovechar todas las consultas pasadas relacionadas. 4.3 Actualización del modelo de necesidad de información Supongamos que en el tiempo t, hemos observado que el usuario ha visto k documentos cuyos resúmenes son s1, ..., sk. Actualizamos nuestro modelo de usuario calculando un nuevo vector de necesidad de información con un método estándar de retroalimentación en la recuperación de información (es decir, Rocchio [19]). Según el modelo de recuperación de espacio vectorial, cada resumen clicado si puede ser representado por un vector de pesos de términos si, con cada término ponderado por una fórmula de ponderación TF-IDF [21]. Rocchio calcula el vector centroide de todos los resúmenes e interpola este con el vector de consulta original para obtener un vector de términos actualizado. Es decir, x = αq + (1 − α) 1 k k i=1 si donde q es el vector de consulta, k es el número de resúmenes que el usuario hace clic inmediatamente después de la consulta actual y α es un parámetro que controla la influencia de los resúmenes clicados en el modelo de necesidad de información inferida. En nuestros experimentos, α se establece en 0.5. Ten en cuenta que actualizamos el modelo de información necesario cada vez que el usuario ve un documento. 4.4 Reclasificación de resultados En general, queremos volver a clasificar todos los resultados no vistos tan pronto como se actualice el modelo de usuario. Actualmente, UCAIR implementa el reordenamiento en dos casos, correspondientes a cuando el usuario hace clic en el botón Atrás y en el enlace Siguiente en Internet Explorer. En ambos casos, el modelo de usuario actualizado se utilizaría para reordenar los resultados no vistos de manera que el usuario vea resultados de búsqueda mejorados de inmediato. Para volver a clasificar cualquier resumen de documento no visto, UCAIR utiliza el modelo estándar de recuperación de espacio vectorial y puntúa cada resumen en función de la similitud del resultado y el vector de necesidad de información actual del usuario x [21]. Dado que la retroalimentación implícita no es completamente confiable, presentamos solo un pequeño número (por ejemplo, 5) de los resultados reordenados más altos para ser seguidos por cualquier resultado originalmente clasificado alto. 828 resultados de Google (consulta del usuario = mapa de Java) Resultados de UCAIR (consulta del usuario = mapa de Java) consulta anterior = viajar a Indonesia consulta anterior = tabla hash consulta del usuario ampliada = mapa de Java Indonesia consulta del usuario ampliada = clase de mapa de Java 1 Proyecciones de mapas de Java del mundo ... Lonely Planet - Mapa de Indonesia Mapa (Plataforma Java SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Proyecciones de mapas de Java del mundo ... TURISMO DE INDONESIA: JAVA CENTRAL - MAPA Plataforma Java SE v1.3.1: Interfaz de Mapa www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Mapa de Java TURISMO DE INDONESIA: JAVA OESTE - MAPA Una introducción a las clases de colección de mapas de Java java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Mapa de Tecnología Java IndoStreets - Mapa de Java Una introducción a las clases de colección de mapas de Java java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Regiones e islas de Indonesia Mapas, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 Una introducción a las clases de colección de mapas de Java Mapa de calles de la ciudad de Indonesia,... Hibernate simplifica el mapeo de herencia www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Mapa de Java Mapas de Indonesia jerarquía de clases de tmap 30.map www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Mapa de API de Java Mapas de Indonesia por Peter Loud Alcance de clases www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas: Mapas de Sam de Indonesia por Peter Loud PrintSafeHashMap de la clase www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 TURISMO DE INDONESIA: JAVA OESTE - MAPA indonesiaphoto.com Java Pro - Unión y mapeo vertical de clases www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Tabla 1: Resultados de muestra de la expansión de la consulta EVALUACIÓN DE UCAIR Ahora presentamos algunos resultados sobre la evaluación de las dos principales funciones de UCAIR: la expansión selectiva de consultas y la reordenación de resultados basada en los datos de clics de los usuarios. 5.1 Resultados de muestra La estrategia de expansión de consultas implementada en UCAIR es intencionalmente conservadora para evitar la interpretación errónea de los modelos implícitos de los usuarios. En la práctica, cada vez que decide expandir la consulta, la expansión suele tener sentido. En la Tabla 1, mostramos cómo UCAIR puede distinguir exitosamente dos contextos de búsqueda diferentes para la consulta java map, correspondientes a dos consultas previas distintas (es decir, viajar a Indonesia vs. hashtable). Debido a la modelización implícita del usuario, UCAIR descubre inteligentemente agregar Indonesia y clase, respectivamente, a la consulta de los usuarios sobre el mapa de Java, lo cual de otro modo sería ambiguo, como se muestra en los resultados originales de Google el 21 de marzo de 2005. Los resultados de UCAIR son mucho más precisos que los resultados de Google y reflejan la personalización en la búsqueda. El componente de retroalimentación implícita entusiasta está diseñado para responder inmediatamente a la actividad de un usuario, como por ejemplo, al visualizar un documento. En la Figura 2, mostramos cómo UCAIR puede desambiguar con éxito una consulta ambigua de jaguar al explotar un resumen del documento visualizado. En este caso, los resultados iniciales de recuperación utilizando \"jaguar\" (mostrados en el lado izquierdo) contienen dos resultados sobre los autos Jaguar seguidos por dos resultados sobre el software Jaguar. Sin embargo, después de que el usuario ve el contenido de la página web del segundo resultado (sobre el automóvil Jaguar) y regresa a la página de resultados de búsqueda haciendo clic en el botón Atrás, UCAIR automáticamente selecciona dos nuevos resultados de búsqueda sobre automóviles Jaguar (mostrados en el lado derecho), mientras que los dos resultados originales sobre software de Jaguar se desplazan hacia abajo en la lista (no se ven en la imagen). 5.2 Evaluación cuantitativa Para evaluar UCAIR de manera cuantitativa, realizamos un estudio de usuario sobre la efectividad del componente de retroalimentación implícita ansiosa. Es un desafío evaluar cuantitativamente la mejora potencial en el rendimiento de nuestro modelo propuesto y UCAIR sobre Google de manera imparcial [7]. Aquí diseñamos un estudio de usuarios, en el cual los participantes realizarían una búsqueda web normal y evaluarían al azar y de forma anónima un conjunto de resultados mezclados de Google y UCAIR al final de la sesión de búsqueda; los participantes no saben si un resultado proviene de Google o de UCAIR. Reclutamos a 6 estudiantes de posgrado para este estudio de usuarios, quienes tienen diferentes antecedentes (3 en informática, 2 en biología y 1 en química). Los documentos que describen leyes para limitar el correo no deseado sin dar detalles de demandas judiciales o juicios penales no son relevantes. Utilizamos los temas de consulta de la pista Terabyte TREC 2 2004 [2] y la tarea de destilación de temas de la pista web TREC 2003 [4] de la manera que se describirá a continuación. Un ejemplo de tema del TREC 2004 Terabyte track aparece en la Figura 3. El título es una frase corta y puede ser utilizada como una consulta al sistema de recuperación. El campo de descripción proporciona una declaración ligeramente más larga del requisito del tema, generalmente expresado como una sola oración completa o pregunta. Finalmente, la narrativa proporciona información adicional necesaria para especificar completamente el requisito, expresado en forma de un breve párrafo. Inicialmente, cada participante exploraría 50 temas ya sea de la categoría Terabyte o de la categoría Web y elegiría los 5 o 7 temas más interesantes. Para cada tema seleccionado, el participante básicamente realizaría la búsqueda web normal utilizando UCAIR para encontrar muchas páginas web relevantes utilizando el título del tema de la consulta como la palabra clave inicial de la consulta. Durante este proceso, el participante puede ver los resultados de la búsqueda y posiblemente hacer clic en algunos interesantes para ver las páginas web, tal como en una búsqueda web normal. No hay ningún requisito o restricción sobre cuántas consultas debe enviar el participante o cuándo debe detener la búsqueda de un tema. Cuando el participante planea cambiar el tema de búsqueda, simplemente presionará un botón 2 de la Conferencia de Recuperación de Texto: http://trec.nist.gov/ 829 Figura 2: Capturas de pantalla para volver a clasificar los resultados y evaluar los resultados de búsqueda antes de cambiar al siguiente tema. En el momento de la evaluación, los 30 resultados mejor clasificados de Google y UCAIR (algunos se superponen) se mezclan aleatoriamente para que el participante no sepa si un resultado proviene de Google o de UCAIR. El participante luego juzgaría la relevancia de estos resultados. Medimos la precisión en los primeros n (n = 5, 10, 20, 30) documentos de Google y UCAIR. También evaluamos precisiones en diferentes niveles de recuperación. En total, 368 documentos fueron considerados relevantes a partir de los resultados de búsqueda de Google y 429 documentos fueron considerados relevantes por los participantes de UCAIR. Los diagramas de dispersión de precisión en los 10 y 20 documentos principales se muestran en la Figura 4 y la Figura 5 respectivamente (El diagrama de dispersión de precisión en los 30 documentos principales es muy similar al de los 20 documentos principales). Cada punto de los gráficos de dispersión representa las precisiones de Google y UCAIR en un tema de consulta. La Tabla 2 muestra la precisión promedio en los primeros n documentos entre 32 temas. A partir de la Figura 4, la Figura 5 y la Tabla 2, vemos que los resultados de búsqueda de UCAIR son consistentemente mejores que los de Google en todas las medidas. Además, la mejora en el rendimiento es más dramática para la precisión en los primeros 20 documentos que para la precisión en los primeros 10 documentos. Una explicación para esto es que cuanto más interacción tenga el usuario con el sistema, más datos de clics se espera que UCAIR pueda recopilar. Por lo tanto, el sistema de recuperación puede construir modelos de usuario implícitos más precisos, lo que conduce a una mayor precisión en la recuperación. El Método de Clasificación prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Mejora 8.0% 17.8% 20.2% 21.8% Tabla 2: Tabla de precisión promedio en los primeros n documentos para 32 temas de consulta El gráfico en la Figura 6 muestra las curvas de precisión-recuperación para UCAIR y Google, donde se observa claramente que el rendimiento de UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Gráfico de dispersión de Precisión en los 10 primeros documentos Figura 4: La precisión en los 10 primeros documentos de UCAIR y Google es consistentemente y considerablemente mejor que la de Google en todos los niveles de recuperación. 6. CONCLUSIONES En este artículo, estudiamos cómo aprovechar la modelización implícita del usuario para personalizar de manera inteligente la recuperación de información y mejorar la <br>precisión de la búsqueda</br>. A diferencia de la mayoría de trabajos anteriores, enfatizamos el uso del contexto de búsqueda inmediata y la información de retroalimentación implícita, así como la actualización rápida de los resultados de búsqueda para beneficiar al máximo a un usuario. Presentamos un marco de trabajo de toma de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos adecuados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para volver a clasificar inmediatamente cualquier documento que aún no haya sido visto por el usuario. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente (UCAIR) sobre un motor de búsqueda popular (Google). Los experimentos en la búsqueda web muestran que nuestro agente de búsqueda puede mejorar la <br>precisión de la búsqueda</br> en más de un 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Gráfico de dispersión de Precisión en los 20 documentos principales Figura 5: Precisión en los 20 documentos principales de UCAIR y Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 precisión recall Curvas de Precisión-Recall Resultado de Google Resultado de UCAIR Figura 6: Precisión en los 20 resultados principales de UCAIR y Google Google. Dado que la información implícita que aprovechamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional. El agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin necesidad de esfuerzo adicional por parte del usuario. AGRADECIMIENTO Agradecemos a los seis participantes de nuestros experimentos de evaluación. Este trabajo fue apoyado en parte por las subvenciones de la Fundación Nacional de Ciencias IIS-0347933 e IIS-0428472. REFERENCIAS [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman y O. Frieder. Análisis por hora de un registro de consultas web muy grande categorizado por tema. En Actas de SIGIR 2004, páginas 321-328, 2004. [2] C. Clarke, N. Craswell e I. Soboroff. Resumen de la pista de terabyte TREC 2004. En Actas de TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda y D. Brown. Indicadores implícitos de interés. En Actas de Interfaces de Usuario Inteligentes 2001, páginas 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson y M. Wu. Resumen de la pista web TREC 2003. En Actas de TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend y V. Larvrenko. Retroalimentación de relevancia y personalización: Una perspectiva de modelado del lenguaje. En Actas del Segundo Taller DELOS: Personalización y Sistemas de Recomendación en Bibliotecas Digitales, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite y D. Harman. Resultados y desafíos en la evaluación de búsqueda en la web. Redes de Computadoras, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A. An, y D. Schuurmans. Identificación dinámica de sesiones de registro web con modelos de lenguaje estadístico. Revista de la Sociedad Americana de Ciencia de la Información y Tecnología, 55(14):1290-1303, 2004. [9] G. Jeh y J. Widom. Escalando la búsqueda web personalizada. En Actas de WWW 2003, páginas 271-279, 2003. [10] T. Joachims. Optimización de motores de búsqueda utilizando datos de clics. En Actas de SIGKDD 2002, páginas 133-142, 2002. [11] D. Kelly y J. Teevan. Retroalimentación implícita para inferir preferencias de usuario: Una bibliografía. SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En Actas de SIGIR01, páginas 111-119, 2001. [13] T. Lau y E. Horvitz. Patrones de búsqueda: Análisis y modelado de la refinación de consultas web. En Actas de la Séptima Conferencia Internacional sobre Modelado de Usuarios (UM), páginas 145-152, 1999. [14] V. Lavrenko y B. Croft. Modelos de lenguaje basados en relevancia. En Actas de SIGIR01, páginas 120-127, 2001. [15] M. Mitra, A. Singhal y C. Buckley. Mejorando la expansión automática de consultas. En Actas de SIGIR 1998, páginas 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg. Según Google, así va la nación. New York Times, mayo de 2003. [18] S. E. Robertson. El principio de clasificación de probabilidad en ı˚. Revista de Documentación, 33(4):294-304, 1977. [19] J. J. Rocchio. Retroalimentación de relevancia en la recuperación de información. En el Sistema de Recuperación SMART: Experimentos en el Procesamiento Automático de Documentos, páginas 313-323. Prentice-Hall Inc., 1971. [20] G. Salton y C. Buckley. Mejorando el rendimiento de recuperación mediante retroalimentación de recuperación. Revista de la Sociedad Americana de Ciencia de la Información, 41(4):288-297, 1990. [21] G. Salton y M. J. McGill. Introducción a la Recuperación de Información Moderna. McGraw-Hill, 1983. [22] X. Shen, B. Tan y C. Zhai. Recuperación de información sensible al contexto utilizando retroalimentación implícita. En Actas de SIGIR 2005, páginas 43-50, 2005. [23] X. Shen y C. Zhai. Explotando el historial de consultas para la clasificación de documentos en la recuperación de información interactiva (Póster). En Actas de SIGIR 2003, páginas 377-378, 2003. [24] A. Singhal. Recuperación de información moderna: Una breve visión general. Boletín del Comité Técnico de Ingeniería de Datos de la Sociedad de Computación de IEEE, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano y M. Yoshikawa. Búsqueda web adaptativa basada en el perfil del usuario construido sin ningún esfuerzo por parte de los usuarios. En Actas de WWW 2004, páginas 675-684, 2004. [26] E. Volokh. Personalización y privacidad. Comunicaciones de la ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen e I. Ruthven. Un estudio simulado de modelos de retroalimentación implícita. En Actas de ECIR 2004, páginas 311-326, 2004. [28] J. Xu y W. B. Croft. Expansión de consultas utilizando análisis local y global de documentos. En Actas de SIGIR 1996, páginas 4-11, 1996. [29] C. Zhai y J. Lafferty. Modelo de retroalimentación basado en el modelo de recuperación de divergencia de KL. En Actas de la CIKM 2001, páginas 403-410, 2001. 831 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "personalize information retrieval": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Implicit User Modeling for Personalized Search Xuehua Shen, Bin Tan, ChengXiang Zhai Department of Computer Science University of Illinois at Urbana-Champaign ABSTRACT Information retrieval systems (e.g., web search engines) are critical for overcoming information overload.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users, resulting in inherently non-optimal retrieval performance.",
                "For example, a tourist and a programmer may use the same word java to search for different information, but the current search systems would return the same results.",
                "In this paper, we study how to infer a users interest from the users search context and use the inferred implicit user model for personalized search .",
                "We present a decision theoretic framework and develop techniques for implicit user modeling in information retrieval.",
                "We develop an intelligent client-side web search agent (UCAIR) that can perform eager implicit feedback, e.g., query expansion based on previous queries and immediate result reranking based on clickthrough information.",
                "Experiments on web search show that our search agent can improve search accuracy over the popular Google search engine.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models, Relevance feedback, Search Process General Terms Algorithms 1.",
                "INTRODUCTION Although many information retrieval systems (e.g., web search engines and digital library systems) have been successfully deployed, the current retrieval systems are far from optimal.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users [17].",
                "This inherent non-optimality is seen clearly in the following two cases: (1) Different users may use exactly the same query (e.g., Java) to search for different information (e.g., the Java island in Indonesia or the Java programming language), but existing IR systems return the same results for these users.",
                "Without considering the actual user, it is impossible to know which sense Java refers to in a query. (2) A users information needs may change over time.",
                "The same user may use Java sometimes to mean the Java island in Indonesia and some other times to mean the programming language.",
                "Without recognizing the search context, it would be again impossible to recognize the correct sense.",
                "In order to optimize retrieval accuracy, we clearly need to model the user appropriately and personalize search according to each individual user.",
                "The major goal of user modeling for information retrieval is to accurately model a users information need, which is, unfortunately, a very difficult task.",
                "Indeed, it is even hard for a user to precisely describe what his/her information need is.",
                "What information is available for a system to infer a users information need?",
                "Obviously, the users query provides the most direct evidence.",
                "Indeed, most existing retrieval systems rely solely on the query to model a users information need.",
                "However, since a query is often extremely short, the user model constructed based on a keyword query is inevitably impoverished .",
                "An effective way to improve user modeling in information retrieval is to ask the user to explicitly specify which documents are relevant (i.e., useful for satisfying his/her information need), and then to improve user modeling based on such examples of relevant documents.",
                "This is called relevance feedback, which has been proved to be quite effective for improving retrieval accuracy [19, 20].",
                "Unfortunately, in real world applications, users are usually reluctant to make the extra effort to provide relevant examples for feedback [11].",
                "It is thus very interesting to study how to infer a users information need based on any implicit feedback information, which naturally exists through user interactions and thus does not require any extra user effort.",
                "Indeed, several previous studies have shown that implicit user modeling can improve retrieval accuracy.",
                "In [3], a web browser (Curious Browser) is developed to record a users explicit relevance ratings of web pages (relevance feedback) and browsing behavior when viewing a page, such as dwelling time, mouse click, mouse movement and scrolling (implicit feedback).",
                "It is shown that the dwelling time on a page, amount of scrolling on a page and the combination of time and scrolling have a strong correlation with explicit relevance ratings, which suggests that implicit feedback may be helpful for inferring user information need.",
                "In [10], user clickthrough data is collected as training data to learn a retrieval function, which is used to produce a customized ranking of search results that suits a group of users preferences.",
                "In [25], the clickthrough data collected over a long time period is exploited through query expansion to improve retrieval accuracy. 824 While a user may have general long term interests and preferences for information, often he/she is searching for documents to satisfy an ad-hoc information need, which only lasts for a short period of time; once the information need is satisfied, the user would generally no longer be interested in such information.",
                "For example, a user may be looking for information about used cars in order to buy one, but once the user has bought a car, he/she is generally no longer interested in such information.",
                "In such cases, implicit feedback information collected over a long period of time is unlikely to be very useful, but the immediate search context and feedback information, such as which of the search results for the current information need are viewed, can be expected to be much more useful.",
                "Consider the query Java again.",
                "Any of the following immediate feedback information about the user could potentially help determine the intended meaning of Java in the query: (1) The previous query submitted by the user is hashtable (as opposed to, e.g., travel Indonesia). (2) In the search results, the user viewed a page where words such as programming, software, and applet occur many times.",
                "To the best of our knowledge, how to exploit such immediate and short-term search context to improve search has so far not been well addressed in the previous work.",
                "In this paper, we study how to construct and update a user model based on the immediate search context and implicit feedback information and use the model to improve the accuracy of ad-hoc retrieval.",
                "In order to maximally benefit the user of a retrieval system through implicit user modeling, we propose to perform eager implicit feedback.",
                "That is, as soon as we observe any new piece of evidence from the user, we would update the systems belief about the users information need and respond with improved retrieval results based on the updated user model.",
                "We present a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "In a traditional retrieval paradigm, the retrieval problem is to match a query with documents and rank documents according to their relevance values.",
                "As a result, the retrieval process is a simple independent cycle of query and result display.",
                "In the proposed new retrieval paradigm, the users search context plays an important role and the inferred implicit user model is exploited immediately to benefit the user.",
                "The new retrieval paradigm is thus fundamentally different from the traditional paradigm, and is inherently more general.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent UCAIR (User-Centered Adaptive Information Retrieval) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "Thus the developed search agent can improve existing web search performance without additional effort from the user.",
                "The remaining sections are organized as follows.",
                "In Section 2, we discuss the related work.",
                "In Section 3, we present a decisiontheoretic interactive retrieval framework for implicit user modeling.",
                "In Section 4, we present the design and implementation of an intelligent client-side web search agent (UCAIR) that performs eager implicit feedback.",
                "In Section 5, we report our experiment results using the search agent.",
                "Section 6 concludes our work. 2.",
                "RELATED WORK Implicit user modeling for personalized search has been studied in previous work, but our work differs from all previous work in several aspects: (1) We emphasize the exploitation of immediate search context such as the related immediately preceding query and the viewed documents in the same session, while most previous work relies on long-term collection of implicit feedback information [25]. (2) We perform eager feedback and bring the benefit of implicit user modeling as soon as any new implicit feedback information is available, while the previous work mostly exploits longterm implicit feedback [10]. (3) We propose a retrieval framework to integrate implicit user modeling with the interactive retrieval process, while the previous work either studies implicit user modeling separately from retrieval [3] or only studies specific retrieval models for exploiting implicit feedback to better match a query with documents [23, 27, 22]. (4) We develop and evaluate a personalized Web search agent with online user studies, while most existing work evaluates algorithms offline without real user interactions.",
                "Currently some search engines provide rudimentary personalization, such as Google Personalized web search [6], which allows users to explicitly describe their interests by selecting from predefined topics, so that those results that match their interests are brought to the top, and My Yahoo! search [16], which gives users the option to save web sites they like and block those they dislike.",
                "In contrast, UCAIR personalizes web search through implicit user modeling without any additional user efforts.",
                "Furthermore, the personalization of UCAIR is provided on the client side.",
                "There are two remarkable advantages on this.",
                "First, the user does not need to worry about the privacy infringement, which is a big concern for personalized search [26].",
                "Second, both the computation of personalization and the storage of the user profile are done at the client side so that the server load is reduced dramatically [9].",
                "There have been many works studying user query logs [1] or query dynamics [13].",
                "UCAIR makes direct use of a users query history to benefit the same user immediately in the same search session.",
                "UCAIR first judges whether two neighboring queries belong to the same information session and if so, it selects terms from the previous query to perform query expansion.",
                "Our query expansion approach is similar to automatic query expansion [28, 15, 5], but instead of using pseudo feedback to expand the query, we use users implicit feedback information to expand the current query.",
                "These two techniques may be combined. 3.",
                "OPTIMIZATION IN INTERACTIVE IR In interactive IR, a user interacts with the retrieval system through an action dialogue, in which the system responds to each user action with some system action.",
                "For example, the users action may be submitting a query and the systems response may be returning a list of 10 document summaries.",
                "In general, the space of user actions and system responses and their granularities would depend on the interface of a particular retrieval system.",
                "In principle, every action of the user can potentially provide new evidence to help the system better infer the users information need.",
                "Thus in order to respond optimally, the system should use all the evidence collected so far about the user when choosing a response.",
                "When viewed in this way, most existing search engines are clearly non-optimal.",
                "For example, if a user has viewed some documents on the first page of search results, when the user clicks on the Next link to fetch more results, an existing retrieval system would still return the next page of results retrieved based on the original query without considering the new evidence that a particular result has been viewed by the user. 825 We propose to optimize retrieval performance by adapting system responses based on every action that a user has taken, and cast the optimization problem as a decision task.",
                "Specifically, at any time, the system would attempt to do two tasks: (1) User model updating: Monitor any useful evidence from the user regarding his/her information need and update the user model as soon as such evidence is available; (2) Improving search results: Rerank immediately all the documents that the user has not yet seen, as soon as the user model is updated.",
                "We emphasize eager updating and reranking, which makes our work quite different from any existing work.",
                "Below we present a formal decision theoretic framework for optimizing retrieval performance through implicit user modeling in interactive information retrieval. 3.1 A decision-theoretic framework Let A be the set of all user actions and R(a) be the set of all possible system responses to a user action a ∈ A.",
                "At any time, let At = (a1, ..., at) be the observed sequence of user actions so far (up to time point t) and Rt−1 = (r1, ..., rt−1) be the responses that the system has made responding to the user actions.",
                "The systems goal is to choose an optimal response rt ∈ R(at) for the current user action at.",
                "Let M be the space of all possible user models.",
                "We further define a loss function L(a, r, m) ∈ , where a ∈ A is a user action, r ∈ R(a) is a system response, and m ∈ M is a user model.",
                "L(a, r, m) encodes our decision preferences and assesses the optimality of responding with r when the current user model is m and the current user action is a.",
                "According to Bayesian decision theory, the optimal decision at time t is to choose a response that minimizes the Bayes risk, i.e., r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) where P(mt|U, D, At, Rt−1) is the posterior probability of the user model mt given all the observations about the user U we have made up to time t. To simplify the computation of Equation 1, let us assume that the posterior probability mass P(mt|U, D, At, Rt−1) is mostly concentrated on the mode m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "We can then approximate the integral with the value of the loss function at m∗ t .",
                "That is, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) where m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "Leaving aside how to define and estimate these probabilistic models and the loss function, we can see that such a decision-theoretic formulation suggests that, in order to choose the optimal response to at, the system should perform two tasks: (1) compute the current user model and obtain m∗ t based on all the useful information. (2) choose a response rt to minimize the loss function value L(at, rt, m∗ t ).",
                "When at does not affect our belief about m∗ t , the first step can be omitted and we may reuse m∗ t−1 for m∗ t .",
                "Note that our framework is quite general since we can potentially model any kind of user actions and system responses.",
                "In most cases, as we may expect, the systems response is some ranking of documents, i.e., for most actions a, R(a) consists of all the possible rankings of the unseen documents, and the decision problem boils down to choosing the best ranking of unseen documents based on the most current user model.",
                "When a is the action of submitting a keyword query, such a response is exactly what a current retrieval system would do.",
                "However, we can easily imagine that a more intelligent web search engine would respond to a users clicking of the Next link (to fetch more unseen results) with a more optimized ranking of documents based on any viewed documents in the current page of results.",
                "In fact, according to our eager updating strategy, we may even allow a system to respond to a users clicking of browsers Back button after viewing a document in the same way, so that the user can maximally benefit from implicit feedback.",
                "These are precisely what our UCAIR system does. 3.2 User models A user model m ∈ M represents what we know about the user U, so in principle, it can contain any information about the user that we wish to model.",
                "We now discuss two important components in a user model.",
                "The first component is a component model of the users information need.",
                "Presumably, the most important factor affecting the optimality of the systems response is how well the response addresses the users information need.",
                "Indeed, at any time, we may assume that the system has some belief about what the user is interested in, which we model through a term vector x = (x1, ..., x|V |), where V = {w1, ..., w|V |} is the set of all terms (i.e., vocabulary) and xi is the weight of term wi.",
                "Such a term vector is commonly used in information retrieval to represent both queries and documents.",
                "For example, the vector-space model, assumes that both the query and the documents are represented as term vectors and the score of a document with respect to a query is computed based on the similarity between the query vector and the document vector [21].",
                "In a language modeling approach, we may also regard the query unigram language model [12, 29] or the relevance model [14] as a term vector representation of the users information need.",
                "Intuitively, x would assign high weights to terms that characterize the topics which the user is interested in.",
                "The second component we may include in our user model is the documents that the user has already viewed.",
                "Obviously, even if a document is relevant, if the user has already seen the document, it would not be useful to present the same document again.",
                "We thus introduce another variable S ⊂ D (D is the whole set of documents in the collection) to denote the subset of documents in the search results that the user has already seen/viewed.",
                "In general, at time t, we may represent a user model as mt = (S, x, At, Rt−1), where S is the seen documents, x is the systems understanding of the users information need, and (At, Rt−1) represents the users interaction history.",
                "Note that an even more general user model may also include other factors such as the users reading level and occupation.",
                "If we assume that the uncertainty of a user model mt is solely due to the uncertainty of x, the computation of our current estimate of user model m∗ t will mainly involve computing our best estimate of x.",
                "That is, the system would choose a response according to r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) where x∗ = argmaxx P(x|U, D, At, Rt−1).",
                "This is the decision mechanism implemented in the UCAIR system to be described later.",
                "In this system, we avoided specifying the probabilistic model P(x|U, D, At, Rt−1) by computing x∗ directly with some existing feedback method. 3.3 Loss functions The exact definition of loss function L depends on the responses, thus it is inevitably application-specific.",
                "We now briefly discuss some possibilities when the response is to rank all the unseen documents and present the top k of them.",
                "Let r = (d1, ..., dk) be the top k documents, S be the set of seen documents by the user, and x∗ be the systems best guess of the users information need.",
                "We 826 may simply define the loss associated with r as the negative sum of the probability that each of the di is relevant, i.e., L(a, r, m) = − k i=1 P(relevant|di, m).",
                "Clearly, in order to minimize this loss function, the optimal response r would contain the k documents with the highest probability of relevance, which is intuitively reasonable.",
                "One deficiency of this top-k loss function is that it is not sensitive to the internal order of the selected top k documents, so switching the ranking order of a non-relevant document and a relevant one would not affect the loss, which is unreasonable.",
                "To model ranking, we can introduce a factor of the user model - the probability of each of the k documents being viewed by the user, P(view|di), and define the following ranking loss function: L(a, r, m) = − k i=1 P(view|di)P(relevant|di, m) Since in general, if di is ranked above dj (i.e., i < j), P(view|di) > P(view|dj), this loss function would favor a decision to rank relevant documents above non-relevant ones, as otherwise, we could always switch di with dj to reduce the loss value.",
                "Thus the system should simply perform a regular retrieval and rank documents according to the probability of relevance [18].",
                "Depending on the users retrieval preferences, there can be many other possibilities.",
                "For example, if the user does not want to see redundant documents, the loss function should include some redundancy measure on r based on the already seen documents S. Of course, when the response is not to choose a ranked list of documents, we would need a different loss function.",
                "We discuss one such example that is relevant to the search agent that we implement.",
                "When a user enters a query qt (current action), our search agent relies on some existing search engine to actually carry out search.",
                "In such a case, even though the search agent does not have control of the retrieval algorithm, it can still attempt to optimize the search results through refining the query sent to the search engine and/or reranking the results obtained from the search engine.",
                "The loss functions for reranking are already discussed above; we now take a look at the loss functions for query refinement.",
                "Let f be the retrieval function of the search engine that our agent uses so that f(q) would give us the search results using query q.",
                "Given that the current action of the user is entering a query qt (i.e., at = qt), our response would be f(q) for some q.",
                "Since we have no choice of f, our decision is to choose a good q.",
                "Formally, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) which shows that our goal is to find q∗ = argminqL(qt, f(q), m), i.e., an optimal query that would give us the best f(q).",
                "A different choice of loss function L(qt, f(q), m) would lead to a different query refinement strategy.",
                "In UCAIR, we heuristically compute q∗ by expanding qt with terms extracted from rt−1 whenever qt−1 and qt have high similarity.",
                "Note that rt−1 and qt−1 are contained in m as part of the users interaction history. 3.4 Implicit user modeling Implicit user modeling is captured in our framework through the computation of x∗ = argmaxx P(x|U, D, At, Rt−1), i.e., the systems current belief of what the users information need is.",
                "Here again there may be many possibilities, leading to different algorithms for implicit user modeling.",
                "We now discuss a few of them.",
                "First, when two consecutive queries are related, the previous query can be exploited to enrich the current query and provide more search context to help disambiguation.",
                "For this purpose, instead of performing query expansion as we did in the previous section, we could also compute an updated x∗ based on the previous query and retrieval results.",
                "The computed new user model can then be used to rank the documents with a standard information retrieval model.",
                "Second, we can also infer a users interest based on the summaries of the viewed documents.",
                "When a user is presented with a list of summaries of top ranked documents, if the user chooses to skip the first n documents and to view the (n+1)-th document, we may infer that the user is not interested in the displayed summaries for the first n documents, but is attracted by the displayed summary of the (n + 1)-th document.",
                "We can thus use these summaries as negative and positive examples to learn a more accurate user model x∗ .",
                "Here many standard relevance feedback techniques can be exploited [19, 20].",
                "Note that we should use the displayed summaries, as opposed to the actual contents of those documents, since it is possible that the displayed summary of the viewed document is relevant, but the document content is actually not.",
                "Similarly, a displayed summary may mislead a user to skip a relevant document.",
                "Inferring user models based on such displayed information, rather than the actual content of a document is an important difference between UCAIR and some other similar systems.",
                "In UCAIR, both of these strategies for inferring an implicit user model are implemented. 4.",
                "UCAIR: A PERSONALIZED SEARCH AGENT 4.1 Design In this section, we present a client-side web search agent called UCAIR, in which we implement some of the methods discussed in the previous section for performing personalized search through implicit user modeling.",
                "UCAIR is a web browser plug-in 1 that acts as a proxy for web search engines.",
                "Currently, it is only implemented for Internet Explorer and Google, but it is a matter of engineering to make it run on other web browsers and interact with other search engines.",
                "The issue of privacy is a primary obstacle for deploying any real world applications involving serious user modeling, such as personalized search.",
                "For this reason, UCAIR is strictly running as a client-side search agent, as opposed to a server-side application.",
                "This way, the captured user information always resides on the computer that the user is using, thus the user does not need to release any information to the outside.",
                "Client-side personalization also allows the system to easily observe a lot of user information that may not be easily available to a server.",
                "Furthermore, performing personalized search on the client-side is more scalable than on the serverside, since the overhead of computation and storage is distributed among clients.",
                "As shown in Figure 1, the UCAIR toolbar has 3 major components: (1) The (implicit) user modeling module captures a users search context and history information, including the submitted queries and any clicked search results and infers search session boundaries. (2) The query modification module selectively improves the query formulation according to the current user model. (3) The result re-ranking module immediately re-ranks any unseen search results whenever the user model is updated.",
                "In UCAIR, we consider four basic user actions: (1) submitting a keyword query; (2) viewing a document; (3) clicking the Back button; (4) clicking the Next link on a result page.",
                "For each of these four actions, the system responds with, respectively, (1) 1 UCAIR is available at: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Search Engine (e.g., Google) Search History Log (e.g.,past queries, clicked results) Query Modification Result Re-Ranking User Modeling Result Buffer UCAIR Userquery results clickthrough… Figure 1: UCAIR architecture generating a ranked list of results by sending a possibly expanded query to a search engine; (2) updating the information need model x; (3) reranking the unseen results on the current result page based on the current model x; and (4) reranking the unseen pages and generating the next page of results based on the current model x.",
                "Behind these responses, there are three basic tasks: (1) Decide whether the previous query is related to the current query and if so expand the current query with useful terms from the previous query or the results of the previous query. (2) Update the information need model x based on a newly clicked document summary. (3) Rerank a set of unseen documents based on the current model x.",
                "Below we describe our algorithms for each of them. 4.2 Session boundary detection and query expansion To effectively exploit previous queries and their corresponding clickthrough information, UCAIR needs to judge whether two adjacent queries belong to the same search session (i.e., detect session boundaries).",
                "Existing work on session boundary detection is mostly in the context of web log analysis (e.g., [8]), and uses statistical information rather than textual features.",
                "Since our clientside agent does not have access to server query logs, we make session boundary decisions based on textual similarity between two queries.",
                "Because related queries do not necessarily share the same words (e.g., java island and travel Indonesia), it is insufficient to use only query text.",
                "Therefore we use the search results of the two queries to help decide whether they are topically related.",
                "For example, for the above queries java island and travel Indonesia, the words java, bali, island, indonesia and travel may occur frequently in both queries search results, yielding a high similarity score.",
                "We only use the titles and summaries of the search results to calculate the similarity since they are available in the retrieved search result page and fetching the full text of every result page would significantly slow down the process.",
                "To compensate for the terseness of titles and summaries, we retrieve more results than a user would normally view for the purpose of detecting session boundaries (typically 50 results).",
                "The similarity between the previous query q and the current query q is computed as follows.",
                "Let {s1, s2, . . . , sn } and {s1, s2, . . . , sn} be the result sets for the two queries.",
                "We use the pivoted normalization TF-IDF weighting formula [24] to compute a term weight vector si for each result si.",
                "We define the average result savg to be the centroid of all the result vectors, i.e., (s1 + s2 + . . . + sn)/n.",
                "The cosine similarity between the two average results is calculated as s avg · savg/ s 2 avg · s2 avg If the similarity value exceeds a predefined threshold, the two queries will be considered to be in the same information session.",
                "If the previous query and the current query are found to belong to the same search session, UCAIR would attempt to expand the current query with terms from the previous query and its search results.",
                "Specifically, for each term in the previous query or the corresponding search results, if its frequency in the results of the current query is greater than a preset threshold (e.g. 5 results out of 50), the term would be added to the current query to form an expanded query.",
                "In this case, UCAIR would send this expanded query rather than the original one to the search engine and return the results corresponding to the expanded query.",
                "Currently, UCAIR only uses the immediate preceding query for query expansion; in principle, we could exploit all related past queries. 4.3 Information need model updating Suppose at time t, we have observed that the user has viewed k documents whose summaries are s1, ..., sk.",
                "We update our user model by computing a new information need vector with a standard feedback method in information retrieval (i.e., Rocchio [19]).",
                "According to the vector space retrieval model, each clicked summary si can be represented by a term weight vector si with each term weighted by a TF-IDF weighting formula [21].",
                "Rocchio computes the centroid vector of all the summaries and interpolates it with the original query vector to obtain an updated term vector.",
                "That is, x = αq + (1 − α) 1 k k i=1 si where q is the query vector, k is the number of summaries the user clicks immediately following the current query and α is a parameter that controls the influence of the clicked summaries on the inferred information need model.",
                "In our experiments, α is set to 0.5.",
                "Note that we update the information need model whenever the user views a document. 4.4 Result reranking In general, we want to rerank all the unseen results as soon as the user model is updated.",
                "Currently, UCAIR implements reranking in two cases, corresponding to the user clicking the Back button and Next link in the Internet Explorer.",
                "In both cases, the current (updated) user model would be used to rerank the unseen results so that the user would see improved search results immediately.",
                "To rerank any unseen document summaries, UCAIR uses the standard vector space retrieval model and scores each summary based on the similarity of the result and the current user information need vector x [21].",
                "Since implicit feedback is not completely reliable, we bring up only a small number (e.g. 5) of highest reranked results to be followed by any originally high ranked results. 828 Google result (user query = java map) UCAIR result (user query =java map) previous query = travel Indonesia previous query = hashtable expanded user query = java map Indonesia expanded user query = java map class 1 Java map projections of the world ... Lonely Planet - Indonesia Map Map (Java 2 Platform SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Java map projections of the world ... INDONESIA TOURISM : CENTRAL JAVA - MAP Java 2 Platform SE v1.3.1: Interface Map www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Java Map INDONESIA TOURISM : WEST JAVA - MAP An Introduction to Java Map Collection Classes java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Java Technology Concept Map IndoStreets - Java Map An Introduction to Java Map Collection Classes java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Indonesia Regions and Islands Maps, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 An Introduction to Java Map Collection Classes Indonesia City Street Map,... Hibernate simplifies inheritance mapping www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Java Map Maps Of Indonesia tmap 30.map Class Hierarchy www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Java API Map Maps of Indonesia by Peter Loud Class Scope www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas : Sam Maps of Indonesia by Peter Loud Class PrintSafeHashMap www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 INDONESIA TOURISM : WEST JAVA - MAP indonesiaphoto.com Java Pro - Union and Vertical Mapping of Classes www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Table 1: Sample results of query expansion 5.",
                "EVALUATION OF UCAIR We now present some results on evaluating the two major UCAIR functions: selective query expansion and result reranking based on user clickthrough data. 5.1 Sample results The query expansion strategy implemented in UCAIR is intentionally conservative to avoid misinterpretation of implicit user models.",
                "In practice, whenever it chooses to expand the query, the expansion usually makes sense.",
                "In Table 1, we show how UCAIR can successfully distinguish two different search contexts for the query java map, corresponding to two different previous queries (i.e., travel Indonesia vs. hashtable).",
                "Due to implicit user modeling, UCAIR intelligently figures out to add Indonesia and class, respectively, to the users query java map, which would otherwise be ambiguous as shown in the original results from Google on March 21, 2005.",
                "UCAIRs results are much more accurate than Googles results and reflect personalization in search.",
                "The eager implicit feedback component is designed to immediately respond to a users activity such as viewing a document.",
                "In Figure 2, we show how UCAIR can successfully disambiguate an ambiguous query jaguar by exploiting a viewed document summary.",
                "In this case, the initial retrieval results using jaguar (shown on the left side) contain two results about the Jaguar cars followed by two results about the Jaguar software.",
                "However, after the user views the web page content of the second result (about Jaguar car) and returns to the search result page by clicking Back button, UCAIR automatically nominates two new search results about Jaguar cars (shown on the right side), while the original two results about Jaguar software are pushed down on the list (unseen from the picture). 5.2 Quantitative evaluation To further evaluate UCAIR quantitatively, we conduct a user study on the effectiveness of the eager implicit feedback component.",
                "It is a challenge to quantitatively evaluate the potential performance improvement of our proposed model and UCAIR over Google in an unbiased way [7].",
                "Here, we design a user study, in which participants would do normal web search and judge a randomly and anonymously mixed set of results from Google and UCAIR at the end of the search session; participants do not know whether a result comes from Google or UCAIR.",
                "We recruited 6 graduate students for this user study, who have different backgrounds (3 computer science, 2 biology, and 1 chem<top> <num> Number: 716 <title> Spammer arrest sue <desc> Description: Have any spammers been arrested or sued for sending unsolicited e-mail? <narr> Narrative: Instances of arrests, prosecutions, convictions, and punishments of spammers, and lawsuits against them are relevant.",
                "Documents which describe laws to limit spam without giving details of lawsuits or criminal trials are not relevant. </top> Figure 3: An example of TREC query topic, expressed in a form which might be given to a human assistant or librarian istry).",
                "We use query topics from TREC 2 2004 Terabyte track [2] and TREC 2003 Web track [4] topic distillation task in the way to be described below.",
                "An example topic from TREC 2004 Terabyte track appears in Figure 3.",
                "The title is a short phrase and may be used as a query to the retrieval system.",
                "The description field provides a slightly longer statement of the topic requirement, usually expressed as a single complete sentence or question.",
                "Finally the narrative supplies additional information necessary to fully specify the requirement, expressed in the form of a short paragraph.",
                "Initially, each participant would browse 50 topics either from Terabyte track or Web track and pick 5 or 7 most interesting topics.",
                "For each picked topic, the participant would essentially do the normal web search using UCAIR to find many relevant web pages by using the title of the query topic as the initial keyword query.",
                "During this process, the participant may view the search results and possibly click on some interesting ones to view the web pages, just as in a normal web search.",
                "There is no requirement or restriction on how many queries the participant must submit or when the participant should stop the search for one topic.",
                "When the participant plans to change the search topic, he/she will simply press a button 2 Text REtrieval Conference: http://trec.nist.gov/ 829 Figure 2: Screen shots for result reranking to evaluate the search results before actually switching to the next topic.",
                "At the time of evaluation, 30 top ranked results from Google and UCAIR (some are overlapping) are randomly mixed together so that the participant would not know whether a result comes from Google or UCAIR.",
                "The participant would then judge the relevance of these results.",
                "We measure precision at top n (n = 5, 10, 20, 30) documents of Google and UCAIR.",
                "We also evaluate precisions at different recall levels.",
                "Altogether, 368 documents judged as relevant from Google search results and 429 documents judged as relevant from UCAIR by participants.",
                "Scatter plots of precision at top 10 and top 20 documents are shown in Figure 4 and Figure 5 respectively (The scatter plot of precision at top 30 documents is very similar to precision at top 20 documents).",
                "Each point of the scatter plots represents the precisions of Google and UCAIR on one query topic.",
                "Table 2 shows the average precision at top n documents among 32 topics.",
                "From Figure 4, Figure 5 and Table 2, we see that the search results from UCAIR are consistently better than those from Google by all the measures.",
                "Moreover, the performance improvement is more dramatic for precision at top 20 documents than that at precision at top 10 documents.",
                "One explanation for this is that the more interaction the user has with the system, the more clickthrough data UCAIR can be expected to collect.",
                "Thus the retrieval system can build more precise implicit user models, which lead to better retrieval accuracy.",
                "Ranking Method prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Improvement 8.0% 17.8% 20.2% 21.8% Table 2: Table of average precision at top n documents for 32 query topics The plot in Figure 6 shows the precision-recall curves for UCAIR and Google, where it is clearly seen that the performance of UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Scatterplot of Precision at Top 10 Documents Figure 4: Precision at top 10 documents of UCAIR and Google is consistently and considerably better than that of Google at all levels of recall. 6.",
                "CONCLUSIONS In this paper, we studied how to exploit implicit user modeling to intelligently <br>personalize information retrieval</br> and improve search accuracy.",
                "Unlike most previous work, we emphasize the use of immediate search context and implicit feedback information as well as eager updating of search results to maximally benefit a user.",
                "We presented a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent (UCAIR) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Scatterplot of Precision at Top 20 documents Figure 5: Precision at top 20 documents of UCAIR and Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 recall precision Precision−Recall curves Google Result UCAIR Result Figure 6: Precision at top 20 result of UCAIR and Google Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "The developed search agent thus can improve existing web search performance without any additional effort from the user. 7.",
                "ACKNOWLEDGEMENT We thank the six participants of our evaluation experiments.",
                "This work was supported in part by the National Science Foundation grants IIS-0347933 and IIS-0428472. 8.",
                "REFERENCES [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman, and O. Frieder.",
                "Hourly analysis of a very large topically categorized web query log.",
                "In Proceedings of SIGIR 2004, pages 321-328, 2004. [2] C. Clarke, N. Craswell, and I. Soboroff.",
                "Overview of the TREC 2004 terabyte track.",
                "In Proceedings of TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda, and D. Brown.",
                "Implicit interest indicators.",
                "In Proceedings of Intelligent User Interfaces 2001, pages 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson, and M. Wu.",
                "Overview of the TREC 2003 web track.",
                "In Proceedings of TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend, and V. Larvrenko.",
                "Relevance feedback and personalization: A language modeling perspective.",
                "In Proeedings of Second DELOS Workshop: Personalisation and Recommender Systems in Digital Libraries, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite, and D. Harman.",
                "Results and challenges in web search evaluation.",
                "Computer Networks, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A.",
                "An, and D. Schuurmans.",
                "Dynamic web log session identification with statistical language models.",
                "Journal of the American Society for Information Science and Technology, 55(14):1290-1303, 2004. [9] G. Jeh and J. Widom.",
                "Scaling personalized web search.",
                "In Proceedings of WWW 2003, pages 271-279, 2003. [10] T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of SIGKDD 2002, pages 133-142, 2002. [11] D. Kelly and J. Teevan.",
                "Implicit feedback for inferring user preference: A bibliography.",
                "SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of SIGIR01, pages 111-119, 2001. [13] T. Lau and E. Horvitz.",
                "Patterns of search: Analyzing and modeling web query refinement.",
                "In Proceedings of the Seventh International Conference on User Modeling (UM), pages 145 -152, 1999. [14] V. Lavrenko and B. Croft.",
                "Relevance-based language models.",
                "In Proceedings of SIGIR01, pages 120-127, 2001. [15] M. Mitra, A. Singhal, and C. Buckley.",
                "Improving automatic query expansion.",
                "In Proceedings of SIGIR 1998, pages 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg.",
                "As google goes, so goes the nation.",
                "New York Times, May 2003. [18] S. E. Robertson.",
                "The probability ranking principle in ı˚.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] J. J. Rocchio.",
                "Relevance feedback in information retrieval.",
                "In The SMART Retrieval System: Experiments in Automatic Document Processing, pages 313-323.",
                "Prentice-Hall Inc., 1971. [20] G. Salton and C. Buckley.",
                "Improving retrieval performance by retrieval feedback.",
                "Journal of the American Society for Information Science, 41(4):288-297, 1990. [21] G. Salton and M. J. McGill.",
                "Introduction to Modern Information Retrieval.",
                "McGraw-Hill, 1983. [22] X. Shen, B. Tan, and C. Zhai.",
                "Context-sensitive information retrieval using implicit feedback.",
                "In Proceedings of SIGIR 2005, pages 43-50, 2005. [23] X. Shen and C. Zhai.",
                "Exploiting query history for document ranking in interactive information retrieval (Poster).",
                "In Proceedings of SIGIR 2003, pages 377-378, 2003. [24] A. Singhal.",
                "Modern information retrieval: A brief overview.",
                "Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano, and M. Yoshikawa.",
                "Adaptive web search based on user profile constructed without any effort from users.",
                "In Proceedings of WWW 2004, pages 675-684, 2004. [26] E. Volokh.",
                "Personalization and privacy.",
                "Communications of the ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen, and I. Ruthven.",
                "A simulated study of implicit feedback models.",
                "In Proceedings of ECIR 2004, pages 311-326, 2004. [28] J. Xu and W. B. Croft.",
                "Query expansion using local and global document analysis.",
                "In Proceedings of SIGIR 1996, pages 4-11, 1996. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in KL divergence retrieval model.",
                "In Proceedings of the CIKM 2001, pages 403-410, 2001. 831"
            ],
            "original_annotated_samples": [
                "CONCLUSIONS In this paper, we studied how to exploit implicit user modeling to intelligently <br>personalize information retrieval</br> and improve search accuracy."
            ],
            "translated_annotated_samples": [
                "CONCLUSIONES En este artículo, estudiamos cómo aprovechar la modelización implícita del usuario para personalizar de manera inteligente la recuperación de información y mejorar la precisión de la búsqueda."
            ],
            "translated_text": "Modelado implícito de usuarios para búsqueda personalizada Xuehua Shen, Bin Tan, ChengXiang Zhai Departamento de Ciencias de la Computación Universidad de Illinois en Urbana-Champaign RESUMEN Los sistemas de recuperación de información (por ejemplo, motores de búsqueda web) son críticos para superar la sobrecarga de información. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales, lo que resulta en un rendimiento de recuperación inherentemente no óptimo. Por ejemplo, un turista y un programador pueden usar la misma palabra \"java\" para buscar información diferente, pero los sistemas de búsqueda actuales devolverían los mismos resultados. En este artículo, estudiamos cómo inferir el interés de un usuario a partir del contexto de búsqueda del usuario y utilizar el modelo de usuario implícito inferido para la búsqueda personalizada. Presentamos un marco teórico de toma de decisiones y desarrollamos técnicas para el modelado implícito del usuario en la recuperación de información. Desarrollamos un agente de búsqueda web inteligente del lado del cliente (UCAIR) que puede realizar retroalimentación implícita ansiosa, por ejemplo, expansión de consultas basada en consultas anteriores y reordenamiento inmediato de resultados basado en información de clics. Los experimentos sobre la búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda sobre el popular motor de búsqueda Google. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación, Retroalimentación de relevancia, Proceso de búsqueda Términos Generales Algoritmos 1. Aunque muchos sistemas de recuperación de información (por ejemplo, motores de búsqueda web y sistemas de biblioteca digital) se han implementado con éxito, los sistemas de recuperación actuales están lejos de ser óptimos. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales [17]. Esta no optimalidad inherente se ve claramente en los siguientes dos casos: (1) Diferentes usuarios pueden utilizar exactamente la misma consulta (por ejemplo, Java) para buscar información diferente (por ejemplo, la isla de Java en Indonesia o el lenguaje de programación Java), pero los sistemas de IR existentes devuelven los mismos resultados para estos usuarios. Sin considerar al usuario actual, es imposible saber a qué sentido se refiere Java en una consulta. (2) Las necesidades de información de un usuario pueden cambiar con el tiempo. El mismo usuario puede usar Java a veces para referirse a la isla de Java en Indonesia y otras veces para referirse al lenguaje de programación. Sin reconocer el contexto de búsqueda, sería nuevamente imposible reconocer el sentido correcto. Para optimizar la precisión de la recuperación, claramente necesitamos modelar al usuario de manera adecuada y personalizar la búsqueda según cada usuario individual. El objetivo principal del modelado de usuario para la recuperación de información es modelar con precisión la necesidad de información de un usuario, lo cual, desafortunadamente, es una tarea muy difícil. De hecho, incluso resulta difícil para un usuario describir con precisión cuál es su necesidad de información. ¿Qué información está disponible para que un sistema pueda inferir la necesidad de información de un usuario? Obviamente, la consulta de los usuarios proporciona la evidencia más directa. De hecho, la mayoría de los sistemas de recuperación existentes se basan únicamente en la consulta para modelar la necesidad de información de los usuarios. Sin embargo, dado que una consulta suele ser extremadamente corta, el modelo de usuario construido basado en una consulta de palabras clave inevitablemente resulta empobrecido. Una forma efectiva de mejorar la modelización de usuarios en la recuperación de información es pedir al usuario que especifique explícitamente qué documentos son relevantes (es decir, útiles para satisfacer su necesidad de información) y luego mejorar la modelización de usuarios basándose en ejemplos de documentos relevantes. Esto se llama retroalimentación de relevancia, lo cual ha demostrado ser bastante efectivo para mejorar la precisión de recuperación [19, 20]. Desafortunadamente, en aplicaciones del mundo real, los usuarios suelen ser reacios a hacer el esfuerzo adicional de proporcionar ejemplos relevantes para retroalimentación [11]. Por lo tanto, es muy interesante estudiar cómo inferir la necesidad de información de un usuario basándose en cualquier información de retroalimentación implícita, la cual existe naturalmente a través de las interacciones del usuario y no requiere ningún esfuerzo adicional por parte del usuario. De hecho, varios estudios previos han demostrado que el modelado implícito del usuario puede mejorar la precisión de recuperación. En [3], se desarrolla un navegador web (Curious Browser) para registrar las calificaciones explícitas de relevancia de las páginas web por parte de los usuarios (retroalimentación de relevancia) y el comportamiento de navegación al ver una página, como el tiempo de permanencia, clics de ratón, movimiento del ratón y desplazamiento (retroalimentación implícita). Se muestra que el tiempo de permanencia en una página, la cantidad de desplazamiento en una página y la combinación de tiempo y desplazamiento tienen una fuerte correlación con las calificaciones de relevancia explícita, lo que sugiere que la retroalimentación implícita puede ser útil para inferir la necesidad de información del usuario. En [10], se recopilan datos de clics de usuario como datos de entrenamiento para aprender una función de recuperación, que se utiliza para producir un ranking personalizado de resultados de búsqueda que se adapte a las preferencias de un grupo de usuarios. En [25], los datos de clics recopilados durante un largo período de tiempo se utilizan a través de la expansión de consultas para mejorar la precisión de recuperación. Si bien un usuario puede tener intereses y preferencias generales a largo plazo para la información, a menudo está buscando documentos para satisfacer una necesidad de información ad-hoc, que solo dura un corto período de tiempo; una vez que se satisface la necesidad de información, el usuario generalmente ya no estaría interesado en esa información. Por ejemplo, un usuario puede estar buscando información sobre autos usados para comprar uno, pero una vez que el usuario ha comprado un auto, generalmente ya no está interesado en esa información. En tales casos, la información de retroalimentación implícita recopilada durante un largo período de tiempo es poco probable que sea muy útil, pero el contexto de búsqueda inmediato y la información de retroalimentación, como cuáles de los resultados de búsqueda para la necesidad de información actual son vistos, se espera que sean mucho más útiles. Considera la consulta de Java nuevamente. Cualquiera de la siguiente información de retroalimentación inmediata sobre el usuario podría potencialmente ayudar a determinar el significado previsto de Java en la consulta: (1) La consulta anterior enviada por el usuario es hashtable (en lugar de, por ejemplo, viajar a Indonesia). (2) En los resultados de búsqueda, el usuario visualizó una página donde palabras como programación, software y applet ocurren muchas veces. Hasta donde sabemos, cómo aprovechar este contexto de búsqueda inmediato y a corto plazo para mejorar la búsqueda aún no ha sido abordado de manera satisfactoria en trabajos anteriores. En este artículo, estudiamos cómo construir y actualizar un modelo de usuario basado en el contexto de búsqueda inmediato y la información de retroalimentación implícita, y utilizar el modelo para mejorar la precisión de la recuperación ad-hoc. Para beneficiar al máximo al usuario de un sistema de recuperación a través de modelado implícito del usuario, proponemos realizar retroalimentación implícita entusiasta. Es decir, tan pronto como observemos cualquier nueva pieza de evidencia del usuario, actualizaríamos la creencia del sistema sobre la necesidad de información del usuario y responderíamos con resultados de recuperación mejorados basados en el modelo de usuario actualizado. Presentamos un marco de trabajo de teoría de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. En un paradigma de recuperación tradicional, el problema de recuperación consiste en emparejar una consulta con documentos y clasificar los documentos según sus valores de relevancia. Como resultado, el proceso de recuperación es un ciclo independiente simple de consulta y visualización de resultados. En el nuevo paradigma de recuperación propuesto, el contexto de búsqueda de los usuarios juega un papel importante y el modelo de usuario implícito inferido se explota inmediatamente para beneficiar al usuario. El nuevo paradigma de recuperación es, por lo tanto, fundamentalmente diferente del paradigma tradicional y es inherentemente más general. Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos apropiados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para reordenar inmediatamente cualquier documento que aún no haya sido visto por el usuario. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente UCAIR (Recuperación de Información Adaptativa Centrada en el Usuario) sobre un motor de búsqueda popular (Google). Los experimentos sobre búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en comparación con Google. Dado que la información implícita que explotamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional. Por lo tanto, el agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin esfuerzo adicional por parte del usuario. Las secciones restantes están organizadas de la siguiente manera. En la Sección 2, discutimos el trabajo relacionado. En la Sección 3, presentamos un marco de recuperación interactiva basado en teoría de decisiones para modelado implícito de usuarios. En la Sección 4, presentamos el diseño e implementación de un agente de búsqueda web inteligente del lado del cliente (UCAIR) que realiza retroalimentación implícita ansiosa. En la Sección 5, informamos nuestros resultados experimentales utilizando el agente de búsqueda. La sección 6 concluye nuestro trabajo. 2. El modelado implícito del usuario para la búsqueda personalizada ha sido estudiado en trabajos anteriores, pero nuestro trabajo difiere de todos los trabajos anteriores en varios aspectos: (1) Enfatizamos la explotación del contexto de búsqueda inmediato, como la consulta inmediatamente anterior relacionada y los documentos vistos en la misma sesión, mientras que la mayoría de los trabajos anteriores se basan en la recopilación a largo plazo de información de retroalimentación implícita [25]. (2) Realizamos una retroalimentación activa y obtenemos el beneficio del modelado implícito del usuario tan pronto como esté disponible cualquier nueva información de retroalimentación implícita, mientras que el trabajo anterior mayormente explota la retroalimentación implícita a largo plazo [10]. (3) Proponemos un marco de recuperación para integrar el modelado implícito del usuario con el proceso interactivo de recuperación, mientras que el trabajo anterior estudia el modelado implícito del usuario por separado de la recuperación [3] o solo estudia modelos de recuperación específicos para explotar la retroalimentación implícita para mejorar la coincidencia de una consulta con documentos [23, 27, 22]. (4) Desarrollamos y evaluamos un agente de búsqueda web personalizado con estudios de usuario en línea, mientras que la mayoría de los trabajos existentes evalúan algoritmos fuera de línea sin interacciones reales de usuarios. Actualmente algunos motores de búsqueda ofrecen personalización rudimentaria, como la búsqueda web personalizada de Google [6], que permite a los usuarios describir explícitamente sus intereses seleccionando entre temas predefinidos, de modo que los resultados que coinciden con sus intereses se muestren en la parte superior, y la búsqueda de My Yahoo! [16], que brinda a los usuarios la opción de guardar los sitios web que les gustan y bloquear aquellos que no les gustan. Por el contrario, UCAIR personaliza la búsqueda web a través de la modelización implícita del usuario sin necesidad de esfuerzos adicionales por parte del usuario. Además, la personalización de UCAIR se proporciona en el lado del cliente. Hay dos ventajas notables en esto. Primero, el usuario no necesita preocuparse por la infracción de privacidad, que es una gran preocupación para la búsqueda personalizada [26]. En segundo lugar, tanto el cálculo de la personalización como el almacenamiento del perfil del usuario se realizan en el lado del cliente para reducir drásticamente la carga del servidor [9]. Ha habido muchos trabajos estudiando los registros de consultas de usuarios [1] o la dinámica de consultas [13]. UCAIR hace uso directo del historial de consultas de un usuario para beneficiar al mismo usuario de inmediato en la misma sesión de búsqueda. UCAIR primero determina si dos consultas vecinas pertenecen a la misma sesión de información y, de ser así, selecciona términos de la consulta anterior para realizar la expansión de la consulta. Nuestro enfoque de expansión de consultas es similar a la expansión automática de consultas [28, 15, 5], pero en lugar de utilizar retroalimentación pseudo para expandir la consulta, utilizamos la información de retroalimentación implícita de los usuarios para expandir la consulta actual. Estas dos técnicas pueden ser combinadas. 3. OPTIMIZACIÓN EN IR INTERACTIVO En IR interactivo, un usuario interactúa con el sistema de recuperación a través de un diálogo de acción, en el cual el sistema responde a cada acción del usuario con alguna acción del sistema. Por ejemplo, la acción de los usuarios puede ser enviar una consulta y la respuesta del sistema puede ser devolver una lista de 10 resúmenes de documentos. En general, el espacio de acciones del usuario y respuestas del sistema y sus granularidades dependerían de la interfaz de un sistema de recuperación particular. En principio, cada acción del usuario puede potencialmente proporcionar nuevas pruebas para ayudar al sistema a inferir mejor la necesidad de información del usuario. Por lo tanto, para responder de manera óptima, el sistema debería utilizar toda la evidencia recopilada hasta ahora sobre el usuario al elegir una respuesta. Cuando se ven de esta manera, la mayoría de los motores de búsqueda existentes son claramente no óptimos. Por ejemplo, si un usuario ha visto algunos documentos en la primera página de resultados de búsqueda, cuando el usuario hace clic en el enlace Siguiente para obtener más resultados, un sistema de recuperación existente seguiría devolviendo la siguiente página de resultados recuperados en función de la consulta original sin considerar la nueva evidencia de que un resultado en particular ha sido visto por el usuario. Proponemos optimizar el rendimiento de la recuperación adaptando las respuestas del sistema en función de cada acción que un usuario haya tomado, y planteamos el problema de optimización como una tarea de decisión. Específicamente, en cualquier momento, el sistema intentaría realizar dos tareas: (1) Actualización del modelo de usuario: Monitorear cualquier evidencia útil del usuario con respecto a su necesidad de información y actualizar el modelo de usuario tan pronto como esta evidencia esté disponible; (2) Mejorar los resultados de búsqueda: Reclasificar inmediatamente todos los documentos que el usuario aún no ha visto, tan pronto como se actualice el modelo de usuario. Enfatizamos la actualización y reordenamiento entusiastas, lo que hace que nuestro trabajo sea bastante diferente a cualquier trabajo existente. A continuación presentamos un marco formal de teoría de decisiones para optimizar el rendimiento de recuperación a través de la modelización implícita del usuario en la recuperación de información interactiva. 3.1 Un marco de teoría de decisiones Sea A el conjunto de todas las acciones del usuario y R(a) el conjunto de todas las posibles respuestas del sistema a una acción del usuario a ∈ A. En cualquier momento, sea At = (a1, ..., at) la secuencia observada de acciones de usuario hasta ahora (hasta el momento t) y Rt−1 = (r1, ..., rt−1) las respuestas que el sistema ha dado en respuesta a las acciones del usuario. El objetivo del sistema es elegir una respuesta óptima rt ∈ R(at) para la acción actual del usuario at. Sea M el espacio de todos los posibles modelos de usuario. Definimos además una función de pérdida L(a, r, m) ∈ , donde a ∈ A es una acción del usuario, r ∈ R(a) es una respuesta del sistema, y m ∈ M es un modelo de usuario. L(a, r, m) codifica nuestras preferencias de decisión y evalúa la optimalidad de responder con r cuando el modelo de usuario actual es m y la acción de usuario actual es a. Según la teoría de decisión bayesiana, la decisión óptima en el tiempo t es elegir una respuesta que minimice el riesgo de Bayes, es decir, r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) donde P(mt|U, D, At, Rt−1) es la probabilidad posterior del modelo de usuario mt dadas todas las observaciones sobre el usuario U que hemos realizado hasta el tiempo t. Para simplificar el cálculo de la Ecuación 1, asumamos que la masa de probabilidad posterior P(mt|U, D, At, Rt−1) está principalmente concentrada en el modo m∗ t = argmaxmt P(mt|U, D, At, Rt−1). Podemos entonces aproximar la integral con el valor de la función de pérdida en m∗ t. Es decir, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) donde m∗ t = argmaxmt P(mt|U, D, At, Rt−1). Dejando de lado cómo definir y estimar estos modelos probabilísticos y la función de pérdida, podemos ver que tal formulación de la teoría de decisiones sugiere que, para elegir la respuesta óptima a at, el sistema debería realizar dos tareas: (1) calcular el modelo de usuario actual y obtener m∗ t basado en toda la información útil. (2) elegir una respuesta rt para minimizar el valor de la función de pérdida L(at, rt, m∗ t). Cuando at no afecta nuestra creencia sobre m∗ t , el primer paso puede omitirse y podemos reutilizar m∗ t−1 para m∗ t . Ten en cuenta que nuestro marco de trabajo es bastante general, ya que potencialmente podemos modelar cualquier tipo de acciones de usuario y respuestas del sistema. En la mayoría de los casos, como podríamos esperar, la respuesta del sistema es algún tipo de clasificación de documentos, es decir, para la mayoría de las acciones a, R(a) consiste en todas las posibles clasificaciones de los documentos no vistos, y el problema de decisión se reduce a elegir la mejor clasificación de los documentos no vistos basándose en el modelo de usuario más actualizado. Cuando a es la acción de enviar una consulta de palabras clave, tal respuesta es exactamente lo que haría un sistema de recuperación actual. Sin embargo, fácilmente podemos imaginar que un motor de búsqueda web más inteligente respondería al clic del usuario en el enlace Siguiente (para obtener más resultados no vistos) con una clasificación más optimizada de documentos basada en cualquier documento visto en la página actual de resultados. De hecho, según nuestra estrategia de actualización entusiasta, incluso podríamos permitir que un sistema responda al clic del botón Atrás del navegador por parte de un usuario después de ver un documento de la misma manera, para que el usuario pueda beneficiarse al máximo de la retroalimentación implícita. Estos son precisamente lo que nuestro sistema UCAIR hace. 3.2 Modelos de usuario Un modelo de usuario m ∈ M representa lo que sabemos sobre el usuario U, por lo que en principio, puede contener cualquier información sobre el usuario que deseemos modelar. Ahora discutimos dos componentes importantes en un modelo de usuario. El primer componente es un modelo de componente de la necesidad de información de los usuarios. Presumiblemente, el factor más importante que afecta la optimalidad de la respuesta del sistema es qué tan bien la respuesta aborda la necesidad de información de los usuarios. De hecho, en cualquier momento, podemos asumir que el sistema tiene alguna creencia sobre lo que le interesa al usuario, la cual modelamos a través de un vector de términos x = (x1, ..., x|V|), donde V = {w1, ..., w|V|} es el conjunto de todos los términos (es decir, vocabulario) y xi es el peso del término wi. Un vector de términos de este tipo se utiliza comúnmente en la recuperación de información para representar tanto consultas como documentos. Por ejemplo, el modelo de espacio vectorial asume que tanto la consulta como los documentos se representan como vectores de términos y que la puntuación de un documento con respecto a una consulta se calcula en función de la similitud entre el vector de la consulta y el vector del documento [21]. En un enfoque de modelado de lenguaje, también podemos considerar el modelo de lenguaje unigrama de consulta [12, 29] o el modelo de relevancia [14] como una representación vectorial de términos de la necesidad de información de los usuarios. Intuitivamente, x asignaría pesos altos a los términos que caracterizan los temas que interesan al usuario. El segundo componente que podemos incluir en nuestro modelo de usuario son los documentos que el usuario ya ha visto. Obviamente, incluso si un documento es relevante, si el usuario ya ha visto el documento, no sería útil presentar el mismo documento de nuevo. Por lo tanto, introducimos otra variable S ⊂ D (D es el conjunto completo de documentos en la colección) para denotar el subconjunto de documentos en los resultados de búsqueda que el usuario ya ha visto. En general, en el tiempo t, podemos representar un modelo de usuario como mt = (S, x, At, Rt−1), donde S son los documentos vistos, x es la comprensión del sistema de la necesidad de información del usuario, y (At, Rt−1) representa el historial de interacción del usuario. Ten en cuenta que un modelo de usuario aún más general también puede incluir otros factores como el nivel de lectura y la ocupación de los usuarios. Si asumimos que la incertidumbre de un modelo de usuario mt se debe únicamente a la incertidumbre de x, el cálculo de nuestra estimación actual del modelo de usuario m∗ t implicará principalmente calcular nuestra mejor estimación de x. Es decir, el sistema elegiría una respuesta de acuerdo a r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) donde x∗ = argmaxx P(x|U, D, At, Rt−1). Este es el mecanismo de decisión implementado en el sistema UCAIR que se describirá más adelante. En este sistema, evitamos especificar el modelo probabilístico P(x|U, D, At, Rt−1) calculando x∗ directamente con algún método de retroalimentación existente. 3.3 Funciones de pérdida La definición exacta de la función de pérdida L depende de las respuestas, por lo que es inevitablemente específica de la aplicación. Ahora discutimos brevemente algunas posibilidades cuando la respuesta es clasificar todos los documentos no vistos y presentar los mejores k de ellos. Sea r = (d1, ..., dk) los k documentos principales, S el conjunto de documentos vistos por el usuario, y x∗ la mejor suposición del sistema sobre la necesidad de información del usuario. Podemos definir simplemente la pérdida asociada con r como la suma negativa de la probabilidad de que cada uno de los di sea relevante, es decir, L(a, r, m) = − k i=1 P(relevante|di, m). Claramente, para minimizar esta función de pérdida, la respuesta óptima r contendría los k documentos con la probabilidad más alta de relevancia, lo cual es intuitivamente razonable. Una deficiencia de esta función de pérdida top-k es que no es sensible al orden interno de los documentos top k seleccionados, por lo que cambiar el orden de clasificación de un documento no relevante y uno relevante no afectaría la pérdida, lo cual es irrazonable. Para modelar el ranking, podemos introducir un factor del modelo de usuario: la probabilidad de que cada uno de los k documentos sea visto por el usuario, P(vista|di), y definir la siguiente función de pérdida de ranking: L(a, r, m) = − k i=1 P(vista|di)P(relevante|di, m). Dado que, en general, si di está clasificado por encima de dj (es decir, i < j), P(vista|di) > P(vista|dj), esta función de pérdida favorecería una decisión de clasificar documentos relevantes por encima de los no relevantes, ya que de lo contrario, siempre podríamos intercambiar di con dj para reducir el valor de pérdida. Por lo tanto, el sistema simplemente debería realizar una recuperación regular y clasificar los documentos según la probabilidad de relevancia [18]. Dependiendo de las preferencias de recuperación de los usuarios, puede haber muchas otras posibilidades. Por ejemplo, si el usuario no desea ver documentos redundantes, la función de pérdida debería incluir alguna medida de redundancia en r basada en los documentos ya vistos S. Por supuesto, cuando la respuesta no es elegir una lista clasificada de documentos, necesitaríamos una función de pérdida diferente. Discutimos un ejemplo relevante para el agente de búsqueda que implementamos. Cuando un usuario ingresa una consulta qt (acción actual), nuestro agente de búsqueda se basa en algún motor de búsqueda existente para llevar a cabo la búsqueda en realidad. En tal caso, aunque el agente de búsqueda no tenga control sobre el algoritmo de recuperación, aún puede intentar optimizar los resultados de la búsqueda refinando la consulta enviada al motor de búsqueda y/o reordenando los resultados obtenidos del motor de búsqueda. Las funciones de pérdida para el reordenamiento ya fueron discutidas anteriormente; ahora echamos un vistazo a las funciones de pérdida para el refinamiento de consultas. Sea f la función de recuperación del motor de búsqueda que nuestro agente utiliza, de modo que f(q) nos daría los resultados de búsqueda utilizando la consulta q. Dado que la acción actual del usuario es ingresar una consulta qt (es decir, at = qt), nuestra respuesta sería f(q) para algún q. Dado que no tenemos elección de f, nuestra decisión es elegir un buen q. Formalmente, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) lo cual muestra que nuestro objetivo es encontrar q∗ = argminqL(qt, f(q), m), es decir, una consulta óptima que nos daría el mejor f(q). Una elección diferente de la función de pérdida L(qt, f(q), m) llevaría a una estrategia de refinamiento de consulta diferente. En UCAIR, calculamos heurísticamente q∗ expandiendo qt con términos extraídos de rt−1 siempre que qt−1 y qt tengan una alta similitud. Se debe tener en cuenta que rt−1 y qt−1 están contenidos en m como parte del historial de interacción de los usuarios. 3.4 Modelado implícito del usuario El modelado implícito del usuario se captura en nuestro marco a través del cálculo de x∗ = argmaxx P(x|U, D, At, Rt−1), es decir, la creencia actual del sistema sobre cuál es la necesidad de información del usuario. Aquí nuevamente puede haber muchas posibilidades, lo que lleva a diferentes algoritmos para la modelización implícita del usuario. Ahora discutimos algunos de ellos. Primero, cuando dos consultas consecutivas están relacionadas, la consulta anterior puede ser explotada para enriquecer la consulta actual y proporcionar más contexto de búsqueda para ayudar en la desambiguación. Para este propósito, en lugar de realizar una expansión de consulta como lo hicimos en la sección anterior, también podríamos calcular un x∗ actualizado basado en la consulta anterior y los resultados de recuperación. El modelo de usuario nuevo calculado puede luego ser utilizado para clasificar los documentos con un modelo estándar de recuperación de información. Segundo, también podemos inferir los intereses de un usuario basándonos en los resúmenes de los documentos visualizados. Cuando a un usuario se le presenta una lista de resúmenes de documentos mejor clasificados, si el usuario elige saltarse los primeros n documentos y ver el documento (n+1)-ésimo, podemos inferir que el usuario no está interesado en los resúmenes mostrados para los primeros n documentos, pero está atraído por el resumen mostrado del documento (n+1)-ésimo. Por lo tanto, podemos usar estos resúmenes como ejemplos negativos y positivos para aprender un modelo de usuario más preciso x∗. Aquí se pueden explotar muchas técnicas estándar de retroalimentación de relevancia [19, 20]. Ten en cuenta que debemos utilizar los resúmenes mostrados, en lugar de los contenidos reales de esos documentos, ya que es posible que el resumen mostrado del documento visto sea relevante, pero el contenido del documento en realidad no lo sea. Del mismo modo, un resumen mostrado puede llevar a un usuario a omitir un documento relevante. Inferir modelos de usuario basados en dicha información mostrada, en lugar del contenido real de un documento, es una diferencia importante entre UCAIR y algunos otros sistemas similares. En UCAIR, ambas estrategias para inferir un modelo de usuario implícito están implementadas. 4. UCAIR: Un agente de búsqueda personalizado 4.1 Diseño En esta sección, presentamos un agente de búsqueda web del lado del cliente llamado UCAIR, en el cual implementamos algunos de los métodos discutidos en la sección anterior para realizar búsquedas personalizadas a través de modelado implícito del usuario. UCAIR es un complemento del navegador web que actúa como proxy para los motores de búsqueda en la web. Actualmente, solo está implementado para Internet Explorer y Google, pero es cuestión de ingeniería hacer que funcione en otros navegadores web e interactúe con otros motores de búsqueda. El tema de la privacidad es un obstáculo principal para implementar cualquier aplicación del mundo real que involucre modelado de usuarios serio, como la búsqueda personalizada. Por esta razón, UCAIR funciona estrictamente como un agente de búsqueda del lado del cliente, en lugar de ser una aplicación del lado del servidor. De esta manera, la información del usuario capturada siempre permanece en la computadora que está utilizando el usuario, por lo tanto, el usuario no necesita revelar ninguna información al exterior. La personalización del lado del cliente también permite que el sistema observe fácilmente una gran cantidad de información del usuario que puede no estar fácilmente disponible para un servidor. Además, realizar búsquedas personalizadas en el lado del cliente es más escalable que en el lado del servidor, ya que la sobrecarga de cálculo y almacenamiento se distribuye entre los clientes. Como se muestra en la Figura 1, la barra de herramientas UCAIR tiene 3 componentes principales: (1) El módulo de modelado de usuario (implícito) captura el contexto de búsqueda de un usuario e información de historial, incluidas las consultas enviadas y los resultados de búsqueda clicados, e infiere los límites de la sesión de búsqueda. (2) El módulo de modificación de consultas mejora selectivamente la formulación de la consulta de acuerdo con el modelo de usuario actual. (3) El módulo de reordenamiento de resultados reordena inmediatamente cualquier resultado de búsqueda no visto cada vez que se actualiza el modelo de usuario. En UCAIR, consideramos cuatro acciones básicas de usuario: (1) enviar una consulta de palabras clave; (2) ver un documento; (3) hacer clic en el botón Atrás; (4) hacer clic en el enlace Siguiente en una página de resultados. Para cada una de estas cuatro acciones, el sistema responde con, respectivamente, (1) 1 UCAIR está disponible en: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Registro de Historial de Búsqueda del Motor de Búsqueda (por ejemplo, Google) (consultas pasadas, resultados clicados) Modificación de Consulta Resultado de Reclasificación Modelo de Usuario Buffer de Resultados de Consulta de Usuario UCAIR... Figura 1: arquitectura de UCAIR generando una lista clasificada de resultados enviando una consulta posiblemente ampliada a un motor de búsqueda; (2) actualizando el modelo de necesidad de información x; (3) reordenando los resultados no vistos en la página de resultados actual basándose en el modelo actual x; y (4) reordenando las páginas no vistas y generando la siguiente página de resultados basándose en el modelo actual x. Detrás de estas respuestas, hay tres tareas básicas: (1) Decidir si la consulta anterior está relacionada con la consulta actual y, de ser así, ampliar la consulta actual con términos útiles de la consulta anterior o los resultados de la consulta anterior. (2) Actualizar el modelo de necesidad de información x basado en un resumen de documento recién seleccionado. (3) Reordenar un conjunto de documentos no vistos basado en el modelo x actual. A continuación describimos nuestros algoritmos para cada uno de ellos. 4.2 Detección de límites de sesión y expansión de consultas Para explotar eficazmente las consultas anteriores y su información correspondiente de clics, UCAIR necesita determinar si dos consultas adyacentes pertenecen a la misma sesión de búsqueda (es decir, detectar los límites de sesión). El trabajo existente sobre la detección de límites de sesión se encuentra principalmente en el contexto del análisis de registros web (por ejemplo, [8]), y utiliza información estadística en lugar de características textuales. Dado que nuestro agente del lado del cliente no tiene acceso a los registros de consultas del servidor, tomamos decisiones sobre los límites de sesión basadas en la similitud textual entre dos consultas. Debido a que las consultas relacionadas no necesariamente comparten las mismas palabras (por ejemplo, isla de Java y viajar a Indonesia), no es suficiente utilizar solo el texto de la consulta. Por lo tanto, utilizamos los resultados de búsqueda de las dos consultas para ayudar a decidir si están relacionadas temáticamente. Por ejemplo, para las consultas anteriores \"java island\" y \"travel Indonesia\", las palabras \"java\", \"bali\", \"island\", \"indonesia\" y \"travel\" pueden aparecer con frecuencia en los resultados de búsqueda de ambas consultas, lo que produce un alto puntaje de similitud. Solo utilizamos los títulos y resúmenes de los resultados de búsqueda para calcular la similitud, ya que están disponibles en la página de resultados de búsqueda recuperada y obtener el texto completo de cada página de resultados ralentizaría significativamente el proceso. Para compensar la concisión de los títulos y resúmenes, recuperamos más resultados de los que un usuario normalmente vería con el propósito de detectar los límites de sesión (típicamente 50 resultados). La similitud entre la consulta anterior q y la consulta actual q se calcula de la siguiente manera. Sean {s1, s2, . . . , sn} y {s1, s2, . . . , sn} los conjuntos de resultados de las dos consultas. Utilizamos la fórmula de ponderación TF-IDF normalizada pivotada [24] para calcular un vector de peso de término si para cada resultado si. Definimos el resultado promedio savg como el centroide de todos los vectores de resultado, es decir, (s1 + s2 + . . . + sn)/n. La similitud del coseno entre los dos resultados promedio se calcula como s avg · savg/ s 2 avg · s2 avg. Si el valor de similitud supera un umbral predefinido, se considerará que las dos consultas están en la misma sesión de información. Si se determina que la consulta anterior y la consulta actual pertenecen a la misma sesión de búsqueda, UCAIR intentaría expandir la consulta actual con términos de la consulta anterior y sus resultados de búsqueda. Específicamente, para cada término en la consulta anterior o los resultados de búsqueda correspondientes, si su frecuencia en los resultados de la consulta actual es mayor que un umbral preestablecido (por ejemplo, 5 resultados de 50), el término se agregaría a la consulta actual para formar una consulta ampliada. En este caso, UCAIR enviaría esta consulta ampliada en lugar de la original al motor de búsqueda y devolvería los resultados correspondientes a la consulta ampliada. Actualmente, UCAIR solo utiliza la consulta inmediatamente anterior para la expansión de consultas; en principio, podríamos aprovechar todas las consultas pasadas relacionadas. 4.3 Actualización del modelo de necesidad de información Supongamos que en el tiempo t, hemos observado que el usuario ha visto k documentos cuyos resúmenes son s1, ..., sk. Actualizamos nuestro modelo de usuario calculando un nuevo vector de necesidad de información con un método estándar de retroalimentación en la recuperación de información (es decir, Rocchio [19]). Según el modelo de recuperación de espacio vectorial, cada resumen clicado si puede ser representado por un vector de pesos de términos si, con cada término ponderado por una fórmula de ponderación TF-IDF [21]. Rocchio calcula el vector centroide de todos los resúmenes e interpola este con el vector de consulta original para obtener un vector de términos actualizado. Es decir, x = αq + (1 − α) 1 k k i=1 si donde q es el vector de consulta, k es el número de resúmenes que el usuario hace clic inmediatamente después de la consulta actual y α es un parámetro que controla la influencia de los resúmenes clicados en el modelo de necesidad de información inferida. En nuestros experimentos, α se establece en 0.5. Ten en cuenta que actualizamos el modelo de información necesario cada vez que el usuario ve un documento. 4.4 Reclasificación de resultados En general, queremos volver a clasificar todos los resultados no vistos tan pronto como se actualice el modelo de usuario. Actualmente, UCAIR implementa el reordenamiento en dos casos, correspondientes a cuando el usuario hace clic en el botón Atrás y en el enlace Siguiente en Internet Explorer. En ambos casos, el modelo de usuario actualizado se utilizaría para reordenar los resultados no vistos de manera que el usuario vea resultados de búsqueda mejorados de inmediato. Para volver a clasificar cualquier resumen de documento no visto, UCAIR utiliza el modelo estándar de recuperación de espacio vectorial y puntúa cada resumen en función de la similitud del resultado y el vector de necesidad de información actual del usuario x [21]. Dado que la retroalimentación implícita no es completamente confiable, presentamos solo un pequeño número (por ejemplo, 5) de los resultados reordenados más altos para ser seguidos por cualquier resultado originalmente clasificado alto. 828 resultados de Google (consulta del usuario = mapa de Java) Resultados de UCAIR (consulta del usuario = mapa de Java) consulta anterior = viajar a Indonesia consulta anterior = tabla hash consulta del usuario ampliada = mapa de Java Indonesia consulta del usuario ampliada = clase de mapa de Java 1 Proyecciones de mapas de Java del mundo ... Lonely Planet - Mapa de Indonesia Mapa (Plataforma Java SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Proyecciones de mapas de Java del mundo ... TURISMO DE INDONESIA: JAVA CENTRAL - MAPA Plataforma Java SE v1.3.1: Interfaz de Mapa www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Mapa de Java TURISMO DE INDONESIA: JAVA OESTE - MAPA Una introducción a las clases de colección de mapas de Java java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Mapa de Tecnología Java IndoStreets - Mapa de Java Una introducción a las clases de colección de mapas de Java java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Regiones e islas de Indonesia Mapas, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 Una introducción a las clases de colección de mapas de Java Mapa de calles de la ciudad de Indonesia,... Hibernate simplifica el mapeo de herencia www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Mapa de Java Mapas de Indonesia jerarquía de clases de tmap 30.map www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Mapa de API de Java Mapas de Indonesia por Peter Loud Alcance de clases www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas: Mapas de Sam de Indonesia por Peter Loud PrintSafeHashMap de la clase www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 TURISMO DE INDONESIA: JAVA OESTE - MAPA indonesiaphoto.com Java Pro - Unión y mapeo vertical de clases www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Tabla 1: Resultados de muestra de la expansión de la consulta EVALUACIÓN DE UCAIR Ahora presentamos algunos resultados sobre la evaluación de las dos principales funciones de UCAIR: la expansión selectiva de consultas y la reordenación de resultados basada en los datos de clics de los usuarios. 5.1 Resultados de muestra La estrategia de expansión de consultas implementada en UCAIR es intencionalmente conservadora para evitar la interpretación errónea de los modelos implícitos de los usuarios. En la práctica, cada vez que decide expandir la consulta, la expansión suele tener sentido. En la Tabla 1, mostramos cómo UCAIR puede distinguir exitosamente dos contextos de búsqueda diferentes para la consulta java map, correspondientes a dos consultas previas distintas (es decir, viajar a Indonesia vs. hashtable). Debido a la modelización implícita del usuario, UCAIR descubre inteligentemente agregar Indonesia y clase, respectivamente, a la consulta de los usuarios sobre el mapa de Java, lo cual de otro modo sería ambiguo, como se muestra en los resultados originales de Google el 21 de marzo de 2005. Los resultados de UCAIR son mucho más precisos que los resultados de Google y reflejan la personalización en la búsqueda. El componente de retroalimentación implícita entusiasta está diseñado para responder inmediatamente a la actividad de un usuario, como por ejemplo, al visualizar un documento. En la Figura 2, mostramos cómo UCAIR puede desambiguar con éxito una consulta ambigua de jaguar al explotar un resumen del documento visualizado. En este caso, los resultados iniciales de recuperación utilizando \"jaguar\" (mostrados en el lado izquierdo) contienen dos resultados sobre los autos Jaguar seguidos por dos resultados sobre el software Jaguar. Sin embargo, después de que el usuario ve el contenido de la página web del segundo resultado (sobre el automóvil Jaguar) y regresa a la página de resultados de búsqueda haciendo clic en el botón Atrás, UCAIR automáticamente selecciona dos nuevos resultados de búsqueda sobre automóviles Jaguar (mostrados en el lado derecho), mientras que los dos resultados originales sobre software de Jaguar se desplazan hacia abajo en la lista (no se ven en la imagen). 5.2 Evaluación cuantitativa Para evaluar UCAIR de manera cuantitativa, realizamos un estudio de usuario sobre la efectividad del componente de retroalimentación implícita ansiosa. Es un desafío evaluar cuantitativamente la mejora potencial en el rendimiento de nuestro modelo propuesto y UCAIR sobre Google de manera imparcial [7]. Aquí diseñamos un estudio de usuarios, en el cual los participantes realizarían una búsqueda web normal y evaluarían al azar y de forma anónima un conjunto de resultados mezclados de Google y UCAIR al final de la sesión de búsqueda; los participantes no saben si un resultado proviene de Google o de UCAIR. Reclutamos a 6 estudiantes de posgrado para este estudio de usuarios, quienes tienen diferentes antecedentes (3 en informática, 2 en biología y 1 en química). Los documentos que describen leyes para limitar el correo no deseado sin dar detalles de demandas judiciales o juicios penales no son relevantes. Utilizamos los temas de consulta de la pista Terabyte TREC 2 2004 [2] y la tarea de destilación de temas de la pista web TREC 2003 [4] de la manera que se describirá a continuación. Un ejemplo de tema del TREC 2004 Terabyte track aparece en la Figura 3. El título es una frase corta y puede ser utilizada como una consulta al sistema de recuperación. El campo de descripción proporciona una declaración ligeramente más larga del requisito del tema, generalmente expresado como una sola oración completa o pregunta. Finalmente, la narrativa proporciona información adicional necesaria para especificar completamente el requisito, expresado en forma de un breve párrafo. Inicialmente, cada participante exploraría 50 temas ya sea de la categoría Terabyte o de la categoría Web y elegiría los 5 o 7 temas más interesantes. Para cada tema seleccionado, el participante básicamente realizaría la búsqueda web normal utilizando UCAIR para encontrar muchas páginas web relevantes utilizando el título del tema de la consulta como la palabra clave inicial de la consulta. Durante este proceso, el participante puede ver los resultados de la búsqueda y posiblemente hacer clic en algunos interesantes para ver las páginas web, tal como en una búsqueda web normal. No hay ningún requisito o restricción sobre cuántas consultas debe enviar el participante o cuándo debe detener la búsqueda de un tema. Cuando el participante planea cambiar el tema de búsqueda, simplemente presionará un botón 2 de la Conferencia de Recuperación de Texto: http://trec.nist.gov/ 829 Figura 2: Capturas de pantalla para volver a clasificar los resultados y evaluar los resultados de búsqueda antes de cambiar al siguiente tema. En el momento de la evaluación, los 30 resultados mejor clasificados de Google y UCAIR (algunos se superponen) se mezclan aleatoriamente para que el participante no sepa si un resultado proviene de Google o de UCAIR. El participante luego juzgaría la relevancia de estos resultados. Medimos la precisión en los primeros n (n = 5, 10, 20, 30) documentos de Google y UCAIR. También evaluamos precisiones en diferentes niveles de recuperación. En total, 368 documentos fueron considerados relevantes a partir de los resultados de búsqueda de Google y 429 documentos fueron considerados relevantes por los participantes de UCAIR. Los diagramas de dispersión de precisión en los 10 y 20 documentos principales se muestran en la Figura 4 y la Figura 5 respectivamente (El diagrama de dispersión de precisión en los 30 documentos principales es muy similar al de los 20 documentos principales). Cada punto de los gráficos de dispersión representa las precisiones de Google y UCAIR en un tema de consulta. La Tabla 2 muestra la precisión promedio en los primeros n documentos entre 32 temas. A partir de la Figura 4, la Figura 5 y la Tabla 2, vemos que los resultados de búsqueda de UCAIR son consistentemente mejores que los de Google en todas las medidas. Además, la mejora en el rendimiento es más dramática para la precisión en los primeros 20 documentos que para la precisión en los primeros 10 documentos. Una explicación para esto es que cuanto más interacción tenga el usuario con el sistema, más datos de clics se espera que UCAIR pueda recopilar. Por lo tanto, el sistema de recuperación puede construir modelos de usuario implícitos más precisos, lo que conduce a una mayor precisión en la recuperación. El Método de Clasificación prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Mejora 8.0% 17.8% 20.2% 21.8% Tabla 2: Tabla de precisión promedio en los primeros n documentos para 32 temas de consulta El gráfico en la Figura 6 muestra las curvas de precisión-recuperación para UCAIR y Google, donde se observa claramente que el rendimiento de UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Gráfico de dispersión de Precisión en los 10 primeros documentos Figura 4: La precisión en los 10 primeros documentos de UCAIR y Google es consistentemente y considerablemente mejor que la de Google en todos los niveles de recuperación. 6. CONCLUSIONES En este artículo, estudiamos cómo aprovechar la modelización implícita del usuario para personalizar de manera inteligente la recuperación de información y mejorar la precisión de la búsqueda. A diferencia de la mayoría de trabajos anteriores, enfatizamos el uso del contexto de búsqueda inmediata y la información de retroalimentación implícita, así como la actualización rápida de los resultados de búsqueda para beneficiar al máximo a un usuario. Presentamos un marco de trabajo de toma de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos adecuados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para volver a clasificar inmediatamente cualquier documento que aún no haya sido visto por el usuario. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente (UCAIR) sobre un motor de búsqueda popular (Google). Los experimentos en la búsqueda web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en más de un 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Gráfico de dispersión de Precisión en los 20 documentos principales Figura 5: Precisión en los 20 documentos principales de UCAIR y Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 precisión recall Curvas de Precisión-Recall Resultado de Google Resultado de UCAIR Figura 6: Precisión en los 20 resultados principales de UCAIR y Google Google. Dado que la información implícita que aprovechamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional. El agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin necesidad de esfuerzo adicional por parte del usuario. AGRADECIMIENTO Agradecemos a los seis participantes de nuestros experimentos de evaluación. Este trabajo fue apoyado en parte por las subvenciones de la Fundación Nacional de Ciencias IIS-0347933 e IIS-0428472. REFERENCIAS [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman y O. Frieder. Análisis por hora de un registro de consultas web muy grande categorizado por tema. En Actas de SIGIR 2004, páginas 321-328, 2004. [2] C. Clarke, N. Craswell e I. Soboroff. Resumen de la pista de terabyte TREC 2004. En Actas de TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda y D. Brown. Indicadores implícitos de interés. En Actas de Interfaces de Usuario Inteligentes 2001, páginas 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson y M. Wu. Resumen de la pista web TREC 2003. En Actas de TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend y V. Larvrenko. Retroalimentación de relevancia y personalización: Una perspectiva de modelado del lenguaje. En Actas del Segundo Taller DELOS: Personalización y Sistemas de Recomendación en Bibliotecas Digitales, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite y D. Harman. Resultados y desafíos en la evaluación de búsqueda en la web. Redes de Computadoras, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A. An, y D. Schuurmans. Identificación dinámica de sesiones de registro web con modelos de lenguaje estadístico. Revista de la Sociedad Americana de Ciencia de la Información y Tecnología, 55(14):1290-1303, 2004. [9] G. Jeh y J. Widom. Escalando la búsqueda web personalizada. En Actas de WWW 2003, páginas 271-279, 2003. [10] T. Joachims. Optimización de motores de búsqueda utilizando datos de clics. En Actas de SIGKDD 2002, páginas 133-142, 2002. [11] D. Kelly y J. Teevan. Retroalimentación implícita para inferir preferencias de usuario: Una bibliografía. SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En Actas de SIGIR01, páginas 111-119, 2001. [13] T. Lau y E. Horvitz. Patrones de búsqueda: Análisis y modelado de la refinación de consultas web. En Actas de la Séptima Conferencia Internacional sobre Modelado de Usuarios (UM), páginas 145-152, 1999. [14] V. Lavrenko y B. Croft. Modelos de lenguaje basados en relevancia. En Actas de SIGIR01, páginas 120-127, 2001. [15] M. Mitra, A. Singhal y C. Buckley. Mejorando la expansión automática de consultas. En Actas de SIGIR 1998, páginas 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg. Según Google, así va la nación. New York Times, mayo de 2003. [18] S. E. Robertson. El principio de clasificación de probabilidad en ı˚. Revista de Documentación, 33(4):294-304, 1977. [19] J. J. Rocchio. Retroalimentación de relevancia en la recuperación de información. En el Sistema de Recuperación SMART: Experimentos en el Procesamiento Automático de Documentos, páginas 313-323. Prentice-Hall Inc., 1971. [20] G. Salton y C. Buckley. Mejorando el rendimiento de recuperación mediante retroalimentación de recuperación. Revista de la Sociedad Americana de Ciencia de la Información, 41(4):288-297, 1990. [21] G. Salton y M. J. McGill. Introducción a la Recuperación de Información Moderna. McGraw-Hill, 1983. [22] X. Shen, B. Tan y C. Zhai. Recuperación de información sensible al contexto utilizando retroalimentación implícita. En Actas de SIGIR 2005, páginas 43-50, 2005. [23] X. Shen y C. Zhai. Explotando el historial de consultas para la clasificación de documentos en la recuperación de información interactiva (Póster). En Actas de SIGIR 2003, páginas 377-378, 2003. [24] A. Singhal. Recuperación de información moderna: Una breve visión general. Boletín del Comité Técnico de Ingeniería de Datos de la Sociedad de Computación de IEEE, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano y M. Yoshikawa. Búsqueda web adaptativa basada en el perfil del usuario construido sin ningún esfuerzo por parte de los usuarios. En Actas de WWW 2004, páginas 675-684, 2004. [26] E. Volokh. Personalización y privacidad. Comunicaciones de la ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen e I. Ruthven. Un estudio simulado de modelos de retroalimentación implícita. En Actas de ECIR 2004, páginas 311-326, 2004. [28] J. Xu y W. B. Croft. Expansión de consultas utilizando análisis local y global de documentos. En Actas de SIGIR 1996, páginas 4-11, 1996. [29] C. Zhai y J. Lafferty. Modelo de retroalimentación basado en el modelo de recuperación de divergencia de KL. En Actas de la CIKM 2001, páginas 403-410, 2001. 831 ",
            "candidates": [],
            "error": [
                []
            ]
        },
        "implicit feedback": {
            "translated_key": "retroalimentación implícita",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Implicit User Modeling for Personalized Search Xuehua Shen, Bin Tan, ChengXiang Zhai Department of Computer Science University of Illinois at Urbana-Champaign ABSTRACT Information retrieval systems (e.g., web search engines) are critical for overcoming information overload.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users, resulting in inherently non-optimal retrieval performance.",
                "For example, a tourist and a programmer may use the same word java to search for different information, but the current search systems would return the same results.",
                "In this paper, we study how to infer a users interest from the users search context and use the inferred implicit user model for personalized search .",
                "We present a decision theoretic framework and develop techniques for implicit user modeling in information retrieval.",
                "We develop an intelligent client-side web search agent (UCAIR) that can perform eager <br>implicit feedback</br>, e.g., query expansion based on previous queries and immediate result reranking based on clickthrough information.",
                "Experiments on web search show that our search agent can improve search accuracy over the popular Google search engine.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models, Relevance feedback, Search Process General Terms Algorithms 1.",
                "INTRODUCTION Although many information retrieval systems (e.g., web search engines and digital library systems) have been successfully deployed, the current retrieval systems are far from optimal.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users [17].",
                "This inherent non-optimality is seen clearly in the following two cases: (1) Different users may use exactly the same query (e.g., Java) to search for different information (e.g., the Java island in Indonesia or the Java programming language), but existing IR systems return the same results for these users.",
                "Without considering the actual user, it is impossible to know which sense Java refers to in a query. (2) A users information needs may change over time.",
                "The same user may use Java sometimes to mean the Java island in Indonesia and some other times to mean the programming language.",
                "Without recognizing the search context, it would be again impossible to recognize the correct sense.",
                "In order to optimize retrieval accuracy, we clearly need to model the user appropriately and personalize search according to each individual user.",
                "The major goal of user modeling for information retrieval is to accurately model a users information need, which is, unfortunately, a very difficult task.",
                "Indeed, it is even hard for a user to precisely describe what his/her information need is.",
                "What information is available for a system to infer a users information need?",
                "Obviously, the users query provides the most direct evidence.",
                "Indeed, most existing retrieval systems rely solely on the query to model a users information need.",
                "However, since a query is often extremely short, the user model constructed based on a keyword query is inevitably impoverished .",
                "An effective way to improve user modeling in information retrieval is to ask the user to explicitly specify which documents are relevant (i.e., useful for satisfying his/her information need), and then to improve user modeling based on such examples of relevant documents.",
                "This is called relevance feedback, which has been proved to be quite effective for improving retrieval accuracy [19, 20].",
                "Unfortunately, in real world applications, users are usually reluctant to make the extra effort to provide relevant examples for feedback [11].",
                "It is thus very interesting to study how to infer a users information need based on any <br>implicit feedback</br> information, which naturally exists through user interactions and thus does not require any extra user effort.",
                "Indeed, several previous studies have shown that implicit user modeling can improve retrieval accuracy.",
                "In [3], a web browser (Curious Browser) is developed to record a users explicit relevance ratings of web pages (relevance feedback) and browsing behavior when viewing a page, such as dwelling time, mouse click, mouse movement and scrolling (<br>implicit feedback</br>).",
                "It is shown that the dwelling time on a page, amount of scrolling on a page and the combination of time and scrolling have a strong correlation with explicit relevance ratings, which suggests that <br>implicit feedback</br> may be helpful for inferring user information need.",
                "In [10], user clickthrough data is collected as training data to learn a retrieval function, which is used to produce a customized ranking of search results that suits a group of users preferences.",
                "In [25], the clickthrough data collected over a long time period is exploited through query expansion to improve retrieval accuracy. 824 While a user may have general long term interests and preferences for information, often he/she is searching for documents to satisfy an ad-hoc information need, which only lasts for a short period of time; once the information need is satisfied, the user would generally no longer be interested in such information.",
                "For example, a user may be looking for information about used cars in order to buy one, but once the user has bought a car, he/she is generally no longer interested in such information.",
                "In such cases, <br>implicit feedback</br> information collected over a long period of time is unlikely to be very useful, but the immediate search context and feedback information, such as which of the search results for the current information need are viewed, can be expected to be much more useful.",
                "Consider the query Java again.",
                "Any of the following immediate feedback information about the user could potentially help determine the intended meaning of Java in the query: (1) The previous query submitted by the user is hashtable (as opposed to, e.g., travel Indonesia). (2) In the search results, the user viewed a page where words such as programming, software, and applet occur many times.",
                "To the best of our knowledge, how to exploit such immediate and short-term search context to improve search has so far not been well addressed in the previous work.",
                "In this paper, we study how to construct and update a user model based on the immediate search context and <br>implicit feedback</br> information and use the model to improve the accuracy of ad-hoc retrieval.",
                "In order to maximally benefit the user of a retrieval system through implicit user modeling, we propose to perform eager <br>implicit feedback</br>.",
                "That is, as soon as we observe any new piece of evidence from the user, we would update the systems belief about the users information need and respond with improved retrieval results based on the updated user model.",
                "We present a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "In a traditional retrieval paradigm, the retrieval problem is to match a query with documents and rank documents according to their relevance values.",
                "As a result, the retrieval process is a simple independent cycle of query and result display.",
                "In the proposed new retrieval paradigm, the users search context plays an important role and the inferred implicit user model is exploited immediately to benefit the user.",
                "The new retrieval paradigm is thus fundamentally different from the traditional paradigm, and is inherently more general.",
                "We further propose specific techniques to capture and exploit two types of <br>implicit feedback</br> information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent UCAIR (User-Centered Adaptive Information Retrieval) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "Thus the developed search agent can improve existing web search performance without additional effort from the user.",
                "The remaining sections are organized as follows.",
                "In Section 2, we discuss the related work.",
                "In Section 3, we present a decisiontheoretic interactive retrieval framework for implicit user modeling.",
                "In Section 4, we present the design and implementation of an intelligent client-side web search agent (UCAIR) that performs eager <br>implicit feedback</br>.",
                "In Section 5, we report our experiment results using the search agent.",
                "Section 6 concludes our work. 2.",
                "RELATED WORK Implicit user modeling for personalized search has been studied in previous work, but our work differs from all previous work in several aspects: (1) We emphasize the exploitation of immediate search context such as the related immediately preceding query and the viewed documents in the same session, while most previous work relies on long-term collection of <br>implicit feedback</br> information [25]. (2) We perform eager feedback and bring the benefit of implicit user modeling as soon as any new <br>implicit feedback</br> information is available, while the previous work mostly exploits longterm implicit feedback [10]. (3) We propose a retrieval framework to integrate implicit user modeling with the interactive retrieval process, while the previous work either studies implicit user modeling separately from retrieval [3] or only studies specific retrieval models for exploiting implicit feedback to better match a query with documents [23, 27, 22]. (4) We develop and evaluate a personalized Web search agent with online user studies, while most existing work evaluates algorithms offline without real user interactions.",
                "Currently some search engines provide rudimentary personalization, such as Google Personalized web search [6], which allows users to explicitly describe their interests by selecting from predefined topics, so that those results that match their interests are brought to the top, and My Yahoo! search [16], which gives users the option to save web sites they like and block those they dislike.",
                "In contrast, UCAIR personalizes web search through implicit user modeling without any additional user efforts.",
                "Furthermore, the personalization of UCAIR is provided on the client side.",
                "There are two remarkable advantages on this.",
                "First, the user does not need to worry about the privacy infringement, which is a big concern for personalized search [26].",
                "Second, both the computation of personalization and the storage of the user profile are done at the client side so that the server load is reduced dramatically [9].",
                "There have been many works studying user query logs [1] or query dynamics [13].",
                "UCAIR makes direct use of a users query history to benefit the same user immediately in the same search session.",
                "UCAIR first judges whether two neighboring queries belong to the same information session and if so, it selects terms from the previous query to perform query expansion.",
                "Our query expansion approach is similar to automatic query expansion [28, 15, 5], but instead of using pseudo feedback to expand the query, we use users <br>implicit feedback</br> information to expand the current query.",
                "These two techniques may be combined. 3.",
                "OPTIMIZATION IN INTERACTIVE IR In interactive IR, a user interacts with the retrieval system through an action dialogue, in which the system responds to each user action with some system action.",
                "For example, the users action may be submitting a query and the systems response may be returning a list of 10 document summaries.",
                "In general, the space of user actions and system responses and their granularities would depend on the interface of a particular retrieval system.",
                "In principle, every action of the user can potentially provide new evidence to help the system better infer the users information need.",
                "Thus in order to respond optimally, the system should use all the evidence collected so far about the user when choosing a response.",
                "When viewed in this way, most existing search engines are clearly non-optimal.",
                "For example, if a user has viewed some documents on the first page of search results, when the user clicks on the Next link to fetch more results, an existing retrieval system would still return the next page of results retrieved based on the original query without considering the new evidence that a particular result has been viewed by the user. 825 We propose to optimize retrieval performance by adapting system responses based on every action that a user has taken, and cast the optimization problem as a decision task.",
                "Specifically, at any time, the system would attempt to do two tasks: (1) User model updating: Monitor any useful evidence from the user regarding his/her information need and update the user model as soon as such evidence is available; (2) Improving search results: Rerank immediately all the documents that the user has not yet seen, as soon as the user model is updated.",
                "We emphasize eager updating and reranking, which makes our work quite different from any existing work.",
                "Below we present a formal decision theoretic framework for optimizing retrieval performance through implicit user modeling in interactive information retrieval. 3.1 A decision-theoretic framework Let A be the set of all user actions and R(a) be the set of all possible system responses to a user action a ∈ A.",
                "At any time, let At = (a1, ..., at) be the observed sequence of user actions so far (up to time point t) and Rt−1 = (r1, ..., rt−1) be the responses that the system has made responding to the user actions.",
                "The systems goal is to choose an optimal response rt ∈ R(at) for the current user action at.",
                "Let M be the space of all possible user models.",
                "We further define a loss function L(a, r, m) ∈ , where a ∈ A is a user action, r ∈ R(a) is a system response, and m ∈ M is a user model.",
                "L(a, r, m) encodes our decision preferences and assesses the optimality of responding with r when the current user model is m and the current user action is a.",
                "According to Bayesian decision theory, the optimal decision at time t is to choose a response that minimizes the Bayes risk, i.e., r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) where P(mt|U, D, At, Rt−1) is the posterior probability of the user model mt given all the observations about the user U we have made up to time t. To simplify the computation of Equation 1, let us assume that the posterior probability mass P(mt|U, D, At, Rt−1) is mostly concentrated on the mode m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "We can then approximate the integral with the value of the loss function at m∗ t .",
                "That is, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) where m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "Leaving aside how to define and estimate these probabilistic models and the loss function, we can see that such a decision-theoretic formulation suggests that, in order to choose the optimal response to at, the system should perform two tasks: (1) compute the current user model and obtain m∗ t based on all the useful information. (2) choose a response rt to minimize the loss function value L(at, rt, m∗ t ).",
                "When at does not affect our belief about m∗ t , the first step can be omitted and we may reuse m∗ t−1 for m∗ t .",
                "Note that our framework is quite general since we can potentially model any kind of user actions and system responses.",
                "In most cases, as we may expect, the systems response is some ranking of documents, i.e., for most actions a, R(a) consists of all the possible rankings of the unseen documents, and the decision problem boils down to choosing the best ranking of unseen documents based on the most current user model.",
                "When a is the action of submitting a keyword query, such a response is exactly what a current retrieval system would do.",
                "However, we can easily imagine that a more intelligent web search engine would respond to a users clicking of the Next link (to fetch more unseen results) with a more optimized ranking of documents based on any viewed documents in the current page of results.",
                "In fact, according to our eager updating strategy, we may even allow a system to respond to a users clicking of browsers Back button after viewing a document in the same way, so that the user can maximally benefit from <br>implicit feedback</br>.",
                "These are precisely what our UCAIR system does. 3.2 User models A user model m ∈ M represents what we know about the user U, so in principle, it can contain any information about the user that we wish to model.",
                "We now discuss two important components in a user model.",
                "The first component is a component model of the users information need.",
                "Presumably, the most important factor affecting the optimality of the systems response is how well the response addresses the users information need.",
                "Indeed, at any time, we may assume that the system has some belief about what the user is interested in, which we model through a term vector x = (x1, ..., x|V |), where V = {w1, ..., w|V |} is the set of all terms (i.e., vocabulary) and xi is the weight of term wi.",
                "Such a term vector is commonly used in information retrieval to represent both queries and documents.",
                "For example, the vector-space model, assumes that both the query and the documents are represented as term vectors and the score of a document with respect to a query is computed based on the similarity between the query vector and the document vector [21].",
                "In a language modeling approach, we may also regard the query unigram language model [12, 29] or the relevance model [14] as a term vector representation of the users information need.",
                "Intuitively, x would assign high weights to terms that characterize the topics which the user is interested in.",
                "The second component we may include in our user model is the documents that the user has already viewed.",
                "Obviously, even if a document is relevant, if the user has already seen the document, it would not be useful to present the same document again.",
                "We thus introduce another variable S ⊂ D (D is the whole set of documents in the collection) to denote the subset of documents in the search results that the user has already seen/viewed.",
                "In general, at time t, we may represent a user model as mt = (S, x, At, Rt−1), where S is the seen documents, x is the systems understanding of the users information need, and (At, Rt−1) represents the users interaction history.",
                "Note that an even more general user model may also include other factors such as the users reading level and occupation.",
                "If we assume that the uncertainty of a user model mt is solely due to the uncertainty of x, the computation of our current estimate of user model m∗ t will mainly involve computing our best estimate of x.",
                "That is, the system would choose a response according to r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) where x∗ = argmaxx P(x|U, D, At, Rt−1).",
                "This is the decision mechanism implemented in the UCAIR system to be described later.",
                "In this system, we avoided specifying the probabilistic model P(x|U, D, At, Rt−1) by computing x∗ directly with some existing feedback method. 3.3 Loss functions The exact definition of loss function L depends on the responses, thus it is inevitably application-specific.",
                "We now briefly discuss some possibilities when the response is to rank all the unseen documents and present the top k of them.",
                "Let r = (d1, ..., dk) be the top k documents, S be the set of seen documents by the user, and x∗ be the systems best guess of the users information need.",
                "We 826 may simply define the loss associated with r as the negative sum of the probability that each of the di is relevant, i.e., L(a, r, m) = − k i=1 P(relevant|di, m).",
                "Clearly, in order to minimize this loss function, the optimal response r would contain the k documents with the highest probability of relevance, which is intuitively reasonable.",
                "One deficiency of this top-k loss function is that it is not sensitive to the internal order of the selected top k documents, so switching the ranking order of a non-relevant document and a relevant one would not affect the loss, which is unreasonable.",
                "To model ranking, we can introduce a factor of the user model - the probability of each of the k documents being viewed by the user, P(view|di), and define the following ranking loss function: L(a, r, m) = − k i=1 P(view|di)P(relevant|di, m) Since in general, if di is ranked above dj (i.e., i < j), P(view|di) > P(view|dj), this loss function would favor a decision to rank relevant documents above non-relevant ones, as otherwise, we could always switch di with dj to reduce the loss value.",
                "Thus the system should simply perform a regular retrieval and rank documents according to the probability of relevance [18].",
                "Depending on the users retrieval preferences, there can be many other possibilities.",
                "For example, if the user does not want to see redundant documents, the loss function should include some redundancy measure on r based on the already seen documents S. Of course, when the response is not to choose a ranked list of documents, we would need a different loss function.",
                "We discuss one such example that is relevant to the search agent that we implement.",
                "When a user enters a query qt (current action), our search agent relies on some existing search engine to actually carry out search.",
                "In such a case, even though the search agent does not have control of the retrieval algorithm, it can still attempt to optimize the search results through refining the query sent to the search engine and/or reranking the results obtained from the search engine.",
                "The loss functions for reranking are already discussed above; we now take a look at the loss functions for query refinement.",
                "Let f be the retrieval function of the search engine that our agent uses so that f(q) would give us the search results using query q.",
                "Given that the current action of the user is entering a query qt (i.e., at = qt), our response would be f(q) for some q.",
                "Since we have no choice of f, our decision is to choose a good q.",
                "Formally, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) which shows that our goal is to find q∗ = argminqL(qt, f(q), m), i.e., an optimal query that would give us the best f(q).",
                "A different choice of loss function L(qt, f(q), m) would lead to a different query refinement strategy.",
                "In UCAIR, we heuristically compute q∗ by expanding qt with terms extracted from rt−1 whenever qt−1 and qt have high similarity.",
                "Note that rt−1 and qt−1 are contained in m as part of the users interaction history. 3.4 Implicit user modeling Implicit user modeling is captured in our framework through the computation of x∗ = argmaxx P(x|U, D, At, Rt−1), i.e., the systems current belief of what the users information need is.",
                "Here again there may be many possibilities, leading to different algorithms for implicit user modeling.",
                "We now discuss a few of them.",
                "First, when two consecutive queries are related, the previous query can be exploited to enrich the current query and provide more search context to help disambiguation.",
                "For this purpose, instead of performing query expansion as we did in the previous section, we could also compute an updated x∗ based on the previous query and retrieval results.",
                "The computed new user model can then be used to rank the documents with a standard information retrieval model.",
                "Second, we can also infer a users interest based on the summaries of the viewed documents.",
                "When a user is presented with a list of summaries of top ranked documents, if the user chooses to skip the first n documents and to view the (n+1)-th document, we may infer that the user is not interested in the displayed summaries for the first n documents, but is attracted by the displayed summary of the (n + 1)-th document.",
                "We can thus use these summaries as negative and positive examples to learn a more accurate user model x∗ .",
                "Here many standard relevance feedback techniques can be exploited [19, 20].",
                "Note that we should use the displayed summaries, as opposed to the actual contents of those documents, since it is possible that the displayed summary of the viewed document is relevant, but the document content is actually not.",
                "Similarly, a displayed summary may mislead a user to skip a relevant document.",
                "Inferring user models based on such displayed information, rather than the actual content of a document is an important difference between UCAIR and some other similar systems.",
                "In UCAIR, both of these strategies for inferring an implicit user model are implemented. 4.",
                "UCAIR: A PERSONALIZED SEARCH AGENT 4.1 Design In this section, we present a client-side web search agent called UCAIR, in which we implement some of the methods discussed in the previous section for performing personalized search through implicit user modeling.",
                "UCAIR is a web browser plug-in 1 that acts as a proxy for web search engines.",
                "Currently, it is only implemented for Internet Explorer and Google, but it is a matter of engineering to make it run on other web browsers and interact with other search engines.",
                "The issue of privacy is a primary obstacle for deploying any real world applications involving serious user modeling, such as personalized search.",
                "For this reason, UCAIR is strictly running as a client-side search agent, as opposed to a server-side application.",
                "This way, the captured user information always resides on the computer that the user is using, thus the user does not need to release any information to the outside.",
                "Client-side personalization also allows the system to easily observe a lot of user information that may not be easily available to a server.",
                "Furthermore, performing personalized search on the client-side is more scalable than on the serverside, since the overhead of computation and storage is distributed among clients.",
                "As shown in Figure 1, the UCAIR toolbar has 3 major components: (1) The (implicit) user modeling module captures a users search context and history information, including the submitted queries and any clicked search results and infers search session boundaries. (2) The query modification module selectively improves the query formulation according to the current user model. (3) The result re-ranking module immediately re-ranks any unseen search results whenever the user model is updated.",
                "In UCAIR, we consider four basic user actions: (1) submitting a keyword query; (2) viewing a document; (3) clicking the Back button; (4) clicking the Next link on a result page.",
                "For each of these four actions, the system responds with, respectively, (1) 1 UCAIR is available at: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Search Engine (e.g., Google) Search History Log (e.g.,past queries, clicked results) Query Modification Result Re-Ranking User Modeling Result Buffer UCAIR Userquery results clickthrough… Figure 1: UCAIR architecture generating a ranked list of results by sending a possibly expanded query to a search engine; (2) updating the information need model x; (3) reranking the unseen results on the current result page based on the current model x; and (4) reranking the unseen pages and generating the next page of results based on the current model x.",
                "Behind these responses, there are three basic tasks: (1) Decide whether the previous query is related to the current query and if so expand the current query with useful terms from the previous query or the results of the previous query. (2) Update the information need model x based on a newly clicked document summary. (3) Rerank a set of unseen documents based on the current model x.",
                "Below we describe our algorithms for each of them. 4.2 Session boundary detection and query expansion To effectively exploit previous queries and their corresponding clickthrough information, UCAIR needs to judge whether two adjacent queries belong to the same search session (i.e., detect session boundaries).",
                "Existing work on session boundary detection is mostly in the context of web log analysis (e.g., [8]), and uses statistical information rather than textual features.",
                "Since our clientside agent does not have access to server query logs, we make session boundary decisions based on textual similarity between two queries.",
                "Because related queries do not necessarily share the same words (e.g., java island and travel Indonesia), it is insufficient to use only query text.",
                "Therefore we use the search results of the two queries to help decide whether they are topically related.",
                "For example, for the above queries java island and travel Indonesia, the words java, bali, island, indonesia and travel may occur frequently in both queries search results, yielding a high similarity score.",
                "We only use the titles and summaries of the search results to calculate the similarity since they are available in the retrieved search result page and fetching the full text of every result page would significantly slow down the process.",
                "To compensate for the terseness of titles and summaries, we retrieve more results than a user would normally view for the purpose of detecting session boundaries (typically 50 results).",
                "The similarity between the previous query q and the current query q is computed as follows.",
                "Let {s1, s2, . . . , sn } and {s1, s2, . . . , sn} be the result sets for the two queries.",
                "We use the pivoted normalization TF-IDF weighting formula [24] to compute a term weight vector si for each result si.",
                "We define the average result savg to be the centroid of all the result vectors, i.e., (s1 + s2 + . . . + sn)/n.",
                "The cosine similarity between the two average results is calculated as s avg · savg/ s 2 avg · s2 avg If the similarity value exceeds a predefined threshold, the two queries will be considered to be in the same information session.",
                "If the previous query and the current query are found to belong to the same search session, UCAIR would attempt to expand the current query with terms from the previous query and its search results.",
                "Specifically, for each term in the previous query or the corresponding search results, if its frequency in the results of the current query is greater than a preset threshold (e.g. 5 results out of 50), the term would be added to the current query to form an expanded query.",
                "In this case, UCAIR would send this expanded query rather than the original one to the search engine and return the results corresponding to the expanded query.",
                "Currently, UCAIR only uses the immediate preceding query for query expansion; in principle, we could exploit all related past queries. 4.3 Information need model updating Suppose at time t, we have observed that the user has viewed k documents whose summaries are s1, ..., sk.",
                "We update our user model by computing a new information need vector with a standard feedback method in information retrieval (i.e., Rocchio [19]).",
                "According to the vector space retrieval model, each clicked summary si can be represented by a term weight vector si with each term weighted by a TF-IDF weighting formula [21].",
                "Rocchio computes the centroid vector of all the summaries and interpolates it with the original query vector to obtain an updated term vector.",
                "That is, x = αq + (1 − α) 1 k k i=1 si where q is the query vector, k is the number of summaries the user clicks immediately following the current query and α is a parameter that controls the influence of the clicked summaries on the inferred information need model.",
                "In our experiments, α is set to 0.5.",
                "Note that we update the information need model whenever the user views a document. 4.4 Result reranking In general, we want to rerank all the unseen results as soon as the user model is updated.",
                "Currently, UCAIR implements reranking in two cases, corresponding to the user clicking the Back button and Next link in the Internet Explorer.",
                "In both cases, the current (updated) user model would be used to rerank the unseen results so that the user would see improved search results immediately.",
                "To rerank any unseen document summaries, UCAIR uses the standard vector space retrieval model and scores each summary based on the similarity of the result and the current user information need vector x [21].",
                "Since <br>implicit feedback</br> is not completely reliable, we bring up only a small number (e.g. 5) of highest reranked results to be followed by any originally high ranked results. 828 Google result (user query = java map) UCAIR result (user query =java map) previous query = travel Indonesia previous query = hashtable expanded user query = java map Indonesia expanded user query = java map class 1 Java map projections of the world ... Lonely Planet - Indonesia Map Map (Java 2 Platform SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Java map projections of the world ... INDONESIA TOURISM : CENTRAL JAVA - MAP Java 2 Platform SE v1.3.1: Interface Map www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Java Map INDONESIA TOURISM : WEST JAVA - MAP An Introduction to Java Map Collection Classes java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Java Technology Concept Map IndoStreets - Java Map An Introduction to Java Map Collection Classes java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Indonesia Regions and Islands Maps, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 An Introduction to Java Map Collection Classes Indonesia City Street Map,... Hibernate simplifies inheritance mapping www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Java Map Maps Of Indonesia tmap 30.map Class Hierarchy www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Java API Map Maps of Indonesia by Peter Loud Class Scope www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas : Sam Maps of Indonesia by Peter Loud Class PrintSafeHashMap www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 INDONESIA TOURISM : WEST JAVA - MAP indonesiaphoto.com Java Pro - Union and Vertical Mapping of Classes www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Table 1: Sample results of query expansion 5.",
                "EVALUATION OF UCAIR We now present some results on evaluating the two major UCAIR functions: selective query expansion and result reranking based on user clickthrough data. 5.1 Sample results The query expansion strategy implemented in UCAIR is intentionally conservative to avoid misinterpretation of implicit user models.",
                "In practice, whenever it chooses to expand the query, the expansion usually makes sense.",
                "In Table 1, we show how UCAIR can successfully distinguish two different search contexts for the query java map, corresponding to two different previous queries (i.e., travel Indonesia vs. hashtable).",
                "Due to implicit user modeling, UCAIR intelligently figures out to add Indonesia and class, respectively, to the users query java map, which would otherwise be ambiguous as shown in the original results from Google on March 21, 2005.",
                "UCAIRs results are much more accurate than Googles results and reflect personalization in search.",
                "The eager <br>implicit feedback</br> component is designed to immediately respond to a users activity such as viewing a document.",
                "In Figure 2, we show how UCAIR can successfully disambiguate an ambiguous query jaguar by exploiting a viewed document summary.",
                "In this case, the initial retrieval results using jaguar (shown on the left side) contain two results about the Jaguar cars followed by two results about the Jaguar software.",
                "However, after the user views the web page content of the second result (about Jaguar car) and returns to the search result page by clicking Back button, UCAIR automatically nominates two new search results about Jaguar cars (shown on the right side), while the original two results about Jaguar software are pushed down on the list (unseen from the picture). 5.2 Quantitative evaluation To further evaluate UCAIR quantitatively, we conduct a user study on the effectiveness of the eager <br>implicit feedback</br> component.",
                "It is a challenge to quantitatively evaluate the potential performance improvement of our proposed model and UCAIR over Google in an unbiased way [7].",
                "Here, we design a user study, in which participants would do normal web search and judge a randomly and anonymously mixed set of results from Google and UCAIR at the end of the search session; participants do not know whether a result comes from Google or UCAIR.",
                "We recruited 6 graduate students for this user study, who have different backgrounds (3 computer science, 2 biology, and 1 chem<top> <num> Number: 716 <title> Spammer arrest sue <desc> Description: Have any spammers been arrested or sued for sending unsolicited e-mail? <narr> Narrative: Instances of arrests, prosecutions, convictions, and punishments of spammers, and lawsuits against them are relevant.",
                "Documents which describe laws to limit spam without giving details of lawsuits or criminal trials are not relevant. </top> Figure 3: An example of TREC query topic, expressed in a form which might be given to a human assistant or librarian istry).",
                "We use query topics from TREC 2 2004 Terabyte track [2] and TREC 2003 Web track [4] topic distillation task in the way to be described below.",
                "An example topic from TREC 2004 Terabyte track appears in Figure 3.",
                "The title is a short phrase and may be used as a query to the retrieval system.",
                "The description field provides a slightly longer statement of the topic requirement, usually expressed as a single complete sentence or question.",
                "Finally the narrative supplies additional information necessary to fully specify the requirement, expressed in the form of a short paragraph.",
                "Initially, each participant would browse 50 topics either from Terabyte track or Web track and pick 5 or 7 most interesting topics.",
                "For each picked topic, the participant would essentially do the normal web search using UCAIR to find many relevant web pages by using the title of the query topic as the initial keyword query.",
                "During this process, the participant may view the search results and possibly click on some interesting ones to view the web pages, just as in a normal web search.",
                "There is no requirement or restriction on how many queries the participant must submit or when the participant should stop the search for one topic.",
                "When the participant plans to change the search topic, he/she will simply press a button 2 Text REtrieval Conference: http://trec.nist.gov/ 829 Figure 2: Screen shots for result reranking to evaluate the search results before actually switching to the next topic.",
                "At the time of evaluation, 30 top ranked results from Google and UCAIR (some are overlapping) are randomly mixed together so that the participant would not know whether a result comes from Google or UCAIR.",
                "The participant would then judge the relevance of these results.",
                "We measure precision at top n (n = 5, 10, 20, 30) documents of Google and UCAIR.",
                "We also evaluate precisions at different recall levels.",
                "Altogether, 368 documents judged as relevant from Google search results and 429 documents judged as relevant from UCAIR by participants.",
                "Scatter plots of precision at top 10 and top 20 documents are shown in Figure 4 and Figure 5 respectively (The scatter plot of precision at top 30 documents is very similar to precision at top 20 documents).",
                "Each point of the scatter plots represents the precisions of Google and UCAIR on one query topic.",
                "Table 2 shows the average precision at top n documents among 32 topics.",
                "From Figure 4, Figure 5 and Table 2, we see that the search results from UCAIR are consistently better than those from Google by all the measures.",
                "Moreover, the performance improvement is more dramatic for precision at top 20 documents than that at precision at top 10 documents.",
                "One explanation for this is that the more interaction the user has with the system, the more clickthrough data UCAIR can be expected to collect.",
                "Thus the retrieval system can build more precise implicit user models, which lead to better retrieval accuracy.",
                "Ranking Method prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Improvement 8.0% 17.8% 20.2% 21.8% Table 2: Table of average precision at top n documents for 32 query topics The plot in Figure 6 shows the precision-recall curves for UCAIR and Google, where it is clearly seen that the performance of UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Scatterplot of Precision at Top 10 Documents Figure 4: Precision at top 10 documents of UCAIR and Google is consistently and considerably better than that of Google at all levels of recall. 6.",
                "CONCLUSIONS In this paper, we studied how to exploit implicit user modeling to intelligently personalize information retrieval and improve search accuracy.",
                "Unlike most previous work, we emphasize the use of immediate search context and <br>implicit feedback</br> information as well as eager updating of search results to maximally benefit a user.",
                "We presented a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "We further propose specific techniques to capture and exploit two types of <br>implicit feedback</br> information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent (UCAIR) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Scatterplot of Precision at Top 20 documents Figure 5: Precision at top 20 documents of UCAIR and Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 recall precision Precision−Recall curves Google Result UCAIR Result Figure 6: Precision at top 20 result of UCAIR and Google Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "The developed search agent thus can improve existing web search performance without any additional effort from the user. 7.",
                "ACKNOWLEDGEMENT We thank the six participants of our evaluation experiments.",
                "This work was supported in part by the National Science Foundation grants IIS-0347933 and IIS-0428472. 8.",
                "REFERENCES [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman, and O. Frieder.",
                "Hourly analysis of a very large topically categorized web query log.",
                "In Proceedings of SIGIR 2004, pages 321-328, 2004. [2] C. Clarke, N. Craswell, and I. Soboroff.",
                "Overview of the TREC 2004 terabyte track.",
                "In Proceedings of TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda, and D. Brown.",
                "Implicit interest indicators.",
                "In Proceedings of Intelligent User Interfaces 2001, pages 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson, and M. Wu.",
                "Overview of the TREC 2003 web track.",
                "In Proceedings of TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend, and V. Larvrenko.",
                "Relevance feedback and personalization: A language modeling perspective.",
                "In Proeedings of Second DELOS Workshop: Personalisation and Recommender Systems in Digital Libraries, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite, and D. Harman.",
                "Results and challenges in web search evaluation.",
                "Computer Networks, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A.",
                "An, and D. Schuurmans.",
                "Dynamic web log session identification with statistical language models.",
                "Journal of the American Society for Information Science and Technology, 55(14):1290-1303, 2004. [9] G. Jeh and J. Widom.",
                "Scaling personalized web search.",
                "In Proceedings of WWW 2003, pages 271-279, 2003. [10] T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of SIGKDD 2002, pages 133-142, 2002. [11] D. Kelly and J. Teevan.",
                "<br>implicit feedback</br> for inferring user preference: A bibliography.",
                "SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of SIGIR01, pages 111-119, 2001. [13] T. Lau and E. Horvitz.",
                "Patterns of search: Analyzing and modeling web query refinement.",
                "In Proceedings of the Seventh International Conference on User Modeling (UM), pages 145 -152, 1999. [14] V. Lavrenko and B. Croft.",
                "Relevance-based language models.",
                "In Proceedings of SIGIR01, pages 120-127, 2001. [15] M. Mitra, A. Singhal, and C. Buckley.",
                "Improving automatic query expansion.",
                "In Proceedings of SIGIR 1998, pages 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg.",
                "As google goes, so goes the nation.",
                "New York Times, May 2003. [18] S. E. Robertson.",
                "The probability ranking principle in ı˚.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] J. J. Rocchio.",
                "Relevance feedback in information retrieval.",
                "In The SMART Retrieval System: Experiments in Automatic Document Processing, pages 313-323.",
                "Prentice-Hall Inc., 1971. [20] G. Salton and C. Buckley.",
                "Improving retrieval performance by retrieval feedback.",
                "Journal of the American Society for Information Science, 41(4):288-297, 1990. [21] G. Salton and M. J. McGill.",
                "Introduction to Modern Information Retrieval.",
                "McGraw-Hill, 1983. [22] X. Shen, B. Tan, and C. Zhai.",
                "Context-sensitive information retrieval using <br>implicit feedback</br>.",
                "In Proceedings of SIGIR 2005, pages 43-50, 2005. [23] X. Shen and C. Zhai.",
                "Exploiting query history for document ranking in interactive information retrieval (Poster).",
                "In Proceedings of SIGIR 2003, pages 377-378, 2003. [24] A. Singhal.",
                "Modern information retrieval: A brief overview.",
                "Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano, and M. Yoshikawa.",
                "Adaptive web search based on user profile constructed without any effort from users.",
                "In Proceedings of WWW 2004, pages 675-684, 2004. [26] E. Volokh.",
                "Personalization and privacy.",
                "Communications of the ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen, and I. Ruthven.",
                "A simulated study of <br>implicit feedback</br> models.",
                "In Proceedings of ECIR 2004, pages 311-326, 2004. [28] J. Xu and W. B. Croft.",
                "Query expansion using local and global document analysis.",
                "In Proceedings of SIGIR 1996, pages 4-11, 1996. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in KL divergence retrieval model.",
                "In Proceedings of the CIKM 2001, pages 403-410, 2001. 831"
            ],
            "original_annotated_samples": [
                "We develop an intelligent client-side web search agent (UCAIR) that can perform eager <br>implicit feedback</br>, e.g., query expansion based on previous queries and immediate result reranking based on clickthrough information.",
                "It is thus very interesting to study how to infer a users information need based on any <br>implicit feedback</br> information, which naturally exists through user interactions and thus does not require any extra user effort.",
                "In [3], a web browser (Curious Browser) is developed to record a users explicit relevance ratings of web pages (relevance feedback) and browsing behavior when viewing a page, such as dwelling time, mouse click, mouse movement and scrolling (<br>implicit feedback</br>).",
                "It is shown that the dwelling time on a page, amount of scrolling on a page and the combination of time and scrolling have a strong correlation with explicit relevance ratings, which suggests that <br>implicit feedback</br> may be helpful for inferring user information need.",
                "In such cases, <br>implicit feedback</br> information collected over a long period of time is unlikely to be very useful, but the immediate search context and feedback information, such as which of the search results for the current information need are viewed, can be expected to be much more useful."
            ],
            "translated_annotated_samples": [
                "Desarrollamos un agente de búsqueda web inteligente del lado del cliente (UCAIR) que puede realizar <br>retroalimentación implícita</br> ansiosa, por ejemplo, expansión de consultas basada en consultas anteriores y reordenamiento inmediato de resultados basado en información de clics.",
                "Por lo tanto, es muy interesante estudiar cómo inferir la necesidad de información de un usuario basándose en cualquier información de <br>retroalimentación implícita</br>, la cual existe naturalmente a través de las interacciones del usuario y no requiere ningún esfuerzo adicional por parte del usuario.",
                "En [3], se desarrolla un navegador web (Curious Browser) para registrar las calificaciones explícitas de relevancia de las páginas web por parte de los usuarios (retroalimentación de relevancia) y el comportamiento de navegación al ver una página, como el tiempo de permanencia, clics de ratón, movimiento del ratón y desplazamiento (<br>retroalimentación implícita</br>).",
                "Se muestra que el tiempo de permanencia en una página, la cantidad de desplazamiento en una página y la combinación de tiempo y desplazamiento tienen una fuerte correlación con las calificaciones de relevancia explícita, lo que sugiere que la <br>retroalimentación implícita</br> puede ser útil para inferir la necesidad de información del usuario.",
                "En tales casos, la información de <br>retroalimentación implícita</br> recopilada durante un largo período de tiempo es poco probable que sea muy útil, pero el contexto de búsqueda inmediato y la información de retroalimentación, como cuáles de los resultados de búsqueda para la necesidad de información actual son vistos, se espera que sean mucho más útiles."
            ],
            "translated_text": "Modelado implícito de usuarios para búsqueda personalizada Xuehua Shen, Bin Tan, ChengXiang Zhai Departamento de Ciencias de la Computación Universidad de Illinois en Urbana-Champaign RESUMEN Los sistemas de recuperación de información (por ejemplo, motores de búsqueda web) son críticos para superar la sobrecarga de información. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales, lo que resulta en un rendimiento de recuperación inherentemente no óptimo. Por ejemplo, un turista y un programador pueden usar la misma palabra \"java\" para buscar información diferente, pero los sistemas de búsqueda actuales devolverían los mismos resultados. En este artículo, estudiamos cómo inferir el interés de un usuario a partir del contexto de búsqueda del usuario y utilizar el modelo de usuario implícito inferido para la búsqueda personalizada. Presentamos un marco teórico de toma de decisiones y desarrollamos técnicas para el modelado implícito del usuario en la recuperación de información. Desarrollamos un agente de búsqueda web inteligente del lado del cliente (UCAIR) que puede realizar <br>retroalimentación implícita</br> ansiosa, por ejemplo, expansión de consultas basada en consultas anteriores y reordenamiento inmediato de resultados basado en información de clics. Los experimentos sobre la búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda sobre el popular motor de búsqueda Google. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación, Retroalimentación de relevancia, Proceso de búsqueda Términos Generales Algoritmos 1. Aunque muchos sistemas de recuperación de información (por ejemplo, motores de búsqueda web y sistemas de biblioteca digital) se han implementado con éxito, los sistemas de recuperación actuales están lejos de ser óptimos. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales [17]. Esta no optimalidad inherente se ve claramente en los siguientes dos casos: (1) Diferentes usuarios pueden utilizar exactamente la misma consulta (por ejemplo, Java) para buscar información diferente (por ejemplo, la isla de Java en Indonesia o el lenguaje de programación Java), pero los sistemas de IR existentes devuelven los mismos resultados para estos usuarios. Sin considerar al usuario actual, es imposible saber a qué sentido se refiere Java en una consulta. (2) Las necesidades de información de un usuario pueden cambiar con el tiempo. El mismo usuario puede usar Java a veces para referirse a la isla de Java en Indonesia y otras veces para referirse al lenguaje de programación. Sin reconocer el contexto de búsqueda, sería nuevamente imposible reconocer el sentido correcto. Para optimizar la precisión de la recuperación, claramente necesitamos modelar al usuario de manera adecuada y personalizar la búsqueda según cada usuario individual. El objetivo principal del modelado de usuario para la recuperación de información es modelar con precisión la necesidad de información de un usuario, lo cual, desafortunadamente, es una tarea muy difícil. De hecho, incluso resulta difícil para un usuario describir con precisión cuál es su necesidad de información. ¿Qué información está disponible para que un sistema pueda inferir la necesidad de información de un usuario? Obviamente, la consulta de los usuarios proporciona la evidencia más directa. De hecho, la mayoría de los sistemas de recuperación existentes se basan únicamente en la consulta para modelar la necesidad de información de los usuarios. Sin embargo, dado que una consulta suele ser extremadamente corta, el modelo de usuario construido basado en una consulta de palabras clave inevitablemente resulta empobrecido. Una forma efectiva de mejorar la modelización de usuarios en la recuperación de información es pedir al usuario que especifique explícitamente qué documentos son relevantes (es decir, útiles para satisfacer su necesidad de información) y luego mejorar la modelización de usuarios basándose en ejemplos de documentos relevantes. Esto se llama retroalimentación de relevancia, lo cual ha demostrado ser bastante efectivo para mejorar la precisión de recuperación [19, 20]. Desafortunadamente, en aplicaciones del mundo real, los usuarios suelen ser reacios a hacer el esfuerzo adicional de proporcionar ejemplos relevantes para retroalimentación [11]. Por lo tanto, es muy interesante estudiar cómo inferir la necesidad de información de un usuario basándose en cualquier información de <br>retroalimentación implícita</br>, la cual existe naturalmente a través de las interacciones del usuario y no requiere ningún esfuerzo adicional por parte del usuario. De hecho, varios estudios previos han demostrado que el modelado implícito del usuario puede mejorar la precisión de recuperación. En [3], se desarrolla un navegador web (Curious Browser) para registrar las calificaciones explícitas de relevancia de las páginas web por parte de los usuarios (retroalimentación de relevancia) y el comportamiento de navegación al ver una página, como el tiempo de permanencia, clics de ratón, movimiento del ratón y desplazamiento (<br>retroalimentación implícita</br>). Se muestra que el tiempo de permanencia en una página, la cantidad de desplazamiento en una página y la combinación de tiempo y desplazamiento tienen una fuerte correlación con las calificaciones de relevancia explícita, lo que sugiere que la <br>retroalimentación implícita</br> puede ser útil para inferir la necesidad de información del usuario. En [10], se recopilan datos de clics de usuario como datos de entrenamiento para aprender una función de recuperación, que se utiliza para producir un ranking personalizado de resultados de búsqueda que se adapte a las preferencias de un grupo de usuarios. En [25], los datos de clics recopilados durante un largo período de tiempo se utilizan a través de la expansión de consultas para mejorar la precisión de recuperación. Si bien un usuario puede tener intereses y preferencias generales a largo plazo para la información, a menudo está buscando documentos para satisfacer una necesidad de información ad-hoc, que solo dura un corto período de tiempo; una vez que se satisface la necesidad de información, el usuario generalmente ya no estaría interesado en esa información. Por ejemplo, un usuario puede estar buscando información sobre autos usados para comprar uno, pero una vez que el usuario ha comprado un auto, generalmente ya no está interesado en esa información. En tales casos, la información de <br>retroalimentación implícita</br> recopilada durante un largo período de tiempo es poco probable que sea muy útil, pero el contexto de búsqueda inmediato y la información de retroalimentación, como cuáles de los resultados de búsqueda para la necesidad de información actual son vistos, se espera que sean mucho más útiles. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "personalize search": {
            "translated_key": "personalizar la búsqueda",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Implicit User Modeling for Personalized Search Xuehua Shen, Bin Tan, ChengXiang Zhai Department of Computer Science University of Illinois at Urbana-Champaign ABSTRACT Information retrieval systems (e.g., web search engines) are critical for overcoming information overload.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users, resulting in inherently non-optimal retrieval performance.",
                "For example, a tourist and a programmer may use the same word java to search for different information, but the current search systems would return the same results.",
                "In this paper, we study how to infer a users interest from the users search context and use the inferred implicit user model for personalized search .",
                "We present a decision theoretic framework and develop techniques for implicit user modeling in information retrieval.",
                "We develop an intelligent client-side web search agent (UCAIR) that can perform eager implicit feedback, e.g., query expansion based on previous queries and immediate result reranking based on clickthrough information.",
                "Experiments on web search show that our search agent can improve search accuracy over the popular Google search engine.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models, Relevance feedback, Search Process General Terms Algorithms 1.",
                "INTRODUCTION Although many information retrieval systems (e.g., web search engines and digital library systems) have been successfully deployed, the current retrieval systems are far from optimal.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users [17].",
                "This inherent non-optimality is seen clearly in the following two cases: (1) Different users may use exactly the same query (e.g., Java) to search for different information (e.g., the Java island in Indonesia or the Java programming language), but existing IR systems return the same results for these users.",
                "Without considering the actual user, it is impossible to know which sense Java refers to in a query. (2) A users information needs may change over time.",
                "The same user may use Java sometimes to mean the Java island in Indonesia and some other times to mean the programming language.",
                "Without recognizing the search context, it would be again impossible to recognize the correct sense.",
                "In order to optimize retrieval accuracy, we clearly need to model the user appropriately and <br>personalize search</br> according to each individual user.",
                "The major goal of user modeling for information retrieval is to accurately model a users information need, which is, unfortunately, a very difficult task.",
                "Indeed, it is even hard for a user to precisely describe what his/her information need is.",
                "What information is available for a system to infer a users information need?",
                "Obviously, the users query provides the most direct evidence.",
                "Indeed, most existing retrieval systems rely solely on the query to model a users information need.",
                "However, since a query is often extremely short, the user model constructed based on a keyword query is inevitably impoverished .",
                "An effective way to improve user modeling in information retrieval is to ask the user to explicitly specify which documents are relevant (i.e., useful for satisfying his/her information need), and then to improve user modeling based on such examples of relevant documents.",
                "This is called relevance feedback, which has been proved to be quite effective for improving retrieval accuracy [19, 20].",
                "Unfortunately, in real world applications, users are usually reluctant to make the extra effort to provide relevant examples for feedback [11].",
                "It is thus very interesting to study how to infer a users information need based on any implicit feedback information, which naturally exists through user interactions and thus does not require any extra user effort.",
                "Indeed, several previous studies have shown that implicit user modeling can improve retrieval accuracy.",
                "In [3], a web browser (Curious Browser) is developed to record a users explicit relevance ratings of web pages (relevance feedback) and browsing behavior when viewing a page, such as dwelling time, mouse click, mouse movement and scrolling (implicit feedback).",
                "It is shown that the dwelling time on a page, amount of scrolling on a page and the combination of time and scrolling have a strong correlation with explicit relevance ratings, which suggests that implicit feedback may be helpful for inferring user information need.",
                "In [10], user clickthrough data is collected as training data to learn a retrieval function, which is used to produce a customized ranking of search results that suits a group of users preferences.",
                "In [25], the clickthrough data collected over a long time period is exploited through query expansion to improve retrieval accuracy. 824 While a user may have general long term interests and preferences for information, often he/she is searching for documents to satisfy an ad-hoc information need, which only lasts for a short period of time; once the information need is satisfied, the user would generally no longer be interested in such information.",
                "For example, a user may be looking for information about used cars in order to buy one, but once the user has bought a car, he/she is generally no longer interested in such information.",
                "In such cases, implicit feedback information collected over a long period of time is unlikely to be very useful, but the immediate search context and feedback information, such as which of the search results for the current information need are viewed, can be expected to be much more useful.",
                "Consider the query Java again.",
                "Any of the following immediate feedback information about the user could potentially help determine the intended meaning of Java in the query: (1) The previous query submitted by the user is hashtable (as opposed to, e.g., travel Indonesia). (2) In the search results, the user viewed a page where words such as programming, software, and applet occur many times.",
                "To the best of our knowledge, how to exploit such immediate and short-term search context to improve search has so far not been well addressed in the previous work.",
                "In this paper, we study how to construct and update a user model based on the immediate search context and implicit feedback information and use the model to improve the accuracy of ad-hoc retrieval.",
                "In order to maximally benefit the user of a retrieval system through implicit user modeling, we propose to perform eager implicit feedback.",
                "That is, as soon as we observe any new piece of evidence from the user, we would update the systems belief about the users information need and respond with improved retrieval results based on the updated user model.",
                "We present a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "In a traditional retrieval paradigm, the retrieval problem is to match a query with documents and rank documents according to their relevance values.",
                "As a result, the retrieval process is a simple independent cycle of query and result display.",
                "In the proposed new retrieval paradigm, the users search context plays an important role and the inferred implicit user model is exploited immediately to benefit the user.",
                "The new retrieval paradigm is thus fundamentally different from the traditional paradigm, and is inherently more general.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent UCAIR (User-Centered Adaptive Information Retrieval) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "Thus the developed search agent can improve existing web search performance without additional effort from the user.",
                "The remaining sections are organized as follows.",
                "In Section 2, we discuss the related work.",
                "In Section 3, we present a decisiontheoretic interactive retrieval framework for implicit user modeling.",
                "In Section 4, we present the design and implementation of an intelligent client-side web search agent (UCAIR) that performs eager implicit feedback.",
                "In Section 5, we report our experiment results using the search agent.",
                "Section 6 concludes our work. 2.",
                "RELATED WORK Implicit user modeling for personalized search has been studied in previous work, but our work differs from all previous work in several aspects: (1) We emphasize the exploitation of immediate search context such as the related immediately preceding query and the viewed documents in the same session, while most previous work relies on long-term collection of implicit feedback information [25]. (2) We perform eager feedback and bring the benefit of implicit user modeling as soon as any new implicit feedback information is available, while the previous work mostly exploits longterm implicit feedback [10]. (3) We propose a retrieval framework to integrate implicit user modeling with the interactive retrieval process, while the previous work either studies implicit user modeling separately from retrieval [3] or only studies specific retrieval models for exploiting implicit feedback to better match a query with documents [23, 27, 22]. (4) We develop and evaluate a personalized Web search agent with online user studies, while most existing work evaluates algorithms offline without real user interactions.",
                "Currently some search engines provide rudimentary personalization, such as Google Personalized web search [6], which allows users to explicitly describe their interests by selecting from predefined topics, so that those results that match their interests are brought to the top, and My Yahoo! search [16], which gives users the option to save web sites they like and block those they dislike.",
                "In contrast, UCAIR personalizes web search through implicit user modeling without any additional user efforts.",
                "Furthermore, the personalization of UCAIR is provided on the client side.",
                "There are two remarkable advantages on this.",
                "First, the user does not need to worry about the privacy infringement, which is a big concern for personalized search [26].",
                "Second, both the computation of personalization and the storage of the user profile are done at the client side so that the server load is reduced dramatically [9].",
                "There have been many works studying user query logs [1] or query dynamics [13].",
                "UCAIR makes direct use of a users query history to benefit the same user immediately in the same search session.",
                "UCAIR first judges whether two neighboring queries belong to the same information session and if so, it selects terms from the previous query to perform query expansion.",
                "Our query expansion approach is similar to automatic query expansion [28, 15, 5], but instead of using pseudo feedback to expand the query, we use users implicit feedback information to expand the current query.",
                "These two techniques may be combined. 3.",
                "OPTIMIZATION IN INTERACTIVE IR In interactive IR, a user interacts with the retrieval system through an action dialogue, in which the system responds to each user action with some system action.",
                "For example, the users action may be submitting a query and the systems response may be returning a list of 10 document summaries.",
                "In general, the space of user actions and system responses and their granularities would depend on the interface of a particular retrieval system.",
                "In principle, every action of the user can potentially provide new evidence to help the system better infer the users information need.",
                "Thus in order to respond optimally, the system should use all the evidence collected so far about the user when choosing a response.",
                "When viewed in this way, most existing search engines are clearly non-optimal.",
                "For example, if a user has viewed some documents on the first page of search results, when the user clicks on the Next link to fetch more results, an existing retrieval system would still return the next page of results retrieved based on the original query without considering the new evidence that a particular result has been viewed by the user. 825 We propose to optimize retrieval performance by adapting system responses based on every action that a user has taken, and cast the optimization problem as a decision task.",
                "Specifically, at any time, the system would attempt to do two tasks: (1) User model updating: Monitor any useful evidence from the user regarding his/her information need and update the user model as soon as such evidence is available; (2) Improving search results: Rerank immediately all the documents that the user has not yet seen, as soon as the user model is updated.",
                "We emphasize eager updating and reranking, which makes our work quite different from any existing work.",
                "Below we present a formal decision theoretic framework for optimizing retrieval performance through implicit user modeling in interactive information retrieval. 3.1 A decision-theoretic framework Let A be the set of all user actions and R(a) be the set of all possible system responses to a user action a ∈ A.",
                "At any time, let At = (a1, ..., at) be the observed sequence of user actions so far (up to time point t) and Rt−1 = (r1, ..., rt−1) be the responses that the system has made responding to the user actions.",
                "The systems goal is to choose an optimal response rt ∈ R(at) for the current user action at.",
                "Let M be the space of all possible user models.",
                "We further define a loss function L(a, r, m) ∈ , where a ∈ A is a user action, r ∈ R(a) is a system response, and m ∈ M is a user model.",
                "L(a, r, m) encodes our decision preferences and assesses the optimality of responding with r when the current user model is m and the current user action is a.",
                "According to Bayesian decision theory, the optimal decision at time t is to choose a response that minimizes the Bayes risk, i.e., r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) where P(mt|U, D, At, Rt−1) is the posterior probability of the user model mt given all the observations about the user U we have made up to time t. To simplify the computation of Equation 1, let us assume that the posterior probability mass P(mt|U, D, At, Rt−1) is mostly concentrated on the mode m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "We can then approximate the integral with the value of the loss function at m∗ t .",
                "That is, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) where m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "Leaving aside how to define and estimate these probabilistic models and the loss function, we can see that such a decision-theoretic formulation suggests that, in order to choose the optimal response to at, the system should perform two tasks: (1) compute the current user model and obtain m∗ t based on all the useful information. (2) choose a response rt to minimize the loss function value L(at, rt, m∗ t ).",
                "When at does not affect our belief about m∗ t , the first step can be omitted and we may reuse m∗ t−1 for m∗ t .",
                "Note that our framework is quite general since we can potentially model any kind of user actions and system responses.",
                "In most cases, as we may expect, the systems response is some ranking of documents, i.e., for most actions a, R(a) consists of all the possible rankings of the unseen documents, and the decision problem boils down to choosing the best ranking of unseen documents based on the most current user model.",
                "When a is the action of submitting a keyword query, such a response is exactly what a current retrieval system would do.",
                "However, we can easily imagine that a more intelligent web search engine would respond to a users clicking of the Next link (to fetch more unseen results) with a more optimized ranking of documents based on any viewed documents in the current page of results.",
                "In fact, according to our eager updating strategy, we may even allow a system to respond to a users clicking of browsers Back button after viewing a document in the same way, so that the user can maximally benefit from implicit feedback.",
                "These are precisely what our UCAIR system does. 3.2 User models A user model m ∈ M represents what we know about the user U, so in principle, it can contain any information about the user that we wish to model.",
                "We now discuss two important components in a user model.",
                "The first component is a component model of the users information need.",
                "Presumably, the most important factor affecting the optimality of the systems response is how well the response addresses the users information need.",
                "Indeed, at any time, we may assume that the system has some belief about what the user is interested in, which we model through a term vector x = (x1, ..., x|V |), where V = {w1, ..., w|V |} is the set of all terms (i.e., vocabulary) and xi is the weight of term wi.",
                "Such a term vector is commonly used in information retrieval to represent both queries and documents.",
                "For example, the vector-space model, assumes that both the query and the documents are represented as term vectors and the score of a document with respect to a query is computed based on the similarity between the query vector and the document vector [21].",
                "In a language modeling approach, we may also regard the query unigram language model [12, 29] or the relevance model [14] as a term vector representation of the users information need.",
                "Intuitively, x would assign high weights to terms that characterize the topics which the user is interested in.",
                "The second component we may include in our user model is the documents that the user has already viewed.",
                "Obviously, even if a document is relevant, if the user has already seen the document, it would not be useful to present the same document again.",
                "We thus introduce another variable S ⊂ D (D is the whole set of documents in the collection) to denote the subset of documents in the search results that the user has already seen/viewed.",
                "In general, at time t, we may represent a user model as mt = (S, x, At, Rt−1), where S is the seen documents, x is the systems understanding of the users information need, and (At, Rt−1) represents the users interaction history.",
                "Note that an even more general user model may also include other factors such as the users reading level and occupation.",
                "If we assume that the uncertainty of a user model mt is solely due to the uncertainty of x, the computation of our current estimate of user model m∗ t will mainly involve computing our best estimate of x.",
                "That is, the system would choose a response according to r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) where x∗ = argmaxx P(x|U, D, At, Rt−1).",
                "This is the decision mechanism implemented in the UCAIR system to be described later.",
                "In this system, we avoided specifying the probabilistic model P(x|U, D, At, Rt−1) by computing x∗ directly with some existing feedback method. 3.3 Loss functions The exact definition of loss function L depends on the responses, thus it is inevitably application-specific.",
                "We now briefly discuss some possibilities when the response is to rank all the unseen documents and present the top k of them.",
                "Let r = (d1, ..., dk) be the top k documents, S be the set of seen documents by the user, and x∗ be the systems best guess of the users information need.",
                "We 826 may simply define the loss associated with r as the negative sum of the probability that each of the di is relevant, i.e., L(a, r, m) = − k i=1 P(relevant|di, m).",
                "Clearly, in order to minimize this loss function, the optimal response r would contain the k documents with the highest probability of relevance, which is intuitively reasonable.",
                "One deficiency of this top-k loss function is that it is not sensitive to the internal order of the selected top k documents, so switching the ranking order of a non-relevant document and a relevant one would not affect the loss, which is unreasonable.",
                "To model ranking, we can introduce a factor of the user model - the probability of each of the k documents being viewed by the user, P(view|di), and define the following ranking loss function: L(a, r, m) = − k i=1 P(view|di)P(relevant|di, m) Since in general, if di is ranked above dj (i.e., i < j), P(view|di) > P(view|dj), this loss function would favor a decision to rank relevant documents above non-relevant ones, as otherwise, we could always switch di with dj to reduce the loss value.",
                "Thus the system should simply perform a regular retrieval and rank documents according to the probability of relevance [18].",
                "Depending on the users retrieval preferences, there can be many other possibilities.",
                "For example, if the user does not want to see redundant documents, the loss function should include some redundancy measure on r based on the already seen documents S. Of course, when the response is not to choose a ranked list of documents, we would need a different loss function.",
                "We discuss one such example that is relevant to the search agent that we implement.",
                "When a user enters a query qt (current action), our search agent relies on some existing search engine to actually carry out search.",
                "In such a case, even though the search agent does not have control of the retrieval algorithm, it can still attempt to optimize the search results through refining the query sent to the search engine and/or reranking the results obtained from the search engine.",
                "The loss functions for reranking are already discussed above; we now take a look at the loss functions for query refinement.",
                "Let f be the retrieval function of the search engine that our agent uses so that f(q) would give us the search results using query q.",
                "Given that the current action of the user is entering a query qt (i.e., at = qt), our response would be f(q) for some q.",
                "Since we have no choice of f, our decision is to choose a good q.",
                "Formally, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) which shows that our goal is to find q∗ = argminqL(qt, f(q), m), i.e., an optimal query that would give us the best f(q).",
                "A different choice of loss function L(qt, f(q), m) would lead to a different query refinement strategy.",
                "In UCAIR, we heuristically compute q∗ by expanding qt with terms extracted from rt−1 whenever qt−1 and qt have high similarity.",
                "Note that rt−1 and qt−1 are contained in m as part of the users interaction history. 3.4 Implicit user modeling Implicit user modeling is captured in our framework through the computation of x∗ = argmaxx P(x|U, D, At, Rt−1), i.e., the systems current belief of what the users information need is.",
                "Here again there may be many possibilities, leading to different algorithms for implicit user modeling.",
                "We now discuss a few of them.",
                "First, when two consecutive queries are related, the previous query can be exploited to enrich the current query and provide more search context to help disambiguation.",
                "For this purpose, instead of performing query expansion as we did in the previous section, we could also compute an updated x∗ based on the previous query and retrieval results.",
                "The computed new user model can then be used to rank the documents with a standard information retrieval model.",
                "Second, we can also infer a users interest based on the summaries of the viewed documents.",
                "When a user is presented with a list of summaries of top ranked documents, if the user chooses to skip the first n documents and to view the (n+1)-th document, we may infer that the user is not interested in the displayed summaries for the first n documents, but is attracted by the displayed summary of the (n + 1)-th document.",
                "We can thus use these summaries as negative and positive examples to learn a more accurate user model x∗ .",
                "Here many standard relevance feedback techniques can be exploited [19, 20].",
                "Note that we should use the displayed summaries, as opposed to the actual contents of those documents, since it is possible that the displayed summary of the viewed document is relevant, but the document content is actually not.",
                "Similarly, a displayed summary may mislead a user to skip a relevant document.",
                "Inferring user models based on such displayed information, rather than the actual content of a document is an important difference between UCAIR and some other similar systems.",
                "In UCAIR, both of these strategies for inferring an implicit user model are implemented. 4.",
                "UCAIR: A PERSONALIZED SEARCH AGENT 4.1 Design In this section, we present a client-side web search agent called UCAIR, in which we implement some of the methods discussed in the previous section for performing personalized search through implicit user modeling.",
                "UCAIR is a web browser plug-in 1 that acts as a proxy for web search engines.",
                "Currently, it is only implemented for Internet Explorer and Google, but it is a matter of engineering to make it run on other web browsers and interact with other search engines.",
                "The issue of privacy is a primary obstacle for deploying any real world applications involving serious user modeling, such as personalized search.",
                "For this reason, UCAIR is strictly running as a client-side search agent, as opposed to a server-side application.",
                "This way, the captured user information always resides on the computer that the user is using, thus the user does not need to release any information to the outside.",
                "Client-side personalization also allows the system to easily observe a lot of user information that may not be easily available to a server.",
                "Furthermore, performing personalized search on the client-side is more scalable than on the serverside, since the overhead of computation and storage is distributed among clients.",
                "As shown in Figure 1, the UCAIR toolbar has 3 major components: (1) The (implicit) user modeling module captures a users search context and history information, including the submitted queries and any clicked search results and infers search session boundaries. (2) The query modification module selectively improves the query formulation according to the current user model. (3) The result re-ranking module immediately re-ranks any unseen search results whenever the user model is updated.",
                "In UCAIR, we consider four basic user actions: (1) submitting a keyword query; (2) viewing a document; (3) clicking the Back button; (4) clicking the Next link on a result page.",
                "For each of these four actions, the system responds with, respectively, (1) 1 UCAIR is available at: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Search Engine (e.g., Google) Search History Log (e.g.,past queries, clicked results) Query Modification Result Re-Ranking User Modeling Result Buffer UCAIR Userquery results clickthrough… Figure 1: UCAIR architecture generating a ranked list of results by sending a possibly expanded query to a search engine; (2) updating the information need model x; (3) reranking the unseen results on the current result page based on the current model x; and (4) reranking the unseen pages and generating the next page of results based on the current model x.",
                "Behind these responses, there are three basic tasks: (1) Decide whether the previous query is related to the current query and if so expand the current query with useful terms from the previous query or the results of the previous query. (2) Update the information need model x based on a newly clicked document summary. (3) Rerank a set of unseen documents based on the current model x.",
                "Below we describe our algorithms for each of them. 4.2 Session boundary detection and query expansion To effectively exploit previous queries and their corresponding clickthrough information, UCAIR needs to judge whether two adjacent queries belong to the same search session (i.e., detect session boundaries).",
                "Existing work on session boundary detection is mostly in the context of web log analysis (e.g., [8]), and uses statistical information rather than textual features.",
                "Since our clientside agent does not have access to server query logs, we make session boundary decisions based on textual similarity between two queries.",
                "Because related queries do not necessarily share the same words (e.g., java island and travel Indonesia), it is insufficient to use only query text.",
                "Therefore we use the search results of the two queries to help decide whether they are topically related.",
                "For example, for the above queries java island and travel Indonesia, the words java, bali, island, indonesia and travel may occur frequently in both queries search results, yielding a high similarity score.",
                "We only use the titles and summaries of the search results to calculate the similarity since they are available in the retrieved search result page and fetching the full text of every result page would significantly slow down the process.",
                "To compensate for the terseness of titles and summaries, we retrieve more results than a user would normally view for the purpose of detecting session boundaries (typically 50 results).",
                "The similarity between the previous query q and the current query q is computed as follows.",
                "Let {s1, s2, . . . , sn } and {s1, s2, . . . , sn} be the result sets for the two queries.",
                "We use the pivoted normalization TF-IDF weighting formula [24] to compute a term weight vector si for each result si.",
                "We define the average result savg to be the centroid of all the result vectors, i.e., (s1 + s2 + . . . + sn)/n.",
                "The cosine similarity between the two average results is calculated as s avg · savg/ s 2 avg · s2 avg If the similarity value exceeds a predefined threshold, the two queries will be considered to be in the same information session.",
                "If the previous query and the current query are found to belong to the same search session, UCAIR would attempt to expand the current query with terms from the previous query and its search results.",
                "Specifically, for each term in the previous query or the corresponding search results, if its frequency in the results of the current query is greater than a preset threshold (e.g. 5 results out of 50), the term would be added to the current query to form an expanded query.",
                "In this case, UCAIR would send this expanded query rather than the original one to the search engine and return the results corresponding to the expanded query.",
                "Currently, UCAIR only uses the immediate preceding query for query expansion; in principle, we could exploit all related past queries. 4.3 Information need model updating Suppose at time t, we have observed that the user has viewed k documents whose summaries are s1, ..., sk.",
                "We update our user model by computing a new information need vector with a standard feedback method in information retrieval (i.e., Rocchio [19]).",
                "According to the vector space retrieval model, each clicked summary si can be represented by a term weight vector si with each term weighted by a TF-IDF weighting formula [21].",
                "Rocchio computes the centroid vector of all the summaries and interpolates it with the original query vector to obtain an updated term vector.",
                "That is, x = αq + (1 − α) 1 k k i=1 si where q is the query vector, k is the number of summaries the user clicks immediately following the current query and α is a parameter that controls the influence of the clicked summaries on the inferred information need model.",
                "In our experiments, α is set to 0.5.",
                "Note that we update the information need model whenever the user views a document. 4.4 Result reranking In general, we want to rerank all the unseen results as soon as the user model is updated.",
                "Currently, UCAIR implements reranking in two cases, corresponding to the user clicking the Back button and Next link in the Internet Explorer.",
                "In both cases, the current (updated) user model would be used to rerank the unseen results so that the user would see improved search results immediately.",
                "To rerank any unseen document summaries, UCAIR uses the standard vector space retrieval model and scores each summary based on the similarity of the result and the current user information need vector x [21].",
                "Since implicit feedback is not completely reliable, we bring up only a small number (e.g. 5) of highest reranked results to be followed by any originally high ranked results. 828 Google result (user query = java map) UCAIR result (user query =java map) previous query = travel Indonesia previous query = hashtable expanded user query = java map Indonesia expanded user query = java map class 1 Java map projections of the world ... Lonely Planet - Indonesia Map Map (Java 2 Platform SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Java map projections of the world ... INDONESIA TOURISM : CENTRAL JAVA - MAP Java 2 Platform SE v1.3.1: Interface Map www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Java Map INDONESIA TOURISM : WEST JAVA - MAP An Introduction to Java Map Collection Classes java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Java Technology Concept Map IndoStreets - Java Map An Introduction to Java Map Collection Classes java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Indonesia Regions and Islands Maps, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 An Introduction to Java Map Collection Classes Indonesia City Street Map,... Hibernate simplifies inheritance mapping www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Java Map Maps Of Indonesia tmap 30.map Class Hierarchy www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Java API Map Maps of Indonesia by Peter Loud Class Scope www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas : Sam Maps of Indonesia by Peter Loud Class PrintSafeHashMap www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 INDONESIA TOURISM : WEST JAVA - MAP indonesiaphoto.com Java Pro - Union and Vertical Mapping of Classes www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Table 1: Sample results of query expansion 5.",
                "EVALUATION OF UCAIR We now present some results on evaluating the two major UCAIR functions: selective query expansion and result reranking based on user clickthrough data. 5.1 Sample results The query expansion strategy implemented in UCAIR is intentionally conservative to avoid misinterpretation of implicit user models.",
                "In practice, whenever it chooses to expand the query, the expansion usually makes sense.",
                "In Table 1, we show how UCAIR can successfully distinguish two different search contexts for the query java map, corresponding to two different previous queries (i.e., travel Indonesia vs. hashtable).",
                "Due to implicit user modeling, UCAIR intelligently figures out to add Indonesia and class, respectively, to the users query java map, which would otherwise be ambiguous as shown in the original results from Google on March 21, 2005.",
                "UCAIRs results are much more accurate than Googles results and reflect personalization in search.",
                "The eager implicit feedback component is designed to immediately respond to a users activity such as viewing a document.",
                "In Figure 2, we show how UCAIR can successfully disambiguate an ambiguous query jaguar by exploiting a viewed document summary.",
                "In this case, the initial retrieval results using jaguar (shown on the left side) contain two results about the Jaguar cars followed by two results about the Jaguar software.",
                "However, after the user views the web page content of the second result (about Jaguar car) and returns to the search result page by clicking Back button, UCAIR automatically nominates two new search results about Jaguar cars (shown on the right side), while the original two results about Jaguar software are pushed down on the list (unseen from the picture). 5.2 Quantitative evaluation To further evaluate UCAIR quantitatively, we conduct a user study on the effectiveness of the eager implicit feedback component.",
                "It is a challenge to quantitatively evaluate the potential performance improvement of our proposed model and UCAIR over Google in an unbiased way [7].",
                "Here, we design a user study, in which participants would do normal web search and judge a randomly and anonymously mixed set of results from Google and UCAIR at the end of the search session; participants do not know whether a result comes from Google or UCAIR.",
                "We recruited 6 graduate students for this user study, who have different backgrounds (3 computer science, 2 biology, and 1 chem<top> <num> Number: 716 <title> Spammer arrest sue <desc> Description: Have any spammers been arrested or sued for sending unsolicited e-mail? <narr> Narrative: Instances of arrests, prosecutions, convictions, and punishments of spammers, and lawsuits against them are relevant.",
                "Documents which describe laws to limit spam without giving details of lawsuits or criminal trials are not relevant. </top> Figure 3: An example of TREC query topic, expressed in a form which might be given to a human assistant or librarian istry).",
                "We use query topics from TREC 2 2004 Terabyte track [2] and TREC 2003 Web track [4] topic distillation task in the way to be described below.",
                "An example topic from TREC 2004 Terabyte track appears in Figure 3.",
                "The title is a short phrase and may be used as a query to the retrieval system.",
                "The description field provides a slightly longer statement of the topic requirement, usually expressed as a single complete sentence or question.",
                "Finally the narrative supplies additional information necessary to fully specify the requirement, expressed in the form of a short paragraph.",
                "Initially, each participant would browse 50 topics either from Terabyte track or Web track and pick 5 or 7 most interesting topics.",
                "For each picked topic, the participant would essentially do the normal web search using UCAIR to find many relevant web pages by using the title of the query topic as the initial keyword query.",
                "During this process, the participant may view the search results and possibly click on some interesting ones to view the web pages, just as in a normal web search.",
                "There is no requirement or restriction on how many queries the participant must submit or when the participant should stop the search for one topic.",
                "When the participant plans to change the search topic, he/she will simply press a button 2 Text REtrieval Conference: http://trec.nist.gov/ 829 Figure 2: Screen shots for result reranking to evaluate the search results before actually switching to the next topic.",
                "At the time of evaluation, 30 top ranked results from Google and UCAIR (some are overlapping) are randomly mixed together so that the participant would not know whether a result comes from Google or UCAIR.",
                "The participant would then judge the relevance of these results.",
                "We measure precision at top n (n = 5, 10, 20, 30) documents of Google and UCAIR.",
                "We also evaluate precisions at different recall levels.",
                "Altogether, 368 documents judged as relevant from Google search results and 429 documents judged as relevant from UCAIR by participants.",
                "Scatter plots of precision at top 10 and top 20 documents are shown in Figure 4 and Figure 5 respectively (The scatter plot of precision at top 30 documents is very similar to precision at top 20 documents).",
                "Each point of the scatter plots represents the precisions of Google and UCAIR on one query topic.",
                "Table 2 shows the average precision at top n documents among 32 topics.",
                "From Figure 4, Figure 5 and Table 2, we see that the search results from UCAIR are consistently better than those from Google by all the measures.",
                "Moreover, the performance improvement is more dramatic for precision at top 20 documents than that at precision at top 10 documents.",
                "One explanation for this is that the more interaction the user has with the system, the more clickthrough data UCAIR can be expected to collect.",
                "Thus the retrieval system can build more precise implicit user models, which lead to better retrieval accuracy.",
                "Ranking Method prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Improvement 8.0% 17.8% 20.2% 21.8% Table 2: Table of average precision at top n documents for 32 query topics The plot in Figure 6 shows the precision-recall curves for UCAIR and Google, where it is clearly seen that the performance of UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Scatterplot of Precision at Top 10 Documents Figure 4: Precision at top 10 documents of UCAIR and Google is consistently and considerably better than that of Google at all levels of recall. 6.",
                "CONCLUSIONS In this paper, we studied how to exploit implicit user modeling to intelligently personalize information retrieval and improve search accuracy.",
                "Unlike most previous work, we emphasize the use of immediate search context and implicit feedback information as well as eager updating of search results to maximally benefit a user.",
                "We presented a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent (UCAIR) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Scatterplot of Precision at Top 20 documents Figure 5: Precision at top 20 documents of UCAIR and Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 recall precision Precision−Recall curves Google Result UCAIR Result Figure 6: Precision at top 20 result of UCAIR and Google Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "The developed search agent thus can improve existing web search performance without any additional effort from the user. 7.",
                "ACKNOWLEDGEMENT We thank the six participants of our evaluation experiments.",
                "This work was supported in part by the National Science Foundation grants IIS-0347933 and IIS-0428472. 8.",
                "REFERENCES [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman, and O. Frieder.",
                "Hourly analysis of a very large topically categorized web query log.",
                "In Proceedings of SIGIR 2004, pages 321-328, 2004. [2] C. Clarke, N. Craswell, and I. Soboroff.",
                "Overview of the TREC 2004 terabyte track.",
                "In Proceedings of TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda, and D. Brown.",
                "Implicit interest indicators.",
                "In Proceedings of Intelligent User Interfaces 2001, pages 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson, and M. Wu.",
                "Overview of the TREC 2003 web track.",
                "In Proceedings of TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend, and V. Larvrenko.",
                "Relevance feedback and personalization: A language modeling perspective.",
                "In Proeedings of Second DELOS Workshop: Personalisation and Recommender Systems in Digital Libraries, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite, and D. Harman.",
                "Results and challenges in web search evaluation.",
                "Computer Networks, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A.",
                "An, and D. Schuurmans.",
                "Dynamic web log session identification with statistical language models.",
                "Journal of the American Society for Information Science and Technology, 55(14):1290-1303, 2004. [9] G. Jeh and J. Widom.",
                "Scaling personalized web search.",
                "In Proceedings of WWW 2003, pages 271-279, 2003. [10] T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of SIGKDD 2002, pages 133-142, 2002. [11] D. Kelly and J. Teevan.",
                "Implicit feedback for inferring user preference: A bibliography.",
                "SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of SIGIR01, pages 111-119, 2001. [13] T. Lau and E. Horvitz.",
                "Patterns of search: Analyzing and modeling web query refinement.",
                "In Proceedings of the Seventh International Conference on User Modeling (UM), pages 145 -152, 1999. [14] V. Lavrenko and B. Croft.",
                "Relevance-based language models.",
                "In Proceedings of SIGIR01, pages 120-127, 2001. [15] M. Mitra, A. Singhal, and C. Buckley.",
                "Improving automatic query expansion.",
                "In Proceedings of SIGIR 1998, pages 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg.",
                "As google goes, so goes the nation.",
                "New York Times, May 2003. [18] S. E. Robertson.",
                "The probability ranking principle in ı˚.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] J. J. Rocchio.",
                "Relevance feedback in information retrieval.",
                "In The SMART Retrieval System: Experiments in Automatic Document Processing, pages 313-323.",
                "Prentice-Hall Inc., 1971. [20] G. Salton and C. Buckley.",
                "Improving retrieval performance by retrieval feedback.",
                "Journal of the American Society for Information Science, 41(4):288-297, 1990. [21] G. Salton and M. J. McGill.",
                "Introduction to Modern Information Retrieval.",
                "McGraw-Hill, 1983. [22] X. Shen, B. Tan, and C. Zhai.",
                "Context-sensitive information retrieval using implicit feedback.",
                "In Proceedings of SIGIR 2005, pages 43-50, 2005. [23] X. Shen and C. Zhai.",
                "Exploiting query history for document ranking in interactive information retrieval (Poster).",
                "In Proceedings of SIGIR 2003, pages 377-378, 2003. [24] A. Singhal.",
                "Modern information retrieval: A brief overview.",
                "Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano, and M. Yoshikawa.",
                "Adaptive web search based on user profile constructed without any effort from users.",
                "In Proceedings of WWW 2004, pages 675-684, 2004. [26] E. Volokh.",
                "Personalization and privacy.",
                "Communications of the ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen, and I. Ruthven.",
                "A simulated study of implicit feedback models.",
                "In Proceedings of ECIR 2004, pages 311-326, 2004. [28] J. Xu and W. B. Croft.",
                "Query expansion using local and global document analysis.",
                "In Proceedings of SIGIR 1996, pages 4-11, 1996. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in KL divergence retrieval model.",
                "In Proceedings of the CIKM 2001, pages 403-410, 2001. 831"
            ],
            "original_annotated_samples": [
                "In order to optimize retrieval accuracy, we clearly need to model the user appropriately and <br>personalize search</br> according to each individual user."
            ],
            "translated_annotated_samples": [
                "Para optimizar la precisión de la recuperación, claramente necesitamos modelar al usuario de manera adecuada y <br>personalizar la búsqueda</br> según cada usuario individual."
            ],
            "translated_text": "Modelado implícito de usuarios para búsqueda personalizada Xuehua Shen, Bin Tan, ChengXiang Zhai Departamento de Ciencias de la Computación Universidad de Illinois en Urbana-Champaign RESUMEN Los sistemas de recuperación de información (por ejemplo, motores de búsqueda web) son críticos para superar la sobrecarga de información. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales, lo que resulta en un rendimiento de recuperación inherentemente no óptimo. Por ejemplo, un turista y un programador pueden usar la misma palabra \"java\" para buscar información diferente, pero los sistemas de búsqueda actuales devolverían los mismos resultados. En este artículo, estudiamos cómo inferir el interés de un usuario a partir del contexto de búsqueda del usuario y utilizar el modelo de usuario implícito inferido para la búsqueda personalizada. Presentamos un marco teórico de toma de decisiones y desarrollamos técnicas para el modelado implícito del usuario en la recuperación de información. Desarrollamos un agente de búsqueda web inteligente del lado del cliente (UCAIR) que puede realizar retroalimentación implícita ansiosa, por ejemplo, expansión de consultas basada en consultas anteriores y reordenamiento inmediato de resultados basado en información de clics. Los experimentos sobre la búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda sobre el popular motor de búsqueda Google. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación, Retroalimentación de relevancia, Proceso de búsqueda Términos Generales Algoritmos 1. Aunque muchos sistemas de recuperación de información (por ejemplo, motores de búsqueda web y sistemas de biblioteca digital) se han implementado con éxito, los sistemas de recuperación actuales están lejos de ser óptimos. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales [17]. Esta no optimalidad inherente se ve claramente en los siguientes dos casos: (1) Diferentes usuarios pueden utilizar exactamente la misma consulta (por ejemplo, Java) para buscar información diferente (por ejemplo, la isla de Java en Indonesia o el lenguaje de programación Java), pero los sistemas de IR existentes devuelven los mismos resultados para estos usuarios. Sin considerar al usuario actual, es imposible saber a qué sentido se refiere Java en una consulta. (2) Las necesidades de información de un usuario pueden cambiar con el tiempo. El mismo usuario puede usar Java a veces para referirse a la isla de Java en Indonesia y otras veces para referirse al lenguaje de programación. Sin reconocer el contexto de búsqueda, sería nuevamente imposible reconocer el sentido correcto. Para optimizar la precisión de la recuperación, claramente necesitamos modelar al usuario de manera adecuada y <br>personalizar la búsqueda</br> según cada usuario individual. El objetivo principal del modelado de usuario para la recuperación de información es modelar con precisión la necesidad de información de un usuario, lo cual, desafortunadamente, es una tarea muy difícil. De hecho, incluso resulta difícil para un usuario describir con precisión cuál es su necesidad de información. ¿Qué información está disponible para que un sistema pueda inferir la necesidad de información de un usuario? Obviamente, la consulta de los usuarios proporciona la evidencia más directa. De hecho, la mayoría de los sistemas de recuperación existentes se basan únicamente en la consulta para modelar la necesidad de información de los usuarios. Sin embargo, dado que una consulta suele ser extremadamente corta, el modelo de usuario construido basado en una consulta de palabras clave inevitablemente resulta empobrecido. Una forma efectiva de mejorar la modelización de usuarios en la recuperación de información es pedir al usuario que especifique explícitamente qué documentos son relevantes (es decir, útiles para satisfacer su necesidad de información) y luego mejorar la modelización de usuarios basándose en ejemplos de documentos relevantes. Esto se llama retroalimentación de relevancia, lo cual ha demostrado ser bastante efectivo para mejorar la precisión de recuperación [19, 20]. Desafortunadamente, en aplicaciones del mundo real, los usuarios suelen ser reacios a hacer el esfuerzo adicional de proporcionar ejemplos relevantes para retroalimentación [11]. Por lo tanto, es muy interesante estudiar cómo inferir la necesidad de información de un usuario basándose en cualquier información de retroalimentación implícita, la cual existe naturalmente a través de las interacciones del usuario y no requiere ningún esfuerzo adicional por parte del usuario. De hecho, varios estudios previos han demostrado que el modelado implícito del usuario puede mejorar la precisión de recuperación. En [3], se desarrolla un navegador web (Curious Browser) para registrar las calificaciones explícitas de relevancia de las páginas web por parte de los usuarios (retroalimentación de relevancia) y el comportamiento de navegación al ver una página, como el tiempo de permanencia, clics de ratón, movimiento del ratón y desplazamiento (retroalimentación implícita). Se muestra que el tiempo de permanencia en una página, la cantidad de desplazamiento en una página y la combinación de tiempo y desplazamiento tienen una fuerte correlación con las calificaciones de relevancia explícita, lo que sugiere que la retroalimentación implícita puede ser útil para inferir la necesidad de información del usuario. En [10], se recopilan datos de clics de usuario como datos de entrenamiento para aprender una función de recuperación, que se utiliza para producir un ranking personalizado de resultados de búsqueda que se adapte a las preferencias de un grupo de usuarios. En [25], los datos de clics recopilados durante un largo período de tiempo se utilizan a través de la expansión de consultas para mejorar la precisión de recuperación. Si bien un usuario puede tener intereses y preferencias generales a largo plazo para la información, a menudo está buscando documentos para satisfacer una necesidad de información ad-hoc, que solo dura un corto período de tiempo; una vez que se satisface la necesidad de información, el usuario generalmente ya no estaría interesado en esa información. Por ejemplo, un usuario puede estar buscando información sobre autos usados para comprar uno, pero una vez que el usuario ha comprado un auto, generalmente ya no está interesado en esa información. En tales casos, la información de retroalimentación implícita recopilada durante un largo período de tiempo es poco probable que sea muy útil, pero el contexto de búsqueda inmediato y la información de retroalimentación, como cuáles de los resultados de búsqueda para la necesidad de información actual son vistos, se espera que sean mucho más útiles. Considera la consulta de Java nuevamente. Cualquiera de la siguiente información de retroalimentación inmediata sobre el usuario podría potencialmente ayudar a determinar el significado previsto de Java en la consulta: (1) La consulta anterior enviada por el usuario es hashtable (en lugar de, por ejemplo, viajar a Indonesia). (2) En los resultados de búsqueda, el usuario visualizó una página donde palabras como programación, software y applet ocurren muchas veces. Hasta donde sabemos, cómo aprovechar este contexto de búsqueda inmediato y a corto plazo para mejorar la búsqueda aún no ha sido abordado de manera satisfactoria en trabajos anteriores. En este artículo, estudiamos cómo construir y actualizar un modelo de usuario basado en el contexto de búsqueda inmediato y la información de retroalimentación implícita, y utilizar el modelo para mejorar la precisión de la recuperación ad-hoc. Para beneficiar al máximo al usuario de un sistema de recuperación a través de modelado implícito del usuario, proponemos realizar retroalimentación implícita entusiasta. Es decir, tan pronto como observemos cualquier nueva pieza de evidencia del usuario, actualizaríamos la creencia del sistema sobre la necesidad de información del usuario y responderíamos con resultados de recuperación mejorados basados en el modelo de usuario actualizado. Presentamos un marco de trabajo de teoría de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. En un paradigma de recuperación tradicional, el problema de recuperación consiste en emparejar una consulta con documentos y clasificar los documentos según sus valores de relevancia. Como resultado, el proceso de recuperación es un ciclo independiente simple de consulta y visualización de resultados. En el nuevo paradigma de recuperación propuesto, el contexto de búsqueda de los usuarios juega un papel importante y el modelo de usuario implícito inferido se explota inmediatamente para beneficiar al usuario. El nuevo paradigma de recuperación es, por lo tanto, fundamentalmente diferente del paradigma tradicional y es inherentemente más general. Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos apropiados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para reordenar inmediatamente cualquier documento que aún no haya sido visto por el usuario. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente UCAIR (Recuperación de Información Adaptativa Centrada en el Usuario) sobre un motor de búsqueda popular (Google). Los experimentos sobre búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en comparación con Google. Dado que la información implícita que explotamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional. Por lo tanto, el agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin esfuerzo adicional por parte del usuario. Las secciones restantes están organizadas de la siguiente manera. En la Sección 2, discutimos el trabajo relacionado. En la Sección 3, presentamos un marco de recuperación interactiva basado en teoría de decisiones para modelado implícito de usuarios. En la Sección 4, presentamos el diseño e implementación de un agente de búsqueda web inteligente del lado del cliente (UCAIR) que realiza retroalimentación implícita ansiosa. En la Sección 5, informamos nuestros resultados experimentales utilizando el agente de búsqueda. La sección 6 concluye nuestro trabajo. 2. El modelado implícito del usuario para la búsqueda personalizada ha sido estudiado en trabajos anteriores, pero nuestro trabajo difiere de todos los trabajos anteriores en varios aspectos: (1) Enfatizamos la explotación del contexto de búsqueda inmediato, como la consulta inmediatamente anterior relacionada y los documentos vistos en la misma sesión, mientras que la mayoría de los trabajos anteriores se basan en la recopilación a largo plazo de información de retroalimentación implícita [25]. (2) Realizamos una retroalimentación activa y obtenemos el beneficio del modelado implícito del usuario tan pronto como esté disponible cualquier nueva información de retroalimentación implícita, mientras que el trabajo anterior mayormente explota la retroalimentación implícita a largo plazo [10]. (3) Proponemos un marco de recuperación para integrar el modelado implícito del usuario con el proceso interactivo de recuperación, mientras que el trabajo anterior estudia el modelado implícito del usuario por separado de la recuperación [3] o solo estudia modelos de recuperación específicos para explotar la retroalimentación implícita para mejorar la coincidencia de una consulta con documentos [23, 27, 22]. (4) Desarrollamos y evaluamos un agente de búsqueda web personalizado con estudios de usuario en línea, mientras que la mayoría de los trabajos existentes evalúan algoritmos fuera de línea sin interacciones reales de usuarios. Actualmente algunos motores de búsqueda ofrecen personalización rudimentaria, como la búsqueda web personalizada de Google [6], que permite a los usuarios describir explícitamente sus intereses seleccionando entre temas predefinidos, de modo que los resultados que coinciden con sus intereses se muestren en la parte superior, y la búsqueda de My Yahoo! [16], que brinda a los usuarios la opción de guardar los sitios web que les gustan y bloquear aquellos que no les gustan. Por el contrario, UCAIR personaliza la búsqueda web a través de la modelización implícita del usuario sin necesidad de esfuerzos adicionales por parte del usuario. Además, la personalización de UCAIR se proporciona en el lado del cliente. Hay dos ventajas notables en esto. Primero, el usuario no necesita preocuparse por la infracción de privacidad, que es una gran preocupación para la búsqueda personalizada [26]. En segundo lugar, tanto el cálculo de la personalización como el almacenamiento del perfil del usuario se realizan en el lado del cliente para reducir drásticamente la carga del servidor [9]. Ha habido muchos trabajos estudiando los registros de consultas de usuarios [1] o la dinámica de consultas [13]. UCAIR hace uso directo del historial de consultas de un usuario para beneficiar al mismo usuario de inmediato en la misma sesión de búsqueda. UCAIR primero determina si dos consultas vecinas pertenecen a la misma sesión de información y, de ser así, selecciona términos de la consulta anterior para realizar la expansión de la consulta. Nuestro enfoque de expansión de consultas es similar a la expansión automática de consultas [28, 15, 5], pero en lugar de utilizar retroalimentación pseudo para expandir la consulta, utilizamos la información de retroalimentación implícita de los usuarios para expandir la consulta actual. Estas dos técnicas pueden ser combinadas. 3. OPTIMIZACIÓN EN IR INTERACTIVO En IR interactivo, un usuario interactúa con el sistema de recuperación a través de un diálogo de acción, en el cual el sistema responde a cada acción del usuario con alguna acción del sistema. Por ejemplo, la acción de los usuarios puede ser enviar una consulta y la respuesta del sistema puede ser devolver una lista de 10 resúmenes de documentos. En general, el espacio de acciones del usuario y respuestas del sistema y sus granularidades dependerían de la interfaz de un sistema de recuperación particular. En principio, cada acción del usuario puede potencialmente proporcionar nuevas pruebas para ayudar al sistema a inferir mejor la necesidad de información del usuario. Por lo tanto, para responder de manera óptima, el sistema debería utilizar toda la evidencia recopilada hasta ahora sobre el usuario al elegir una respuesta. Cuando se ven de esta manera, la mayoría de los motores de búsqueda existentes son claramente no óptimos. Por ejemplo, si un usuario ha visto algunos documentos en la primera página de resultados de búsqueda, cuando el usuario hace clic en el enlace Siguiente para obtener más resultados, un sistema de recuperación existente seguiría devolviendo la siguiente página de resultados recuperados en función de la consulta original sin considerar la nueva evidencia de que un resultado en particular ha sido visto por el usuario. Proponemos optimizar el rendimiento de la recuperación adaptando las respuestas del sistema en función de cada acción que un usuario haya tomado, y planteamos el problema de optimización como una tarea de decisión. Específicamente, en cualquier momento, el sistema intentaría realizar dos tareas: (1) Actualización del modelo de usuario: Monitorear cualquier evidencia útil del usuario con respecto a su necesidad de información y actualizar el modelo de usuario tan pronto como esta evidencia esté disponible; (2) Mejorar los resultados de búsqueda: Reclasificar inmediatamente todos los documentos que el usuario aún no ha visto, tan pronto como se actualice el modelo de usuario. Enfatizamos la actualización y reordenamiento entusiastas, lo que hace que nuestro trabajo sea bastante diferente a cualquier trabajo existente. A continuación presentamos un marco formal de teoría de decisiones para optimizar el rendimiento de recuperación a través de la modelización implícita del usuario en la recuperación de información interactiva. 3.1 Un marco de teoría de decisiones Sea A el conjunto de todas las acciones del usuario y R(a) el conjunto de todas las posibles respuestas del sistema a una acción del usuario a ∈ A. En cualquier momento, sea At = (a1, ..., at) la secuencia observada de acciones de usuario hasta ahora (hasta el momento t) y Rt−1 = (r1, ..., rt−1) las respuestas que el sistema ha dado en respuesta a las acciones del usuario. El objetivo del sistema es elegir una respuesta óptima rt ∈ R(at) para la acción actual del usuario at. Sea M el espacio de todos los posibles modelos de usuario. Definimos además una función de pérdida L(a, r, m) ∈ , donde a ∈ A es una acción del usuario, r ∈ R(a) es una respuesta del sistema, y m ∈ M es un modelo de usuario. L(a, r, m) codifica nuestras preferencias de decisión y evalúa la optimalidad de responder con r cuando el modelo de usuario actual es m y la acción de usuario actual es a. Según la teoría de decisión bayesiana, la decisión óptima en el tiempo t es elegir una respuesta que minimice el riesgo de Bayes, es decir, r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) donde P(mt|U, D, At, Rt−1) es la probabilidad posterior del modelo de usuario mt dadas todas las observaciones sobre el usuario U que hemos realizado hasta el tiempo t. Para simplificar el cálculo de la Ecuación 1, asumamos que la masa de probabilidad posterior P(mt|U, D, At, Rt−1) está principalmente concentrada en el modo m∗ t = argmaxmt P(mt|U, D, At, Rt−1). Podemos entonces aproximar la integral con el valor de la función de pérdida en m∗ t. Es decir, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) donde m∗ t = argmaxmt P(mt|U, D, At, Rt−1). Dejando de lado cómo definir y estimar estos modelos probabilísticos y la función de pérdida, podemos ver que tal formulación de la teoría de decisiones sugiere que, para elegir la respuesta óptima a at, el sistema debería realizar dos tareas: (1) calcular el modelo de usuario actual y obtener m∗ t basado en toda la información útil. (2) elegir una respuesta rt para minimizar el valor de la función de pérdida L(at, rt, m∗ t). Cuando at no afecta nuestra creencia sobre m∗ t , el primer paso puede omitirse y podemos reutilizar m∗ t−1 para m∗ t . Ten en cuenta que nuestro marco de trabajo es bastante general, ya que potencialmente podemos modelar cualquier tipo de acciones de usuario y respuestas del sistema. En la mayoría de los casos, como podríamos esperar, la respuesta del sistema es algún tipo de clasificación de documentos, es decir, para la mayoría de las acciones a, R(a) consiste en todas las posibles clasificaciones de los documentos no vistos, y el problema de decisión se reduce a elegir la mejor clasificación de los documentos no vistos basándose en el modelo de usuario más actualizado. Cuando a es la acción de enviar una consulta de palabras clave, tal respuesta es exactamente lo que haría un sistema de recuperación actual. Sin embargo, fácilmente podemos imaginar que un motor de búsqueda web más inteligente respondería al clic del usuario en el enlace Siguiente (para obtener más resultados no vistos) con una clasificación más optimizada de documentos basada en cualquier documento visto en la página actual de resultados. De hecho, según nuestra estrategia de actualización entusiasta, incluso podríamos permitir que un sistema responda al clic del botón Atrás del navegador por parte de un usuario después de ver un documento de la misma manera, para que el usuario pueda beneficiarse al máximo de la retroalimentación implícita. Estos son precisamente lo que nuestro sistema UCAIR hace. 3.2 Modelos de usuario Un modelo de usuario m ∈ M representa lo que sabemos sobre el usuario U, por lo que en principio, puede contener cualquier información sobre el usuario que deseemos modelar. Ahora discutimos dos componentes importantes en un modelo de usuario. El primer componente es un modelo de componente de la necesidad de información de los usuarios. Presumiblemente, el factor más importante que afecta la optimalidad de la respuesta del sistema es qué tan bien la respuesta aborda la necesidad de información de los usuarios. De hecho, en cualquier momento, podemos asumir que el sistema tiene alguna creencia sobre lo que le interesa al usuario, la cual modelamos a través de un vector de términos x = (x1, ..., x|V|), donde V = {w1, ..., w|V|} es el conjunto de todos los términos (es decir, vocabulario) y xi es el peso del término wi. Un vector de términos de este tipo se utiliza comúnmente en la recuperación de información para representar tanto consultas como documentos. Por ejemplo, el modelo de espacio vectorial asume que tanto la consulta como los documentos se representan como vectores de términos y que la puntuación de un documento con respecto a una consulta se calcula en función de la similitud entre el vector de la consulta y el vector del documento [21]. En un enfoque de modelado de lenguaje, también podemos considerar el modelo de lenguaje unigrama de consulta [12, 29] o el modelo de relevancia [14] como una representación vectorial de términos de la necesidad de información de los usuarios. Intuitivamente, x asignaría pesos altos a los términos que caracterizan los temas que interesan al usuario. El segundo componente que podemos incluir en nuestro modelo de usuario son los documentos que el usuario ya ha visto. Obviamente, incluso si un documento es relevante, si el usuario ya ha visto el documento, no sería útil presentar el mismo documento de nuevo. Por lo tanto, introducimos otra variable S ⊂ D (D es el conjunto completo de documentos en la colección) para denotar el subconjunto de documentos en los resultados de búsqueda que el usuario ya ha visto. En general, en el tiempo t, podemos representar un modelo de usuario como mt = (S, x, At, Rt−1), donde S son los documentos vistos, x es la comprensión del sistema de la necesidad de información del usuario, y (At, Rt−1) representa el historial de interacción del usuario. Ten en cuenta que un modelo de usuario aún más general también puede incluir otros factores como el nivel de lectura y la ocupación de los usuarios. Si asumimos que la incertidumbre de un modelo de usuario mt se debe únicamente a la incertidumbre de x, el cálculo de nuestra estimación actual del modelo de usuario m∗ t implicará principalmente calcular nuestra mejor estimación de x. Es decir, el sistema elegiría una respuesta de acuerdo a r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) donde x∗ = argmaxx P(x|U, D, At, Rt−1). Este es el mecanismo de decisión implementado en el sistema UCAIR que se describirá más adelante. En este sistema, evitamos especificar el modelo probabilístico P(x|U, D, At, Rt−1) calculando x∗ directamente con algún método de retroalimentación existente. 3.3 Funciones de pérdida La definición exacta de la función de pérdida L depende de las respuestas, por lo que es inevitablemente específica de la aplicación. Ahora discutimos brevemente algunas posibilidades cuando la respuesta es clasificar todos los documentos no vistos y presentar los mejores k de ellos. Sea r = (d1, ..., dk) los k documentos principales, S el conjunto de documentos vistos por el usuario, y x∗ la mejor suposición del sistema sobre la necesidad de información del usuario. Podemos definir simplemente la pérdida asociada con r como la suma negativa de la probabilidad de que cada uno de los di sea relevante, es decir, L(a, r, m) = − k i=1 P(relevante|di, m). Claramente, para minimizar esta función de pérdida, la respuesta óptima r contendría los k documentos con la probabilidad más alta de relevancia, lo cual es intuitivamente razonable. Una deficiencia de esta función de pérdida top-k es que no es sensible al orden interno de los documentos top k seleccionados, por lo que cambiar el orden de clasificación de un documento no relevante y uno relevante no afectaría la pérdida, lo cual es irrazonable. Para modelar el ranking, podemos introducir un factor del modelo de usuario: la probabilidad de que cada uno de los k documentos sea visto por el usuario, P(vista|di), y definir la siguiente función de pérdida de ranking: L(a, r, m) = − k i=1 P(vista|di)P(relevante|di, m). Dado que, en general, si di está clasificado por encima de dj (es decir, i < j), P(vista|di) > P(vista|dj), esta función de pérdida favorecería una decisión de clasificar documentos relevantes por encima de los no relevantes, ya que de lo contrario, siempre podríamos intercambiar di con dj para reducir el valor de pérdida. Por lo tanto, el sistema simplemente debería realizar una recuperación regular y clasificar los documentos según la probabilidad de relevancia [18]. Dependiendo de las preferencias de recuperación de los usuarios, puede haber muchas otras posibilidades. Por ejemplo, si el usuario no desea ver documentos redundantes, la función de pérdida debería incluir alguna medida de redundancia en r basada en los documentos ya vistos S. Por supuesto, cuando la respuesta no es elegir una lista clasificada de documentos, necesitaríamos una función de pérdida diferente. Discutimos un ejemplo relevante para el agente de búsqueda que implementamos. Cuando un usuario ingresa una consulta qt (acción actual), nuestro agente de búsqueda se basa en algún motor de búsqueda existente para llevar a cabo la búsqueda en realidad. En tal caso, aunque el agente de búsqueda no tenga control sobre el algoritmo de recuperación, aún puede intentar optimizar los resultados de la búsqueda refinando la consulta enviada al motor de búsqueda y/o reordenando los resultados obtenidos del motor de búsqueda. Las funciones de pérdida para el reordenamiento ya fueron discutidas anteriormente; ahora echamos un vistazo a las funciones de pérdida para el refinamiento de consultas. Sea f la función de recuperación del motor de búsqueda que nuestro agente utiliza, de modo que f(q) nos daría los resultados de búsqueda utilizando la consulta q. Dado que la acción actual del usuario es ingresar una consulta qt (es decir, at = qt), nuestra respuesta sería f(q) para algún q. Dado que no tenemos elección de f, nuestra decisión es elegir un buen q. Formalmente, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) lo cual muestra que nuestro objetivo es encontrar q∗ = argminqL(qt, f(q), m), es decir, una consulta óptima que nos daría el mejor f(q). Una elección diferente de la función de pérdida L(qt, f(q), m) llevaría a una estrategia de refinamiento de consulta diferente. En UCAIR, calculamos heurísticamente q∗ expandiendo qt con términos extraídos de rt−1 siempre que qt−1 y qt tengan una alta similitud. Se debe tener en cuenta que rt−1 y qt−1 están contenidos en m como parte del historial de interacción de los usuarios. 3.4 Modelado implícito del usuario El modelado implícito del usuario se captura en nuestro marco a través del cálculo de x∗ = argmaxx P(x|U, D, At, Rt−1), es decir, la creencia actual del sistema sobre cuál es la necesidad de información del usuario. Aquí nuevamente puede haber muchas posibilidades, lo que lleva a diferentes algoritmos para la modelización implícita del usuario. Ahora discutimos algunos de ellos. Primero, cuando dos consultas consecutivas están relacionadas, la consulta anterior puede ser explotada para enriquecer la consulta actual y proporcionar más contexto de búsqueda para ayudar en la desambiguación. Para este propósito, en lugar de realizar una expansión de consulta como lo hicimos en la sección anterior, también podríamos calcular un x∗ actualizado basado en la consulta anterior y los resultados de recuperación. El modelo de usuario nuevo calculado puede luego ser utilizado para clasificar los documentos con un modelo estándar de recuperación de información. Segundo, también podemos inferir los intereses de un usuario basándonos en los resúmenes de los documentos visualizados. Cuando a un usuario se le presenta una lista de resúmenes de documentos mejor clasificados, si el usuario elige saltarse los primeros n documentos y ver el documento (n+1)-ésimo, podemos inferir que el usuario no está interesado en los resúmenes mostrados para los primeros n documentos, pero está atraído por el resumen mostrado del documento (n+1)-ésimo. Por lo tanto, podemos usar estos resúmenes como ejemplos negativos y positivos para aprender un modelo de usuario más preciso x∗. Aquí se pueden explotar muchas técnicas estándar de retroalimentación de relevancia [19, 20]. Ten en cuenta que debemos utilizar los resúmenes mostrados, en lugar de los contenidos reales de esos documentos, ya que es posible que el resumen mostrado del documento visto sea relevante, pero el contenido del documento en realidad no lo sea. Del mismo modo, un resumen mostrado puede llevar a un usuario a omitir un documento relevante. Inferir modelos de usuario basados en dicha información mostrada, en lugar del contenido real de un documento, es una diferencia importante entre UCAIR y algunos otros sistemas similares. En UCAIR, ambas estrategias para inferir un modelo de usuario implícito están implementadas. 4. UCAIR: Un agente de búsqueda personalizado 4.1 Diseño En esta sección, presentamos un agente de búsqueda web del lado del cliente llamado UCAIR, en el cual implementamos algunos de los métodos discutidos en la sección anterior para realizar búsquedas personalizadas a través de modelado implícito del usuario. UCAIR es un complemento del navegador web que actúa como proxy para los motores de búsqueda en la web. Actualmente, solo está implementado para Internet Explorer y Google, pero es cuestión de ingeniería hacer que funcione en otros navegadores web e interactúe con otros motores de búsqueda. El tema de la privacidad es un obstáculo principal para implementar cualquier aplicación del mundo real que involucre modelado de usuarios serio, como la búsqueda personalizada. Por esta razón, UCAIR funciona estrictamente como un agente de búsqueda del lado del cliente, en lugar de ser una aplicación del lado del servidor. De esta manera, la información del usuario capturada siempre permanece en la computadora que está utilizando el usuario, por lo tanto, el usuario no necesita revelar ninguna información al exterior. La personalización del lado del cliente también permite que el sistema observe fácilmente una gran cantidad de información del usuario que puede no estar fácilmente disponible para un servidor. Además, realizar búsquedas personalizadas en el lado del cliente es más escalable que en el lado del servidor, ya que la sobrecarga de cálculo y almacenamiento se distribuye entre los clientes. Como se muestra en la Figura 1, la barra de herramientas UCAIR tiene 3 componentes principales: (1) El módulo de modelado de usuario (implícito) captura el contexto de búsqueda de un usuario e información de historial, incluidas las consultas enviadas y los resultados de búsqueda clicados, e infiere los límites de la sesión de búsqueda. (2) El módulo de modificación de consultas mejora selectivamente la formulación de la consulta de acuerdo con el modelo de usuario actual. (3) El módulo de reordenamiento de resultados reordena inmediatamente cualquier resultado de búsqueda no visto cada vez que se actualiza el modelo de usuario. En UCAIR, consideramos cuatro acciones básicas de usuario: (1) enviar una consulta de palabras clave; (2) ver un documento; (3) hacer clic en el botón Atrás; (4) hacer clic en el enlace Siguiente en una página de resultados. Para cada una de estas cuatro acciones, el sistema responde con, respectivamente, (1) 1 UCAIR está disponible en: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Registro de Historial de Búsqueda del Motor de Búsqueda (por ejemplo, Google) (consultas pasadas, resultados clicados) Modificación de Consulta Resultado de Reclasificación Modelo de Usuario Buffer de Resultados de Consulta de Usuario UCAIR... Figura 1: arquitectura de UCAIR generando una lista clasificada de resultados enviando una consulta posiblemente ampliada a un motor de búsqueda; (2) actualizando el modelo de necesidad de información x; (3) reordenando los resultados no vistos en la página de resultados actual basándose en el modelo actual x; y (4) reordenando las páginas no vistas y generando la siguiente página de resultados basándose en el modelo actual x. Detrás de estas respuestas, hay tres tareas básicas: (1) Decidir si la consulta anterior está relacionada con la consulta actual y, de ser así, ampliar la consulta actual con términos útiles de la consulta anterior o los resultados de la consulta anterior. (2) Actualizar el modelo de necesidad de información x basado en un resumen de documento recién seleccionado. (3) Reordenar un conjunto de documentos no vistos basado en el modelo x actual. A continuación describimos nuestros algoritmos para cada uno de ellos. 4.2 Detección de límites de sesión y expansión de consultas Para explotar eficazmente las consultas anteriores y su información correspondiente de clics, UCAIR necesita determinar si dos consultas adyacentes pertenecen a la misma sesión de búsqueda (es decir, detectar los límites de sesión). El trabajo existente sobre la detección de límites de sesión se encuentra principalmente en el contexto del análisis de registros web (por ejemplo, [8]), y utiliza información estadística en lugar de características textuales. Dado que nuestro agente del lado del cliente no tiene acceso a los registros de consultas del servidor, tomamos decisiones sobre los límites de sesión basadas en la similitud textual entre dos consultas. Debido a que las consultas relacionadas no necesariamente comparten las mismas palabras (por ejemplo, isla de Java y viajar a Indonesia), no es suficiente utilizar solo el texto de la consulta. Por lo tanto, utilizamos los resultados de búsqueda de las dos consultas para ayudar a decidir si están relacionadas temáticamente. Por ejemplo, para las consultas anteriores \"java island\" y \"travel Indonesia\", las palabras \"java\", \"bali\", \"island\", \"indonesia\" y \"travel\" pueden aparecer con frecuencia en los resultados de búsqueda de ambas consultas, lo que produce un alto puntaje de similitud. Solo utilizamos los títulos y resúmenes de los resultados de búsqueda para calcular la similitud, ya que están disponibles en la página de resultados de búsqueda recuperada y obtener el texto completo de cada página de resultados ralentizaría significativamente el proceso. Para compensar la concisión de los títulos y resúmenes, recuperamos más resultados de los que un usuario normalmente vería con el propósito de detectar los límites de sesión (típicamente 50 resultados). La similitud entre la consulta anterior q y la consulta actual q se calcula de la siguiente manera. Sean {s1, s2, . . . , sn} y {s1, s2, . . . , sn} los conjuntos de resultados de las dos consultas. Utilizamos la fórmula de ponderación TF-IDF normalizada pivotada [24] para calcular un vector de peso de término si para cada resultado si. Definimos el resultado promedio savg como el centroide de todos los vectores de resultado, es decir, (s1 + s2 + . . . + sn)/n. La similitud del coseno entre los dos resultados promedio se calcula como s avg · savg/ s 2 avg · s2 avg. Si el valor de similitud supera un umbral predefinido, se considerará que las dos consultas están en la misma sesión de información. Si se determina que la consulta anterior y la consulta actual pertenecen a la misma sesión de búsqueda, UCAIR intentaría expandir la consulta actual con términos de la consulta anterior y sus resultados de búsqueda. Específicamente, para cada término en la consulta anterior o los resultados de búsqueda correspondientes, si su frecuencia en los resultados de la consulta actual es mayor que un umbral preestablecido (por ejemplo, 5 resultados de 50), el término se agregaría a la consulta actual para formar una consulta ampliada. En este caso, UCAIR enviaría esta consulta ampliada en lugar de la original al motor de búsqueda y devolvería los resultados correspondientes a la consulta ampliada. Actualmente, UCAIR solo utiliza la consulta inmediatamente anterior para la expansión de consultas; en principio, podríamos aprovechar todas las consultas pasadas relacionadas. 4.3 Actualización del modelo de necesidad de información Supongamos que en el tiempo t, hemos observado que el usuario ha visto k documentos cuyos resúmenes son s1, ..., sk. Actualizamos nuestro modelo de usuario calculando un nuevo vector de necesidad de información con un método estándar de retroalimentación en la recuperación de información (es decir, Rocchio [19]). Según el modelo de recuperación de espacio vectorial, cada resumen clicado si puede ser representado por un vector de pesos de términos si, con cada término ponderado por una fórmula de ponderación TF-IDF [21]. Rocchio calcula el vector centroide de todos los resúmenes e interpola este con el vector de consulta original para obtener un vector de términos actualizado. Es decir, x = αq + (1 − α) 1 k k i=1 si donde q es el vector de consulta, k es el número de resúmenes que el usuario hace clic inmediatamente después de la consulta actual y α es un parámetro que controla la influencia de los resúmenes clicados en el modelo de necesidad de información inferida. En nuestros experimentos, α se establece en 0.5. Ten en cuenta que actualizamos el modelo de información necesario cada vez que el usuario ve un documento. 4.4 Reclasificación de resultados En general, queremos volver a clasificar todos los resultados no vistos tan pronto como se actualice el modelo de usuario. Actualmente, UCAIR implementa el reordenamiento en dos casos, correspondientes a cuando el usuario hace clic en el botón Atrás y en el enlace Siguiente en Internet Explorer. En ambos casos, el modelo de usuario actualizado se utilizaría para reordenar los resultados no vistos de manera que el usuario vea resultados de búsqueda mejorados de inmediato. Para volver a clasificar cualquier resumen de documento no visto, UCAIR utiliza el modelo estándar de recuperación de espacio vectorial y puntúa cada resumen en función de la similitud del resultado y el vector de necesidad de información actual del usuario x [21]. Dado que la retroalimentación implícita no es completamente confiable, presentamos solo un pequeño número (por ejemplo, 5) de los resultados reordenados más altos para ser seguidos por cualquier resultado originalmente clasificado alto. 828 resultados de Google (consulta del usuario = mapa de Java) Resultados de UCAIR (consulta del usuario = mapa de Java) consulta anterior = viajar a Indonesia consulta anterior = tabla hash consulta del usuario ampliada = mapa de Java Indonesia consulta del usuario ampliada = clase de mapa de Java 1 Proyecciones de mapas de Java del mundo ... Lonely Planet - Mapa de Indonesia Mapa (Plataforma Java SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Proyecciones de mapas de Java del mundo ... TURISMO DE INDONESIA: JAVA CENTRAL - MAPA Plataforma Java SE v1.3.1: Interfaz de Mapa www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Mapa de Java TURISMO DE INDONESIA: JAVA OESTE - MAPA Una introducción a las clases de colección de mapas de Java java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Mapa de Tecnología Java IndoStreets - Mapa de Java Una introducción a las clases de colección de mapas de Java java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Regiones e islas de Indonesia Mapas, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 Una introducción a las clases de colección de mapas de Java Mapa de calles de la ciudad de Indonesia,... Hibernate simplifica el mapeo de herencia www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Mapa de Java Mapas de Indonesia jerarquía de clases de tmap 30.map www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Mapa de API de Java Mapas de Indonesia por Peter Loud Alcance de clases www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas: Mapas de Sam de Indonesia por Peter Loud PrintSafeHashMap de la clase www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 TURISMO DE INDONESIA: JAVA OESTE - MAPA indonesiaphoto.com Java Pro - Unión y mapeo vertical de clases www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Tabla 1: Resultados de muestra de la expansión de la consulta EVALUACIÓN DE UCAIR Ahora presentamos algunos resultados sobre la evaluación de las dos principales funciones de UCAIR: la expansión selectiva de consultas y la reordenación de resultados basada en los datos de clics de los usuarios. 5.1 Resultados de muestra La estrategia de expansión de consultas implementada en UCAIR es intencionalmente conservadora para evitar la interpretación errónea de los modelos implícitos de los usuarios. En la práctica, cada vez que decide expandir la consulta, la expansión suele tener sentido. En la Tabla 1, mostramos cómo UCAIR puede distinguir exitosamente dos contextos de búsqueda diferentes para la consulta java map, correspondientes a dos consultas previas distintas (es decir, viajar a Indonesia vs. hashtable). Debido a la modelización implícita del usuario, UCAIR descubre inteligentemente agregar Indonesia y clase, respectivamente, a la consulta de los usuarios sobre el mapa de Java, lo cual de otro modo sería ambiguo, como se muestra en los resultados originales de Google el 21 de marzo de 2005. Los resultados de UCAIR son mucho más precisos que los resultados de Google y reflejan la personalización en la búsqueda. El componente de retroalimentación implícita entusiasta está diseñado para responder inmediatamente a la actividad de un usuario, como por ejemplo, al visualizar un documento. En la Figura 2, mostramos cómo UCAIR puede desambiguar con éxito una consulta ambigua de jaguar al explotar un resumen del documento visualizado. En este caso, los resultados iniciales de recuperación utilizando \"jaguar\" (mostrados en el lado izquierdo) contienen dos resultados sobre los autos Jaguar seguidos por dos resultados sobre el software Jaguar. Sin embargo, después de que el usuario ve el contenido de la página web del segundo resultado (sobre el automóvil Jaguar) y regresa a la página de resultados de búsqueda haciendo clic en el botón Atrás, UCAIR automáticamente selecciona dos nuevos resultados de búsqueda sobre automóviles Jaguar (mostrados en el lado derecho), mientras que los dos resultados originales sobre software de Jaguar se desplazan hacia abajo en la lista (no se ven en la imagen). 5.2 Evaluación cuantitativa Para evaluar UCAIR de manera cuantitativa, realizamos un estudio de usuario sobre la efectividad del componente de retroalimentación implícita ansiosa. Es un desafío evaluar cuantitativamente la mejora potencial en el rendimiento de nuestro modelo propuesto y UCAIR sobre Google de manera imparcial [7]. Aquí diseñamos un estudio de usuarios, en el cual los participantes realizarían una búsqueda web normal y evaluarían al azar y de forma anónima un conjunto de resultados mezclados de Google y UCAIR al final de la sesión de búsqueda; los participantes no saben si un resultado proviene de Google o de UCAIR. Reclutamos a 6 estudiantes de posgrado para este estudio de usuarios, quienes tienen diferentes antecedentes (3 en informática, 2 en biología y 1 en química). Los documentos que describen leyes para limitar el correo no deseado sin dar detalles de demandas judiciales o juicios penales no son relevantes. Utilizamos los temas de consulta de la pista Terabyte TREC 2 2004 [2] y la tarea de destilación de temas de la pista web TREC 2003 [4] de la manera que se describirá a continuación. Un ejemplo de tema del TREC 2004 Terabyte track aparece en la Figura 3. El título es una frase corta y puede ser utilizada como una consulta al sistema de recuperación. El campo de descripción proporciona una declaración ligeramente más larga del requisito del tema, generalmente expresado como una sola oración completa o pregunta. Finalmente, la narrativa proporciona información adicional necesaria para especificar completamente el requisito, expresado en forma de un breve párrafo. Inicialmente, cada participante exploraría 50 temas ya sea de la categoría Terabyte o de la categoría Web y elegiría los 5 o 7 temas más interesantes. Para cada tema seleccionado, el participante básicamente realizaría la búsqueda web normal utilizando UCAIR para encontrar muchas páginas web relevantes utilizando el título del tema de la consulta como la palabra clave inicial de la consulta. Durante este proceso, el participante puede ver los resultados de la búsqueda y posiblemente hacer clic en algunos interesantes para ver las páginas web, tal como en una búsqueda web normal. No hay ningún requisito o restricción sobre cuántas consultas debe enviar el participante o cuándo debe detener la búsqueda de un tema. Cuando el participante planea cambiar el tema de búsqueda, simplemente presionará un botón 2 de la Conferencia de Recuperación de Texto: http://trec.nist.gov/ 829 Figura 2: Capturas de pantalla para volver a clasificar los resultados y evaluar los resultados de búsqueda antes de cambiar al siguiente tema. En el momento de la evaluación, los 30 resultados mejor clasificados de Google y UCAIR (algunos se superponen) se mezclan aleatoriamente para que el participante no sepa si un resultado proviene de Google o de UCAIR. El participante luego juzgaría la relevancia de estos resultados. Medimos la precisión en los primeros n (n = 5, 10, 20, 30) documentos de Google y UCAIR. También evaluamos precisiones en diferentes niveles de recuperación. En total, 368 documentos fueron considerados relevantes a partir de los resultados de búsqueda de Google y 429 documentos fueron considerados relevantes por los participantes de UCAIR. Los diagramas de dispersión de precisión en los 10 y 20 documentos principales se muestran en la Figura 4 y la Figura 5 respectivamente (El diagrama de dispersión de precisión en los 30 documentos principales es muy similar al de los 20 documentos principales). Cada punto de los gráficos de dispersión representa las precisiones de Google y UCAIR en un tema de consulta. La Tabla 2 muestra la precisión promedio en los primeros n documentos entre 32 temas. A partir de la Figura 4, la Figura 5 y la Tabla 2, vemos que los resultados de búsqueda de UCAIR son consistentemente mejores que los de Google en todas las medidas. Además, la mejora en el rendimiento es más dramática para la precisión en los primeros 20 documentos que para la precisión en los primeros 10 documentos. Una explicación para esto es que cuanto más interacción tenga el usuario con el sistema, más datos de clics se espera que UCAIR pueda recopilar. Por lo tanto, el sistema de recuperación puede construir modelos de usuario implícitos más precisos, lo que conduce a una mayor precisión en la recuperación. El Método de Clasificación prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Mejora 8.0% 17.8% 20.2% 21.8% Tabla 2: Tabla de precisión promedio en los primeros n documentos para 32 temas de consulta El gráfico en la Figura 6 muestra las curvas de precisión-recuperación para UCAIR y Google, donde se observa claramente que el rendimiento de UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Gráfico de dispersión de Precisión en los 10 primeros documentos Figura 4: La precisión en los 10 primeros documentos de UCAIR y Google es consistentemente y considerablemente mejor que la de Google en todos los niveles de recuperación. 6. CONCLUSIONES En este artículo, estudiamos cómo aprovechar la modelización implícita del usuario para personalizar de manera inteligente la recuperación de información y mejorar la precisión de la búsqueda. A diferencia de la mayoría de trabajos anteriores, enfatizamos el uso del contexto de búsqueda inmediata y la información de retroalimentación implícita, así como la actualización rápida de los resultados de búsqueda para beneficiar al máximo a un usuario. Presentamos un marco de trabajo de toma de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos adecuados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para volver a clasificar inmediatamente cualquier documento que aún no haya sido visto por el usuario. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente (UCAIR) sobre un motor de búsqueda popular (Google). Los experimentos en la búsqueda web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en más de un 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Gráfico de dispersión de Precisión en los 20 documentos principales Figura 5: Precisión en los 20 documentos principales de UCAIR y Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 precisión recall Curvas de Precisión-Recall Resultado de Google Resultado de UCAIR Figura 6: Precisión en los 20 resultados principales de UCAIR y Google Google. Dado que la información implícita que aprovechamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional. El agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin necesidad de esfuerzo adicional por parte del usuario. AGRADECIMIENTO Agradecemos a los seis participantes de nuestros experimentos de evaluación. Este trabajo fue apoyado en parte por las subvenciones de la Fundación Nacional de Ciencias IIS-0347933 e IIS-0428472. REFERENCIAS [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman y O. Frieder. Análisis por hora de un registro de consultas web muy grande categorizado por tema. En Actas de SIGIR 2004, páginas 321-328, 2004. [2] C. Clarke, N. Craswell e I. Soboroff. Resumen de la pista de terabyte TREC 2004. En Actas de TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda y D. Brown. Indicadores implícitos de interés. En Actas de Interfaces de Usuario Inteligentes 2001, páginas 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson y M. Wu. Resumen de la pista web TREC 2003. En Actas de TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend y V. Larvrenko. Retroalimentación de relevancia y personalización: Una perspectiva de modelado del lenguaje. En Actas del Segundo Taller DELOS: Personalización y Sistemas de Recomendación en Bibliotecas Digitales, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite y D. Harman. Resultados y desafíos en la evaluación de búsqueda en la web. Redes de Computadoras, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A. An, y D. Schuurmans. Identificación dinámica de sesiones de registro web con modelos de lenguaje estadístico. Revista de la Sociedad Americana de Ciencia de la Información y Tecnología, 55(14):1290-1303, 2004. [9] G. Jeh y J. Widom. Escalando la búsqueda web personalizada. En Actas de WWW 2003, páginas 271-279, 2003. [10] T. Joachims. Optimización de motores de búsqueda utilizando datos de clics. En Actas de SIGKDD 2002, páginas 133-142, 2002. [11] D. Kelly y J. Teevan. Retroalimentación implícita para inferir preferencias de usuario: Una bibliografía. SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En Actas de SIGIR01, páginas 111-119, 2001. [13] T. Lau y E. Horvitz. Patrones de búsqueda: Análisis y modelado de la refinación de consultas web. En Actas de la Séptima Conferencia Internacional sobre Modelado de Usuarios (UM), páginas 145-152, 1999. [14] V. Lavrenko y B. Croft. Modelos de lenguaje basados en relevancia. En Actas de SIGIR01, páginas 120-127, 2001. [15] M. Mitra, A. Singhal y C. Buckley. Mejorando la expansión automática de consultas. En Actas de SIGIR 1998, páginas 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg. Según Google, así va la nación. New York Times, mayo de 2003. [18] S. E. Robertson. El principio de clasificación de probabilidad en ı˚. Revista de Documentación, 33(4):294-304, 1977. [19] J. J. Rocchio. Retroalimentación de relevancia en la recuperación de información. En el Sistema de Recuperación SMART: Experimentos en el Procesamiento Automático de Documentos, páginas 313-323. Prentice-Hall Inc., 1971. [20] G. Salton y C. Buckley. Mejorando el rendimiento de recuperación mediante retroalimentación de recuperación. Revista de la Sociedad Americana de Ciencia de la Información, 41(4):288-297, 1990. [21] G. Salton y M. J. McGill. Introducción a la Recuperación de Información Moderna. McGraw-Hill, 1983. [22] X. Shen, B. Tan y C. Zhai. Recuperación de información sensible al contexto utilizando retroalimentación implícita. En Actas de SIGIR 2005, páginas 43-50, 2005. [23] X. Shen y C. Zhai. Explotando el historial de consultas para la clasificación de documentos en la recuperación de información interactiva (Póster). En Actas de SIGIR 2003, páginas 377-378, 2003. [24] A. Singhal. Recuperación de información moderna: Una breve visión general. Boletín del Comité Técnico de Ingeniería de Datos de la Sociedad de Computación de IEEE, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano y M. Yoshikawa. Búsqueda web adaptativa basada en el perfil del usuario construido sin ningún esfuerzo por parte de los usuarios. En Actas de WWW 2004, páginas 675-684, 2004. [26] E. Volokh. Personalización y privacidad. Comunicaciones de la ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen e I. Ruthven. Un estudio simulado de modelos de retroalimentación implícita. En Actas de ECIR 2004, páginas 311-326, 2004. [28] J. Xu y W. B. Croft. Expansión de consultas utilizando análisis local y global de documentos. En Actas de SIGIR 1996, páginas 4-11, 1996. [29] C. Zhai y J. Lafferty. Modelo de retroalimentación basado en el modelo de recuperación de divergencia de KL. En Actas de la CIKM 2001, páginas 403-410, 2001. 831 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "user model": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Implicit User Modeling for Personalized Search Xuehua Shen, Bin Tan, ChengXiang Zhai Department of Computer Science University of Illinois at Urbana-Champaign ABSTRACT Information retrieval systems (e.g., web search engines) are critical for overcoming information overload.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users, resulting in inherently non-optimal retrieval performance.",
                "For example, a tourist and a programmer may use the same word java to search for different information, but the current search systems would return the same results.",
                "In this paper, we study how to infer a users interest from the users search context and use the inferred implicit <br>user model</br> for personalized search .",
                "We present a decision theoretic framework and develop techniques for implicit user modeling in information retrieval.",
                "We develop an intelligent client-side web search agent (UCAIR) that can perform eager implicit feedback, e.g., query expansion based on previous queries and immediate result reranking based on clickthrough information.",
                "Experiments on web search show that our search agent can improve search accuracy over the popular Google search engine.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models, Relevance feedback, Search Process General Terms Algorithms 1.",
                "INTRODUCTION Although many information retrieval systems (e.g., web search engines and digital library systems) have been successfully deployed, the current retrieval systems are far from optimal.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users [17].",
                "This inherent non-optimality is seen clearly in the following two cases: (1) Different users may use exactly the same query (e.g., Java) to search for different information (e.g., the Java island in Indonesia or the Java programming language), but existing IR systems return the same results for these users.",
                "Without considering the actual user, it is impossible to know which sense Java refers to in a query. (2) A users information needs may change over time.",
                "The same user may use Java sometimes to mean the Java island in Indonesia and some other times to mean the programming language.",
                "Without recognizing the search context, it would be again impossible to recognize the correct sense.",
                "In order to optimize retrieval accuracy, we clearly need to model the user appropriately and personalize search according to each individual user.",
                "The major goal of user modeling for information retrieval is to accurately model a users information need, which is, unfortunately, a very difficult task.",
                "Indeed, it is even hard for a user to precisely describe what his/her information need is.",
                "What information is available for a system to infer a users information need?",
                "Obviously, the users query provides the most direct evidence.",
                "Indeed, most existing retrieval systems rely solely on the query to model a users information need.",
                "However, since a query is often extremely short, the <br>user model</br> constructed based on a keyword query is inevitably impoverished .",
                "An effective way to improve user modeling in information retrieval is to ask the user to explicitly specify which documents are relevant (i.e., useful for satisfying his/her information need), and then to improve user modeling based on such examples of relevant documents.",
                "This is called relevance feedback, which has been proved to be quite effective for improving retrieval accuracy [19, 20].",
                "Unfortunately, in real world applications, users are usually reluctant to make the extra effort to provide relevant examples for feedback [11].",
                "It is thus very interesting to study how to infer a users information need based on any implicit feedback information, which naturally exists through user interactions and thus does not require any extra user effort.",
                "Indeed, several previous studies have shown that implicit user modeling can improve retrieval accuracy.",
                "In [3], a web browser (Curious Browser) is developed to record a users explicit relevance ratings of web pages (relevance feedback) and browsing behavior when viewing a page, such as dwelling time, mouse click, mouse movement and scrolling (implicit feedback).",
                "It is shown that the dwelling time on a page, amount of scrolling on a page and the combination of time and scrolling have a strong correlation with explicit relevance ratings, which suggests that implicit feedback may be helpful for inferring user information need.",
                "In [10], user clickthrough data is collected as training data to learn a retrieval function, which is used to produce a customized ranking of search results that suits a group of users preferences.",
                "In [25], the clickthrough data collected over a long time period is exploited through query expansion to improve retrieval accuracy. 824 While a user may have general long term interests and preferences for information, often he/she is searching for documents to satisfy an ad-hoc information need, which only lasts for a short period of time; once the information need is satisfied, the user would generally no longer be interested in such information.",
                "For example, a user may be looking for information about used cars in order to buy one, but once the user has bought a car, he/she is generally no longer interested in such information.",
                "In such cases, implicit feedback information collected over a long period of time is unlikely to be very useful, but the immediate search context and feedback information, such as which of the search results for the current information need are viewed, can be expected to be much more useful.",
                "Consider the query Java again.",
                "Any of the following immediate feedback information about the user could potentially help determine the intended meaning of Java in the query: (1) The previous query submitted by the user is hashtable (as opposed to, e.g., travel Indonesia). (2) In the search results, the user viewed a page where words such as programming, software, and applet occur many times.",
                "To the best of our knowledge, how to exploit such immediate and short-term search context to improve search has so far not been well addressed in the previous work.",
                "In this paper, we study how to construct and update a <br>user model</br> based on the immediate search context and implicit feedback information and use the model to improve the accuracy of ad-hoc retrieval.",
                "In order to maximally benefit the user of a retrieval system through implicit user modeling, we propose to perform eager implicit feedback.",
                "That is, as soon as we observe any new piece of evidence from the user, we would update the systems belief about the users information need and respond with improved retrieval results based on the updated <br>user model</br>.",
                "We present a decision-theoretic framework for optimizing interactive information retrieval based on eager <br>user model</br> updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "In a traditional retrieval paradigm, the retrieval problem is to match a query with documents and rank documents according to their relevance values.",
                "As a result, the retrieval process is a simple independent cycle of query and result display.",
                "In the proposed new retrieval paradigm, the users search context plays an important role and the inferred implicit <br>user model</br> is exploited immediately to benefit the user.",
                "The new retrieval paradigm is thus fundamentally different from the traditional paradigm, and is inherently more general.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent UCAIR (User-Centered Adaptive Information Retrieval) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "Thus the developed search agent can improve existing web search performance without additional effort from the user.",
                "The remaining sections are organized as follows.",
                "In Section 2, we discuss the related work.",
                "In Section 3, we present a decisiontheoretic interactive retrieval framework for implicit user modeling.",
                "In Section 4, we present the design and implementation of an intelligent client-side web search agent (UCAIR) that performs eager implicit feedback.",
                "In Section 5, we report our experiment results using the search agent.",
                "Section 6 concludes our work. 2.",
                "RELATED WORK Implicit user modeling for personalized search has been studied in previous work, but our work differs from all previous work in several aspects: (1) We emphasize the exploitation of immediate search context such as the related immediately preceding query and the viewed documents in the same session, while most previous work relies on long-term collection of implicit feedback information [25]. (2) We perform eager feedback and bring the benefit of implicit user modeling as soon as any new implicit feedback information is available, while the previous work mostly exploits longterm implicit feedback [10]. (3) We propose a retrieval framework to integrate implicit user modeling with the interactive retrieval process, while the previous work either studies implicit user modeling separately from retrieval [3] or only studies specific retrieval models for exploiting implicit feedback to better match a query with documents [23, 27, 22]. (4) We develop and evaluate a personalized Web search agent with online user studies, while most existing work evaluates algorithms offline without real user interactions.",
                "Currently some search engines provide rudimentary personalization, such as Google Personalized web search [6], which allows users to explicitly describe their interests by selecting from predefined topics, so that those results that match their interests are brought to the top, and My Yahoo! search [16], which gives users the option to save web sites they like and block those they dislike.",
                "In contrast, UCAIR personalizes web search through implicit user modeling without any additional user efforts.",
                "Furthermore, the personalization of UCAIR is provided on the client side.",
                "There are two remarkable advantages on this.",
                "First, the user does not need to worry about the privacy infringement, which is a big concern for personalized search [26].",
                "Second, both the computation of personalization and the storage of the user profile are done at the client side so that the server load is reduced dramatically [9].",
                "There have been many works studying user query logs [1] or query dynamics [13].",
                "UCAIR makes direct use of a users query history to benefit the same user immediately in the same search session.",
                "UCAIR first judges whether two neighboring queries belong to the same information session and if so, it selects terms from the previous query to perform query expansion.",
                "Our query expansion approach is similar to automatic query expansion [28, 15, 5], but instead of using pseudo feedback to expand the query, we use users implicit feedback information to expand the current query.",
                "These two techniques may be combined. 3.",
                "OPTIMIZATION IN INTERACTIVE IR In interactive IR, a user interacts with the retrieval system through an action dialogue, in which the system responds to each user action with some system action.",
                "For example, the users action may be submitting a query and the systems response may be returning a list of 10 document summaries.",
                "In general, the space of user actions and system responses and their granularities would depend on the interface of a particular retrieval system.",
                "In principle, every action of the user can potentially provide new evidence to help the system better infer the users information need.",
                "Thus in order to respond optimally, the system should use all the evidence collected so far about the user when choosing a response.",
                "When viewed in this way, most existing search engines are clearly non-optimal.",
                "For example, if a user has viewed some documents on the first page of search results, when the user clicks on the Next link to fetch more results, an existing retrieval system would still return the next page of results retrieved based on the original query without considering the new evidence that a particular result has been viewed by the user. 825 We propose to optimize retrieval performance by adapting system responses based on every action that a user has taken, and cast the optimization problem as a decision task.",
                "Specifically, at any time, the system would attempt to do two tasks: (1) <br>user model</br> updating: Monitor any useful evidence from the user regarding his/her information need and update the <br>user model</br> as soon as such evidence is available; (2) Improving search results: Rerank immediately all the documents that the user has not yet seen, as soon as the user model is updated.",
                "We emphasize eager updating and reranking, which makes our work quite different from any existing work.",
                "Below we present a formal decision theoretic framework for optimizing retrieval performance through implicit user modeling in interactive information retrieval. 3.1 A decision-theoretic framework Let A be the set of all user actions and R(a) be the set of all possible system responses to a user action a ∈ A.",
                "At any time, let At = (a1, ..., at) be the observed sequence of user actions so far (up to time point t) and Rt−1 = (r1, ..., rt−1) be the responses that the system has made responding to the user actions.",
                "The systems goal is to choose an optimal response rt ∈ R(at) for the current user action at.",
                "Let M be the space of all possible user models.",
                "We further define a loss function L(a, r, m) ∈ , where a ∈ A is a user action, r ∈ R(a) is a system response, and m ∈ M is a <br>user model</br>.",
                "L(a, r, m) encodes our decision preferences and assesses the optimality of responding with r when the current <br>user model</br> is m and the current user action is a.",
                "According to Bayesian decision theory, the optimal decision at time t is to choose a response that minimizes the Bayes risk, i.e., r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) where P(mt|U, D, At, Rt−1) is the posterior probability of the <br>user model</br> mt given all the observations about the user U we have made up to time t. To simplify the computation of Equation 1, let us assume that the posterior probability mass P(mt|U, D, At, Rt−1) is mostly concentrated on the mode m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "We can then approximate the integral with the value of the loss function at m∗ t .",
                "That is, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) where m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "Leaving aside how to define and estimate these probabilistic models and the loss function, we can see that such a decision-theoretic formulation suggests that, in order to choose the optimal response to at, the system should perform two tasks: (1) compute the current <br>user model</br> and obtain m∗ t based on all the useful information. (2) choose a response rt to minimize the loss function value L(at, rt, m∗ t ).",
                "When at does not affect our belief about m∗ t , the first step can be omitted and we may reuse m∗ t−1 for m∗ t .",
                "Note that our framework is quite general since we can potentially model any kind of user actions and system responses.",
                "In most cases, as we may expect, the systems response is some ranking of documents, i.e., for most actions a, R(a) consists of all the possible rankings of the unseen documents, and the decision problem boils down to choosing the best ranking of unseen documents based on the most current <br>user model</br>.",
                "When a is the action of submitting a keyword query, such a response is exactly what a current retrieval system would do.",
                "However, we can easily imagine that a more intelligent web search engine would respond to a users clicking of the Next link (to fetch more unseen results) with a more optimized ranking of documents based on any viewed documents in the current page of results.",
                "In fact, according to our eager updating strategy, we may even allow a system to respond to a users clicking of browsers Back button after viewing a document in the same way, so that the user can maximally benefit from implicit feedback.",
                "These are precisely what our UCAIR system does. 3.2 User models A <br>user model</br> m ∈ M represents what we know about the user U, so in principle, it can contain any information about the user that we wish to model.",
                "We now discuss two important components in a <br>user model</br>.",
                "The first component is a component model of the users information need.",
                "Presumably, the most important factor affecting the optimality of the systems response is how well the response addresses the users information need.",
                "Indeed, at any time, we may assume that the system has some belief about what the user is interested in, which we model through a term vector x = (x1, ..., x|V |), where V = {w1, ..., w|V |} is the set of all terms (i.e., vocabulary) and xi is the weight of term wi.",
                "Such a term vector is commonly used in information retrieval to represent both queries and documents.",
                "For example, the vector-space model, assumes that both the query and the documents are represented as term vectors and the score of a document with respect to a query is computed based on the similarity between the query vector and the document vector [21].",
                "In a language modeling approach, we may also regard the query unigram language model [12, 29] or the relevance model [14] as a term vector representation of the users information need.",
                "Intuitively, x would assign high weights to terms that characterize the topics which the user is interested in.",
                "The second component we may include in our <br>user model</br> is the documents that the user has already viewed.",
                "Obviously, even if a document is relevant, if the user has already seen the document, it would not be useful to present the same document again.",
                "We thus introduce another variable S ⊂ D (D is the whole set of documents in the collection) to denote the subset of documents in the search results that the user has already seen/viewed.",
                "In general, at time t, we may represent a <br>user model</br> as mt = (S, x, At, Rt−1), where S is the seen documents, x is the systems understanding of the users information need, and (At, Rt−1) represents the users interaction history.",
                "Note that an even more general <br>user model</br> may also include other factors such as the users reading level and occupation.",
                "If we assume that the uncertainty of a <br>user model</br> mt is solely due to the uncertainty of x, the computation of our current estimate of <br>user model</br> m∗ t will mainly involve computing our best estimate of x.",
                "That is, the system would choose a response according to r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) where x∗ = argmaxx P(x|U, D, At, Rt−1).",
                "This is the decision mechanism implemented in the UCAIR system to be described later.",
                "In this system, we avoided specifying the probabilistic model P(x|U, D, At, Rt−1) by computing x∗ directly with some existing feedback method. 3.3 Loss functions The exact definition of loss function L depends on the responses, thus it is inevitably application-specific.",
                "We now briefly discuss some possibilities when the response is to rank all the unseen documents and present the top k of them.",
                "Let r = (d1, ..., dk) be the top k documents, S be the set of seen documents by the user, and x∗ be the systems best guess of the users information need.",
                "We 826 may simply define the loss associated with r as the negative sum of the probability that each of the di is relevant, i.e., L(a, r, m) = − k i=1 P(relevant|di, m).",
                "Clearly, in order to minimize this loss function, the optimal response r would contain the k documents with the highest probability of relevance, which is intuitively reasonable.",
                "One deficiency of this top-k loss function is that it is not sensitive to the internal order of the selected top k documents, so switching the ranking order of a non-relevant document and a relevant one would not affect the loss, which is unreasonable.",
                "To model ranking, we can introduce a factor of the <br>user model</br> - the probability of each of the k documents being viewed by the user, P(view|di), and define the following ranking loss function: L(a, r, m) = − k i=1 P(view|di)P(relevant|di, m) Since in general, if di is ranked above dj (i.e., i < j), P(view|di) > P(view|dj), this loss function would favor a decision to rank relevant documents above non-relevant ones, as otherwise, we could always switch di with dj to reduce the loss value.",
                "Thus the system should simply perform a regular retrieval and rank documents according to the probability of relevance [18].",
                "Depending on the users retrieval preferences, there can be many other possibilities.",
                "For example, if the user does not want to see redundant documents, the loss function should include some redundancy measure on r based on the already seen documents S. Of course, when the response is not to choose a ranked list of documents, we would need a different loss function.",
                "We discuss one such example that is relevant to the search agent that we implement.",
                "When a user enters a query qt (current action), our search agent relies on some existing search engine to actually carry out search.",
                "In such a case, even though the search agent does not have control of the retrieval algorithm, it can still attempt to optimize the search results through refining the query sent to the search engine and/or reranking the results obtained from the search engine.",
                "The loss functions for reranking are already discussed above; we now take a look at the loss functions for query refinement.",
                "Let f be the retrieval function of the search engine that our agent uses so that f(q) would give us the search results using query q.",
                "Given that the current action of the user is entering a query qt (i.e., at = qt), our response would be f(q) for some q.",
                "Since we have no choice of f, our decision is to choose a good q.",
                "Formally, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) which shows that our goal is to find q∗ = argminqL(qt, f(q), m), i.e., an optimal query that would give us the best f(q).",
                "A different choice of loss function L(qt, f(q), m) would lead to a different query refinement strategy.",
                "In UCAIR, we heuristically compute q∗ by expanding qt with terms extracted from rt−1 whenever qt−1 and qt have high similarity.",
                "Note that rt−1 and qt−1 are contained in m as part of the users interaction history. 3.4 Implicit user modeling Implicit user modeling is captured in our framework through the computation of x∗ = argmaxx P(x|U, D, At, Rt−1), i.e., the systems current belief of what the users information need is.",
                "Here again there may be many possibilities, leading to different algorithms for implicit user modeling.",
                "We now discuss a few of them.",
                "First, when two consecutive queries are related, the previous query can be exploited to enrich the current query and provide more search context to help disambiguation.",
                "For this purpose, instead of performing query expansion as we did in the previous section, we could also compute an updated x∗ based on the previous query and retrieval results.",
                "The computed new <br>user model</br> can then be used to rank the documents with a standard information retrieval model.",
                "Second, we can also infer a users interest based on the summaries of the viewed documents.",
                "When a user is presented with a list of summaries of top ranked documents, if the user chooses to skip the first n documents and to view the (n+1)-th document, we may infer that the user is not interested in the displayed summaries for the first n documents, but is attracted by the displayed summary of the (n + 1)-th document.",
                "We can thus use these summaries as negative and positive examples to learn a more accurate <br>user model</br> x∗ .",
                "Here many standard relevance feedback techniques can be exploited [19, 20].",
                "Note that we should use the displayed summaries, as opposed to the actual contents of those documents, since it is possible that the displayed summary of the viewed document is relevant, but the document content is actually not.",
                "Similarly, a displayed summary may mislead a user to skip a relevant document.",
                "Inferring user models based on such displayed information, rather than the actual content of a document is an important difference between UCAIR and some other similar systems.",
                "In UCAIR, both of these strategies for inferring an implicit <br>user model</br> are implemented. 4.",
                "UCAIR: A PERSONALIZED SEARCH AGENT 4.1 Design In this section, we present a client-side web search agent called UCAIR, in which we implement some of the methods discussed in the previous section for performing personalized search through implicit user modeling.",
                "UCAIR is a web browser plug-in 1 that acts as a proxy for web search engines.",
                "Currently, it is only implemented for Internet Explorer and Google, but it is a matter of engineering to make it run on other web browsers and interact with other search engines.",
                "The issue of privacy is a primary obstacle for deploying any real world applications involving serious user modeling, such as personalized search.",
                "For this reason, UCAIR is strictly running as a client-side search agent, as opposed to a server-side application.",
                "This way, the captured user information always resides on the computer that the user is using, thus the user does not need to release any information to the outside.",
                "Client-side personalization also allows the system to easily observe a lot of user information that may not be easily available to a server.",
                "Furthermore, performing personalized search on the client-side is more scalable than on the serverside, since the overhead of computation and storage is distributed among clients.",
                "As shown in Figure 1, the UCAIR toolbar has 3 major components: (1) The (implicit) user modeling module captures a users search context and history information, including the submitted queries and any clicked search results and infers search session boundaries. (2) The query modification module selectively improves the query formulation according to the current <br>user model</br>. (3) The result re-ranking module immediately re-ranks any unseen search results whenever the <br>user model</br> is updated.",
                "In UCAIR, we consider four basic user actions: (1) submitting a keyword query; (2) viewing a document; (3) clicking the Back button; (4) clicking the Next link on a result page.",
                "For each of these four actions, the system responds with, respectively, (1) 1 UCAIR is available at: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Search Engine (e.g., Google) Search History Log (e.g.,past queries, clicked results) Query Modification Result Re-Ranking User Modeling Result Buffer UCAIR Userquery results clickthrough… Figure 1: UCAIR architecture generating a ranked list of results by sending a possibly expanded query to a search engine; (2) updating the information need model x; (3) reranking the unseen results on the current result page based on the current model x; and (4) reranking the unseen pages and generating the next page of results based on the current model x.",
                "Behind these responses, there are three basic tasks: (1) Decide whether the previous query is related to the current query and if so expand the current query with useful terms from the previous query or the results of the previous query. (2) Update the information need model x based on a newly clicked document summary. (3) Rerank a set of unseen documents based on the current model x.",
                "Below we describe our algorithms for each of them. 4.2 Session boundary detection and query expansion To effectively exploit previous queries and their corresponding clickthrough information, UCAIR needs to judge whether two adjacent queries belong to the same search session (i.e., detect session boundaries).",
                "Existing work on session boundary detection is mostly in the context of web log analysis (e.g., [8]), and uses statistical information rather than textual features.",
                "Since our clientside agent does not have access to server query logs, we make session boundary decisions based on textual similarity between two queries.",
                "Because related queries do not necessarily share the same words (e.g., java island and travel Indonesia), it is insufficient to use only query text.",
                "Therefore we use the search results of the two queries to help decide whether they are topically related.",
                "For example, for the above queries java island and travel Indonesia, the words java, bali, island, indonesia and travel may occur frequently in both queries search results, yielding a high similarity score.",
                "We only use the titles and summaries of the search results to calculate the similarity since they are available in the retrieved search result page and fetching the full text of every result page would significantly slow down the process.",
                "To compensate for the terseness of titles and summaries, we retrieve more results than a user would normally view for the purpose of detecting session boundaries (typically 50 results).",
                "The similarity between the previous query q and the current query q is computed as follows.",
                "Let {s1, s2, . . . , sn } and {s1, s2, . . . , sn} be the result sets for the two queries.",
                "We use the pivoted normalization TF-IDF weighting formula [24] to compute a term weight vector si for each result si.",
                "We define the average result savg to be the centroid of all the result vectors, i.e., (s1 + s2 + . . . + sn)/n.",
                "The cosine similarity between the two average results is calculated as s avg · savg/ s 2 avg · s2 avg If the similarity value exceeds a predefined threshold, the two queries will be considered to be in the same information session.",
                "If the previous query and the current query are found to belong to the same search session, UCAIR would attempt to expand the current query with terms from the previous query and its search results.",
                "Specifically, for each term in the previous query or the corresponding search results, if its frequency in the results of the current query is greater than a preset threshold (e.g. 5 results out of 50), the term would be added to the current query to form an expanded query.",
                "In this case, UCAIR would send this expanded query rather than the original one to the search engine and return the results corresponding to the expanded query.",
                "Currently, UCAIR only uses the immediate preceding query for query expansion; in principle, we could exploit all related past queries. 4.3 Information need model updating Suppose at time t, we have observed that the user has viewed k documents whose summaries are s1, ..., sk.",
                "We update our <br>user model</br> by computing a new information need vector with a standard feedback method in information retrieval (i.e., Rocchio [19]).",
                "According to the vector space retrieval model, each clicked summary si can be represented by a term weight vector si with each term weighted by a TF-IDF weighting formula [21].",
                "Rocchio computes the centroid vector of all the summaries and interpolates it with the original query vector to obtain an updated term vector.",
                "That is, x = αq + (1 − α) 1 k k i=1 si where q is the query vector, k is the number of summaries the user clicks immediately following the current query and α is a parameter that controls the influence of the clicked summaries on the inferred information need model.",
                "In our experiments, α is set to 0.5.",
                "Note that we update the information need model whenever the user views a document. 4.4 Result reranking In general, we want to rerank all the unseen results as soon as the <br>user model</br> is updated.",
                "Currently, UCAIR implements reranking in two cases, corresponding to the user clicking the Back button and Next link in the Internet Explorer.",
                "In both cases, the current (updated) <br>user model</br> would be used to rerank the unseen results so that the user would see improved search results immediately.",
                "To rerank any unseen document summaries, UCAIR uses the standard vector space retrieval model and scores each summary based on the similarity of the result and the current user information need vector x [21].",
                "Since implicit feedback is not completely reliable, we bring up only a small number (e.g. 5) of highest reranked results to be followed by any originally high ranked results. 828 Google result (user query = java map) UCAIR result (user query =java map) previous query = travel Indonesia previous query = hashtable expanded user query = java map Indonesia expanded user query = java map class 1 Java map projections of the world ... Lonely Planet - Indonesia Map Map (Java 2 Platform SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Java map projections of the world ... INDONESIA TOURISM : CENTRAL JAVA - MAP Java 2 Platform SE v1.3.1: Interface Map www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Java Map INDONESIA TOURISM : WEST JAVA - MAP An Introduction to Java Map Collection Classes java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Java Technology Concept Map IndoStreets - Java Map An Introduction to Java Map Collection Classes java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Indonesia Regions and Islands Maps, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 An Introduction to Java Map Collection Classes Indonesia City Street Map,... Hibernate simplifies inheritance mapping www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Java Map Maps Of Indonesia tmap 30.map Class Hierarchy www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Java API Map Maps of Indonesia by Peter Loud Class Scope www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas : Sam Maps of Indonesia by Peter Loud Class PrintSafeHashMap www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 INDONESIA TOURISM : WEST JAVA - MAP indonesiaphoto.com Java Pro - Union and Vertical Mapping of Classes www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Table 1: Sample results of query expansion 5.",
                "EVALUATION OF UCAIR We now present some results on evaluating the two major UCAIR functions: selective query expansion and result reranking based on user clickthrough data. 5.1 Sample results The query expansion strategy implemented in UCAIR is intentionally conservative to avoid misinterpretation of implicit user models.",
                "In practice, whenever it chooses to expand the query, the expansion usually makes sense.",
                "In Table 1, we show how UCAIR can successfully distinguish two different search contexts for the query java map, corresponding to two different previous queries (i.e., travel Indonesia vs. hashtable).",
                "Due to implicit user modeling, UCAIR intelligently figures out to add Indonesia and class, respectively, to the users query java map, which would otherwise be ambiguous as shown in the original results from Google on March 21, 2005.",
                "UCAIRs results are much more accurate than Googles results and reflect personalization in search.",
                "The eager implicit feedback component is designed to immediately respond to a users activity such as viewing a document.",
                "In Figure 2, we show how UCAIR can successfully disambiguate an ambiguous query jaguar by exploiting a viewed document summary.",
                "In this case, the initial retrieval results using jaguar (shown on the left side) contain two results about the Jaguar cars followed by two results about the Jaguar software.",
                "However, after the user views the web page content of the second result (about Jaguar car) and returns to the search result page by clicking Back button, UCAIR automatically nominates two new search results about Jaguar cars (shown on the right side), while the original two results about Jaguar software are pushed down on the list (unseen from the picture). 5.2 Quantitative evaluation To further evaluate UCAIR quantitatively, we conduct a user study on the effectiveness of the eager implicit feedback component.",
                "It is a challenge to quantitatively evaluate the potential performance improvement of our proposed model and UCAIR over Google in an unbiased way [7].",
                "Here, we design a user study, in which participants would do normal web search and judge a randomly and anonymously mixed set of results from Google and UCAIR at the end of the search session; participants do not know whether a result comes from Google or UCAIR.",
                "We recruited 6 graduate students for this user study, who have different backgrounds (3 computer science, 2 biology, and 1 chem<top> <num> Number: 716 <title> Spammer arrest sue <desc> Description: Have any spammers been arrested or sued for sending unsolicited e-mail? <narr> Narrative: Instances of arrests, prosecutions, convictions, and punishments of spammers, and lawsuits against them are relevant.",
                "Documents which describe laws to limit spam without giving details of lawsuits or criminal trials are not relevant. </top> Figure 3: An example of TREC query topic, expressed in a form which might be given to a human assistant or librarian istry).",
                "We use query topics from TREC 2 2004 Terabyte track [2] and TREC 2003 Web track [4] topic distillation task in the way to be described below.",
                "An example topic from TREC 2004 Terabyte track appears in Figure 3.",
                "The title is a short phrase and may be used as a query to the retrieval system.",
                "The description field provides a slightly longer statement of the topic requirement, usually expressed as a single complete sentence or question.",
                "Finally the narrative supplies additional information necessary to fully specify the requirement, expressed in the form of a short paragraph.",
                "Initially, each participant would browse 50 topics either from Terabyte track or Web track and pick 5 or 7 most interesting topics.",
                "For each picked topic, the participant would essentially do the normal web search using UCAIR to find many relevant web pages by using the title of the query topic as the initial keyword query.",
                "During this process, the participant may view the search results and possibly click on some interesting ones to view the web pages, just as in a normal web search.",
                "There is no requirement or restriction on how many queries the participant must submit or when the participant should stop the search for one topic.",
                "When the participant plans to change the search topic, he/she will simply press a button 2 Text REtrieval Conference: http://trec.nist.gov/ 829 Figure 2: Screen shots for result reranking to evaluate the search results before actually switching to the next topic.",
                "At the time of evaluation, 30 top ranked results from Google and UCAIR (some are overlapping) are randomly mixed together so that the participant would not know whether a result comes from Google or UCAIR.",
                "The participant would then judge the relevance of these results.",
                "We measure precision at top n (n = 5, 10, 20, 30) documents of Google and UCAIR.",
                "We also evaluate precisions at different recall levels.",
                "Altogether, 368 documents judged as relevant from Google search results and 429 documents judged as relevant from UCAIR by participants.",
                "Scatter plots of precision at top 10 and top 20 documents are shown in Figure 4 and Figure 5 respectively (The scatter plot of precision at top 30 documents is very similar to precision at top 20 documents).",
                "Each point of the scatter plots represents the precisions of Google and UCAIR on one query topic.",
                "Table 2 shows the average precision at top n documents among 32 topics.",
                "From Figure 4, Figure 5 and Table 2, we see that the search results from UCAIR are consistently better than those from Google by all the measures.",
                "Moreover, the performance improvement is more dramatic for precision at top 20 documents than that at precision at top 10 documents.",
                "One explanation for this is that the more interaction the user has with the system, the more clickthrough data UCAIR can be expected to collect.",
                "Thus the retrieval system can build more precise implicit user models, which lead to better retrieval accuracy.",
                "Ranking Method prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Improvement 8.0% 17.8% 20.2% 21.8% Table 2: Table of average precision at top n documents for 32 query topics The plot in Figure 6 shows the precision-recall curves for UCAIR and Google, where it is clearly seen that the performance of UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Scatterplot of Precision at Top 10 Documents Figure 4: Precision at top 10 documents of UCAIR and Google is consistently and considerably better than that of Google at all levels of recall. 6.",
                "CONCLUSIONS In this paper, we studied how to exploit implicit user modeling to intelligently personalize information retrieval and improve search accuracy.",
                "Unlike most previous work, we emphasize the use of immediate search context and implicit feedback information as well as eager updating of search results to maximally benefit a user.",
                "We presented a decision-theoretic framework for optimizing interactive information retrieval based on eager <br>user model</br> updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent (UCAIR) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Scatterplot of Precision at Top 20 documents Figure 5: Precision at top 20 documents of UCAIR and Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 recall precision Precision−Recall curves Google Result UCAIR Result Figure 6: Precision at top 20 result of UCAIR and Google Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "The developed search agent thus can improve existing web search performance without any additional effort from the user. 7.",
                "ACKNOWLEDGEMENT We thank the six participants of our evaluation experiments.",
                "This work was supported in part by the National Science Foundation grants IIS-0347933 and IIS-0428472. 8.",
                "REFERENCES [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman, and O. Frieder.",
                "Hourly analysis of a very large topically categorized web query log.",
                "In Proceedings of SIGIR 2004, pages 321-328, 2004. [2] C. Clarke, N. Craswell, and I. Soboroff.",
                "Overview of the TREC 2004 terabyte track.",
                "In Proceedings of TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda, and D. Brown.",
                "Implicit interest indicators.",
                "In Proceedings of Intelligent User Interfaces 2001, pages 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson, and M. Wu.",
                "Overview of the TREC 2003 web track.",
                "In Proceedings of TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend, and V. Larvrenko.",
                "Relevance feedback and personalization: A language modeling perspective.",
                "In Proeedings of Second DELOS Workshop: Personalisation and Recommender Systems in Digital Libraries, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite, and D. Harman.",
                "Results and challenges in web search evaluation.",
                "Computer Networks, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A.",
                "An, and D. Schuurmans.",
                "Dynamic web log session identification with statistical language models.",
                "Journal of the American Society for Information Science and Technology, 55(14):1290-1303, 2004. [9] G. Jeh and J. Widom.",
                "Scaling personalized web search.",
                "In Proceedings of WWW 2003, pages 271-279, 2003. [10] T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of SIGKDD 2002, pages 133-142, 2002. [11] D. Kelly and J. Teevan.",
                "Implicit feedback for inferring user preference: A bibliography.",
                "SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of SIGIR01, pages 111-119, 2001. [13] T. Lau and E. Horvitz.",
                "Patterns of search: Analyzing and modeling web query refinement.",
                "In Proceedings of the Seventh International Conference on User Modeling (UM), pages 145 -152, 1999. [14] V. Lavrenko and B. Croft.",
                "Relevance-based language models.",
                "In Proceedings of SIGIR01, pages 120-127, 2001. [15] M. Mitra, A. Singhal, and C. Buckley.",
                "Improving automatic query expansion.",
                "In Proceedings of SIGIR 1998, pages 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg.",
                "As google goes, so goes the nation.",
                "New York Times, May 2003. [18] S. E. Robertson.",
                "The probability ranking principle in ı˚.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] J. J. Rocchio.",
                "Relevance feedback in information retrieval.",
                "In The SMART Retrieval System: Experiments in Automatic Document Processing, pages 313-323.",
                "Prentice-Hall Inc., 1971. [20] G. Salton and C. Buckley.",
                "Improving retrieval performance by retrieval feedback.",
                "Journal of the American Society for Information Science, 41(4):288-297, 1990. [21] G. Salton and M. J. McGill.",
                "Introduction to Modern Information Retrieval.",
                "McGraw-Hill, 1983. [22] X. Shen, B. Tan, and C. Zhai.",
                "Context-sensitive information retrieval using implicit feedback.",
                "In Proceedings of SIGIR 2005, pages 43-50, 2005. [23] X. Shen and C. Zhai.",
                "Exploiting query history for document ranking in interactive information retrieval (Poster).",
                "In Proceedings of SIGIR 2003, pages 377-378, 2003. [24] A. Singhal.",
                "Modern information retrieval: A brief overview.",
                "Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano, and M. Yoshikawa.",
                "Adaptive web search based on user profile constructed without any effort from users.",
                "In Proceedings of WWW 2004, pages 675-684, 2004. [26] E. Volokh.",
                "Personalization and privacy.",
                "Communications of the ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen, and I. Ruthven.",
                "A simulated study of implicit feedback models.",
                "In Proceedings of ECIR 2004, pages 311-326, 2004. [28] J. Xu and W. B. Croft.",
                "Query expansion using local and global document analysis.",
                "In Proceedings of SIGIR 1996, pages 4-11, 1996. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in KL divergence retrieval model.",
                "In Proceedings of the CIKM 2001, pages 403-410, 2001. 831"
            ],
            "original_annotated_samples": [
                "In this paper, we study how to infer a users interest from the users search context and use the inferred implicit <br>user model</br> for personalized search .",
                "However, since a query is often extremely short, the <br>user model</br> constructed based on a keyword query is inevitably impoverished .",
                "In this paper, we study how to construct and update a <br>user model</br> based on the immediate search context and implicit feedback information and use the model to improve the accuracy of ad-hoc retrieval.",
                "That is, as soon as we observe any new piece of evidence from the user, we would update the systems belief about the users information need and respond with improved retrieval results based on the updated <br>user model</br>.",
                "We present a decision-theoretic framework for optimizing interactive information retrieval based on eager <br>user model</br> updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function."
            ],
            "translated_annotated_samples": [
                "En este artículo, estudiamos cómo inferir el interés de un usuario a partir del contexto de búsqueda del usuario y utilizar el <br>modelo de usuario</br> implícito inferido para la búsqueda personalizada.",
                "Sin embargo, dado que una consulta suele ser extremadamente corta, el <br>modelo de usuario</br> construido basado en una consulta de palabras clave inevitablemente resulta empobrecido.",
                "En este artículo, estudiamos cómo construir y actualizar un <br>modelo de usuario</br> basado en el contexto de búsqueda inmediato y la información de retroalimentación implícita, y utilizar el modelo para mejorar la precisión de la recuperación ad-hoc.",
                "Es decir, tan pronto como observemos cualquier nueva pieza de evidencia del usuario, actualizaríamos la creencia del sistema sobre la necesidad de información del usuario y responderíamos con resultados de recuperación mejorados basados en el <br>modelo de usuario</br> actualizado.",
                "Presentamos un marco de trabajo de teoría de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del <br>modelo del usuario</br>, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad."
            ],
            "translated_text": "Modelado implícito de usuarios para búsqueda personalizada Xuehua Shen, Bin Tan, ChengXiang Zhai Departamento de Ciencias de la Computación Universidad de Illinois en Urbana-Champaign RESUMEN Los sistemas de recuperación de información (por ejemplo, motores de búsqueda web) son críticos para superar la sobrecarga de información. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales, lo que resulta en un rendimiento de recuperación inherentemente no óptimo. Por ejemplo, un turista y un programador pueden usar la misma palabra \"java\" para buscar información diferente, pero los sistemas de búsqueda actuales devolverían los mismos resultados. En este artículo, estudiamos cómo inferir el interés de un usuario a partir del contexto de búsqueda del usuario y utilizar el <br>modelo de usuario</br> implícito inferido para la búsqueda personalizada. Presentamos un marco teórico de toma de decisiones y desarrollamos técnicas para el modelado implícito del usuario en la recuperación de información. Desarrollamos un agente de búsqueda web inteligente del lado del cliente (UCAIR) que puede realizar retroalimentación implícita ansiosa, por ejemplo, expansión de consultas basada en consultas anteriores y reordenamiento inmediato de resultados basado en información de clics. Los experimentos sobre la búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda sobre el popular motor de búsqueda Google. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación, Retroalimentación de relevancia, Proceso de búsqueda Términos Generales Algoritmos 1. Aunque muchos sistemas de recuperación de información (por ejemplo, motores de búsqueda web y sistemas de biblioteca digital) se han implementado con éxito, los sistemas de recuperación actuales están lejos de ser óptimos. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales [17]. Esta no optimalidad inherente se ve claramente en los siguientes dos casos: (1) Diferentes usuarios pueden utilizar exactamente la misma consulta (por ejemplo, Java) para buscar información diferente (por ejemplo, la isla de Java en Indonesia o el lenguaje de programación Java), pero los sistemas de IR existentes devuelven los mismos resultados para estos usuarios. Sin considerar al usuario actual, es imposible saber a qué sentido se refiere Java en una consulta. (2) Las necesidades de información de un usuario pueden cambiar con el tiempo. El mismo usuario puede usar Java a veces para referirse a la isla de Java en Indonesia y otras veces para referirse al lenguaje de programación. Sin reconocer el contexto de búsqueda, sería nuevamente imposible reconocer el sentido correcto. Para optimizar la precisión de la recuperación, claramente necesitamos modelar al usuario de manera adecuada y personalizar la búsqueda según cada usuario individual. El objetivo principal del modelado de usuario para la recuperación de información es modelar con precisión la necesidad de información de un usuario, lo cual, desafortunadamente, es una tarea muy difícil. De hecho, incluso resulta difícil para un usuario describir con precisión cuál es su necesidad de información. ¿Qué información está disponible para que un sistema pueda inferir la necesidad de información de un usuario? Obviamente, la consulta de los usuarios proporciona la evidencia más directa. De hecho, la mayoría de los sistemas de recuperación existentes se basan únicamente en la consulta para modelar la necesidad de información de los usuarios. Sin embargo, dado que una consulta suele ser extremadamente corta, el <br>modelo de usuario</br> construido basado en una consulta de palabras clave inevitablemente resulta empobrecido. Una forma efectiva de mejorar la modelización de usuarios en la recuperación de información es pedir al usuario que especifique explícitamente qué documentos son relevantes (es decir, útiles para satisfacer su necesidad de información) y luego mejorar la modelización de usuarios basándose en ejemplos de documentos relevantes. Esto se llama retroalimentación de relevancia, lo cual ha demostrado ser bastante efectivo para mejorar la precisión de recuperación [19, 20]. Desafortunadamente, en aplicaciones del mundo real, los usuarios suelen ser reacios a hacer el esfuerzo adicional de proporcionar ejemplos relevantes para retroalimentación [11]. Por lo tanto, es muy interesante estudiar cómo inferir la necesidad de información de un usuario basándose en cualquier información de retroalimentación implícita, la cual existe naturalmente a través de las interacciones del usuario y no requiere ningún esfuerzo adicional por parte del usuario. De hecho, varios estudios previos han demostrado que el modelado implícito del usuario puede mejorar la precisión de recuperación. En [3], se desarrolla un navegador web (Curious Browser) para registrar las calificaciones explícitas de relevancia de las páginas web por parte de los usuarios (retroalimentación de relevancia) y el comportamiento de navegación al ver una página, como el tiempo de permanencia, clics de ratón, movimiento del ratón y desplazamiento (retroalimentación implícita). Se muestra que el tiempo de permanencia en una página, la cantidad de desplazamiento en una página y la combinación de tiempo y desplazamiento tienen una fuerte correlación con las calificaciones de relevancia explícita, lo que sugiere que la retroalimentación implícita puede ser útil para inferir la necesidad de información del usuario. En [10], se recopilan datos de clics de usuario como datos de entrenamiento para aprender una función de recuperación, que se utiliza para producir un ranking personalizado de resultados de búsqueda que se adapte a las preferencias de un grupo de usuarios. En [25], los datos de clics recopilados durante un largo período de tiempo se utilizan a través de la expansión de consultas para mejorar la precisión de recuperación. Si bien un usuario puede tener intereses y preferencias generales a largo plazo para la información, a menudo está buscando documentos para satisfacer una necesidad de información ad-hoc, que solo dura un corto período de tiempo; una vez que se satisface la necesidad de información, el usuario generalmente ya no estaría interesado en esa información. Por ejemplo, un usuario puede estar buscando información sobre autos usados para comprar uno, pero una vez que el usuario ha comprado un auto, generalmente ya no está interesado en esa información. En tales casos, la información de retroalimentación implícita recopilada durante un largo período de tiempo es poco probable que sea muy útil, pero el contexto de búsqueda inmediato y la información de retroalimentación, como cuáles de los resultados de búsqueda para la necesidad de información actual son vistos, se espera que sean mucho más útiles. Considera la consulta de Java nuevamente. Cualquiera de la siguiente información de retroalimentación inmediata sobre el usuario podría potencialmente ayudar a determinar el significado previsto de Java en la consulta: (1) La consulta anterior enviada por el usuario es hashtable (en lugar de, por ejemplo, viajar a Indonesia). (2) En los resultados de búsqueda, el usuario visualizó una página donde palabras como programación, software y applet ocurren muchas veces. Hasta donde sabemos, cómo aprovechar este contexto de búsqueda inmediato y a corto plazo para mejorar la búsqueda aún no ha sido abordado de manera satisfactoria en trabajos anteriores. En este artículo, estudiamos cómo construir y actualizar un <br>modelo de usuario</br> basado en el contexto de búsqueda inmediato y la información de retroalimentación implícita, y utilizar el modelo para mejorar la precisión de la recuperación ad-hoc. Para beneficiar al máximo al usuario de un sistema de recuperación a través de modelado implícito del usuario, proponemos realizar retroalimentación implícita entusiasta. Es decir, tan pronto como observemos cualquier nueva pieza de evidencia del usuario, actualizaríamos la creencia del sistema sobre la necesidad de información del usuario y responderíamos con resultados de recuperación mejorados basados en el <br>modelo de usuario</br> actualizado. Presentamos un marco de trabajo de teoría de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del <br>modelo del usuario</br>, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. ",
            "candidates": [],
            "error": [
                [
                    "modelo de usuario",
                    "modelo de usuario",
                    "modelo de usuario",
                    "modelo de usuario",
                    "modelo del usuario"
                ]
            ]
        },
        "interactive retrieval": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Implicit User Modeling for Personalized Search Xuehua Shen, Bin Tan, ChengXiang Zhai Department of Computer Science University of Illinois at Urbana-Champaign ABSTRACT Information retrieval systems (e.g., web search engines) are critical for overcoming information overload.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users, resulting in inherently non-optimal retrieval performance.",
                "For example, a tourist and a programmer may use the same word java to search for different information, but the current search systems would return the same results.",
                "In this paper, we study how to infer a users interest from the users search context and use the inferred implicit user model for personalized search .",
                "We present a decision theoretic framework and develop techniques for implicit user modeling in information retrieval.",
                "We develop an intelligent client-side web search agent (UCAIR) that can perform eager implicit feedback, e.g., query expansion based on previous queries and immediate result reranking based on clickthrough information.",
                "Experiments on web search show that our search agent can improve search accuracy over the popular Google search engine.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models, Relevance feedback, Search Process General Terms Algorithms 1.",
                "INTRODUCTION Although many information retrieval systems (e.g., web search engines and digital library systems) have been successfully deployed, the current retrieval systems are far from optimal.",
                "A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users [17].",
                "This inherent non-optimality is seen clearly in the following two cases: (1) Different users may use exactly the same query (e.g., Java) to search for different information (e.g., the Java island in Indonesia or the Java programming language), but existing IR systems return the same results for these users.",
                "Without considering the actual user, it is impossible to know which sense Java refers to in a query. (2) A users information needs may change over time.",
                "The same user may use Java sometimes to mean the Java island in Indonesia and some other times to mean the programming language.",
                "Without recognizing the search context, it would be again impossible to recognize the correct sense.",
                "In order to optimize retrieval accuracy, we clearly need to model the user appropriately and personalize search according to each individual user.",
                "The major goal of user modeling for information retrieval is to accurately model a users information need, which is, unfortunately, a very difficult task.",
                "Indeed, it is even hard for a user to precisely describe what his/her information need is.",
                "What information is available for a system to infer a users information need?",
                "Obviously, the users query provides the most direct evidence.",
                "Indeed, most existing retrieval systems rely solely on the query to model a users information need.",
                "However, since a query is often extremely short, the user model constructed based on a keyword query is inevitably impoverished .",
                "An effective way to improve user modeling in information retrieval is to ask the user to explicitly specify which documents are relevant (i.e., useful for satisfying his/her information need), and then to improve user modeling based on such examples of relevant documents.",
                "This is called relevance feedback, which has been proved to be quite effective for improving retrieval accuracy [19, 20].",
                "Unfortunately, in real world applications, users are usually reluctant to make the extra effort to provide relevant examples for feedback [11].",
                "It is thus very interesting to study how to infer a users information need based on any implicit feedback information, which naturally exists through user interactions and thus does not require any extra user effort.",
                "Indeed, several previous studies have shown that implicit user modeling can improve retrieval accuracy.",
                "In [3], a web browser (Curious Browser) is developed to record a users explicit relevance ratings of web pages (relevance feedback) and browsing behavior when viewing a page, such as dwelling time, mouse click, mouse movement and scrolling (implicit feedback).",
                "It is shown that the dwelling time on a page, amount of scrolling on a page and the combination of time and scrolling have a strong correlation with explicit relevance ratings, which suggests that implicit feedback may be helpful for inferring user information need.",
                "In [10], user clickthrough data is collected as training data to learn a retrieval function, which is used to produce a customized ranking of search results that suits a group of users preferences.",
                "In [25], the clickthrough data collected over a long time period is exploited through query expansion to improve retrieval accuracy. 824 While a user may have general long term interests and preferences for information, often he/she is searching for documents to satisfy an ad-hoc information need, which only lasts for a short period of time; once the information need is satisfied, the user would generally no longer be interested in such information.",
                "For example, a user may be looking for information about used cars in order to buy one, but once the user has bought a car, he/she is generally no longer interested in such information.",
                "In such cases, implicit feedback information collected over a long period of time is unlikely to be very useful, but the immediate search context and feedback information, such as which of the search results for the current information need are viewed, can be expected to be much more useful.",
                "Consider the query Java again.",
                "Any of the following immediate feedback information about the user could potentially help determine the intended meaning of Java in the query: (1) The previous query submitted by the user is hashtable (as opposed to, e.g., travel Indonesia). (2) In the search results, the user viewed a page where words such as programming, software, and applet occur many times.",
                "To the best of our knowledge, how to exploit such immediate and short-term search context to improve search has so far not been well addressed in the previous work.",
                "In this paper, we study how to construct and update a user model based on the immediate search context and implicit feedback information and use the model to improve the accuracy of ad-hoc retrieval.",
                "In order to maximally benefit the user of a retrieval system through implicit user modeling, we propose to perform eager implicit feedback.",
                "That is, as soon as we observe any new piece of evidence from the user, we would update the systems belief about the users information need and respond with improved retrieval results based on the updated user model.",
                "We present a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "In a traditional retrieval paradigm, the retrieval problem is to match a query with documents and rank documents according to their relevance values.",
                "As a result, the retrieval process is a simple independent cycle of query and result display.",
                "In the proposed new retrieval paradigm, the users search context plays an important role and the inferred implicit user model is exploited immediately to benefit the user.",
                "The new retrieval paradigm is thus fundamentally different from the traditional paradigm, and is inherently more general.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent UCAIR (User-Centered Adaptive Information Retrieval) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "Thus the developed search agent can improve existing web search performance without additional effort from the user.",
                "The remaining sections are organized as follows.",
                "In Section 2, we discuss the related work.",
                "In Section 3, we present a decisiontheoretic <br>interactive retrieval</br> framework for implicit user modeling.",
                "In Section 4, we present the design and implementation of an intelligent client-side web search agent (UCAIR) that performs eager implicit feedback.",
                "In Section 5, we report our experiment results using the search agent.",
                "Section 6 concludes our work. 2.",
                "RELATED WORK Implicit user modeling for personalized search has been studied in previous work, but our work differs from all previous work in several aspects: (1) We emphasize the exploitation of immediate search context such as the related immediately preceding query and the viewed documents in the same session, while most previous work relies on long-term collection of implicit feedback information [25]. (2) We perform eager feedback and bring the benefit of implicit user modeling as soon as any new implicit feedback information is available, while the previous work mostly exploits longterm implicit feedback [10]. (3) We propose a retrieval framework to integrate implicit user modeling with the <br>interactive retrieval</br> process, while the previous work either studies implicit user modeling separately from retrieval [3] or only studies specific retrieval models for exploiting implicit feedback to better match a query with documents [23, 27, 22]. (4) We develop and evaluate a personalized Web search agent with online user studies, while most existing work evaluates algorithms offline without real user interactions.",
                "Currently some search engines provide rudimentary personalization, such as Google Personalized web search [6], which allows users to explicitly describe their interests by selecting from predefined topics, so that those results that match their interests are brought to the top, and My Yahoo! search [16], which gives users the option to save web sites they like and block those they dislike.",
                "In contrast, UCAIR personalizes web search through implicit user modeling without any additional user efforts.",
                "Furthermore, the personalization of UCAIR is provided on the client side.",
                "There are two remarkable advantages on this.",
                "First, the user does not need to worry about the privacy infringement, which is a big concern for personalized search [26].",
                "Second, both the computation of personalization and the storage of the user profile are done at the client side so that the server load is reduced dramatically [9].",
                "There have been many works studying user query logs [1] or query dynamics [13].",
                "UCAIR makes direct use of a users query history to benefit the same user immediately in the same search session.",
                "UCAIR first judges whether two neighboring queries belong to the same information session and if so, it selects terms from the previous query to perform query expansion.",
                "Our query expansion approach is similar to automatic query expansion [28, 15, 5], but instead of using pseudo feedback to expand the query, we use users implicit feedback information to expand the current query.",
                "These two techniques may be combined. 3.",
                "OPTIMIZATION IN INTERACTIVE IR In interactive IR, a user interacts with the retrieval system through an action dialogue, in which the system responds to each user action with some system action.",
                "For example, the users action may be submitting a query and the systems response may be returning a list of 10 document summaries.",
                "In general, the space of user actions and system responses and their granularities would depend on the interface of a particular retrieval system.",
                "In principle, every action of the user can potentially provide new evidence to help the system better infer the users information need.",
                "Thus in order to respond optimally, the system should use all the evidence collected so far about the user when choosing a response.",
                "When viewed in this way, most existing search engines are clearly non-optimal.",
                "For example, if a user has viewed some documents on the first page of search results, when the user clicks on the Next link to fetch more results, an existing retrieval system would still return the next page of results retrieved based on the original query without considering the new evidence that a particular result has been viewed by the user. 825 We propose to optimize retrieval performance by adapting system responses based on every action that a user has taken, and cast the optimization problem as a decision task.",
                "Specifically, at any time, the system would attempt to do two tasks: (1) User model updating: Monitor any useful evidence from the user regarding his/her information need and update the user model as soon as such evidence is available; (2) Improving search results: Rerank immediately all the documents that the user has not yet seen, as soon as the user model is updated.",
                "We emphasize eager updating and reranking, which makes our work quite different from any existing work.",
                "Below we present a formal decision theoretic framework for optimizing retrieval performance through implicit user modeling in interactive information retrieval. 3.1 A decision-theoretic framework Let A be the set of all user actions and R(a) be the set of all possible system responses to a user action a ∈ A.",
                "At any time, let At = (a1, ..., at) be the observed sequence of user actions so far (up to time point t) and Rt−1 = (r1, ..., rt−1) be the responses that the system has made responding to the user actions.",
                "The systems goal is to choose an optimal response rt ∈ R(at) for the current user action at.",
                "Let M be the space of all possible user models.",
                "We further define a loss function L(a, r, m) ∈ , where a ∈ A is a user action, r ∈ R(a) is a system response, and m ∈ M is a user model.",
                "L(a, r, m) encodes our decision preferences and assesses the optimality of responding with r when the current user model is m and the current user action is a.",
                "According to Bayesian decision theory, the optimal decision at time t is to choose a response that minimizes the Bayes risk, i.e., r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) where P(mt|U, D, At, Rt−1) is the posterior probability of the user model mt given all the observations about the user U we have made up to time t. To simplify the computation of Equation 1, let us assume that the posterior probability mass P(mt|U, D, At, Rt−1) is mostly concentrated on the mode m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "We can then approximate the integral with the value of the loss function at m∗ t .",
                "That is, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) where m∗ t = argmaxmt P(mt|U, D, At, Rt−1).",
                "Leaving aside how to define and estimate these probabilistic models and the loss function, we can see that such a decision-theoretic formulation suggests that, in order to choose the optimal response to at, the system should perform two tasks: (1) compute the current user model and obtain m∗ t based on all the useful information. (2) choose a response rt to minimize the loss function value L(at, rt, m∗ t ).",
                "When at does not affect our belief about m∗ t , the first step can be omitted and we may reuse m∗ t−1 for m∗ t .",
                "Note that our framework is quite general since we can potentially model any kind of user actions and system responses.",
                "In most cases, as we may expect, the systems response is some ranking of documents, i.e., for most actions a, R(a) consists of all the possible rankings of the unseen documents, and the decision problem boils down to choosing the best ranking of unseen documents based on the most current user model.",
                "When a is the action of submitting a keyword query, such a response is exactly what a current retrieval system would do.",
                "However, we can easily imagine that a more intelligent web search engine would respond to a users clicking of the Next link (to fetch more unseen results) with a more optimized ranking of documents based on any viewed documents in the current page of results.",
                "In fact, according to our eager updating strategy, we may even allow a system to respond to a users clicking of browsers Back button after viewing a document in the same way, so that the user can maximally benefit from implicit feedback.",
                "These are precisely what our UCAIR system does. 3.2 User models A user model m ∈ M represents what we know about the user U, so in principle, it can contain any information about the user that we wish to model.",
                "We now discuss two important components in a user model.",
                "The first component is a component model of the users information need.",
                "Presumably, the most important factor affecting the optimality of the systems response is how well the response addresses the users information need.",
                "Indeed, at any time, we may assume that the system has some belief about what the user is interested in, which we model through a term vector x = (x1, ..., x|V |), where V = {w1, ..., w|V |} is the set of all terms (i.e., vocabulary) and xi is the weight of term wi.",
                "Such a term vector is commonly used in information retrieval to represent both queries and documents.",
                "For example, the vector-space model, assumes that both the query and the documents are represented as term vectors and the score of a document with respect to a query is computed based on the similarity between the query vector and the document vector [21].",
                "In a language modeling approach, we may also regard the query unigram language model [12, 29] or the relevance model [14] as a term vector representation of the users information need.",
                "Intuitively, x would assign high weights to terms that characterize the topics which the user is interested in.",
                "The second component we may include in our user model is the documents that the user has already viewed.",
                "Obviously, even if a document is relevant, if the user has already seen the document, it would not be useful to present the same document again.",
                "We thus introduce another variable S ⊂ D (D is the whole set of documents in the collection) to denote the subset of documents in the search results that the user has already seen/viewed.",
                "In general, at time t, we may represent a user model as mt = (S, x, At, Rt−1), where S is the seen documents, x is the systems understanding of the users information need, and (At, Rt−1) represents the users interaction history.",
                "Note that an even more general user model may also include other factors such as the users reading level and occupation.",
                "If we assume that the uncertainty of a user model mt is solely due to the uncertainty of x, the computation of our current estimate of user model m∗ t will mainly involve computing our best estimate of x.",
                "That is, the system would choose a response according to r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) where x∗ = argmaxx P(x|U, D, At, Rt−1).",
                "This is the decision mechanism implemented in the UCAIR system to be described later.",
                "In this system, we avoided specifying the probabilistic model P(x|U, D, At, Rt−1) by computing x∗ directly with some existing feedback method. 3.3 Loss functions The exact definition of loss function L depends on the responses, thus it is inevitably application-specific.",
                "We now briefly discuss some possibilities when the response is to rank all the unseen documents and present the top k of them.",
                "Let r = (d1, ..., dk) be the top k documents, S be the set of seen documents by the user, and x∗ be the systems best guess of the users information need.",
                "We 826 may simply define the loss associated with r as the negative sum of the probability that each of the di is relevant, i.e., L(a, r, m) = − k i=1 P(relevant|di, m).",
                "Clearly, in order to minimize this loss function, the optimal response r would contain the k documents with the highest probability of relevance, which is intuitively reasonable.",
                "One deficiency of this top-k loss function is that it is not sensitive to the internal order of the selected top k documents, so switching the ranking order of a non-relevant document and a relevant one would not affect the loss, which is unreasonable.",
                "To model ranking, we can introduce a factor of the user model - the probability of each of the k documents being viewed by the user, P(view|di), and define the following ranking loss function: L(a, r, m) = − k i=1 P(view|di)P(relevant|di, m) Since in general, if di is ranked above dj (i.e., i < j), P(view|di) > P(view|dj), this loss function would favor a decision to rank relevant documents above non-relevant ones, as otherwise, we could always switch di with dj to reduce the loss value.",
                "Thus the system should simply perform a regular retrieval and rank documents according to the probability of relevance [18].",
                "Depending on the users retrieval preferences, there can be many other possibilities.",
                "For example, if the user does not want to see redundant documents, the loss function should include some redundancy measure on r based on the already seen documents S. Of course, when the response is not to choose a ranked list of documents, we would need a different loss function.",
                "We discuss one such example that is relevant to the search agent that we implement.",
                "When a user enters a query qt (current action), our search agent relies on some existing search engine to actually carry out search.",
                "In such a case, even though the search agent does not have control of the retrieval algorithm, it can still attempt to optimize the search results through refining the query sent to the search engine and/or reranking the results obtained from the search engine.",
                "The loss functions for reranking are already discussed above; we now take a look at the loss functions for query refinement.",
                "Let f be the retrieval function of the search engine that our agent uses so that f(q) would give us the search results using query q.",
                "Given that the current action of the user is entering a query qt (i.e., at = qt), our response would be f(q) for some q.",
                "Since we have no choice of f, our decision is to choose a good q.",
                "Formally, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) which shows that our goal is to find q∗ = argminqL(qt, f(q), m), i.e., an optimal query that would give us the best f(q).",
                "A different choice of loss function L(qt, f(q), m) would lead to a different query refinement strategy.",
                "In UCAIR, we heuristically compute q∗ by expanding qt with terms extracted from rt−1 whenever qt−1 and qt have high similarity.",
                "Note that rt−1 and qt−1 are contained in m as part of the users interaction history. 3.4 Implicit user modeling Implicit user modeling is captured in our framework through the computation of x∗ = argmaxx P(x|U, D, At, Rt−1), i.e., the systems current belief of what the users information need is.",
                "Here again there may be many possibilities, leading to different algorithms for implicit user modeling.",
                "We now discuss a few of them.",
                "First, when two consecutive queries are related, the previous query can be exploited to enrich the current query and provide more search context to help disambiguation.",
                "For this purpose, instead of performing query expansion as we did in the previous section, we could also compute an updated x∗ based on the previous query and retrieval results.",
                "The computed new user model can then be used to rank the documents with a standard information retrieval model.",
                "Second, we can also infer a users interest based on the summaries of the viewed documents.",
                "When a user is presented with a list of summaries of top ranked documents, if the user chooses to skip the first n documents and to view the (n+1)-th document, we may infer that the user is not interested in the displayed summaries for the first n documents, but is attracted by the displayed summary of the (n + 1)-th document.",
                "We can thus use these summaries as negative and positive examples to learn a more accurate user model x∗ .",
                "Here many standard relevance feedback techniques can be exploited [19, 20].",
                "Note that we should use the displayed summaries, as opposed to the actual contents of those documents, since it is possible that the displayed summary of the viewed document is relevant, but the document content is actually not.",
                "Similarly, a displayed summary may mislead a user to skip a relevant document.",
                "Inferring user models based on such displayed information, rather than the actual content of a document is an important difference between UCAIR and some other similar systems.",
                "In UCAIR, both of these strategies for inferring an implicit user model are implemented. 4.",
                "UCAIR: A PERSONALIZED SEARCH AGENT 4.1 Design In this section, we present a client-side web search agent called UCAIR, in which we implement some of the methods discussed in the previous section for performing personalized search through implicit user modeling.",
                "UCAIR is a web browser plug-in 1 that acts as a proxy for web search engines.",
                "Currently, it is only implemented for Internet Explorer and Google, but it is a matter of engineering to make it run on other web browsers and interact with other search engines.",
                "The issue of privacy is a primary obstacle for deploying any real world applications involving serious user modeling, such as personalized search.",
                "For this reason, UCAIR is strictly running as a client-side search agent, as opposed to a server-side application.",
                "This way, the captured user information always resides on the computer that the user is using, thus the user does not need to release any information to the outside.",
                "Client-side personalization also allows the system to easily observe a lot of user information that may not be easily available to a server.",
                "Furthermore, performing personalized search on the client-side is more scalable than on the serverside, since the overhead of computation and storage is distributed among clients.",
                "As shown in Figure 1, the UCAIR toolbar has 3 major components: (1) The (implicit) user modeling module captures a users search context and history information, including the submitted queries and any clicked search results and infers search session boundaries. (2) The query modification module selectively improves the query formulation according to the current user model. (3) The result re-ranking module immediately re-ranks any unseen search results whenever the user model is updated.",
                "In UCAIR, we consider four basic user actions: (1) submitting a keyword query; (2) viewing a document; (3) clicking the Back button; (4) clicking the Next link on a result page.",
                "For each of these four actions, the system responds with, respectively, (1) 1 UCAIR is available at: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Search Engine (e.g., Google) Search History Log (e.g.,past queries, clicked results) Query Modification Result Re-Ranking User Modeling Result Buffer UCAIR Userquery results clickthrough… Figure 1: UCAIR architecture generating a ranked list of results by sending a possibly expanded query to a search engine; (2) updating the information need model x; (3) reranking the unseen results on the current result page based on the current model x; and (4) reranking the unseen pages and generating the next page of results based on the current model x.",
                "Behind these responses, there are three basic tasks: (1) Decide whether the previous query is related to the current query and if so expand the current query with useful terms from the previous query or the results of the previous query. (2) Update the information need model x based on a newly clicked document summary. (3) Rerank a set of unseen documents based on the current model x.",
                "Below we describe our algorithms for each of them. 4.2 Session boundary detection and query expansion To effectively exploit previous queries and their corresponding clickthrough information, UCAIR needs to judge whether two adjacent queries belong to the same search session (i.e., detect session boundaries).",
                "Existing work on session boundary detection is mostly in the context of web log analysis (e.g., [8]), and uses statistical information rather than textual features.",
                "Since our clientside agent does not have access to server query logs, we make session boundary decisions based on textual similarity between two queries.",
                "Because related queries do not necessarily share the same words (e.g., java island and travel Indonesia), it is insufficient to use only query text.",
                "Therefore we use the search results of the two queries to help decide whether they are topically related.",
                "For example, for the above queries java island and travel Indonesia, the words java, bali, island, indonesia and travel may occur frequently in both queries search results, yielding a high similarity score.",
                "We only use the titles and summaries of the search results to calculate the similarity since they are available in the retrieved search result page and fetching the full text of every result page would significantly slow down the process.",
                "To compensate for the terseness of titles and summaries, we retrieve more results than a user would normally view for the purpose of detecting session boundaries (typically 50 results).",
                "The similarity between the previous query q and the current query q is computed as follows.",
                "Let {s1, s2, . . . , sn } and {s1, s2, . . . , sn} be the result sets for the two queries.",
                "We use the pivoted normalization TF-IDF weighting formula [24] to compute a term weight vector si for each result si.",
                "We define the average result savg to be the centroid of all the result vectors, i.e., (s1 + s2 + . . . + sn)/n.",
                "The cosine similarity between the two average results is calculated as s avg · savg/ s 2 avg · s2 avg If the similarity value exceeds a predefined threshold, the two queries will be considered to be in the same information session.",
                "If the previous query and the current query are found to belong to the same search session, UCAIR would attempt to expand the current query with terms from the previous query and its search results.",
                "Specifically, for each term in the previous query or the corresponding search results, if its frequency in the results of the current query is greater than a preset threshold (e.g. 5 results out of 50), the term would be added to the current query to form an expanded query.",
                "In this case, UCAIR would send this expanded query rather than the original one to the search engine and return the results corresponding to the expanded query.",
                "Currently, UCAIR only uses the immediate preceding query for query expansion; in principle, we could exploit all related past queries. 4.3 Information need model updating Suppose at time t, we have observed that the user has viewed k documents whose summaries are s1, ..., sk.",
                "We update our user model by computing a new information need vector with a standard feedback method in information retrieval (i.e., Rocchio [19]).",
                "According to the vector space retrieval model, each clicked summary si can be represented by a term weight vector si with each term weighted by a TF-IDF weighting formula [21].",
                "Rocchio computes the centroid vector of all the summaries and interpolates it with the original query vector to obtain an updated term vector.",
                "That is, x = αq + (1 − α) 1 k k i=1 si where q is the query vector, k is the number of summaries the user clicks immediately following the current query and α is a parameter that controls the influence of the clicked summaries on the inferred information need model.",
                "In our experiments, α is set to 0.5.",
                "Note that we update the information need model whenever the user views a document. 4.4 Result reranking In general, we want to rerank all the unseen results as soon as the user model is updated.",
                "Currently, UCAIR implements reranking in two cases, corresponding to the user clicking the Back button and Next link in the Internet Explorer.",
                "In both cases, the current (updated) user model would be used to rerank the unseen results so that the user would see improved search results immediately.",
                "To rerank any unseen document summaries, UCAIR uses the standard vector space retrieval model and scores each summary based on the similarity of the result and the current user information need vector x [21].",
                "Since implicit feedback is not completely reliable, we bring up only a small number (e.g. 5) of highest reranked results to be followed by any originally high ranked results. 828 Google result (user query = java map) UCAIR result (user query =java map) previous query = travel Indonesia previous query = hashtable expanded user query = java map Indonesia expanded user query = java map class 1 Java map projections of the world ... Lonely Planet - Indonesia Map Map (Java 2 Platform SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Java map projections of the world ... INDONESIA TOURISM : CENTRAL JAVA - MAP Java 2 Platform SE v1.3.1: Interface Map www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Java Map INDONESIA TOURISM : WEST JAVA - MAP An Introduction to Java Map Collection Classes java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Java Technology Concept Map IndoStreets - Java Map An Introduction to Java Map Collection Classes java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Indonesia Regions and Islands Maps, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 An Introduction to Java Map Collection Classes Indonesia City Street Map,... Hibernate simplifies inheritance mapping www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Java Map Maps Of Indonesia tmap 30.map Class Hierarchy www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Java API Map Maps of Indonesia by Peter Loud Class Scope www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas : Sam Maps of Indonesia by Peter Loud Class PrintSafeHashMap www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 INDONESIA TOURISM : WEST JAVA - MAP indonesiaphoto.com Java Pro - Union and Vertical Mapping of Classes www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Table 1: Sample results of query expansion 5.",
                "EVALUATION OF UCAIR We now present some results on evaluating the two major UCAIR functions: selective query expansion and result reranking based on user clickthrough data. 5.1 Sample results The query expansion strategy implemented in UCAIR is intentionally conservative to avoid misinterpretation of implicit user models.",
                "In practice, whenever it chooses to expand the query, the expansion usually makes sense.",
                "In Table 1, we show how UCAIR can successfully distinguish two different search contexts for the query java map, corresponding to two different previous queries (i.e., travel Indonesia vs. hashtable).",
                "Due to implicit user modeling, UCAIR intelligently figures out to add Indonesia and class, respectively, to the users query java map, which would otherwise be ambiguous as shown in the original results from Google on March 21, 2005.",
                "UCAIRs results are much more accurate than Googles results and reflect personalization in search.",
                "The eager implicit feedback component is designed to immediately respond to a users activity such as viewing a document.",
                "In Figure 2, we show how UCAIR can successfully disambiguate an ambiguous query jaguar by exploiting a viewed document summary.",
                "In this case, the initial retrieval results using jaguar (shown on the left side) contain two results about the Jaguar cars followed by two results about the Jaguar software.",
                "However, after the user views the web page content of the second result (about Jaguar car) and returns to the search result page by clicking Back button, UCAIR automatically nominates two new search results about Jaguar cars (shown on the right side), while the original two results about Jaguar software are pushed down on the list (unseen from the picture). 5.2 Quantitative evaluation To further evaluate UCAIR quantitatively, we conduct a user study on the effectiveness of the eager implicit feedback component.",
                "It is a challenge to quantitatively evaluate the potential performance improvement of our proposed model and UCAIR over Google in an unbiased way [7].",
                "Here, we design a user study, in which participants would do normal web search and judge a randomly and anonymously mixed set of results from Google and UCAIR at the end of the search session; participants do not know whether a result comes from Google or UCAIR.",
                "We recruited 6 graduate students for this user study, who have different backgrounds (3 computer science, 2 biology, and 1 chem<top> <num> Number: 716 <title> Spammer arrest sue <desc> Description: Have any spammers been arrested or sued for sending unsolicited e-mail? <narr> Narrative: Instances of arrests, prosecutions, convictions, and punishments of spammers, and lawsuits against them are relevant.",
                "Documents which describe laws to limit spam without giving details of lawsuits or criminal trials are not relevant. </top> Figure 3: An example of TREC query topic, expressed in a form which might be given to a human assistant or librarian istry).",
                "We use query topics from TREC 2 2004 Terabyte track [2] and TREC 2003 Web track [4] topic distillation task in the way to be described below.",
                "An example topic from TREC 2004 Terabyte track appears in Figure 3.",
                "The title is a short phrase and may be used as a query to the retrieval system.",
                "The description field provides a slightly longer statement of the topic requirement, usually expressed as a single complete sentence or question.",
                "Finally the narrative supplies additional information necessary to fully specify the requirement, expressed in the form of a short paragraph.",
                "Initially, each participant would browse 50 topics either from Terabyte track or Web track and pick 5 or 7 most interesting topics.",
                "For each picked topic, the participant would essentially do the normal web search using UCAIR to find many relevant web pages by using the title of the query topic as the initial keyword query.",
                "During this process, the participant may view the search results and possibly click on some interesting ones to view the web pages, just as in a normal web search.",
                "There is no requirement or restriction on how many queries the participant must submit or when the participant should stop the search for one topic.",
                "When the participant plans to change the search topic, he/she will simply press a button 2 Text REtrieval Conference: http://trec.nist.gov/ 829 Figure 2: Screen shots for result reranking to evaluate the search results before actually switching to the next topic.",
                "At the time of evaluation, 30 top ranked results from Google and UCAIR (some are overlapping) are randomly mixed together so that the participant would not know whether a result comes from Google or UCAIR.",
                "The participant would then judge the relevance of these results.",
                "We measure precision at top n (n = 5, 10, 20, 30) documents of Google and UCAIR.",
                "We also evaluate precisions at different recall levels.",
                "Altogether, 368 documents judged as relevant from Google search results and 429 documents judged as relevant from UCAIR by participants.",
                "Scatter plots of precision at top 10 and top 20 documents are shown in Figure 4 and Figure 5 respectively (The scatter plot of precision at top 30 documents is very similar to precision at top 20 documents).",
                "Each point of the scatter plots represents the precisions of Google and UCAIR on one query topic.",
                "Table 2 shows the average precision at top n documents among 32 topics.",
                "From Figure 4, Figure 5 and Table 2, we see that the search results from UCAIR are consistently better than those from Google by all the measures.",
                "Moreover, the performance improvement is more dramatic for precision at top 20 documents than that at precision at top 10 documents.",
                "One explanation for this is that the more interaction the user has with the system, the more clickthrough data UCAIR can be expected to collect.",
                "Thus the retrieval system can build more precise implicit user models, which lead to better retrieval accuracy.",
                "Ranking Method prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Improvement 8.0% 17.8% 20.2% 21.8% Table 2: Table of average precision at top n documents for 32 query topics The plot in Figure 6 shows the precision-recall curves for UCAIR and Google, where it is clearly seen that the performance of UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Scatterplot of Precision at Top 10 Documents Figure 4: Precision at top 10 documents of UCAIR and Google is consistently and considerably better than that of Google at all levels of recall. 6.",
                "CONCLUSIONS In this paper, we studied how to exploit implicit user modeling to intelligently personalize information retrieval and improve search accuracy.",
                "Unlike most previous work, we emphasize the use of immediate search context and implicit feedback information as well as eager updating of search results to maximally benefit a user.",
                "We presented a decision-theoretic framework for optimizing interactive information retrieval based on eager user model updating, in which the system responds to every action of the user by choosing a system action to optimize a utility function.",
                "We further propose specific techniques to capture and exploit two types of implicit feedback information: (1) identifying related immediately preceding query and using the query and the corresponding search results to select appropriate terms to expand the current query, and (2) exploiting the viewed document summaries to immediately rerank any documents that have not yet been seen by the user.",
                "Using these techniques, we develop a client-side web search agent (UCAIR) on top of a popular search engine (Google).",
                "Experiments on web search show that our search agent can improve search accuracy over 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Scatterplot of Precision at Top 20 documents Figure 5: Precision at top 20 documents of UCAIR and Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 recall precision Precision−Recall curves Google Result UCAIR Result Figure 6: Precision at top 20 result of UCAIR and Google Google.",
                "Since the implicit information we exploit already naturally exists through user interactions, the user does not need to make any extra effort.",
                "The developed search agent thus can improve existing web search performance without any additional effort from the user. 7.",
                "ACKNOWLEDGEMENT We thank the six participants of our evaluation experiments.",
                "This work was supported in part by the National Science Foundation grants IIS-0347933 and IIS-0428472. 8.",
                "REFERENCES [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman, and O. Frieder.",
                "Hourly analysis of a very large topically categorized web query log.",
                "In Proceedings of SIGIR 2004, pages 321-328, 2004. [2] C. Clarke, N. Craswell, and I. Soboroff.",
                "Overview of the TREC 2004 terabyte track.",
                "In Proceedings of TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda, and D. Brown.",
                "Implicit interest indicators.",
                "In Proceedings of Intelligent User Interfaces 2001, pages 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson, and M. Wu.",
                "Overview of the TREC 2003 web track.",
                "In Proceedings of TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend, and V. Larvrenko.",
                "Relevance feedback and personalization: A language modeling perspective.",
                "In Proeedings of Second DELOS Workshop: Personalisation and Recommender Systems in Digital Libraries, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite, and D. Harman.",
                "Results and challenges in web search evaluation.",
                "Computer Networks, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A.",
                "An, and D. Schuurmans.",
                "Dynamic web log session identification with statistical language models.",
                "Journal of the American Society for Information Science and Technology, 55(14):1290-1303, 2004. [9] G. Jeh and J. Widom.",
                "Scaling personalized web search.",
                "In Proceedings of WWW 2003, pages 271-279, 2003. [10] T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of SIGKDD 2002, pages 133-142, 2002. [11] D. Kelly and J. Teevan.",
                "Implicit feedback for inferring user preference: A bibliography.",
                "SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty and C. Zhai.",
                "Document language models, query models, and risk minimization for information retrieval.",
                "In Proceedings of SIGIR01, pages 111-119, 2001. [13] T. Lau and E. Horvitz.",
                "Patterns of search: Analyzing and modeling web query refinement.",
                "In Proceedings of the Seventh International Conference on User Modeling (UM), pages 145 -152, 1999. [14] V. Lavrenko and B. Croft.",
                "Relevance-based language models.",
                "In Proceedings of SIGIR01, pages 120-127, 2001. [15] M. Mitra, A. Singhal, and C. Buckley.",
                "Improving automatic query expansion.",
                "In Proceedings of SIGIR 1998, pages 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg.",
                "As google goes, so goes the nation.",
                "New York Times, May 2003. [18] S. E. Robertson.",
                "The probability ranking principle in ı˚.",
                "Journal of Documentation, 33(4):294-304, 1977. [19] J. J. Rocchio.",
                "Relevance feedback in information retrieval.",
                "In The SMART Retrieval System: Experiments in Automatic Document Processing, pages 313-323.",
                "Prentice-Hall Inc., 1971. [20] G. Salton and C. Buckley.",
                "Improving retrieval performance by retrieval feedback.",
                "Journal of the American Society for Information Science, 41(4):288-297, 1990. [21] G. Salton and M. J. McGill.",
                "Introduction to Modern Information Retrieval.",
                "McGraw-Hill, 1983. [22] X. Shen, B. Tan, and C. Zhai.",
                "Context-sensitive information retrieval using implicit feedback.",
                "In Proceedings of SIGIR 2005, pages 43-50, 2005. [23] X. Shen and C. Zhai.",
                "Exploiting query history for document ranking in interactive information retrieval (Poster).",
                "In Proceedings of SIGIR 2003, pages 377-378, 2003. [24] A. Singhal.",
                "Modern information retrieval: A brief overview.",
                "Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano, and M. Yoshikawa.",
                "Adaptive web search based on user profile constructed without any effort from users.",
                "In Proceedings of WWW 2004, pages 675-684, 2004. [26] E. Volokh.",
                "Personalization and privacy.",
                "Communications of the ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen, and I. Ruthven.",
                "A simulated study of implicit feedback models.",
                "In Proceedings of ECIR 2004, pages 311-326, 2004. [28] J. Xu and W. B. Croft.",
                "Query expansion using local and global document analysis.",
                "In Proceedings of SIGIR 1996, pages 4-11, 1996. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in KL divergence retrieval model.",
                "In Proceedings of the CIKM 2001, pages 403-410, 2001. 831"
            ],
            "original_annotated_samples": [
                "In Section 3, we present a decisiontheoretic <br>interactive retrieval</br> framework for implicit user modeling.",
                "RELATED WORK Implicit user modeling for personalized search has been studied in previous work, but our work differs from all previous work in several aspects: (1) We emphasize the exploitation of immediate search context such as the related immediately preceding query and the viewed documents in the same session, while most previous work relies on long-term collection of implicit feedback information [25]. (2) We perform eager feedback and bring the benefit of implicit user modeling as soon as any new implicit feedback information is available, while the previous work mostly exploits longterm implicit feedback [10]. (3) We propose a retrieval framework to integrate implicit user modeling with the <br>interactive retrieval</br> process, while the previous work either studies implicit user modeling separately from retrieval [3] or only studies specific retrieval models for exploiting implicit feedback to better match a query with documents [23, 27, 22]. (4) We develop and evaluate a personalized Web search agent with online user studies, while most existing work evaluates algorithms offline without real user interactions."
            ],
            "translated_annotated_samples": [
                "En la Sección 3, presentamos un marco de <br>recuperación interactiva</br> basado en teoría de decisiones para modelado implícito de usuarios.",
                "El modelado implícito del usuario para la búsqueda personalizada ha sido estudiado en trabajos anteriores, pero nuestro trabajo difiere de todos los trabajos anteriores en varios aspectos: (1) Enfatizamos la explotación del contexto de búsqueda inmediato, como la consulta inmediatamente anterior relacionada y los documentos vistos en la misma sesión, mientras que la mayoría de los trabajos anteriores se basan en la recopilación a largo plazo de información de retroalimentación implícita [25]. (2) Realizamos una retroalimentación activa y obtenemos el beneficio del modelado implícito del usuario tan pronto como esté disponible cualquier nueva información de retroalimentación implícita, mientras que el trabajo anterior mayormente explota la retroalimentación implícita a largo plazo [10]. (3) Proponemos un marco de recuperación para integrar el modelado implícito del usuario con el <br>proceso interactivo de recuperación</br>, mientras que el trabajo anterior estudia el modelado implícito del usuario por separado de la recuperación [3] o solo estudia modelos de recuperación específicos para explotar la retroalimentación implícita para mejorar la coincidencia de una consulta con documentos [23, 27, 22]. (4) Desarrollamos y evaluamos un agente de búsqueda web personalizado con estudios de usuario en línea, mientras que la mayoría de los trabajos existentes evalúan algoritmos fuera de línea sin interacciones reales de usuarios."
            ],
            "translated_text": "Modelado implícito de usuarios para búsqueda personalizada Xuehua Shen, Bin Tan, ChengXiang Zhai Departamento de Ciencias de la Computación Universidad de Illinois en Urbana-Champaign RESUMEN Los sistemas de recuperación de información (por ejemplo, motores de búsqueda web) son críticos para superar la sobrecarga de información. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales, lo que resulta en un rendimiento de recuperación inherentemente no óptimo. Por ejemplo, un turista y un programador pueden usar la misma palabra \"java\" para buscar información diferente, pero los sistemas de búsqueda actuales devolverían los mismos resultados. En este artículo, estudiamos cómo inferir el interés de un usuario a partir del contexto de búsqueda del usuario y utilizar el modelo de usuario implícito inferido para la búsqueda personalizada. Presentamos un marco teórico de toma de decisiones y desarrollamos técnicas para el modelado implícito del usuario en la recuperación de información. Desarrollamos un agente de búsqueda web inteligente del lado del cliente (UCAIR) que puede realizar retroalimentación implícita ansiosa, por ejemplo, expansión de consultas basada en consultas anteriores y reordenamiento inmediato de resultados basado en información de clics. Los experimentos sobre la búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda sobre el popular motor de búsqueda Google. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación, Retroalimentación de relevancia, Proceso de búsqueda Términos Generales Algoritmos 1. Aunque muchos sistemas de recuperación de información (por ejemplo, motores de búsqueda web y sistemas de biblioteca digital) se han implementado con éxito, los sistemas de recuperación actuales están lejos de ser óptimos. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuario y no son adaptables a usuarios individuales [17]. Esta no optimalidad inherente se ve claramente en los siguientes dos casos: (1) Diferentes usuarios pueden utilizar exactamente la misma consulta (por ejemplo, Java) para buscar información diferente (por ejemplo, la isla de Java en Indonesia o el lenguaje de programación Java), pero los sistemas de IR existentes devuelven los mismos resultados para estos usuarios. Sin considerar al usuario actual, es imposible saber a qué sentido se refiere Java en una consulta. (2) Las necesidades de información de un usuario pueden cambiar con el tiempo. El mismo usuario puede usar Java a veces para referirse a la isla de Java en Indonesia y otras veces para referirse al lenguaje de programación. Sin reconocer el contexto de búsqueda, sería nuevamente imposible reconocer el sentido correcto. Para optimizar la precisión de la recuperación, claramente necesitamos modelar al usuario de manera adecuada y personalizar la búsqueda según cada usuario individual. El objetivo principal del modelado de usuario para la recuperación de información es modelar con precisión la necesidad de información de un usuario, lo cual, desafortunadamente, es una tarea muy difícil. De hecho, incluso resulta difícil para un usuario describir con precisión cuál es su necesidad de información. ¿Qué información está disponible para que un sistema pueda inferir la necesidad de información de un usuario? Obviamente, la consulta de los usuarios proporciona la evidencia más directa. De hecho, la mayoría de los sistemas de recuperación existentes se basan únicamente en la consulta para modelar la necesidad de información de los usuarios. Sin embargo, dado que una consulta suele ser extremadamente corta, el modelo de usuario construido basado en una consulta de palabras clave inevitablemente resulta empobrecido. Una forma efectiva de mejorar la modelización de usuarios en la recuperación de información es pedir al usuario que especifique explícitamente qué documentos son relevantes (es decir, útiles para satisfacer su necesidad de información) y luego mejorar la modelización de usuarios basándose en ejemplos de documentos relevantes. Esto se llama retroalimentación de relevancia, lo cual ha demostrado ser bastante efectivo para mejorar la precisión de recuperación [19, 20]. Desafortunadamente, en aplicaciones del mundo real, los usuarios suelen ser reacios a hacer el esfuerzo adicional de proporcionar ejemplos relevantes para retroalimentación [11]. Por lo tanto, es muy interesante estudiar cómo inferir la necesidad de información de un usuario basándose en cualquier información de retroalimentación implícita, la cual existe naturalmente a través de las interacciones del usuario y no requiere ningún esfuerzo adicional por parte del usuario. De hecho, varios estudios previos han demostrado que el modelado implícito del usuario puede mejorar la precisión de recuperación. En [3], se desarrolla un navegador web (Curious Browser) para registrar las calificaciones explícitas de relevancia de las páginas web por parte de los usuarios (retroalimentación de relevancia) y el comportamiento de navegación al ver una página, como el tiempo de permanencia, clics de ratón, movimiento del ratón y desplazamiento (retroalimentación implícita). Se muestra que el tiempo de permanencia en una página, la cantidad de desplazamiento en una página y la combinación de tiempo y desplazamiento tienen una fuerte correlación con las calificaciones de relevancia explícita, lo que sugiere que la retroalimentación implícita puede ser útil para inferir la necesidad de información del usuario. En [10], se recopilan datos de clics de usuario como datos de entrenamiento para aprender una función de recuperación, que se utiliza para producir un ranking personalizado de resultados de búsqueda que se adapte a las preferencias de un grupo de usuarios. En [25], los datos de clics recopilados durante un largo período de tiempo se utilizan a través de la expansión de consultas para mejorar la precisión de recuperación. Si bien un usuario puede tener intereses y preferencias generales a largo plazo para la información, a menudo está buscando documentos para satisfacer una necesidad de información ad-hoc, que solo dura un corto período de tiempo; una vez que se satisface la necesidad de información, el usuario generalmente ya no estaría interesado en esa información. Por ejemplo, un usuario puede estar buscando información sobre autos usados para comprar uno, pero una vez que el usuario ha comprado un auto, generalmente ya no está interesado en esa información. En tales casos, la información de retroalimentación implícita recopilada durante un largo período de tiempo es poco probable que sea muy útil, pero el contexto de búsqueda inmediato y la información de retroalimentación, como cuáles de los resultados de búsqueda para la necesidad de información actual son vistos, se espera que sean mucho más útiles. Considera la consulta de Java nuevamente. Cualquiera de la siguiente información de retroalimentación inmediata sobre el usuario podría potencialmente ayudar a determinar el significado previsto de Java en la consulta: (1) La consulta anterior enviada por el usuario es hashtable (en lugar de, por ejemplo, viajar a Indonesia). (2) En los resultados de búsqueda, el usuario visualizó una página donde palabras como programación, software y applet ocurren muchas veces. Hasta donde sabemos, cómo aprovechar este contexto de búsqueda inmediato y a corto plazo para mejorar la búsqueda aún no ha sido abordado de manera satisfactoria en trabajos anteriores. En este artículo, estudiamos cómo construir y actualizar un modelo de usuario basado en el contexto de búsqueda inmediato y la información de retroalimentación implícita, y utilizar el modelo para mejorar la precisión de la recuperación ad-hoc. Para beneficiar al máximo al usuario de un sistema de recuperación a través de modelado implícito del usuario, proponemos realizar retroalimentación implícita entusiasta. Es decir, tan pronto como observemos cualquier nueva pieza de evidencia del usuario, actualizaríamos la creencia del sistema sobre la necesidad de información del usuario y responderíamos con resultados de recuperación mejorados basados en el modelo de usuario actualizado. Presentamos un marco de trabajo de teoría de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. En un paradigma de recuperación tradicional, el problema de recuperación consiste en emparejar una consulta con documentos y clasificar los documentos según sus valores de relevancia. Como resultado, el proceso de recuperación es un ciclo independiente simple de consulta y visualización de resultados. En el nuevo paradigma de recuperación propuesto, el contexto de búsqueda de los usuarios juega un papel importante y el modelo de usuario implícito inferido se explota inmediatamente para beneficiar al usuario. El nuevo paradigma de recuperación es, por lo tanto, fundamentalmente diferente del paradigma tradicional y es inherentemente más general. Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos apropiados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para reordenar inmediatamente cualquier documento que aún no haya sido visto por el usuario. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente UCAIR (Recuperación de Información Adaptativa Centrada en el Usuario) sobre un motor de búsqueda popular (Google). Los experimentos sobre búsqueda en la web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en comparación con Google. Dado que la información implícita que explotamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional. Por lo tanto, el agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin esfuerzo adicional por parte del usuario. Las secciones restantes están organizadas de la siguiente manera. En la Sección 2, discutimos el trabajo relacionado. En la Sección 3, presentamos un marco de <br>recuperación interactiva</br> basado en teoría de decisiones para modelado implícito de usuarios. En la Sección 4, presentamos el diseño e implementación de un agente de búsqueda web inteligente del lado del cliente (UCAIR) que realiza retroalimentación implícita ansiosa. En la Sección 5, informamos nuestros resultados experimentales utilizando el agente de búsqueda. La sección 6 concluye nuestro trabajo. 2. El modelado implícito del usuario para la búsqueda personalizada ha sido estudiado en trabajos anteriores, pero nuestro trabajo difiere de todos los trabajos anteriores en varios aspectos: (1) Enfatizamos la explotación del contexto de búsqueda inmediato, como la consulta inmediatamente anterior relacionada y los documentos vistos en la misma sesión, mientras que la mayoría de los trabajos anteriores se basan en la recopilación a largo plazo de información de retroalimentación implícita [25]. (2) Realizamos una retroalimentación activa y obtenemos el beneficio del modelado implícito del usuario tan pronto como esté disponible cualquier nueva información de retroalimentación implícita, mientras que el trabajo anterior mayormente explota la retroalimentación implícita a largo plazo [10]. (3) Proponemos un marco de recuperación para integrar el modelado implícito del usuario con el <br>proceso interactivo de recuperación</br>, mientras que el trabajo anterior estudia el modelado implícito del usuario por separado de la recuperación [3] o solo estudia modelos de recuperación específicos para explotar la retroalimentación implícita para mejorar la coincidencia de una consulta con documentos [23, 27, 22]. (4) Desarrollamos y evaluamos un agente de búsqueda web personalizado con estudios de usuario en línea, mientras que la mayoría de los trabajos existentes evalúan algoritmos fuera de línea sin interacciones reales de usuarios. Actualmente algunos motores de búsqueda ofrecen personalización rudimentaria, como la búsqueda web personalizada de Google [6], que permite a los usuarios describir explícitamente sus intereses seleccionando entre temas predefinidos, de modo que los resultados que coinciden con sus intereses se muestren en la parte superior, y la búsqueda de My Yahoo! [16], que brinda a los usuarios la opción de guardar los sitios web que les gustan y bloquear aquellos que no les gustan. Por el contrario, UCAIR personaliza la búsqueda web a través de la modelización implícita del usuario sin necesidad de esfuerzos adicionales por parte del usuario. Además, la personalización de UCAIR se proporciona en el lado del cliente. Hay dos ventajas notables en esto. Primero, el usuario no necesita preocuparse por la infracción de privacidad, que es una gran preocupación para la búsqueda personalizada [26]. En segundo lugar, tanto el cálculo de la personalización como el almacenamiento del perfil del usuario se realizan en el lado del cliente para reducir drásticamente la carga del servidor [9]. Ha habido muchos trabajos estudiando los registros de consultas de usuarios [1] o la dinámica de consultas [13]. UCAIR hace uso directo del historial de consultas de un usuario para beneficiar al mismo usuario de inmediato en la misma sesión de búsqueda. UCAIR primero determina si dos consultas vecinas pertenecen a la misma sesión de información y, de ser así, selecciona términos de la consulta anterior para realizar la expansión de la consulta. Nuestro enfoque de expansión de consultas es similar a la expansión automática de consultas [28, 15, 5], pero en lugar de utilizar retroalimentación pseudo para expandir la consulta, utilizamos la información de retroalimentación implícita de los usuarios para expandir la consulta actual. Estas dos técnicas pueden ser combinadas. 3. OPTIMIZACIÓN EN IR INTERACTIVO En IR interactivo, un usuario interactúa con el sistema de recuperación a través de un diálogo de acción, en el cual el sistema responde a cada acción del usuario con alguna acción del sistema. Por ejemplo, la acción de los usuarios puede ser enviar una consulta y la respuesta del sistema puede ser devolver una lista de 10 resúmenes de documentos. En general, el espacio de acciones del usuario y respuestas del sistema y sus granularidades dependerían de la interfaz de un sistema de recuperación particular. En principio, cada acción del usuario puede potencialmente proporcionar nuevas pruebas para ayudar al sistema a inferir mejor la necesidad de información del usuario. Por lo tanto, para responder de manera óptima, el sistema debería utilizar toda la evidencia recopilada hasta ahora sobre el usuario al elegir una respuesta. Cuando se ven de esta manera, la mayoría de los motores de búsqueda existentes son claramente no óptimos. Por ejemplo, si un usuario ha visto algunos documentos en la primera página de resultados de búsqueda, cuando el usuario hace clic en el enlace Siguiente para obtener más resultados, un sistema de recuperación existente seguiría devolviendo la siguiente página de resultados recuperados en función de la consulta original sin considerar la nueva evidencia de que un resultado en particular ha sido visto por el usuario. Proponemos optimizar el rendimiento de la recuperación adaptando las respuestas del sistema en función de cada acción que un usuario haya tomado, y planteamos el problema de optimización como una tarea de decisión. Específicamente, en cualquier momento, el sistema intentaría realizar dos tareas: (1) Actualización del modelo de usuario: Monitorear cualquier evidencia útil del usuario con respecto a su necesidad de información y actualizar el modelo de usuario tan pronto como esta evidencia esté disponible; (2) Mejorar los resultados de búsqueda: Reclasificar inmediatamente todos los documentos que el usuario aún no ha visto, tan pronto como se actualice el modelo de usuario. Enfatizamos la actualización y reordenamiento entusiastas, lo que hace que nuestro trabajo sea bastante diferente a cualquier trabajo existente. A continuación presentamos un marco formal de teoría de decisiones para optimizar el rendimiento de recuperación a través de la modelización implícita del usuario en la recuperación de información interactiva. 3.1 Un marco de teoría de decisiones Sea A el conjunto de todas las acciones del usuario y R(a) el conjunto de todas las posibles respuestas del sistema a una acción del usuario a ∈ A. En cualquier momento, sea At = (a1, ..., at) la secuencia observada de acciones de usuario hasta ahora (hasta el momento t) y Rt−1 = (r1, ..., rt−1) las respuestas que el sistema ha dado en respuesta a las acciones del usuario. El objetivo del sistema es elegir una respuesta óptima rt ∈ R(at) para la acción actual del usuario at. Sea M el espacio de todos los posibles modelos de usuario. Definimos además una función de pérdida L(a, r, m) ∈ , donde a ∈ A es una acción del usuario, r ∈ R(a) es una respuesta del sistema, y m ∈ M es un modelo de usuario. L(a, r, m) codifica nuestras preferencias de decisión y evalúa la optimalidad de responder con r cuando el modelo de usuario actual es m y la acción de usuario actual es a. Según la teoría de decisión bayesiana, la decisión óptima en el tiempo t es elegir una respuesta que minimice el riesgo de Bayes, es decir, r∗ t = argmin r∈R(at) M L(at, r, mt)P(mt|U, D, At, Rt−1)dmt (1) donde P(mt|U, D, At, Rt−1) es la probabilidad posterior del modelo de usuario mt dadas todas las observaciones sobre el usuario U que hemos realizado hasta el tiempo t. Para simplificar el cálculo de la Ecuación 1, asumamos que la masa de probabilidad posterior P(mt|U, D, At, Rt−1) está principalmente concentrada en el modo m∗ t = argmaxmt P(mt|U, D, At, Rt−1). Podemos entonces aproximar la integral con el valor de la función de pérdida en m∗ t. Es decir, r∗ t ≈ argminr∈R(at)L(at, r, m∗ t ) (2) donde m∗ t = argmaxmt P(mt|U, D, At, Rt−1). Dejando de lado cómo definir y estimar estos modelos probabilísticos y la función de pérdida, podemos ver que tal formulación de la teoría de decisiones sugiere que, para elegir la respuesta óptima a at, el sistema debería realizar dos tareas: (1) calcular el modelo de usuario actual y obtener m∗ t basado en toda la información útil. (2) elegir una respuesta rt para minimizar el valor de la función de pérdida L(at, rt, m∗ t). Cuando at no afecta nuestra creencia sobre m∗ t , el primer paso puede omitirse y podemos reutilizar m∗ t−1 para m∗ t . Ten en cuenta que nuestro marco de trabajo es bastante general, ya que potencialmente podemos modelar cualquier tipo de acciones de usuario y respuestas del sistema. En la mayoría de los casos, como podríamos esperar, la respuesta del sistema es algún tipo de clasificación de documentos, es decir, para la mayoría de las acciones a, R(a) consiste en todas las posibles clasificaciones de los documentos no vistos, y el problema de decisión se reduce a elegir la mejor clasificación de los documentos no vistos basándose en el modelo de usuario más actualizado. Cuando a es la acción de enviar una consulta de palabras clave, tal respuesta es exactamente lo que haría un sistema de recuperación actual. Sin embargo, fácilmente podemos imaginar que un motor de búsqueda web más inteligente respondería al clic del usuario en el enlace Siguiente (para obtener más resultados no vistos) con una clasificación más optimizada de documentos basada en cualquier documento visto en la página actual de resultados. De hecho, según nuestra estrategia de actualización entusiasta, incluso podríamos permitir que un sistema responda al clic del botón Atrás del navegador por parte de un usuario después de ver un documento de la misma manera, para que el usuario pueda beneficiarse al máximo de la retroalimentación implícita. Estos son precisamente lo que nuestro sistema UCAIR hace. 3.2 Modelos de usuario Un modelo de usuario m ∈ M representa lo que sabemos sobre el usuario U, por lo que en principio, puede contener cualquier información sobre el usuario que deseemos modelar. Ahora discutimos dos componentes importantes en un modelo de usuario. El primer componente es un modelo de componente de la necesidad de información de los usuarios. Presumiblemente, el factor más importante que afecta la optimalidad de la respuesta del sistema es qué tan bien la respuesta aborda la necesidad de información de los usuarios. De hecho, en cualquier momento, podemos asumir que el sistema tiene alguna creencia sobre lo que le interesa al usuario, la cual modelamos a través de un vector de términos x = (x1, ..., x|V|), donde V = {w1, ..., w|V|} es el conjunto de todos los términos (es decir, vocabulario) y xi es el peso del término wi. Un vector de términos de este tipo se utiliza comúnmente en la recuperación de información para representar tanto consultas como documentos. Por ejemplo, el modelo de espacio vectorial asume que tanto la consulta como los documentos se representan como vectores de términos y que la puntuación de un documento con respecto a una consulta se calcula en función de la similitud entre el vector de la consulta y el vector del documento [21]. En un enfoque de modelado de lenguaje, también podemos considerar el modelo de lenguaje unigrama de consulta [12, 29] o el modelo de relevancia [14] como una representación vectorial de términos de la necesidad de información de los usuarios. Intuitivamente, x asignaría pesos altos a los términos que caracterizan los temas que interesan al usuario. El segundo componente que podemos incluir en nuestro modelo de usuario son los documentos que el usuario ya ha visto. Obviamente, incluso si un documento es relevante, si el usuario ya ha visto el documento, no sería útil presentar el mismo documento de nuevo. Por lo tanto, introducimos otra variable S ⊂ D (D es el conjunto completo de documentos en la colección) para denotar el subconjunto de documentos en los resultados de búsqueda que el usuario ya ha visto. En general, en el tiempo t, podemos representar un modelo de usuario como mt = (S, x, At, Rt−1), donde S son los documentos vistos, x es la comprensión del sistema de la necesidad de información del usuario, y (At, Rt−1) representa el historial de interacción del usuario. Ten en cuenta que un modelo de usuario aún más general también puede incluir otros factores como el nivel de lectura y la ocupación de los usuarios. Si asumimos que la incertidumbre de un modelo de usuario mt se debe únicamente a la incertidumbre de x, el cálculo de nuestra estimación actual del modelo de usuario m∗ t implicará principalmente calcular nuestra mejor estimación de x. Es decir, el sistema elegiría una respuesta de acuerdo a r∗ t = argminr∈R(at)L(at, r, S, x∗ , At, Rt−1) (3) donde x∗ = argmaxx P(x|U, D, At, Rt−1). Este es el mecanismo de decisión implementado en el sistema UCAIR que se describirá más adelante. En este sistema, evitamos especificar el modelo probabilístico P(x|U, D, At, Rt−1) calculando x∗ directamente con algún método de retroalimentación existente. 3.3 Funciones de pérdida La definición exacta de la función de pérdida L depende de las respuestas, por lo que es inevitablemente específica de la aplicación. Ahora discutimos brevemente algunas posibilidades cuando la respuesta es clasificar todos los documentos no vistos y presentar los mejores k de ellos. Sea r = (d1, ..., dk) los k documentos principales, S el conjunto de documentos vistos por el usuario, y x∗ la mejor suposición del sistema sobre la necesidad de información del usuario. Podemos definir simplemente la pérdida asociada con r como la suma negativa de la probabilidad de que cada uno de los di sea relevante, es decir, L(a, r, m) = − k i=1 P(relevante|di, m). Claramente, para minimizar esta función de pérdida, la respuesta óptima r contendría los k documentos con la probabilidad más alta de relevancia, lo cual es intuitivamente razonable. Una deficiencia de esta función de pérdida top-k es que no es sensible al orden interno de los documentos top k seleccionados, por lo que cambiar el orden de clasificación de un documento no relevante y uno relevante no afectaría la pérdida, lo cual es irrazonable. Para modelar el ranking, podemos introducir un factor del modelo de usuario: la probabilidad de que cada uno de los k documentos sea visto por el usuario, P(vista|di), y definir la siguiente función de pérdida de ranking: L(a, r, m) = − k i=1 P(vista|di)P(relevante|di, m). Dado que, en general, si di está clasificado por encima de dj (es decir, i < j), P(vista|di) > P(vista|dj), esta función de pérdida favorecería una decisión de clasificar documentos relevantes por encima de los no relevantes, ya que de lo contrario, siempre podríamos intercambiar di con dj para reducir el valor de pérdida. Por lo tanto, el sistema simplemente debería realizar una recuperación regular y clasificar los documentos según la probabilidad de relevancia [18]. Dependiendo de las preferencias de recuperación de los usuarios, puede haber muchas otras posibilidades. Por ejemplo, si el usuario no desea ver documentos redundantes, la función de pérdida debería incluir alguna medida de redundancia en r basada en los documentos ya vistos S. Por supuesto, cuando la respuesta no es elegir una lista clasificada de documentos, necesitaríamos una función de pérdida diferente. Discutimos un ejemplo relevante para el agente de búsqueda que implementamos. Cuando un usuario ingresa una consulta qt (acción actual), nuestro agente de búsqueda se basa en algún motor de búsqueda existente para llevar a cabo la búsqueda en realidad. En tal caso, aunque el agente de búsqueda no tenga control sobre el algoritmo de recuperación, aún puede intentar optimizar los resultados de la búsqueda refinando la consulta enviada al motor de búsqueda y/o reordenando los resultados obtenidos del motor de búsqueda. Las funciones de pérdida para el reordenamiento ya fueron discutidas anteriormente; ahora echamos un vistazo a las funciones de pérdida para el refinamiento de consultas. Sea f la función de recuperación del motor de búsqueda que nuestro agente utiliza, de modo que f(q) nos daría los resultados de búsqueda utilizando la consulta q. Dado que la acción actual del usuario es ingresar una consulta qt (es decir, at = qt), nuestra respuesta sería f(q) para algún q. Dado que no tenemos elección de f, nuestra decisión es elegir un buen q. Formalmente, r∗ t = argminrt L(a, rt, m) = argminf(q)L(a, f(q), m) = f(argminqL(qt, f(q), m)) lo cual muestra que nuestro objetivo es encontrar q∗ = argminqL(qt, f(q), m), es decir, una consulta óptima que nos daría el mejor f(q). Una elección diferente de la función de pérdida L(qt, f(q), m) llevaría a una estrategia de refinamiento de consulta diferente. En UCAIR, calculamos heurísticamente q∗ expandiendo qt con términos extraídos de rt−1 siempre que qt−1 y qt tengan una alta similitud. Se debe tener en cuenta que rt−1 y qt−1 están contenidos en m como parte del historial de interacción de los usuarios. 3.4 Modelado implícito del usuario El modelado implícito del usuario se captura en nuestro marco a través del cálculo de x∗ = argmaxx P(x|U, D, At, Rt−1), es decir, la creencia actual del sistema sobre cuál es la necesidad de información del usuario. Aquí nuevamente puede haber muchas posibilidades, lo que lleva a diferentes algoritmos para la modelización implícita del usuario. Ahora discutimos algunos de ellos. Primero, cuando dos consultas consecutivas están relacionadas, la consulta anterior puede ser explotada para enriquecer la consulta actual y proporcionar más contexto de búsqueda para ayudar en la desambiguación. Para este propósito, en lugar de realizar una expansión de consulta como lo hicimos en la sección anterior, también podríamos calcular un x∗ actualizado basado en la consulta anterior y los resultados de recuperación. El modelo de usuario nuevo calculado puede luego ser utilizado para clasificar los documentos con un modelo estándar de recuperación de información. Segundo, también podemos inferir los intereses de un usuario basándonos en los resúmenes de los documentos visualizados. Cuando a un usuario se le presenta una lista de resúmenes de documentos mejor clasificados, si el usuario elige saltarse los primeros n documentos y ver el documento (n+1)-ésimo, podemos inferir que el usuario no está interesado en los resúmenes mostrados para los primeros n documentos, pero está atraído por el resumen mostrado del documento (n+1)-ésimo. Por lo tanto, podemos usar estos resúmenes como ejemplos negativos y positivos para aprender un modelo de usuario más preciso x∗. Aquí se pueden explotar muchas técnicas estándar de retroalimentación de relevancia [19, 20]. Ten en cuenta que debemos utilizar los resúmenes mostrados, en lugar de los contenidos reales de esos documentos, ya que es posible que el resumen mostrado del documento visto sea relevante, pero el contenido del documento en realidad no lo sea. Del mismo modo, un resumen mostrado puede llevar a un usuario a omitir un documento relevante. Inferir modelos de usuario basados en dicha información mostrada, en lugar del contenido real de un documento, es una diferencia importante entre UCAIR y algunos otros sistemas similares. En UCAIR, ambas estrategias para inferir un modelo de usuario implícito están implementadas. 4. UCAIR: Un agente de búsqueda personalizado 4.1 Diseño En esta sección, presentamos un agente de búsqueda web del lado del cliente llamado UCAIR, en el cual implementamos algunos de los métodos discutidos en la sección anterior para realizar búsquedas personalizadas a través de modelado implícito del usuario. UCAIR es un complemento del navegador web que actúa como proxy para los motores de búsqueda en la web. Actualmente, solo está implementado para Internet Explorer y Google, pero es cuestión de ingeniería hacer que funcione en otros navegadores web e interactúe con otros motores de búsqueda. El tema de la privacidad es un obstáculo principal para implementar cualquier aplicación del mundo real que involucre modelado de usuarios serio, como la búsqueda personalizada. Por esta razón, UCAIR funciona estrictamente como un agente de búsqueda del lado del cliente, en lugar de ser una aplicación del lado del servidor. De esta manera, la información del usuario capturada siempre permanece en la computadora que está utilizando el usuario, por lo tanto, el usuario no necesita revelar ninguna información al exterior. La personalización del lado del cliente también permite que el sistema observe fácilmente una gran cantidad de información del usuario que puede no estar fácilmente disponible para un servidor. Además, realizar búsquedas personalizadas en el lado del cliente es más escalable que en el lado del servidor, ya que la sobrecarga de cálculo y almacenamiento se distribuye entre los clientes. Como se muestra en la Figura 1, la barra de herramientas UCAIR tiene 3 componentes principales: (1) El módulo de modelado de usuario (implícito) captura el contexto de búsqueda de un usuario e información de historial, incluidas las consultas enviadas y los resultados de búsqueda clicados, e infiere los límites de la sesión de búsqueda. (2) El módulo de modificación de consultas mejora selectivamente la formulación de la consulta de acuerdo con el modelo de usuario actual. (3) El módulo de reordenamiento de resultados reordena inmediatamente cualquier resultado de búsqueda no visto cada vez que se actualiza el modelo de usuario. En UCAIR, consideramos cuatro acciones básicas de usuario: (1) enviar una consulta de palabras clave; (2) ver un documento; (3) hacer clic en el botón Atrás; (4) hacer clic en el enlace Siguiente en una página de resultados. Para cada una de estas cuatro acciones, el sistema responde con, respectivamente, (1) 1 UCAIR está disponible en: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Registro de Historial de Búsqueda del Motor de Búsqueda (por ejemplo, Google) (consultas pasadas, resultados clicados) Modificación de Consulta Resultado de Reclasificación Modelo de Usuario Buffer de Resultados de Consulta de Usuario UCAIR... Figura 1: arquitectura de UCAIR generando una lista clasificada de resultados enviando una consulta posiblemente ampliada a un motor de búsqueda; (2) actualizando el modelo de necesidad de información x; (3) reordenando los resultados no vistos en la página de resultados actual basándose en el modelo actual x; y (4) reordenando las páginas no vistas y generando la siguiente página de resultados basándose en el modelo actual x. Detrás de estas respuestas, hay tres tareas básicas: (1) Decidir si la consulta anterior está relacionada con la consulta actual y, de ser así, ampliar la consulta actual con términos útiles de la consulta anterior o los resultados de la consulta anterior. (2) Actualizar el modelo de necesidad de información x basado en un resumen de documento recién seleccionado. (3) Reordenar un conjunto de documentos no vistos basado en el modelo x actual. A continuación describimos nuestros algoritmos para cada uno de ellos. 4.2 Detección de límites de sesión y expansión de consultas Para explotar eficazmente las consultas anteriores y su información correspondiente de clics, UCAIR necesita determinar si dos consultas adyacentes pertenecen a la misma sesión de búsqueda (es decir, detectar los límites de sesión). El trabajo existente sobre la detección de límites de sesión se encuentra principalmente en el contexto del análisis de registros web (por ejemplo, [8]), y utiliza información estadística en lugar de características textuales. Dado que nuestro agente del lado del cliente no tiene acceso a los registros de consultas del servidor, tomamos decisiones sobre los límites de sesión basadas en la similitud textual entre dos consultas. Debido a que las consultas relacionadas no necesariamente comparten las mismas palabras (por ejemplo, isla de Java y viajar a Indonesia), no es suficiente utilizar solo el texto de la consulta. Por lo tanto, utilizamos los resultados de búsqueda de las dos consultas para ayudar a decidir si están relacionadas temáticamente. Por ejemplo, para las consultas anteriores \"java island\" y \"travel Indonesia\", las palabras \"java\", \"bali\", \"island\", \"indonesia\" y \"travel\" pueden aparecer con frecuencia en los resultados de búsqueda de ambas consultas, lo que produce un alto puntaje de similitud. Solo utilizamos los títulos y resúmenes de los resultados de búsqueda para calcular la similitud, ya que están disponibles en la página de resultados de búsqueda recuperada y obtener el texto completo de cada página de resultados ralentizaría significativamente el proceso. Para compensar la concisión de los títulos y resúmenes, recuperamos más resultados de los que un usuario normalmente vería con el propósito de detectar los límites de sesión (típicamente 50 resultados). La similitud entre la consulta anterior q y la consulta actual q se calcula de la siguiente manera. Sean {s1, s2, . . . , sn} y {s1, s2, . . . , sn} los conjuntos de resultados de las dos consultas. Utilizamos la fórmula de ponderación TF-IDF normalizada pivotada [24] para calcular un vector de peso de término si para cada resultado si. Definimos el resultado promedio savg como el centroide de todos los vectores de resultado, es decir, (s1 + s2 + . . . + sn)/n. La similitud del coseno entre los dos resultados promedio se calcula como s avg · savg/ s 2 avg · s2 avg. Si el valor de similitud supera un umbral predefinido, se considerará que las dos consultas están en la misma sesión de información. Si se determina que la consulta anterior y la consulta actual pertenecen a la misma sesión de búsqueda, UCAIR intentaría expandir la consulta actual con términos de la consulta anterior y sus resultados de búsqueda. Específicamente, para cada término en la consulta anterior o los resultados de búsqueda correspondientes, si su frecuencia en los resultados de la consulta actual es mayor que un umbral preestablecido (por ejemplo, 5 resultados de 50), el término se agregaría a la consulta actual para formar una consulta ampliada. En este caso, UCAIR enviaría esta consulta ampliada en lugar de la original al motor de búsqueda y devolvería los resultados correspondientes a la consulta ampliada. Actualmente, UCAIR solo utiliza la consulta inmediatamente anterior para la expansión de consultas; en principio, podríamos aprovechar todas las consultas pasadas relacionadas. 4.3 Actualización del modelo de necesidad de información Supongamos que en el tiempo t, hemos observado que el usuario ha visto k documentos cuyos resúmenes son s1, ..., sk. Actualizamos nuestro modelo de usuario calculando un nuevo vector de necesidad de información con un método estándar de retroalimentación en la recuperación de información (es decir, Rocchio [19]). Según el modelo de recuperación de espacio vectorial, cada resumen clicado si puede ser representado por un vector de pesos de términos si, con cada término ponderado por una fórmula de ponderación TF-IDF [21]. Rocchio calcula el vector centroide de todos los resúmenes e interpola este con el vector de consulta original para obtener un vector de términos actualizado. Es decir, x = αq + (1 − α) 1 k k i=1 si donde q es el vector de consulta, k es el número de resúmenes que el usuario hace clic inmediatamente después de la consulta actual y α es un parámetro que controla la influencia de los resúmenes clicados en el modelo de necesidad de información inferida. En nuestros experimentos, α se establece en 0.5. Ten en cuenta que actualizamos el modelo de información necesario cada vez que el usuario ve un documento. 4.4 Reclasificación de resultados En general, queremos volver a clasificar todos los resultados no vistos tan pronto como se actualice el modelo de usuario. Actualmente, UCAIR implementa el reordenamiento en dos casos, correspondientes a cuando el usuario hace clic en el botón Atrás y en el enlace Siguiente en Internet Explorer. En ambos casos, el modelo de usuario actualizado se utilizaría para reordenar los resultados no vistos de manera que el usuario vea resultados de búsqueda mejorados de inmediato. Para volver a clasificar cualquier resumen de documento no visto, UCAIR utiliza el modelo estándar de recuperación de espacio vectorial y puntúa cada resumen en función de la similitud del resultado y el vector de necesidad de información actual del usuario x [21]. Dado que la retroalimentación implícita no es completamente confiable, presentamos solo un pequeño número (por ejemplo, 5) de los resultados reordenados más altos para ser seguidos por cualquier resultado originalmente clasificado alto. 828 resultados de Google (consulta del usuario = mapa de Java) Resultados de UCAIR (consulta del usuario = mapa de Java) consulta anterior = viajar a Indonesia consulta anterior = tabla hash consulta del usuario ampliada = mapa de Java Indonesia consulta del usuario ampliada = clase de mapa de Java 1 Proyecciones de mapas de Java del mundo ... Lonely Planet - Mapa de Indonesia Mapa (Plataforma Java SE v1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/docs/... 2 Proyecciones de mapas de Java del mundo ... TURISMO DE INDONESIA: JAVA CENTRAL - MAPA Plataforma Java SE v1.3.1: Interfaz de Mapa www.btinternet.com/ se16/js/oldmapproj.htm www.indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 Mapa de Java TURISMO DE INDONESIA: JAVA OESTE - MAPA Una introducción a las clases de colección de mapas de Java java.sun.com/developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Mapa de Tecnología Java IndoStreets - Mapa de Java Una introducción a las clases de colección de mapas de Java java.sun.com/developer/onlineTraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 Science@NASA Home Regiones e islas de Indonesia Mapas, Bali, Java, ... Koders - Mappings.java science.nasa.gov/Realtime/... www.maps2anywhere.com/Maps/... www.koders.com/java/ 6 Una introducción a las clases de colección de mapas de Java Mapa de calles de la ciudad de Indonesia,... Hibernate simplifica el mapeo de herencia www.oracle.com/technology/... www.maps2anywhere.com/Maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Mapa de Java Mapas de Indonesia jerarquía de clases de tmap 30.map www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 ONJava.com: Mapa de API de Java Mapas de Indonesia por Peter Loud Alcance de clases www.onjava.com/pub/a/onjava/api map/ users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/Scope.html 9 GTA San Andreas: Mapas de Sam de Indonesia por Peter Loud PrintSafeHashMap de la clase www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 TURISMO DE INDONESIA: JAVA OESTE - MAPA indonesiaphoto.com Java Pro - Unión y mapeo vertical de clases www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Tabla 1: Resultados de muestra de la expansión de la consulta EVALUACIÓN DE UCAIR Ahora presentamos algunos resultados sobre la evaluación de las dos principales funciones de UCAIR: la expansión selectiva de consultas y la reordenación de resultados basada en los datos de clics de los usuarios. 5.1 Resultados de muestra La estrategia de expansión de consultas implementada en UCAIR es intencionalmente conservadora para evitar la interpretación errónea de los modelos implícitos de los usuarios. En la práctica, cada vez que decide expandir la consulta, la expansión suele tener sentido. En la Tabla 1, mostramos cómo UCAIR puede distinguir exitosamente dos contextos de búsqueda diferentes para la consulta java map, correspondientes a dos consultas previas distintas (es decir, viajar a Indonesia vs. hashtable). Debido a la modelización implícita del usuario, UCAIR descubre inteligentemente agregar Indonesia y clase, respectivamente, a la consulta de los usuarios sobre el mapa de Java, lo cual de otro modo sería ambiguo, como se muestra en los resultados originales de Google el 21 de marzo de 2005. Los resultados de UCAIR son mucho más precisos que los resultados de Google y reflejan la personalización en la búsqueda. El componente de retroalimentación implícita entusiasta está diseñado para responder inmediatamente a la actividad de un usuario, como por ejemplo, al visualizar un documento. En la Figura 2, mostramos cómo UCAIR puede desambiguar con éxito una consulta ambigua de jaguar al explotar un resumen del documento visualizado. En este caso, los resultados iniciales de recuperación utilizando \"jaguar\" (mostrados en el lado izquierdo) contienen dos resultados sobre los autos Jaguar seguidos por dos resultados sobre el software Jaguar. Sin embargo, después de que el usuario ve el contenido de la página web del segundo resultado (sobre el automóvil Jaguar) y regresa a la página de resultados de búsqueda haciendo clic en el botón Atrás, UCAIR automáticamente selecciona dos nuevos resultados de búsqueda sobre automóviles Jaguar (mostrados en el lado derecho), mientras que los dos resultados originales sobre software de Jaguar se desplazan hacia abajo en la lista (no se ven en la imagen). 5.2 Evaluación cuantitativa Para evaluar UCAIR de manera cuantitativa, realizamos un estudio de usuario sobre la efectividad del componente de retroalimentación implícita ansiosa. Es un desafío evaluar cuantitativamente la mejora potencial en el rendimiento de nuestro modelo propuesto y UCAIR sobre Google de manera imparcial [7]. Aquí diseñamos un estudio de usuarios, en el cual los participantes realizarían una búsqueda web normal y evaluarían al azar y de forma anónima un conjunto de resultados mezclados de Google y UCAIR al final de la sesión de búsqueda; los participantes no saben si un resultado proviene de Google o de UCAIR. Reclutamos a 6 estudiantes de posgrado para este estudio de usuarios, quienes tienen diferentes antecedentes (3 en informática, 2 en biología y 1 en química). Los documentos que describen leyes para limitar el correo no deseado sin dar detalles de demandas judiciales o juicios penales no son relevantes. Utilizamos los temas de consulta de la pista Terabyte TREC 2 2004 [2] y la tarea de destilación de temas de la pista web TREC 2003 [4] de la manera que se describirá a continuación. Un ejemplo de tema del TREC 2004 Terabyte track aparece en la Figura 3. El título es una frase corta y puede ser utilizada como una consulta al sistema de recuperación. El campo de descripción proporciona una declaración ligeramente más larga del requisito del tema, generalmente expresado como una sola oración completa o pregunta. Finalmente, la narrativa proporciona información adicional necesaria para especificar completamente el requisito, expresado en forma de un breve párrafo. Inicialmente, cada participante exploraría 50 temas ya sea de la categoría Terabyte o de la categoría Web y elegiría los 5 o 7 temas más interesantes. Para cada tema seleccionado, el participante básicamente realizaría la búsqueda web normal utilizando UCAIR para encontrar muchas páginas web relevantes utilizando el título del tema de la consulta como la palabra clave inicial de la consulta. Durante este proceso, el participante puede ver los resultados de la búsqueda y posiblemente hacer clic en algunos interesantes para ver las páginas web, tal como en una búsqueda web normal. No hay ningún requisito o restricción sobre cuántas consultas debe enviar el participante o cuándo debe detener la búsqueda de un tema. Cuando el participante planea cambiar el tema de búsqueda, simplemente presionará un botón 2 de la Conferencia de Recuperación de Texto: http://trec.nist.gov/ 829 Figura 2: Capturas de pantalla para volver a clasificar los resultados y evaluar los resultados de búsqueda antes de cambiar al siguiente tema. En el momento de la evaluación, los 30 resultados mejor clasificados de Google y UCAIR (algunos se superponen) se mezclan aleatoriamente para que el participante no sepa si un resultado proviene de Google o de UCAIR. El participante luego juzgaría la relevancia de estos resultados. Medimos la precisión en los primeros n (n = 5, 10, 20, 30) documentos de Google y UCAIR. También evaluamos precisiones en diferentes niveles de recuperación. En total, 368 documentos fueron considerados relevantes a partir de los resultados de búsqueda de Google y 429 documentos fueron considerados relevantes por los participantes de UCAIR. Los diagramas de dispersión de precisión en los 10 y 20 documentos principales se muestran en la Figura 4 y la Figura 5 respectivamente (El diagrama de dispersión de precisión en los 30 documentos principales es muy similar al de los 20 documentos principales). Cada punto de los gráficos de dispersión representa las precisiones de Google y UCAIR en un tema de consulta. La Tabla 2 muestra la precisión promedio en los primeros n documentos entre 32 temas. A partir de la Figura 4, la Figura 5 y la Tabla 2, vemos que los resultados de búsqueda de UCAIR son consistentemente mejores que los de Google en todas las medidas. Además, la mejora en el rendimiento es más dramática para la precisión en los primeros 20 documentos que para la precisión en los primeros 10 documentos. Una explicación para esto es que cuanto más interacción tenga el usuario con el sistema, más datos de clics se espera que UCAIR pueda recopilar. Por lo tanto, el sistema de recuperación puede construir modelos de usuario implícitos más precisos, lo que conduce a una mayor precisión en la recuperación. El Método de Clasificación prec@5 prec@10 prec@20 prec@30 Google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Mejora 8.0% 17.8% 20.2% 21.8% Tabla 2: Tabla de precisión promedio en los primeros n documentos para 32 temas de consulta El gráfico en la Figura 6 muestra las curvas de precisión-recuperación para UCAIR y Google, donde se observa claramente que el rendimiento de UCAIR 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@10 Googleprec@10 Gráfico de dispersión de Precisión en los 10 primeros documentos Figura 4: La precisión en los 10 primeros documentos de UCAIR y Google es consistentemente y considerablemente mejor que la de Google en todos los niveles de recuperación. 6. CONCLUSIONES En este artículo, estudiamos cómo aprovechar la modelización implícita del usuario para personalizar de manera inteligente la recuperación de información y mejorar la precisión de la búsqueda. A diferencia de la mayoría de trabajos anteriores, enfatizamos el uso del contexto de búsqueda inmediata y la información de retroalimentación implícita, así como la actualización rápida de los resultados de búsqueda para beneficiar al máximo a un usuario. Presentamos un marco de trabajo de toma de decisiones para optimizar la recuperación interactiva de información basado en la actualización ansiosa del modelo del usuario, en el cual el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. Además, proponemos técnicas específicas para capturar y aprovechar dos tipos de información de retroalimentación implícita: (1) identificar consultas inmediatamente anteriores relacionadas y utilizar la consulta y los resultados de búsqueda correspondientes para seleccionar términos adecuados para expandir la consulta actual, y (2) aprovechar los resúmenes de documentos vistos para volver a clasificar inmediatamente cualquier documento que aún no haya sido visto por el usuario. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente (UCAIR) sobre un motor de búsqueda popular (Google). Los experimentos en la búsqueda web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en más de un 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 UCAIR prec@20 Googleprec@20 Gráfico de dispersión de Precisión en los 20 documentos principales Figura 5: Precisión en los 20 documentos principales de UCAIR y Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 precisión recall Curvas de Precisión-Recall Resultado de Google Resultado de UCAIR Figura 6: Precisión en los 20 resultados principales de UCAIR y Google Google. Dado que la información implícita que aprovechamos ya existe de forma natural a través de las interacciones del usuario, este no necesita hacer ningún esfuerzo adicional. El agente de búsqueda desarrollado puede mejorar el rendimiento de la búsqueda web existente sin necesidad de esfuerzo adicional por parte del usuario. AGRADECIMIENTO Agradecemos a los seis participantes de nuestros experimentos de evaluación. Este trabajo fue apoyado en parte por las subvenciones de la Fundación Nacional de Ciencias IIS-0347933 e IIS-0428472. REFERENCIAS [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman y O. Frieder. Análisis por hora de un registro de consultas web muy grande categorizado por tema. En Actas de SIGIR 2004, páginas 321-328, 2004. [2] C. Clarke, N. Craswell e I. Soboroff. Resumen de la pista de terabyte TREC 2004. En Actas de TREC 2004, 2004. [3] M. Claypool, P. Le, M. Waseda y D. Brown. Indicadores implícitos de interés. En Actas de Interfaces de Usuario Inteligentes 2001, páginas 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson y M. Wu. Resumen de la pista web TREC 2003. En Actas de TREC 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend y V. Larvrenko. Retroalimentación de relevancia y personalización: Una perspectiva de modelado del lenguaje. En Actas del Segundo Taller DELOS: Personalización y Sistemas de Recomendación en Bibliotecas Digitales, 2001. [6] Google Personalized. http://labs.google.com/personalized. [7] D. Hawking, N. Craswell, P. B. Thistlewaite y D. Harman. Resultados y desafíos en la evaluación de búsqueda en la web. Redes de Computadoras, 31(11-16):1321-1330, 1999. [8] X. Huang, F. Peng, A. An, y D. Schuurmans. Identificación dinámica de sesiones de registro web con modelos de lenguaje estadístico. Revista de la Sociedad Americana de Ciencia de la Información y Tecnología, 55(14):1290-1303, 2004. [9] G. Jeh y J. Widom. Escalando la búsqueda web personalizada. En Actas de WWW 2003, páginas 271-279, 2003. [10] T. Joachims. Optimización de motores de búsqueda utilizando datos de clics. En Actas de SIGKDD 2002, páginas 133-142, 2002. [11] D. Kelly y J. Teevan. Retroalimentación implícita para inferir preferencias de usuario: Una bibliografía. SIGIR Forum, 37(2):18-28, 2003. [12] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En Actas de SIGIR01, páginas 111-119, 2001. [13] T. Lau y E. Horvitz. Patrones de búsqueda: Análisis y modelado de la refinación de consultas web. En Actas de la Séptima Conferencia Internacional sobre Modelado de Usuarios (UM), páginas 145-152, 1999. [14] V. Lavrenko y B. Croft. Modelos de lenguaje basados en relevancia. En Actas de SIGIR01, páginas 120-127, 2001. [15] M. Mitra, A. Singhal y C. Buckley. Mejorando la expansión automática de consultas. En Actas de SIGIR 1998, páginas 206-214, 1998. [16] My Yahoo! http://mysearch.yahoo.com. [17] G. Nunberg. Según Google, así va la nación. New York Times, mayo de 2003. [18] S. E. Robertson. El principio de clasificación de probabilidad en ı˚. Revista de Documentación, 33(4):294-304, 1977. [19] J. J. Rocchio. Retroalimentación de relevancia en la recuperación de información. En el Sistema de Recuperación SMART: Experimentos en el Procesamiento Automático de Documentos, páginas 313-323. Prentice-Hall Inc., 1971. [20] G. Salton y C. Buckley. Mejorando el rendimiento de recuperación mediante retroalimentación de recuperación. Revista de la Sociedad Americana de Ciencia de la Información, 41(4):288-297, 1990. [21] G. Salton y M. J. McGill. Introducción a la Recuperación de Información Moderna. McGraw-Hill, 1983. [22] X. Shen, B. Tan y C. Zhai. Recuperación de información sensible al contexto utilizando retroalimentación implícita. En Actas de SIGIR 2005, páginas 43-50, 2005. [23] X. Shen y C. Zhai. Explotando el historial de consultas para la clasificación de documentos en la recuperación de información interactiva (Póster). En Actas de SIGIR 2003, páginas 377-378, 2003. [24] A. Singhal. Recuperación de información moderna: Una breve visión general. Boletín del Comité Técnico de Ingeniería de Datos de la Sociedad de Computación de IEEE, 24(4):35-43, 2001. [25] K. Sugiyama, K. Hatano y M. Yoshikawa. Búsqueda web adaptativa basada en el perfil del usuario construido sin ningún esfuerzo por parte de los usuarios. En Actas de WWW 2004, páginas 675-684, 2004. [26] E. Volokh. Personalización y privacidad. Comunicaciones de la ACM, 43(8):84-88, 2000. [27] R. W. White, J. M. Jose, C. J. van Rijsbergen e I. Ruthven. Un estudio simulado de modelos de retroalimentación implícita. En Actas de ECIR 2004, páginas 311-326, 2004. [28] J. Xu y W. B. Croft. Expansión de consultas utilizando análisis local y global de documentos. En Actas de SIGIR 1996, páginas 4-11, 1996. [29] C. Zhai y J. Lafferty. Modelo de retroalimentación basado en el modelo de recuperación de divergencia de KL. En Actas de la CIKM 2001, páginas 403-410, 2001. 831 ",
            "candidates": [],
            "error": [
                [
                    "recuperación interactiva",
                    "proceso interactivo de recuperación"
                ]
            ]
        }
    }
}