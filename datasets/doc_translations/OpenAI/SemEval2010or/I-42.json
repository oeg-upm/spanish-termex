{
    "id": "I-42",
    "original_text": "A Complete Distributed Constraint Optimization Method For Non-Traditional Pseudotree Arrangements∗ James Atlas Computer and Information Sciences University of Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Computer and Information Sciences University of Delaware Newark, DE 19716 decker@cis.udel.edu ABSTRACT Distributed Constraint Optimization (DCOP) is a general framework that can model complex problems in multi-agent systems. Several current algorithms that solve general DCOP instances, including ADOPT and DPOP, arrange agents into a traditional pseudotree structure. We introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements. Our algorithm correctly solves DCOP instances for pseudotrees that include edges between nodes in separate branches. The algorithm also solves instances with traditional pseudotree arrangements using the same procedure as DPOP. We compare our algorithm with DPOP using several metrics including the induced width of the pseudotrees, the maximum dimensionality of messages and computation, and the maximum sequential path cost through the algorithm. We prove that for some problem instances it is not possible to generate a traditional pseudotree using edge-traversal heuristics that will outperform a cross-edged pseudotree. We use multiple heuristics to generate pseudotrees and choose the best pseudotree in linear space-time complexity. For some problem instances we observe significant improvements in message and computation sizes compared to DPOP. Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent Systems General Terms Algorithms 1. INTRODUCTION Many historical problems in the AI community can be transformed into Constraint Satisfaction Problems (CSP). With the advent of distributed AI, multi-agent systems became a popular way to model the complex interactions and coordination required to solve distributed problems. CSPs were originally extended to distributed agent environments in [9]. Early domains for distributed constraint satisfaction problems (DisCSP) included job shop scheduling [1] and resource allocation [2]. Many domains for agent systems, especially teamwork coordination, distributed scheduling, and sensor networks, involve overly constrained problems that are difficult or impossible to satisfy for every constraint. Recent approaches to solving problems in these domains rely on optimization techniques that map constraints into multi-valued utility functions. Instead of finding an assignment that satisfies all constraints, these approaches find an assignment that produces a high level of global utility. This extension to the original DisCSP approach has become popular in multi-agent systems, and has been labeled the Distributed Constraint Optimization Problem (DCOP) [1]. Current algorithms that solve complete DCOPs use two main approaches: search and dynamic programming. Search based algorithms that originated from DisCSP typically use some form of backtracking [10] or bounds propagation, as in ADOPT [3]. Dynamic programming based algorithms include DPOP and its extensions [5, 6, 7]. To date, both categories of algorithms arrange agents into a traditional pseudotree to solve the problem. It has been shown in [6] that any constraint graph can be mapped into a traditional pseudotree. However, it was also shown that finding the optimal pseudotree was NP-Hard. We began to investigate the performance of traditional pseudotrees generated by current edge-traversal heuristics. We found that these heuristics often produced little parallelism as the pseudotrees tended to have high depth and low branching factors. We suspected that there could be other ways to arrange the pseudotrees that would provide increased parallelism and smaller message sizes. After exploring these other arrangements we found that cross-edged pseudotrees provide shorter depths and higher branching factors than the traditional pseudotrees. Our hypothesis was that these crossedged pseudotrees would outperform traditional pseudotrees for some problem types. In this paper we introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements which include cross-edged pseudotrees. We begin with a definition of 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, traditional pseudotrees, and cross-edged pseudotrees. We then provide a summary of the original DPOP algorithm and introduce our DCPOP algorithm. We discuss the complexity of our algorithm as well as the impact of pseudotree generation heuristics. We then show that our Distributed Cross-edged Pseudotree Optimization Procedure (DCPOP) performs significantly better in practice than the original DPOP algorithm for some problem instances. We conclude with a selection of ideas for future work and extensions for DCPOP. 2. PROBLEM DEFINITION DCOP has been formalized in slightly different ways in recent literature, so we will adopt the definition as presented in [6]. A Distributed Constraint Optimization Problem with n nodes and m constraints consists of the tuple < X, D, U > where: • X = {x1,..,xn} is a set of variables, each one assigned to a unique agent • D = {d1,..,dn} is a set of finite domains for each variable • U = {u1,..,um} is a set of utility functions such that each function involves a subset of variables in X and defines a utility for each combination of values among these variables An optimal solution to a DCOP instance consists of an assignment of values in D to X such that the sum of utilities in U is maximal. Problem domains that require minimum cost instead of maximum utility can map costs into negative utilities. The utility functions represent soft constraints but can also represent hard constraints by using arbitrarily large negative values. For this paper we only consider binary utility functions involving two variables. Higher order utility functions can be modeled with minor changes to the algorithm, but they also substantially increase the complexity. 2.1 Traditional Pseudotrees Pseudotrees are a common structure used in search procedures to allow parallel processing of independent branches. As defined in [6], a pseudotree is an arrangement of a graph G into a rooted tree T such that vertices in G that share an edge are in the same branch in T. A back-edge is an edge between a node X and any node which lies on the path from X to the root (excluding Xs parent). Figure 1 shows a pseudotree with four nodes, three edges (A-B, B-C, BD), and one back-edge (A-C). Also defined in [6] are four types of relationships between nodes exist in a pseudotree: • P(X) - the parent of a node X: the single node higher in the pseudotree that is connected to X directly through a tree edge • C(X) - the children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through tree edges • PP(X) - the pseudo-parents of a node X: the set of nodes higher in the pseudotree that are connected to X directly through back-edges (In Figure 1, A = PP(C)) • PC(X) - the pseudo-children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through back-edges (In Figure 1, C = PC(A)) Figure 1: A traditional pseudotree. Solid line edges represent parent-child relationships and the dashed line represents a pseudo-parent-pseudo-child relationship. Figure 2: A cross-edged pseudotree. Solid line edges represent parent-child relationships, the dashed line represents a pseudoparent-pseudo-child relationship, and the dotted line represents a branch-parent-branch-child relationship. The bolded node, B, is the merge point for node E. 2.2 Cross-edged Pseudotrees We define a cross-edge as an edge from node X to a node Y that is above X but not in the path from X to the root. A cross-edged pseudotree is a traditional pseudotree with the addition of cross-edges. Figure 2 shows a cross-edged pseudotree with a cross-edge (D-E). In a cross-edged pseudotree we designate certain edges as primary. The set of primary edges defines a spanning tree of the nodes. The parent, child, pseudo-parent, and pseudo-child relationships from the traditional pseudotree are now defined in the context of this primary edge spanning tree. This definition also yields two additional types of relationships that may exist between nodes: • BP(X) - the branch-parents of a node X: the set of nodes higher in the pseudotree that are connected to X but are not in the primary path from X to the root (In Figure 2, D = BP(E)) • BC(X) - the branch-children of a node X: the set of nodes lower in the pseudotree that are connected to X but are not in any primary path from X to any leaf node (In Figure 2, E = BC(D)) 2.3 Pseudotree Generation 742 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Current algorithms usually have a pre-execution phase to generate a traditional pseudotree from a general DCOP instance. Our DCPOP algorithm generates a cross-edged pseudotree in the same fashion. First, the DCOP instance < X, D, U > translates directly into a graph with X as the set of vertices and an edge for each pair of variables represented in U. Next, various heuristics are used to arrange this graph into a pseudotree. One common heuristic is to perform a guided depth-first search (DFS) as the resulting traversal is a pseudotree, and a DFS can easily be performed in a distributed fashion. We define an edge-traversal based method as any method that produces a pseudotree in which all parent/child pairs share an edge in the original graph. This includes DFS, breadth-first search, and best-first search based traversals. Our heuristics that generate cross-edged pseudotrees use a distributed best-first search traversal. 3. DPOP ALGORITHM The original DPOP algorithm operates in three main phases. The first phase generates a traditional pseudotree from the DCOP instance using a distributed algorithm. The second phase joins utility hypercubes from children and the local node and propagates them towards the root. The third phase chooses an assignment for each domain in a top down fashion beginning with the agent at the root node. The complexity of DPOP depends on the size of the largest computation and utility message during phase two. It has been shown that this size directly corresponds to the induced width of the pseudotree generated in phase one [6]. DPOP uses polynomial time heuristics to generate the pseudotree since finding the minimum induced width pseudotree is NP-hard. Several distributed edgetraversal heuristics have been developed to find low width pseudotrees [8]. At the end of the first phase, each agent knows its parent, children, pseudo-parents, and pseudo-children. 3.1 Utility Propagation Agents located at leaf nodes in the pseudotree begin the process by calculating a local utility hypercube. This hypercube at node X contains summed utilities for each combination of values in the domains for P(X) and PP(X). This hypercube has dimensional size equal to the number of pseudo-parents plus one. A message containing this hypercube is sent to P(X). Agents located at non-leaf nodes wait for all messages from children to arrive. Once the agent at node Y has all utility messages, it calculates its local utility hypercube which includes domains for P(Y), PP(Y), and Y. The local utility hypercube is then joined with all of the hypercubes from the child messages. At this point all utilities involving node Y are known, and the domain for Y may be safely eliminated from the joined hypercube. This elimination process chooses the best utility over the domain of Y for each combination of the remaining domains. A message containing this hypercube is now sent to P(Y). The dimensional size of this hypercube depends on the number of overlapping domains in received messages and the local utility hypercube. This dynamic programming based propagation phase continues until the agent at the root node of the pseudotree has received all messages from its children. 3.2 Value Propagation Value propagation begins when the agent at the root node Z has received all messages from its children. Since Z has no parents or pseudo-parents, it simply combines the utility hypercubes received from its children. The combined hypercube contains only values for the domain for Z. At this point the agent at node Z simply chooses the assignment for its domain that has the best utility. A value propagation message with this assignment is sent to each node in C(Z). Each other node then receives a value propagation message from its parent and chooses the assignment for its domain that has the best utility given the assignments received in the message. The node adds its domain assignment to the assignments it received and passes the set of assignments to its children. The algorithm is complete when all nodes have chosen an assignment for their domain. 4. DCPOP ALGORITHM Our extension to the original DPOP algorithm, shown in Algorithm 1, shares the same three phases. The first phase generates the cross-edged pseudotree for the DCOP instance. The second phase merges branches and propagates the utility hypercubes. The third phase chooses assignments for domains at branch merge points and in a top down fashion, beginning with the agent at the root node. For the first phase we generate a pseudotree using several distributed heuristics and select the one with lowest overall complexity. The complexity of the computation and utility message size in DCPOP does not directly correspond to the induced width of the cross-edged pseudotree. Instead, we use a polynomial time method for calculating the maximum computation and utility message size for a given cross-edged pseudotree. A description of this method and the pseudotree selection process appears in Section 5. At the end of the first phase, each agent knows its parent, children, pseudo-parents, pseudo-children, branch-parents, and branch-children. 4.1 Merging Branches and Utility Propagation In the original DPOP algorithm a node X only had utility functions involving its parent and its pseudo-parents. In DCPOP, a node X is allowed to have a utility function involving a branch-parent. The concept of a branch can be seen in Figure 2 with node E representing our node X. The two distinct paths from node E to node B are called branches of E. The single node where all branches of E meet is node B, which is called the merge point of E. Agents with nodes that have branch-parents begin by sending a utility propagation message to each branch-parent. This message includes a two dimensional utility hypercube with domains for the node X and the branch-parent BP(X). It also includes a branch information structure which contains the origination node of the branch, X, the total number of branches originating from X, and the number of branches originating from X that are merged into a single representation by this branch information structure (this number starts at 1). Intuitively when the number of merged branches equals the total number of originating branches, the algorithm has reached the merge point for X. In Figure 2, node E sends a utility propagation message to its branch-parent, node D. This message has dimensions for the domains of E and D, and includes branch information with an origin of E, 2 total branches, and 1 merged branch. As in the original DPOP utility propagation phase, an agent at leaf node X sends a utility propagation message to its parent. In DCPOP this message contains dimensions for the domains of P(X) and PP(X). If node X also has branch-parents, then the utility propagation message also contains a dimension for the domain of X, and will include a branch information structure. In Figure 2, node E sends a utility propagation message to its parent, node C. This message has dimensions for the domains of E and C, and includes branch information with an origin of E, 2 total branches, and 1 merged branch. When a node Y receives utility propagation messages from all of The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 743 its children and branch-children, it merges any branches with the same origination node X. The merged branch information structure accumulates the number of merged branches for X. If the cumulative total number of merged branches equals the total number of branches, then Y is the merge point for X. This means that the utility hypercubes present at Y contain all information about the valuations for utility functions involving node X. In addition to the typical elimination of the domain of Y from the utility hypercubes, we can now safely eliminate the domain of X from the utility hypercubes. To illustrate this process, we will examine what happens in the second phase for node B in Figure 2. In the second phase Node B receives two utility propagation messages. The first comes from node C and includes dimensions for domains E, B, and A. It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch. The second comes from node D and includes dimensions for domains E and B. It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch. Node B then merges the branch information structures from both messages because they have the same origination, node E. Since the number of merged branches originating from E is now 2 and the total branches originating from E is 2, node B now eliminates the dimensions for domain E. Node B also eliminates the dimension for its own domain, leaving only information about domain A. Node B then sends a utility propagation message to node A, containing only one dimension for the domain of A. Although not possible in DPOP, this method of utility propagation and dimension elimination may produce hypercubes at node Y that do not share any domains. In DCPOP we do not join domain independent hypercubes, but instead may send multiple hypercubes in the utility propagation message sent to the parent of Y. This lazy approach to joins helps to reduce message sizes. 4.2 Value Propagation As in DPOP, value propagation begins when the agent at the root node Z has received all messages from its children. At this point the agent at node Z chooses the assignment for its domain that has the best utility. If Z is the merge point for the branches of some node X, Z will also choose the assignment for the domain of X. Thus any node that is a merge point will choose assignments for a domain other than its own. These assignments are then passed down the primary edge hierarchy. If node X in the hierarchy has branch-parents, then the value assignment message from P(X) will contain an assignment for the domain of X. Every node in the hierarchy adds any assignments it has chosen to the ones it received and passes the set of assignments to its children. The algorithm is complete when all nodes have chosen or received an assignment for their domain. 4.3 Proof of Correctness We will prove the correctness of DCPOP by first noting that DCPOP fully extends DPOP and then examining the two cases for value assignment in DCPOP. Given a traditional pseudotree as input, the DCPOP algorithm execution is identical to DPOP. Using a traditional pseudotree arrangement no nodes have branch-parents or branch-children since all edges are either back-edges or tree edges. Thus the DCPOP algorithm using a traditional pseudotree sends only utility propagation messages that contain domains belonging to the parent or pseudo-parents of a node. Since no node has any branch-parents, no branches exist, and thus no node serves as a merge point for any other node. Thus all value propagation assignments are chosen at the node of the assignment domain. For DCPOP execution with cross-edged pseudotrees, some nodes serve as merge points. We note that any node X that is not a merge point assigns its value exactly as in DPOP. The local utility hypercube at X contains domains for X, P(X), PP(X), and BC(X). As in DPOP the value assignment message received at X includes the values assigned to P(X) and PP(X). Also, since X is not a merge point, all assignments to BC(X) must have been calculated at merge points higher in the tree and are in the value assignment message from P(X). Thus after eliminating domains for which assignments are known, only the domain of X is left. The agent at node X can now correctly choose the assignment with maximum utility for its own domain. If node X is a merge point for some branch-child Y, we know that X must be a node along the path from Y to the root, and from P(Y) and all BP(Y) to the root. From the algorithm, we know that Y necessarily has all information from C(Y), PC(Y), and BC(Y) since it waits for their messages. Node X has information about all nodes below it in the tree, which would include Y, P(Y), BP(Y), and those PP(Y) that are below X in the tree. For any PP(Y) above X in the tree, X receives the assignment for the domain of PP(Y) in the value assignment message from P(X). Thus X has utility information about all of the utility functions of which Y is a part. By eliminating domains included in the value assignment message, node X is left with a local utility hypercube with domains for X and Y. The agent at node X can now correctly choose the assignments with maximum utility for the domains of X and Y. 4.4 Complexity Analysis The first phase of DCPOP sends one message to each P(X), PP(X), and BP(X). The second phase sends one value assignment message to each C(X). Thus, DCPOP produces a linear number of messages with respect to the number of edges (utility functions) in the cross-edged pseudotree and the original DCOP instance. The actual complexity of DCPOP depends on two additional measurements: message size and computation size. Message size and computation size in DCPOP depend on the number of overlapping branches as well as the number of overlapping back-edges. It was shown in [6] that the number of overlapping back-edges is equal to the induced width of the pseudotree. In a poorly constructed cross-edged pseudotree, the number of overlapping branches at node X can be as large as the total number of descendants of X. Thus, the total message size in DCPOP in a poorly constructed instance can be space-exponential in the total number of nodes in the graph. However, in practice a well constructed cross-edged pseudotree can achieve much better results. Later we address the issue of choosing well constructed crossedged pseudotrees from a set. We introduce an additional measurement of the maximum sequential path cost through the algorithm. This measurement directly relates to the maximum amount of parallelism achievable by the algorithm. To take this measurement we first store the total computation size for each node during phase two and three. This computation size represents the number of individual accesses to a value in a hypercube at each node. For example, a join between two domains of size 4 costs 4 ∗ 4 = 16. Two directed acyclic graphs (DAG) can then be drawn; one with the utility propagation messages as edges and the phase two costs at nodes, and the other with value assignment messages and the phase three costs at nodes. The maximum sequential path cost is equal to the sum of the longest path on each DAG from the root to any leaf node. 5. HEURISTICS In our assessment of complexity in DCPOP we focused on the worst case possibly produced by the algorithm. We acknowledge 744 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Algorithm 1 DCPOP Algorithm 1: DCPOP(X; D; U) Each agent Xi executes: Phase 1: pseudotree creation 2: elect leader from all Xj ∈ X 3: elected leader initiates pseudotree creation 4: afterwards, Xi knows P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) and PC(Xi) Phase 2: UTIL message propagation 5: if |BP(Xi)| > 0 then 6: BRANCHXi ← |BP(Xi)| + 1 7: for all Xk ∈BP(Xi) do 8: UTILXi (Xk) ←Compute utils(Xi, Xk) 9: Send message(Xk,UTILXi (Xk),BRANCHXi ) 10: if |C(Xi)| = 0(i.e. Xi is a leaf node) then 11: UTILXi (P(Xi)) ← Compute utils(P(Xi),PP(Xi)) for all PP(Xi) 12: Send message(P(Xi), UTILXi (P(Xi)),BRANCHXi ) 13: Send message(PP(Xi), empty UTIL, empty BRANCH) to all PP(Xi) 14: activate UTIL Message handler() Phase 3: VALUE message propagation 15: activate VALUE Message handler() END ALGORITHM UTIL Message handler(Xk,UTILXk (Xi), BRANCHXk ) 16: store UTILXk (Xi),BRANCHXk (Xi) 17: if UTIL messages from all children and branch children arrived then 18: for all Bj ∈BRANCH(Xi) do 19: if Bj is merged then 20: join all hypercubes where Bj ∈UTIL(Xi) 21: eliminate Bj from the joined hypercube 22: if P(Xi) == null (that means Xi is the root) then 23: v ∗ i ← Choose optimal(null) 24: Send VALUE(Xi, v ∗ i) to all C(Xi) 25: else 26: UTILXi (P(Xi)) ← Compute utils(P(Xi), PP(Xi)) 27: Send message(P(Xi),UTILXi (P(Xi)), BRANCHXi (P(Xi))) VALUE Message handler(VALUEXi ,P(Xi)) 28: add all Xk ← v ∗ k ∈VALUEXi ,P(Xi) to agent view 29: Xi ← v ∗ i =Choose optimal(agent view) 30: Send VALUEXl , Xi to all Xl ∈C(Xi) that in real world problems the generation of the pseudotree has a significant impact on the actual performance. The problem of finding the best pseudotree for a given DCOP instance is NP-Hard. Thus a heuristic is used for generation, and the performance of the algorithm depends on the pseudotree found by the heuristic. Some previous research focused on finding heuristics to generate good pseudotrees [8]. While we have developed some heuristics that generate good cross-edged pseudotrees for use with DCPOP, our focus has been to use multiple heuristics and then select the best pseudotree from the generated pseudotrees. We consider only heuristics that run in polynomial time with respect to the number of nodes in the original DCOP instance. The actual DCPOP algorithm has worst case exponential complexity, but we can calculate the maximum message size, computation size, and sequential path cost for a given cross-edged pseudotree in linear space-time complexity. To do this, we simply run the algorithm without attempting to calculate any of the local utility hypercubes or optimal value assignments. Instead, messages include dimensional and branch information but no utility hypercubes. After each heuristic completes its generation of a pseudotree, we execute the measurement procedure and propagate the measurement information up to the chosen root in that pseudotree. The root then broadcasts the total complexity for that heuristic to all nodes. After all heuristics have had a chance to complete, every node knows which heuristic produced the best pseudotree. Each node then proceeds to begin the DCPOP algorithm using its knowledge of the pseudotree generated by the best heuristic. The heuristics used to generate traditional pseudotrees perform a distributed DFS traversal. The general distributed algorithm uses a token passing mechanism and a linear number of messages. Improved DFS based heuristics use a special procedure to choose the root node, and also provide an ordering function over the neighbors of a node to determine the order of path recursion. The DFS based heuristics used in our experiments come from the work done in [4, 8]. 5.1 The best-first cross-edged pseudotree heuristic The heuristics used to generate cross-edged pseudotrees perform a best-first traversal. A general distributed best-first algorithm for node expansion is presented in Algorithm 2. An evaluation function at each node provides the values that are used to determine the next best node to expand. Note that in this algorithm each node only exchanges its best value with its neighbors. In our experiments we used several evaluation functions that took as arguments an ordered list of ancestors and a node, which contains a list of neighbors (with each neighbors placement depth in the tree if it was placed). From these we can calculate branchparents, branch-children, and unknown relationships for a potential node placement. The best overall function calculated the value as ancestors−(branchparents+branchchildren) with the number of unknown relationships being a tiebreak. After completion each node has knowledge of its parent and ancestors, so it can easily determine which connected nodes are pseudo-parents, branchparents, pseudo-children, and branch-children. The complexity of the best-first traversal depends on the complexity of the evaluation function. Assuming a complexity of O(V ) for the evaluation function, which is the case for our best overall function, the best-first traversal is O(V · E) which is at worst O(n3 ). For each v ∈ V we perform a place operation, and find the next node to place using the getBestNeighbor operation. The place operation is at most O(V ) because of the sent messages. Finding the next node uses recursion and traverses only already placed The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 745 Algorithm 2 Distributed Best-First Search Algorithm root ← electedleader next(root, ∅) place(node, parent) node.parent ← parent node.ancestors ← parent.ancestors ∪ parent send placement message (node, node.ancestors) to all neighbors of node next(current, previous) if current is not placed then place(current, previous) next(current, ∅) else best ← getBestNeighbor(current, previous) if best = ∅ then if previous = ∅ then terminate, all nodes are placed next(previous, ∅) else next(best, current) getBestNeighbor(current, previous) best ← ∅; score ← 0 for all n ∈ current.neighbors do if n! = previous then if n is placed then nscore ← getBestNeighbor(n, current) else nscore ← evaluate(current, n) if nscore > score then score ← nscore best ← n return best, score nodes, so it has O(V ) recursions. Each recursion performs a recursive getBestNeighbor operation that traverses all placed nodes and their neighbors. This operation is O(V · E), but results can be cached using only O(V ) space at each node. Thus we have O(V ·(V +V +V ·E)) = O(V 2 ·E). If we are smart about evaluating local changes when each node receives placement messages from its neighbors and cache the results the getBestNeighbor operation is only O(E). This increases the complexity of the place operation, but for all placements the total complexity is only O(V · E). Thus we have an overall complexity of O(V ·E+V ·(V +E)) = O(V ·E). 6. COMPARISON OF COMPLEXITY IN DPOP AND DCPOP We have already shown that given the same input, DCPOP performs the same as DPOP. We also have shown that we can accurately predict performance of a given pseudotree in linear spacetime complexity. If we use a constant number of heuristics to generate the set of pseudotrees, we can choose the best pseudotree in linear space-time complexity. We will now show that there exists a DCOP instance for which a cross-edged pseudotree outperforms all possible traditional pseudotrees (based on edge-traversal heuristics). In Figure 3(a) we have a DCOP instance with six nodes. This is a bipartite graph with each partition fully connected to the other (a) (b) (c) Figure 3: (a) The DCOP instance (b) A traditional pseudotree arrangement for the DCOP instance (c) A cross-edged pseudotree arrangement for the DCOP instance partition. In Figure 3(b) we see a traditional pseudotree arrangement for this DCOP instance. It is easy to see that any edgetraversal based heuristic cannot expand two nodes from the same partition in succession. We also see that no node can have more than one child because any such arrangement would be an invalid pseudotree. Thus any traditional pseudotree arrangement for this DCOP instance must take the form of Figure 3(b). We can see that the back-edges F-B and F-A overlap node C. Node C also has a parent E, and a back-edge with D. Using the original DPOP algorithm (or DCPOP since they are identical in this case), we find that the computation at node C involves five domains: A, B, C, D, and E. In contrast, the cross-edged pseudotree arrangement in Figure 3(c) requires only a maximum of four domains in any computation during DCPOP. Since node A is the merge point for branches from both B and C, we can see that each of the nodes D, E, and F have two overlapping branches. In addition each of these nodes has node A as its parent. Using the DCPOP algorithm we find that the computation at node D (or E or F) involves four domains: A, B, C, and D (or E or F). Since no better traditional pseudotree arrangement can be created using an edge-traversal heuristic, we have shown that DCPOP can outperform DPOP even if we use the optimal pseudotree found through edge-traversal. We acknowledge that pseudotree arrangements that allow parent-child relationships without an actual constraint can solve the problem in Figure 3(a) with maximum computation size of four domains. However, current heuristics used with DPOP do not produce such pseudotrees, and such a heuristic would be difficult to distribute since each node would require information about nodes with which it has no constraint. Also, while we do not prove it here, cross-edged pseudotrees can produce smaller message sizes than such pseudotrees even if the computation size is similar. In practice, since finding the best pseudotree arrangement is NP-Hard, we find that heuristics that produce cross-edged pseudotrees often produce significantly smaller computation and message sizes. 7. EXPERIMENTAL RESULTS 746 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Existing performance metrics for DCOP algorithms include the total number of messages, synchronous clock cycles, and message size. We have already shown that the total number of messages is linear with respect to the number of constraints in the DCOP instance. We also introduced the maximum sequential path cost (PC) as a measurement of the maximum amount of parallelism achievable by the algorithm. The maximum sequential path cost is equal to the sum of the computations performed on the longest path from the root to any leaf node. We also include as metrics the maximum computation size in number of dimensions (CD) and maximum message size in number of dimensions (MD). To analyze the relative complexity of a given DCOP instance, we find the minimum induced width (IW) of any traditional pseudotree produced by a heuristic for the original DPOP. 7.1 Generic DCOP instances For our initial tests we randomly generated two sets of problems with 3000 cases in each. Each problem was generated by assigning a random number (picked from a range) of constraints to each variable. The generator then created binary constraints until each variable reached its maximum number of constraints. The first set uses 20 variables, and the best DPOP IW ranges from 1 to 16 with an average of 8.5. The second set uses 100 variables, and the best DPOP IW ranged from 2 to 68 with an average of 39.3. Since most of the problems in the second set were too complex to actually compute the solution, we took measurements of the metrics using the techniques described earlier in Section 5 without actually solving the problem. Results are shown for the first set in Table 1 and for the second set in Table 2. For the two problem sets we split the cases into low density and high density categories. Low density cases consist of those problems that have a best DPOP IW less than or equal to half of the total number of nodes (e.g. IW ≤ 10 for the 20 node problems and IW ≤ 50 for the 100 node problems). High density problems consist of the remainder of the problem sets. In both Table 1 and Table 2 we have listed performance metrics for the original DPOP algorithm, the DCPOP algorithm using only cross-edged pseudotrees (DCPOP-CE), and the DCPOP algorithm using traditional and cross-edged pseudotrees (DCPOP-All). The pseudotrees used for DPOP were generated using 5 heuristics: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB, and DFS MCN BEC. These are all versions of the guided DFS traversal discussed in Section 5. The cross-edged pseudotrees used for DCPOP-CE were generated using 5 heuristics: MCN, LCN, MCN A-B, LCN A-B, and LCSG A-B. These are all versions of the best-first traversal discussed in Section 5. For both DPOP and DCPOP-CE we chose the best pseudotree produced by their respective 5 heuristics for each problem in the set. For DCPOP-All we chose the best pseudotree produced by all 10 heuristics for each problem in the set. For the CD and MD metrics the value shown is the average number of dimensions. For the PC metric the value shown is the natural logarithm of the maximum sequential path cost (since the actual value grows exponentially with the complexity of the problem). The final row in both tables is a measurement of improvement of DCPOP-All over DPOP. For the CD and MD metrics the value shown is a reduction in number of dimensions. For the PC metric the value shown is a percentage reduction in the maximum sequential path cost (% = DP OP −DCP OP DCP OP ∗ 100). Notice that DCPOPAll outperforms DPOP on all metrics. This logically follows from our earlier assertion that given the same input, DCPOP performs exactly the same as DPOP. Thus given the choice between the pseudotrees produced by all 10 heuristics, DCPOP-All will always outLow Density High Density Algorithm CD MD PC CD MD PC DPOP 7.81 6.81 3.78 13.34 12.34 5.34 DCPOP-CE 7.94 6.73 3.74 12.83 11.43 5.07 DCPOP-All 7.62 6.49 3.66 12.72 11.36 5.05 Improvement 0.18 0.32 13% 0.62 0.98 36% Table 1: 20 node problems Low Density High Density Algorithm CD MD PC CD MD PC DPOP 33.35 32.35 14.55 58.51 57.50 19.90 DCPOP-CE 33.49 29.17 15.22 57.11 50.03 20.01 DCPOP-All 32.35 29.57 14.10 56.33 51.17 18.84 Improvement 1.00 2.78 104% 2.18 6.33 256% Table 2: 100 node problems Figure 4: Computation Dimension Size Figure 5: Message Dimension Size The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 747 Figure 6: Path Cost DCPOP Improvement Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Table 3: Meeting Scheduling Problems perform DPOP. Another trend we notice is that the improvement is greater for high density problems than low density problems. We show this trend in greater detail in Figures 4, 5, and 6. Notice how the improvement increases as the complexity of the problem increases. 7.2 Meeting Scheduling Problem In addition to our initial generic DCOP tests, we ran a series of tests on the Meeting Scheduling Problem (MSP) as described in [6]. The problem setup includes a number of people that are grouped into departments. Each person must attend a specified number of meetings. Meetings can be held within departments or among departments, and can be assigned to one of eight time slots. The MSP maps to a DCOP instance where each variable represents the time slot that a specific person will attend a specific meeting. All variables that belong to the same person have mutual exclusion constraints placed so that the person cannot attend more than one meeting during the same time slot. All variables that belong to the same meeting have equality constraints so that all of the participants choose the same time slot. Unary constraints are placed on each variable to account for a persons valuation of each meeting and time slot. For our tests we generated 100 sample problems for each combination of agents and meetings. Results are shown in Table 3. The values in the first five columns represent (in left to right order), the total number of agents, the total number of meetings, the total number of variables, the average total number of constraints, and the average minimum IW produced by a traditional pseudotree. The last three columns show the same metrics we used for the generic DCOP instances, except this time we only show the improvements of DCPOP-All over DPOP. Performance is better on average for all MSP instances, but again we see larger improvements for more complex problem instances. 8. CONCLUSIONS AND FUTURE WORK We presented a complete, distributed algorithm that solves general DCOP instances using cross-edged pseudotree arrangements. Our algorithm extends the DPOP algorithm by adding additional utility propagation messages, and introducing the concept of branch merging during the utility propagation phase. Our algorithm also allows value assignments to occur at higher level merge points for lower level nodes. We have shown that DCPOP fully extends DPOP by performing the same operations given the same input. We have also shown through some examples and experimental data that DCPOP can achieve greater performance for some problem instances by extending the allowable input set to include cross-edged pseudotrees. We placed particular emphasis on the role that edge-traversal heuristics play in the generation of pseudotrees. We have shown that the performance penalty is minimal to generate multiple heuristics, and that we can choose the best generated pseudotree in linear space-time complexity. Given the importance of a good pseudotree for performance, future work will include new heuristics to find better pseudotrees. Future work will also include adapting existing DPOP extensions [5, 7] that support different problem domains for use with DCPOP. 9. REFERENCES [1] J. Liu and K. P. Sycara. Exploiting problem structure for distributed constraint optimization. In V. Lesser, editor, Proceedings of the First International Conference on Multi-Agent Systems, pages 246-254, San Francisco, CA, 1995. MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni. A dynamic distributed constraint satisfaction approach to resource allocation. Lecture Notes in Computer Science, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe, and M. Yokoo. An asynchronous complete method for distributed constraint optimization. In AAMAS 03, 2003. [4] A. Petcu. Frodo: A framework for open/distributed constraint optimization. Technical Report No. 2006/001 2006/001, Swiss Federal Institute of Technology (EPFL), Lausanne (Switzerland), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu and B. Faltings. A-dpop: Approximations in distributed optimization. In poster in CP 2005, pages 802-806, Sitges, Spain, October 2005. [6] A. Petcu and B. Faltings. Dpop: A scalable method for multiagent constraint optimization. In IJCAI 05, pages 266-271, Edinburgh, Scotland, Aug 2005. [7] A. Petcu, B. Faltings, and D. Parkes. M-dpop: Faithful distributed implementation of efficient social choice problems. In AAMAS 06, pages 1397-1404, Hakodate, Japan, May 2006. [8] G. Ushakov. Solving meeting scheduling problems using distributed pseudotree-optimization procedure. Masters thesis, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara. Distributed constraint satisfaction for formalizing distributed problem solving. In International Conference on Distributed Computing Systems, pages 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara. The distributed constraint satisfaction problem: Formalization and algorithms. Knowledge and Data Engineering, 10(5):673-685, 1998. 748 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)",
    "original_translation": "Un Método Completo de Optimización de Restricciones Distribuidas para Arreglos de Pseudotree No Tradicionales∗ James Atlas Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 decker@cis.udel.edu RESUMEN La Optimización de Restricciones Distribuidas (DCOP) es un marco general que puede modelar problemas complejos en sistemas multiagente. Varios algoritmos actuales que resuelven instancias generales de DCOP, incluyendo ADOPT y DPOP, organizan a los agentes en una estructura de pseudobosque tradicional. Introducimos una extensión al algoritmo DPOP que maneja un conjunto extendido de disposiciones de pseudobosque. Nuestro algoritmo resuelve correctamente instancias de DCOP para pseudobosques que incluyen aristas entre nodos en ramas separadas. El algoritmo también resuelve instancias con arreglos de pseudobosque tradicionales utilizando el mismo procedimiento que DPOP. Comparamos nuestro algoritmo con DPOP utilizando varios métricos, incluyendo el ancho inducido de los pseudobosques, la dimensionalidad máxima de los mensajes y la computación, y el costo máximo de la ruta secuencial a través del algoritmo. Demostramos que para algunas instancias del problema no es posible generar un pseudoárbol tradicional utilizando heurísticas de recorrido de aristas que supere a un pseudoárbol con aristas cruzadas. Utilizamos múltiples heurísticas para generar pseudoárboles y elegir el mejor pseudoárbol en complejidad espacio-temporal lineal. Para algunas instancias del problema observamos mejoras significativas en los tamaños de los mensajes y cálculos en comparación con DPOP. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Algoritmos 1. INTRODUCCIÓN Muchos problemas históricos en la comunidad de IA pueden transformarse en Problemas de Satisfacción de Restricciones (CSP). Con la llegada de la inteligencia artificial distribuida, los sistemas multiagente se convirtieron en una forma popular de modelar las interacciones complejas y la coordinación necesaria para resolver problemas distribuidos. Los CSPs fueron originalmente extendidos a entornos de agentes distribuidos en [9]. Los primeros dominios para problemas de satisfacción de restricciones distribuidas (DisCSP) incluyeron la programación de talleres de trabajo [1] y la asignación de recursos [2]. Muchos dominios para sistemas de agentes, especialmente coordinación de trabajo en equipo, programación distribuida y redes de sensores, implican problemas excesivamente restringidos que son difíciles o imposibles de satisfacer para cada restricción. Los enfoques recientes para resolver problemas en estos dominios se basan en técnicas de optimización que mapean restricciones en funciones de utilidad multivaluadas. En lugar de encontrar una asignación que satisfaga todas las restricciones, estos enfoques encuentran una asignación que produce un alto nivel de utilidad global. Esta extensión al enfoque original de DisCSP se ha vuelto popular en sistemas multiagente, y ha sido etiquetada como Problema de Optimización de Restricciones Distribuidas (DCOP) [1]. Los algoritmos actuales que resuelven DCOPs completos utilizan dos enfoques principales: búsqueda y programación dinámica. Los algoritmos basados en búsqueda que se originaron a partir de DisCSP típicamente utilizan alguna forma de retroceso [10] o propagación de límites, como en ADOPT [3]. Los algoritmos basados en programación dinámica incluyen DPOP y sus extensiones [5, 6, 7]. Hasta la fecha, ambas categorías de algoritmos organizan agentes en un pseudoárbol tradicional para resolver el problema. Se ha demostrado en [6] que cualquier grafo de restricciones puede ser mapeado en un pseudoárbol tradicional. Sin embargo, también se demostró que encontrar el pseudoárbol óptimo era NP-Difícil. Comenzamos a investigar el rendimiento de los pseudobosques tradicionales generados por las heurísticas actuales de recorrido de aristas. Descubrimos que estas heurísticas a menudo generaban poco paralelismo, ya que los pseudárboles tendían a tener una gran profundidad y bajos factores de ramificación. Sospechábamos que podría haber otras formas de organizar los pseudobosques que proporcionarían un mayor paralelismo y tamaños de mensaje más pequeños. Después de explorar estos otros arreglos, descubrimos que los pseudobosques de bordes cruzados proporcionan profundidades más cortas y factores de ramificación más altos que los pseudobosques tradicionales. Nuestra hipótesis era que estos pseudorboles cruzados superarían a los pseudorboles tradicionales en algunos tipos de problemas. En este artículo presentamos una extensión al algoritmo DPOP que maneja un conjunto ampliado de disposiciones de pseudobosque que incluyen pseudobosques con aristas cruzadas. Comenzamos con una definición de 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, pseudobosques tradicionales y pseudobosques de bordes cruzados. Luego proporcionamos un resumen del algoritmo DPOP original e introducimos nuestro algoritmo DCPOP. Discutimos la complejidad de nuestro algoritmo, así como el impacto de las heurísticas de generación de pseudobosques. Luego demostramos que nuestro Procedimiento de Optimización de Pseudotree de Bordes Cruzados Distribuido (DCPOP) funciona significativamente mejor en la práctica que el algoritmo DPOP original para algunas instancias del problema. Concluimos con una selección de ideas para trabajos futuros y extensiones para DCPOP. 2. La DEFINICIÓN DEL PROBLEMA DCOP ha sido formalizada de maneras ligeramente diferentes en la literatura reciente, por lo que adoptaremos la definición presentada en [6]. Un Problema de Optimización de Restricciones Distribuidas con n nodos y m restricciones consiste en la tupla < X, D, U > donde: • X = {x1,..,xn} es un conjunto de variables, cada una asignada a un agente único • D = {d1,..,dn} es un conjunto de dominios finitos para cada variable • U = {u1,..,um} es un conjunto de funciones de utilidad tales que cada función involucra un subconjunto de variables en X y define una utilidad para cada combinación de valores entre estas variables. Una solución óptima para una instancia de DCOP consiste en una asignación de valores en D a X tal que la suma de las utilidades en U sea máxima. Los dominios de problemas que requieren un costo mínimo en lugar de una utilidad máxima pueden mapear los costos en utilidades negativas. Las funciones de utilidad representan restricciones suaves pero también pueden representar restricciones fuertes mediante el uso de valores negativos arbitrariamente grandes. Para este artículo solo consideramos funciones de utilidad binarias que involucran dos variables. Las funciones de utilidad de orden superior pueden ser modeladas con cambios menores en el algoritmo, pero también aumentan sustancialmente la complejidad. 2.1 Pseudárboles Tradicionales Los pseudárboles son una estructura común utilizada en procedimientos de búsqueda para permitir el procesamiento paralelo de ramas independientes. Como se define en [6], un pseudoárbol es un arreglo de un grafo G en un árbol raíz T de tal manera que los vértices en G que comparten una arista están en la misma rama en T. Una arista de retroceso es una arista entre un nodo X y cualquier nodo que se encuentre en el camino desde X hasta la raíz (excluyendo al padre de X). La Figura 1 muestra un pseudoárbol con cuatro nodos, tres aristas (A-B, B-C, BD) y una arista de retroceso (A-C). También se definen en [6] cuatro tipos de relaciones entre nodos que existen en un pseudoárbol: • P(X) - el padre de un nodo X: el único nodo más alto en el pseudoárbol que está conectado a X directamente a través de un borde de árbol • C(X) - los hijos de un nodo X: el conjunto de nodos más bajos en el pseudo Las líneas sólidas representan relaciones padre-hijo y la línea discontinua representa una relación pseudo-padre-pseudo-hijo. Figura 2: Un pseudoárbol de bordes cruzados. Las líneas sólidas representan relaciones padre-hijo, la línea discontinua representa una relación pseudo-padre-pseudo-hijo, y la línea punteada representa una relación rama-padre-rama-hijo. El nodo en negrita, B, es el punto de fusión para el nodo E. 2.2 Pseudárboles con aristas cruzadas Definimos una arista cruzada como una arista de un nodo X a un nodo Y que está por encima de X pero no en el camino desde X hasta la raíz. Un pseudoárbol de bordes cruzados es un pseudoárbol tradicional con la adición de bordes cruzados. La Figura 2 muestra un pseudoárbol con una arista cruzada (D-E). En un pseudoárbol de bordes cruzados designamos ciertos bordes como primarios. El conjunto de aristas primarias define un árbol de expansión de los nodos. Las relaciones de padre, hijo, pseudo-padre y pseudo-hijo del pseudotree tradicional ahora están definidas en el contexto de este árbol de expansión de borde primario. Esta definición también produce dos tipos adicionales de relaciones que pueden existir entre nodos: • BP(X) - los nodos padres de rama de un nodo X: el conjunto de nodos más altos en el pseudoárbol que están conectados a X pero no están en el camino principal desde X hasta la raíz (En la Figura 2, D = BP(E)) • BC(X) - los nodos hijos de rama de un nodo X: el conjunto de nodos más bajos en el pseudo La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Los algoritmos actuales suelen tener una fase de pre-ejecución para generar un pseudoárbol tradicional a partir de una instancia general de DCOP. Nuestro algoritmo DCPOP genera un pseudoárbol de bordes cruzados de la misma manera. Primero, la instancia DCOP < X, D, U > se traduce directamente en un grafo con X como el conjunto de vértices y una arista para cada par de variables representadas en U. A continuación, se utilizan varias heurísticas para organizar este grafo en un pseudoárbol. Un heurístico común es realizar una búsqueda en profundidad guiada (DFS, por sus siglas en inglés) ya que el recorrido resultante es un pseudoárbol, y un DFS se puede realizar fácilmente de manera distribuida. Definimos un método basado en el recorrido de aristas como cualquier método que produce un pseudoárbol en el que todos los pares padre/hijo comparten una arista en el grafo original. Esto incluye recorridos basados en DFS, búsqueda en anchura y búsqueda de mejor primero. Nuestras heurísticas que generan pseudobosques de bordes cruzados utilizan un recorrido de búsqueda mejor primero distribuido. 3. ALGORITMO DPOP El algoritmo DPOP original opera en tres fases principales. La primera fase genera un pseudoárbol tradicional a partir de la instancia de DCOP utilizando un algoritmo distribuido. La segunda fase une hipercubos de utilidad de los nodos hijos y el nodo local y los propaga hacia la raíz. La tercera fase elige una asignación para cada dominio de arriba hacia abajo, comenzando con el agente en el nodo raíz. La complejidad de DPOP depende del tamaño del cálculo más grande y del mensaje de utilidad durante la fase dos. Se ha demostrado que este tamaño corresponde directamente al ancho inducido del pseudoárbol generado en la fase uno [6]. DPOP utiliza heurísticas de tiempo polinómico para generar el pseudoárbol, ya que encontrar el pseudoárbol de ancho inducido mínimo es NP-duro. Se han desarrollado varias heurísticas de recorrido de borde distribuido para encontrar pseudobosques de ancho reducido [8]. Al final de la primera fase, cada agente conoce a su padre, hijos, pseudo-padres y pseudo-hijos. 3.1 Propagación de utilidad Los agentes ubicados en los nodos hoja del pseudoárbol comienzan el proceso calculando un hipercubo de utilidad local. Este hipercubo en el nodo X contiene las utilidades sumadas para cada combinación de valores en los dominios de P(X) y PP(X). Este hipercubo tiene un tamaño dimensional igual al número de pseudo-padres más uno. Un mensaje que contiene este hipercubo se envía a P(X). Los agentes ubicados en nodos no hoja esperan a que lleguen todos los mensajes de los nodos hijos. Una vez que el agente en el nodo Y tiene todos los mensajes de utilidad, calcula su hipercubo de utilidad local que incluye los dominios de P(Y), PP(Y) y Y. El hipercubo de utilidad local se une luego con todos los hipercubos de los mensajes hijos. En este punto, todas las utilidades que involucran al nodo Y son conocidas, y el dominio de Y puede ser eliminado de forma segura del hipercubo unido. Este proceso de eliminación elige la mejor utilidad sobre el dominio de Y para cada combinación de los dominios restantes. Un mensaje que contiene este hipercubo se envía ahora a P(Y). El tamaño dimensional de este hipercubo depende del número de dominios superpuestos en los mensajes recibidos y del hipercubo de utilidad local. Esta fase de propagación basada en programación dinámica continúa hasta que el agente en el nodo raíz del pseudoárbol haya recibido todos los mensajes de sus hijos. 3.2 Propagación de Valor La propagación de valor comienza cuando el agente en el nodo raíz Z ha recibido todos los mensajes de sus hijos. Dado que Z no tiene padres ni pseudo-padres, simplemente combina los hipercubos de utilidad recibidos de sus hijos. El hipercubo combinado contiene solo valores para el dominio de Z. En este punto, el agente en el nodo Z simplemente elige la asignación para su dominio que tiene la mejor utilidad. Un mensaje de propagación de valor con esta asignación se envía a cada nodo en C(Z). Cada nodo luego recibe un mensaje de propagación de valor de su padre y elige la asignación para su dominio que tenga la mejor utilidad dadas las asignaciones recibidas en el mensaje. El nodo agrega su asignación de dominio a las asignaciones que recibió y pasa el conjunto de asignaciones a sus hijos. El algoritmo está completo cuando todos los nodos han elegido una asignación para su dominio. ALGORITMO DCPOP Nuestra extensión al algoritmo DPOP original, mostrada en el Algoritmo 1, comparte las mismas tres fases. La primera fase genera el pseudoárbol de bordes cruzados para la instancia de DCOP. La segunda fase fusiona ramas y propaga los hipercubos de utilidad. La tercera fase elige asignaciones para dominios en los puntos de fusión de ramas y de arriba hacia abajo, comenzando con el agente en el nodo raíz. Para la primera fase generamos un pseudoárbol utilizando varios heurísticos distribuidos y seleccionamos el que tenga la menor complejidad general. La complejidad de la computación y el tamaño del mensaje de utilidad en DCPOP no corresponden directamente al ancho inducido del pseudoárbol de aristas cruzadas. En cambio, utilizamos un método de tiempo polinómico para calcular el tamaño máximo de computación y utilidad del mensaje para un pseudoárbol de bordes cruzados dado. Una descripción de este método y el proceso de selección de pseudodendrogramas aparece en la Sección 5. Al final de la primera fase, cada agente conoce a su padre, hijos, pseudo-padres, pseudo-hijos, padres de rama e hijos de rama. 4.1 Fusión de Ramas y Propagación de Utilidad En el algoritmo DPOP original, un nodo X solo tenía funciones de utilidad que involucraban a su padre y a sus pseudo-padres. En DCPOP, se permite que un nodo X tenga una función de utilidad que involucre a un padre de rama. El concepto de una rama se puede ver en la Figura 2 con el nodo E representando nuestro nodo X. Las dos rutas distintas desde el nodo E hasta el nodo B se llaman ramas de E. El único nodo donde se encuentran todas las ramas de E es el nodo B, que se llama punto de fusión de E. Los agentes con nodos que tienen padres de rama comienzan enviando un mensaje de propagación de utilidad a cada padre de rama. Este mensaje incluye un hipercubo de utilidad bidimensional con dominios para el nodo X y el nodo padre de la rama BP(X). También incluye una estructura de información de rama que contiene el nodo de origen de la rama, X, el número total de ramas que se originan en X y el número de ramas que se originan en X y se fusionan en una representación única por esta estructura de información de rama (este número comienza en 1). Intuitivamente, cuando el número de ramas fusionadas es igual al número total de ramas originales, el algoritmo ha alcanzado el punto de fusión para X. En la Figura 2, el nodo E envía un mensaje de propagación de utilidad a su nodo padre de rama, el nodo D. Este mensaje tiene dimensiones para los dominios de E y D, e incluye información de rama con un origen en E, 2 ramas totales y 1 rama fusionada. Como en la fase de propagación de utilidad de la utilidad DPOP original, un agente en el nodo hoja X envía un mensaje de propagación de utilidad a su padre. En DCPOP, este mensaje contiene dimensiones para los dominios de P(X) y PP(X). Si el nodo X también tiene padres de rama, entonces el mensaje de propagación de utilidad también contiene una dimensión para el dominio de X e incluirá una estructura de información de rama. En la Figura 2, el nodo E envía un mensaje de propagación de utilidad a su padre, el nodo C. Este mensaje tiene dimensiones para los dominios de E y C, e incluye información de rama con un origen en E, 2 ramas en total y 1 rama fusionada. Cuando un nodo Y recibe mensajes de propagación de utilidad de todos de The Sixth Intl. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), 743 sus hijos y sus hijos de rama, fusiona cualquier rama con el mismo nodo de origen X. La estructura de información de la rama fusionada acumula el número de ramas fusionadas para X. Si el número total acumulado de ramas fusionadas es igual al número total de ramas, entonces Y es el punto de fusión para X. Esto significa que los hipercubos de utilidad presentes en Y contienen toda la información sobre las valoraciones de las funciones de utilidad que involucran al nodo X. Además de la eliminación típica del dominio de Y de los hipercubos de utilidad, ahora podemos eliminar de forma segura el dominio de X de los hipercubos de utilidad. Para ilustrar este proceso, examinaremos lo que sucede en la segunda fase para el nodo B en la Figura 2. En la segunda fase, el Nodo B recibe dos mensajes de propagación de utilidad. El primero proviene del nodo C e incluye dimensiones para los dominios E, B y A. También tiene una estructura de información de ramas con origen en E, 2 ramas en total y 1 rama fusionada. El segundo proviene del nodo D e incluye dimensiones para los dominios E y B. También tiene una estructura de información de rama con origen en E, 2 ramas en total y 1 rama fusionada. El nodo B luego fusiona las estructuras de información de rama de ambos mensajes porque tienen la misma procedencia, el nodo E. Dado que el número de ramas fusionadas que provienen de E es ahora 2 y el total de ramas que provienen de E es 2, el nodo B elimina las dimensiones para el dominio E. El nodo B también elimina la dimensión para su propio dominio, dejando solo información sobre el dominio A. Luego, el nodo B envía un mensaje de propagación de utilidad al nodo A, que contiene solo una dimensión para el dominio de A. Aunque no sea posible en DPOP, este método de propagación de utilidad y eliminación de dimensiones puede producir hipercubos en el nodo Y que no comparten ningún dominio. En DCPOP no unimos hipercubos independientes de dominio, sino que en su lugar podemos enviar múltiples hipercubos en el mensaje de propagación de utilidad enviado al padre de Y. Este enfoque perezoso de las uniones ayuda a reducir el tamaño de los mensajes. 4.2 Propagación de valores Al igual que en DPOP, la propagación de valores comienza cuando el agente en el nodo raíz Z ha recibido todos los mensajes de sus hijos. En este punto, el agente en el nodo Z elige la asignación para su dominio que tiene la mejor utilidad. Si Z es el punto de fusión de las ramas de algún nodo X, Z también elegirá la asignación para el dominio de X. Por lo tanto, cualquier nodo que sea un punto de fusión elegirá asignaciones para un dominio que no sea el suyo propio. Estas tareas luego se pasan por la jerarquía de la cadena de mando principal. Si el nodo X en la jerarquía tiene padres de rama, entonces el mensaje de asignación de valor de P(X) contendrá una asignación para el dominio de X. Cada nodo en la jerarquía agrega cualquier tarea que haya elegido a las que recibió y pasa el conjunto de tareas a sus hijos. El algoritmo está completo cuando todos los nodos han elegido o recibido una asignación para su dominio. 4.3 Prueba de Corrección Demostraremos la corrección de DCPOP notando primero que DCPOP extiende completamente DPOP y luego examinando los dos casos para la asignación de valores en DCPOP. Dado un pseudoárbol tradicional como entrada, la ejecución del algoritmo DCPOP es idéntica a DPOP. Usando un arreglo de pseudodendrograma tradicional, ningún nodo tiene padres de rama o hijos de rama, ya que todas las aristas son aristas de retroceso o aristas de árbol. Por lo tanto, el algoritmo DCPOP utilizando un pseudoárbol tradicional envía solo mensajes de propagación de utilidad que contienen dominios pertenecientes al padre o pseudo-padres de un nodo. Dado que ningún nodo tiene ramas-padres, no existen ramas, y por lo tanto ningún nodo sirve como punto de fusión para ningún otro nodo. Por lo tanto, todas las asignaciones de propagación de valor se eligen en el nodo del dominio de la asignación. Para la ejecución de DCPOP con pseudárboles de bordes cruzados, algunos nodos actúan como puntos de fusión. Observamos que cualquier nodo X que no sea un punto de fusión asigna su valor exactamente como en DPOP. El hipercubo de utilidad local en X contiene dominios para X, P(X), PP(X) y BC(X). Como en DPOP, el mensaje de asignación de valores recibido en X incluye los valores asignados a P(X) y PP(X). Además, dado que X no es un punto de fusión, todas las asignaciones a BC(X) deben haber sido calculadas en puntos de fusión más altos en el árbol y están en el mensaje de asignación de valor de P(X). Por lo tanto, después de eliminar los dominios para los cuales se conocen las asignaciones, solo queda el dominio de X. El agente en el nodo X ahora puede elegir correctamente la asignación con la máxima utilidad para su propio dominio. Si el nodo X es un punto de fusión para alguna rama-hijo Y, sabemos que X debe ser un nodo a lo largo del camino desde Y hasta la raíz, y desde P(Y) y todos los BP(Y) hasta la raíz. A partir del algoritmo, sabemos que Y necesariamente tiene toda la información de C(Y), PC(Y) y BC(Y) ya que espera sus mensajes. El nodo X tiene información sobre todos los nodos debajo de él en el árbol, lo cual incluiría a Y, P(Y), BP(Y) y aquellos PP(Y) que están debajo de X en el árbol. Para cualquier PP(Y) por encima de X en el árbol, X recibe la asignación para el dominio de PP(Y) en el mensaje de asignación de valor de P(X). Por lo tanto, X tiene información de utilidad sobre todas las funciones de utilidad de las cuales Y forma parte. Al eliminar los dominios incluidos en el mensaje de asignación de valor, el nodo X se queda con un hipercubo de utilidad local con dominios para X e Y. El agente en el nodo X ahora puede elegir correctamente las asignaciones con la máxima utilidad para los dominios de X e Y. 4.4 Análisis de complejidad La primera fase de DCPOP envía un mensaje a cada P(X), PP(X) y BP(X). La segunda fase envía un mensaje de asignación de valor a cada C(X). Por lo tanto, DCPOP produce un número lineal de mensajes con respecto al número de aristas (funciones de utilidad) en el pseudoárbol de aristas cruzadas y la instancia original de DCOP. La complejidad real de DCPOP depende de dos medidas adicionales: el tamaño del mensaje y el tamaño de la computación. El tamaño del mensaje y el tamaño de la computación en DCPOP dependen del número de ramas superpuestas, así como del número de aristas de retroceso superpuestas. Se demostró en [6] que el número de aristas traslapadas es igual al ancho inducido del pseudoárbol. En un pseudoárbol de bordes cruzados mal construido, el número de ramas superpuestas en el nodo X puede ser tan grande como el número total de descendientes de X. Por lo tanto, el tamaño total del mensaje en DCPOP en una instancia mal construida puede ser exponencial en el espacio en el número total de nodos en el grafo. Sin embargo, en la práctica, un pseudoárbol bien construido con bordes cruzados puede lograr resultados mucho mejores. Más tarde abordaremos el tema de elegir pseudobosques cruzados bien construidos de un conjunto. Introducimos una medida adicional del costo máximo de la ruta secuencial a través del algoritmo. Esta medida se relaciona directamente con la cantidad máxima de paralelismo que puede lograr el algoritmo. Para tomar esta medida, primero almacenamos el tamaño total de cálculo para cada nodo durante las fases dos y tres. Este tamaño de cálculo representa el número de accesos individuales a un valor en un hipercubo en cada nodo. Por ejemplo, una unión entre dos dominios de tamaño 4 cuesta 4 ∗ 4 = 16. Dos grafos acíclicos dirigidos (DAG) pueden ser dibujados; uno con los mensajes de propagación de utilidad como aristas y los costos de la fase dos en los nodos, y el otro con los mensajes de asignación de valor y los costos de la fase tres en los nodos. El costo máximo del camino secuencial es igual a la suma del camino más largo en cada DAG desde la raíz hasta cualquier nodo hoja. HEURÍSTICAS En nuestra evaluación de la complejidad en DCPOP nos enfocamos en el peor caso posiblemente producido por el algoritmo. Reconocemos 744 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Algoritmo 1 DCPOP Algoritmo 1: DCPOP(X; D; U) Cada agente Xi ejecuta: Fase 1: creación de pseudotree 2: elegir líder de todos los Xj ∈ X 3: líder elegido inicia la creación de pseudotree 4: después, Xi conoce P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) y PC(Xi) Fase 2: propagación de mensajes UTIL 5: si |BP(Xi)| > 0 entonces 6: BRANCHXi ← |BP(Xi)| + 1 7: para todos Xk ∈BP(Xi) hacer 8: UTILXi (Xk) ← Calcular utils(Xi, Xk) 9: Enviar mensaje(Xk,UTILXi (Xk),BRANCHXi ) 10: si |C(Xi)| = 0 (es decir, Si Xi es un nodo hoja, entonces 11: UTILXi (P(Xi)) ← Calcular utils(P(Xi),PP(Xi)) para todos los PP(Xi) 12: Enviar mensaje(P(Xi), UTILXi (P(Xi)), BRANCHXi ) 13: Enviar mensaje(PP(Xi), UTIL vacío, BRANCH vacío) a todos los PP(Xi) 14: Activar el manejador de mensajes UTIL() Fase 3: Propagación de mensajes de VALOR 15: Activar el manejador de mensajes de VALOR() FIN ALGORITMO Manejador de mensajes UTIL(Xk, UTILXk (Xi), BRANCHXk ) 16: Almacenar UTILXk (Xi), BRANCHXk (Xi) 17: Si han llegado mensajes UTIL de todos los hijos y los hijos de la rama, entonces 18: Para todos los Bj ∈ BRANCH(Xi) hacer 19: Si Bj está fusionado, entonces 20: Unir todos los hipercubos donde Bj ∈ UTIL(Xi) 21: Eliminar Bj del hipercubo unido 22: Si P(Xi) == nulo (eso significa que Xi es la raíz) entonces 23: v ∗ i ← Elegir óptimo(nulo) 24: Enviar VALOR(Xi, v ∗ i) a todos los C(Xi) 25: De lo contrario 26: UTILXi (P(Xi)) ← Calcular utils(P(Xi), PP(Xi)) 27: Enviar mensaje(P(Xi), UTILXi (P(Xi)), BRANCHXi (P(Xi))) Manejador de mensajes de VALOR(VALORXi , P(Xi)) 28: Agregar todos los Xk ← v ∗ k ∈ VALORXi , P(Xi) a la vista del agente 29: Xi ← v ∗ i = Elegir óptimo(vista del agente) 30: Enviar VALORXl , Xi a todos los Xl ∈ C(Xi) que en problemas del mundo real la generación del pseudoárbol tiene un impacto significativo en el rendimiento real. El problema de encontrar la mejor pseudotree para una instancia de DCOP dada es NP-Difícil. Por lo tanto, se utiliza una heurística para la generación, y el rendimiento del algoritmo depende del pseudoárbol encontrado por la heurística. Algunas investigaciones previas se centraron en encontrar heurísticas para generar buenas pseudorboles [8]. Si bien hemos desarrollado algunas heurísticas que generan buenos pseudoárboles cruzados para usar con DCPOP, nuestro enfoque ha sido utilizar múltiples heurísticas y luego seleccionar el mejor pseudo Consideramos solo heurísticas que se ejecuten en tiempo polinómico con respecto al número de nodos en la instancia original del DCOP. El algoritmo DCPOP actual tiene una complejidad exponencial en el peor de los casos, pero podemos calcular el tamaño máximo del mensaje, el tamaño de la computación y el costo de la ruta secuencial para un pseudoárbol de bordes cruzados dado en complejidad espacio-temporal lineal. Para hacer esto, simplemente ejecutamos el algoritmo sin intentar calcular ninguno de los hipercubos de utilidad local o asignaciones de valor óptimo. En cambio, los mensajes incluyen información dimensional y de ramificación pero no hipercubos de utilidad. Después de que cada heurística complete la generación de un pseudoárbol, ejecutamos el procedimiento de medición y propagamos la información de la medición hasta la raíz elegida en ese pseudo La raíz luego transmite la complejidad total de esa heurística a todos los nodos. Después de que todas las heurísticas hayan tenido la oportunidad de completarse, cada nodo sabe qué heurística produjo el mejor pseudoárbol. Cada nodo luego procede a comenzar el algoritmo DCPOP utilizando su conocimiento del pseudoárbol generado por la mejor heurística. Las heurísticas utilizadas para generar pseudárboles tradicionales realizan un recorrido DFS distribuido. El algoritmo distribuido general utiliza un mecanismo de paso de token y un número lineal de mensajes. Las heurísticas mejoradas basadas en DFS utilizan un procedimiento especial para elegir el nodo raíz, y también proporcionan una función de ordenación sobre los vecinos de un nodo para determinar el orden de la recursión de caminos. Las heurísticas basadas en DFS utilizadas en nuestros experimentos provienen del trabajo realizado en [4, 8]. 5.1 La heurística de pseudotree cruzado de mejor primer recorrido. Las heurísticas utilizadas para generar pseudárboles cruzados realizan un recorrido de mejor primer recorrido. Se presenta un algoritmo general distribuido de mejor primero para la expansión de nodos en el Algoritmo 2. Una función de evaluación en cada nodo proporciona los valores que se utilizan para determinar el siguiente mejor nodo a expandir. Ten en cuenta que en este algoritmo cada nodo solo intercambia su mejor valor con sus vecinos. En nuestros experimentos utilizamos varias funciones de evaluación que tomaban como argumentos una lista ordenada de ancestros y un nodo, que contiene una lista de vecinos (con la profundidad de colocación de cada vecino en el árbol). A partir de estos podemos calcular los padres de la rama, los hijos de la rama y las relaciones desconocidas para una posible ubicación del nodo. La mejor función general calculó el valor como ancestros - (padres de rama + hijos de rama) con el número de relaciones desconocidas como criterio de desempate. Después de completarse, cada nodo tiene conocimiento de su padre y ancestros, por lo que puede determinar fácilmente qué nodos conectados son pseudo-padres, padres de rama, pseudo-hijos e hijos de rama. La complejidad de la travesía de mejor primero depende de la complejidad de la función de evaluación. Suponiendo una complejidad de O(V) para la función de evaluación, que es el caso de nuestra mejor función general, el recorrido de mejor primero es O(V · E), lo que en el peor de los casos es O(n3). Para cada v ∈ V realizamos una operación de colocación y encontramos el siguiente nodo a colocar usando la operación getBestNeighbor. La complejidad de la operación del lugar es a lo sumo O(V) debido a los mensajes enviados. Encontrar el siguiente nodo utiliza recursión y recorre solo los ya colocados The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 745 Algoritmo 2 Algoritmo de Búsqueda Distribuida de Mejor Primero root ← líder elegido next(root, ∅) place(nodo, padre) nodo.padre ← padre nodo.ancestros ← padre.ancestros ∪ padre enviar mensaje de ubicación (nodo, nodo.ancestros) a todos los vecinos de nodo next(actual, anterior) si actual no está ubicado entonces place(actual, anterior) next(actual, ∅) else mejor ← obtenerMejorVecino(actual, anterior) si mejor = ∅ entonces si anterior = ∅ entonces terminar, todos los nodos están ubicados next(anterior, ∅) else next(mejor, actual) obtenerMejorVecino(actual, anterior) mejor ← ∅; puntaje ← 0 para todo n ∈ vecinos de actual hacer si n! = anterior entonces si n está ubicado entonces puntajeN ← obtenerMejorVecino(n, actual) else puntajeN ← evaluar(actual, n) si puntajeN > puntaje entonces puntaje ← puntajeN mejor ← n return mejor, puntaje nodos, por lo que tiene O(V) recursiones. Cada recursión realiza una operación recursiva getBestNeighbor que recorre todos los nodos colocados y sus vecinos. Esta operación es O(V · E), pero los resultados se pueden almacenar en caché utilizando solo O(V) espacio en cada nodo. Así que tenemos O(V ·(V +V +V ·E)) = O(V 2 ·E). Si somos inteligentes al evaluar los cambios locales cuando cada nodo recibe mensajes de ubicación de sus vecinos y almacenamos en caché los resultados, la operación getBestNeighbor es solo O(E). Esto aumenta la complejidad de la operación de ubicación, pero para todas las ubicaciones la complejidad total es solo O(V · E). Por lo tanto, tenemos una complejidad general de O(V ·E+V ·(V +E)) = O(V ·E). 6. COMPARACIÓN DE COMPLEJIDAD EN DPOP Y DCPOP Ya hemos demostrado que, dado el mismo input, DCPOP se desempeña igual que DPOP. También hemos demostrado que podemos predecir con precisión el rendimiento de un pseudoárbol dado en complejidad temporal lineal. Si usamos un número constante de heurísticas para generar el conjunto de pseudobosques, podemos elegir el mejor pseudobosque con complejidad lineal en espacio y tiempo. Ahora demostraremos que existe una instancia de DCOP para la cual un pseudoárbol de bordes cruzados supera a todos los posibles pseudoárboles tradicionales (basados en heurísticas de recorrido de bordes). En la Figura 3(a) tenemos una instancia de DCOP con seis nodos. Este es un grafo bipartito con cada partición completamente conectada a la otra (a) (b) (c) Figura 3: (a) La instancia de DCOP (b) Un arreglo de pseudobosque tradicional para la instancia de DCOP (c) Un arreglo de pseudobosque con aristas cruzadas para la partición de la instancia de DCOP. En la Figura 3(b) vemos un arreglo tradicional de pseudotree para esta instancia de DCOP. Es fácil ver que cualquier heurística basada en el recorrido de aristas no puede expandir dos nodos de la misma partición sucesivamente. También observamos que ningún nodo puede tener más de un hijo porque cualquier disposición de este tipo sería un pseudoárbol inválido. Por lo tanto, cualquier disposición tradicional de pseudodendrograma para esta instancia de DCOP debe tener la forma de la Figura 3(b). Podemos ver que las aristas de retroceso F-B y F-A se superponen al nodo C. El nodo C también tiene un padre E y una arista de retroceso con D. Utilizando el algoritmo DPOP original (o DCPOP ya que son idénticos en este caso), encontramos que el cálculo en el nodo C implica cinco dominios: A, B, C, D y E. En contraste, el arreglo de pseudonodos con aristas cruzadas en la Figura 3(c) requiere un máximo de cuatro dominios en cualquier cálculo durante DCPOP. Dado que el nodo A es el punto de fusión de las ramas tanto de B como de C, podemos ver que cada uno de los nodos D, E y F tiene dos ramas superpuestas. Además, cada uno de estos nodos tiene al nodo A como su padre. Usando el algoritmo DCPOP, encontramos que el cálculo en el nodo D (o E o F) implica cuatro dominios: A, B, C y D (o E o F). Dado que no se puede crear una disposición de pseudobosque tradicional mejor utilizando una heurística de recorrido de aristas, hemos demostrado que DCPOP puede superar a DPOP incluso si utilizamos el pseudobosque óptimo encontrado a través del recorrido de aristas. Reconocemos que los arreglos de pseudodistribución de árboles que permiten relaciones padre-hijo sin una restricción real pueden resolver el problema en la Figura 3(a) con un tamaño de cálculo máximo de cuatro dominios. Sin embargo, las heurísticas actuales utilizadas con DPOP no producen tales pseudobosques, y sería difícil distribuir una heurística así, ya que cada nodo requeriría información sobre nodos con los que no tiene restricciones. Además, aunque no lo demostramos aquí, los pseudobosques de bordes cruzados pueden producir tamaños de mensaje más pequeños que tales pseudobosques, incluso si el tamaño de la computación es similar. En la práctica, dado que encontrar la mejor disposición de pseudoramas es NP-Difícil, observamos que las heurísticas que producen pseudoramas con aristas cruzadas a menudo generan tamaños de cálculo y mensajes significativamente más pequeños. 7. RESULTADOS EXPERIMENTALES 746 El Sexto Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Los métricos de rendimiento existentes para algoritmos DCOP incluyen el número total de mensajes, ciclos de reloj síncronos y tamaño de mensaje. Ya hemos demostrado que el número total de mensajes es lineal con respecto al número de restricciones en la instancia de DCOP. También introdujimos el costo de camino secuencial máximo (PC) como una medida de la máxima cantidad de paralelismo alcanzable por el algoritmo. El costo máximo de la ruta secuencial es igual a la suma de los cálculos realizados en la ruta más larga desde la raíz hasta cualquier nodo hoja. También incluimos como métricas el tamaño máximo de cálculo en número de dimensiones (CD) y el tamaño máximo de mensaje en número de dimensiones (MD). Para analizar la complejidad relativa de una instancia DCOP dada, encontramos el ancho inducido mínimo (IW) de cualquier pseudobosque tradicional producido por una heurística para el DPOP original. 7.1 Instancias genéricas de DCOP Para nuestras pruebas iniciales generamos aleatoriamente dos conjuntos de problemas con 3000 casos en cada uno. Cada problema fue generado asignando un número aleatorio (elegido de un rango) de restricciones a cada variable. El generador luego creó restricciones binarias hasta que cada variable alcanzó su número máximo de restricciones. El primer conjunto utiliza 20 variables, y el mejor DPOP IW varía de 1 a 16 con un promedio de 8.5. El segundo conjunto utiliza 100 variables, y el mejor DPOP IW osciló entre 2 y 68 con un promedio de 39.3. Dado que la mayoría de los problemas en el segundo conjunto eran demasiado complejos para calcular la solución, tomamos medidas de las métricas utilizando las técnicas descritas anteriormente en la Sección 5 sin resolver realmente el problema. Los resultados se muestran para el primer conjunto en la Tabla 1 y para el segundo conjunto en la Tabla 2. Para los dos conjuntos de problemas dividimos los casos en categorías de baja densidad y alta densidad. Los casos de baja densidad consisten en aquellos problemas que tienen un mejor DPOP IW menor o igual a la mitad del número total de nodos (por ejemplo, IW ≤ 10 para los problemas de 20 nodos e IW ≤ 50 para los problemas de 100 nodos. Los problemas de alta densidad consisten en el resto de los conjuntos de problemas. En ambas Tabla 1 y Tabla 2 hemos enumerado las métricas de rendimiento para el algoritmo DPOP original, el algoritmo DCPOP utilizando solo pseudobosques de bordes cruzados (DCPOP-CE), y el algoritmo DCPOP utilizando pseudobosques tradicionales y de bordes cruzados (DCPOP-All). Los pseudobosques utilizados para DPOP fueron generados utilizando 5 heurísticas: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB y DFS MCN BEC. Estas son todas las versiones del recorrido DFS guiado discutidas en la Sección 5. Los pseudobosques de bordes cruzados utilizados para DCPOP-CE fueron generados utilizando 5 heurísticas: MCN, LCN, MCN A-B, LCN A-B y LCSG A-B. Estas son todas las versiones del recorrido de mejor primero discutidas en la Sección 5. Para tanto DPOP como DCPOP-CE elegimos el mejor pseudoárbol producido por sus respectivas 5 heurísticas para cada problema en el conjunto. Para DCPOP-All elegimos la mejor pseudotree producida por las 10 heurísticas para cada problema en el conjunto. Para las métricas de CD y MD, el valor mostrado es el número promedio de dimensiones. Para la métrica de PC, el valor mostrado es el logaritmo natural del costo de ruta secuencial máximo (ya que el valor real crece exponencialmente con la complejidad del problema). La última fila en ambas tablas es una medida de mejora de DCPOP-All sobre DPOP. Para las métricas CD y MD, el valor mostrado es una reducción en el número de dimensiones. Para la métrica de PC, el valor mostrado es una reducción porcentual en el costo máximo de la ruta secuencial (% = DP OP −DCP OP DCP OP ∗ 100). Observa que DCPOP supera a DPOP en todas las métricas. Esto se sigue lógicamente de nuestra afirmación anterior de que, dada la misma entrada, DCPOP se comporta exactamente igual que DPOP. Así, dada la elección entre los pseudobosques producidos por las 10 heurísticas, DCPOP-All siempre superará a DCPOP-CE y DPOP. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 6: Mejora del Costo del Camino DCPOP Reunión Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Tabla 3: Problemas de Programación de Reuniones realizan DPOP. Otra tendencia que observamos es que la mejora es mayor para problemas de alta densidad que para problemas de baja densidad. Mostramos esta tendencia con mayor detalle en las Figuras 4, 5 y 6. Observa cómo la mejora aumenta a medida que aumenta la complejidad del problema. 7.2 Problema de Programación de Reuniones Además de nuestras pruebas genéricas iniciales de DCOP, realizamos una serie de pruebas en el Problema de Programación de Reuniones (MSP) como se describe en [6]. La configuración del problema incluye un número de personas agrupadas en departamentos. Cada persona debe asistir a un número específico de reuniones. Las reuniones pueden llevarse a cabo dentro de los departamentos o entre departamentos, y pueden asignarse a uno de los ocho horarios disponibles. El MSP se mapea a una instancia de DCOP donde cada variable representa el intervalo de tiempo en el que una persona específica asistirá a una reunión específica. Todas las variables que pertenecen a la misma persona tienen restricciones de exclusión mutua para que la persona no pueda asistir a más de una reunión durante el mismo intervalo de tiempo. Todas las variables que pertenecen a la misma reunión tienen restricciones de igualdad para que todos los participantes elijan el mismo horario. Se imponen restricciones unarias en cada variable para tener en cuenta la valoración de una persona de cada reunión y franja horaria. Para nuestros tests generamos 100 problemas de muestra para cada combinación de agentes y reuniones. Los resultados se muestran en la Tabla 3. Los valores en las primeras cinco columnas representan (en orden de izquierda a derecha), el número total de agentes, el número total de reuniones, el número total de variables, el promedio total de restricciones y el promedio mínimo de IW producido por un pseudoárbol tradicional. Las últimas tres columnas muestran las mismas métricas que utilizamos para las instancias genéricas de DCOP, excepto que esta vez solo mostramos las mejoras de DCPOP-All sobre DPOP. El rendimiento es mejor en promedio para todas las instancias de MSP, pero nuevamente vemos mejoras más grandes para instancias de problemas más complejos. 8. CONCLUSIONES Y TRABAJO FUTURO Presentamos un algoritmo completo y distribuido que resuelve instancias generales de DCOP utilizando arreglos de pseudoramas cruzados. Nuestro algoritmo extiende el algoritmo DPOP al agregar mensajes adicionales de propagación de utilidad e introducir el concepto de fusión de ramas durante la fase de propagación de utilidad. Nuestro algoritmo también permite que las asignaciones de valor ocurran en puntos de fusión de nivel superior para nodos de nivel inferior. Hemos demostrado que DCPOP extiende completamente DPOP al realizar las mismas operaciones dadas las mismas entradas. También hemos demostrado a través de algunos ejemplos y datos experimentales que DCPOP puede lograr un mejor rendimiento para algunas instancias del problema al extender el conjunto de entrada permitido para incluir pseudobosques cruzados. Damos especial énfasis al papel que desempeñan las heurísticas de recorrido de bordes en la generación de pseudobosques. Hemos demostrado que la penalización en el rendimiento es mínima para generar múltiples heurísticas, y que podemos elegir el mejor pseudoárbol generado en complejidad lineal de espacio-tiempo. Dada la importancia de un buen pseudoárbol para el rendimiento, el trabajo futuro incluirá nuevas heurísticas para encontrar mejores pseudo El trabajo futuro también incluirá adaptar las extensiones existentes de DPOP [5, 7] que soportan diferentes dominios de problemas para su uso con DCPOP. 9. REFERENCIAS [1] J. Liu y K. P. Sycara. Explotando la estructura del problema para la optimización distribuida de restricciones. En V. Lesser, editor, Actas de la Primera Conferencia Internacional sobre Sistemas Multiagente, páginas 246-254, San Francisco, CA, 1995. MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, y S. Kulkarni. Un enfoque dinámico distribuido de satisfacción de restricciones para la asignación de recursos. Notas de conferencia en Ciencias de la Computación, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe y M. Yokoo. Un método completo asíncrono para la optimización de restricciones distribuidas. En AAMAS 03, 2003. [4] A. Petcu. Frodo: Un marco para la optimización de restricciones abiertas/distribuidas. Informe técnico No. 2006/001, Instituto Federal Suizo de Tecnología (EPFL), Lausana (Suiza), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu y B. Faltings. A-dpop: Aproximaciones en optimización distribuida. En póster en CP 2005, páginas 802-806, Sitges, España, octubre de 2005. [6] A. Petcu y B. Faltings. Dpop: Un método escalable para la optimización de restricciones multiagente. En IJCAI 05, páginas 266-271, Edimburgo, Escocia, agosto de 2005. [7] A. Petcu, B. Faltings y D. Parkes. M-dpop: Implementación distribuida fiel de problemas eficientes de elección social. En AAMAS 06, páginas 1397-1404, Hakodate, Japón, mayo de 2006. [8] G. Ushakov. Resolviendo problemas de programación de reuniones utilizando un procedimiento de optimización distribuido de pseudobosque. Tesis de maestría, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida y K. Kuwabara. Satisfacción de restricciones distribuida para formalizar la resolución de problemas distribuidos. En la Conferencia Internacional sobre Sistemas de Computación Distribuida, páginas 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida y K. Kuwabara. El problema de satisfacción de restricciones distribuidas: Formalización y algoritmos. Ingeniería del Conocimiento y de Datos, 10(5):673-685, 1998. 748 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07)",
    "original_sentences": [
        "A Complete Distributed Constraint Optimization Method For Non-Traditional Pseudotree Arrangements∗ James Atlas Computer and Information Sciences University of Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Computer and Information Sciences University of Delaware Newark, DE 19716 decker@cis.udel.edu ABSTRACT Distributed Constraint Optimization (DCOP) is a general framework that can model complex problems in multi-agent systems.",
        "Several current algorithms that solve general DCOP instances, including ADOPT and DPOP, arrange agents into a traditional pseudotree structure.",
        "We introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements.",
        "Our algorithm correctly solves DCOP instances for pseudotrees that include edges between nodes in separate branches.",
        "The algorithm also solves instances with traditional pseudotree arrangements using the same procedure as DPOP.",
        "We compare our algorithm with DPOP using several metrics including the induced width of the pseudotrees, the maximum dimensionality of messages and computation, and the maximum sequential path cost through the algorithm.",
        "We prove that for some problem instances it is not possible to generate a traditional pseudotree using edge-traversal heuristics that will outperform a cross-edged pseudotree.",
        "We use multiple heuristics to generate pseudotrees and choose the best pseudotree in linear space-time complexity.",
        "For some problem instances we observe significant improvements in message and computation sizes compared to DPOP.",
        "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent Systems General Terms Algorithms 1.",
        "INTRODUCTION Many historical problems in the AI community can be transformed into Constraint Satisfaction Problems (CSP).",
        "With the advent of distributed AI, multi-agent systems became a popular way to model the complex interactions and coordination required to solve distributed problems.",
        "CSPs were originally extended to distributed agent environments in [9].",
        "Early domains for distributed constraint satisfaction problems (DisCSP) included job shop scheduling [1] and resource allocation [2].",
        "Many domains for agent systems, especially teamwork coordination, distributed scheduling, and sensor networks, involve overly constrained problems that are difficult or impossible to satisfy for every constraint.",
        "Recent approaches to solving problems in these domains rely on optimization techniques that map constraints into multi-valued utility functions.",
        "Instead of finding an assignment that satisfies all constraints, these approaches find an assignment that produces a high level of global utility.",
        "This extension to the original DisCSP approach has become popular in multi-agent systems, and has been labeled the Distributed Constraint Optimization Problem (DCOP) [1].",
        "Current algorithms that solve complete DCOPs use two main approaches: search and dynamic programming.",
        "Search based algorithms that originated from DisCSP typically use some form of backtracking [10] or bounds propagation, as in ADOPT [3].",
        "Dynamic programming based algorithms include DPOP and its extensions [5, 6, 7].",
        "To date, both categories of algorithms arrange agents into a traditional pseudotree to solve the problem.",
        "It has been shown in [6] that any constraint graph can be mapped into a traditional pseudotree.",
        "However, it was also shown that finding the optimal pseudotree was NP-Hard.",
        "We began to investigate the performance of traditional pseudotrees generated by current edge-traversal heuristics.",
        "We found that these heuristics often produced little parallelism as the pseudotrees tended to have high depth and low branching factors.",
        "We suspected that there could be other ways to arrange the pseudotrees that would provide increased parallelism and smaller message sizes.",
        "After exploring these other arrangements we found that cross-edged pseudotrees provide shorter depths and higher branching factors than the traditional pseudotrees.",
        "Our hypothesis was that these crossedged pseudotrees would outperform traditional pseudotrees for some problem types.",
        "In this paper we introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements which include cross-edged pseudotrees.",
        "We begin with a definition of 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, traditional pseudotrees, and cross-edged pseudotrees.",
        "We then provide a summary of the original DPOP algorithm and introduce our DCPOP algorithm.",
        "We discuss the complexity of our algorithm as well as the impact of pseudotree generation heuristics.",
        "We then show that our Distributed Cross-edged Pseudotree Optimization Procedure (DCPOP) performs significantly better in practice than the original DPOP algorithm for some problem instances.",
        "We conclude with a selection of ideas for future work and extensions for DCPOP. 2.",
        "PROBLEM DEFINITION DCOP has been formalized in slightly different ways in recent literature, so we will adopt the definition as presented in [6].",
        "A Distributed Constraint Optimization Problem with n nodes and m constraints consists of the tuple < X, D, U > where: • X = {x1,..,xn} is a set of variables, each one assigned to a unique agent • D = {d1,..,dn} is a set of finite domains for each variable • U = {u1,..,um} is a set of utility functions such that each function involves a subset of variables in X and defines a utility for each combination of values among these variables An optimal solution to a DCOP instance consists of an assignment of values in D to X such that the sum of utilities in U is maximal.",
        "Problem domains that require minimum cost instead of maximum utility can map costs into negative utilities.",
        "The utility functions represent soft constraints but can also represent hard constraints by using arbitrarily large negative values.",
        "For this paper we only consider binary utility functions involving two variables.",
        "Higher order utility functions can be modeled with minor changes to the algorithm, but they also substantially increase the complexity. 2.1 Traditional Pseudotrees Pseudotrees are a common structure used in search procedures to allow parallel processing of independent branches.",
        "As defined in [6], a pseudotree is an arrangement of a graph G into a rooted tree T such that vertices in G that share an edge are in the same branch in T. A back-edge is an edge between a node X and any node which lies on the path from X to the root (excluding Xs parent).",
        "Figure 1 shows a pseudotree with four nodes, three edges (A-B, B-C, BD), and one back-edge (A-C).",
        "Also defined in [6] are four types of relationships between nodes exist in a pseudotree: • P(X) - the parent of a node X: the single node higher in the pseudotree that is connected to X directly through a tree edge • C(X) - the children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through tree edges • PP(X) - the pseudo-parents of a node X: the set of nodes higher in the pseudotree that are connected to X directly through back-edges (In Figure 1, A = PP(C)) • PC(X) - the pseudo-children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through back-edges (In Figure 1, C = PC(A)) Figure 1: A traditional pseudotree.",
        "Solid line edges represent parent-child relationships and the dashed line represents a pseudo-parent-pseudo-child relationship.",
        "Figure 2: A cross-edged pseudotree.",
        "Solid line edges represent parent-child relationships, the dashed line represents a pseudoparent-pseudo-child relationship, and the dotted line represents a branch-parent-branch-child relationship.",
        "The bolded node, B, is the merge point for node E. 2.2 Cross-edged Pseudotrees We define a cross-edge as an edge from node X to a node Y that is above X but not in the path from X to the root.",
        "A cross-edged pseudotree is a traditional pseudotree with the addition of cross-edges.",
        "Figure 2 shows a cross-edged pseudotree with a cross-edge (D-E).",
        "In a cross-edged pseudotree we designate certain edges as primary.",
        "The set of primary edges defines a spanning tree of the nodes.",
        "The parent, child, pseudo-parent, and pseudo-child relationships from the traditional pseudotree are now defined in the context of this primary edge spanning tree.",
        "This definition also yields two additional types of relationships that may exist between nodes: • BP(X) - the branch-parents of a node X: the set of nodes higher in the pseudotree that are connected to X but are not in the primary path from X to the root (In Figure 2, D = BP(E)) • BC(X) - the branch-children of a node X: the set of nodes lower in the pseudotree that are connected to X but are not in any primary path from X to any leaf node (In Figure 2, E = BC(D)) 2.3 Pseudotree Generation 742 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Current algorithms usually have a pre-execution phase to generate a traditional pseudotree from a general DCOP instance.",
        "Our DCPOP algorithm generates a cross-edged pseudotree in the same fashion.",
        "First, the DCOP instance < X, D, U > translates directly into a graph with X as the set of vertices and an edge for each pair of variables represented in U.",
        "Next, various heuristics are used to arrange this graph into a pseudotree.",
        "One common heuristic is to perform a guided depth-first search (DFS) as the resulting traversal is a pseudotree, and a DFS can easily be performed in a distributed fashion.",
        "We define an edge-traversal based method as any method that produces a pseudotree in which all parent/child pairs share an edge in the original graph.",
        "This includes DFS, breadth-first search, and best-first search based traversals.",
        "Our heuristics that generate cross-edged pseudotrees use a distributed best-first search traversal. 3.",
        "DPOP ALGORITHM The original DPOP algorithm operates in three main phases.",
        "The first phase generates a traditional pseudotree from the DCOP instance using a distributed algorithm.",
        "The second phase joins utility hypercubes from children and the local node and propagates them towards the root.",
        "The third phase chooses an assignment for each domain in a top down fashion beginning with the agent at the root node.",
        "The complexity of DPOP depends on the size of the largest computation and utility message during phase two.",
        "It has been shown that this size directly corresponds to the induced width of the pseudotree generated in phase one [6].",
        "DPOP uses polynomial time heuristics to generate the pseudotree since finding the minimum induced width pseudotree is NP-hard.",
        "Several distributed edgetraversal heuristics have been developed to find low width pseudotrees [8].",
        "At the end of the first phase, each agent knows its parent, children, pseudo-parents, and pseudo-children. 3.1 Utility Propagation Agents located at leaf nodes in the pseudotree begin the process by calculating a local utility hypercube.",
        "This hypercube at node X contains summed utilities for each combination of values in the domains for P(X) and PP(X).",
        "This hypercube has dimensional size equal to the number of pseudo-parents plus one.",
        "A message containing this hypercube is sent to P(X).",
        "Agents located at non-leaf nodes wait for all messages from children to arrive.",
        "Once the agent at node Y has all utility messages, it calculates its local utility hypercube which includes domains for P(Y), PP(Y), and Y.",
        "The local utility hypercube is then joined with all of the hypercubes from the child messages.",
        "At this point all utilities involving node Y are known, and the domain for Y may be safely eliminated from the joined hypercube.",
        "This elimination process chooses the best utility over the domain of Y for each combination of the remaining domains.",
        "A message containing this hypercube is now sent to P(Y).",
        "The dimensional size of this hypercube depends on the number of overlapping domains in received messages and the local utility hypercube.",
        "This dynamic programming based propagation phase continues until the agent at the root node of the pseudotree has received all messages from its children. 3.2 Value Propagation Value propagation begins when the agent at the root node Z has received all messages from its children.",
        "Since Z has no parents or pseudo-parents, it simply combines the utility hypercubes received from its children.",
        "The combined hypercube contains only values for the domain for Z.",
        "At this point the agent at node Z simply chooses the assignment for its domain that has the best utility.",
        "A value propagation message with this assignment is sent to each node in C(Z).",
        "Each other node then receives a value propagation message from its parent and chooses the assignment for its domain that has the best utility given the assignments received in the message.",
        "The node adds its domain assignment to the assignments it received and passes the set of assignments to its children.",
        "The algorithm is complete when all nodes have chosen an assignment for their domain. 4.",
        "DCPOP ALGORITHM Our extension to the original DPOP algorithm, shown in Algorithm 1, shares the same three phases.",
        "The first phase generates the cross-edged pseudotree for the DCOP instance.",
        "The second phase merges branches and propagates the utility hypercubes.",
        "The third phase chooses assignments for domains at branch merge points and in a top down fashion, beginning with the agent at the root node.",
        "For the first phase we generate a pseudotree using several distributed heuristics and select the one with lowest overall complexity.",
        "The complexity of the computation and utility message size in DCPOP does not directly correspond to the induced width of the cross-edged pseudotree.",
        "Instead, we use a polynomial time method for calculating the maximum computation and utility message size for a given cross-edged pseudotree.",
        "A description of this method and the pseudotree selection process appears in Section 5.",
        "At the end of the first phase, each agent knows its parent, children, pseudo-parents, pseudo-children, branch-parents, and branch-children. 4.1 Merging Branches and Utility Propagation In the original DPOP algorithm a node X only had utility functions involving its parent and its pseudo-parents.",
        "In DCPOP, a node X is allowed to have a utility function involving a branch-parent.",
        "The concept of a branch can be seen in Figure 2 with node E representing our node X.",
        "The two distinct paths from node E to node B are called branches of E. The single node where all branches of E meet is node B, which is called the merge point of E. Agents with nodes that have branch-parents begin by sending a utility propagation message to each branch-parent.",
        "This message includes a two dimensional utility hypercube with domains for the node X and the branch-parent BP(X).",
        "It also includes a branch information structure which contains the origination node of the branch, X, the total number of branches originating from X, and the number of branches originating from X that are merged into a single representation by this branch information structure (this number starts at 1).",
        "Intuitively when the number of merged branches equals the total number of originating branches, the algorithm has reached the merge point for X.",
        "In Figure 2, node E sends a utility propagation message to its branch-parent, node D. This message has dimensions for the domains of E and D, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
        "As in the original DPOP utility propagation phase, an agent at leaf node X sends a utility propagation message to its parent.",
        "In DCPOP this message contains dimensions for the domains of P(X) and PP(X).",
        "If node X also has branch-parents, then the utility propagation message also contains a dimension for the domain of X, and will include a branch information structure.",
        "In Figure 2, node E sends a utility propagation message to its parent, node C. This message has dimensions for the domains of E and C, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
        "When a node Y receives utility propagation messages from all of The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 743 its children and branch-children, it merges any branches with the same origination node X.",
        "The merged branch information structure accumulates the number of merged branches for X.",
        "If the cumulative total number of merged branches equals the total number of branches, then Y is the merge point for X.",
        "This means that the utility hypercubes present at Y contain all information about the valuations for utility functions involving node X.",
        "In addition to the typical elimination of the domain of Y from the utility hypercubes, we can now safely eliminate the domain of X from the utility hypercubes.",
        "To illustrate this process, we will examine what happens in the second phase for node B in Figure 2.",
        "In the second phase Node B receives two utility propagation messages.",
        "The first comes from node C and includes dimensions for domains E, B, and A.",
        "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
        "The second comes from node D and includes dimensions for domains E and B.",
        "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
        "Node B then merges the branch information structures from both messages because they have the same origination, node E. Since the number of merged branches originating from E is now 2 and the total branches originating from E is 2, node B now eliminates the dimensions for domain E. Node B also eliminates the dimension for its own domain, leaving only information about domain A. Node B then sends a utility propagation message to node A, containing only one dimension for the domain of A.",
        "Although not possible in DPOP, this method of utility propagation and dimension elimination may produce hypercubes at node Y that do not share any domains.",
        "In DCPOP we do not join domain independent hypercubes, but instead may send multiple hypercubes in the utility propagation message sent to the parent of Y.",
        "This lazy approach to joins helps to reduce message sizes. 4.2 Value Propagation As in DPOP, value propagation begins when the agent at the root node Z has received all messages from its children.",
        "At this point the agent at node Z chooses the assignment for its domain that has the best utility.",
        "If Z is the merge point for the branches of some node X, Z will also choose the assignment for the domain of X.",
        "Thus any node that is a merge point will choose assignments for a domain other than its own.",
        "These assignments are then passed down the primary edge hierarchy.",
        "If node X in the hierarchy has branch-parents, then the value assignment message from P(X) will contain an assignment for the domain of X.",
        "Every node in the hierarchy adds any assignments it has chosen to the ones it received and passes the set of assignments to its children.",
        "The algorithm is complete when all nodes have chosen or received an assignment for their domain. 4.3 Proof of Correctness We will prove the correctness of DCPOP by first noting that DCPOP fully extends DPOP and then examining the two cases for value assignment in DCPOP.",
        "Given a traditional pseudotree as input, the DCPOP algorithm execution is identical to DPOP.",
        "Using a traditional pseudotree arrangement no nodes have branch-parents or branch-children since all edges are either back-edges or tree edges.",
        "Thus the DCPOP algorithm using a traditional pseudotree sends only utility propagation messages that contain domains belonging to the parent or pseudo-parents of a node.",
        "Since no node has any branch-parents, no branches exist, and thus no node serves as a merge point for any other node.",
        "Thus all value propagation assignments are chosen at the node of the assignment domain.",
        "For DCPOP execution with cross-edged pseudotrees, some nodes serve as merge points.",
        "We note that any node X that is not a merge point assigns its value exactly as in DPOP.",
        "The local utility hypercube at X contains domains for X, P(X), PP(X), and BC(X).",
        "As in DPOP the value assignment message received at X includes the values assigned to P(X) and PP(X).",
        "Also, since X is not a merge point, all assignments to BC(X) must have been calculated at merge points higher in the tree and are in the value assignment message from P(X).",
        "Thus after eliminating domains for which assignments are known, only the domain of X is left.",
        "The agent at node X can now correctly choose the assignment with maximum utility for its own domain.",
        "If node X is a merge point for some branch-child Y, we know that X must be a node along the path from Y to the root, and from P(Y) and all BP(Y) to the root.",
        "From the algorithm, we know that Y necessarily has all information from C(Y), PC(Y), and BC(Y) since it waits for their messages.",
        "Node X has information about all nodes below it in the tree, which would include Y, P(Y), BP(Y), and those PP(Y) that are below X in the tree.",
        "For any PP(Y) above X in the tree, X receives the assignment for the domain of PP(Y) in the value assignment message from P(X).",
        "Thus X has utility information about all of the utility functions of which Y is a part.",
        "By eliminating domains included in the value assignment message, node X is left with a local utility hypercube with domains for X and Y.",
        "The agent at node X can now correctly choose the assignments with maximum utility for the domains of X and Y. 4.4 Complexity Analysis The first phase of DCPOP sends one message to each P(X), PP(X), and BP(X).",
        "The second phase sends one value assignment message to each C(X).",
        "Thus, DCPOP produces a linear number of messages with respect to the number of edges (utility functions) in the cross-edged pseudotree and the original DCOP instance.",
        "The actual complexity of DCPOP depends on two additional measurements: message size and computation size.",
        "Message size and computation size in DCPOP depend on the number of overlapping branches as well as the number of overlapping back-edges.",
        "It was shown in [6] that the number of overlapping back-edges is equal to the induced width of the pseudotree.",
        "In a poorly constructed cross-edged pseudotree, the number of overlapping branches at node X can be as large as the total number of descendants of X.",
        "Thus, the total message size in DCPOP in a poorly constructed instance can be space-exponential in the total number of nodes in the graph.",
        "However, in practice a well constructed cross-edged pseudotree can achieve much better results.",
        "Later we address the issue of choosing well constructed crossedged pseudotrees from a set.",
        "We introduce an additional measurement of the maximum sequential path cost through the algorithm.",
        "This measurement directly relates to the maximum amount of parallelism achievable by the algorithm.",
        "To take this measurement we first store the total computation size for each node during phase two and three.",
        "This computation size represents the number of individual accesses to a value in a hypercube at each node.",
        "For example, a join between two domains of size 4 costs 4 ∗ 4 = 16.",
        "Two directed acyclic graphs (DAG) can then be drawn; one with the utility propagation messages as edges and the phase two costs at nodes, and the other with value assignment messages and the phase three costs at nodes.",
        "The maximum sequential path cost is equal to the sum of the longest path on each DAG from the root to any leaf node. 5.",
        "HEURISTICS In our assessment of complexity in DCPOP we focused on the worst case possibly produced by the algorithm.",
        "We acknowledge 744 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Algorithm 1 DCPOP Algorithm 1: DCPOP(X; D; U) Each agent Xi executes: Phase 1: pseudotree creation 2: elect leader from all Xj ∈ X 3: elected leader initiates pseudotree creation 4: afterwards, Xi knows P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) and PC(Xi) Phase 2: UTIL message propagation 5: if |BP(Xi)| > 0 then 6: BRANCHXi ← |BP(Xi)| + 1 7: for all Xk ∈BP(Xi) do 8: UTILXi (Xk) ←Compute utils(Xi, Xk) 9: Send message(Xk,UTILXi (Xk),BRANCHXi ) 10: if |C(Xi)| = 0(i.e.",
        "Xi is a leaf node) then 11: UTILXi (P(Xi)) ← Compute utils(P(Xi),PP(Xi)) for all PP(Xi) 12: Send message(P(Xi), UTILXi (P(Xi)),BRANCHXi ) 13: Send message(PP(Xi), empty UTIL, empty BRANCH) to all PP(Xi) 14: activate UTIL Message handler() Phase 3: VALUE message propagation 15: activate VALUE Message handler() END ALGORITHM UTIL Message handler(Xk,UTILXk (Xi), BRANCHXk ) 16: store UTILXk (Xi),BRANCHXk (Xi) 17: if UTIL messages from all children and branch children arrived then 18: for all Bj ∈BRANCH(Xi) do 19: if Bj is merged then 20: join all hypercubes where Bj ∈UTIL(Xi) 21: eliminate Bj from the joined hypercube 22: if P(Xi) == null (that means Xi is the root) then 23: v ∗ i ← Choose optimal(null) 24: Send VALUE(Xi, v ∗ i) to all C(Xi) 25: else 26: UTILXi (P(Xi)) ← Compute utils(P(Xi), PP(Xi)) 27: Send message(P(Xi),UTILXi (P(Xi)), BRANCHXi (P(Xi))) VALUE Message handler(VALUEXi ,P(Xi)) 28: add all Xk ← v ∗ k ∈VALUEXi ,P(Xi) to agent view 29: Xi ← v ∗ i =Choose optimal(agent view) 30: Send VALUEXl , Xi to all Xl ∈C(Xi) that in real world problems the generation of the pseudotree has a significant impact on the actual performance.",
        "The problem of finding the best pseudotree for a given DCOP instance is NP-Hard.",
        "Thus a heuristic is used for generation, and the performance of the algorithm depends on the pseudotree found by the heuristic.",
        "Some previous research focused on finding heuristics to generate good pseudotrees [8].",
        "While we have developed some heuristics that generate good cross-edged pseudotrees for use with DCPOP, our focus has been to use multiple heuristics and then select the best pseudotree from the generated pseudotrees.",
        "We consider only heuristics that run in polynomial time with respect to the number of nodes in the original DCOP instance.",
        "The actual DCPOP algorithm has worst case exponential complexity, but we can calculate the maximum message size, computation size, and sequential path cost for a given cross-edged pseudotree in linear space-time complexity.",
        "To do this, we simply run the algorithm without attempting to calculate any of the local utility hypercubes or optimal value assignments.",
        "Instead, messages include dimensional and branch information but no utility hypercubes.",
        "After each heuristic completes its generation of a pseudotree, we execute the measurement procedure and propagate the measurement information up to the chosen root in that pseudotree.",
        "The root then broadcasts the total complexity for that heuristic to all nodes.",
        "After all heuristics have had a chance to complete, every node knows which heuristic produced the best pseudotree.",
        "Each node then proceeds to begin the DCPOP algorithm using its knowledge of the pseudotree generated by the best heuristic.",
        "The heuristics used to generate traditional pseudotrees perform a distributed DFS traversal.",
        "The general distributed algorithm uses a token passing mechanism and a linear number of messages.",
        "Improved DFS based heuristics use a special procedure to choose the root node, and also provide an ordering function over the neighbors of a node to determine the order of path recursion.",
        "The DFS based heuristics used in our experiments come from the work done in [4, 8]. 5.1 The best-first cross-edged pseudotree heuristic The heuristics used to generate cross-edged pseudotrees perform a best-first traversal.",
        "A general distributed best-first algorithm for node expansion is presented in Algorithm 2.",
        "An evaluation function at each node provides the values that are used to determine the next best node to expand.",
        "Note that in this algorithm each node only exchanges its best value with its neighbors.",
        "In our experiments we used several evaluation functions that took as arguments an ordered list of ancestors and a node, which contains a list of neighbors (with each neighbors placement depth in the tree if it was placed).",
        "From these we can calculate branchparents, branch-children, and unknown relationships for a potential node placement.",
        "The best overall function calculated the value as ancestors−(branchparents+branchchildren) with the number of unknown relationships being a tiebreak.",
        "After completion each node has knowledge of its parent and ancestors, so it can easily determine which connected nodes are pseudo-parents, branchparents, pseudo-children, and branch-children.",
        "The complexity of the best-first traversal depends on the complexity of the evaluation function.",
        "Assuming a complexity of O(V ) for the evaluation function, which is the case for our best overall function, the best-first traversal is O(V · E) which is at worst O(n3 ).",
        "For each v ∈ V we perform a place operation, and find the next node to place using the getBestNeighbor operation.",
        "The place operation is at most O(V ) because of the sent messages.",
        "Finding the next node uses recursion and traverses only already placed The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 745 Algorithm 2 Distributed Best-First Search Algorithm root ← electedleader next(root, ∅) place(node, parent) node.parent ← parent node.ancestors ← parent.ancestors ∪ parent send placement message (node, node.ancestors) to all neighbors of node next(current, previous) if current is not placed then place(current, previous) next(current, ∅) else best ← getBestNeighbor(current, previous) if best = ∅ then if previous = ∅ then terminate, all nodes are placed next(previous, ∅) else next(best, current) getBestNeighbor(current, previous) best ← ∅; score ← 0 for all n ∈ current.neighbors do if n! = previous then if n is placed then nscore ← getBestNeighbor(n, current) else nscore ← evaluate(current, n) if nscore > score then score ← nscore best ← n return best, score nodes, so it has O(V ) recursions.",
        "Each recursion performs a recursive getBestNeighbor operation that traverses all placed nodes and their neighbors.",
        "This operation is O(V · E), but results can be cached using only O(V ) space at each node.",
        "Thus we have O(V ·(V +V +V ·E)) = O(V 2 ·E).",
        "If we are smart about evaluating local changes when each node receives placement messages from its neighbors and cache the results the getBestNeighbor operation is only O(E).",
        "This increases the complexity of the place operation, but for all placements the total complexity is only O(V · E).",
        "Thus we have an overall complexity of O(V ·E+V ·(V +E)) = O(V ·E). 6.",
        "COMPARISON OF COMPLEXITY IN DPOP AND DCPOP We have already shown that given the same input, DCPOP performs the same as DPOP.",
        "We also have shown that we can accurately predict performance of a given pseudotree in linear spacetime complexity.",
        "If we use a constant number of heuristics to generate the set of pseudotrees, we can choose the best pseudotree in linear space-time complexity.",
        "We will now show that there exists a DCOP instance for which a cross-edged pseudotree outperforms all possible traditional pseudotrees (based on edge-traversal heuristics).",
        "In Figure 3(a) we have a DCOP instance with six nodes.",
        "This is a bipartite graph with each partition fully connected to the other (a) (b) (c) Figure 3: (a) The DCOP instance (b) A traditional pseudotree arrangement for the DCOP instance (c) A cross-edged pseudotree arrangement for the DCOP instance partition.",
        "In Figure 3(b) we see a traditional pseudotree arrangement for this DCOP instance.",
        "It is easy to see that any edgetraversal based heuristic cannot expand two nodes from the same partition in succession.",
        "We also see that no node can have more than one child because any such arrangement would be an invalid pseudotree.",
        "Thus any traditional pseudotree arrangement for this DCOP instance must take the form of Figure 3(b).",
        "We can see that the back-edges F-B and F-A overlap node C. Node C also has a parent E, and a back-edge with D. Using the original DPOP algorithm (or DCPOP since they are identical in this case), we find that the computation at node C involves five domains: A, B, C, D, and E. In contrast, the cross-edged pseudotree arrangement in Figure 3(c) requires only a maximum of four domains in any computation during DCPOP.",
        "Since node A is the merge point for branches from both B and C, we can see that each of the nodes D, E, and F have two overlapping branches.",
        "In addition each of these nodes has node A as its parent.",
        "Using the DCPOP algorithm we find that the computation at node D (or E or F) involves four domains: A, B, C, and D (or E or F).",
        "Since no better traditional pseudotree arrangement can be created using an edge-traversal heuristic, we have shown that DCPOP can outperform DPOP even if we use the optimal pseudotree found through edge-traversal.",
        "We acknowledge that pseudotree arrangements that allow parent-child relationships without an actual constraint can solve the problem in Figure 3(a) with maximum computation size of four domains.",
        "However, current heuristics used with DPOP do not produce such pseudotrees, and such a heuristic would be difficult to distribute since each node would require information about nodes with which it has no constraint.",
        "Also, while we do not prove it here, cross-edged pseudotrees can produce smaller message sizes than such pseudotrees even if the computation size is similar.",
        "In practice, since finding the best pseudotree arrangement is NP-Hard, we find that heuristics that produce cross-edged pseudotrees often produce significantly smaller computation and message sizes. 7.",
        "EXPERIMENTAL RESULTS 746 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Existing performance metrics for DCOP algorithms include the total number of messages, synchronous clock cycles, and message size.",
        "We have already shown that the total number of messages is linear with respect to the number of constraints in the DCOP instance.",
        "We also introduced the maximum sequential path cost (PC) as a measurement of the maximum amount of parallelism achievable by the algorithm.",
        "The maximum sequential path cost is equal to the sum of the computations performed on the longest path from the root to any leaf node.",
        "We also include as metrics the maximum computation size in number of dimensions (CD) and maximum message size in number of dimensions (MD).",
        "To analyze the relative complexity of a given DCOP instance, we find the minimum induced width (IW) of any traditional pseudotree produced by a heuristic for the original DPOP. 7.1 Generic DCOP instances For our initial tests we randomly generated two sets of problems with 3000 cases in each.",
        "Each problem was generated by assigning a random number (picked from a range) of constraints to each variable.",
        "The generator then created binary constraints until each variable reached its maximum number of constraints.",
        "The first set uses 20 variables, and the best DPOP IW ranges from 1 to 16 with an average of 8.5.",
        "The second set uses 100 variables, and the best DPOP IW ranged from 2 to 68 with an average of 39.3.",
        "Since most of the problems in the second set were too complex to actually compute the solution, we took measurements of the metrics using the techniques described earlier in Section 5 without actually solving the problem.",
        "Results are shown for the first set in Table 1 and for the second set in Table 2.",
        "For the two problem sets we split the cases into low density and high density categories.",
        "Low density cases consist of those problems that have a best DPOP IW less than or equal to half of the total number of nodes (e.g.",
        "IW ≤ 10 for the 20 node problems and IW ≤ 50 for the 100 node problems).",
        "High density problems consist of the remainder of the problem sets.",
        "In both Table 1 and Table 2 we have listed performance metrics for the original DPOP algorithm, the DCPOP algorithm using only cross-edged pseudotrees (DCPOP-CE), and the DCPOP algorithm using traditional and cross-edged pseudotrees (DCPOP-All).",
        "The pseudotrees used for DPOP were generated using 5 heuristics: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB, and DFS MCN BEC.",
        "These are all versions of the guided DFS traversal discussed in Section 5.",
        "The cross-edged pseudotrees used for DCPOP-CE were generated using 5 heuristics: MCN, LCN, MCN A-B, LCN A-B, and LCSG A-B.",
        "These are all versions of the best-first traversal discussed in Section 5.",
        "For both DPOP and DCPOP-CE we chose the best pseudotree produced by their respective 5 heuristics for each problem in the set.",
        "For DCPOP-All we chose the best pseudotree produced by all 10 heuristics for each problem in the set.",
        "For the CD and MD metrics the value shown is the average number of dimensions.",
        "For the PC metric the value shown is the natural logarithm of the maximum sequential path cost (since the actual value grows exponentially with the complexity of the problem).",
        "The final row in both tables is a measurement of improvement of DCPOP-All over DPOP.",
        "For the CD and MD metrics the value shown is a reduction in number of dimensions.",
        "For the PC metric the value shown is a percentage reduction in the maximum sequential path cost (% = DP OP −DCP OP DCP OP ∗ 100).",
        "Notice that DCPOPAll outperforms DPOP on all metrics.",
        "This logically follows from our earlier assertion that given the same input, DCPOP performs exactly the same as DPOP.",
        "Thus given the choice between the pseudotrees produced by all 10 heuristics, DCPOP-All will always outLow Density High Density Algorithm CD MD PC CD MD PC DPOP 7.81 6.81 3.78 13.34 12.34 5.34 DCPOP-CE 7.94 6.73 3.74 12.83 11.43 5.07 DCPOP-All 7.62 6.49 3.66 12.72 11.36 5.05 Improvement 0.18 0.32 13% 0.62 0.98 36% Table 1: 20 node problems Low Density High Density Algorithm CD MD PC CD MD PC DPOP 33.35 32.35 14.55 58.51 57.50 19.90 DCPOP-CE 33.49 29.17 15.22 57.11 50.03 20.01 DCPOP-All 32.35 29.57 14.10 56.33 51.17 18.84 Improvement 1.00 2.78 104% 2.18 6.33 256% Table 2: 100 node problems Figure 4: Computation Dimension Size Figure 5: Message Dimension Size The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 747 Figure 6: Path Cost DCPOP Improvement Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Table 3: Meeting Scheduling Problems perform DPOP.",
        "Another trend we notice is that the improvement is greater for high density problems than low density problems.",
        "We show this trend in greater detail in Figures 4, 5, and 6.",
        "Notice how the improvement increases as the complexity of the problem increases. 7.2 Meeting Scheduling Problem In addition to our initial generic DCOP tests, we ran a series of tests on the Meeting Scheduling Problem (MSP) as described in [6].",
        "The problem setup includes a number of people that are grouped into departments.",
        "Each person must attend a specified number of meetings.",
        "Meetings can be held within departments or among departments, and can be assigned to one of eight time slots.",
        "The MSP maps to a DCOP instance where each variable represents the time slot that a specific person will attend a specific meeting.",
        "All variables that belong to the same person have mutual exclusion constraints placed so that the person cannot attend more than one meeting during the same time slot.",
        "All variables that belong to the same meeting have equality constraints so that all of the participants choose the same time slot.",
        "Unary constraints are placed on each variable to account for a persons valuation of each meeting and time slot.",
        "For our tests we generated 100 sample problems for each combination of agents and meetings.",
        "Results are shown in Table 3.",
        "The values in the first five columns represent (in left to right order), the total number of agents, the total number of meetings, the total number of variables, the average total number of constraints, and the average minimum IW produced by a traditional pseudotree.",
        "The last three columns show the same metrics we used for the generic DCOP instances, except this time we only show the improvements of DCPOP-All over DPOP.",
        "Performance is better on average for all MSP instances, but again we see larger improvements for more complex problem instances. 8.",
        "CONCLUSIONS AND FUTURE WORK We presented a complete, distributed algorithm that solves general DCOP instances using cross-edged pseudotree arrangements.",
        "Our algorithm extends the DPOP algorithm by adding additional utility propagation messages, and introducing the concept of branch merging during the utility propagation phase.",
        "Our algorithm also allows value assignments to occur at higher level merge points for lower level nodes.",
        "We have shown that DCPOP fully extends DPOP by performing the same operations given the same input.",
        "We have also shown through some examples and experimental data that DCPOP can achieve greater performance for some problem instances by extending the allowable input set to include cross-edged pseudotrees.",
        "We placed particular emphasis on the role that edge-traversal heuristics play in the generation of pseudotrees.",
        "We have shown that the performance penalty is minimal to generate multiple heuristics, and that we can choose the best generated pseudotree in linear space-time complexity.",
        "Given the importance of a good pseudotree for performance, future work will include new heuristics to find better pseudotrees.",
        "Future work will also include adapting existing DPOP extensions [5, 7] that support different problem domains for use with DCPOP. 9.",
        "REFERENCES [1] J. Liu and K. P. Sycara.",
        "Exploiting problem structure for distributed constraint optimization.",
        "In V. Lesser, editor, Proceedings of the First International Conference on Multi-Agent Systems, pages 246-254, San Francisco, CA, 1995.",
        "MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni.",
        "A dynamic distributed constraint satisfaction approach to resource allocation.",
        "Lecture Notes in Computer Science, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe, and M. Yokoo.",
        "An asynchronous complete method for distributed constraint optimization.",
        "In AAMAS 03, 2003. [4] A. Petcu.",
        "Frodo: A framework for open/distributed constraint optimization.",
        "Technical Report No. 2006/001 2006/001, Swiss Federal Institute of Technology (EPFL), Lausanne (Switzerland), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu and B. Faltings.",
        "A-dpop: Approximations in distributed optimization.",
        "In poster in CP 2005, pages 802-806, Sitges, Spain, October 2005. [6] A. Petcu and B. Faltings.",
        "Dpop: A scalable method for multiagent constraint optimization.",
        "In IJCAI 05, pages 266-271, Edinburgh, Scotland, Aug 2005. [7] A. Petcu, B. Faltings, and D. Parkes.",
        "M-dpop: Faithful distributed implementation of efficient social choice problems.",
        "In AAMAS 06, pages 1397-1404, Hakodate, Japan, May 2006. [8] G. Ushakov.",
        "Solving meeting scheduling problems using distributed pseudotree-optimization procedure.",
        "Masters thesis, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
        "Distributed constraint satisfaction for formalizing distributed problem solving.",
        "In International Conference on Distributed Computing Systems, pages 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
        "The distributed constraint satisfaction problem: Formalization and algorithms.",
        "Knowledge and Data Engineering, 10(5):673-685, 1998. 748 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
    ],
    "translated_text_sentences": [
        "Un Método Completo de Optimización de Restricciones Distribuidas para Arreglos de Pseudotree No Tradicionales∗ James Atlas Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 decker@cis.udel.edu RESUMEN La Optimización de Restricciones Distribuidas (DCOP) es un marco general que puede modelar problemas complejos en sistemas multiagente.",
        "Varios algoritmos actuales que resuelven instancias generales de DCOP, incluyendo ADOPT y DPOP, organizan a los agentes en una estructura de pseudobosque tradicional.",
        "Introducimos una extensión al algoritmo DPOP que maneja un conjunto extendido de disposiciones de pseudobosque.",
        "Nuestro algoritmo resuelve correctamente instancias de DCOP para pseudobosques que incluyen aristas entre nodos en ramas separadas.",
        "El algoritmo también resuelve instancias con arreglos de pseudobosque tradicionales utilizando el mismo procedimiento que DPOP.",
        "Comparamos nuestro algoritmo con DPOP utilizando varios métricos, incluyendo el ancho inducido de los pseudobosques, la dimensionalidad máxima de los mensajes y la computación, y el costo máximo de la ruta secuencial a través del algoritmo.",
        "Demostramos que para algunas instancias del problema no es posible generar un pseudoárbol tradicional utilizando heurísticas de recorrido de aristas que supere a un pseudoárbol con aristas cruzadas.",
        "Utilizamos múltiples heurísticas para generar pseudoárboles y elegir el mejor pseudoárbol en complejidad espacio-temporal lineal.",
        "Para algunas instancias del problema observamos mejoras significativas en los tamaños de los mensajes y cálculos en comparación con DPOP.",
        "Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Algoritmos 1.",
        "INTRODUCCIÓN Muchos problemas históricos en la comunidad de IA pueden transformarse en Problemas de Satisfacción de Restricciones (CSP).",
        "Con la llegada de la inteligencia artificial distribuida, los sistemas multiagente se convirtieron en una forma popular de modelar las interacciones complejas y la coordinación necesaria para resolver problemas distribuidos.",
        "Los CSPs fueron originalmente extendidos a entornos de agentes distribuidos en [9].",
        "Los primeros dominios para problemas de satisfacción de restricciones distribuidas (DisCSP) incluyeron la programación de talleres de trabajo [1] y la asignación de recursos [2].",
        "Muchos dominios para sistemas de agentes, especialmente coordinación de trabajo en equipo, programación distribuida y redes de sensores, implican problemas excesivamente restringidos que son difíciles o imposibles de satisfacer para cada restricción.",
        "Los enfoques recientes para resolver problemas en estos dominios se basan en técnicas de optimización que mapean restricciones en funciones de utilidad multivaluadas.",
        "En lugar de encontrar una asignación que satisfaga todas las restricciones, estos enfoques encuentran una asignación que produce un alto nivel de utilidad global.",
        "Esta extensión al enfoque original de DisCSP se ha vuelto popular en sistemas multiagente, y ha sido etiquetada como Problema de Optimización de Restricciones Distribuidas (DCOP) [1].",
        "Los algoritmos actuales que resuelven DCOPs completos utilizan dos enfoques principales: búsqueda y programación dinámica.",
        "Los algoritmos basados en búsqueda que se originaron a partir de DisCSP típicamente utilizan alguna forma de retroceso [10] o propagación de límites, como en ADOPT [3].",
        "Los algoritmos basados en programación dinámica incluyen DPOP y sus extensiones [5, 6, 7].",
        "Hasta la fecha, ambas categorías de algoritmos organizan agentes en un pseudoárbol tradicional para resolver el problema.",
        "Se ha demostrado en [6] que cualquier grafo de restricciones puede ser mapeado en un pseudoárbol tradicional.",
        "Sin embargo, también se demostró que encontrar el pseudoárbol óptimo era NP-Difícil.",
        "Comenzamos a investigar el rendimiento de los pseudobosques tradicionales generados por las heurísticas actuales de recorrido de aristas.",
        "Descubrimos que estas heurísticas a menudo generaban poco paralelismo, ya que los pseudárboles tendían a tener una gran profundidad y bajos factores de ramificación.",
        "Sospechábamos que podría haber otras formas de organizar los pseudobosques que proporcionarían un mayor paralelismo y tamaños de mensaje más pequeños.",
        "Después de explorar estos otros arreglos, descubrimos que los pseudobosques de bordes cruzados proporcionan profundidades más cortas y factores de ramificación más altos que los pseudobosques tradicionales.",
        "Nuestra hipótesis era que estos pseudorboles cruzados superarían a los pseudorboles tradicionales en algunos tipos de problemas.",
        "En este artículo presentamos una extensión al algoritmo DPOP que maneja un conjunto ampliado de disposiciones de pseudobosque que incluyen pseudobosques con aristas cruzadas.",
        "Comenzamos con una definición de 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, pseudobosques tradicionales y pseudobosques de bordes cruzados.",
        "Luego proporcionamos un resumen del algoritmo DPOP original e introducimos nuestro algoritmo DCPOP.",
        "Discutimos la complejidad de nuestro algoritmo, así como el impacto de las heurísticas de generación de pseudobosques.",
        "Luego demostramos que nuestro Procedimiento de Optimización de Pseudotree de Bordes Cruzados Distribuido (DCPOP) funciona significativamente mejor en la práctica que el algoritmo DPOP original para algunas instancias del problema.",
        "Concluimos con una selección de ideas para trabajos futuros y extensiones para DCPOP. 2.",
        "La DEFINICIÓN DEL PROBLEMA DCOP ha sido formalizada de maneras ligeramente diferentes en la literatura reciente, por lo que adoptaremos la definición presentada en [6].",
        "Un Problema de Optimización de Restricciones Distribuidas con n nodos y m restricciones consiste en la tupla < X, D, U > donde: • X = {x1,..,xn} es un conjunto de variables, cada una asignada a un agente único • D = {d1,..,dn} es un conjunto de dominios finitos para cada variable • U = {u1,..,um} es un conjunto de funciones de utilidad tales que cada función involucra un subconjunto de variables en X y define una utilidad para cada combinación de valores entre estas variables. Una solución óptima para una instancia de DCOP consiste en una asignación de valores en D a X tal que la suma de las utilidades en U sea máxima.",
        "Los dominios de problemas que requieren un costo mínimo en lugar de una utilidad máxima pueden mapear los costos en utilidades negativas.",
        "Las funciones de utilidad representan restricciones suaves pero también pueden representar restricciones fuertes mediante el uso de valores negativos arbitrariamente grandes.",
        "Para este artículo solo consideramos funciones de utilidad binarias que involucran dos variables.",
        "Las funciones de utilidad de orden superior pueden ser modeladas con cambios menores en el algoritmo, pero también aumentan sustancialmente la complejidad. 2.1 Pseudárboles Tradicionales Los pseudárboles son una estructura común utilizada en procedimientos de búsqueda para permitir el procesamiento paralelo de ramas independientes.",
        "Como se define en [6], un pseudoárbol es un arreglo de un grafo G en un árbol raíz T de tal manera que los vértices en G que comparten una arista están en la misma rama en T. Una arista de retroceso es una arista entre un nodo X y cualquier nodo que se encuentre en el camino desde X hasta la raíz (excluyendo al padre de X).",
        "La Figura 1 muestra un pseudoárbol con cuatro nodos, tres aristas (A-B, B-C, BD) y una arista de retroceso (A-C).",
        "También se definen en [6] cuatro tipos de relaciones entre nodos que existen en un pseudoárbol: • P(X) - el padre de un nodo X: el único nodo más alto en el pseudoárbol que está conectado a X directamente a través de un borde de árbol • C(X) - los hijos de un nodo X: el conjunto de nodos más bajos en el pseudo",
        "Las líneas sólidas representan relaciones padre-hijo y la línea discontinua representa una relación pseudo-padre-pseudo-hijo.",
        "Figura 2: Un pseudoárbol de bordes cruzados.",
        "Las líneas sólidas representan relaciones padre-hijo, la línea discontinua representa una relación pseudo-padre-pseudo-hijo, y la línea punteada representa una relación rama-padre-rama-hijo.",
        "El nodo en negrita, B, es el punto de fusión para el nodo E. 2.2 Pseudárboles con aristas cruzadas Definimos una arista cruzada como una arista de un nodo X a un nodo Y que está por encima de X pero no en el camino desde X hasta la raíz.",
        "Un pseudoárbol de bordes cruzados es un pseudoárbol tradicional con la adición de bordes cruzados.",
        "La Figura 2 muestra un pseudoárbol con una arista cruzada (D-E).",
        "En un pseudoárbol de bordes cruzados designamos ciertos bordes como primarios.",
        "El conjunto de aristas primarias define un árbol de expansión de los nodos.",
        "Las relaciones de padre, hijo, pseudo-padre y pseudo-hijo del pseudotree tradicional ahora están definidas en el contexto de este árbol de expansión de borde primario.",
        "Esta definición también produce dos tipos adicionales de relaciones que pueden existir entre nodos: • BP(X) - los nodos padres de rama de un nodo X: el conjunto de nodos más altos en el pseudoárbol que están conectados a X pero no están en el camino principal desde X hasta la raíz (En la Figura 2, D = BP(E)) • BC(X) - los nodos hijos de rama de un nodo X: el conjunto de nodos más bajos en el pseudo",
        "La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Los algoritmos actuales suelen tener una fase de pre-ejecución para generar un pseudoárbol tradicional a partir de una instancia general de DCOP.",
        "Nuestro algoritmo DCPOP genera un pseudoárbol de bordes cruzados de la misma manera.",
        "Primero, la instancia DCOP < X, D, U > se traduce directamente en un grafo con X como el conjunto de vértices y una arista para cada par de variables representadas en U.",
        "A continuación, se utilizan varias heurísticas para organizar este grafo en un pseudoárbol.",
        "Un heurístico común es realizar una búsqueda en profundidad guiada (DFS, por sus siglas en inglés) ya que el recorrido resultante es un pseudoárbol, y un DFS se puede realizar fácilmente de manera distribuida.",
        "Definimos un método basado en el recorrido de aristas como cualquier método que produce un pseudoárbol en el que todos los pares padre/hijo comparten una arista en el grafo original.",
        "Esto incluye recorridos basados en DFS, búsqueda en anchura y búsqueda de mejor primero.",
        "Nuestras heurísticas que generan pseudobosques de bordes cruzados utilizan un recorrido de búsqueda mejor primero distribuido. 3.",
        "ALGORITMO DPOP El algoritmo DPOP original opera en tres fases principales.",
        "La primera fase genera un pseudoárbol tradicional a partir de la instancia de DCOP utilizando un algoritmo distribuido.",
        "La segunda fase une hipercubos de utilidad de los nodos hijos y el nodo local y los propaga hacia la raíz.",
        "La tercera fase elige una asignación para cada dominio de arriba hacia abajo, comenzando con el agente en el nodo raíz.",
        "La complejidad de DPOP depende del tamaño del cálculo más grande y del mensaje de utilidad durante la fase dos.",
        "Se ha demostrado que este tamaño corresponde directamente al ancho inducido del pseudoárbol generado en la fase uno [6].",
        "DPOP utiliza heurísticas de tiempo polinómico para generar el pseudoárbol, ya que encontrar el pseudoárbol de ancho inducido mínimo es NP-duro.",
        "Se han desarrollado varias heurísticas de recorrido de borde distribuido para encontrar pseudobosques de ancho reducido [8].",
        "Al final de la primera fase, cada agente conoce a su padre, hijos, pseudo-padres y pseudo-hijos. 3.1 Propagación de utilidad Los agentes ubicados en los nodos hoja del pseudoárbol comienzan el proceso calculando un hipercubo de utilidad local.",
        "Este hipercubo en el nodo X contiene las utilidades sumadas para cada combinación de valores en los dominios de P(X) y PP(X).",
        "Este hipercubo tiene un tamaño dimensional igual al número de pseudo-padres más uno.",
        "Un mensaje que contiene este hipercubo se envía a P(X).",
        "Los agentes ubicados en nodos no hoja esperan a que lleguen todos los mensajes de los nodos hijos.",
        "Una vez que el agente en el nodo Y tiene todos los mensajes de utilidad, calcula su hipercubo de utilidad local que incluye los dominios de P(Y), PP(Y) y Y.",
        "El hipercubo de utilidad local se une luego con todos los hipercubos de los mensajes hijos.",
        "En este punto, todas las utilidades que involucran al nodo Y son conocidas, y el dominio de Y puede ser eliminado de forma segura del hipercubo unido.",
        "Este proceso de eliminación elige la mejor utilidad sobre el dominio de Y para cada combinación de los dominios restantes.",
        "Un mensaje que contiene este hipercubo se envía ahora a P(Y).",
        "El tamaño dimensional de este hipercubo depende del número de dominios superpuestos en los mensajes recibidos y del hipercubo de utilidad local.",
        "Esta fase de propagación basada en programación dinámica continúa hasta que el agente en el nodo raíz del pseudoárbol haya recibido todos los mensajes de sus hijos. 3.2 Propagación de Valor La propagación de valor comienza cuando el agente en el nodo raíz Z ha recibido todos los mensajes de sus hijos.",
        "Dado que Z no tiene padres ni pseudo-padres, simplemente combina los hipercubos de utilidad recibidos de sus hijos.",
        "El hipercubo combinado contiene solo valores para el dominio de Z.",
        "En este punto, el agente en el nodo Z simplemente elige la asignación para su dominio que tiene la mejor utilidad.",
        "Un mensaje de propagación de valor con esta asignación se envía a cada nodo en C(Z).",
        "Cada nodo luego recibe un mensaje de propagación de valor de su padre y elige la asignación para su dominio que tenga la mejor utilidad dadas las asignaciones recibidas en el mensaje.",
        "El nodo agrega su asignación de dominio a las asignaciones que recibió y pasa el conjunto de asignaciones a sus hijos.",
        "El algoritmo está completo cuando todos los nodos han elegido una asignación para su dominio.",
        "ALGORITMO DCPOP Nuestra extensión al algoritmo DPOP original, mostrada en el Algoritmo 1, comparte las mismas tres fases.",
        "La primera fase genera el pseudoárbol de bordes cruzados para la instancia de DCOP.",
        "La segunda fase fusiona ramas y propaga los hipercubos de utilidad.",
        "La tercera fase elige asignaciones para dominios en los puntos de fusión de ramas y de arriba hacia abajo, comenzando con el agente en el nodo raíz.",
        "Para la primera fase generamos un pseudoárbol utilizando varios heurísticos distribuidos y seleccionamos el que tenga la menor complejidad general.",
        "La complejidad de la computación y el tamaño del mensaje de utilidad en DCPOP no corresponden directamente al ancho inducido del pseudoárbol de aristas cruzadas.",
        "En cambio, utilizamos un método de tiempo polinómico para calcular el tamaño máximo de computación y utilidad del mensaje para un pseudoárbol de bordes cruzados dado.",
        "Una descripción de este método y el proceso de selección de pseudodendrogramas aparece en la Sección 5.",
        "Al final de la primera fase, cada agente conoce a su padre, hijos, pseudo-padres, pseudo-hijos, padres de rama e hijos de rama. 4.1 Fusión de Ramas y Propagación de Utilidad En el algoritmo DPOP original, un nodo X solo tenía funciones de utilidad que involucraban a su padre y a sus pseudo-padres.",
        "En DCPOP, se permite que un nodo X tenga una función de utilidad que involucre a un padre de rama.",
        "El concepto de una rama se puede ver en la Figura 2 con el nodo E representando nuestro nodo X.",
        "Las dos rutas distintas desde el nodo E hasta el nodo B se llaman ramas de E. El único nodo donde se encuentran todas las ramas de E es el nodo B, que se llama punto de fusión de E. Los agentes con nodos que tienen padres de rama comienzan enviando un mensaje de propagación de utilidad a cada padre de rama.",
        "Este mensaje incluye un hipercubo de utilidad bidimensional con dominios para el nodo X y el nodo padre de la rama BP(X).",
        "También incluye una estructura de información de rama que contiene el nodo de origen de la rama, X, el número total de ramas que se originan en X y el número de ramas que se originan en X y se fusionan en una representación única por esta estructura de información de rama (este número comienza en 1).",
        "Intuitivamente, cuando el número de ramas fusionadas es igual al número total de ramas originales, el algoritmo ha alcanzado el punto de fusión para X.",
        "En la Figura 2, el nodo E envía un mensaje de propagación de utilidad a su nodo padre de rama, el nodo D. Este mensaje tiene dimensiones para los dominios de E y D, e incluye información de rama con un origen en E, 2 ramas totales y 1 rama fusionada.",
        "Como en la fase de propagación de utilidad de la utilidad DPOP original, un agente en el nodo hoja X envía un mensaje de propagación de utilidad a su padre.",
        "En DCPOP, este mensaje contiene dimensiones para los dominios de P(X) y PP(X).",
        "Si el nodo X también tiene padres de rama, entonces el mensaje de propagación de utilidad también contiene una dimensión para el dominio de X e incluirá una estructura de información de rama.",
        "En la Figura 2, el nodo E envía un mensaje de propagación de utilidad a su padre, el nodo C. Este mensaje tiene dimensiones para los dominios de E y C, e incluye información de rama con un origen en E, 2 ramas en total y 1 rama fusionada.",
        "Cuando un nodo Y recibe mensajes de propagación de utilidad de todos de The Sixth Intl.",
        "En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), 743 sus hijos y sus hijos de rama, fusiona cualquier rama con el mismo nodo de origen X.",
        "La estructura de información de la rama fusionada acumula el número de ramas fusionadas para X.",
        "Si el número total acumulado de ramas fusionadas es igual al número total de ramas, entonces Y es el punto de fusión para X.",
        "Esto significa que los hipercubos de utilidad presentes en Y contienen toda la información sobre las valoraciones de las funciones de utilidad que involucran al nodo X.",
        "Además de la eliminación típica del dominio de Y de los hipercubos de utilidad, ahora podemos eliminar de forma segura el dominio de X de los hipercubos de utilidad.",
        "Para ilustrar este proceso, examinaremos lo que sucede en la segunda fase para el nodo B en la Figura 2.",
        "En la segunda fase, el Nodo B recibe dos mensajes de propagación de utilidad.",
        "El primero proviene del nodo C e incluye dimensiones para los dominios E, B y A.",
        "También tiene una estructura de información de ramas con origen en E, 2 ramas en total y 1 rama fusionada.",
        "El segundo proviene del nodo D e incluye dimensiones para los dominios E y B.",
        "También tiene una estructura de información de rama con origen en E, 2 ramas en total y 1 rama fusionada.",
        "El nodo B luego fusiona las estructuras de información de rama de ambos mensajes porque tienen la misma procedencia, el nodo E. Dado que el número de ramas fusionadas que provienen de E es ahora 2 y el total de ramas que provienen de E es 2, el nodo B elimina las dimensiones para el dominio E. El nodo B también elimina la dimensión para su propio dominio, dejando solo información sobre el dominio A. Luego, el nodo B envía un mensaje de propagación de utilidad al nodo A, que contiene solo una dimensión para el dominio de A.",
        "Aunque no sea posible en DPOP, este método de propagación de utilidad y eliminación de dimensiones puede producir hipercubos en el nodo Y que no comparten ningún dominio.",
        "En DCPOP no unimos hipercubos independientes de dominio, sino que en su lugar podemos enviar múltiples hipercubos en el mensaje de propagación de utilidad enviado al padre de Y.",
        "Este enfoque perezoso de las uniones ayuda a reducir el tamaño de los mensajes. 4.2 Propagación de valores Al igual que en DPOP, la propagación de valores comienza cuando el agente en el nodo raíz Z ha recibido todos los mensajes de sus hijos.",
        "En este punto, el agente en el nodo Z elige la asignación para su dominio que tiene la mejor utilidad.",
        "Si Z es el punto de fusión de las ramas de algún nodo X, Z también elegirá la asignación para el dominio de X.",
        "Por lo tanto, cualquier nodo que sea un punto de fusión elegirá asignaciones para un dominio que no sea el suyo propio.",
        "Estas tareas luego se pasan por la jerarquía de la cadena de mando principal.",
        "Si el nodo X en la jerarquía tiene padres de rama, entonces el mensaje de asignación de valor de P(X) contendrá una asignación para el dominio de X.",
        "Cada nodo en la jerarquía agrega cualquier tarea que haya elegido a las que recibió y pasa el conjunto de tareas a sus hijos.",
        "El algoritmo está completo cuando todos los nodos han elegido o recibido una asignación para su dominio. 4.3 Prueba de Corrección Demostraremos la corrección de DCPOP notando primero que DCPOP extiende completamente DPOP y luego examinando los dos casos para la asignación de valores en DCPOP.",
        "Dado un pseudoárbol tradicional como entrada, la ejecución del algoritmo DCPOP es idéntica a DPOP.",
        "Usando un arreglo de pseudodendrograma tradicional, ningún nodo tiene padres de rama o hijos de rama, ya que todas las aristas son aristas de retroceso o aristas de árbol.",
        "Por lo tanto, el algoritmo DCPOP utilizando un pseudoárbol tradicional envía solo mensajes de propagación de utilidad que contienen dominios pertenecientes al padre o pseudo-padres de un nodo.",
        "Dado que ningún nodo tiene ramas-padres, no existen ramas, y por lo tanto ningún nodo sirve como punto de fusión para ningún otro nodo.",
        "Por lo tanto, todas las asignaciones de propagación de valor se eligen en el nodo del dominio de la asignación.",
        "Para la ejecución de DCPOP con pseudárboles de bordes cruzados, algunos nodos actúan como puntos de fusión.",
        "Observamos que cualquier nodo X que no sea un punto de fusión asigna su valor exactamente como en DPOP.",
        "El hipercubo de utilidad local en X contiene dominios para X, P(X), PP(X) y BC(X).",
        "Como en DPOP, el mensaje de asignación de valores recibido en X incluye los valores asignados a P(X) y PP(X).",
        "Además, dado que X no es un punto de fusión, todas las asignaciones a BC(X) deben haber sido calculadas en puntos de fusión más altos en el árbol y están en el mensaje de asignación de valor de P(X).",
        "Por lo tanto, después de eliminar los dominios para los cuales se conocen las asignaciones, solo queda el dominio de X.",
        "El agente en el nodo X ahora puede elegir correctamente la asignación con la máxima utilidad para su propio dominio.",
        "Si el nodo X es un punto de fusión para alguna rama-hijo Y, sabemos que X debe ser un nodo a lo largo del camino desde Y hasta la raíz, y desde P(Y) y todos los BP(Y) hasta la raíz.",
        "A partir del algoritmo, sabemos que Y necesariamente tiene toda la información de C(Y), PC(Y) y BC(Y) ya que espera sus mensajes.",
        "El nodo X tiene información sobre todos los nodos debajo de él en el árbol, lo cual incluiría a Y, P(Y), BP(Y) y aquellos PP(Y) que están debajo de X en el árbol.",
        "Para cualquier PP(Y) por encima de X en el árbol, X recibe la asignación para el dominio de PP(Y) en el mensaje de asignación de valor de P(X).",
        "Por lo tanto, X tiene información de utilidad sobre todas las funciones de utilidad de las cuales Y forma parte.",
        "Al eliminar los dominios incluidos en el mensaje de asignación de valor, el nodo X se queda con un hipercubo de utilidad local con dominios para X e Y.",
        "El agente en el nodo X ahora puede elegir correctamente las asignaciones con la máxima utilidad para los dominios de X e Y. 4.4 Análisis de complejidad La primera fase de DCPOP envía un mensaje a cada P(X), PP(X) y BP(X).",
        "La segunda fase envía un mensaje de asignación de valor a cada C(X).",
        "Por lo tanto, DCPOP produce un número lineal de mensajes con respecto al número de aristas (funciones de utilidad) en el pseudoárbol de aristas cruzadas y la instancia original de DCOP.",
        "La complejidad real de DCPOP depende de dos medidas adicionales: el tamaño del mensaje y el tamaño de la computación.",
        "El tamaño del mensaje y el tamaño de la computación en DCPOP dependen del número de ramas superpuestas, así como del número de aristas de retroceso superpuestas.",
        "Se demostró en [6] que el número de aristas traslapadas es igual al ancho inducido del pseudoárbol.",
        "En un pseudoárbol de bordes cruzados mal construido, el número de ramas superpuestas en el nodo X puede ser tan grande como el número total de descendientes de X.",
        "Por lo tanto, el tamaño total del mensaje en DCPOP en una instancia mal construida puede ser exponencial en el espacio en el número total de nodos en el grafo.",
        "Sin embargo, en la práctica, un pseudoárbol bien construido con bordes cruzados puede lograr resultados mucho mejores.",
        "Más tarde abordaremos el tema de elegir pseudobosques cruzados bien construidos de un conjunto.",
        "Introducimos una medida adicional del costo máximo de la ruta secuencial a través del algoritmo.",
        "Esta medida se relaciona directamente con la cantidad máxima de paralelismo que puede lograr el algoritmo.",
        "Para tomar esta medida, primero almacenamos el tamaño total de cálculo para cada nodo durante las fases dos y tres.",
        "Este tamaño de cálculo representa el número de accesos individuales a un valor en un hipercubo en cada nodo.",
        "Por ejemplo, una unión entre dos dominios de tamaño 4 cuesta 4 ∗ 4 = 16.",
        "Dos grafos acíclicos dirigidos (DAG) pueden ser dibujados; uno con los mensajes de propagación de utilidad como aristas y los costos de la fase dos en los nodos, y el otro con los mensajes de asignación de valor y los costos de la fase tres en los nodos.",
        "El costo máximo del camino secuencial es igual a la suma del camino más largo en cada DAG desde la raíz hasta cualquier nodo hoja.",
        "HEURÍSTICAS En nuestra evaluación de la complejidad en DCPOP nos enfocamos en el peor caso posiblemente producido por el algoritmo.",
        "Reconocemos 744 La Sexta Internacional.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Algoritmo 1 DCPOP Algoritmo 1: DCPOP(X; D; U) Cada agente Xi ejecuta: Fase 1: creación de pseudotree 2: elegir líder de todos los Xj ∈ X 3: líder elegido inicia la creación de pseudotree 4: después, Xi conoce P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) y PC(Xi) Fase 2: propagación de mensajes UTIL 5: si |BP(Xi)| > 0 entonces 6: BRANCHXi ← |BP(Xi)| + 1 7: para todos Xk ∈BP(Xi) hacer 8: UTILXi (Xk) ← Calcular utils(Xi, Xk) 9: Enviar mensaje(Xk,UTILXi (Xk),BRANCHXi ) 10: si |C(Xi)| = 0 (es decir,",
        "Si Xi es un nodo hoja, entonces 11: UTILXi (P(Xi)) ← Calcular utils(P(Xi),PP(Xi)) para todos los PP(Xi) 12: Enviar mensaje(P(Xi), UTILXi (P(Xi)), BRANCHXi ) 13: Enviar mensaje(PP(Xi), UTIL vacío, BRANCH vacío) a todos los PP(Xi) 14: Activar el manejador de mensajes UTIL() Fase 3: Propagación de mensajes de VALOR 15: Activar el manejador de mensajes de VALOR() FIN ALGORITMO Manejador de mensajes UTIL(Xk, UTILXk (Xi), BRANCHXk ) 16: Almacenar UTILXk (Xi), BRANCHXk (Xi) 17: Si han llegado mensajes UTIL de todos los hijos y los hijos de la rama, entonces 18: Para todos los Bj ∈ BRANCH(Xi) hacer 19: Si Bj está fusionado, entonces 20: Unir todos los hipercubos donde Bj ∈ UTIL(Xi) 21: Eliminar Bj del hipercubo unido 22: Si P(Xi) == nulo (eso significa que Xi es la raíz) entonces 23: v ∗ i ← Elegir óptimo(nulo) 24: Enviar VALOR(Xi, v ∗ i) a todos los C(Xi) 25: De lo contrario 26: UTILXi (P(Xi)) ← Calcular utils(P(Xi), PP(Xi)) 27: Enviar mensaje(P(Xi), UTILXi (P(Xi)), BRANCHXi (P(Xi))) Manejador de mensajes de VALOR(VALORXi , P(Xi)) 28: Agregar todos los Xk ← v ∗ k ∈ VALORXi , P(Xi) a la vista del agente 29: Xi ← v ∗ i = Elegir óptimo(vista del agente) 30: Enviar VALORXl , Xi a todos los Xl ∈ C(Xi) que en problemas del mundo real la generación del pseudoárbol tiene un impacto significativo en el rendimiento real.",
        "El problema de encontrar la mejor pseudotree para una instancia de DCOP dada es NP-Difícil.",
        "Por lo tanto, se utiliza una heurística para la generación, y el rendimiento del algoritmo depende del pseudoárbol encontrado por la heurística.",
        "Algunas investigaciones previas se centraron en encontrar heurísticas para generar buenas pseudorboles [8].",
        "Si bien hemos desarrollado algunas heurísticas que generan buenos pseudoárboles cruzados para usar con DCPOP, nuestro enfoque ha sido utilizar múltiples heurísticas y luego seleccionar el mejor pseudo",
        "Consideramos solo heurísticas que se ejecuten en tiempo polinómico con respecto al número de nodos en la instancia original del DCOP.",
        "El algoritmo DCPOP actual tiene una complejidad exponencial en el peor de los casos, pero podemos calcular el tamaño máximo del mensaje, el tamaño de la computación y el costo de la ruta secuencial para un pseudoárbol de bordes cruzados dado en complejidad espacio-temporal lineal.",
        "Para hacer esto, simplemente ejecutamos el algoritmo sin intentar calcular ninguno de los hipercubos de utilidad local o asignaciones de valor óptimo.",
        "En cambio, los mensajes incluyen información dimensional y de ramificación pero no hipercubos de utilidad.",
        "Después de que cada heurística complete la generación de un pseudoárbol, ejecutamos el procedimiento de medición y propagamos la información de la medición hasta la raíz elegida en ese pseudo",
        "La raíz luego transmite la complejidad total de esa heurística a todos los nodos.",
        "Después de que todas las heurísticas hayan tenido la oportunidad de completarse, cada nodo sabe qué heurística produjo el mejor pseudoárbol.",
        "Cada nodo luego procede a comenzar el algoritmo DCPOP utilizando su conocimiento del pseudoárbol generado por la mejor heurística.",
        "Las heurísticas utilizadas para generar pseudárboles tradicionales realizan un recorrido DFS distribuido.",
        "El algoritmo distribuido general utiliza un mecanismo de paso de token y un número lineal de mensajes.",
        "Las heurísticas mejoradas basadas en DFS utilizan un procedimiento especial para elegir el nodo raíz, y también proporcionan una función de ordenación sobre los vecinos de un nodo para determinar el orden de la recursión de caminos.",
        "Las heurísticas basadas en DFS utilizadas en nuestros experimentos provienen del trabajo realizado en [4, 8]. 5.1 La heurística de pseudotree cruzado de mejor primer recorrido. Las heurísticas utilizadas para generar pseudárboles cruzados realizan un recorrido de mejor primer recorrido.",
        "Se presenta un algoritmo general distribuido de mejor primero para la expansión de nodos en el Algoritmo 2.",
        "Una función de evaluación en cada nodo proporciona los valores que se utilizan para determinar el siguiente mejor nodo a expandir.",
        "Ten en cuenta que en este algoritmo cada nodo solo intercambia su mejor valor con sus vecinos.",
        "En nuestros experimentos utilizamos varias funciones de evaluación que tomaban como argumentos una lista ordenada de ancestros y un nodo, que contiene una lista de vecinos (con la profundidad de colocación de cada vecino en el árbol).",
        "A partir de estos podemos calcular los padres de la rama, los hijos de la rama y las relaciones desconocidas para una posible ubicación del nodo.",
        "La mejor función general calculó el valor como ancestros - (padres de rama + hijos de rama) con el número de relaciones desconocidas como criterio de desempate.",
        "Después de completarse, cada nodo tiene conocimiento de su padre y ancestros, por lo que puede determinar fácilmente qué nodos conectados son pseudo-padres, padres de rama, pseudo-hijos e hijos de rama.",
        "La complejidad de la travesía de mejor primero depende de la complejidad de la función de evaluación.",
        "Suponiendo una complejidad de O(V) para la función de evaluación, que es el caso de nuestra mejor función general, el recorrido de mejor primero es O(V · E), lo que en el peor de los casos es O(n3).",
        "Para cada v ∈ V realizamos una operación de colocación y encontramos el siguiente nodo a colocar usando la operación getBestNeighbor.",
        "La complejidad de la operación del lugar es a lo sumo O(V) debido a los mensajes enviados.",
        "Encontrar el siguiente nodo utiliza recursión y recorre solo los ya colocados The Sixth Intl.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 745 Algoritmo 2 Algoritmo de Búsqueda Distribuida de Mejor Primero root ← líder elegido next(root, ∅) place(nodo, padre) nodo.padre ← padre nodo.ancestros ← padre.ancestros ∪ padre enviar mensaje de ubicación (nodo, nodo.ancestros) a todos los vecinos de nodo next(actual, anterior) si actual no está ubicado entonces place(actual, anterior) next(actual, ∅) else mejor ← obtenerMejorVecino(actual, anterior) si mejor = ∅ entonces si anterior = ∅ entonces terminar, todos los nodos están ubicados next(anterior, ∅) else next(mejor, actual) obtenerMejorVecino(actual, anterior) mejor ← ∅; puntaje ← 0 para todo n ∈ vecinos de actual hacer si n! = anterior entonces si n está ubicado entonces puntajeN ← obtenerMejorVecino(n, actual) else puntajeN ← evaluar(actual, n) si puntajeN > puntaje entonces puntaje ← puntajeN mejor ← n return mejor, puntaje nodos, por lo que tiene O(V) recursiones.",
        "Cada recursión realiza una operación recursiva getBestNeighbor que recorre todos los nodos colocados y sus vecinos.",
        "Esta operación es O(V · E), pero los resultados se pueden almacenar en caché utilizando solo O(V) espacio en cada nodo.",
        "Así que tenemos O(V ·(V +V +V ·E)) = O(V 2 ·E).",
        "Si somos inteligentes al evaluar los cambios locales cuando cada nodo recibe mensajes de ubicación de sus vecinos y almacenamos en caché los resultados, la operación getBestNeighbor es solo O(E).",
        "Esto aumenta la complejidad de la operación de ubicación, pero para todas las ubicaciones la complejidad total es solo O(V · E).",
        "Por lo tanto, tenemos una complejidad general de O(V ·E+V ·(V +E)) = O(V ·E). 6.",
        "COMPARACIÓN DE COMPLEJIDAD EN DPOP Y DCPOP Ya hemos demostrado que, dado el mismo input, DCPOP se desempeña igual que DPOP.",
        "También hemos demostrado que podemos predecir con precisión el rendimiento de un pseudoárbol dado en complejidad temporal lineal.",
        "Si usamos un número constante de heurísticas para generar el conjunto de pseudobosques, podemos elegir el mejor pseudobosque con complejidad lineal en espacio y tiempo.",
        "Ahora demostraremos que existe una instancia de DCOP para la cual un pseudoárbol de bordes cruzados supera a todos los posibles pseudoárboles tradicionales (basados en heurísticas de recorrido de bordes).",
        "En la Figura 3(a) tenemos una instancia de DCOP con seis nodos.",
        "Este es un grafo bipartito con cada partición completamente conectada a la otra (a) (b) (c) Figura 3: (a) La instancia de DCOP (b) Un arreglo de pseudobosque tradicional para la instancia de DCOP (c) Un arreglo de pseudobosque con aristas cruzadas para la partición de la instancia de DCOP.",
        "En la Figura 3(b) vemos un arreglo tradicional de pseudotree para esta instancia de DCOP.",
        "Es fácil ver que cualquier heurística basada en el recorrido de aristas no puede expandir dos nodos de la misma partición sucesivamente.",
        "También observamos que ningún nodo puede tener más de un hijo porque cualquier disposición de este tipo sería un pseudoárbol inválido.",
        "Por lo tanto, cualquier disposición tradicional de pseudodendrograma para esta instancia de DCOP debe tener la forma de la Figura 3(b).",
        "Podemos ver que las aristas de retroceso F-B y F-A se superponen al nodo C. El nodo C también tiene un padre E y una arista de retroceso con D. Utilizando el algoritmo DPOP original (o DCPOP ya que son idénticos en este caso), encontramos que el cálculo en el nodo C implica cinco dominios: A, B, C, D y E. En contraste, el arreglo de pseudonodos con aristas cruzadas en la Figura 3(c) requiere un máximo de cuatro dominios en cualquier cálculo durante DCPOP.",
        "Dado que el nodo A es el punto de fusión de las ramas tanto de B como de C, podemos ver que cada uno de los nodos D, E y F tiene dos ramas superpuestas.",
        "Además, cada uno de estos nodos tiene al nodo A como su padre.",
        "Usando el algoritmo DCPOP, encontramos que el cálculo en el nodo D (o E o F) implica cuatro dominios: A, B, C y D (o E o F).",
        "Dado que no se puede crear una disposición de pseudobosque tradicional mejor utilizando una heurística de recorrido de aristas, hemos demostrado que DCPOP puede superar a DPOP incluso si utilizamos el pseudobosque óptimo encontrado a través del recorrido de aristas.",
        "Reconocemos que los arreglos de pseudodistribución de árboles que permiten relaciones padre-hijo sin una restricción real pueden resolver el problema en la Figura 3(a) con un tamaño de cálculo máximo de cuatro dominios.",
        "Sin embargo, las heurísticas actuales utilizadas con DPOP no producen tales pseudobosques, y sería difícil distribuir una heurística así, ya que cada nodo requeriría información sobre nodos con los que no tiene restricciones.",
        "Además, aunque no lo demostramos aquí, los pseudobosques de bordes cruzados pueden producir tamaños de mensaje más pequeños que tales pseudobosques, incluso si el tamaño de la computación es similar.",
        "En la práctica, dado que encontrar la mejor disposición de pseudoramas es NP-Difícil, observamos que las heurísticas que producen pseudoramas con aristas cruzadas a menudo generan tamaños de cálculo y mensajes significativamente más pequeños. 7.",
        "RESULTADOS EXPERIMENTALES 746 El Sexto Internacional.",
        "La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Los métricos de rendimiento existentes para algoritmos DCOP incluyen el número total de mensajes, ciclos de reloj síncronos y tamaño de mensaje.",
        "Ya hemos demostrado que el número total de mensajes es lineal con respecto al número de restricciones en la instancia de DCOP.",
        "También introdujimos el costo de camino secuencial máximo (PC) como una medida de la máxima cantidad de paralelismo alcanzable por el algoritmo.",
        "El costo máximo de la ruta secuencial es igual a la suma de los cálculos realizados en la ruta más larga desde la raíz hasta cualquier nodo hoja.",
        "También incluimos como métricas el tamaño máximo de cálculo en número de dimensiones (CD) y el tamaño máximo de mensaje en número de dimensiones (MD).",
        "Para analizar la complejidad relativa de una instancia DCOP dada, encontramos el ancho inducido mínimo (IW) de cualquier pseudobosque tradicional producido por una heurística para el DPOP original. 7.1 Instancias genéricas de DCOP Para nuestras pruebas iniciales generamos aleatoriamente dos conjuntos de problemas con 3000 casos en cada uno.",
        "Cada problema fue generado asignando un número aleatorio (elegido de un rango) de restricciones a cada variable.",
        "El generador luego creó restricciones binarias hasta que cada variable alcanzó su número máximo de restricciones.",
        "El primer conjunto utiliza 20 variables, y el mejor DPOP IW varía de 1 a 16 con un promedio de 8.5.",
        "El segundo conjunto utiliza 100 variables, y el mejor DPOP IW osciló entre 2 y 68 con un promedio de 39.3.",
        "Dado que la mayoría de los problemas en el segundo conjunto eran demasiado complejos para calcular la solución, tomamos medidas de las métricas utilizando las técnicas descritas anteriormente en la Sección 5 sin resolver realmente el problema.",
        "Los resultados se muestran para el primer conjunto en la Tabla 1 y para el segundo conjunto en la Tabla 2.",
        "Para los dos conjuntos de problemas dividimos los casos en categorías de baja densidad y alta densidad.",
        "Los casos de baja densidad consisten en aquellos problemas que tienen un mejor DPOP IW menor o igual a la mitad del número total de nodos (por ejemplo,",
        "IW ≤ 10 para los problemas de 20 nodos e IW ≤ 50 para los problemas de 100 nodos.",
        "Los problemas de alta densidad consisten en el resto de los conjuntos de problemas.",
        "En ambas Tabla 1 y Tabla 2 hemos enumerado las métricas de rendimiento para el algoritmo DPOP original, el algoritmo DCPOP utilizando solo pseudobosques de bordes cruzados (DCPOP-CE), y el algoritmo DCPOP utilizando pseudobosques tradicionales y de bordes cruzados (DCPOP-All).",
        "Los pseudobosques utilizados para DPOP fueron generados utilizando 5 heurísticas: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB y DFS MCN BEC.",
        "Estas son todas las versiones del recorrido DFS guiado discutidas en la Sección 5.",
        "Los pseudobosques de bordes cruzados utilizados para DCPOP-CE fueron generados utilizando 5 heurísticas: MCN, LCN, MCN A-B, LCN A-B y LCSG A-B.",
        "Estas son todas las versiones del recorrido de mejor primero discutidas en la Sección 5.",
        "Para tanto DPOP como DCPOP-CE elegimos el mejor pseudoárbol producido por sus respectivas 5 heurísticas para cada problema en el conjunto.",
        "Para DCPOP-All elegimos la mejor pseudotree producida por las 10 heurísticas para cada problema en el conjunto.",
        "Para las métricas de CD y MD, el valor mostrado es el número promedio de dimensiones.",
        "Para la métrica de PC, el valor mostrado es el logaritmo natural del costo de ruta secuencial máximo (ya que el valor real crece exponencialmente con la complejidad del problema).",
        "La última fila en ambas tablas es una medida de mejora de DCPOP-All sobre DPOP.",
        "Para las métricas CD y MD, el valor mostrado es una reducción en el número de dimensiones.",
        "Para la métrica de PC, el valor mostrado es una reducción porcentual en el costo máximo de la ruta secuencial (% = DP OP −DCP OP DCP OP ∗ 100).",
        "Observa que DCPOP supera a DPOP en todas las métricas.",
        "Esto se sigue lógicamente de nuestra afirmación anterior de que, dada la misma entrada, DCPOP se comporta exactamente igual que DPOP.",
        "Así, dada la elección entre los pseudobosques producidos por las 10 heurísticas, DCPOP-All siempre superará a DCPOP-CE y DPOP.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 6: Mejora del Costo del Camino DCPOP Reunión Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Tabla 3: Problemas de Programación de Reuniones realizan DPOP.",
        "Otra tendencia que observamos es que la mejora es mayor para problemas de alta densidad que para problemas de baja densidad.",
        "Mostramos esta tendencia con mayor detalle en las Figuras 4, 5 y 6.",
        "Observa cómo la mejora aumenta a medida que aumenta la complejidad del problema. 7.2 Problema de Programación de Reuniones Además de nuestras pruebas genéricas iniciales de DCOP, realizamos una serie de pruebas en el Problema de Programación de Reuniones (MSP) como se describe en [6].",
        "La configuración del problema incluye un número de personas agrupadas en departamentos.",
        "Cada persona debe asistir a un número específico de reuniones.",
        "Las reuniones pueden llevarse a cabo dentro de los departamentos o entre departamentos, y pueden asignarse a uno de los ocho horarios disponibles.",
        "El MSP se mapea a una instancia de DCOP donde cada variable representa el intervalo de tiempo en el que una persona específica asistirá a una reunión específica.",
        "Todas las variables que pertenecen a la misma persona tienen restricciones de exclusión mutua para que la persona no pueda asistir a más de una reunión durante el mismo intervalo de tiempo.",
        "Todas las variables que pertenecen a la misma reunión tienen restricciones de igualdad para que todos los participantes elijan el mismo horario.",
        "Se imponen restricciones unarias en cada variable para tener en cuenta la valoración de una persona de cada reunión y franja horaria.",
        "Para nuestros tests generamos 100 problemas de muestra para cada combinación de agentes y reuniones.",
        "Los resultados se muestran en la Tabla 3.",
        "Los valores en las primeras cinco columnas representan (en orden de izquierda a derecha), el número total de agentes, el número total de reuniones, el número total de variables, el promedio total de restricciones y el promedio mínimo de IW producido por un pseudoárbol tradicional.",
        "Las últimas tres columnas muestran las mismas métricas que utilizamos para las instancias genéricas de DCOP, excepto que esta vez solo mostramos las mejoras de DCPOP-All sobre DPOP.",
        "El rendimiento es mejor en promedio para todas las instancias de MSP, pero nuevamente vemos mejoras más grandes para instancias de problemas más complejos. 8.",
        "CONCLUSIONES Y TRABAJO FUTURO Presentamos un algoritmo completo y distribuido que resuelve instancias generales de DCOP utilizando arreglos de pseudoramas cruzados.",
        "Nuestro algoritmo extiende el algoritmo DPOP al agregar mensajes adicionales de propagación de utilidad e introducir el concepto de fusión de ramas durante la fase de propagación de utilidad.",
        "Nuestro algoritmo también permite que las asignaciones de valor ocurran en puntos de fusión de nivel superior para nodos de nivel inferior.",
        "Hemos demostrado que DCPOP extiende completamente DPOP al realizar las mismas operaciones dadas las mismas entradas.",
        "También hemos demostrado a través de algunos ejemplos y datos experimentales que DCPOP puede lograr un mejor rendimiento para algunas instancias del problema al extender el conjunto de entrada permitido para incluir pseudobosques cruzados.",
        "Damos especial énfasis al papel que desempeñan las heurísticas de recorrido de bordes en la generación de pseudobosques.",
        "Hemos demostrado que la penalización en el rendimiento es mínima para generar múltiples heurísticas, y que podemos elegir el mejor pseudoárbol generado en complejidad lineal de espacio-tiempo.",
        "Dada la importancia de un buen pseudoárbol para el rendimiento, el trabajo futuro incluirá nuevas heurísticas para encontrar mejores pseudo",
        "El trabajo futuro también incluirá adaptar las extensiones existentes de DPOP [5, 7] que soportan diferentes dominios de problemas para su uso con DCPOP. 9.",
        "REFERENCIAS [1] J. Liu y K. P. Sycara.",
        "Explotando la estructura del problema para la optimización distribuida de restricciones.",
        "En V. Lesser, editor, Actas de la Primera Conferencia Internacional sobre Sistemas Multiagente, páginas 246-254, San Francisco, CA, 1995.",
        "MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, y S. Kulkarni.",
        "Un enfoque dinámico distribuido de satisfacción de restricciones para la asignación de recursos.",
        "Notas de conferencia en Ciencias de la Computación, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe y M. Yokoo.",
        "Un método completo asíncrono para la optimización de restricciones distribuidas.",
        "En AAMAS 03, 2003. [4] A. Petcu.",
        "Frodo: Un marco para la optimización de restricciones abiertas/distribuidas.",
        "Informe técnico No. 2006/001, Instituto Federal Suizo de Tecnología (EPFL), Lausana (Suiza), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu y B. Faltings.",
        "A-dpop: Aproximaciones en optimización distribuida.",
        "En póster en CP 2005, páginas 802-806, Sitges, España, octubre de 2005. [6] A. Petcu y B. Faltings.",
        "Dpop: Un método escalable para la optimización de restricciones multiagente.",
        "En IJCAI 05, páginas 266-271, Edimburgo, Escocia, agosto de 2005. [7] A. Petcu, B. Faltings y D. Parkes.",
        "M-dpop: Implementación distribuida fiel de problemas eficientes de elección social.",
        "En AAMAS 06, páginas 1397-1404, Hakodate, Japón, mayo de 2006. [8] G. Ushakov.",
        "Resolviendo problemas de programación de reuniones utilizando un procedimiento de optimización distribuido de pseudobosque.",
        "Tesis de maestría, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida y K. Kuwabara.",
        "Satisfacción de restricciones distribuida para formalizar la resolución de problemas distribuidos.",
        "En la Conferencia Internacional sobre Sistemas de Computación Distribuida, páginas 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida y K. Kuwabara.",
        "El problema de satisfacción de restricciones distribuidas: Formalización y algoritmos.",
        "Ingeniería del Conocimiento y de Datos, 10(5):673-685, 1998. 748 La Sexta Internacional.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07)"
    ],
    "error_count": 6,
    "keys": {
        "distributed constraint optimization": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Complete <br>distributed constraint optimization</br> Method For Non-Traditional Pseudotree Arrangements∗ James Atlas Computer and Information Sciences University of Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Computer and Information Sciences University of Delaware Newark, DE 19716 decker@cis.udel.edu ABSTRACT <br>distributed constraint optimization</br> (DCOP) is a general framework that can model complex problems in multi-agent systems.",
                "Several current algorithms that solve general DCOP instances, including ADOPT and DPOP, arrange agents into a traditional pseudotree structure.",
                "We introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements.",
                "Our algorithm correctly solves DCOP instances for pseudotrees that include edges between nodes in separate branches.",
                "The algorithm also solves instances with traditional pseudotree arrangements using the same procedure as DPOP.",
                "We compare our algorithm with DPOP using several metrics including the induced width of the pseudotrees, the maximum dimensionality of messages and computation, and the maximum sequential path cost through the algorithm.",
                "We prove that for some problem instances it is not possible to generate a traditional pseudotree using edge-traversal heuristics that will outperform a cross-edged pseudotree.",
                "We use multiple heuristics to generate pseudotrees and choose the best pseudotree in linear space-time complexity.",
                "For some problem instances we observe significant improvements in message and computation sizes compared to DPOP.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent Systems General Terms Algorithms 1.",
                "INTRODUCTION Many historical problems in the AI community can be transformed into Constraint Satisfaction Problems (CSP).",
                "With the advent of distributed AI, multi-agent systems became a popular way to model the complex interactions and coordination required to solve distributed problems.",
                "CSPs were originally extended to distributed agent environments in [9].",
                "Early domains for distributed constraint satisfaction problems (DisCSP) included job shop scheduling [1] and resource allocation [2].",
                "Many domains for agent systems, especially teamwork coordination, distributed scheduling, and sensor networks, involve overly constrained problems that are difficult or impossible to satisfy for every constraint.",
                "Recent approaches to solving problems in these domains rely on optimization techniques that map constraints into multi-valued utility functions.",
                "Instead of finding an assignment that satisfies all constraints, these approaches find an assignment that produces a high level of global utility.",
                "This extension to the original DisCSP approach has become popular in multi-agent systems, and has been labeled the <br>distributed constraint optimization</br> Problem (DCOP) [1].",
                "Current algorithms that solve complete DCOPs use two main approaches: search and dynamic programming.",
                "Search based algorithms that originated from DisCSP typically use some form of backtracking [10] or bounds propagation, as in ADOPT [3].",
                "Dynamic programming based algorithms include DPOP and its extensions [5, 6, 7].",
                "To date, both categories of algorithms arrange agents into a traditional pseudotree to solve the problem.",
                "It has been shown in [6] that any constraint graph can be mapped into a traditional pseudotree.",
                "However, it was also shown that finding the optimal pseudotree was NP-Hard.",
                "We began to investigate the performance of traditional pseudotrees generated by current edge-traversal heuristics.",
                "We found that these heuristics often produced little parallelism as the pseudotrees tended to have high depth and low branching factors.",
                "We suspected that there could be other ways to arrange the pseudotrees that would provide increased parallelism and smaller message sizes.",
                "After exploring these other arrangements we found that cross-edged pseudotrees provide shorter depths and higher branching factors than the traditional pseudotrees.",
                "Our hypothesis was that these crossedged pseudotrees would outperform traditional pseudotrees for some problem types.",
                "In this paper we introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements which include cross-edged pseudotrees.",
                "We begin with a definition of 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, traditional pseudotrees, and cross-edged pseudotrees.",
                "We then provide a summary of the original DPOP algorithm and introduce our DCPOP algorithm.",
                "We discuss the complexity of our algorithm as well as the impact of pseudotree generation heuristics.",
                "We then show that our Distributed Cross-edged Pseudotree Optimization Procedure (DCPOP) performs significantly better in practice than the original DPOP algorithm for some problem instances.",
                "We conclude with a selection of ideas for future work and extensions for DCPOP. 2.",
                "PROBLEM DEFINITION DCOP has been formalized in slightly different ways in recent literature, so we will adopt the definition as presented in [6].",
                "A <br>distributed constraint optimization</br> Problem with n nodes and m constraints consists of the tuple < X, D, U > where: • X = {x1,..,xn} is a set of variables, each one assigned to a unique agent • D = {d1,..,dn} is a set of finite domains for each variable • U = {u1,..,um} is a set of utility functions such that each function involves a subset of variables in X and defines a utility for each combination of values among these variables An optimal solution to a DCOP instance consists of an assignment of values in D to X such that the sum of utilities in U is maximal.",
                "Problem domains that require minimum cost instead of maximum utility can map costs into negative utilities.",
                "The utility functions represent soft constraints but can also represent hard constraints by using arbitrarily large negative values.",
                "For this paper we only consider binary utility functions involving two variables.",
                "Higher order utility functions can be modeled with minor changes to the algorithm, but they also substantially increase the complexity. 2.1 Traditional Pseudotrees Pseudotrees are a common structure used in search procedures to allow parallel processing of independent branches.",
                "As defined in [6], a pseudotree is an arrangement of a graph G into a rooted tree T such that vertices in G that share an edge are in the same branch in T. A back-edge is an edge between a node X and any node which lies on the path from X to the root (excluding Xs parent).",
                "Figure 1 shows a pseudotree with four nodes, three edges (A-B, B-C, BD), and one back-edge (A-C).",
                "Also defined in [6] are four types of relationships between nodes exist in a pseudotree: • P(X) - the parent of a node X: the single node higher in the pseudotree that is connected to X directly through a tree edge • C(X) - the children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through tree edges • PP(X) - the pseudo-parents of a node X: the set of nodes higher in the pseudotree that are connected to X directly through back-edges (In Figure 1, A = PP(C)) • PC(X) - the pseudo-children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through back-edges (In Figure 1, C = PC(A)) Figure 1: A traditional pseudotree.",
                "Solid line edges represent parent-child relationships and the dashed line represents a pseudo-parent-pseudo-child relationship.",
                "Figure 2: A cross-edged pseudotree.",
                "Solid line edges represent parent-child relationships, the dashed line represents a pseudoparent-pseudo-child relationship, and the dotted line represents a branch-parent-branch-child relationship.",
                "The bolded node, B, is the merge point for node E. 2.2 Cross-edged Pseudotrees We define a cross-edge as an edge from node X to a node Y that is above X but not in the path from X to the root.",
                "A cross-edged pseudotree is a traditional pseudotree with the addition of cross-edges.",
                "Figure 2 shows a cross-edged pseudotree with a cross-edge (D-E).",
                "In a cross-edged pseudotree we designate certain edges as primary.",
                "The set of primary edges defines a spanning tree of the nodes.",
                "The parent, child, pseudo-parent, and pseudo-child relationships from the traditional pseudotree are now defined in the context of this primary edge spanning tree.",
                "This definition also yields two additional types of relationships that may exist between nodes: • BP(X) - the branch-parents of a node X: the set of nodes higher in the pseudotree that are connected to X but are not in the primary path from X to the root (In Figure 2, D = BP(E)) • BC(X) - the branch-children of a node X: the set of nodes lower in the pseudotree that are connected to X but are not in any primary path from X to any leaf node (In Figure 2, E = BC(D)) 2.3 Pseudotree Generation 742 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Current algorithms usually have a pre-execution phase to generate a traditional pseudotree from a general DCOP instance.",
                "Our DCPOP algorithm generates a cross-edged pseudotree in the same fashion.",
                "First, the DCOP instance < X, D, U > translates directly into a graph with X as the set of vertices and an edge for each pair of variables represented in U.",
                "Next, various heuristics are used to arrange this graph into a pseudotree.",
                "One common heuristic is to perform a guided depth-first search (DFS) as the resulting traversal is a pseudotree, and a DFS can easily be performed in a distributed fashion.",
                "We define an edge-traversal based method as any method that produces a pseudotree in which all parent/child pairs share an edge in the original graph.",
                "This includes DFS, breadth-first search, and best-first search based traversals.",
                "Our heuristics that generate cross-edged pseudotrees use a distributed best-first search traversal. 3.",
                "DPOP ALGORITHM The original DPOP algorithm operates in three main phases.",
                "The first phase generates a traditional pseudotree from the DCOP instance using a distributed algorithm.",
                "The second phase joins utility hypercubes from children and the local node and propagates them towards the root.",
                "The third phase chooses an assignment for each domain in a top down fashion beginning with the agent at the root node.",
                "The complexity of DPOP depends on the size of the largest computation and utility message during phase two.",
                "It has been shown that this size directly corresponds to the induced width of the pseudotree generated in phase one [6].",
                "DPOP uses polynomial time heuristics to generate the pseudotree since finding the minimum induced width pseudotree is NP-hard.",
                "Several distributed edgetraversal heuristics have been developed to find low width pseudotrees [8].",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, and pseudo-children. 3.1 Utility Propagation Agents located at leaf nodes in the pseudotree begin the process by calculating a local utility hypercube.",
                "This hypercube at node X contains summed utilities for each combination of values in the domains for P(X) and PP(X).",
                "This hypercube has dimensional size equal to the number of pseudo-parents plus one.",
                "A message containing this hypercube is sent to P(X).",
                "Agents located at non-leaf nodes wait for all messages from children to arrive.",
                "Once the agent at node Y has all utility messages, it calculates its local utility hypercube which includes domains for P(Y), PP(Y), and Y.",
                "The local utility hypercube is then joined with all of the hypercubes from the child messages.",
                "At this point all utilities involving node Y are known, and the domain for Y may be safely eliminated from the joined hypercube.",
                "This elimination process chooses the best utility over the domain of Y for each combination of the remaining domains.",
                "A message containing this hypercube is now sent to P(Y).",
                "The dimensional size of this hypercube depends on the number of overlapping domains in received messages and the local utility hypercube.",
                "This dynamic programming based propagation phase continues until the agent at the root node of the pseudotree has received all messages from its children. 3.2 Value Propagation Value propagation begins when the agent at the root node Z has received all messages from its children.",
                "Since Z has no parents or pseudo-parents, it simply combines the utility hypercubes received from its children.",
                "The combined hypercube contains only values for the domain for Z.",
                "At this point the agent at node Z simply chooses the assignment for its domain that has the best utility.",
                "A value propagation message with this assignment is sent to each node in C(Z).",
                "Each other node then receives a value propagation message from its parent and chooses the assignment for its domain that has the best utility given the assignments received in the message.",
                "The node adds its domain assignment to the assignments it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen an assignment for their domain. 4.",
                "DCPOP ALGORITHM Our extension to the original DPOP algorithm, shown in Algorithm 1, shares the same three phases.",
                "The first phase generates the cross-edged pseudotree for the DCOP instance.",
                "The second phase merges branches and propagates the utility hypercubes.",
                "The third phase chooses assignments for domains at branch merge points and in a top down fashion, beginning with the agent at the root node.",
                "For the first phase we generate a pseudotree using several distributed heuristics and select the one with lowest overall complexity.",
                "The complexity of the computation and utility message size in DCPOP does not directly correspond to the induced width of the cross-edged pseudotree.",
                "Instead, we use a polynomial time method for calculating the maximum computation and utility message size for a given cross-edged pseudotree.",
                "A description of this method and the pseudotree selection process appears in Section 5.",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, pseudo-children, branch-parents, and branch-children. 4.1 Merging Branches and Utility Propagation In the original DPOP algorithm a node X only had utility functions involving its parent and its pseudo-parents.",
                "In DCPOP, a node X is allowed to have a utility function involving a branch-parent.",
                "The concept of a branch can be seen in Figure 2 with node E representing our node X.",
                "The two distinct paths from node E to node B are called branches of E. The single node where all branches of E meet is node B, which is called the merge point of E. Agents with nodes that have branch-parents begin by sending a utility propagation message to each branch-parent.",
                "This message includes a two dimensional utility hypercube with domains for the node X and the branch-parent BP(X).",
                "It also includes a branch information structure which contains the origination node of the branch, X, the total number of branches originating from X, and the number of branches originating from X that are merged into a single representation by this branch information structure (this number starts at 1).",
                "Intuitively when the number of merged branches equals the total number of originating branches, the algorithm has reached the merge point for X.",
                "In Figure 2, node E sends a utility propagation message to its branch-parent, node D. This message has dimensions for the domains of E and D, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "As in the original DPOP utility propagation phase, an agent at leaf node X sends a utility propagation message to its parent.",
                "In DCPOP this message contains dimensions for the domains of P(X) and PP(X).",
                "If node X also has branch-parents, then the utility propagation message also contains a dimension for the domain of X, and will include a branch information structure.",
                "In Figure 2, node E sends a utility propagation message to its parent, node C. This message has dimensions for the domains of E and C, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "When a node Y receives utility propagation messages from all of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 743 its children and branch-children, it merges any branches with the same origination node X.",
                "The merged branch information structure accumulates the number of merged branches for X.",
                "If the cumulative total number of merged branches equals the total number of branches, then Y is the merge point for X.",
                "This means that the utility hypercubes present at Y contain all information about the valuations for utility functions involving node X.",
                "In addition to the typical elimination of the domain of Y from the utility hypercubes, we can now safely eliminate the domain of X from the utility hypercubes.",
                "To illustrate this process, we will examine what happens in the second phase for node B in Figure 2.",
                "In the second phase Node B receives two utility propagation messages.",
                "The first comes from node C and includes dimensions for domains E, B, and A.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "The second comes from node D and includes dimensions for domains E and B.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "Node B then merges the branch information structures from both messages because they have the same origination, node E. Since the number of merged branches originating from E is now 2 and the total branches originating from E is 2, node B now eliminates the dimensions for domain E. Node B also eliminates the dimension for its own domain, leaving only information about domain A. Node B then sends a utility propagation message to node A, containing only one dimension for the domain of A.",
                "Although not possible in DPOP, this method of utility propagation and dimension elimination may produce hypercubes at node Y that do not share any domains.",
                "In DCPOP we do not join domain independent hypercubes, but instead may send multiple hypercubes in the utility propagation message sent to the parent of Y.",
                "This lazy approach to joins helps to reduce message sizes. 4.2 Value Propagation As in DPOP, value propagation begins when the agent at the root node Z has received all messages from its children.",
                "At this point the agent at node Z chooses the assignment for its domain that has the best utility.",
                "If Z is the merge point for the branches of some node X, Z will also choose the assignment for the domain of X.",
                "Thus any node that is a merge point will choose assignments for a domain other than its own.",
                "These assignments are then passed down the primary edge hierarchy.",
                "If node X in the hierarchy has branch-parents, then the value assignment message from P(X) will contain an assignment for the domain of X.",
                "Every node in the hierarchy adds any assignments it has chosen to the ones it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen or received an assignment for their domain. 4.3 Proof of Correctness We will prove the correctness of DCPOP by first noting that DCPOP fully extends DPOP and then examining the two cases for value assignment in DCPOP.",
                "Given a traditional pseudotree as input, the DCPOP algorithm execution is identical to DPOP.",
                "Using a traditional pseudotree arrangement no nodes have branch-parents or branch-children since all edges are either back-edges or tree edges.",
                "Thus the DCPOP algorithm using a traditional pseudotree sends only utility propagation messages that contain domains belonging to the parent or pseudo-parents of a node.",
                "Since no node has any branch-parents, no branches exist, and thus no node serves as a merge point for any other node.",
                "Thus all value propagation assignments are chosen at the node of the assignment domain.",
                "For DCPOP execution with cross-edged pseudotrees, some nodes serve as merge points.",
                "We note that any node X that is not a merge point assigns its value exactly as in DPOP.",
                "The local utility hypercube at X contains domains for X, P(X), PP(X), and BC(X).",
                "As in DPOP the value assignment message received at X includes the values assigned to P(X) and PP(X).",
                "Also, since X is not a merge point, all assignments to BC(X) must have been calculated at merge points higher in the tree and are in the value assignment message from P(X).",
                "Thus after eliminating domains for which assignments are known, only the domain of X is left.",
                "The agent at node X can now correctly choose the assignment with maximum utility for its own domain.",
                "If node X is a merge point for some branch-child Y, we know that X must be a node along the path from Y to the root, and from P(Y) and all BP(Y) to the root.",
                "From the algorithm, we know that Y necessarily has all information from C(Y), PC(Y), and BC(Y) since it waits for their messages.",
                "Node X has information about all nodes below it in the tree, which would include Y, P(Y), BP(Y), and those PP(Y) that are below X in the tree.",
                "For any PP(Y) above X in the tree, X receives the assignment for the domain of PP(Y) in the value assignment message from P(X).",
                "Thus X has utility information about all of the utility functions of which Y is a part.",
                "By eliminating domains included in the value assignment message, node X is left with a local utility hypercube with domains for X and Y.",
                "The agent at node X can now correctly choose the assignments with maximum utility for the domains of X and Y. 4.4 Complexity Analysis The first phase of DCPOP sends one message to each P(X), PP(X), and BP(X).",
                "The second phase sends one value assignment message to each C(X).",
                "Thus, DCPOP produces a linear number of messages with respect to the number of edges (utility functions) in the cross-edged pseudotree and the original DCOP instance.",
                "The actual complexity of DCPOP depends on two additional measurements: message size and computation size.",
                "Message size and computation size in DCPOP depend on the number of overlapping branches as well as the number of overlapping back-edges.",
                "It was shown in [6] that the number of overlapping back-edges is equal to the induced width of the pseudotree.",
                "In a poorly constructed cross-edged pseudotree, the number of overlapping branches at node X can be as large as the total number of descendants of X.",
                "Thus, the total message size in DCPOP in a poorly constructed instance can be space-exponential in the total number of nodes in the graph.",
                "However, in practice a well constructed cross-edged pseudotree can achieve much better results.",
                "Later we address the issue of choosing well constructed crossedged pseudotrees from a set.",
                "We introduce an additional measurement of the maximum sequential path cost through the algorithm.",
                "This measurement directly relates to the maximum amount of parallelism achievable by the algorithm.",
                "To take this measurement we first store the total computation size for each node during phase two and three.",
                "This computation size represents the number of individual accesses to a value in a hypercube at each node.",
                "For example, a join between two domains of size 4 costs 4 ∗ 4 = 16.",
                "Two directed acyclic graphs (DAG) can then be drawn; one with the utility propagation messages as edges and the phase two costs at nodes, and the other with value assignment messages and the phase three costs at nodes.",
                "The maximum sequential path cost is equal to the sum of the longest path on each DAG from the root to any leaf node. 5.",
                "HEURISTICS In our assessment of complexity in DCPOP we focused on the worst case possibly produced by the algorithm.",
                "We acknowledge 744 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Algorithm 1 DCPOP Algorithm 1: DCPOP(X; D; U) Each agent Xi executes: Phase 1: pseudotree creation 2: elect leader from all Xj ∈ X 3: elected leader initiates pseudotree creation 4: afterwards, Xi knows P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) and PC(Xi) Phase 2: UTIL message propagation 5: if |BP(Xi)| > 0 then 6: BRANCHXi ← |BP(Xi)| + 1 7: for all Xk ∈BP(Xi) do 8: UTILXi (Xk) ←Compute utils(Xi, Xk) 9: Send message(Xk,UTILXi (Xk),BRANCHXi ) 10: if |C(Xi)| = 0(i.e.",
                "Xi is a leaf node) then 11: UTILXi (P(Xi)) ← Compute utils(P(Xi),PP(Xi)) for all PP(Xi) 12: Send message(P(Xi), UTILXi (P(Xi)),BRANCHXi ) 13: Send message(PP(Xi), empty UTIL, empty BRANCH) to all PP(Xi) 14: activate UTIL Message handler() Phase 3: VALUE message propagation 15: activate VALUE Message handler() END ALGORITHM UTIL Message handler(Xk,UTILXk (Xi), BRANCHXk ) 16: store UTILXk (Xi),BRANCHXk (Xi) 17: if UTIL messages from all children and branch children arrived then 18: for all Bj ∈BRANCH(Xi) do 19: if Bj is merged then 20: join all hypercubes where Bj ∈UTIL(Xi) 21: eliminate Bj from the joined hypercube 22: if P(Xi) == null (that means Xi is the root) then 23: v ∗ i ← Choose optimal(null) 24: Send VALUE(Xi, v ∗ i) to all C(Xi) 25: else 26: UTILXi (P(Xi)) ← Compute utils(P(Xi), PP(Xi)) 27: Send message(P(Xi),UTILXi (P(Xi)), BRANCHXi (P(Xi))) VALUE Message handler(VALUEXi ,P(Xi)) 28: add all Xk ← v ∗ k ∈VALUEXi ,P(Xi) to agent view 29: Xi ← v ∗ i =Choose optimal(agent view) 30: Send VALUEXl , Xi to all Xl ∈C(Xi) that in real world problems the generation of the pseudotree has a significant impact on the actual performance.",
                "The problem of finding the best pseudotree for a given DCOP instance is NP-Hard.",
                "Thus a heuristic is used for generation, and the performance of the algorithm depends on the pseudotree found by the heuristic.",
                "Some previous research focused on finding heuristics to generate good pseudotrees [8].",
                "While we have developed some heuristics that generate good cross-edged pseudotrees for use with DCPOP, our focus has been to use multiple heuristics and then select the best pseudotree from the generated pseudotrees.",
                "We consider only heuristics that run in polynomial time with respect to the number of nodes in the original DCOP instance.",
                "The actual DCPOP algorithm has worst case exponential complexity, but we can calculate the maximum message size, computation size, and sequential path cost for a given cross-edged pseudotree in linear space-time complexity.",
                "To do this, we simply run the algorithm without attempting to calculate any of the local utility hypercubes or optimal value assignments.",
                "Instead, messages include dimensional and branch information but no utility hypercubes.",
                "After each heuristic completes its generation of a pseudotree, we execute the measurement procedure and propagate the measurement information up to the chosen root in that pseudotree.",
                "The root then broadcasts the total complexity for that heuristic to all nodes.",
                "After all heuristics have had a chance to complete, every node knows which heuristic produced the best pseudotree.",
                "Each node then proceeds to begin the DCPOP algorithm using its knowledge of the pseudotree generated by the best heuristic.",
                "The heuristics used to generate traditional pseudotrees perform a distributed DFS traversal.",
                "The general distributed algorithm uses a token passing mechanism and a linear number of messages.",
                "Improved DFS based heuristics use a special procedure to choose the root node, and also provide an ordering function over the neighbors of a node to determine the order of path recursion.",
                "The DFS based heuristics used in our experiments come from the work done in [4, 8]. 5.1 The best-first cross-edged pseudotree heuristic The heuristics used to generate cross-edged pseudotrees perform a best-first traversal.",
                "A general distributed best-first algorithm for node expansion is presented in Algorithm 2.",
                "An evaluation function at each node provides the values that are used to determine the next best node to expand.",
                "Note that in this algorithm each node only exchanges its best value with its neighbors.",
                "In our experiments we used several evaluation functions that took as arguments an ordered list of ancestors and a node, which contains a list of neighbors (with each neighbors placement depth in the tree if it was placed).",
                "From these we can calculate branchparents, branch-children, and unknown relationships for a potential node placement.",
                "The best overall function calculated the value as ancestors−(branchparents+branchchildren) with the number of unknown relationships being a tiebreak.",
                "After completion each node has knowledge of its parent and ancestors, so it can easily determine which connected nodes are pseudo-parents, branchparents, pseudo-children, and branch-children.",
                "The complexity of the best-first traversal depends on the complexity of the evaluation function.",
                "Assuming a complexity of O(V ) for the evaluation function, which is the case for our best overall function, the best-first traversal is O(V · E) which is at worst O(n3 ).",
                "For each v ∈ V we perform a place operation, and find the next node to place using the getBestNeighbor operation.",
                "The place operation is at most O(V ) because of the sent messages.",
                "Finding the next node uses recursion and traverses only already placed The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 745 Algorithm 2 Distributed Best-First Search Algorithm root ← electedleader next(root, ∅) place(node, parent) node.parent ← parent node.ancestors ← parent.ancestors ∪ parent send placement message (node, node.ancestors) to all neighbors of node next(current, previous) if current is not placed then place(current, previous) next(current, ∅) else best ← getBestNeighbor(current, previous) if best = ∅ then if previous = ∅ then terminate, all nodes are placed next(previous, ∅) else next(best, current) getBestNeighbor(current, previous) best ← ∅; score ← 0 for all n ∈ current.neighbors do if n! = previous then if n is placed then nscore ← getBestNeighbor(n, current) else nscore ← evaluate(current, n) if nscore > score then score ← nscore best ← n return best, score nodes, so it has O(V ) recursions.",
                "Each recursion performs a recursive getBestNeighbor operation that traverses all placed nodes and their neighbors.",
                "This operation is O(V · E), but results can be cached using only O(V ) space at each node.",
                "Thus we have O(V ·(V +V +V ·E)) = O(V 2 ·E).",
                "If we are smart about evaluating local changes when each node receives placement messages from its neighbors and cache the results the getBestNeighbor operation is only O(E).",
                "This increases the complexity of the place operation, but for all placements the total complexity is only O(V · E).",
                "Thus we have an overall complexity of O(V ·E+V ·(V +E)) = O(V ·E). 6.",
                "COMPARISON OF COMPLEXITY IN DPOP AND DCPOP We have already shown that given the same input, DCPOP performs the same as DPOP.",
                "We also have shown that we can accurately predict performance of a given pseudotree in linear spacetime complexity.",
                "If we use a constant number of heuristics to generate the set of pseudotrees, we can choose the best pseudotree in linear space-time complexity.",
                "We will now show that there exists a DCOP instance for which a cross-edged pseudotree outperforms all possible traditional pseudotrees (based on edge-traversal heuristics).",
                "In Figure 3(a) we have a DCOP instance with six nodes.",
                "This is a bipartite graph with each partition fully connected to the other (a) (b) (c) Figure 3: (a) The DCOP instance (b) A traditional pseudotree arrangement for the DCOP instance (c) A cross-edged pseudotree arrangement for the DCOP instance partition.",
                "In Figure 3(b) we see a traditional pseudotree arrangement for this DCOP instance.",
                "It is easy to see that any edgetraversal based heuristic cannot expand two nodes from the same partition in succession.",
                "We also see that no node can have more than one child because any such arrangement would be an invalid pseudotree.",
                "Thus any traditional pseudotree arrangement for this DCOP instance must take the form of Figure 3(b).",
                "We can see that the back-edges F-B and F-A overlap node C. Node C also has a parent E, and a back-edge with D. Using the original DPOP algorithm (or DCPOP since they are identical in this case), we find that the computation at node C involves five domains: A, B, C, D, and E. In contrast, the cross-edged pseudotree arrangement in Figure 3(c) requires only a maximum of four domains in any computation during DCPOP.",
                "Since node A is the merge point for branches from both B and C, we can see that each of the nodes D, E, and F have two overlapping branches.",
                "In addition each of these nodes has node A as its parent.",
                "Using the DCPOP algorithm we find that the computation at node D (or E or F) involves four domains: A, B, C, and D (or E or F).",
                "Since no better traditional pseudotree arrangement can be created using an edge-traversal heuristic, we have shown that DCPOP can outperform DPOP even if we use the optimal pseudotree found through edge-traversal.",
                "We acknowledge that pseudotree arrangements that allow parent-child relationships without an actual constraint can solve the problem in Figure 3(a) with maximum computation size of four domains.",
                "However, current heuristics used with DPOP do not produce such pseudotrees, and such a heuristic would be difficult to distribute since each node would require information about nodes with which it has no constraint.",
                "Also, while we do not prove it here, cross-edged pseudotrees can produce smaller message sizes than such pseudotrees even if the computation size is similar.",
                "In practice, since finding the best pseudotree arrangement is NP-Hard, we find that heuristics that produce cross-edged pseudotrees often produce significantly smaller computation and message sizes. 7.",
                "EXPERIMENTAL RESULTS 746 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Existing performance metrics for DCOP algorithms include the total number of messages, synchronous clock cycles, and message size.",
                "We have already shown that the total number of messages is linear with respect to the number of constraints in the DCOP instance.",
                "We also introduced the maximum sequential path cost (PC) as a measurement of the maximum amount of parallelism achievable by the algorithm.",
                "The maximum sequential path cost is equal to the sum of the computations performed on the longest path from the root to any leaf node.",
                "We also include as metrics the maximum computation size in number of dimensions (CD) and maximum message size in number of dimensions (MD).",
                "To analyze the relative complexity of a given DCOP instance, we find the minimum induced width (IW) of any traditional pseudotree produced by a heuristic for the original DPOP. 7.1 Generic DCOP instances For our initial tests we randomly generated two sets of problems with 3000 cases in each.",
                "Each problem was generated by assigning a random number (picked from a range) of constraints to each variable.",
                "The generator then created binary constraints until each variable reached its maximum number of constraints.",
                "The first set uses 20 variables, and the best DPOP IW ranges from 1 to 16 with an average of 8.5.",
                "The second set uses 100 variables, and the best DPOP IW ranged from 2 to 68 with an average of 39.3.",
                "Since most of the problems in the second set were too complex to actually compute the solution, we took measurements of the metrics using the techniques described earlier in Section 5 without actually solving the problem.",
                "Results are shown for the first set in Table 1 and for the second set in Table 2.",
                "For the two problem sets we split the cases into low density and high density categories.",
                "Low density cases consist of those problems that have a best DPOP IW less than or equal to half of the total number of nodes (e.g.",
                "IW ≤ 10 for the 20 node problems and IW ≤ 50 for the 100 node problems).",
                "High density problems consist of the remainder of the problem sets.",
                "In both Table 1 and Table 2 we have listed performance metrics for the original DPOP algorithm, the DCPOP algorithm using only cross-edged pseudotrees (DCPOP-CE), and the DCPOP algorithm using traditional and cross-edged pseudotrees (DCPOP-All).",
                "The pseudotrees used for DPOP were generated using 5 heuristics: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB, and DFS MCN BEC.",
                "These are all versions of the guided DFS traversal discussed in Section 5.",
                "The cross-edged pseudotrees used for DCPOP-CE were generated using 5 heuristics: MCN, LCN, MCN A-B, LCN A-B, and LCSG A-B.",
                "These are all versions of the best-first traversal discussed in Section 5.",
                "For both DPOP and DCPOP-CE we chose the best pseudotree produced by their respective 5 heuristics for each problem in the set.",
                "For DCPOP-All we chose the best pseudotree produced by all 10 heuristics for each problem in the set.",
                "For the CD and MD metrics the value shown is the average number of dimensions.",
                "For the PC metric the value shown is the natural logarithm of the maximum sequential path cost (since the actual value grows exponentially with the complexity of the problem).",
                "The final row in both tables is a measurement of improvement of DCPOP-All over DPOP.",
                "For the CD and MD metrics the value shown is a reduction in number of dimensions.",
                "For the PC metric the value shown is a percentage reduction in the maximum sequential path cost (% = DP OP −DCP OP DCP OP ∗ 100).",
                "Notice that DCPOPAll outperforms DPOP on all metrics.",
                "This logically follows from our earlier assertion that given the same input, DCPOP performs exactly the same as DPOP.",
                "Thus given the choice between the pseudotrees produced by all 10 heuristics, DCPOP-All will always outLow Density High Density Algorithm CD MD PC CD MD PC DPOP 7.81 6.81 3.78 13.34 12.34 5.34 DCPOP-CE 7.94 6.73 3.74 12.83 11.43 5.07 DCPOP-All 7.62 6.49 3.66 12.72 11.36 5.05 Improvement 0.18 0.32 13% 0.62 0.98 36% Table 1: 20 node problems Low Density High Density Algorithm CD MD PC CD MD PC DPOP 33.35 32.35 14.55 58.51 57.50 19.90 DCPOP-CE 33.49 29.17 15.22 57.11 50.03 20.01 DCPOP-All 32.35 29.57 14.10 56.33 51.17 18.84 Improvement 1.00 2.78 104% 2.18 6.33 256% Table 2: 100 node problems Figure 4: Computation Dimension Size Figure 5: Message Dimension Size The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 747 Figure 6: Path Cost DCPOP Improvement Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Table 3: Meeting Scheduling Problems perform DPOP.",
                "Another trend we notice is that the improvement is greater for high density problems than low density problems.",
                "We show this trend in greater detail in Figures 4, 5, and 6.",
                "Notice how the improvement increases as the complexity of the problem increases. 7.2 Meeting Scheduling Problem In addition to our initial generic DCOP tests, we ran a series of tests on the Meeting Scheduling Problem (MSP) as described in [6].",
                "The problem setup includes a number of people that are grouped into departments.",
                "Each person must attend a specified number of meetings.",
                "Meetings can be held within departments or among departments, and can be assigned to one of eight time slots.",
                "The MSP maps to a DCOP instance where each variable represents the time slot that a specific person will attend a specific meeting.",
                "All variables that belong to the same person have mutual exclusion constraints placed so that the person cannot attend more than one meeting during the same time slot.",
                "All variables that belong to the same meeting have equality constraints so that all of the participants choose the same time slot.",
                "Unary constraints are placed on each variable to account for a persons valuation of each meeting and time slot.",
                "For our tests we generated 100 sample problems for each combination of agents and meetings.",
                "Results are shown in Table 3.",
                "The values in the first five columns represent (in left to right order), the total number of agents, the total number of meetings, the total number of variables, the average total number of constraints, and the average minimum IW produced by a traditional pseudotree.",
                "The last three columns show the same metrics we used for the generic DCOP instances, except this time we only show the improvements of DCPOP-All over DPOP.",
                "Performance is better on average for all MSP instances, but again we see larger improvements for more complex problem instances. 8.",
                "CONCLUSIONS AND FUTURE WORK We presented a complete, distributed algorithm that solves general DCOP instances using cross-edged pseudotree arrangements.",
                "Our algorithm extends the DPOP algorithm by adding additional utility propagation messages, and introducing the concept of branch merging during the utility propagation phase.",
                "Our algorithm also allows value assignments to occur at higher level merge points for lower level nodes.",
                "We have shown that DCPOP fully extends DPOP by performing the same operations given the same input.",
                "We have also shown through some examples and experimental data that DCPOP can achieve greater performance for some problem instances by extending the allowable input set to include cross-edged pseudotrees.",
                "We placed particular emphasis on the role that edge-traversal heuristics play in the generation of pseudotrees.",
                "We have shown that the performance penalty is minimal to generate multiple heuristics, and that we can choose the best generated pseudotree in linear space-time complexity.",
                "Given the importance of a good pseudotree for performance, future work will include new heuristics to find better pseudotrees.",
                "Future work will also include adapting existing DPOP extensions [5, 7] that support different problem domains for use with DCPOP. 9.",
                "REFERENCES [1] J. Liu and K. P. Sycara.",
                "Exploiting problem structure for <br>distributed constraint optimization</br>.",
                "In V. Lesser, editor, Proceedings of the First International Conference on Multi-Agent Systems, pages 246-254, San Francisco, CA, 1995.",
                "MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni.",
                "A dynamic distributed constraint satisfaction approach to resource allocation.",
                "Lecture Notes in Computer Science, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe, and M. Yokoo.",
                "An asynchronous complete method for <br>distributed constraint optimization</br>.",
                "In AAMAS 03, 2003. [4] A. Petcu.",
                "Frodo: A framework for open/<br>distributed constraint optimization</br>.",
                "Technical Report No. 2006/001 2006/001, Swiss Federal Institute of Technology (EPFL), Lausanne (Switzerland), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu and B. Faltings.",
                "A-dpop: Approximations in distributed optimization.",
                "In poster in CP 2005, pages 802-806, Sitges, Spain, October 2005. [6] A. Petcu and B. Faltings.",
                "Dpop: A scalable method for multiagent constraint optimization.",
                "In IJCAI 05, pages 266-271, Edinburgh, Scotland, Aug 2005. [7] A. Petcu, B. Faltings, and D. Parkes.",
                "M-dpop: Faithful distributed implementation of efficient social choice problems.",
                "In AAMAS 06, pages 1397-1404, Hakodate, Japan, May 2006. [8] G. Ushakov.",
                "Solving meeting scheduling problems using distributed pseudotree-optimization procedure.",
                "Masters thesis, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "Distributed constraint satisfaction for formalizing distributed problem solving.",
                "In International Conference on Distributed Computing Systems, pages 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "The distributed constraint satisfaction problem: Formalization and algorithms.",
                "Knowledge and Data Engineering, 10(5):673-685, 1998. 748 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "A Complete <br>distributed constraint optimization</br> Method For Non-Traditional Pseudotree Arrangements∗ James Atlas Computer and Information Sciences University of Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Computer and Information Sciences University of Delaware Newark, DE 19716 decker@cis.udel.edu ABSTRACT <br>distributed constraint optimization</br> (DCOP) is a general framework that can model complex problems in multi-agent systems.",
                "This extension to the original DisCSP approach has become popular in multi-agent systems, and has been labeled the <br>distributed constraint optimization</br> Problem (DCOP) [1].",
                "A <br>distributed constraint optimization</br> Problem with n nodes and m constraints consists of the tuple < X, D, U > where: • X = {x1,..,xn} is a set of variables, each one assigned to a unique agent • D = {d1,..,dn} is a set of finite domains for each variable • U = {u1,..,um} is a set of utility functions such that each function involves a subset of variables in X and defines a utility for each combination of values among these variables An optimal solution to a DCOP instance consists of an assignment of values in D to X such that the sum of utilities in U is maximal.",
                "Exploiting problem structure for <br>distributed constraint optimization</br>.",
                "An asynchronous complete method for <br>distributed constraint optimization</br>."
            ],
            "translated_annotated_samples": [
                "Un Método Completo de Optimización de Restricciones Distribuidas para Arreglos de Pseudotree No Tradicionales∗ James Atlas Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 decker@cis.udel.edu RESUMEN La Optimización de Restricciones Distribuidas (DCOP) es un marco general que puede modelar problemas complejos en sistemas multiagente.",
                "Esta extensión al enfoque original de DisCSP se ha vuelto popular en sistemas multiagente, y ha sido etiquetada como Problema de Optimización de Restricciones Distribuidas (DCOP) [1].",
                "Un Problema de Optimización de Restricciones Distribuidas con n nodos y m restricciones consiste en la tupla < X, D, U > donde: • X = {x1,..,xn} es un conjunto de variables, cada una asignada a un agente único • D = {d1,..,dn} es un conjunto de dominios finitos para cada variable • U = {u1,..,um} es un conjunto de funciones de utilidad tales que cada función involucra un subconjunto de variables en X y define una utilidad para cada combinación de valores entre estas variables. Una solución óptima para una instancia de DCOP consiste en una asignación de valores en D a X tal que la suma de las utilidades en U sea máxima.",
                "Explotando la estructura del problema para la <br>optimización distribuida de restricciones</br>.",
                "Un método completo asíncrono para la <br>optimización de restricciones distribuidas</br>."
            ],
            "translated_text": "Un Método Completo de Optimización de Restricciones Distribuidas para Arreglos de Pseudotree No Tradicionales∗ James Atlas Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 decker@cis.udel.edu RESUMEN La Optimización de Restricciones Distribuidas (DCOP) es un marco general que puede modelar problemas complejos en sistemas multiagente. Varios algoritmos actuales que resuelven instancias generales de DCOP, incluyendo ADOPT y DPOP, organizan a los agentes en una estructura de pseudobosque tradicional. Introducimos una extensión al algoritmo DPOP que maneja un conjunto extendido de disposiciones de pseudobosque. Nuestro algoritmo resuelve correctamente instancias de DCOP para pseudobosques que incluyen aristas entre nodos en ramas separadas. El algoritmo también resuelve instancias con arreglos de pseudobosque tradicionales utilizando el mismo procedimiento que DPOP. Comparamos nuestro algoritmo con DPOP utilizando varios métricos, incluyendo el ancho inducido de los pseudobosques, la dimensionalidad máxima de los mensajes y la computación, y el costo máximo de la ruta secuencial a través del algoritmo. Demostramos que para algunas instancias del problema no es posible generar un pseudoárbol tradicional utilizando heurísticas de recorrido de aristas que supere a un pseudoárbol con aristas cruzadas. Utilizamos múltiples heurísticas para generar pseudoárboles y elegir el mejor pseudoárbol en complejidad espacio-temporal lineal. Para algunas instancias del problema observamos mejoras significativas en los tamaños de los mensajes y cálculos en comparación con DPOP. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Algoritmos 1. INTRODUCCIÓN Muchos problemas históricos en la comunidad de IA pueden transformarse en Problemas de Satisfacción de Restricciones (CSP). Con la llegada de la inteligencia artificial distribuida, los sistemas multiagente se convirtieron en una forma popular de modelar las interacciones complejas y la coordinación necesaria para resolver problemas distribuidos. Los CSPs fueron originalmente extendidos a entornos de agentes distribuidos en [9]. Los primeros dominios para problemas de satisfacción de restricciones distribuidas (DisCSP) incluyeron la programación de talleres de trabajo [1] y la asignación de recursos [2]. Muchos dominios para sistemas de agentes, especialmente coordinación de trabajo en equipo, programación distribuida y redes de sensores, implican problemas excesivamente restringidos que son difíciles o imposibles de satisfacer para cada restricción. Los enfoques recientes para resolver problemas en estos dominios se basan en técnicas de optimización que mapean restricciones en funciones de utilidad multivaluadas. En lugar de encontrar una asignación que satisfaga todas las restricciones, estos enfoques encuentran una asignación que produce un alto nivel de utilidad global. Esta extensión al enfoque original de DisCSP se ha vuelto popular en sistemas multiagente, y ha sido etiquetada como Problema de Optimización de Restricciones Distribuidas (DCOP) [1]. Los algoritmos actuales que resuelven DCOPs completos utilizan dos enfoques principales: búsqueda y programación dinámica. Los algoritmos basados en búsqueda que se originaron a partir de DisCSP típicamente utilizan alguna forma de retroceso [10] o propagación de límites, como en ADOPT [3]. Los algoritmos basados en programación dinámica incluyen DPOP y sus extensiones [5, 6, 7]. Hasta la fecha, ambas categorías de algoritmos organizan agentes en un pseudoárbol tradicional para resolver el problema. Se ha demostrado en [6] que cualquier grafo de restricciones puede ser mapeado en un pseudoárbol tradicional. Sin embargo, también se demostró que encontrar el pseudoárbol óptimo era NP-Difícil. Comenzamos a investigar el rendimiento de los pseudobosques tradicionales generados por las heurísticas actuales de recorrido de aristas. Descubrimos que estas heurísticas a menudo generaban poco paralelismo, ya que los pseudárboles tendían a tener una gran profundidad y bajos factores de ramificación. Sospechábamos que podría haber otras formas de organizar los pseudobosques que proporcionarían un mayor paralelismo y tamaños de mensaje más pequeños. Después de explorar estos otros arreglos, descubrimos que los pseudobosques de bordes cruzados proporcionan profundidades más cortas y factores de ramificación más altos que los pseudobosques tradicionales. Nuestra hipótesis era que estos pseudorboles cruzados superarían a los pseudorboles tradicionales en algunos tipos de problemas. En este artículo presentamos una extensión al algoritmo DPOP que maneja un conjunto ampliado de disposiciones de pseudobosque que incluyen pseudobosques con aristas cruzadas. Comenzamos con una definición de 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, pseudobosques tradicionales y pseudobosques de bordes cruzados. Luego proporcionamos un resumen del algoritmo DPOP original e introducimos nuestro algoritmo DCPOP. Discutimos la complejidad de nuestro algoritmo, así como el impacto de las heurísticas de generación de pseudobosques. Luego demostramos que nuestro Procedimiento de Optimización de Pseudotree de Bordes Cruzados Distribuido (DCPOP) funciona significativamente mejor en la práctica que el algoritmo DPOP original para algunas instancias del problema. Concluimos con una selección de ideas para trabajos futuros y extensiones para DCPOP. 2. La DEFINICIÓN DEL PROBLEMA DCOP ha sido formalizada de maneras ligeramente diferentes en la literatura reciente, por lo que adoptaremos la definición presentada en [6]. Un Problema de Optimización de Restricciones Distribuidas con n nodos y m restricciones consiste en la tupla < X, D, U > donde: • X = {x1,..,xn} es un conjunto de variables, cada una asignada a un agente único • D = {d1,..,dn} es un conjunto de dominios finitos para cada variable • U = {u1,..,um} es un conjunto de funciones de utilidad tales que cada función involucra un subconjunto de variables en X y define una utilidad para cada combinación de valores entre estas variables. Una solución óptima para una instancia de DCOP consiste en una asignación de valores en D a X tal que la suma de las utilidades en U sea máxima. Los dominios de problemas que requieren un costo mínimo en lugar de una utilidad máxima pueden mapear los costos en utilidades negativas. Las funciones de utilidad representan restricciones suaves pero también pueden representar restricciones fuertes mediante el uso de valores negativos arbitrariamente grandes. Para este artículo solo consideramos funciones de utilidad binarias que involucran dos variables. Las funciones de utilidad de orden superior pueden ser modeladas con cambios menores en el algoritmo, pero también aumentan sustancialmente la complejidad. 2.1 Pseudárboles Tradicionales Los pseudárboles son una estructura común utilizada en procedimientos de búsqueda para permitir el procesamiento paralelo de ramas independientes. Como se define en [6], un pseudoárbol es un arreglo de un grafo G en un árbol raíz T de tal manera que los vértices en G que comparten una arista están en la misma rama en T. Una arista de retroceso es una arista entre un nodo X y cualquier nodo que se encuentre en el camino desde X hasta la raíz (excluyendo al padre de X). La Figura 1 muestra un pseudoárbol con cuatro nodos, tres aristas (A-B, B-C, BD) y una arista de retroceso (A-C). También se definen en [6] cuatro tipos de relaciones entre nodos que existen en un pseudoárbol: • P(X) - el padre de un nodo X: el único nodo más alto en el pseudoárbol que está conectado a X directamente a través de un borde de árbol • C(X) - los hijos de un nodo X: el conjunto de nodos más bajos en el pseudo Las líneas sólidas representan relaciones padre-hijo y la línea discontinua representa una relación pseudo-padre-pseudo-hijo. Figura 2: Un pseudoárbol de bordes cruzados. Las líneas sólidas representan relaciones padre-hijo, la línea discontinua representa una relación pseudo-padre-pseudo-hijo, y la línea punteada representa una relación rama-padre-rama-hijo. El nodo en negrita, B, es el punto de fusión para el nodo E. 2.2 Pseudárboles con aristas cruzadas Definimos una arista cruzada como una arista de un nodo X a un nodo Y que está por encima de X pero no en el camino desde X hasta la raíz. Un pseudoárbol de bordes cruzados es un pseudoárbol tradicional con la adición de bordes cruzados. La Figura 2 muestra un pseudoárbol con una arista cruzada (D-E). En un pseudoárbol de bordes cruzados designamos ciertos bordes como primarios. El conjunto de aristas primarias define un árbol de expansión de los nodos. Las relaciones de padre, hijo, pseudo-padre y pseudo-hijo del pseudotree tradicional ahora están definidas en el contexto de este árbol de expansión de borde primario. Esta definición también produce dos tipos adicionales de relaciones que pueden existir entre nodos: • BP(X) - los nodos padres de rama de un nodo X: el conjunto de nodos más altos en el pseudoárbol que están conectados a X pero no están en el camino principal desde X hasta la raíz (En la Figura 2, D = BP(E)) • BC(X) - los nodos hijos de rama de un nodo X: el conjunto de nodos más bajos en el pseudo La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Los algoritmos actuales suelen tener una fase de pre-ejecución para generar un pseudoárbol tradicional a partir de una instancia general de DCOP. Nuestro algoritmo DCPOP genera un pseudoárbol de bordes cruzados de la misma manera. Primero, la instancia DCOP < X, D, U > se traduce directamente en un grafo con X como el conjunto de vértices y una arista para cada par de variables representadas en U. A continuación, se utilizan varias heurísticas para organizar este grafo en un pseudoárbol. Un heurístico común es realizar una búsqueda en profundidad guiada (DFS, por sus siglas en inglés) ya que el recorrido resultante es un pseudoárbol, y un DFS se puede realizar fácilmente de manera distribuida. Definimos un método basado en el recorrido de aristas como cualquier método que produce un pseudoárbol en el que todos los pares padre/hijo comparten una arista en el grafo original. Esto incluye recorridos basados en DFS, búsqueda en anchura y búsqueda de mejor primero. Nuestras heurísticas que generan pseudobosques de bordes cruzados utilizan un recorrido de búsqueda mejor primero distribuido. 3. ALGORITMO DPOP El algoritmo DPOP original opera en tres fases principales. La primera fase genera un pseudoárbol tradicional a partir de la instancia de DCOP utilizando un algoritmo distribuido. La segunda fase une hipercubos de utilidad de los nodos hijos y el nodo local y los propaga hacia la raíz. La tercera fase elige una asignación para cada dominio de arriba hacia abajo, comenzando con el agente en el nodo raíz. La complejidad de DPOP depende del tamaño del cálculo más grande y del mensaje de utilidad durante la fase dos. Se ha demostrado que este tamaño corresponde directamente al ancho inducido del pseudoárbol generado en la fase uno [6]. DPOP utiliza heurísticas de tiempo polinómico para generar el pseudoárbol, ya que encontrar el pseudoárbol de ancho inducido mínimo es NP-duro. Se han desarrollado varias heurísticas de recorrido de borde distribuido para encontrar pseudobosques de ancho reducido [8]. Al final de la primera fase, cada agente conoce a su padre, hijos, pseudo-padres y pseudo-hijos. 3.1 Propagación de utilidad Los agentes ubicados en los nodos hoja del pseudoárbol comienzan el proceso calculando un hipercubo de utilidad local. Este hipercubo en el nodo X contiene las utilidades sumadas para cada combinación de valores en los dominios de P(X) y PP(X). Este hipercubo tiene un tamaño dimensional igual al número de pseudo-padres más uno. Un mensaje que contiene este hipercubo se envía a P(X). Los agentes ubicados en nodos no hoja esperan a que lleguen todos los mensajes de los nodos hijos. Una vez que el agente en el nodo Y tiene todos los mensajes de utilidad, calcula su hipercubo de utilidad local que incluye los dominios de P(Y), PP(Y) y Y. El hipercubo de utilidad local se une luego con todos los hipercubos de los mensajes hijos. En este punto, todas las utilidades que involucran al nodo Y son conocidas, y el dominio de Y puede ser eliminado de forma segura del hipercubo unido. Este proceso de eliminación elige la mejor utilidad sobre el dominio de Y para cada combinación de los dominios restantes. Un mensaje que contiene este hipercubo se envía ahora a P(Y). El tamaño dimensional de este hipercubo depende del número de dominios superpuestos en los mensajes recibidos y del hipercubo de utilidad local. Esta fase de propagación basada en programación dinámica continúa hasta que el agente en el nodo raíz del pseudoárbol haya recibido todos los mensajes de sus hijos. 3.2 Propagación de Valor La propagación de valor comienza cuando el agente en el nodo raíz Z ha recibido todos los mensajes de sus hijos. Dado que Z no tiene padres ni pseudo-padres, simplemente combina los hipercubos de utilidad recibidos de sus hijos. El hipercubo combinado contiene solo valores para el dominio de Z. En este punto, el agente en el nodo Z simplemente elige la asignación para su dominio que tiene la mejor utilidad. Un mensaje de propagación de valor con esta asignación se envía a cada nodo en C(Z). Cada nodo luego recibe un mensaje de propagación de valor de su padre y elige la asignación para su dominio que tenga la mejor utilidad dadas las asignaciones recibidas en el mensaje. El nodo agrega su asignación de dominio a las asignaciones que recibió y pasa el conjunto de asignaciones a sus hijos. El algoritmo está completo cuando todos los nodos han elegido una asignación para su dominio. ALGORITMO DCPOP Nuestra extensión al algoritmo DPOP original, mostrada en el Algoritmo 1, comparte las mismas tres fases. La primera fase genera el pseudoárbol de bordes cruzados para la instancia de DCOP. La segunda fase fusiona ramas y propaga los hipercubos de utilidad. La tercera fase elige asignaciones para dominios en los puntos de fusión de ramas y de arriba hacia abajo, comenzando con el agente en el nodo raíz. Para la primera fase generamos un pseudoárbol utilizando varios heurísticos distribuidos y seleccionamos el que tenga la menor complejidad general. La complejidad de la computación y el tamaño del mensaje de utilidad en DCPOP no corresponden directamente al ancho inducido del pseudoárbol de aristas cruzadas. En cambio, utilizamos un método de tiempo polinómico para calcular el tamaño máximo de computación y utilidad del mensaje para un pseudoárbol de bordes cruzados dado. Una descripción de este método y el proceso de selección de pseudodendrogramas aparece en la Sección 5. Al final de la primera fase, cada agente conoce a su padre, hijos, pseudo-padres, pseudo-hijos, padres de rama e hijos de rama. 4.1 Fusión de Ramas y Propagación de Utilidad En el algoritmo DPOP original, un nodo X solo tenía funciones de utilidad que involucraban a su padre y a sus pseudo-padres. En DCPOP, se permite que un nodo X tenga una función de utilidad que involucre a un padre de rama. El concepto de una rama se puede ver en la Figura 2 con el nodo E representando nuestro nodo X. Las dos rutas distintas desde el nodo E hasta el nodo B se llaman ramas de E. El único nodo donde se encuentran todas las ramas de E es el nodo B, que se llama punto de fusión de E. Los agentes con nodos que tienen padres de rama comienzan enviando un mensaje de propagación de utilidad a cada padre de rama. Este mensaje incluye un hipercubo de utilidad bidimensional con dominios para el nodo X y el nodo padre de la rama BP(X). También incluye una estructura de información de rama que contiene el nodo de origen de la rama, X, el número total de ramas que se originan en X y el número de ramas que se originan en X y se fusionan en una representación única por esta estructura de información de rama (este número comienza en 1). Intuitivamente, cuando el número de ramas fusionadas es igual al número total de ramas originales, el algoritmo ha alcanzado el punto de fusión para X. En la Figura 2, el nodo E envía un mensaje de propagación de utilidad a su nodo padre de rama, el nodo D. Este mensaje tiene dimensiones para los dominios de E y D, e incluye información de rama con un origen en E, 2 ramas totales y 1 rama fusionada. Como en la fase de propagación de utilidad de la utilidad DPOP original, un agente en el nodo hoja X envía un mensaje de propagación de utilidad a su padre. En DCPOP, este mensaje contiene dimensiones para los dominios de P(X) y PP(X). Si el nodo X también tiene padres de rama, entonces el mensaje de propagación de utilidad también contiene una dimensión para el dominio de X e incluirá una estructura de información de rama. En la Figura 2, el nodo E envía un mensaje de propagación de utilidad a su padre, el nodo C. Este mensaje tiene dimensiones para los dominios de E y C, e incluye información de rama con un origen en E, 2 ramas en total y 1 rama fusionada. Cuando un nodo Y recibe mensajes de propagación de utilidad de todos de The Sixth Intl. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), 743 sus hijos y sus hijos de rama, fusiona cualquier rama con el mismo nodo de origen X. La estructura de información de la rama fusionada acumula el número de ramas fusionadas para X. Si el número total acumulado de ramas fusionadas es igual al número total de ramas, entonces Y es el punto de fusión para X. Esto significa que los hipercubos de utilidad presentes en Y contienen toda la información sobre las valoraciones de las funciones de utilidad que involucran al nodo X. Además de la eliminación típica del dominio de Y de los hipercubos de utilidad, ahora podemos eliminar de forma segura el dominio de X de los hipercubos de utilidad. Para ilustrar este proceso, examinaremos lo que sucede en la segunda fase para el nodo B en la Figura 2. En la segunda fase, el Nodo B recibe dos mensajes de propagación de utilidad. El primero proviene del nodo C e incluye dimensiones para los dominios E, B y A. También tiene una estructura de información de ramas con origen en E, 2 ramas en total y 1 rama fusionada. El segundo proviene del nodo D e incluye dimensiones para los dominios E y B. También tiene una estructura de información de rama con origen en E, 2 ramas en total y 1 rama fusionada. El nodo B luego fusiona las estructuras de información de rama de ambos mensajes porque tienen la misma procedencia, el nodo E. Dado que el número de ramas fusionadas que provienen de E es ahora 2 y el total de ramas que provienen de E es 2, el nodo B elimina las dimensiones para el dominio E. El nodo B también elimina la dimensión para su propio dominio, dejando solo información sobre el dominio A. Luego, el nodo B envía un mensaje de propagación de utilidad al nodo A, que contiene solo una dimensión para el dominio de A. Aunque no sea posible en DPOP, este método de propagación de utilidad y eliminación de dimensiones puede producir hipercubos en el nodo Y que no comparten ningún dominio. En DCPOP no unimos hipercubos independientes de dominio, sino que en su lugar podemos enviar múltiples hipercubos en el mensaje de propagación de utilidad enviado al padre de Y. Este enfoque perezoso de las uniones ayuda a reducir el tamaño de los mensajes. 4.2 Propagación de valores Al igual que en DPOP, la propagación de valores comienza cuando el agente en el nodo raíz Z ha recibido todos los mensajes de sus hijos. En este punto, el agente en el nodo Z elige la asignación para su dominio que tiene la mejor utilidad. Si Z es el punto de fusión de las ramas de algún nodo X, Z también elegirá la asignación para el dominio de X. Por lo tanto, cualquier nodo que sea un punto de fusión elegirá asignaciones para un dominio que no sea el suyo propio. Estas tareas luego se pasan por la jerarquía de la cadena de mando principal. Si el nodo X en la jerarquía tiene padres de rama, entonces el mensaje de asignación de valor de P(X) contendrá una asignación para el dominio de X. Cada nodo en la jerarquía agrega cualquier tarea que haya elegido a las que recibió y pasa el conjunto de tareas a sus hijos. El algoritmo está completo cuando todos los nodos han elegido o recibido una asignación para su dominio. 4.3 Prueba de Corrección Demostraremos la corrección de DCPOP notando primero que DCPOP extiende completamente DPOP y luego examinando los dos casos para la asignación de valores en DCPOP. Dado un pseudoárbol tradicional como entrada, la ejecución del algoritmo DCPOP es idéntica a DPOP. Usando un arreglo de pseudodendrograma tradicional, ningún nodo tiene padres de rama o hijos de rama, ya que todas las aristas son aristas de retroceso o aristas de árbol. Por lo tanto, el algoritmo DCPOP utilizando un pseudoárbol tradicional envía solo mensajes de propagación de utilidad que contienen dominios pertenecientes al padre o pseudo-padres de un nodo. Dado que ningún nodo tiene ramas-padres, no existen ramas, y por lo tanto ningún nodo sirve como punto de fusión para ningún otro nodo. Por lo tanto, todas las asignaciones de propagación de valor se eligen en el nodo del dominio de la asignación. Para la ejecución de DCPOP con pseudárboles de bordes cruzados, algunos nodos actúan como puntos de fusión. Observamos que cualquier nodo X que no sea un punto de fusión asigna su valor exactamente como en DPOP. El hipercubo de utilidad local en X contiene dominios para X, P(X), PP(X) y BC(X). Como en DPOP, el mensaje de asignación de valores recibido en X incluye los valores asignados a P(X) y PP(X). Además, dado que X no es un punto de fusión, todas las asignaciones a BC(X) deben haber sido calculadas en puntos de fusión más altos en el árbol y están en el mensaje de asignación de valor de P(X). Por lo tanto, después de eliminar los dominios para los cuales se conocen las asignaciones, solo queda el dominio de X. El agente en el nodo X ahora puede elegir correctamente la asignación con la máxima utilidad para su propio dominio. Si el nodo X es un punto de fusión para alguna rama-hijo Y, sabemos que X debe ser un nodo a lo largo del camino desde Y hasta la raíz, y desde P(Y) y todos los BP(Y) hasta la raíz. A partir del algoritmo, sabemos que Y necesariamente tiene toda la información de C(Y), PC(Y) y BC(Y) ya que espera sus mensajes. El nodo X tiene información sobre todos los nodos debajo de él en el árbol, lo cual incluiría a Y, P(Y), BP(Y) y aquellos PP(Y) que están debajo de X en el árbol. Para cualquier PP(Y) por encima de X en el árbol, X recibe la asignación para el dominio de PP(Y) en el mensaje de asignación de valor de P(X). Por lo tanto, X tiene información de utilidad sobre todas las funciones de utilidad de las cuales Y forma parte. Al eliminar los dominios incluidos en el mensaje de asignación de valor, el nodo X se queda con un hipercubo de utilidad local con dominios para X e Y. El agente en el nodo X ahora puede elegir correctamente las asignaciones con la máxima utilidad para los dominios de X e Y. 4.4 Análisis de complejidad La primera fase de DCPOP envía un mensaje a cada P(X), PP(X) y BP(X). La segunda fase envía un mensaje de asignación de valor a cada C(X). Por lo tanto, DCPOP produce un número lineal de mensajes con respecto al número de aristas (funciones de utilidad) en el pseudoárbol de aristas cruzadas y la instancia original de DCOP. La complejidad real de DCPOP depende de dos medidas adicionales: el tamaño del mensaje y el tamaño de la computación. El tamaño del mensaje y el tamaño de la computación en DCPOP dependen del número de ramas superpuestas, así como del número de aristas de retroceso superpuestas. Se demostró en [6] que el número de aristas traslapadas es igual al ancho inducido del pseudoárbol. En un pseudoárbol de bordes cruzados mal construido, el número de ramas superpuestas en el nodo X puede ser tan grande como el número total de descendientes de X. Por lo tanto, el tamaño total del mensaje en DCPOP en una instancia mal construida puede ser exponencial en el espacio en el número total de nodos en el grafo. Sin embargo, en la práctica, un pseudoárbol bien construido con bordes cruzados puede lograr resultados mucho mejores. Más tarde abordaremos el tema de elegir pseudobosques cruzados bien construidos de un conjunto. Introducimos una medida adicional del costo máximo de la ruta secuencial a través del algoritmo. Esta medida se relaciona directamente con la cantidad máxima de paralelismo que puede lograr el algoritmo. Para tomar esta medida, primero almacenamos el tamaño total de cálculo para cada nodo durante las fases dos y tres. Este tamaño de cálculo representa el número de accesos individuales a un valor en un hipercubo en cada nodo. Por ejemplo, una unión entre dos dominios de tamaño 4 cuesta 4 ∗ 4 = 16. Dos grafos acíclicos dirigidos (DAG) pueden ser dibujados; uno con los mensajes de propagación de utilidad como aristas y los costos de la fase dos en los nodos, y el otro con los mensajes de asignación de valor y los costos de la fase tres en los nodos. El costo máximo del camino secuencial es igual a la suma del camino más largo en cada DAG desde la raíz hasta cualquier nodo hoja. HEURÍSTICAS En nuestra evaluación de la complejidad en DCPOP nos enfocamos en el peor caso posiblemente producido por el algoritmo. Reconocemos 744 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Algoritmo 1 DCPOP Algoritmo 1: DCPOP(X; D; U) Cada agente Xi ejecuta: Fase 1: creación de pseudotree 2: elegir líder de todos los Xj ∈ X 3: líder elegido inicia la creación de pseudotree 4: después, Xi conoce P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) y PC(Xi) Fase 2: propagación de mensajes UTIL 5: si |BP(Xi)| > 0 entonces 6: BRANCHXi ← |BP(Xi)| + 1 7: para todos Xk ∈BP(Xi) hacer 8: UTILXi (Xk) ← Calcular utils(Xi, Xk) 9: Enviar mensaje(Xk,UTILXi (Xk),BRANCHXi ) 10: si |C(Xi)| = 0 (es decir, Si Xi es un nodo hoja, entonces 11: UTILXi (P(Xi)) ← Calcular utils(P(Xi),PP(Xi)) para todos los PP(Xi) 12: Enviar mensaje(P(Xi), UTILXi (P(Xi)), BRANCHXi ) 13: Enviar mensaje(PP(Xi), UTIL vacío, BRANCH vacío) a todos los PP(Xi) 14: Activar el manejador de mensajes UTIL() Fase 3: Propagación de mensajes de VALOR 15: Activar el manejador de mensajes de VALOR() FIN ALGORITMO Manejador de mensajes UTIL(Xk, UTILXk (Xi), BRANCHXk ) 16: Almacenar UTILXk (Xi), BRANCHXk (Xi) 17: Si han llegado mensajes UTIL de todos los hijos y los hijos de la rama, entonces 18: Para todos los Bj ∈ BRANCH(Xi) hacer 19: Si Bj está fusionado, entonces 20: Unir todos los hipercubos donde Bj ∈ UTIL(Xi) 21: Eliminar Bj del hipercubo unido 22: Si P(Xi) == nulo (eso significa que Xi es la raíz) entonces 23: v ∗ i ← Elegir óptimo(nulo) 24: Enviar VALOR(Xi, v ∗ i) a todos los C(Xi) 25: De lo contrario 26: UTILXi (P(Xi)) ← Calcular utils(P(Xi), PP(Xi)) 27: Enviar mensaje(P(Xi), UTILXi (P(Xi)), BRANCHXi (P(Xi))) Manejador de mensajes de VALOR(VALORXi , P(Xi)) 28: Agregar todos los Xk ← v ∗ k ∈ VALORXi , P(Xi) a la vista del agente 29: Xi ← v ∗ i = Elegir óptimo(vista del agente) 30: Enviar VALORXl , Xi a todos los Xl ∈ C(Xi) que en problemas del mundo real la generación del pseudoárbol tiene un impacto significativo en el rendimiento real. El problema de encontrar la mejor pseudotree para una instancia de DCOP dada es NP-Difícil. Por lo tanto, se utiliza una heurística para la generación, y el rendimiento del algoritmo depende del pseudoárbol encontrado por la heurística. Algunas investigaciones previas se centraron en encontrar heurísticas para generar buenas pseudorboles [8]. Si bien hemos desarrollado algunas heurísticas que generan buenos pseudoárboles cruzados para usar con DCPOP, nuestro enfoque ha sido utilizar múltiples heurísticas y luego seleccionar el mejor pseudo Consideramos solo heurísticas que se ejecuten en tiempo polinómico con respecto al número de nodos en la instancia original del DCOP. El algoritmo DCPOP actual tiene una complejidad exponencial en el peor de los casos, pero podemos calcular el tamaño máximo del mensaje, el tamaño de la computación y el costo de la ruta secuencial para un pseudoárbol de bordes cruzados dado en complejidad espacio-temporal lineal. Para hacer esto, simplemente ejecutamos el algoritmo sin intentar calcular ninguno de los hipercubos de utilidad local o asignaciones de valor óptimo. En cambio, los mensajes incluyen información dimensional y de ramificación pero no hipercubos de utilidad. Después de que cada heurística complete la generación de un pseudoárbol, ejecutamos el procedimiento de medición y propagamos la información de la medición hasta la raíz elegida en ese pseudo La raíz luego transmite la complejidad total de esa heurística a todos los nodos. Después de que todas las heurísticas hayan tenido la oportunidad de completarse, cada nodo sabe qué heurística produjo el mejor pseudoárbol. Cada nodo luego procede a comenzar el algoritmo DCPOP utilizando su conocimiento del pseudoárbol generado por la mejor heurística. Las heurísticas utilizadas para generar pseudárboles tradicionales realizan un recorrido DFS distribuido. El algoritmo distribuido general utiliza un mecanismo de paso de token y un número lineal de mensajes. Las heurísticas mejoradas basadas en DFS utilizan un procedimiento especial para elegir el nodo raíz, y también proporcionan una función de ordenación sobre los vecinos de un nodo para determinar el orden de la recursión de caminos. Las heurísticas basadas en DFS utilizadas en nuestros experimentos provienen del trabajo realizado en [4, 8]. 5.1 La heurística de pseudotree cruzado de mejor primer recorrido. Las heurísticas utilizadas para generar pseudárboles cruzados realizan un recorrido de mejor primer recorrido. Se presenta un algoritmo general distribuido de mejor primero para la expansión de nodos en el Algoritmo 2. Una función de evaluación en cada nodo proporciona los valores que se utilizan para determinar el siguiente mejor nodo a expandir. Ten en cuenta que en este algoritmo cada nodo solo intercambia su mejor valor con sus vecinos. En nuestros experimentos utilizamos varias funciones de evaluación que tomaban como argumentos una lista ordenada de ancestros y un nodo, que contiene una lista de vecinos (con la profundidad de colocación de cada vecino en el árbol). A partir de estos podemos calcular los padres de la rama, los hijos de la rama y las relaciones desconocidas para una posible ubicación del nodo. La mejor función general calculó el valor como ancestros - (padres de rama + hijos de rama) con el número de relaciones desconocidas como criterio de desempate. Después de completarse, cada nodo tiene conocimiento de su padre y ancestros, por lo que puede determinar fácilmente qué nodos conectados son pseudo-padres, padres de rama, pseudo-hijos e hijos de rama. La complejidad de la travesía de mejor primero depende de la complejidad de la función de evaluación. Suponiendo una complejidad de O(V) para la función de evaluación, que es el caso de nuestra mejor función general, el recorrido de mejor primero es O(V · E), lo que en el peor de los casos es O(n3). Para cada v ∈ V realizamos una operación de colocación y encontramos el siguiente nodo a colocar usando la operación getBestNeighbor. La complejidad de la operación del lugar es a lo sumo O(V) debido a los mensajes enviados. Encontrar el siguiente nodo utiliza recursión y recorre solo los ya colocados The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 745 Algoritmo 2 Algoritmo de Búsqueda Distribuida de Mejor Primero root ← líder elegido next(root, ∅) place(nodo, padre) nodo.padre ← padre nodo.ancestros ← padre.ancestros ∪ padre enviar mensaje de ubicación (nodo, nodo.ancestros) a todos los vecinos de nodo next(actual, anterior) si actual no está ubicado entonces place(actual, anterior) next(actual, ∅) else mejor ← obtenerMejorVecino(actual, anterior) si mejor = ∅ entonces si anterior = ∅ entonces terminar, todos los nodos están ubicados next(anterior, ∅) else next(mejor, actual) obtenerMejorVecino(actual, anterior) mejor ← ∅; puntaje ← 0 para todo n ∈ vecinos de actual hacer si n! = anterior entonces si n está ubicado entonces puntajeN ← obtenerMejorVecino(n, actual) else puntajeN ← evaluar(actual, n) si puntajeN > puntaje entonces puntaje ← puntajeN mejor ← n return mejor, puntaje nodos, por lo que tiene O(V) recursiones. Cada recursión realiza una operación recursiva getBestNeighbor que recorre todos los nodos colocados y sus vecinos. Esta operación es O(V · E), pero los resultados se pueden almacenar en caché utilizando solo O(V) espacio en cada nodo. Así que tenemos O(V ·(V +V +V ·E)) = O(V 2 ·E). Si somos inteligentes al evaluar los cambios locales cuando cada nodo recibe mensajes de ubicación de sus vecinos y almacenamos en caché los resultados, la operación getBestNeighbor es solo O(E). Esto aumenta la complejidad de la operación de ubicación, pero para todas las ubicaciones la complejidad total es solo O(V · E). Por lo tanto, tenemos una complejidad general de O(V ·E+V ·(V +E)) = O(V ·E). 6. COMPARACIÓN DE COMPLEJIDAD EN DPOP Y DCPOP Ya hemos demostrado que, dado el mismo input, DCPOP se desempeña igual que DPOP. También hemos demostrado que podemos predecir con precisión el rendimiento de un pseudoárbol dado en complejidad temporal lineal. Si usamos un número constante de heurísticas para generar el conjunto de pseudobosques, podemos elegir el mejor pseudobosque con complejidad lineal en espacio y tiempo. Ahora demostraremos que existe una instancia de DCOP para la cual un pseudoárbol de bordes cruzados supera a todos los posibles pseudoárboles tradicionales (basados en heurísticas de recorrido de bordes). En la Figura 3(a) tenemos una instancia de DCOP con seis nodos. Este es un grafo bipartito con cada partición completamente conectada a la otra (a) (b) (c) Figura 3: (a) La instancia de DCOP (b) Un arreglo de pseudobosque tradicional para la instancia de DCOP (c) Un arreglo de pseudobosque con aristas cruzadas para la partición de la instancia de DCOP. En la Figura 3(b) vemos un arreglo tradicional de pseudotree para esta instancia de DCOP. Es fácil ver que cualquier heurística basada en el recorrido de aristas no puede expandir dos nodos de la misma partición sucesivamente. También observamos que ningún nodo puede tener más de un hijo porque cualquier disposición de este tipo sería un pseudoárbol inválido. Por lo tanto, cualquier disposición tradicional de pseudodendrograma para esta instancia de DCOP debe tener la forma de la Figura 3(b). Podemos ver que las aristas de retroceso F-B y F-A se superponen al nodo C. El nodo C también tiene un padre E y una arista de retroceso con D. Utilizando el algoritmo DPOP original (o DCPOP ya que son idénticos en este caso), encontramos que el cálculo en el nodo C implica cinco dominios: A, B, C, D y E. En contraste, el arreglo de pseudonodos con aristas cruzadas en la Figura 3(c) requiere un máximo de cuatro dominios en cualquier cálculo durante DCPOP. Dado que el nodo A es el punto de fusión de las ramas tanto de B como de C, podemos ver que cada uno de los nodos D, E y F tiene dos ramas superpuestas. Además, cada uno de estos nodos tiene al nodo A como su padre. Usando el algoritmo DCPOP, encontramos que el cálculo en el nodo D (o E o F) implica cuatro dominios: A, B, C y D (o E o F). Dado que no se puede crear una disposición de pseudobosque tradicional mejor utilizando una heurística de recorrido de aristas, hemos demostrado que DCPOP puede superar a DPOP incluso si utilizamos el pseudobosque óptimo encontrado a través del recorrido de aristas. Reconocemos que los arreglos de pseudodistribución de árboles que permiten relaciones padre-hijo sin una restricción real pueden resolver el problema en la Figura 3(a) con un tamaño de cálculo máximo de cuatro dominios. Sin embargo, las heurísticas actuales utilizadas con DPOP no producen tales pseudobosques, y sería difícil distribuir una heurística así, ya que cada nodo requeriría información sobre nodos con los que no tiene restricciones. Además, aunque no lo demostramos aquí, los pseudobosques de bordes cruzados pueden producir tamaños de mensaje más pequeños que tales pseudobosques, incluso si el tamaño de la computación es similar. En la práctica, dado que encontrar la mejor disposición de pseudoramas es NP-Difícil, observamos que las heurísticas que producen pseudoramas con aristas cruzadas a menudo generan tamaños de cálculo y mensajes significativamente más pequeños. 7. RESULTADOS EXPERIMENTALES 746 El Sexto Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Los métricos de rendimiento existentes para algoritmos DCOP incluyen el número total de mensajes, ciclos de reloj síncronos y tamaño de mensaje. Ya hemos demostrado que el número total de mensajes es lineal con respecto al número de restricciones en la instancia de DCOP. También introdujimos el costo de camino secuencial máximo (PC) como una medida de la máxima cantidad de paralelismo alcanzable por el algoritmo. El costo máximo de la ruta secuencial es igual a la suma de los cálculos realizados en la ruta más larga desde la raíz hasta cualquier nodo hoja. También incluimos como métricas el tamaño máximo de cálculo en número de dimensiones (CD) y el tamaño máximo de mensaje en número de dimensiones (MD). Para analizar la complejidad relativa de una instancia DCOP dada, encontramos el ancho inducido mínimo (IW) de cualquier pseudobosque tradicional producido por una heurística para el DPOP original. 7.1 Instancias genéricas de DCOP Para nuestras pruebas iniciales generamos aleatoriamente dos conjuntos de problemas con 3000 casos en cada uno. Cada problema fue generado asignando un número aleatorio (elegido de un rango) de restricciones a cada variable. El generador luego creó restricciones binarias hasta que cada variable alcanzó su número máximo de restricciones. El primer conjunto utiliza 20 variables, y el mejor DPOP IW varía de 1 a 16 con un promedio de 8.5. El segundo conjunto utiliza 100 variables, y el mejor DPOP IW osciló entre 2 y 68 con un promedio de 39.3. Dado que la mayoría de los problemas en el segundo conjunto eran demasiado complejos para calcular la solución, tomamos medidas de las métricas utilizando las técnicas descritas anteriormente en la Sección 5 sin resolver realmente el problema. Los resultados se muestran para el primer conjunto en la Tabla 1 y para el segundo conjunto en la Tabla 2. Para los dos conjuntos de problemas dividimos los casos en categorías de baja densidad y alta densidad. Los casos de baja densidad consisten en aquellos problemas que tienen un mejor DPOP IW menor o igual a la mitad del número total de nodos (por ejemplo, IW ≤ 10 para los problemas de 20 nodos e IW ≤ 50 para los problemas de 100 nodos. Los problemas de alta densidad consisten en el resto de los conjuntos de problemas. En ambas Tabla 1 y Tabla 2 hemos enumerado las métricas de rendimiento para el algoritmo DPOP original, el algoritmo DCPOP utilizando solo pseudobosques de bordes cruzados (DCPOP-CE), y el algoritmo DCPOP utilizando pseudobosques tradicionales y de bordes cruzados (DCPOP-All). Los pseudobosques utilizados para DPOP fueron generados utilizando 5 heurísticas: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB y DFS MCN BEC. Estas son todas las versiones del recorrido DFS guiado discutidas en la Sección 5. Los pseudobosques de bordes cruzados utilizados para DCPOP-CE fueron generados utilizando 5 heurísticas: MCN, LCN, MCN A-B, LCN A-B y LCSG A-B. Estas son todas las versiones del recorrido de mejor primero discutidas en la Sección 5. Para tanto DPOP como DCPOP-CE elegimos el mejor pseudoárbol producido por sus respectivas 5 heurísticas para cada problema en el conjunto. Para DCPOP-All elegimos la mejor pseudotree producida por las 10 heurísticas para cada problema en el conjunto. Para las métricas de CD y MD, el valor mostrado es el número promedio de dimensiones. Para la métrica de PC, el valor mostrado es el logaritmo natural del costo de ruta secuencial máximo (ya que el valor real crece exponencialmente con la complejidad del problema). La última fila en ambas tablas es una medida de mejora de DCPOP-All sobre DPOP. Para las métricas CD y MD, el valor mostrado es una reducción en el número de dimensiones. Para la métrica de PC, el valor mostrado es una reducción porcentual en el costo máximo de la ruta secuencial (% = DP OP −DCP OP DCP OP ∗ 100). Observa que DCPOP supera a DPOP en todas las métricas. Esto se sigue lógicamente de nuestra afirmación anterior de que, dada la misma entrada, DCPOP se comporta exactamente igual que DPOP. Así, dada la elección entre los pseudobosques producidos por las 10 heurísticas, DCPOP-All siempre superará a DCPOP-CE y DPOP. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 6: Mejora del Costo del Camino DCPOP Reunión Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Tabla 3: Problemas de Programación de Reuniones realizan DPOP. Otra tendencia que observamos es que la mejora es mayor para problemas de alta densidad que para problemas de baja densidad. Mostramos esta tendencia con mayor detalle en las Figuras 4, 5 y 6. Observa cómo la mejora aumenta a medida que aumenta la complejidad del problema. 7.2 Problema de Programación de Reuniones Además de nuestras pruebas genéricas iniciales de DCOP, realizamos una serie de pruebas en el Problema de Programación de Reuniones (MSP) como se describe en [6]. La configuración del problema incluye un número de personas agrupadas en departamentos. Cada persona debe asistir a un número específico de reuniones. Las reuniones pueden llevarse a cabo dentro de los departamentos o entre departamentos, y pueden asignarse a uno de los ocho horarios disponibles. El MSP se mapea a una instancia de DCOP donde cada variable representa el intervalo de tiempo en el que una persona específica asistirá a una reunión específica. Todas las variables que pertenecen a la misma persona tienen restricciones de exclusión mutua para que la persona no pueda asistir a más de una reunión durante el mismo intervalo de tiempo. Todas las variables que pertenecen a la misma reunión tienen restricciones de igualdad para que todos los participantes elijan el mismo horario. Se imponen restricciones unarias en cada variable para tener en cuenta la valoración de una persona de cada reunión y franja horaria. Para nuestros tests generamos 100 problemas de muestra para cada combinación de agentes y reuniones. Los resultados se muestran en la Tabla 3. Los valores en las primeras cinco columnas representan (en orden de izquierda a derecha), el número total de agentes, el número total de reuniones, el número total de variables, el promedio total de restricciones y el promedio mínimo de IW producido por un pseudoárbol tradicional. Las últimas tres columnas muestran las mismas métricas que utilizamos para las instancias genéricas de DCOP, excepto que esta vez solo mostramos las mejoras de DCPOP-All sobre DPOP. El rendimiento es mejor en promedio para todas las instancias de MSP, pero nuevamente vemos mejoras más grandes para instancias de problemas más complejos. 8. CONCLUSIONES Y TRABAJO FUTURO Presentamos un algoritmo completo y distribuido que resuelve instancias generales de DCOP utilizando arreglos de pseudoramas cruzados. Nuestro algoritmo extiende el algoritmo DPOP al agregar mensajes adicionales de propagación de utilidad e introducir el concepto de fusión de ramas durante la fase de propagación de utilidad. Nuestro algoritmo también permite que las asignaciones de valor ocurran en puntos de fusión de nivel superior para nodos de nivel inferior. Hemos demostrado que DCPOP extiende completamente DPOP al realizar las mismas operaciones dadas las mismas entradas. También hemos demostrado a través de algunos ejemplos y datos experimentales que DCPOP puede lograr un mejor rendimiento para algunas instancias del problema al extender el conjunto de entrada permitido para incluir pseudobosques cruzados. Damos especial énfasis al papel que desempeñan las heurísticas de recorrido de bordes en la generación de pseudobosques. Hemos demostrado que la penalización en el rendimiento es mínima para generar múltiples heurísticas, y que podemos elegir el mejor pseudoárbol generado en complejidad lineal de espacio-tiempo. Dada la importancia de un buen pseudoárbol para el rendimiento, el trabajo futuro incluirá nuevas heurísticas para encontrar mejores pseudo El trabajo futuro también incluirá adaptar las extensiones existentes de DPOP [5, 7] que soportan diferentes dominios de problemas para su uso con DCPOP. 9. REFERENCIAS [1] J. Liu y K. P. Sycara. Explotando la estructura del problema para la <br>optimización distribuida de restricciones</br>. En V. Lesser, editor, Actas de la Primera Conferencia Internacional sobre Sistemas Multiagente, páginas 246-254, San Francisco, CA, 1995. MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, y S. Kulkarni. Un enfoque dinámico distribuido de satisfacción de restricciones para la asignación de recursos. Notas de conferencia en Ciencias de la Computación, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe y M. Yokoo. Un método completo asíncrono para la <br>optimización de restricciones distribuidas</br>. ",
            "candidates": [],
            "error": [
                [
                    "optimización distribuida de restricciones",
                    "optimización de restricciones distribuidas"
                ]
            ]
        },
        "pseudotree arrangement": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Complete Distributed Constraint Optimization Method For Non-Traditional Pseudotree Arrangements∗ James Atlas Computer and Information Sciences University of Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Computer and Information Sciences University of Delaware Newark, DE 19716 decker@cis.udel.edu ABSTRACT Distributed Constraint Optimization (DCOP) is a general framework that can model complex problems in multi-agent systems.",
                "Several current algorithms that solve general DCOP instances, including ADOPT and DPOP, arrange agents into a traditional pseudotree structure.",
                "We introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements.",
                "Our algorithm correctly solves DCOP instances for pseudotrees that include edges between nodes in separate branches.",
                "The algorithm also solves instances with traditional pseudotree arrangements using the same procedure as DPOP.",
                "We compare our algorithm with DPOP using several metrics including the induced width of the pseudotrees, the maximum dimensionality of messages and computation, and the maximum sequential path cost through the algorithm.",
                "We prove that for some problem instances it is not possible to generate a traditional pseudotree using edge-traversal heuristics that will outperform a cross-edged pseudotree.",
                "We use multiple heuristics to generate pseudotrees and choose the best pseudotree in linear space-time complexity.",
                "For some problem instances we observe significant improvements in message and computation sizes compared to DPOP.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent Systems General Terms Algorithms 1.",
                "INTRODUCTION Many historical problems in the AI community can be transformed into Constraint Satisfaction Problems (CSP).",
                "With the advent of distributed AI, multi-agent systems became a popular way to model the complex interactions and coordination required to solve distributed problems.",
                "CSPs were originally extended to distributed agent environments in [9].",
                "Early domains for distributed constraint satisfaction problems (DisCSP) included job shop scheduling [1] and resource allocation [2].",
                "Many domains for agent systems, especially teamwork coordination, distributed scheduling, and sensor networks, involve overly constrained problems that are difficult or impossible to satisfy for every constraint.",
                "Recent approaches to solving problems in these domains rely on optimization techniques that map constraints into multi-valued utility functions.",
                "Instead of finding an assignment that satisfies all constraints, these approaches find an assignment that produces a high level of global utility.",
                "This extension to the original DisCSP approach has become popular in multi-agent systems, and has been labeled the Distributed Constraint Optimization Problem (DCOP) [1].",
                "Current algorithms that solve complete DCOPs use two main approaches: search and dynamic programming.",
                "Search based algorithms that originated from DisCSP typically use some form of backtracking [10] or bounds propagation, as in ADOPT [3].",
                "Dynamic programming based algorithms include DPOP and its extensions [5, 6, 7].",
                "To date, both categories of algorithms arrange agents into a traditional pseudotree to solve the problem.",
                "It has been shown in [6] that any constraint graph can be mapped into a traditional pseudotree.",
                "However, it was also shown that finding the optimal pseudotree was NP-Hard.",
                "We began to investigate the performance of traditional pseudotrees generated by current edge-traversal heuristics.",
                "We found that these heuristics often produced little parallelism as the pseudotrees tended to have high depth and low branching factors.",
                "We suspected that there could be other ways to arrange the pseudotrees that would provide increased parallelism and smaller message sizes.",
                "After exploring these other arrangements we found that cross-edged pseudotrees provide shorter depths and higher branching factors than the traditional pseudotrees.",
                "Our hypothesis was that these crossedged pseudotrees would outperform traditional pseudotrees for some problem types.",
                "In this paper we introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements which include cross-edged pseudotrees.",
                "We begin with a definition of 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, traditional pseudotrees, and cross-edged pseudotrees.",
                "We then provide a summary of the original DPOP algorithm and introduce our DCPOP algorithm.",
                "We discuss the complexity of our algorithm as well as the impact of pseudotree generation heuristics.",
                "We then show that our Distributed Cross-edged Pseudotree Optimization Procedure (DCPOP) performs significantly better in practice than the original DPOP algorithm for some problem instances.",
                "We conclude with a selection of ideas for future work and extensions for DCPOP. 2.",
                "PROBLEM DEFINITION DCOP has been formalized in slightly different ways in recent literature, so we will adopt the definition as presented in [6].",
                "A Distributed Constraint Optimization Problem with n nodes and m constraints consists of the tuple < X, D, U > where: • X = {x1,..,xn} is a set of variables, each one assigned to a unique agent • D = {d1,..,dn} is a set of finite domains for each variable • U = {u1,..,um} is a set of utility functions such that each function involves a subset of variables in X and defines a utility for each combination of values among these variables An optimal solution to a DCOP instance consists of an assignment of values in D to X such that the sum of utilities in U is maximal.",
                "Problem domains that require minimum cost instead of maximum utility can map costs into negative utilities.",
                "The utility functions represent soft constraints but can also represent hard constraints by using arbitrarily large negative values.",
                "For this paper we only consider binary utility functions involving two variables.",
                "Higher order utility functions can be modeled with minor changes to the algorithm, but they also substantially increase the complexity. 2.1 Traditional Pseudotrees Pseudotrees are a common structure used in search procedures to allow parallel processing of independent branches.",
                "As defined in [6], a pseudotree is an arrangement of a graph G into a rooted tree T such that vertices in G that share an edge are in the same branch in T. A back-edge is an edge between a node X and any node which lies on the path from X to the root (excluding Xs parent).",
                "Figure 1 shows a pseudotree with four nodes, three edges (A-B, B-C, BD), and one back-edge (A-C).",
                "Also defined in [6] are four types of relationships between nodes exist in a pseudotree: • P(X) - the parent of a node X: the single node higher in the pseudotree that is connected to X directly through a tree edge • C(X) - the children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through tree edges • PP(X) - the pseudo-parents of a node X: the set of nodes higher in the pseudotree that are connected to X directly through back-edges (In Figure 1, A = PP(C)) • PC(X) - the pseudo-children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through back-edges (In Figure 1, C = PC(A)) Figure 1: A traditional pseudotree.",
                "Solid line edges represent parent-child relationships and the dashed line represents a pseudo-parent-pseudo-child relationship.",
                "Figure 2: A cross-edged pseudotree.",
                "Solid line edges represent parent-child relationships, the dashed line represents a pseudoparent-pseudo-child relationship, and the dotted line represents a branch-parent-branch-child relationship.",
                "The bolded node, B, is the merge point for node E. 2.2 Cross-edged Pseudotrees We define a cross-edge as an edge from node X to a node Y that is above X but not in the path from X to the root.",
                "A cross-edged pseudotree is a traditional pseudotree with the addition of cross-edges.",
                "Figure 2 shows a cross-edged pseudotree with a cross-edge (D-E).",
                "In a cross-edged pseudotree we designate certain edges as primary.",
                "The set of primary edges defines a spanning tree of the nodes.",
                "The parent, child, pseudo-parent, and pseudo-child relationships from the traditional pseudotree are now defined in the context of this primary edge spanning tree.",
                "This definition also yields two additional types of relationships that may exist between nodes: • BP(X) - the branch-parents of a node X: the set of nodes higher in the pseudotree that are connected to X but are not in the primary path from X to the root (In Figure 2, D = BP(E)) • BC(X) - the branch-children of a node X: the set of nodes lower in the pseudotree that are connected to X but are not in any primary path from X to any leaf node (In Figure 2, E = BC(D)) 2.3 Pseudotree Generation 742 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Current algorithms usually have a pre-execution phase to generate a traditional pseudotree from a general DCOP instance.",
                "Our DCPOP algorithm generates a cross-edged pseudotree in the same fashion.",
                "First, the DCOP instance < X, D, U > translates directly into a graph with X as the set of vertices and an edge for each pair of variables represented in U.",
                "Next, various heuristics are used to arrange this graph into a pseudotree.",
                "One common heuristic is to perform a guided depth-first search (DFS) as the resulting traversal is a pseudotree, and a DFS can easily be performed in a distributed fashion.",
                "We define an edge-traversal based method as any method that produces a pseudotree in which all parent/child pairs share an edge in the original graph.",
                "This includes DFS, breadth-first search, and best-first search based traversals.",
                "Our heuristics that generate cross-edged pseudotrees use a distributed best-first search traversal. 3.",
                "DPOP ALGORITHM The original DPOP algorithm operates in three main phases.",
                "The first phase generates a traditional pseudotree from the DCOP instance using a distributed algorithm.",
                "The second phase joins utility hypercubes from children and the local node and propagates them towards the root.",
                "The third phase chooses an assignment for each domain in a top down fashion beginning with the agent at the root node.",
                "The complexity of DPOP depends on the size of the largest computation and utility message during phase two.",
                "It has been shown that this size directly corresponds to the induced width of the pseudotree generated in phase one [6].",
                "DPOP uses polynomial time heuristics to generate the pseudotree since finding the minimum induced width pseudotree is NP-hard.",
                "Several distributed edgetraversal heuristics have been developed to find low width pseudotrees [8].",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, and pseudo-children. 3.1 Utility Propagation Agents located at leaf nodes in the pseudotree begin the process by calculating a local utility hypercube.",
                "This hypercube at node X contains summed utilities for each combination of values in the domains for P(X) and PP(X).",
                "This hypercube has dimensional size equal to the number of pseudo-parents plus one.",
                "A message containing this hypercube is sent to P(X).",
                "Agents located at non-leaf nodes wait for all messages from children to arrive.",
                "Once the agent at node Y has all utility messages, it calculates its local utility hypercube which includes domains for P(Y), PP(Y), and Y.",
                "The local utility hypercube is then joined with all of the hypercubes from the child messages.",
                "At this point all utilities involving node Y are known, and the domain for Y may be safely eliminated from the joined hypercube.",
                "This elimination process chooses the best utility over the domain of Y for each combination of the remaining domains.",
                "A message containing this hypercube is now sent to P(Y).",
                "The dimensional size of this hypercube depends on the number of overlapping domains in received messages and the local utility hypercube.",
                "This dynamic programming based propagation phase continues until the agent at the root node of the pseudotree has received all messages from its children. 3.2 Value Propagation Value propagation begins when the agent at the root node Z has received all messages from its children.",
                "Since Z has no parents or pseudo-parents, it simply combines the utility hypercubes received from its children.",
                "The combined hypercube contains only values for the domain for Z.",
                "At this point the agent at node Z simply chooses the assignment for its domain that has the best utility.",
                "A value propagation message with this assignment is sent to each node in C(Z).",
                "Each other node then receives a value propagation message from its parent and chooses the assignment for its domain that has the best utility given the assignments received in the message.",
                "The node adds its domain assignment to the assignments it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen an assignment for their domain. 4.",
                "DCPOP ALGORITHM Our extension to the original DPOP algorithm, shown in Algorithm 1, shares the same three phases.",
                "The first phase generates the cross-edged pseudotree for the DCOP instance.",
                "The second phase merges branches and propagates the utility hypercubes.",
                "The third phase chooses assignments for domains at branch merge points and in a top down fashion, beginning with the agent at the root node.",
                "For the first phase we generate a pseudotree using several distributed heuristics and select the one with lowest overall complexity.",
                "The complexity of the computation and utility message size in DCPOP does not directly correspond to the induced width of the cross-edged pseudotree.",
                "Instead, we use a polynomial time method for calculating the maximum computation and utility message size for a given cross-edged pseudotree.",
                "A description of this method and the pseudotree selection process appears in Section 5.",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, pseudo-children, branch-parents, and branch-children. 4.1 Merging Branches and Utility Propagation In the original DPOP algorithm a node X only had utility functions involving its parent and its pseudo-parents.",
                "In DCPOP, a node X is allowed to have a utility function involving a branch-parent.",
                "The concept of a branch can be seen in Figure 2 with node E representing our node X.",
                "The two distinct paths from node E to node B are called branches of E. The single node where all branches of E meet is node B, which is called the merge point of E. Agents with nodes that have branch-parents begin by sending a utility propagation message to each branch-parent.",
                "This message includes a two dimensional utility hypercube with domains for the node X and the branch-parent BP(X).",
                "It also includes a branch information structure which contains the origination node of the branch, X, the total number of branches originating from X, and the number of branches originating from X that are merged into a single representation by this branch information structure (this number starts at 1).",
                "Intuitively when the number of merged branches equals the total number of originating branches, the algorithm has reached the merge point for X.",
                "In Figure 2, node E sends a utility propagation message to its branch-parent, node D. This message has dimensions for the domains of E and D, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "As in the original DPOP utility propagation phase, an agent at leaf node X sends a utility propagation message to its parent.",
                "In DCPOP this message contains dimensions for the domains of P(X) and PP(X).",
                "If node X also has branch-parents, then the utility propagation message also contains a dimension for the domain of X, and will include a branch information structure.",
                "In Figure 2, node E sends a utility propagation message to its parent, node C. This message has dimensions for the domains of E and C, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "When a node Y receives utility propagation messages from all of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 743 its children and branch-children, it merges any branches with the same origination node X.",
                "The merged branch information structure accumulates the number of merged branches for X.",
                "If the cumulative total number of merged branches equals the total number of branches, then Y is the merge point for X.",
                "This means that the utility hypercubes present at Y contain all information about the valuations for utility functions involving node X.",
                "In addition to the typical elimination of the domain of Y from the utility hypercubes, we can now safely eliminate the domain of X from the utility hypercubes.",
                "To illustrate this process, we will examine what happens in the second phase for node B in Figure 2.",
                "In the second phase Node B receives two utility propagation messages.",
                "The first comes from node C and includes dimensions for domains E, B, and A.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "The second comes from node D and includes dimensions for domains E and B.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "Node B then merges the branch information structures from both messages because they have the same origination, node E. Since the number of merged branches originating from E is now 2 and the total branches originating from E is 2, node B now eliminates the dimensions for domain E. Node B also eliminates the dimension for its own domain, leaving only information about domain A. Node B then sends a utility propagation message to node A, containing only one dimension for the domain of A.",
                "Although not possible in DPOP, this method of utility propagation and dimension elimination may produce hypercubes at node Y that do not share any domains.",
                "In DCPOP we do not join domain independent hypercubes, but instead may send multiple hypercubes in the utility propagation message sent to the parent of Y.",
                "This lazy approach to joins helps to reduce message sizes. 4.2 Value Propagation As in DPOP, value propagation begins when the agent at the root node Z has received all messages from its children.",
                "At this point the agent at node Z chooses the assignment for its domain that has the best utility.",
                "If Z is the merge point for the branches of some node X, Z will also choose the assignment for the domain of X.",
                "Thus any node that is a merge point will choose assignments for a domain other than its own.",
                "These assignments are then passed down the primary edge hierarchy.",
                "If node X in the hierarchy has branch-parents, then the value assignment message from P(X) will contain an assignment for the domain of X.",
                "Every node in the hierarchy adds any assignments it has chosen to the ones it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen or received an assignment for their domain. 4.3 Proof of Correctness We will prove the correctness of DCPOP by first noting that DCPOP fully extends DPOP and then examining the two cases for value assignment in DCPOP.",
                "Given a traditional pseudotree as input, the DCPOP algorithm execution is identical to DPOP.",
                "Using a traditional <br>pseudotree arrangement</br> no nodes have branch-parents or branch-children since all edges are either back-edges or tree edges.",
                "Thus the DCPOP algorithm using a traditional pseudotree sends only utility propagation messages that contain domains belonging to the parent or pseudo-parents of a node.",
                "Since no node has any branch-parents, no branches exist, and thus no node serves as a merge point for any other node.",
                "Thus all value propagation assignments are chosen at the node of the assignment domain.",
                "For DCPOP execution with cross-edged pseudotrees, some nodes serve as merge points.",
                "We note that any node X that is not a merge point assigns its value exactly as in DPOP.",
                "The local utility hypercube at X contains domains for X, P(X), PP(X), and BC(X).",
                "As in DPOP the value assignment message received at X includes the values assigned to P(X) and PP(X).",
                "Also, since X is not a merge point, all assignments to BC(X) must have been calculated at merge points higher in the tree and are in the value assignment message from P(X).",
                "Thus after eliminating domains for which assignments are known, only the domain of X is left.",
                "The agent at node X can now correctly choose the assignment with maximum utility for its own domain.",
                "If node X is a merge point for some branch-child Y, we know that X must be a node along the path from Y to the root, and from P(Y) and all BP(Y) to the root.",
                "From the algorithm, we know that Y necessarily has all information from C(Y), PC(Y), and BC(Y) since it waits for their messages.",
                "Node X has information about all nodes below it in the tree, which would include Y, P(Y), BP(Y), and those PP(Y) that are below X in the tree.",
                "For any PP(Y) above X in the tree, X receives the assignment for the domain of PP(Y) in the value assignment message from P(X).",
                "Thus X has utility information about all of the utility functions of which Y is a part.",
                "By eliminating domains included in the value assignment message, node X is left with a local utility hypercube with domains for X and Y.",
                "The agent at node X can now correctly choose the assignments with maximum utility for the domains of X and Y. 4.4 Complexity Analysis The first phase of DCPOP sends one message to each P(X), PP(X), and BP(X).",
                "The second phase sends one value assignment message to each C(X).",
                "Thus, DCPOP produces a linear number of messages with respect to the number of edges (utility functions) in the cross-edged pseudotree and the original DCOP instance.",
                "The actual complexity of DCPOP depends on two additional measurements: message size and computation size.",
                "Message size and computation size in DCPOP depend on the number of overlapping branches as well as the number of overlapping back-edges.",
                "It was shown in [6] that the number of overlapping back-edges is equal to the induced width of the pseudotree.",
                "In a poorly constructed cross-edged pseudotree, the number of overlapping branches at node X can be as large as the total number of descendants of X.",
                "Thus, the total message size in DCPOP in a poorly constructed instance can be space-exponential in the total number of nodes in the graph.",
                "However, in practice a well constructed cross-edged pseudotree can achieve much better results.",
                "Later we address the issue of choosing well constructed crossedged pseudotrees from a set.",
                "We introduce an additional measurement of the maximum sequential path cost through the algorithm.",
                "This measurement directly relates to the maximum amount of parallelism achievable by the algorithm.",
                "To take this measurement we first store the total computation size for each node during phase two and three.",
                "This computation size represents the number of individual accesses to a value in a hypercube at each node.",
                "For example, a join between two domains of size 4 costs 4 ∗ 4 = 16.",
                "Two directed acyclic graphs (DAG) can then be drawn; one with the utility propagation messages as edges and the phase two costs at nodes, and the other with value assignment messages and the phase three costs at nodes.",
                "The maximum sequential path cost is equal to the sum of the longest path on each DAG from the root to any leaf node. 5.",
                "HEURISTICS In our assessment of complexity in DCPOP we focused on the worst case possibly produced by the algorithm.",
                "We acknowledge 744 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Algorithm 1 DCPOP Algorithm 1: DCPOP(X; D; U) Each agent Xi executes: Phase 1: pseudotree creation 2: elect leader from all Xj ∈ X 3: elected leader initiates pseudotree creation 4: afterwards, Xi knows P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) and PC(Xi) Phase 2: UTIL message propagation 5: if |BP(Xi)| > 0 then 6: BRANCHXi ← |BP(Xi)| + 1 7: for all Xk ∈BP(Xi) do 8: UTILXi (Xk) ←Compute utils(Xi, Xk) 9: Send message(Xk,UTILXi (Xk),BRANCHXi ) 10: if |C(Xi)| = 0(i.e.",
                "Xi is a leaf node) then 11: UTILXi (P(Xi)) ← Compute utils(P(Xi),PP(Xi)) for all PP(Xi) 12: Send message(P(Xi), UTILXi (P(Xi)),BRANCHXi ) 13: Send message(PP(Xi), empty UTIL, empty BRANCH) to all PP(Xi) 14: activate UTIL Message handler() Phase 3: VALUE message propagation 15: activate VALUE Message handler() END ALGORITHM UTIL Message handler(Xk,UTILXk (Xi), BRANCHXk ) 16: store UTILXk (Xi),BRANCHXk (Xi) 17: if UTIL messages from all children and branch children arrived then 18: for all Bj ∈BRANCH(Xi) do 19: if Bj is merged then 20: join all hypercubes where Bj ∈UTIL(Xi) 21: eliminate Bj from the joined hypercube 22: if P(Xi) == null (that means Xi is the root) then 23: v ∗ i ← Choose optimal(null) 24: Send VALUE(Xi, v ∗ i) to all C(Xi) 25: else 26: UTILXi (P(Xi)) ← Compute utils(P(Xi), PP(Xi)) 27: Send message(P(Xi),UTILXi (P(Xi)), BRANCHXi (P(Xi))) VALUE Message handler(VALUEXi ,P(Xi)) 28: add all Xk ← v ∗ k ∈VALUEXi ,P(Xi) to agent view 29: Xi ← v ∗ i =Choose optimal(agent view) 30: Send VALUEXl , Xi to all Xl ∈C(Xi) that in real world problems the generation of the pseudotree has a significant impact on the actual performance.",
                "The problem of finding the best pseudotree for a given DCOP instance is NP-Hard.",
                "Thus a heuristic is used for generation, and the performance of the algorithm depends on the pseudotree found by the heuristic.",
                "Some previous research focused on finding heuristics to generate good pseudotrees [8].",
                "While we have developed some heuristics that generate good cross-edged pseudotrees for use with DCPOP, our focus has been to use multiple heuristics and then select the best pseudotree from the generated pseudotrees.",
                "We consider only heuristics that run in polynomial time with respect to the number of nodes in the original DCOP instance.",
                "The actual DCPOP algorithm has worst case exponential complexity, but we can calculate the maximum message size, computation size, and sequential path cost for a given cross-edged pseudotree in linear space-time complexity.",
                "To do this, we simply run the algorithm without attempting to calculate any of the local utility hypercubes or optimal value assignments.",
                "Instead, messages include dimensional and branch information but no utility hypercubes.",
                "After each heuristic completes its generation of a pseudotree, we execute the measurement procedure and propagate the measurement information up to the chosen root in that pseudotree.",
                "The root then broadcasts the total complexity for that heuristic to all nodes.",
                "After all heuristics have had a chance to complete, every node knows which heuristic produced the best pseudotree.",
                "Each node then proceeds to begin the DCPOP algorithm using its knowledge of the pseudotree generated by the best heuristic.",
                "The heuristics used to generate traditional pseudotrees perform a distributed DFS traversal.",
                "The general distributed algorithm uses a token passing mechanism and a linear number of messages.",
                "Improved DFS based heuristics use a special procedure to choose the root node, and also provide an ordering function over the neighbors of a node to determine the order of path recursion.",
                "The DFS based heuristics used in our experiments come from the work done in [4, 8]. 5.1 The best-first cross-edged pseudotree heuristic The heuristics used to generate cross-edged pseudotrees perform a best-first traversal.",
                "A general distributed best-first algorithm for node expansion is presented in Algorithm 2.",
                "An evaluation function at each node provides the values that are used to determine the next best node to expand.",
                "Note that in this algorithm each node only exchanges its best value with its neighbors.",
                "In our experiments we used several evaluation functions that took as arguments an ordered list of ancestors and a node, which contains a list of neighbors (with each neighbors placement depth in the tree if it was placed).",
                "From these we can calculate branchparents, branch-children, and unknown relationships for a potential node placement.",
                "The best overall function calculated the value as ancestors−(branchparents+branchchildren) with the number of unknown relationships being a tiebreak.",
                "After completion each node has knowledge of its parent and ancestors, so it can easily determine which connected nodes are pseudo-parents, branchparents, pseudo-children, and branch-children.",
                "The complexity of the best-first traversal depends on the complexity of the evaluation function.",
                "Assuming a complexity of O(V ) for the evaluation function, which is the case for our best overall function, the best-first traversal is O(V · E) which is at worst O(n3 ).",
                "For each v ∈ V we perform a place operation, and find the next node to place using the getBestNeighbor operation.",
                "The place operation is at most O(V ) because of the sent messages.",
                "Finding the next node uses recursion and traverses only already placed The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 745 Algorithm 2 Distributed Best-First Search Algorithm root ← electedleader next(root, ∅) place(node, parent) node.parent ← parent node.ancestors ← parent.ancestors ∪ parent send placement message (node, node.ancestors) to all neighbors of node next(current, previous) if current is not placed then place(current, previous) next(current, ∅) else best ← getBestNeighbor(current, previous) if best = ∅ then if previous = ∅ then terminate, all nodes are placed next(previous, ∅) else next(best, current) getBestNeighbor(current, previous) best ← ∅; score ← 0 for all n ∈ current.neighbors do if n! = previous then if n is placed then nscore ← getBestNeighbor(n, current) else nscore ← evaluate(current, n) if nscore > score then score ← nscore best ← n return best, score nodes, so it has O(V ) recursions.",
                "Each recursion performs a recursive getBestNeighbor operation that traverses all placed nodes and their neighbors.",
                "This operation is O(V · E), but results can be cached using only O(V ) space at each node.",
                "Thus we have O(V ·(V +V +V ·E)) = O(V 2 ·E).",
                "If we are smart about evaluating local changes when each node receives placement messages from its neighbors and cache the results the getBestNeighbor operation is only O(E).",
                "This increases the complexity of the place operation, but for all placements the total complexity is only O(V · E).",
                "Thus we have an overall complexity of O(V ·E+V ·(V +E)) = O(V ·E). 6.",
                "COMPARISON OF COMPLEXITY IN DPOP AND DCPOP We have already shown that given the same input, DCPOP performs the same as DPOP.",
                "We also have shown that we can accurately predict performance of a given pseudotree in linear spacetime complexity.",
                "If we use a constant number of heuristics to generate the set of pseudotrees, we can choose the best pseudotree in linear space-time complexity.",
                "We will now show that there exists a DCOP instance for which a cross-edged pseudotree outperforms all possible traditional pseudotrees (based on edge-traversal heuristics).",
                "In Figure 3(a) we have a DCOP instance with six nodes.",
                "This is a bipartite graph with each partition fully connected to the other (a) (b) (c) Figure 3: (a) The DCOP instance (b) A traditional <br>pseudotree arrangement</br> for the DCOP instance (c) A cross-edged <br>pseudotree arrangement</br> for the DCOP instance partition.",
                "In Figure 3(b) we see a traditional <br>pseudotree arrangement</br> for this DCOP instance.",
                "It is easy to see that any edgetraversal based heuristic cannot expand two nodes from the same partition in succession.",
                "We also see that no node can have more than one child because any such arrangement would be an invalid pseudotree.",
                "Thus any traditional <br>pseudotree arrangement</br> for this DCOP instance must take the form of Figure 3(b).",
                "We can see that the back-edges F-B and F-A overlap node C. Node C also has a parent E, and a back-edge with D. Using the original DPOP algorithm (or DCPOP since they are identical in this case), we find that the computation at node C involves five domains: A, B, C, D, and E. In contrast, the cross-edged <br>pseudotree arrangement</br> in Figure 3(c) requires only a maximum of four domains in any computation during DCPOP.",
                "Since node A is the merge point for branches from both B and C, we can see that each of the nodes D, E, and F have two overlapping branches.",
                "In addition each of these nodes has node A as its parent.",
                "Using the DCPOP algorithm we find that the computation at node D (or E or F) involves four domains: A, B, C, and D (or E or F).",
                "Since no better traditional <br>pseudotree arrangement</br> can be created using an edge-traversal heuristic, we have shown that DCPOP can outperform DPOP even if we use the optimal pseudotree found through edge-traversal.",
                "We acknowledge that pseudotree arrangements that allow parent-child relationships without an actual constraint can solve the problem in Figure 3(a) with maximum computation size of four domains.",
                "However, current heuristics used with DPOP do not produce such pseudotrees, and such a heuristic would be difficult to distribute since each node would require information about nodes with which it has no constraint.",
                "Also, while we do not prove it here, cross-edged pseudotrees can produce smaller message sizes than such pseudotrees even if the computation size is similar.",
                "In practice, since finding the best <br>pseudotree arrangement</br> is NP-Hard, we find that heuristics that produce cross-edged pseudotrees often produce significantly smaller computation and message sizes. 7.",
                "EXPERIMENTAL RESULTS 746 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Existing performance metrics for DCOP algorithms include the total number of messages, synchronous clock cycles, and message size.",
                "We have already shown that the total number of messages is linear with respect to the number of constraints in the DCOP instance.",
                "We also introduced the maximum sequential path cost (PC) as a measurement of the maximum amount of parallelism achievable by the algorithm.",
                "The maximum sequential path cost is equal to the sum of the computations performed on the longest path from the root to any leaf node.",
                "We also include as metrics the maximum computation size in number of dimensions (CD) and maximum message size in number of dimensions (MD).",
                "To analyze the relative complexity of a given DCOP instance, we find the minimum induced width (IW) of any traditional pseudotree produced by a heuristic for the original DPOP. 7.1 Generic DCOP instances For our initial tests we randomly generated two sets of problems with 3000 cases in each.",
                "Each problem was generated by assigning a random number (picked from a range) of constraints to each variable.",
                "The generator then created binary constraints until each variable reached its maximum number of constraints.",
                "The first set uses 20 variables, and the best DPOP IW ranges from 1 to 16 with an average of 8.5.",
                "The second set uses 100 variables, and the best DPOP IW ranged from 2 to 68 with an average of 39.3.",
                "Since most of the problems in the second set were too complex to actually compute the solution, we took measurements of the metrics using the techniques described earlier in Section 5 without actually solving the problem.",
                "Results are shown for the first set in Table 1 and for the second set in Table 2.",
                "For the two problem sets we split the cases into low density and high density categories.",
                "Low density cases consist of those problems that have a best DPOP IW less than or equal to half of the total number of nodes (e.g.",
                "IW ≤ 10 for the 20 node problems and IW ≤ 50 for the 100 node problems).",
                "High density problems consist of the remainder of the problem sets.",
                "In both Table 1 and Table 2 we have listed performance metrics for the original DPOP algorithm, the DCPOP algorithm using only cross-edged pseudotrees (DCPOP-CE), and the DCPOP algorithm using traditional and cross-edged pseudotrees (DCPOP-All).",
                "The pseudotrees used for DPOP were generated using 5 heuristics: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB, and DFS MCN BEC.",
                "These are all versions of the guided DFS traversal discussed in Section 5.",
                "The cross-edged pseudotrees used for DCPOP-CE were generated using 5 heuristics: MCN, LCN, MCN A-B, LCN A-B, and LCSG A-B.",
                "These are all versions of the best-first traversal discussed in Section 5.",
                "For both DPOP and DCPOP-CE we chose the best pseudotree produced by their respective 5 heuristics for each problem in the set.",
                "For DCPOP-All we chose the best pseudotree produced by all 10 heuristics for each problem in the set.",
                "For the CD and MD metrics the value shown is the average number of dimensions.",
                "For the PC metric the value shown is the natural logarithm of the maximum sequential path cost (since the actual value grows exponentially with the complexity of the problem).",
                "The final row in both tables is a measurement of improvement of DCPOP-All over DPOP.",
                "For the CD and MD metrics the value shown is a reduction in number of dimensions.",
                "For the PC metric the value shown is a percentage reduction in the maximum sequential path cost (% = DP OP −DCP OP DCP OP ∗ 100).",
                "Notice that DCPOPAll outperforms DPOP on all metrics.",
                "This logically follows from our earlier assertion that given the same input, DCPOP performs exactly the same as DPOP.",
                "Thus given the choice between the pseudotrees produced by all 10 heuristics, DCPOP-All will always outLow Density High Density Algorithm CD MD PC CD MD PC DPOP 7.81 6.81 3.78 13.34 12.34 5.34 DCPOP-CE 7.94 6.73 3.74 12.83 11.43 5.07 DCPOP-All 7.62 6.49 3.66 12.72 11.36 5.05 Improvement 0.18 0.32 13% 0.62 0.98 36% Table 1: 20 node problems Low Density High Density Algorithm CD MD PC CD MD PC DPOP 33.35 32.35 14.55 58.51 57.50 19.90 DCPOP-CE 33.49 29.17 15.22 57.11 50.03 20.01 DCPOP-All 32.35 29.57 14.10 56.33 51.17 18.84 Improvement 1.00 2.78 104% 2.18 6.33 256% Table 2: 100 node problems Figure 4: Computation Dimension Size Figure 5: Message Dimension Size The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 747 Figure 6: Path Cost DCPOP Improvement Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Table 3: Meeting Scheduling Problems perform DPOP.",
                "Another trend we notice is that the improvement is greater for high density problems than low density problems.",
                "We show this trend in greater detail in Figures 4, 5, and 6.",
                "Notice how the improvement increases as the complexity of the problem increases. 7.2 Meeting Scheduling Problem In addition to our initial generic DCOP tests, we ran a series of tests on the Meeting Scheduling Problem (MSP) as described in [6].",
                "The problem setup includes a number of people that are grouped into departments.",
                "Each person must attend a specified number of meetings.",
                "Meetings can be held within departments or among departments, and can be assigned to one of eight time slots.",
                "The MSP maps to a DCOP instance where each variable represents the time slot that a specific person will attend a specific meeting.",
                "All variables that belong to the same person have mutual exclusion constraints placed so that the person cannot attend more than one meeting during the same time slot.",
                "All variables that belong to the same meeting have equality constraints so that all of the participants choose the same time slot.",
                "Unary constraints are placed on each variable to account for a persons valuation of each meeting and time slot.",
                "For our tests we generated 100 sample problems for each combination of agents and meetings.",
                "Results are shown in Table 3.",
                "The values in the first five columns represent (in left to right order), the total number of agents, the total number of meetings, the total number of variables, the average total number of constraints, and the average minimum IW produced by a traditional pseudotree.",
                "The last three columns show the same metrics we used for the generic DCOP instances, except this time we only show the improvements of DCPOP-All over DPOP.",
                "Performance is better on average for all MSP instances, but again we see larger improvements for more complex problem instances. 8.",
                "CONCLUSIONS AND FUTURE WORK We presented a complete, distributed algorithm that solves general DCOP instances using cross-edged pseudotree arrangements.",
                "Our algorithm extends the DPOP algorithm by adding additional utility propagation messages, and introducing the concept of branch merging during the utility propagation phase.",
                "Our algorithm also allows value assignments to occur at higher level merge points for lower level nodes.",
                "We have shown that DCPOP fully extends DPOP by performing the same operations given the same input.",
                "We have also shown through some examples and experimental data that DCPOP can achieve greater performance for some problem instances by extending the allowable input set to include cross-edged pseudotrees.",
                "We placed particular emphasis on the role that edge-traversal heuristics play in the generation of pseudotrees.",
                "We have shown that the performance penalty is minimal to generate multiple heuristics, and that we can choose the best generated pseudotree in linear space-time complexity.",
                "Given the importance of a good pseudotree for performance, future work will include new heuristics to find better pseudotrees.",
                "Future work will also include adapting existing DPOP extensions [5, 7] that support different problem domains for use with DCPOP. 9.",
                "REFERENCES [1] J. Liu and K. P. Sycara.",
                "Exploiting problem structure for distributed constraint optimization.",
                "In V. Lesser, editor, Proceedings of the First International Conference on Multi-Agent Systems, pages 246-254, San Francisco, CA, 1995.",
                "MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni.",
                "A dynamic distributed constraint satisfaction approach to resource allocation.",
                "Lecture Notes in Computer Science, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe, and M. Yokoo.",
                "An asynchronous complete method for distributed constraint optimization.",
                "In AAMAS 03, 2003. [4] A. Petcu.",
                "Frodo: A framework for open/distributed constraint optimization.",
                "Technical Report No. 2006/001 2006/001, Swiss Federal Institute of Technology (EPFL), Lausanne (Switzerland), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu and B. Faltings.",
                "A-dpop: Approximations in distributed optimization.",
                "In poster in CP 2005, pages 802-806, Sitges, Spain, October 2005. [6] A. Petcu and B. Faltings.",
                "Dpop: A scalable method for multiagent constraint optimization.",
                "In IJCAI 05, pages 266-271, Edinburgh, Scotland, Aug 2005. [7] A. Petcu, B. Faltings, and D. Parkes.",
                "M-dpop: Faithful distributed implementation of efficient social choice problems.",
                "In AAMAS 06, pages 1397-1404, Hakodate, Japan, May 2006. [8] G. Ushakov.",
                "Solving meeting scheduling problems using distributed pseudotree-optimization procedure.",
                "Masters thesis, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "Distributed constraint satisfaction for formalizing distributed problem solving.",
                "In International Conference on Distributed Computing Systems, pages 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "The distributed constraint satisfaction problem: Formalization and algorithms.",
                "Knowledge and Data Engineering, 10(5):673-685, 1998. 748 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "Using a traditional <br>pseudotree arrangement</br> no nodes have branch-parents or branch-children since all edges are either back-edges or tree edges.",
                "This is a bipartite graph with each partition fully connected to the other (a) (b) (c) Figure 3: (a) The DCOP instance (b) A traditional <br>pseudotree arrangement</br> for the DCOP instance (c) A cross-edged <br>pseudotree arrangement</br> for the DCOP instance partition.",
                "In Figure 3(b) we see a traditional <br>pseudotree arrangement</br> for this DCOP instance.",
                "Thus any traditional <br>pseudotree arrangement</br> for this DCOP instance must take the form of Figure 3(b).",
                "We can see that the back-edges F-B and F-A overlap node C. Node C also has a parent E, and a back-edge with D. Using the original DPOP algorithm (or DCPOP since they are identical in this case), we find that the computation at node C involves five domains: A, B, C, D, and E. In contrast, the cross-edged <br>pseudotree arrangement</br> in Figure 3(c) requires only a maximum of four domains in any computation during DCPOP."
            ],
            "translated_annotated_samples": [
                "Usando un <br>arreglo de pseudodendrograma</br> tradicional, ningún nodo tiene padres de rama o hijos de rama, ya que todas las aristas son aristas de retroceso o aristas de árbol.",
                "Este es un grafo bipartito con cada partición completamente conectada a la otra (a) (b) (c) Figura 3: (a) La instancia de DCOP (b) Un arreglo de <br>pseudobosque</br> tradicional para la instancia de DCOP (c) Un arreglo de <br>pseudobosque</br> con aristas cruzadas para la partición de la instancia de DCOP.",
                "En la Figura 3(b) vemos un <br>arreglo tradicional de pseudotree</br> para esta instancia de DCOP.",
                "Por lo tanto, cualquier disposición tradicional de <br>pseudodendrograma</br> para esta instancia de DCOP debe tener la forma de la Figura 3(b).",
                "Podemos ver que las aristas de retroceso F-B y F-A se superponen al nodo C. El nodo C también tiene un padre E y una arista de retroceso con D. Utilizando el algoritmo DPOP original (o DCPOP ya que son idénticos en este caso), encontramos que el cálculo en el nodo C implica cinco dominios: A, B, C, D y E. En contraste, el <br>arreglo de pseudonodos con aristas cruzadas</br> en la Figura 3(c) requiere un máximo de cuatro dominios en cualquier cálculo durante DCPOP."
            ],
            "translated_text": "Un Método Completo de Optimización de Restricciones Distribuidas para Arreglos de Pseudotree No Tradicionales∗ James Atlas Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 decker@cis.udel.edu RESUMEN La Optimización de Restricciones Distribuidas (DCOP) es un marco general que puede modelar problemas complejos en sistemas multiagente. Varios algoritmos actuales que resuelven instancias generales de DCOP, incluyendo ADOPT y DPOP, organizan a los agentes en una estructura de pseudobosque tradicional. Introducimos una extensión al algoritmo DPOP que maneja un conjunto extendido de disposiciones de pseudobosque. Nuestro algoritmo resuelve correctamente instancias de DCOP para pseudobosques que incluyen aristas entre nodos en ramas separadas. El algoritmo también resuelve instancias con arreglos de pseudobosque tradicionales utilizando el mismo procedimiento que DPOP. Comparamos nuestro algoritmo con DPOP utilizando varios métricos, incluyendo el ancho inducido de los pseudobosques, la dimensionalidad máxima de los mensajes y la computación, y el costo máximo de la ruta secuencial a través del algoritmo. Demostramos que para algunas instancias del problema no es posible generar un pseudoárbol tradicional utilizando heurísticas de recorrido de aristas que supere a un pseudoárbol con aristas cruzadas. Utilizamos múltiples heurísticas para generar pseudoárboles y elegir el mejor pseudoárbol en complejidad espacio-temporal lineal. Para algunas instancias del problema observamos mejoras significativas en los tamaños de los mensajes y cálculos en comparación con DPOP. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Algoritmos 1. INTRODUCCIÓN Muchos problemas históricos en la comunidad de IA pueden transformarse en Problemas de Satisfacción de Restricciones (CSP). Con la llegada de la inteligencia artificial distribuida, los sistemas multiagente se convirtieron en una forma popular de modelar las interacciones complejas y la coordinación necesaria para resolver problemas distribuidos. Los CSPs fueron originalmente extendidos a entornos de agentes distribuidos en [9]. Los primeros dominios para problemas de satisfacción de restricciones distribuidas (DisCSP) incluyeron la programación de talleres de trabajo [1] y la asignación de recursos [2]. Muchos dominios para sistemas de agentes, especialmente coordinación de trabajo en equipo, programación distribuida y redes de sensores, implican problemas excesivamente restringidos que son difíciles o imposibles de satisfacer para cada restricción. Los enfoques recientes para resolver problemas en estos dominios se basan en técnicas de optimización que mapean restricciones en funciones de utilidad multivaluadas. En lugar de encontrar una asignación que satisfaga todas las restricciones, estos enfoques encuentran una asignación que produce un alto nivel de utilidad global. Esta extensión al enfoque original de DisCSP se ha vuelto popular en sistemas multiagente, y ha sido etiquetada como Problema de Optimización de Restricciones Distribuidas (DCOP) [1]. Los algoritmos actuales que resuelven DCOPs completos utilizan dos enfoques principales: búsqueda y programación dinámica. Los algoritmos basados en búsqueda que se originaron a partir de DisCSP típicamente utilizan alguna forma de retroceso [10] o propagación de límites, como en ADOPT [3]. Los algoritmos basados en programación dinámica incluyen DPOP y sus extensiones [5, 6, 7]. Hasta la fecha, ambas categorías de algoritmos organizan agentes en un pseudoárbol tradicional para resolver el problema. Se ha demostrado en [6] que cualquier grafo de restricciones puede ser mapeado en un pseudoárbol tradicional. Sin embargo, también se demostró que encontrar el pseudoárbol óptimo era NP-Difícil. Comenzamos a investigar el rendimiento de los pseudobosques tradicionales generados por las heurísticas actuales de recorrido de aristas. Descubrimos que estas heurísticas a menudo generaban poco paralelismo, ya que los pseudárboles tendían a tener una gran profundidad y bajos factores de ramificación. Sospechábamos que podría haber otras formas de organizar los pseudobosques que proporcionarían un mayor paralelismo y tamaños de mensaje más pequeños. Después de explorar estos otros arreglos, descubrimos que los pseudobosques de bordes cruzados proporcionan profundidades más cortas y factores de ramificación más altos que los pseudobosques tradicionales. Nuestra hipótesis era que estos pseudorboles cruzados superarían a los pseudorboles tradicionales en algunos tipos de problemas. En este artículo presentamos una extensión al algoritmo DPOP que maneja un conjunto ampliado de disposiciones de pseudobosque que incluyen pseudobosques con aristas cruzadas. Comenzamos con una definición de 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, pseudobosques tradicionales y pseudobosques de bordes cruzados. Luego proporcionamos un resumen del algoritmo DPOP original e introducimos nuestro algoritmo DCPOP. Discutimos la complejidad de nuestro algoritmo, así como el impacto de las heurísticas de generación de pseudobosques. Luego demostramos que nuestro Procedimiento de Optimización de Pseudotree de Bordes Cruzados Distribuido (DCPOP) funciona significativamente mejor en la práctica que el algoritmo DPOP original para algunas instancias del problema. Concluimos con una selección de ideas para trabajos futuros y extensiones para DCPOP. 2. La DEFINICIÓN DEL PROBLEMA DCOP ha sido formalizada de maneras ligeramente diferentes en la literatura reciente, por lo que adoptaremos la definición presentada en [6]. Un Problema de Optimización de Restricciones Distribuidas con n nodos y m restricciones consiste en la tupla < X, D, U > donde: • X = {x1,..,xn} es un conjunto de variables, cada una asignada a un agente único • D = {d1,..,dn} es un conjunto de dominios finitos para cada variable • U = {u1,..,um} es un conjunto de funciones de utilidad tales que cada función involucra un subconjunto de variables en X y define una utilidad para cada combinación de valores entre estas variables. Una solución óptima para una instancia de DCOP consiste en una asignación de valores en D a X tal que la suma de las utilidades en U sea máxima. Los dominios de problemas que requieren un costo mínimo en lugar de una utilidad máxima pueden mapear los costos en utilidades negativas. Las funciones de utilidad representan restricciones suaves pero también pueden representar restricciones fuertes mediante el uso de valores negativos arbitrariamente grandes. Para este artículo solo consideramos funciones de utilidad binarias que involucran dos variables. Las funciones de utilidad de orden superior pueden ser modeladas con cambios menores en el algoritmo, pero también aumentan sustancialmente la complejidad. 2.1 Pseudárboles Tradicionales Los pseudárboles son una estructura común utilizada en procedimientos de búsqueda para permitir el procesamiento paralelo de ramas independientes. Como se define en [6], un pseudoárbol es un arreglo de un grafo G en un árbol raíz T de tal manera que los vértices en G que comparten una arista están en la misma rama en T. Una arista de retroceso es una arista entre un nodo X y cualquier nodo que se encuentre en el camino desde X hasta la raíz (excluyendo al padre de X). La Figura 1 muestra un pseudoárbol con cuatro nodos, tres aristas (A-B, B-C, BD) y una arista de retroceso (A-C). También se definen en [6] cuatro tipos de relaciones entre nodos que existen en un pseudoárbol: • P(X) - el padre de un nodo X: el único nodo más alto en el pseudoárbol que está conectado a X directamente a través de un borde de árbol • C(X) - los hijos de un nodo X: el conjunto de nodos más bajos en el pseudo Las líneas sólidas representan relaciones padre-hijo y la línea discontinua representa una relación pseudo-padre-pseudo-hijo. Figura 2: Un pseudoárbol de bordes cruzados. Las líneas sólidas representan relaciones padre-hijo, la línea discontinua representa una relación pseudo-padre-pseudo-hijo, y la línea punteada representa una relación rama-padre-rama-hijo. El nodo en negrita, B, es el punto de fusión para el nodo E. 2.2 Pseudárboles con aristas cruzadas Definimos una arista cruzada como una arista de un nodo X a un nodo Y que está por encima de X pero no en el camino desde X hasta la raíz. Un pseudoárbol de bordes cruzados es un pseudoárbol tradicional con la adición de bordes cruzados. La Figura 2 muestra un pseudoárbol con una arista cruzada (D-E). En un pseudoárbol de bordes cruzados designamos ciertos bordes como primarios. El conjunto de aristas primarias define un árbol de expansión de los nodos. Las relaciones de padre, hijo, pseudo-padre y pseudo-hijo del pseudotree tradicional ahora están definidas en el contexto de este árbol de expansión de borde primario. Esta definición también produce dos tipos adicionales de relaciones que pueden existir entre nodos: • BP(X) - los nodos padres de rama de un nodo X: el conjunto de nodos más altos en el pseudoárbol que están conectados a X pero no están en el camino principal desde X hasta la raíz (En la Figura 2, D = BP(E)) • BC(X) - los nodos hijos de rama de un nodo X: el conjunto de nodos más bajos en el pseudo La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Los algoritmos actuales suelen tener una fase de pre-ejecución para generar un pseudoárbol tradicional a partir de una instancia general de DCOP. Nuestro algoritmo DCPOP genera un pseudoárbol de bordes cruzados de la misma manera. Primero, la instancia DCOP < X, D, U > se traduce directamente en un grafo con X como el conjunto de vértices y una arista para cada par de variables representadas en U. A continuación, se utilizan varias heurísticas para organizar este grafo en un pseudoárbol. Un heurístico común es realizar una búsqueda en profundidad guiada (DFS, por sus siglas en inglés) ya que el recorrido resultante es un pseudoárbol, y un DFS se puede realizar fácilmente de manera distribuida. Definimos un método basado en el recorrido de aristas como cualquier método que produce un pseudoárbol en el que todos los pares padre/hijo comparten una arista en el grafo original. Esto incluye recorridos basados en DFS, búsqueda en anchura y búsqueda de mejor primero. Nuestras heurísticas que generan pseudobosques de bordes cruzados utilizan un recorrido de búsqueda mejor primero distribuido. 3. ALGORITMO DPOP El algoritmo DPOP original opera en tres fases principales. La primera fase genera un pseudoárbol tradicional a partir de la instancia de DCOP utilizando un algoritmo distribuido. La segunda fase une hipercubos de utilidad de los nodos hijos y el nodo local y los propaga hacia la raíz. La tercera fase elige una asignación para cada dominio de arriba hacia abajo, comenzando con el agente en el nodo raíz. La complejidad de DPOP depende del tamaño del cálculo más grande y del mensaje de utilidad durante la fase dos. Se ha demostrado que este tamaño corresponde directamente al ancho inducido del pseudoárbol generado en la fase uno [6]. DPOP utiliza heurísticas de tiempo polinómico para generar el pseudoárbol, ya que encontrar el pseudoárbol de ancho inducido mínimo es NP-duro. Se han desarrollado varias heurísticas de recorrido de borde distribuido para encontrar pseudobosques de ancho reducido [8]. Al final de la primera fase, cada agente conoce a su padre, hijos, pseudo-padres y pseudo-hijos. 3.1 Propagación de utilidad Los agentes ubicados en los nodos hoja del pseudoárbol comienzan el proceso calculando un hipercubo de utilidad local. Este hipercubo en el nodo X contiene las utilidades sumadas para cada combinación de valores en los dominios de P(X) y PP(X). Este hipercubo tiene un tamaño dimensional igual al número de pseudo-padres más uno. Un mensaje que contiene este hipercubo se envía a P(X). Los agentes ubicados en nodos no hoja esperan a que lleguen todos los mensajes de los nodos hijos. Una vez que el agente en el nodo Y tiene todos los mensajes de utilidad, calcula su hipercubo de utilidad local que incluye los dominios de P(Y), PP(Y) y Y. El hipercubo de utilidad local se une luego con todos los hipercubos de los mensajes hijos. En este punto, todas las utilidades que involucran al nodo Y son conocidas, y el dominio de Y puede ser eliminado de forma segura del hipercubo unido. Este proceso de eliminación elige la mejor utilidad sobre el dominio de Y para cada combinación de los dominios restantes. Un mensaje que contiene este hipercubo se envía ahora a P(Y). El tamaño dimensional de este hipercubo depende del número de dominios superpuestos en los mensajes recibidos y del hipercubo de utilidad local. Esta fase de propagación basada en programación dinámica continúa hasta que el agente en el nodo raíz del pseudoárbol haya recibido todos los mensajes de sus hijos. 3.2 Propagación de Valor La propagación de valor comienza cuando el agente en el nodo raíz Z ha recibido todos los mensajes de sus hijos. Dado que Z no tiene padres ni pseudo-padres, simplemente combina los hipercubos de utilidad recibidos de sus hijos. El hipercubo combinado contiene solo valores para el dominio de Z. En este punto, el agente en el nodo Z simplemente elige la asignación para su dominio que tiene la mejor utilidad. Un mensaje de propagación de valor con esta asignación se envía a cada nodo en C(Z). Cada nodo luego recibe un mensaje de propagación de valor de su padre y elige la asignación para su dominio que tenga la mejor utilidad dadas las asignaciones recibidas en el mensaje. El nodo agrega su asignación de dominio a las asignaciones que recibió y pasa el conjunto de asignaciones a sus hijos. El algoritmo está completo cuando todos los nodos han elegido una asignación para su dominio. ALGORITMO DCPOP Nuestra extensión al algoritmo DPOP original, mostrada en el Algoritmo 1, comparte las mismas tres fases. La primera fase genera el pseudoárbol de bordes cruzados para la instancia de DCOP. La segunda fase fusiona ramas y propaga los hipercubos de utilidad. La tercera fase elige asignaciones para dominios en los puntos de fusión de ramas y de arriba hacia abajo, comenzando con el agente en el nodo raíz. Para la primera fase generamos un pseudoárbol utilizando varios heurísticos distribuidos y seleccionamos el que tenga la menor complejidad general. La complejidad de la computación y el tamaño del mensaje de utilidad en DCPOP no corresponden directamente al ancho inducido del pseudoárbol de aristas cruzadas. En cambio, utilizamos un método de tiempo polinómico para calcular el tamaño máximo de computación y utilidad del mensaje para un pseudoárbol de bordes cruzados dado. Una descripción de este método y el proceso de selección de pseudodendrogramas aparece en la Sección 5. Al final de la primera fase, cada agente conoce a su padre, hijos, pseudo-padres, pseudo-hijos, padres de rama e hijos de rama. 4.1 Fusión de Ramas y Propagación de Utilidad En el algoritmo DPOP original, un nodo X solo tenía funciones de utilidad que involucraban a su padre y a sus pseudo-padres. En DCPOP, se permite que un nodo X tenga una función de utilidad que involucre a un padre de rama. El concepto de una rama se puede ver en la Figura 2 con el nodo E representando nuestro nodo X. Las dos rutas distintas desde el nodo E hasta el nodo B se llaman ramas de E. El único nodo donde se encuentran todas las ramas de E es el nodo B, que se llama punto de fusión de E. Los agentes con nodos que tienen padres de rama comienzan enviando un mensaje de propagación de utilidad a cada padre de rama. Este mensaje incluye un hipercubo de utilidad bidimensional con dominios para el nodo X y el nodo padre de la rama BP(X). También incluye una estructura de información de rama que contiene el nodo de origen de la rama, X, el número total de ramas que se originan en X y el número de ramas que se originan en X y se fusionan en una representación única por esta estructura de información de rama (este número comienza en 1). Intuitivamente, cuando el número de ramas fusionadas es igual al número total de ramas originales, el algoritmo ha alcanzado el punto de fusión para X. En la Figura 2, el nodo E envía un mensaje de propagación de utilidad a su nodo padre de rama, el nodo D. Este mensaje tiene dimensiones para los dominios de E y D, e incluye información de rama con un origen en E, 2 ramas totales y 1 rama fusionada. Como en la fase de propagación de utilidad de la utilidad DPOP original, un agente en el nodo hoja X envía un mensaje de propagación de utilidad a su padre. En DCPOP, este mensaje contiene dimensiones para los dominios de P(X) y PP(X). Si el nodo X también tiene padres de rama, entonces el mensaje de propagación de utilidad también contiene una dimensión para el dominio de X e incluirá una estructura de información de rama. En la Figura 2, el nodo E envía un mensaje de propagación de utilidad a su padre, el nodo C. Este mensaje tiene dimensiones para los dominios de E y C, e incluye información de rama con un origen en E, 2 ramas en total y 1 rama fusionada. Cuando un nodo Y recibe mensajes de propagación de utilidad de todos de The Sixth Intl. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), 743 sus hijos y sus hijos de rama, fusiona cualquier rama con el mismo nodo de origen X. La estructura de información de la rama fusionada acumula el número de ramas fusionadas para X. Si el número total acumulado de ramas fusionadas es igual al número total de ramas, entonces Y es el punto de fusión para X. Esto significa que los hipercubos de utilidad presentes en Y contienen toda la información sobre las valoraciones de las funciones de utilidad que involucran al nodo X. Además de la eliminación típica del dominio de Y de los hipercubos de utilidad, ahora podemos eliminar de forma segura el dominio de X de los hipercubos de utilidad. Para ilustrar este proceso, examinaremos lo que sucede en la segunda fase para el nodo B en la Figura 2. En la segunda fase, el Nodo B recibe dos mensajes de propagación de utilidad. El primero proviene del nodo C e incluye dimensiones para los dominios E, B y A. También tiene una estructura de información de ramas con origen en E, 2 ramas en total y 1 rama fusionada. El segundo proviene del nodo D e incluye dimensiones para los dominios E y B. También tiene una estructura de información de rama con origen en E, 2 ramas en total y 1 rama fusionada. El nodo B luego fusiona las estructuras de información de rama de ambos mensajes porque tienen la misma procedencia, el nodo E. Dado que el número de ramas fusionadas que provienen de E es ahora 2 y el total de ramas que provienen de E es 2, el nodo B elimina las dimensiones para el dominio E. El nodo B también elimina la dimensión para su propio dominio, dejando solo información sobre el dominio A. Luego, el nodo B envía un mensaje de propagación de utilidad al nodo A, que contiene solo una dimensión para el dominio de A. Aunque no sea posible en DPOP, este método de propagación de utilidad y eliminación de dimensiones puede producir hipercubos en el nodo Y que no comparten ningún dominio. En DCPOP no unimos hipercubos independientes de dominio, sino que en su lugar podemos enviar múltiples hipercubos en el mensaje de propagación de utilidad enviado al padre de Y. Este enfoque perezoso de las uniones ayuda a reducir el tamaño de los mensajes. 4.2 Propagación de valores Al igual que en DPOP, la propagación de valores comienza cuando el agente en el nodo raíz Z ha recibido todos los mensajes de sus hijos. En este punto, el agente en el nodo Z elige la asignación para su dominio que tiene la mejor utilidad. Si Z es el punto de fusión de las ramas de algún nodo X, Z también elegirá la asignación para el dominio de X. Por lo tanto, cualquier nodo que sea un punto de fusión elegirá asignaciones para un dominio que no sea el suyo propio. Estas tareas luego se pasan por la jerarquía de la cadena de mando principal. Si el nodo X en la jerarquía tiene padres de rama, entonces el mensaje de asignación de valor de P(X) contendrá una asignación para el dominio de X. Cada nodo en la jerarquía agrega cualquier tarea que haya elegido a las que recibió y pasa el conjunto de tareas a sus hijos. El algoritmo está completo cuando todos los nodos han elegido o recibido una asignación para su dominio. 4.3 Prueba de Corrección Demostraremos la corrección de DCPOP notando primero que DCPOP extiende completamente DPOP y luego examinando los dos casos para la asignación de valores en DCPOP. Dado un pseudoárbol tradicional como entrada, la ejecución del algoritmo DCPOP es idéntica a DPOP. Usando un <br>arreglo de pseudodendrograma</br> tradicional, ningún nodo tiene padres de rama o hijos de rama, ya que todas las aristas son aristas de retroceso o aristas de árbol. Por lo tanto, el algoritmo DCPOP utilizando un pseudoárbol tradicional envía solo mensajes de propagación de utilidad que contienen dominios pertenecientes al padre o pseudo-padres de un nodo. Dado que ningún nodo tiene ramas-padres, no existen ramas, y por lo tanto ningún nodo sirve como punto de fusión para ningún otro nodo. Por lo tanto, todas las asignaciones de propagación de valor se eligen en el nodo del dominio de la asignación. Para la ejecución de DCPOP con pseudárboles de bordes cruzados, algunos nodos actúan como puntos de fusión. Observamos que cualquier nodo X que no sea un punto de fusión asigna su valor exactamente como en DPOP. El hipercubo de utilidad local en X contiene dominios para X, P(X), PP(X) y BC(X). Como en DPOP, el mensaje de asignación de valores recibido en X incluye los valores asignados a P(X) y PP(X). Además, dado que X no es un punto de fusión, todas las asignaciones a BC(X) deben haber sido calculadas en puntos de fusión más altos en el árbol y están en el mensaje de asignación de valor de P(X). Por lo tanto, después de eliminar los dominios para los cuales se conocen las asignaciones, solo queda el dominio de X. El agente en el nodo X ahora puede elegir correctamente la asignación con la máxima utilidad para su propio dominio. Si el nodo X es un punto de fusión para alguna rama-hijo Y, sabemos que X debe ser un nodo a lo largo del camino desde Y hasta la raíz, y desde P(Y) y todos los BP(Y) hasta la raíz. A partir del algoritmo, sabemos que Y necesariamente tiene toda la información de C(Y), PC(Y) y BC(Y) ya que espera sus mensajes. El nodo X tiene información sobre todos los nodos debajo de él en el árbol, lo cual incluiría a Y, P(Y), BP(Y) y aquellos PP(Y) que están debajo de X en el árbol. Para cualquier PP(Y) por encima de X en el árbol, X recibe la asignación para el dominio de PP(Y) en el mensaje de asignación de valor de P(X). Por lo tanto, X tiene información de utilidad sobre todas las funciones de utilidad de las cuales Y forma parte. Al eliminar los dominios incluidos en el mensaje de asignación de valor, el nodo X se queda con un hipercubo de utilidad local con dominios para X e Y. El agente en el nodo X ahora puede elegir correctamente las asignaciones con la máxima utilidad para los dominios de X e Y. 4.4 Análisis de complejidad La primera fase de DCPOP envía un mensaje a cada P(X), PP(X) y BP(X). La segunda fase envía un mensaje de asignación de valor a cada C(X). Por lo tanto, DCPOP produce un número lineal de mensajes con respecto al número de aristas (funciones de utilidad) en el pseudoárbol de aristas cruzadas y la instancia original de DCOP. La complejidad real de DCPOP depende de dos medidas adicionales: el tamaño del mensaje y el tamaño de la computación. El tamaño del mensaje y el tamaño de la computación en DCPOP dependen del número de ramas superpuestas, así como del número de aristas de retroceso superpuestas. Se demostró en [6] que el número de aristas traslapadas es igual al ancho inducido del pseudoárbol. En un pseudoárbol de bordes cruzados mal construido, el número de ramas superpuestas en el nodo X puede ser tan grande como el número total de descendientes de X. Por lo tanto, el tamaño total del mensaje en DCPOP en una instancia mal construida puede ser exponencial en el espacio en el número total de nodos en el grafo. Sin embargo, en la práctica, un pseudoárbol bien construido con bordes cruzados puede lograr resultados mucho mejores. Más tarde abordaremos el tema de elegir pseudobosques cruzados bien construidos de un conjunto. Introducimos una medida adicional del costo máximo de la ruta secuencial a través del algoritmo. Esta medida se relaciona directamente con la cantidad máxima de paralelismo que puede lograr el algoritmo. Para tomar esta medida, primero almacenamos el tamaño total de cálculo para cada nodo durante las fases dos y tres. Este tamaño de cálculo representa el número de accesos individuales a un valor en un hipercubo en cada nodo. Por ejemplo, una unión entre dos dominios de tamaño 4 cuesta 4 ∗ 4 = 16. Dos grafos acíclicos dirigidos (DAG) pueden ser dibujados; uno con los mensajes de propagación de utilidad como aristas y los costos de la fase dos en los nodos, y el otro con los mensajes de asignación de valor y los costos de la fase tres en los nodos. El costo máximo del camino secuencial es igual a la suma del camino más largo en cada DAG desde la raíz hasta cualquier nodo hoja. HEURÍSTICAS En nuestra evaluación de la complejidad en DCPOP nos enfocamos en el peor caso posiblemente producido por el algoritmo. Reconocemos 744 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Algoritmo 1 DCPOP Algoritmo 1: DCPOP(X; D; U) Cada agente Xi ejecuta: Fase 1: creación de pseudotree 2: elegir líder de todos los Xj ∈ X 3: líder elegido inicia la creación de pseudotree 4: después, Xi conoce P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) y PC(Xi) Fase 2: propagación de mensajes UTIL 5: si |BP(Xi)| > 0 entonces 6: BRANCHXi ← |BP(Xi)| + 1 7: para todos Xk ∈BP(Xi) hacer 8: UTILXi (Xk) ← Calcular utils(Xi, Xk) 9: Enviar mensaje(Xk,UTILXi (Xk),BRANCHXi ) 10: si |C(Xi)| = 0 (es decir, Si Xi es un nodo hoja, entonces 11: UTILXi (P(Xi)) ← Calcular utils(P(Xi),PP(Xi)) para todos los PP(Xi) 12: Enviar mensaje(P(Xi), UTILXi (P(Xi)), BRANCHXi ) 13: Enviar mensaje(PP(Xi), UTIL vacío, BRANCH vacío) a todos los PP(Xi) 14: Activar el manejador de mensajes UTIL() Fase 3: Propagación de mensajes de VALOR 15: Activar el manejador de mensajes de VALOR() FIN ALGORITMO Manejador de mensajes UTIL(Xk, UTILXk (Xi), BRANCHXk ) 16: Almacenar UTILXk (Xi), BRANCHXk (Xi) 17: Si han llegado mensajes UTIL de todos los hijos y los hijos de la rama, entonces 18: Para todos los Bj ∈ BRANCH(Xi) hacer 19: Si Bj está fusionado, entonces 20: Unir todos los hipercubos donde Bj ∈ UTIL(Xi) 21: Eliminar Bj del hipercubo unido 22: Si P(Xi) == nulo (eso significa que Xi es la raíz) entonces 23: v ∗ i ← Elegir óptimo(nulo) 24: Enviar VALOR(Xi, v ∗ i) a todos los C(Xi) 25: De lo contrario 26: UTILXi (P(Xi)) ← Calcular utils(P(Xi), PP(Xi)) 27: Enviar mensaje(P(Xi), UTILXi (P(Xi)), BRANCHXi (P(Xi))) Manejador de mensajes de VALOR(VALORXi , P(Xi)) 28: Agregar todos los Xk ← v ∗ k ∈ VALORXi , P(Xi) a la vista del agente 29: Xi ← v ∗ i = Elegir óptimo(vista del agente) 30: Enviar VALORXl , Xi a todos los Xl ∈ C(Xi) que en problemas del mundo real la generación del pseudoárbol tiene un impacto significativo en el rendimiento real. El problema de encontrar la mejor pseudotree para una instancia de DCOP dada es NP-Difícil. Por lo tanto, se utiliza una heurística para la generación, y el rendimiento del algoritmo depende del pseudoárbol encontrado por la heurística. Algunas investigaciones previas se centraron en encontrar heurísticas para generar buenas pseudorboles [8]. Si bien hemos desarrollado algunas heurísticas que generan buenos pseudoárboles cruzados para usar con DCPOP, nuestro enfoque ha sido utilizar múltiples heurísticas y luego seleccionar el mejor pseudo Consideramos solo heurísticas que se ejecuten en tiempo polinómico con respecto al número de nodos en la instancia original del DCOP. El algoritmo DCPOP actual tiene una complejidad exponencial en el peor de los casos, pero podemos calcular el tamaño máximo del mensaje, el tamaño de la computación y el costo de la ruta secuencial para un pseudoárbol de bordes cruzados dado en complejidad espacio-temporal lineal. Para hacer esto, simplemente ejecutamos el algoritmo sin intentar calcular ninguno de los hipercubos de utilidad local o asignaciones de valor óptimo. En cambio, los mensajes incluyen información dimensional y de ramificación pero no hipercubos de utilidad. Después de que cada heurística complete la generación de un pseudoárbol, ejecutamos el procedimiento de medición y propagamos la información de la medición hasta la raíz elegida en ese pseudo La raíz luego transmite la complejidad total de esa heurística a todos los nodos. Después de que todas las heurísticas hayan tenido la oportunidad de completarse, cada nodo sabe qué heurística produjo el mejor pseudoárbol. Cada nodo luego procede a comenzar el algoritmo DCPOP utilizando su conocimiento del pseudoárbol generado por la mejor heurística. Las heurísticas utilizadas para generar pseudárboles tradicionales realizan un recorrido DFS distribuido. El algoritmo distribuido general utiliza un mecanismo de paso de token y un número lineal de mensajes. Las heurísticas mejoradas basadas en DFS utilizan un procedimiento especial para elegir el nodo raíz, y también proporcionan una función de ordenación sobre los vecinos de un nodo para determinar el orden de la recursión de caminos. Las heurísticas basadas en DFS utilizadas en nuestros experimentos provienen del trabajo realizado en [4, 8]. 5.1 La heurística de pseudotree cruzado de mejor primer recorrido. Las heurísticas utilizadas para generar pseudárboles cruzados realizan un recorrido de mejor primer recorrido. Se presenta un algoritmo general distribuido de mejor primero para la expansión de nodos en el Algoritmo 2. Una función de evaluación en cada nodo proporciona los valores que se utilizan para determinar el siguiente mejor nodo a expandir. Ten en cuenta que en este algoritmo cada nodo solo intercambia su mejor valor con sus vecinos. En nuestros experimentos utilizamos varias funciones de evaluación que tomaban como argumentos una lista ordenada de ancestros y un nodo, que contiene una lista de vecinos (con la profundidad de colocación de cada vecino en el árbol). A partir de estos podemos calcular los padres de la rama, los hijos de la rama y las relaciones desconocidas para una posible ubicación del nodo. La mejor función general calculó el valor como ancestros - (padres de rama + hijos de rama) con el número de relaciones desconocidas como criterio de desempate. Después de completarse, cada nodo tiene conocimiento de su padre y ancestros, por lo que puede determinar fácilmente qué nodos conectados son pseudo-padres, padres de rama, pseudo-hijos e hijos de rama. La complejidad de la travesía de mejor primero depende de la complejidad de la función de evaluación. Suponiendo una complejidad de O(V) para la función de evaluación, que es el caso de nuestra mejor función general, el recorrido de mejor primero es O(V · E), lo que en el peor de los casos es O(n3). Para cada v ∈ V realizamos una operación de colocación y encontramos el siguiente nodo a colocar usando la operación getBestNeighbor. La complejidad de la operación del lugar es a lo sumo O(V) debido a los mensajes enviados. Encontrar el siguiente nodo utiliza recursión y recorre solo los ya colocados The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 745 Algoritmo 2 Algoritmo de Búsqueda Distribuida de Mejor Primero root ← líder elegido next(root, ∅) place(nodo, padre) nodo.padre ← padre nodo.ancestros ← padre.ancestros ∪ padre enviar mensaje de ubicación (nodo, nodo.ancestros) a todos los vecinos de nodo next(actual, anterior) si actual no está ubicado entonces place(actual, anterior) next(actual, ∅) else mejor ← obtenerMejorVecino(actual, anterior) si mejor = ∅ entonces si anterior = ∅ entonces terminar, todos los nodos están ubicados next(anterior, ∅) else next(mejor, actual) obtenerMejorVecino(actual, anterior) mejor ← ∅; puntaje ← 0 para todo n ∈ vecinos de actual hacer si n! = anterior entonces si n está ubicado entonces puntajeN ← obtenerMejorVecino(n, actual) else puntajeN ← evaluar(actual, n) si puntajeN > puntaje entonces puntaje ← puntajeN mejor ← n return mejor, puntaje nodos, por lo que tiene O(V) recursiones. Cada recursión realiza una operación recursiva getBestNeighbor que recorre todos los nodos colocados y sus vecinos. Esta operación es O(V · E), pero los resultados se pueden almacenar en caché utilizando solo O(V) espacio en cada nodo. Así que tenemos O(V ·(V +V +V ·E)) = O(V 2 ·E). Si somos inteligentes al evaluar los cambios locales cuando cada nodo recibe mensajes de ubicación de sus vecinos y almacenamos en caché los resultados, la operación getBestNeighbor es solo O(E). Esto aumenta la complejidad de la operación de ubicación, pero para todas las ubicaciones la complejidad total es solo O(V · E). Por lo tanto, tenemos una complejidad general de O(V ·E+V ·(V +E)) = O(V ·E). 6. COMPARACIÓN DE COMPLEJIDAD EN DPOP Y DCPOP Ya hemos demostrado que, dado el mismo input, DCPOP se desempeña igual que DPOP. También hemos demostrado que podemos predecir con precisión el rendimiento de un pseudoárbol dado en complejidad temporal lineal. Si usamos un número constante de heurísticas para generar el conjunto de pseudobosques, podemos elegir el mejor pseudobosque con complejidad lineal en espacio y tiempo. Ahora demostraremos que existe una instancia de DCOP para la cual un pseudoárbol de bordes cruzados supera a todos los posibles pseudoárboles tradicionales (basados en heurísticas de recorrido de bordes). En la Figura 3(a) tenemos una instancia de DCOP con seis nodos. Este es un grafo bipartito con cada partición completamente conectada a la otra (a) (b) (c) Figura 3: (a) La instancia de DCOP (b) Un arreglo de <br>pseudobosque</br> tradicional para la instancia de DCOP (c) Un arreglo de <br>pseudobosque</br> con aristas cruzadas para la partición de la instancia de DCOP. En la Figura 3(b) vemos un <br>arreglo tradicional de pseudotree</br> para esta instancia de DCOP. Es fácil ver que cualquier heurística basada en el recorrido de aristas no puede expandir dos nodos de la misma partición sucesivamente. También observamos que ningún nodo puede tener más de un hijo porque cualquier disposición de este tipo sería un pseudoárbol inválido. Por lo tanto, cualquier disposición tradicional de <br>pseudodendrograma</br> para esta instancia de DCOP debe tener la forma de la Figura 3(b). Podemos ver que las aristas de retroceso F-B y F-A se superponen al nodo C. El nodo C también tiene un padre E y una arista de retroceso con D. Utilizando el algoritmo DPOP original (o DCPOP ya que son idénticos en este caso), encontramos que el cálculo en el nodo C implica cinco dominios: A, B, C, D y E. En contraste, el <br>arreglo de pseudonodos con aristas cruzadas</br> en la Figura 3(c) requiere un máximo de cuatro dominios en cualquier cálculo durante DCPOP. ",
            "candidates": [],
            "error": [
                [
                    "arreglo de pseudodendrograma",
                    "pseudobosque",
                    "pseudobosque",
                    "arreglo tradicional de pseudotree",
                    "pseudodendrograma",
                    "arreglo de pseudonodos con aristas cruzadas"
                ]
            ]
        },
        "multi-agent system": {
            "translated_key": "sistemas multiagente",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Complete Distributed Constraint Optimization Method For Non-Traditional Pseudotree Arrangements∗ James Atlas Computer and Information Sciences University of Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Computer and Information Sciences University of Delaware Newark, DE 19716 decker@cis.udel.edu ABSTRACT Distributed Constraint Optimization (DCOP) is a general framework that can model complex problems in <br>multi-agent system</br>s.",
                "Several current algorithms that solve general DCOP instances, including ADOPT and DPOP, arrange agents into a traditional pseudotree structure.",
                "We introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements.",
                "Our algorithm correctly solves DCOP instances for pseudotrees that include edges between nodes in separate branches.",
                "The algorithm also solves instances with traditional pseudotree arrangements using the same procedure as DPOP.",
                "We compare our algorithm with DPOP using several metrics including the induced width of the pseudotrees, the maximum dimensionality of messages and computation, and the maximum sequential path cost through the algorithm.",
                "We prove that for some problem instances it is not possible to generate a traditional pseudotree using edge-traversal heuristics that will outperform a cross-edged pseudotree.",
                "We use multiple heuristics to generate pseudotrees and choose the best pseudotree in linear space-time complexity.",
                "For some problem instances we observe significant improvements in message and computation sizes compared to DPOP.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent Systems General Terms Algorithms 1.",
                "INTRODUCTION Many historical problems in the AI community can be transformed into Constraint Satisfaction Problems (CSP).",
                "With the advent of distributed AI, <br>multi-agent system</br>s became a popular way to model the complex interactions and coordination required to solve distributed problems.",
                "CSPs were originally extended to distributed agent environments in [9].",
                "Early domains for distributed constraint satisfaction problems (DisCSP) included job shop scheduling [1] and resource allocation [2].",
                "Many domains for agent systems, especially teamwork coordination, distributed scheduling, and sensor networks, involve overly constrained problems that are difficult or impossible to satisfy for every constraint.",
                "Recent approaches to solving problems in these domains rely on optimization techniques that map constraints into multi-valued utility functions.",
                "Instead of finding an assignment that satisfies all constraints, these approaches find an assignment that produces a high level of global utility.",
                "This extension to the original DisCSP approach has become popular in <br>multi-agent system</br>s, and has been labeled the Distributed Constraint Optimization Problem (DCOP) [1].",
                "Current algorithms that solve complete DCOPs use two main approaches: search and dynamic programming.",
                "Search based algorithms that originated from DisCSP typically use some form of backtracking [10] or bounds propagation, as in ADOPT [3].",
                "Dynamic programming based algorithms include DPOP and its extensions [5, 6, 7].",
                "To date, both categories of algorithms arrange agents into a traditional pseudotree to solve the problem.",
                "It has been shown in [6] that any constraint graph can be mapped into a traditional pseudotree.",
                "However, it was also shown that finding the optimal pseudotree was NP-Hard.",
                "We began to investigate the performance of traditional pseudotrees generated by current edge-traversal heuristics.",
                "We found that these heuristics often produced little parallelism as the pseudotrees tended to have high depth and low branching factors.",
                "We suspected that there could be other ways to arrange the pseudotrees that would provide increased parallelism and smaller message sizes.",
                "After exploring these other arrangements we found that cross-edged pseudotrees provide shorter depths and higher branching factors than the traditional pseudotrees.",
                "Our hypothesis was that these crossedged pseudotrees would outperform traditional pseudotrees for some problem types.",
                "In this paper we introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements which include cross-edged pseudotrees.",
                "We begin with a definition of 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, traditional pseudotrees, and cross-edged pseudotrees.",
                "We then provide a summary of the original DPOP algorithm and introduce our DCPOP algorithm.",
                "We discuss the complexity of our algorithm as well as the impact of pseudotree generation heuristics.",
                "We then show that our Distributed Cross-edged Pseudotree Optimization Procedure (DCPOP) performs significantly better in practice than the original DPOP algorithm for some problem instances.",
                "We conclude with a selection of ideas for future work and extensions for DCPOP. 2.",
                "PROBLEM DEFINITION DCOP has been formalized in slightly different ways in recent literature, so we will adopt the definition as presented in [6].",
                "A Distributed Constraint Optimization Problem with n nodes and m constraints consists of the tuple < X, D, U > where: • X = {x1,..,xn} is a set of variables, each one assigned to a unique agent • D = {d1,..,dn} is a set of finite domains for each variable • U = {u1,..,um} is a set of utility functions such that each function involves a subset of variables in X and defines a utility for each combination of values among these variables An optimal solution to a DCOP instance consists of an assignment of values in D to X such that the sum of utilities in U is maximal.",
                "Problem domains that require minimum cost instead of maximum utility can map costs into negative utilities.",
                "The utility functions represent soft constraints but can also represent hard constraints by using arbitrarily large negative values.",
                "For this paper we only consider binary utility functions involving two variables.",
                "Higher order utility functions can be modeled with minor changes to the algorithm, but they also substantially increase the complexity. 2.1 Traditional Pseudotrees Pseudotrees are a common structure used in search procedures to allow parallel processing of independent branches.",
                "As defined in [6], a pseudotree is an arrangement of a graph G into a rooted tree T such that vertices in G that share an edge are in the same branch in T. A back-edge is an edge between a node X and any node which lies on the path from X to the root (excluding Xs parent).",
                "Figure 1 shows a pseudotree with four nodes, three edges (A-B, B-C, BD), and one back-edge (A-C).",
                "Also defined in [6] are four types of relationships between nodes exist in a pseudotree: • P(X) - the parent of a node X: the single node higher in the pseudotree that is connected to X directly through a tree edge • C(X) - the children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through tree edges • PP(X) - the pseudo-parents of a node X: the set of nodes higher in the pseudotree that are connected to X directly through back-edges (In Figure 1, A = PP(C)) • PC(X) - the pseudo-children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through back-edges (In Figure 1, C = PC(A)) Figure 1: A traditional pseudotree.",
                "Solid line edges represent parent-child relationships and the dashed line represents a pseudo-parent-pseudo-child relationship.",
                "Figure 2: A cross-edged pseudotree.",
                "Solid line edges represent parent-child relationships, the dashed line represents a pseudoparent-pseudo-child relationship, and the dotted line represents a branch-parent-branch-child relationship.",
                "The bolded node, B, is the merge point for node E. 2.2 Cross-edged Pseudotrees We define a cross-edge as an edge from node X to a node Y that is above X but not in the path from X to the root.",
                "A cross-edged pseudotree is a traditional pseudotree with the addition of cross-edges.",
                "Figure 2 shows a cross-edged pseudotree with a cross-edge (D-E).",
                "In a cross-edged pseudotree we designate certain edges as primary.",
                "The set of primary edges defines a spanning tree of the nodes.",
                "The parent, child, pseudo-parent, and pseudo-child relationships from the traditional pseudotree are now defined in the context of this primary edge spanning tree.",
                "This definition also yields two additional types of relationships that may exist between nodes: • BP(X) - the branch-parents of a node X: the set of nodes higher in the pseudotree that are connected to X but are not in the primary path from X to the root (In Figure 2, D = BP(E)) • BC(X) - the branch-children of a node X: the set of nodes lower in the pseudotree that are connected to X but are not in any primary path from X to any leaf node (In Figure 2, E = BC(D)) 2.3 Pseudotree Generation 742 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Current algorithms usually have a pre-execution phase to generate a traditional pseudotree from a general DCOP instance.",
                "Our DCPOP algorithm generates a cross-edged pseudotree in the same fashion.",
                "First, the DCOP instance < X, D, U > translates directly into a graph with X as the set of vertices and an edge for each pair of variables represented in U.",
                "Next, various heuristics are used to arrange this graph into a pseudotree.",
                "One common heuristic is to perform a guided depth-first search (DFS) as the resulting traversal is a pseudotree, and a DFS can easily be performed in a distributed fashion.",
                "We define an edge-traversal based method as any method that produces a pseudotree in which all parent/child pairs share an edge in the original graph.",
                "This includes DFS, breadth-first search, and best-first search based traversals.",
                "Our heuristics that generate cross-edged pseudotrees use a distributed best-first search traversal. 3.",
                "DPOP ALGORITHM The original DPOP algorithm operates in three main phases.",
                "The first phase generates a traditional pseudotree from the DCOP instance using a distributed algorithm.",
                "The second phase joins utility hypercubes from children and the local node and propagates them towards the root.",
                "The third phase chooses an assignment for each domain in a top down fashion beginning with the agent at the root node.",
                "The complexity of DPOP depends on the size of the largest computation and utility message during phase two.",
                "It has been shown that this size directly corresponds to the induced width of the pseudotree generated in phase one [6].",
                "DPOP uses polynomial time heuristics to generate the pseudotree since finding the minimum induced width pseudotree is NP-hard.",
                "Several distributed edgetraversal heuristics have been developed to find low width pseudotrees [8].",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, and pseudo-children. 3.1 Utility Propagation Agents located at leaf nodes in the pseudotree begin the process by calculating a local utility hypercube.",
                "This hypercube at node X contains summed utilities for each combination of values in the domains for P(X) and PP(X).",
                "This hypercube has dimensional size equal to the number of pseudo-parents plus one.",
                "A message containing this hypercube is sent to P(X).",
                "Agents located at non-leaf nodes wait for all messages from children to arrive.",
                "Once the agent at node Y has all utility messages, it calculates its local utility hypercube which includes domains for P(Y), PP(Y), and Y.",
                "The local utility hypercube is then joined with all of the hypercubes from the child messages.",
                "At this point all utilities involving node Y are known, and the domain for Y may be safely eliminated from the joined hypercube.",
                "This elimination process chooses the best utility over the domain of Y for each combination of the remaining domains.",
                "A message containing this hypercube is now sent to P(Y).",
                "The dimensional size of this hypercube depends on the number of overlapping domains in received messages and the local utility hypercube.",
                "This dynamic programming based propagation phase continues until the agent at the root node of the pseudotree has received all messages from its children. 3.2 Value Propagation Value propagation begins when the agent at the root node Z has received all messages from its children.",
                "Since Z has no parents or pseudo-parents, it simply combines the utility hypercubes received from its children.",
                "The combined hypercube contains only values for the domain for Z.",
                "At this point the agent at node Z simply chooses the assignment for its domain that has the best utility.",
                "A value propagation message with this assignment is sent to each node in C(Z).",
                "Each other node then receives a value propagation message from its parent and chooses the assignment for its domain that has the best utility given the assignments received in the message.",
                "The node adds its domain assignment to the assignments it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen an assignment for their domain. 4.",
                "DCPOP ALGORITHM Our extension to the original DPOP algorithm, shown in Algorithm 1, shares the same three phases.",
                "The first phase generates the cross-edged pseudotree for the DCOP instance.",
                "The second phase merges branches and propagates the utility hypercubes.",
                "The third phase chooses assignments for domains at branch merge points and in a top down fashion, beginning with the agent at the root node.",
                "For the first phase we generate a pseudotree using several distributed heuristics and select the one with lowest overall complexity.",
                "The complexity of the computation and utility message size in DCPOP does not directly correspond to the induced width of the cross-edged pseudotree.",
                "Instead, we use a polynomial time method for calculating the maximum computation and utility message size for a given cross-edged pseudotree.",
                "A description of this method and the pseudotree selection process appears in Section 5.",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, pseudo-children, branch-parents, and branch-children. 4.1 Merging Branches and Utility Propagation In the original DPOP algorithm a node X only had utility functions involving its parent and its pseudo-parents.",
                "In DCPOP, a node X is allowed to have a utility function involving a branch-parent.",
                "The concept of a branch can be seen in Figure 2 with node E representing our node X.",
                "The two distinct paths from node E to node B are called branches of E. The single node where all branches of E meet is node B, which is called the merge point of E. Agents with nodes that have branch-parents begin by sending a utility propagation message to each branch-parent.",
                "This message includes a two dimensional utility hypercube with domains for the node X and the branch-parent BP(X).",
                "It also includes a branch information structure which contains the origination node of the branch, X, the total number of branches originating from X, and the number of branches originating from X that are merged into a single representation by this branch information structure (this number starts at 1).",
                "Intuitively when the number of merged branches equals the total number of originating branches, the algorithm has reached the merge point for X.",
                "In Figure 2, node E sends a utility propagation message to its branch-parent, node D. This message has dimensions for the domains of E and D, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "As in the original DPOP utility propagation phase, an agent at leaf node X sends a utility propagation message to its parent.",
                "In DCPOP this message contains dimensions for the domains of P(X) and PP(X).",
                "If node X also has branch-parents, then the utility propagation message also contains a dimension for the domain of X, and will include a branch information structure.",
                "In Figure 2, node E sends a utility propagation message to its parent, node C. This message has dimensions for the domains of E and C, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "When a node Y receives utility propagation messages from all of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 743 its children and branch-children, it merges any branches with the same origination node X.",
                "The merged branch information structure accumulates the number of merged branches for X.",
                "If the cumulative total number of merged branches equals the total number of branches, then Y is the merge point for X.",
                "This means that the utility hypercubes present at Y contain all information about the valuations for utility functions involving node X.",
                "In addition to the typical elimination of the domain of Y from the utility hypercubes, we can now safely eliminate the domain of X from the utility hypercubes.",
                "To illustrate this process, we will examine what happens in the second phase for node B in Figure 2.",
                "In the second phase Node B receives two utility propagation messages.",
                "The first comes from node C and includes dimensions for domains E, B, and A.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "The second comes from node D and includes dimensions for domains E and B.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "Node B then merges the branch information structures from both messages because they have the same origination, node E. Since the number of merged branches originating from E is now 2 and the total branches originating from E is 2, node B now eliminates the dimensions for domain E. Node B also eliminates the dimension for its own domain, leaving only information about domain A. Node B then sends a utility propagation message to node A, containing only one dimension for the domain of A.",
                "Although not possible in DPOP, this method of utility propagation and dimension elimination may produce hypercubes at node Y that do not share any domains.",
                "In DCPOP we do not join domain independent hypercubes, but instead may send multiple hypercubes in the utility propagation message sent to the parent of Y.",
                "This lazy approach to joins helps to reduce message sizes. 4.2 Value Propagation As in DPOP, value propagation begins when the agent at the root node Z has received all messages from its children.",
                "At this point the agent at node Z chooses the assignment for its domain that has the best utility.",
                "If Z is the merge point for the branches of some node X, Z will also choose the assignment for the domain of X.",
                "Thus any node that is a merge point will choose assignments for a domain other than its own.",
                "These assignments are then passed down the primary edge hierarchy.",
                "If node X in the hierarchy has branch-parents, then the value assignment message from P(X) will contain an assignment for the domain of X.",
                "Every node in the hierarchy adds any assignments it has chosen to the ones it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen or received an assignment for their domain. 4.3 Proof of Correctness We will prove the correctness of DCPOP by first noting that DCPOP fully extends DPOP and then examining the two cases for value assignment in DCPOP.",
                "Given a traditional pseudotree as input, the DCPOP algorithm execution is identical to DPOP.",
                "Using a traditional pseudotree arrangement no nodes have branch-parents or branch-children since all edges are either back-edges or tree edges.",
                "Thus the DCPOP algorithm using a traditional pseudotree sends only utility propagation messages that contain domains belonging to the parent or pseudo-parents of a node.",
                "Since no node has any branch-parents, no branches exist, and thus no node serves as a merge point for any other node.",
                "Thus all value propagation assignments are chosen at the node of the assignment domain.",
                "For DCPOP execution with cross-edged pseudotrees, some nodes serve as merge points.",
                "We note that any node X that is not a merge point assigns its value exactly as in DPOP.",
                "The local utility hypercube at X contains domains for X, P(X), PP(X), and BC(X).",
                "As in DPOP the value assignment message received at X includes the values assigned to P(X) and PP(X).",
                "Also, since X is not a merge point, all assignments to BC(X) must have been calculated at merge points higher in the tree and are in the value assignment message from P(X).",
                "Thus after eliminating domains for which assignments are known, only the domain of X is left.",
                "The agent at node X can now correctly choose the assignment with maximum utility for its own domain.",
                "If node X is a merge point for some branch-child Y, we know that X must be a node along the path from Y to the root, and from P(Y) and all BP(Y) to the root.",
                "From the algorithm, we know that Y necessarily has all information from C(Y), PC(Y), and BC(Y) since it waits for their messages.",
                "Node X has information about all nodes below it in the tree, which would include Y, P(Y), BP(Y), and those PP(Y) that are below X in the tree.",
                "For any PP(Y) above X in the tree, X receives the assignment for the domain of PP(Y) in the value assignment message from P(X).",
                "Thus X has utility information about all of the utility functions of which Y is a part.",
                "By eliminating domains included in the value assignment message, node X is left with a local utility hypercube with domains for X and Y.",
                "The agent at node X can now correctly choose the assignments with maximum utility for the domains of X and Y. 4.4 Complexity Analysis The first phase of DCPOP sends one message to each P(X), PP(X), and BP(X).",
                "The second phase sends one value assignment message to each C(X).",
                "Thus, DCPOP produces a linear number of messages with respect to the number of edges (utility functions) in the cross-edged pseudotree and the original DCOP instance.",
                "The actual complexity of DCPOP depends on two additional measurements: message size and computation size.",
                "Message size and computation size in DCPOP depend on the number of overlapping branches as well as the number of overlapping back-edges.",
                "It was shown in [6] that the number of overlapping back-edges is equal to the induced width of the pseudotree.",
                "In a poorly constructed cross-edged pseudotree, the number of overlapping branches at node X can be as large as the total number of descendants of X.",
                "Thus, the total message size in DCPOP in a poorly constructed instance can be space-exponential in the total number of nodes in the graph.",
                "However, in practice a well constructed cross-edged pseudotree can achieve much better results.",
                "Later we address the issue of choosing well constructed crossedged pseudotrees from a set.",
                "We introduce an additional measurement of the maximum sequential path cost through the algorithm.",
                "This measurement directly relates to the maximum amount of parallelism achievable by the algorithm.",
                "To take this measurement we first store the total computation size for each node during phase two and three.",
                "This computation size represents the number of individual accesses to a value in a hypercube at each node.",
                "For example, a join between two domains of size 4 costs 4 ∗ 4 = 16.",
                "Two directed acyclic graphs (DAG) can then be drawn; one with the utility propagation messages as edges and the phase two costs at nodes, and the other with value assignment messages and the phase three costs at nodes.",
                "The maximum sequential path cost is equal to the sum of the longest path on each DAG from the root to any leaf node. 5.",
                "HEURISTICS In our assessment of complexity in DCPOP we focused on the worst case possibly produced by the algorithm.",
                "We acknowledge 744 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Algorithm 1 DCPOP Algorithm 1: DCPOP(X; D; U) Each agent Xi executes: Phase 1: pseudotree creation 2: elect leader from all Xj ∈ X 3: elected leader initiates pseudotree creation 4: afterwards, Xi knows P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) and PC(Xi) Phase 2: UTIL message propagation 5: if |BP(Xi)| > 0 then 6: BRANCHXi ← |BP(Xi)| + 1 7: for all Xk ∈BP(Xi) do 8: UTILXi (Xk) ←Compute utils(Xi, Xk) 9: Send message(Xk,UTILXi (Xk),BRANCHXi ) 10: if |C(Xi)| = 0(i.e.",
                "Xi is a leaf node) then 11: UTILXi (P(Xi)) ← Compute utils(P(Xi),PP(Xi)) for all PP(Xi) 12: Send message(P(Xi), UTILXi (P(Xi)),BRANCHXi ) 13: Send message(PP(Xi), empty UTIL, empty BRANCH) to all PP(Xi) 14: activate UTIL Message handler() Phase 3: VALUE message propagation 15: activate VALUE Message handler() END ALGORITHM UTIL Message handler(Xk,UTILXk (Xi), BRANCHXk ) 16: store UTILXk (Xi),BRANCHXk (Xi) 17: if UTIL messages from all children and branch children arrived then 18: for all Bj ∈BRANCH(Xi) do 19: if Bj is merged then 20: join all hypercubes where Bj ∈UTIL(Xi) 21: eliminate Bj from the joined hypercube 22: if P(Xi) == null (that means Xi is the root) then 23: v ∗ i ← Choose optimal(null) 24: Send VALUE(Xi, v ∗ i) to all C(Xi) 25: else 26: UTILXi (P(Xi)) ← Compute utils(P(Xi), PP(Xi)) 27: Send message(P(Xi),UTILXi (P(Xi)), BRANCHXi (P(Xi))) VALUE Message handler(VALUEXi ,P(Xi)) 28: add all Xk ← v ∗ k ∈VALUEXi ,P(Xi) to agent view 29: Xi ← v ∗ i =Choose optimal(agent view) 30: Send VALUEXl , Xi to all Xl ∈C(Xi) that in real world problems the generation of the pseudotree has a significant impact on the actual performance.",
                "The problem of finding the best pseudotree for a given DCOP instance is NP-Hard.",
                "Thus a heuristic is used for generation, and the performance of the algorithm depends on the pseudotree found by the heuristic.",
                "Some previous research focused on finding heuristics to generate good pseudotrees [8].",
                "While we have developed some heuristics that generate good cross-edged pseudotrees for use with DCPOP, our focus has been to use multiple heuristics and then select the best pseudotree from the generated pseudotrees.",
                "We consider only heuristics that run in polynomial time with respect to the number of nodes in the original DCOP instance.",
                "The actual DCPOP algorithm has worst case exponential complexity, but we can calculate the maximum message size, computation size, and sequential path cost for a given cross-edged pseudotree in linear space-time complexity.",
                "To do this, we simply run the algorithm without attempting to calculate any of the local utility hypercubes or optimal value assignments.",
                "Instead, messages include dimensional and branch information but no utility hypercubes.",
                "After each heuristic completes its generation of a pseudotree, we execute the measurement procedure and propagate the measurement information up to the chosen root in that pseudotree.",
                "The root then broadcasts the total complexity for that heuristic to all nodes.",
                "After all heuristics have had a chance to complete, every node knows which heuristic produced the best pseudotree.",
                "Each node then proceeds to begin the DCPOP algorithm using its knowledge of the pseudotree generated by the best heuristic.",
                "The heuristics used to generate traditional pseudotrees perform a distributed DFS traversal.",
                "The general distributed algorithm uses a token passing mechanism and a linear number of messages.",
                "Improved DFS based heuristics use a special procedure to choose the root node, and also provide an ordering function over the neighbors of a node to determine the order of path recursion.",
                "The DFS based heuristics used in our experiments come from the work done in [4, 8]. 5.1 The best-first cross-edged pseudotree heuristic The heuristics used to generate cross-edged pseudotrees perform a best-first traversal.",
                "A general distributed best-first algorithm for node expansion is presented in Algorithm 2.",
                "An evaluation function at each node provides the values that are used to determine the next best node to expand.",
                "Note that in this algorithm each node only exchanges its best value with its neighbors.",
                "In our experiments we used several evaluation functions that took as arguments an ordered list of ancestors and a node, which contains a list of neighbors (with each neighbors placement depth in the tree if it was placed).",
                "From these we can calculate branchparents, branch-children, and unknown relationships for a potential node placement.",
                "The best overall function calculated the value as ancestors−(branchparents+branchchildren) with the number of unknown relationships being a tiebreak.",
                "After completion each node has knowledge of its parent and ancestors, so it can easily determine which connected nodes are pseudo-parents, branchparents, pseudo-children, and branch-children.",
                "The complexity of the best-first traversal depends on the complexity of the evaluation function.",
                "Assuming a complexity of O(V ) for the evaluation function, which is the case for our best overall function, the best-first traversal is O(V · E) which is at worst O(n3 ).",
                "For each v ∈ V we perform a place operation, and find the next node to place using the getBestNeighbor operation.",
                "The place operation is at most O(V ) because of the sent messages.",
                "Finding the next node uses recursion and traverses only already placed The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 745 Algorithm 2 Distributed Best-First Search Algorithm root ← electedleader next(root, ∅) place(node, parent) node.parent ← parent node.ancestors ← parent.ancestors ∪ parent send placement message (node, node.ancestors) to all neighbors of node next(current, previous) if current is not placed then place(current, previous) next(current, ∅) else best ← getBestNeighbor(current, previous) if best = ∅ then if previous = ∅ then terminate, all nodes are placed next(previous, ∅) else next(best, current) getBestNeighbor(current, previous) best ← ∅; score ← 0 for all n ∈ current.neighbors do if n! = previous then if n is placed then nscore ← getBestNeighbor(n, current) else nscore ← evaluate(current, n) if nscore > score then score ← nscore best ← n return best, score nodes, so it has O(V ) recursions.",
                "Each recursion performs a recursive getBestNeighbor operation that traverses all placed nodes and their neighbors.",
                "This operation is O(V · E), but results can be cached using only O(V ) space at each node.",
                "Thus we have O(V ·(V +V +V ·E)) = O(V 2 ·E).",
                "If we are smart about evaluating local changes when each node receives placement messages from its neighbors and cache the results the getBestNeighbor operation is only O(E).",
                "This increases the complexity of the place operation, but for all placements the total complexity is only O(V · E).",
                "Thus we have an overall complexity of O(V ·E+V ·(V +E)) = O(V ·E). 6.",
                "COMPARISON OF COMPLEXITY IN DPOP AND DCPOP We have already shown that given the same input, DCPOP performs the same as DPOP.",
                "We also have shown that we can accurately predict performance of a given pseudotree in linear spacetime complexity.",
                "If we use a constant number of heuristics to generate the set of pseudotrees, we can choose the best pseudotree in linear space-time complexity.",
                "We will now show that there exists a DCOP instance for which a cross-edged pseudotree outperforms all possible traditional pseudotrees (based on edge-traversal heuristics).",
                "In Figure 3(a) we have a DCOP instance with six nodes.",
                "This is a bipartite graph with each partition fully connected to the other (a) (b) (c) Figure 3: (a) The DCOP instance (b) A traditional pseudotree arrangement for the DCOP instance (c) A cross-edged pseudotree arrangement for the DCOP instance partition.",
                "In Figure 3(b) we see a traditional pseudotree arrangement for this DCOP instance.",
                "It is easy to see that any edgetraversal based heuristic cannot expand two nodes from the same partition in succession.",
                "We also see that no node can have more than one child because any such arrangement would be an invalid pseudotree.",
                "Thus any traditional pseudotree arrangement for this DCOP instance must take the form of Figure 3(b).",
                "We can see that the back-edges F-B and F-A overlap node C. Node C also has a parent E, and a back-edge with D. Using the original DPOP algorithm (or DCPOP since they are identical in this case), we find that the computation at node C involves five domains: A, B, C, D, and E. In contrast, the cross-edged pseudotree arrangement in Figure 3(c) requires only a maximum of four domains in any computation during DCPOP.",
                "Since node A is the merge point for branches from both B and C, we can see that each of the nodes D, E, and F have two overlapping branches.",
                "In addition each of these nodes has node A as its parent.",
                "Using the DCPOP algorithm we find that the computation at node D (or E or F) involves four domains: A, B, C, and D (or E or F).",
                "Since no better traditional pseudotree arrangement can be created using an edge-traversal heuristic, we have shown that DCPOP can outperform DPOP even if we use the optimal pseudotree found through edge-traversal.",
                "We acknowledge that pseudotree arrangements that allow parent-child relationships without an actual constraint can solve the problem in Figure 3(a) with maximum computation size of four domains.",
                "However, current heuristics used with DPOP do not produce such pseudotrees, and such a heuristic would be difficult to distribute since each node would require information about nodes with which it has no constraint.",
                "Also, while we do not prove it here, cross-edged pseudotrees can produce smaller message sizes than such pseudotrees even if the computation size is similar.",
                "In practice, since finding the best pseudotree arrangement is NP-Hard, we find that heuristics that produce cross-edged pseudotrees often produce significantly smaller computation and message sizes. 7.",
                "EXPERIMENTAL RESULTS 746 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Existing performance metrics for DCOP algorithms include the total number of messages, synchronous clock cycles, and message size.",
                "We have already shown that the total number of messages is linear with respect to the number of constraints in the DCOP instance.",
                "We also introduced the maximum sequential path cost (PC) as a measurement of the maximum amount of parallelism achievable by the algorithm.",
                "The maximum sequential path cost is equal to the sum of the computations performed on the longest path from the root to any leaf node.",
                "We also include as metrics the maximum computation size in number of dimensions (CD) and maximum message size in number of dimensions (MD).",
                "To analyze the relative complexity of a given DCOP instance, we find the minimum induced width (IW) of any traditional pseudotree produced by a heuristic for the original DPOP. 7.1 Generic DCOP instances For our initial tests we randomly generated two sets of problems with 3000 cases in each.",
                "Each problem was generated by assigning a random number (picked from a range) of constraints to each variable.",
                "The generator then created binary constraints until each variable reached its maximum number of constraints.",
                "The first set uses 20 variables, and the best DPOP IW ranges from 1 to 16 with an average of 8.5.",
                "The second set uses 100 variables, and the best DPOP IW ranged from 2 to 68 with an average of 39.3.",
                "Since most of the problems in the second set were too complex to actually compute the solution, we took measurements of the metrics using the techniques described earlier in Section 5 without actually solving the problem.",
                "Results are shown for the first set in Table 1 and for the second set in Table 2.",
                "For the two problem sets we split the cases into low density and high density categories.",
                "Low density cases consist of those problems that have a best DPOP IW less than or equal to half of the total number of nodes (e.g.",
                "IW ≤ 10 for the 20 node problems and IW ≤ 50 for the 100 node problems).",
                "High density problems consist of the remainder of the problem sets.",
                "In both Table 1 and Table 2 we have listed performance metrics for the original DPOP algorithm, the DCPOP algorithm using only cross-edged pseudotrees (DCPOP-CE), and the DCPOP algorithm using traditional and cross-edged pseudotrees (DCPOP-All).",
                "The pseudotrees used for DPOP were generated using 5 heuristics: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB, and DFS MCN BEC.",
                "These are all versions of the guided DFS traversal discussed in Section 5.",
                "The cross-edged pseudotrees used for DCPOP-CE were generated using 5 heuristics: MCN, LCN, MCN A-B, LCN A-B, and LCSG A-B.",
                "These are all versions of the best-first traversal discussed in Section 5.",
                "For both DPOP and DCPOP-CE we chose the best pseudotree produced by their respective 5 heuristics for each problem in the set.",
                "For DCPOP-All we chose the best pseudotree produced by all 10 heuristics for each problem in the set.",
                "For the CD and MD metrics the value shown is the average number of dimensions.",
                "For the PC metric the value shown is the natural logarithm of the maximum sequential path cost (since the actual value grows exponentially with the complexity of the problem).",
                "The final row in both tables is a measurement of improvement of DCPOP-All over DPOP.",
                "For the CD and MD metrics the value shown is a reduction in number of dimensions.",
                "For the PC metric the value shown is a percentage reduction in the maximum sequential path cost (% = DP OP −DCP OP DCP OP ∗ 100).",
                "Notice that DCPOPAll outperforms DPOP on all metrics.",
                "This logically follows from our earlier assertion that given the same input, DCPOP performs exactly the same as DPOP.",
                "Thus given the choice between the pseudotrees produced by all 10 heuristics, DCPOP-All will always outLow Density High Density Algorithm CD MD PC CD MD PC DPOP 7.81 6.81 3.78 13.34 12.34 5.34 DCPOP-CE 7.94 6.73 3.74 12.83 11.43 5.07 DCPOP-All 7.62 6.49 3.66 12.72 11.36 5.05 Improvement 0.18 0.32 13% 0.62 0.98 36% Table 1: 20 node problems Low Density High Density Algorithm CD MD PC CD MD PC DPOP 33.35 32.35 14.55 58.51 57.50 19.90 DCPOP-CE 33.49 29.17 15.22 57.11 50.03 20.01 DCPOP-All 32.35 29.57 14.10 56.33 51.17 18.84 Improvement 1.00 2.78 104% 2.18 6.33 256% Table 2: 100 node problems Figure 4: Computation Dimension Size Figure 5: Message Dimension Size The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 747 Figure 6: Path Cost DCPOP Improvement Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Table 3: Meeting Scheduling Problems perform DPOP.",
                "Another trend we notice is that the improvement is greater for high density problems than low density problems.",
                "We show this trend in greater detail in Figures 4, 5, and 6.",
                "Notice how the improvement increases as the complexity of the problem increases. 7.2 Meeting Scheduling Problem In addition to our initial generic DCOP tests, we ran a series of tests on the Meeting Scheduling Problem (MSP) as described in [6].",
                "The problem setup includes a number of people that are grouped into departments.",
                "Each person must attend a specified number of meetings.",
                "Meetings can be held within departments or among departments, and can be assigned to one of eight time slots.",
                "The MSP maps to a DCOP instance where each variable represents the time slot that a specific person will attend a specific meeting.",
                "All variables that belong to the same person have mutual exclusion constraints placed so that the person cannot attend more than one meeting during the same time slot.",
                "All variables that belong to the same meeting have equality constraints so that all of the participants choose the same time slot.",
                "Unary constraints are placed on each variable to account for a persons valuation of each meeting and time slot.",
                "For our tests we generated 100 sample problems for each combination of agents and meetings.",
                "Results are shown in Table 3.",
                "The values in the first five columns represent (in left to right order), the total number of agents, the total number of meetings, the total number of variables, the average total number of constraints, and the average minimum IW produced by a traditional pseudotree.",
                "The last three columns show the same metrics we used for the generic DCOP instances, except this time we only show the improvements of DCPOP-All over DPOP.",
                "Performance is better on average for all MSP instances, but again we see larger improvements for more complex problem instances. 8.",
                "CONCLUSIONS AND FUTURE WORK We presented a complete, distributed algorithm that solves general DCOP instances using cross-edged pseudotree arrangements.",
                "Our algorithm extends the DPOP algorithm by adding additional utility propagation messages, and introducing the concept of branch merging during the utility propagation phase.",
                "Our algorithm also allows value assignments to occur at higher level merge points for lower level nodes.",
                "We have shown that DCPOP fully extends DPOP by performing the same operations given the same input.",
                "We have also shown through some examples and experimental data that DCPOP can achieve greater performance for some problem instances by extending the allowable input set to include cross-edged pseudotrees.",
                "We placed particular emphasis on the role that edge-traversal heuristics play in the generation of pseudotrees.",
                "We have shown that the performance penalty is minimal to generate multiple heuristics, and that we can choose the best generated pseudotree in linear space-time complexity.",
                "Given the importance of a good pseudotree for performance, future work will include new heuristics to find better pseudotrees.",
                "Future work will also include adapting existing DPOP extensions [5, 7] that support different problem domains for use with DCPOP. 9.",
                "REFERENCES [1] J. Liu and K. P. Sycara.",
                "Exploiting problem structure for distributed constraint optimization.",
                "In V. Lesser, editor, Proceedings of the First International Conference on Multi-Agent Systems, pages 246-254, San Francisco, CA, 1995.",
                "MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni.",
                "A dynamic distributed constraint satisfaction approach to resource allocation.",
                "Lecture Notes in Computer Science, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe, and M. Yokoo.",
                "An asynchronous complete method for distributed constraint optimization.",
                "In AAMAS 03, 2003. [4] A. Petcu.",
                "Frodo: A framework for open/distributed constraint optimization.",
                "Technical Report No. 2006/001 2006/001, Swiss Federal Institute of Technology (EPFL), Lausanne (Switzerland), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu and B. Faltings.",
                "A-dpop: Approximations in distributed optimization.",
                "In poster in CP 2005, pages 802-806, Sitges, Spain, October 2005. [6] A. Petcu and B. Faltings.",
                "Dpop: A scalable method for multiagent constraint optimization.",
                "In IJCAI 05, pages 266-271, Edinburgh, Scotland, Aug 2005. [7] A. Petcu, B. Faltings, and D. Parkes.",
                "M-dpop: Faithful distributed implementation of efficient social choice problems.",
                "In AAMAS 06, pages 1397-1404, Hakodate, Japan, May 2006. [8] G. Ushakov.",
                "Solving meeting scheduling problems using distributed pseudotree-optimization procedure.",
                "Masters thesis, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "Distributed constraint satisfaction for formalizing distributed problem solving.",
                "In International Conference on Distributed Computing Systems, pages 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "The distributed constraint satisfaction problem: Formalization and algorithms.",
                "Knowledge and Data Engineering, 10(5):673-685, 1998. 748 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "A Complete Distributed Constraint Optimization Method For Non-Traditional Pseudotree Arrangements∗ James Atlas Computer and Information Sciences University of Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Computer and Information Sciences University of Delaware Newark, DE 19716 decker@cis.udel.edu ABSTRACT Distributed Constraint Optimization (DCOP) is a general framework that can model complex problems in <br>multi-agent system</br>s.",
                "With the advent of distributed AI, <br>multi-agent system</br>s became a popular way to model the complex interactions and coordination required to solve distributed problems.",
                "This extension to the original DisCSP approach has become popular in <br>multi-agent system</br>s, and has been labeled the Distributed Constraint Optimization Problem (DCOP) [1]."
            ],
            "translated_annotated_samples": [
                "Un Método Completo de Optimización de Restricciones Distribuidas para Arreglos de Pseudotree No Tradicionales∗ James Atlas Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 decker@cis.udel.edu RESUMEN La Optimización de Restricciones Distribuidas (DCOP) es un marco general que puede modelar problemas complejos en <br>sistemas multiagente</br>.",
                "Con la llegada de la inteligencia artificial distribuida, los <br>sistemas multiagente</br> se convirtieron en una forma popular de modelar las interacciones complejas y la coordinación necesaria para resolver problemas distribuidos.",
                "Esta extensión al enfoque original de DisCSP se ha vuelto popular en <br>sistemas multiagente</br>, y ha sido etiquetada como Problema de Optimización de Restricciones Distribuidas (DCOP) [1]."
            ],
            "translated_text": "Un Método Completo de Optimización de Restricciones Distribuidas para Arreglos de Pseudotree No Tradicionales∗ James Atlas Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 decker@cis.udel.edu RESUMEN La Optimización de Restricciones Distribuidas (DCOP) es un marco general que puede modelar problemas complejos en <br>sistemas multiagente</br>. Varios algoritmos actuales que resuelven instancias generales de DCOP, incluyendo ADOPT y DPOP, organizan a los agentes en una estructura de pseudobosque tradicional. Introducimos una extensión al algoritmo DPOP que maneja un conjunto extendido de disposiciones de pseudobosque. Nuestro algoritmo resuelve correctamente instancias de DCOP para pseudobosques que incluyen aristas entre nodos en ramas separadas. El algoritmo también resuelve instancias con arreglos de pseudobosque tradicionales utilizando el mismo procedimiento que DPOP. Comparamos nuestro algoritmo con DPOP utilizando varios métricos, incluyendo el ancho inducido de los pseudobosques, la dimensionalidad máxima de los mensajes y la computación, y el costo máximo de la ruta secuencial a través del algoritmo. Demostramos que para algunas instancias del problema no es posible generar un pseudoárbol tradicional utilizando heurísticas de recorrido de aristas que supere a un pseudoárbol con aristas cruzadas. Utilizamos múltiples heurísticas para generar pseudoárboles y elegir el mejor pseudoárbol en complejidad espacio-temporal lineal. Para algunas instancias del problema observamos mejoras significativas en los tamaños de los mensajes y cálculos en comparación con DPOP. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Algoritmos 1. INTRODUCCIÓN Muchos problemas históricos en la comunidad de IA pueden transformarse en Problemas de Satisfacción de Restricciones (CSP). Con la llegada de la inteligencia artificial distribuida, los <br>sistemas multiagente</br> se convirtieron en una forma popular de modelar las interacciones complejas y la coordinación necesaria para resolver problemas distribuidos. Los CSPs fueron originalmente extendidos a entornos de agentes distribuidos en [9]. Los primeros dominios para problemas de satisfacción de restricciones distribuidas (DisCSP) incluyeron la programación de talleres de trabajo [1] y la asignación de recursos [2]. Muchos dominios para sistemas de agentes, especialmente coordinación de trabajo en equipo, programación distribuida y redes de sensores, implican problemas excesivamente restringidos que son difíciles o imposibles de satisfacer para cada restricción. Los enfoques recientes para resolver problemas en estos dominios se basan en técnicas de optimización que mapean restricciones en funciones de utilidad multivaluadas. En lugar de encontrar una asignación que satisfaga todas las restricciones, estos enfoques encuentran una asignación que produce un alto nivel de utilidad global. Esta extensión al enfoque original de DisCSP se ha vuelto popular en <br>sistemas multiagente</br>, y ha sido etiquetada como Problema de Optimización de Restricciones Distribuidas (DCOP) [1]. Los algoritmos actuales que resuelven DCOPs completos utilizan dos enfoques principales: búsqueda y programación dinámica. Los algoritmos basados en búsqueda que se originaron a partir de DisCSP típicamente utilizan alguna forma de retroceso [10] o propagación de límites, como en ADOPT [3]. Los algoritmos basados en programación dinámica incluyen DPOP y sus extensiones [5, 6, 7]. Hasta la fecha, ambas categorías de algoritmos organizan agentes en un pseudoárbol tradicional para resolver el problema. Se ha demostrado en [6] que cualquier grafo de restricciones puede ser mapeado en un pseudoárbol tradicional. Sin embargo, también se demostró que encontrar el pseudoárbol óptimo era NP-Difícil. Comenzamos a investigar el rendimiento de los pseudobosques tradicionales generados por las heurísticas actuales de recorrido de aristas. Descubrimos que estas heurísticas a menudo generaban poco paralelismo, ya que los pseudárboles tendían a tener una gran profundidad y bajos factores de ramificación. Sospechábamos que podría haber otras formas de organizar los pseudobosques que proporcionarían un mayor paralelismo y tamaños de mensaje más pequeños. Después de explorar estos otros arreglos, descubrimos que los pseudobosques de bordes cruzados proporcionan profundidades más cortas y factores de ramificación más altos que los pseudobosques tradicionales. Nuestra hipótesis era que estos pseudorboles cruzados superarían a los pseudorboles tradicionales en algunos tipos de problemas. En este artículo presentamos una extensión al algoritmo DPOP que maneja un conjunto ampliado de disposiciones de pseudobosque que incluyen pseudobosques con aristas cruzadas. Comenzamos con una definición de 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, pseudobosques tradicionales y pseudobosques de bordes cruzados. Luego proporcionamos un resumen del algoritmo DPOP original e introducimos nuestro algoritmo DCPOP. Discutimos la complejidad de nuestro algoritmo, así como el impacto de las heurísticas de generación de pseudobosques. Luego demostramos que nuestro Procedimiento de Optimización de Pseudotree de Bordes Cruzados Distribuido (DCPOP) funciona significativamente mejor en la práctica que el algoritmo DPOP original para algunas instancias del problema. Concluimos con una selección de ideas para trabajos futuros y extensiones para DCPOP. 2. La DEFINICIÓN DEL PROBLEMA DCOP ha sido formalizada de maneras ligeramente diferentes en la literatura reciente, por lo que adoptaremos la definición presentada en [6]. Un Problema de Optimización de Restricciones Distribuidas con n nodos y m restricciones consiste en la tupla < X, D, U > donde: • X = {x1,..,xn} es un conjunto de variables, cada una asignada a un agente único • D = {d1,..,dn} es un conjunto de dominios finitos para cada variable • U = {u1,..,um} es un conjunto de funciones de utilidad tales que cada función involucra un subconjunto de variables en X y define una utilidad para cada combinación de valores entre estas variables. Una solución óptima para una instancia de DCOP consiste en una asignación de valores en D a X tal que la suma de las utilidades en U sea máxima. Los dominios de problemas que requieren un costo mínimo en lugar de una utilidad máxima pueden mapear los costos en utilidades negativas. Las funciones de utilidad representan restricciones suaves pero también pueden representar restricciones fuertes mediante el uso de valores negativos arbitrariamente grandes. Para este artículo solo consideramos funciones de utilidad binarias que involucran dos variables. Las funciones de utilidad de orden superior pueden ser modeladas con cambios menores en el algoritmo, pero también aumentan sustancialmente la complejidad. 2.1 Pseudárboles Tradicionales Los pseudárboles son una estructura común utilizada en procedimientos de búsqueda para permitir el procesamiento paralelo de ramas independientes. Como se define en [6], un pseudoárbol es un arreglo de un grafo G en un árbol raíz T de tal manera que los vértices en G que comparten una arista están en la misma rama en T. Una arista de retroceso es una arista entre un nodo X y cualquier nodo que se encuentre en el camino desde X hasta la raíz (excluyendo al padre de X). La Figura 1 muestra un pseudoárbol con cuatro nodos, tres aristas (A-B, B-C, BD) y una arista de retroceso (A-C). También se definen en [6] cuatro tipos de relaciones entre nodos que existen en un pseudoárbol: • P(X) - el padre de un nodo X: el único nodo más alto en el pseudoárbol que está conectado a X directamente a través de un borde de árbol • C(X) - los hijos de un nodo X: el conjunto de nodos más bajos en el pseudo Las líneas sólidas representan relaciones padre-hijo y la línea discontinua representa una relación pseudo-padre-pseudo-hijo. Figura 2: Un pseudoárbol de bordes cruzados. Las líneas sólidas representan relaciones padre-hijo, la línea discontinua representa una relación pseudo-padre-pseudo-hijo, y la línea punteada representa una relación rama-padre-rama-hijo. El nodo en negrita, B, es el punto de fusión para el nodo E. 2.2 Pseudárboles con aristas cruzadas Definimos una arista cruzada como una arista de un nodo X a un nodo Y que está por encima de X pero no en el camino desde X hasta la raíz. Un pseudoárbol de bordes cruzados es un pseudoárbol tradicional con la adición de bordes cruzados. La Figura 2 muestra un pseudoárbol con una arista cruzada (D-E). En un pseudoárbol de bordes cruzados designamos ciertos bordes como primarios. El conjunto de aristas primarias define un árbol de expansión de los nodos. Las relaciones de padre, hijo, pseudo-padre y pseudo-hijo del pseudotree tradicional ahora están definidas en el contexto de este árbol de expansión de borde primario. Esta definición también produce dos tipos adicionales de relaciones que pueden existir entre nodos: • BP(X) - los nodos padres de rama de un nodo X: el conjunto de nodos más altos en el pseudoárbol que están conectados a X pero no están en el camino principal desde X hasta la raíz (En la Figura 2, D = BP(E)) • BC(X) - los nodos hijos de rama de un nodo X: el conjunto de nodos más bajos en el pseudo La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Los algoritmos actuales suelen tener una fase de pre-ejecución para generar un pseudoárbol tradicional a partir de una instancia general de DCOP. Nuestro algoritmo DCPOP genera un pseudoárbol de bordes cruzados de la misma manera. Primero, la instancia DCOP < X, D, U > se traduce directamente en un grafo con X como el conjunto de vértices y una arista para cada par de variables representadas en U. A continuación, se utilizan varias heurísticas para organizar este grafo en un pseudoárbol. Un heurístico común es realizar una búsqueda en profundidad guiada (DFS, por sus siglas en inglés) ya que el recorrido resultante es un pseudoárbol, y un DFS se puede realizar fácilmente de manera distribuida. Definimos un método basado en el recorrido de aristas como cualquier método que produce un pseudoárbol en el que todos los pares padre/hijo comparten una arista en el grafo original. Esto incluye recorridos basados en DFS, búsqueda en anchura y búsqueda de mejor primero. Nuestras heurísticas que generan pseudobosques de bordes cruzados utilizan un recorrido de búsqueda mejor primero distribuido. 3. ALGORITMO DPOP El algoritmo DPOP original opera en tres fases principales. La primera fase genera un pseudoárbol tradicional a partir de la instancia de DCOP utilizando un algoritmo distribuido. La segunda fase une hipercubos de utilidad de los nodos hijos y el nodo local y los propaga hacia la raíz. La tercera fase elige una asignación para cada dominio de arriba hacia abajo, comenzando con el agente en el nodo raíz. La complejidad de DPOP depende del tamaño del cálculo más grande y del mensaje de utilidad durante la fase dos. Se ha demostrado que este tamaño corresponde directamente al ancho inducido del pseudoárbol generado en la fase uno [6]. DPOP utiliza heurísticas de tiempo polinómico para generar el pseudoárbol, ya que encontrar el pseudoárbol de ancho inducido mínimo es NP-duro. Se han desarrollado varias heurísticas de recorrido de borde distribuido para encontrar pseudobosques de ancho reducido [8]. Al final de la primera fase, cada agente conoce a su padre, hijos, pseudo-padres y pseudo-hijos. 3.1 Propagación de utilidad Los agentes ubicados en los nodos hoja del pseudoárbol comienzan el proceso calculando un hipercubo de utilidad local. Este hipercubo en el nodo X contiene las utilidades sumadas para cada combinación de valores en los dominios de P(X) y PP(X). Este hipercubo tiene un tamaño dimensional igual al número de pseudo-padres más uno. Un mensaje que contiene este hipercubo se envía a P(X). Los agentes ubicados en nodos no hoja esperan a que lleguen todos los mensajes de los nodos hijos. Una vez que el agente en el nodo Y tiene todos los mensajes de utilidad, calcula su hipercubo de utilidad local que incluye los dominios de P(Y), PP(Y) y Y. El hipercubo de utilidad local se une luego con todos los hipercubos de los mensajes hijos. En este punto, todas las utilidades que involucran al nodo Y son conocidas, y el dominio de Y puede ser eliminado de forma segura del hipercubo unido. Este proceso de eliminación elige la mejor utilidad sobre el dominio de Y para cada combinación de los dominios restantes. Un mensaje que contiene este hipercubo se envía ahora a P(Y). El tamaño dimensional de este hipercubo depende del número de dominios superpuestos en los mensajes recibidos y del hipercubo de utilidad local. Esta fase de propagación basada en programación dinámica continúa hasta que el agente en el nodo raíz del pseudoárbol haya recibido todos los mensajes de sus hijos. 3.2 Propagación de Valor La propagación de valor comienza cuando el agente en el nodo raíz Z ha recibido todos los mensajes de sus hijos. Dado que Z no tiene padres ni pseudo-padres, simplemente combina los hipercubos de utilidad recibidos de sus hijos. El hipercubo combinado contiene solo valores para el dominio de Z. En este punto, el agente en el nodo Z simplemente elige la asignación para su dominio que tiene la mejor utilidad. Un mensaje de propagación de valor con esta asignación se envía a cada nodo en C(Z). Cada nodo luego recibe un mensaje de propagación de valor de su padre y elige la asignación para su dominio que tenga la mejor utilidad dadas las asignaciones recibidas en el mensaje. El nodo agrega su asignación de dominio a las asignaciones que recibió y pasa el conjunto de asignaciones a sus hijos. El algoritmo está completo cuando todos los nodos han elegido una asignación para su dominio. ALGORITMO DCPOP Nuestra extensión al algoritmo DPOP original, mostrada en el Algoritmo 1, comparte las mismas tres fases. La primera fase genera el pseudoárbol de bordes cruzados para la instancia de DCOP. La segunda fase fusiona ramas y propaga los hipercubos de utilidad. La tercera fase elige asignaciones para dominios en los puntos de fusión de ramas y de arriba hacia abajo, comenzando con el agente en el nodo raíz. Para la primera fase generamos un pseudoárbol utilizando varios heurísticos distribuidos y seleccionamos el que tenga la menor complejidad general. La complejidad de la computación y el tamaño del mensaje de utilidad en DCPOP no corresponden directamente al ancho inducido del pseudoárbol de aristas cruzadas. En cambio, utilizamos un método de tiempo polinómico para calcular el tamaño máximo de computación y utilidad del mensaje para un pseudoárbol de bordes cruzados dado. Una descripción de este método y el proceso de selección de pseudodendrogramas aparece en la Sección 5. Al final de la primera fase, cada agente conoce a su padre, hijos, pseudo-padres, pseudo-hijos, padres de rama e hijos de rama. 4.1 Fusión de Ramas y Propagación de Utilidad En el algoritmo DPOP original, un nodo X solo tenía funciones de utilidad que involucraban a su padre y a sus pseudo-padres. En DCPOP, se permite que un nodo X tenga una función de utilidad que involucre a un padre de rama. El concepto de una rama se puede ver en la Figura 2 con el nodo E representando nuestro nodo X. Las dos rutas distintas desde el nodo E hasta el nodo B se llaman ramas de E. El único nodo donde se encuentran todas las ramas de E es el nodo B, que se llama punto de fusión de E. Los agentes con nodos que tienen padres de rama comienzan enviando un mensaje de propagación de utilidad a cada padre de rama. Este mensaje incluye un hipercubo de utilidad bidimensional con dominios para el nodo X y el nodo padre de la rama BP(X). También incluye una estructura de información de rama que contiene el nodo de origen de la rama, X, el número total de ramas que se originan en X y el número de ramas que se originan en X y se fusionan en una representación única por esta estructura de información de rama (este número comienza en 1). Intuitivamente, cuando el número de ramas fusionadas es igual al número total de ramas originales, el algoritmo ha alcanzado el punto de fusión para X. En la Figura 2, el nodo E envía un mensaje de propagación de utilidad a su nodo padre de rama, el nodo D. Este mensaje tiene dimensiones para los dominios de E y D, e incluye información de rama con un origen en E, 2 ramas totales y 1 rama fusionada. Como en la fase de propagación de utilidad de la utilidad DPOP original, un agente en el nodo hoja X envía un mensaje de propagación de utilidad a su padre. En DCPOP, este mensaje contiene dimensiones para los dominios de P(X) y PP(X). Si el nodo X también tiene padres de rama, entonces el mensaje de propagación de utilidad también contiene una dimensión para el dominio de X e incluirá una estructura de información de rama. En la Figura 2, el nodo E envía un mensaje de propagación de utilidad a su padre, el nodo C. Este mensaje tiene dimensiones para los dominios de E y C, e incluye información de rama con un origen en E, 2 ramas en total y 1 rama fusionada. Cuando un nodo Y recibe mensajes de propagación de utilidad de todos de The Sixth Intl. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), 743 sus hijos y sus hijos de rama, fusiona cualquier rama con el mismo nodo de origen X. La estructura de información de la rama fusionada acumula el número de ramas fusionadas para X. Si el número total acumulado de ramas fusionadas es igual al número total de ramas, entonces Y es el punto de fusión para X. Esto significa que los hipercubos de utilidad presentes en Y contienen toda la información sobre las valoraciones de las funciones de utilidad que involucran al nodo X. Además de la eliminación típica del dominio de Y de los hipercubos de utilidad, ahora podemos eliminar de forma segura el dominio de X de los hipercubos de utilidad. Para ilustrar este proceso, examinaremos lo que sucede en la segunda fase para el nodo B en la Figura 2. En la segunda fase, el Nodo B recibe dos mensajes de propagación de utilidad. El primero proviene del nodo C e incluye dimensiones para los dominios E, B y A. También tiene una estructura de información de ramas con origen en E, 2 ramas en total y 1 rama fusionada. El segundo proviene del nodo D e incluye dimensiones para los dominios E y B. También tiene una estructura de información de rama con origen en E, 2 ramas en total y 1 rama fusionada. El nodo B luego fusiona las estructuras de información de rama de ambos mensajes porque tienen la misma procedencia, el nodo E. Dado que el número de ramas fusionadas que provienen de E es ahora 2 y el total de ramas que provienen de E es 2, el nodo B elimina las dimensiones para el dominio E. El nodo B también elimina la dimensión para su propio dominio, dejando solo información sobre el dominio A. Luego, el nodo B envía un mensaje de propagación de utilidad al nodo A, que contiene solo una dimensión para el dominio de A. Aunque no sea posible en DPOP, este método de propagación de utilidad y eliminación de dimensiones puede producir hipercubos en el nodo Y que no comparten ningún dominio. En DCPOP no unimos hipercubos independientes de dominio, sino que en su lugar podemos enviar múltiples hipercubos en el mensaje de propagación de utilidad enviado al padre de Y. Este enfoque perezoso de las uniones ayuda a reducir el tamaño de los mensajes. 4.2 Propagación de valores Al igual que en DPOP, la propagación de valores comienza cuando el agente en el nodo raíz Z ha recibido todos los mensajes de sus hijos. En este punto, el agente en el nodo Z elige la asignación para su dominio que tiene la mejor utilidad. Si Z es el punto de fusión de las ramas de algún nodo X, Z también elegirá la asignación para el dominio de X. Por lo tanto, cualquier nodo que sea un punto de fusión elegirá asignaciones para un dominio que no sea el suyo propio. Estas tareas luego se pasan por la jerarquía de la cadena de mando principal. Si el nodo X en la jerarquía tiene padres de rama, entonces el mensaje de asignación de valor de P(X) contendrá una asignación para el dominio de X. Cada nodo en la jerarquía agrega cualquier tarea que haya elegido a las que recibió y pasa el conjunto de tareas a sus hijos. El algoritmo está completo cuando todos los nodos han elegido o recibido una asignación para su dominio. 4.3 Prueba de Corrección Demostraremos la corrección de DCPOP notando primero que DCPOP extiende completamente DPOP y luego examinando los dos casos para la asignación de valores en DCPOP. Dado un pseudoárbol tradicional como entrada, la ejecución del algoritmo DCPOP es idéntica a DPOP. Usando un arreglo de pseudodendrograma tradicional, ningún nodo tiene padres de rama o hijos de rama, ya que todas las aristas son aristas de retroceso o aristas de árbol. Por lo tanto, el algoritmo DCPOP utilizando un pseudoárbol tradicional envía solo mensajes de propagación de utilidad que contienen dominios pertenecientes al padre o pseudo-padres de un nodo. Dado que ningún nodo tiene ramas-padres, no existen ramas, y por lo tanto ningún nodo sirve como punto de fusión para ningún otro nodo. Por lo tanto, todas las asignaciones de propagación de valor se eligen en el nodo del dominio de la asignación. Para la ejecución de DCPOP con pseudárboles de bordes cruzados, algunos nodos actúan como puntos de fusión. Observamos que cualquier nodo X que no sea un punto de fusión asigna su valor exactamente como en DPOP. El hipercubo de utilidad local en X contiene dominios para X, P(X), PP(X) y BC(X). Como en DPOP, el mensaje de asignación de valores recibido en X incluye los valores asignados a P(X) y PP(X). Además, dado que X no es un punto de fusión, todas las asignaciones a BC(X) deben haber sido calculadas en puntos de fusión más altos en el árbol y están en el mensaje de asignación de valor de P(X). Por lo tanto, después de eliminar los dominios para los cuales se conocen las asignaciones, solo queda el dominio de X. El agente en el nodo X ahora puede elegir correctamente la asignación con la máxima utilidad para su propio dominio. Si el nodo X es un punto de fusión para alguna rama-hijo Y, sabemos que X debe ser un nodo a lo largo del camino desde Y hasta la raíz, y desde P(Y) y todos los BP(Y) hasta la raíz. A partir del algoritmo, sabemos que Y necesariamente tiene toda la información de C(Y), PC(Y) y BC(Y) ya que espera sus mensajes. El nodo X tiene información sobre todos los nodos debajo de él en el árbol, lo cual incluiría a Y, P(Y), BP(Y) y aquellos PP(Y) que están debajo de X en el árbol. Para cualquier PP(Y) por encima de X en el árbol, X recibe la asignación para el dominio de PP(Y) en el mensaje de asignación de valor de P(X). Por lo tanto, X tiene información de utilidad sobre todas las funciones de utilidad de las cuales Y forma parte. Al eliminar los dominios incluidos en el mensaje de asignación de valor, el nodo X se queda con un hipercubo de utilidad local con dominios para X e Y. El agente en el nodo X ahora puede elegir correctamente las asignaciones con la máxima utilidad para los dominios de X e Y. 4.4 Análisis de complejidad La primera fase de DCPOP envía un mensaje a cada P(X), PP(X) y BP(X). La segunda fase envía un mensaje de asignación de valor a cada C(X). Por lo tanto, DCPOP produce un número lineal de mensajes con respecto al número de aristas (funciones de utilidad) en el pseudoárbol de aristas cruzadas y la instancia original de DCOP. La complejidad real de DCPOP depende de dos medidas adicionales: el tamaño del mensaje y el tamaño de la computación. El tamaño del mensaje y el tamaño de la computación en DCPOP dependen del número de ramas superpuestas, así como del número de aristas de retroceso superpuestas. Se demostró en [6] que el número de aristas traslapadas es igual al ancho inducido del pseudoárbol. En un pseudoárbol de bordes cruzados mal construido, el número de ramas superpuestas en el nodo X puede ser tan grande como el número total de descendientes de X. Por lo tanto, el tamaño total del mensaje en DCPOP en una instancia mal construida puede ser exponencial en el espacio en el número total de nodos en el grafo. Sin embargo, en la práctica, un pseudoárbol bien construido con bordes cruzados puede lograr resultados mucho mejores. Más tarde abordaremos el tema de elegir pseudobosques cruzados bien construidos de un conjunto. Introducimos una medida adicional del costo máximo de la ruta secuencial a través del algoritmo. Esta medida se relaciona directamente con la cantidad máxima de paralelismo que puede lograr el algoritmo. Para tomar esta medida, primero almacenamos el tamaño total de cálculo para cada nodo durante las fases dos y tres. Este tamaño de cálculo representa el número de accesos individuales a un valor en un hipercubo en cada nodo. Por ejemplo, una unión entre dos dominios de tamaño 4 cuesta 4 ∗ 4 = 16. Dos grafos acíclicos dirigidos (DAG) pueden ser dibujados; uno con los mensajes de propagación de utilidad como aristas y los costos de la fase dos en los nodos, y el otro con los mensajes de asignación de valor y los costos de la fase tres en los nodos. El costo máximo del camino secuencial es igual a la suma del camino más largo en cada DAG desde la raíz hasta cualquier nodo hoja. HEURÍSTICAS En nuestra evaluación de la complejidad en DCPOP nos enfocamos en el peor caso posiblemente producido por el algoritmo. Reconocemos 744 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Algoritmo 1 DCPOP Algoritmo 1: DCPOP(X; D; U) Cada agente Xi ejecuta: Fase 1: creación de pseudotree 2: elegir líder de todos los Xj ∈ X 3: líder elegido inicia la creación de pseudotree 4: después, Xi conoce P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) y PC(Xi) Fase 2: propagación de mensajes UTIL 5: si |BP(Xi)| > 0 entonces 6: BRANCHXi ← |BP(Xi)| + 1 7: para todos Xk ∈BP(Xi) hacer 8: UTILXi (Xk) ← Calcular utils(Xi, Xk) 9: Enviar mensaje(Xk,UTILXi (Xk),BRANCHXi ) 10: si |C(Xi)| = 0 (es decir, Si Xi es un nodo hoja, entonces 11: UTILXi (P(Xi)) ← Calcular utils(P(Xi),PP(Xi)) para todos los PP(Xi) 12: Enviar mensaje(P(Xi), UTILXi (P(Xi)), BRANCHXi ) 13: Enviar mensaje(PP(Xi), UTIL vacío, BRANCH vacío) a todos los PP(Xi) 14: Activar el manejador de mensajes UTIL() Fase 3: Propagación de mensajes de VALOR 15: Activar el manejador de mensajes de VALOR() FIN ALGORITMO Manejador de mensajes UTIL(Xk, UTILXk (Xi), BRANCHXk ) 16: Almacenar UTILXk (Xi), BRANCHXk (Xi) 17: Si han llegado mensajes UTIL de todos los hijos y los hijos de la rama, entonces 18: Para todos los Bj ∈ BRANCH(Xi) hacer 19: Si Bj está fusionado, entonces 20: Unir todos los hipercubos donde Bj ∈ UTIL(Xi) 21: Eliminar Bj del hipercubo unido 22: Si P(Xi) == nulo (eso significa que Xi es la raíz) entonces 23: v ∗ i ← Elegir óptimo(nulo) 24: Enviar VALOR(Xi, v ∗ i) a todos los C(Xi) 25: De lo contrario 26: UTILXi (P(Xi)) ← Calcular utils(P(Xi), PP(Xi)) 27: Enviar mensaje(P(Xi), UTILXi (P(Xi)), BRANCHXi (P(Xi))) Manejador de mensajes de VALOR(VALORXi , P(Xi)) 28: Agregar todos los Xk ← v ∗ k ∈ VALORXi , P(Xi) a la vista del agente 29: Xi ← v ∗ i = Elegir óptimo(vista del agente) 30: Enviar VALORXl , Xi a todos los Xl ∈ C(Xi) que en problemas del mundo real la generación del pseudoárbol tiene un impacto significativo en el rendimiento real. El problema de encontrar la mejor pseudotree para una instancia de DCOP dada es NP-Difícil. Por lo tanto, se utiliza una heurística para la generación, y el rendimiento del algoritmo depende del pseudoárbol encontrado por la heurística. Algunas investigaciones previas se centraron en encontrar heurísticas para generar buenas pseudorboles [8]. Si bien hemos desarrollado algunas heurísticas que generan buenos pseudoárboles cruzados para usar con DCPOP, nuestro enfoque ha sido utilizar múltiples heurísticas y luego seleccionar el mejor pseudo Consideramos solo heurísticas que se ejecuten en tiempo polinómico con respecto al número de nodos en la instancia original del DCOP. El algoritmo DCPOP actual tiene una complejidad exponencial en el peor de los casos, pero podemos calcular el tamaño máximo del mensaje, el tamaño de la computación y el costo de la ruta secuencial para un pseudoárbol de bordes cruzados dado en complejidad espacio-temporal lineal. Para hacer esto, simplemente ejecutamos el algoritmo sin intentar calcular ninguno de los hipercubos de utilidad local o asignaciones de valor óptimo. En cambio, los mensajes incluyen información dimensional y de ramificación pero no hipercubos de utilidad. Después de que cada heurística complete la generación de un pseudoárbol, ejecutamos el procedimiento de medición y propagamos la información de la medición hasta la raíz elegida en ese pseudo La raíz luego transmite la complejidad total de esa heurística a todos los nodos. Después de que todas las heurísticas hayan tenido la oportunidad de completarse, cada nodo sabe qué heurística produjo el mejor pseudoárbol. Cada nodo luego procede a comenzar el algoritmo DCPOP utilizando su conocimiento del pseudoárbol generado por la mejor heurística. Las heurísticas utilizadas para generar pseudárboles tradicionales realizan un recorrido DFS distribuido. El algoritmo distribuido general utiliza un mecanismo de paso de token y un número lineal de mensajes. Las heurísticas mejoradas basadas en DFS utilizan un procedimiento especial para elegir el nodo raíz, y también proporcionan una función de ordenación sobre los vecinos de un nodo para determinar el orden de la recursión de caminos. Las heurísticas basadas en DFS utilizadas en nuestros experimentos provienen del trabajo realizado en [4, 8]. 5.1 La heurística de pseudotree cruzado de mejor primer recorrido. Las heurísticas utilizadas para generar pseudárboles cruzados realizan un recorrido de mejor primer recorrido. Se presenta un algoritmo general distribuido de mejor primero para la expansión de nodos en el Algoritmo 2. Una función de evaluación en cada nodo proporciona los valores que se utilizan para determinar el siguiente mejor nodo a expandir. Ten en cuenta que en este algoritmo cada nodo solo intercambia su mejor valor con sus vecinos. En nuestros experimentos utilizamos varias funciones de evaluación que tomaban como argumentos una lista ordenada de ancestros y un nodo, que contiene una lista de vecinos (con la profundidad de colocación de cada vecino en el árbol). A partir de estos podemos calcular los padres de la rama, los hijos de la rama y las relaciones desconocidas para una posible ubicación del nodo. La mejor función general calculó el valor como ancestros - (padres de rama + hijos de rama) con el número de relaciones desconocidas como criterio de desempate. Después de completarse, cada nodo tiene conocimiento de su padre y ancestros, por lo que puede determinar fácilmente qué nodos conectados son pseudo-padres, padres de rama, pseudo-hijos e hijos de rama. La complejidad de la travesía de mejor primero depende de la complejidad de la función de evaluación. Suponiendo una complejidad de O(V) para la función de evaluación, que es el caso de nuestra mejor función general, el recorrido de mejor primero es O(V · E), lo que en el peor de los casos es O(n3). Para cada v ∈ V realizamos una operación de colocación y encontramos el siguiente nodo a colocar usando la operación getBestNeighbor. La complejidad de la operación del lugar es a lo sumo O(V) debido a los mensajes enviados. Encontrar el siguiente nodo utiliza recursión y recorre solo los ya colocados The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 745 Algoritmo 2 Algoritmo de Búsqueda Distribuida de Mejor Primero root ← líder elegido next(root, ∅) place(nodo, padre) nodo.padre ← padre nodo.ancestros ← padre.ancestros ∪ padre enviar mensaje de ubicación (nodo, nodo.ancestros) a todos los vecinos de nodo next(actual, anterior) si actual no está ubicado entonces place(actual, anterior) next(actual, ∅) else mejor ← obtenerMejorVecino(actual, anterior) si mejor = ∅ entonces si anterior = ∅ entonces terminar, todos los nodos están ubicados next(anterior, ∅) else next(mejor, actual) obtenerMejorVecino(actual, anterior) mejor ← ∅; puntaje ← 0 para todo n ∈ vecinos de actual hacer si n! = anterior entonces si n está ubicado entonces puntajeN ← obtenerMejorVecino(n, actual) else puntajeN ← evaluar(actual, n) si puntajeN > puntaje entonces puntaje ← puntajeN mejor ← n return mejor, puntaje nodos, por lo que tiene O(V) recursiones. Cada recursión realiza una operación recursiva getBestNeighbor que recorre todos los nodos colocados y sus vecinos. Esta operación es O(V · E), pero los resultados se pueden almacenar en caché utilizando solo O(V) espacio en cada nodo. Así que tenemos O(V ·(V +V +V ·E)) = O(V 2 ·E). Si somos inteligentes al evaluar los cambios locales cuando cada nodo recibe mensajes de ubicación de sus vecinos y almacenamos en caché los resultados, la operación getBestNeighbor es solo O(E). Esto aumenta la complejidad de la operación de ubicación, pero para todas las ubicaciones la complejidad total es solo O(V · E). Por lo tanto, tenemos una complejidad general de O(V ·E+V ·(V +E)) = O(V ·E). 6. COMPARACIÓN DE COMPLEJIDAD EN DPOP Y DCPOP Ya hemos demostrado que, dado el mismo input, DCPOP se desempeña igual que DPOP. También hemos demostrado que podemos predecir con precisión el rendimiento de un pseudoárbol dado en complejidad temporal lineal. Si usamos un número constante de heurísticas para generar el conjunto de pseudobosques, podemos elegir el mejor pseudobosque con complejidad lineal en espacio y tiempo. Ahora demostraremos que existe una instancia de DCOP para la cual un pseudoárbol de bordes cruzados supera a todos los posibles pseudoárboles tradicionales (basados en heurísticas de recorrido de bordes). En la Figura 3(a) tenemos una instancia de DCOP con seis nodos. Este es un grafo bipartito con cada partición completamente conectada a la otra (a) (b) (c) Figura 3: (a) La instancia de DCOP (b) Un arreglo de pseudobosque tradicional para la instancia de DCOP (c) Un arreglo de pseudobosque con aristas cruzadas para la partición de la instancia de DCOP. En la Figura 3(b) vemos un arreglo tradicional de pseudotree para esta instancia de DCOP. Es fácil ver que cualquier heurística basada en el recorrido de aristas no puede expandir dos nodos de la misma partición sucesivamente. También observamos que ningún nodo puede tener más de un hijo porque cualquier disposición de este tipo sería un pseudoárbol inválido. Por lo tanto, cualquier disposición tradicional de pseudodendrograma para esta instancia de DCOP debe tener la forma de la Figura 3(b). Podemos ver que las aristas de retroceso F-B y F-A se superponen al nodo C. El nodo C también tiene un padre E y una arista de retroceso con D. Utilizando el algoritmo DPOP original (o DCPOP ya que son idénticos en este caso), encontramos que el cálculo en el nodo C implica cinco dominios: A, B, C, D y E. En contraste, el arreglo de pseudonodos con aristas cruzadas en la Figura 3(c) requiere un máximo de cuatro dominios en cualquier cálculo durante DCPOP. Dado que el nodo A es el punto de fusión de las ramas tanto de B como de C, podemos ver que cada uno de los nodos D, E y F tiene dos ramas superpuestas. Además, cada uno de estos nodos tiene al nodo A como su padre. Usando el algoritmo DCPOP, encontramos que el cálculo en el nodo D (o E o F) implica cuatro dominios: A, B, C y D (o E o F). Dado que no se puede crear una disposición de pseudobosque tradicional mejor utilizando una heurística de recorrido de aristas, hemos demostrado que DCPOP puede superar a DPOP incluso si utilizamos el pseudobosque óptimo encontrado a través del recorrido de aristas. Reconocemos que los arreglos de pseudodistribución de árboles que permiten relaciones padre-hijo sin una restricción real pueden resolver el problema en la Figura 3(a) con un tamaño de cálculo máximo de cuatro dominios. Sin embargo, las heurísticas actuales utilizadas con DPOP no producen tales pseudobosques, y sería difícil distribuir una heurística así, ya que cada nodo requeriría información sobre nodos con los que no tiene restricciones. Además, aunque no lo demostramos aquí, los pseudobosques de bordes cruzados pueden producir tamaños de mensaje más pequeños que tales pseudobosques, incluso si el tamaño de la computación es similar. En la práctica, dado que encontrar la mejor disposición de pseudoramas es NP-Difícil, observamos que las heurísticas que producen pseudoramas con aristas cruzadas a menudo generan tamaños de cálculo y mensajes significativamente más pequeños. 7. RESULTADOS EXPERIMENTALES 746 El Sexto Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Los métricos de rendimiento existentes para algoritmos DCOP incluyen el número total de mensajes, ciclos de reloj síncronos y tamaño de mensaje. Ya hemos demostrado que el número total de mensajes es lineal con respecto al número de restricciones en la instancia de DCOP. También introdujimos el costo de camino secuencial máximo (PC) como una medida de la máxima cantidad de paralelismo alcanzable por el algoritmo. El costo máximo de la ruta secuencial es igual a la suma de los cálculos realizados en la ruta más larga desde la raíz hasta cualquier nodo hoja. También incluimos como métricas el tamaño máximo de cálculo en número de dimensiones (CD) y el tamaño máximo de mensaje en número de dimensiones (MD). Para analizar la complejidad relativa de una instancia DCOP dada, encontramos el ancho inducido mínimo (IW) de cualquier pseudobosque tradicional producido por una heurística para el DPOP original. 7.1 Instancias genéricas de DCOP Para nuestras pruebas iniciales generamos aleatoriamente dos conjuntos de problemas con 3000 casos en cada uno. Cada problema fue generado asignando un número aleatorio (elegido de un rango) de restricciones a cada variable. El generador luego creó restricciones binarias hasta que cada variable alcanzó su número máximo de restricciones. El primer conjunto utiliza 20 variables, y el mejor DPOP IW varía de 1 a 16 con un promedio de 8.5. El segundo conjunto utiliza 100 variables, y el mejor DPOP IW osciló entre 2 y 68 con un promedio de 39.3. Dado que la mayoría de los problemas en el segundo conjunto eran demasiado complejos para calcular la solución, tomamos medidas de las métricas utilizando las técnicas descritas anteriormente en la Sección 5 sin resolver realmente el problema. Los resultados se muestran para el primer conjunto en la Tabla 1 y para el segundo conjunto en la Tabla 2. Para los dos conjuntos de problemas dividimos los casos en categorías de baja densidad y alta densidad. Los casos de baja densidad consisten en aquellos problemas que tienen un mejor DPOP IW menor o igual a la mitad del número total de nodos (por ejemplo, IW ≤ 10 para los problemas de 20 nodos e IW ≤ 50 para los problemas de 100 nodos. Los problemas de alta densidad consisten en el resto de los conjuntos de problemas. En ambas Tabla 1 y Tabla 2 hemos enumerado las métricas de rendimiento para el algoritmo DPOP original, el algoritmo DCPOP utilizando solo pseudobosques de bordes cruzados (DCPOP-CE), y el algoritmo DCPOP utilizando pseudobosques tradicionales y de bordes cruzados (DCPOP-All). Los pseudobosques utilizados para DPOP fueron generados utilizando 5 heurísticas: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB y DFS MCN BEC. Estas son todas las versiones del recorrido DFS guiado discutidas en la Sección 5. Los pseudobosques de bordes cruzados utilizados para DCPOP-CE fueron generados utilizando 5 heurísticas: MCN, LCN, MCN A-B, LCN A-B y LCSG A-B. Estas son todas las versiones del recorrido de mejor primero discutidas en la Sección 5. Para tanto DPOP como DCPOP-CE elegimos el mejor pseudoárbol producido por sus respectivas 5 heurísticas para cada problema en el conjunto. Para DCPOP-All elegimos la mejor pseudotree producida por las 10 heurísticas para cada problema en el conjunto. Para las métricas de CD y MD, el valor mostrado es el número promedio de dimensiones. Para la métrica de PC, el valor mostrado es el logaritmo natural del costo de ruta secuencial máximo (ya que el valor real crece exponencialmente con la complejidad del problema). La última fila en ambas tablas es una medida de mejora de DCPOP-All sobre DPOP. Para las métricas CD y MD, el valor mostrado es una reducción en el número de dimensiones. Para la métrica de PC, el valor mostrado es una reducción porcentual en el costo máximo de la ruta secuencial (% = DP OP −DCP OP DCP OP ∗ 100). Observa que DCPOP supera a DPOP en todas las métricas. Esto se sigue lógicamente de nuestra afirmación anterior de que, dada la misma entrada, DCPOP se comporta exactamente igual que DPOP. Así, dada la elección entre los pseudobosques producidos por las 10 heurísticas, DCPOP-All siempre superará a DCPOP-CE y DPOP. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 6: Mejora del Costo del Camino DCPOP Reunión Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Tabla 3: Problemas de Programación de Reuniones realizan DPOP. Otra tendencia que observamos es que la mejora es mayor para problemas de alta densidad que para problemas de baja densidad. Mostramos esta tendencia con mayor detalle en las Figuras 4, 5 y 6. Observa cómo la mejora aumenta a medida que aumenta la complejidad del problema. 7.2 Problema de Programación de Reuniones Además de nuestras pruebas genéricas iniciales de DCOP, realizamos una serie de pruebas en el Problema de Programación de Reuniones (MSP) como se describe en [6]. La configuración del problema incluye un número de personas agrupadas en departamentos. Cada persona debe asistir a un número específico de reuniones. Las reuniones pueden llevarse a cabo dentro de los departamentos o entre departamentos, y pueden asignarse a uno de los ocho horarios disponibles. El MSP se mapea a una instancia de DCOP donde cada variable representa el intervalo de tiempo en el que una persona específica asistirá a una reunión específica. Todas las variables que pertenecen a la misma persona tienen restricciones de exclusión mutua para que la persona no pueda asistir a más de una reunión durante el mismo intervalo de tiempo. Todas las variables que pertenecen a la misma reunión tienen restricciones de igualdad para que todos los participantes elijan el mismo horario. Se imponen restricciones unarias en cada variable para tener en cuenta la valoración de una persona de cada reunión y franja horaria. Para nuestros tests generamos 100 problemas de muestra para cada combinación de agentes y reuniones. Los resultados se muestran en la Tabla 3. Los valores en las primeras cinco columnas representan (en orden de izquierda a derecha), el número total de agentes, el número total de reuniones, el número total de variables, el promedio total de restricciones y el promedio mínimo de IW producido por un pseudoárbol tradicional. Las últimas tres columnas muestran las mismas métricas que utilizamos para las instancias genéricas de DCOP, excepto que esta vez solo mostramos las mejoras de DCPOP-All sobre DPOP. El rendimiento es mejor en promedio para todas las instancias de MSP, pero nuevamente vemos mejoras más grandes para instancias de problemas más complejos. 8. CONCLUSIONES Y TRABAJO FUTURO Presentamos un algoritmo completo y distribuido que resuelve instancias generales de DCOP utilizando arreglos de pseudoramas cruzados. Nuestro algoritmo extiende el algoritmo DPOP al agregar mensajes adicionales de propagación de utilidad e introducir el concepto de fusión de ramas durante la fase de propagación de utilidad. Nuestro algoritmo también permite que las asignaciones de valor ocurran en puntos de fusión de nivel superior para nodos de nivel inferior. Hemos demostrado que DCPOP extiende completamente DPOP al realizar las mismas operaciones dadas las mismas entradas. También hemos demostrado a través de algunos ejemplos y datos experimentales que DCPOP puede lograr un mejor rendimiento para algunas instancias del problema al extender el conjunto de entrada permitido para incluir pseudobosques cruzados. Damos especial énfasis al papel que desempeñan las heurísticas de recorrido de bordes en la generación de pseudobosques. Hemos demostrado que la penalización en el rendimiento es mínima para generar múltiples heurísticas, y que podemos elegir el mejor pseudoárbol generado en complejidad lineal de espacio-tiempo. Dada la importancia de un buen pseudoárbol para el rendimiento, el trabajo futuro incluirá nuevas heurísticas para encontrar mejores pseudo El trabajo futuro también incluirá adaptar las extensiones existentes de DPOP [5, 7] que soportan diferentes dominios de problemas para su uso con DCPOP. 9. REFERENCIAS [1] J. Liu y K. P. Sycara. Explotando la estructura del problema para la optimización distribuida de restricciones. En V. Lesser, editor, Actas de la Primera Conferencia Internacional sobre Sistemas Multiagente, páginas 246-254, San Francisco, CA, 1995. MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, y S. Kulkarni. Un enfoque dinámico distribuido de satisfacción de restricciones para la asignación de recursos. Notas de conferencia en Ciencias de la Computación, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe y M. Yokoo. Un método completo asíncrono para la optimización de restricciones distribuidas. En AAMAS 03, 2003. [4] A. Petcu. Frodo: Un marco para la optimización de restricciones abiertas/distribuidas. Informe técnico No. 2006/001, Instituto Federal Suizo de Tecnología (EPFL), Lausana (Suiza), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu y B. Faltings. A-dpop: Aproximaciones en optimización distribuida. En póster en CP 2005, páginas 802-806, Sitges, España, octubre de 2005. [6] A. Petcu y B. Faltings. Dpop: Un método escalable para la optimización de restricciones multiagente. En IJCAI 05, páginas 266-271, Edimburgo, Escocia, agosto de 2005. [7] A. Petcu, B. Faltings y D. Parkes. M-dpop: Implementación distribuida fiel de problemas eficientes de elección social. En AAMAS 06, páginas 1397-1404, Hakodate, Japón, mayo de 2006. [8] G. Ushakov. Resolviendo problemas de programación de reuniones utilizando un procedimiento de optimización distribuido de pseudobosque. Tesis de maestría, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida y K. Kuwabara. Satisfacción de restricciones distribuida para formalizar la resolución de problemas distribuidos. En la Conferencia Internacional sobre Sistemas de Computación Distribuida, páginas 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida y K. Kuwabara. El problema de satisfacción de restricciones distribuidas: Formalización y algoritmos. Ingeniería del Conocimiento y de Datos, 10(5):673-685, 1998. 748 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "agent": {
            "translated_key": "agente",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Complete Distributed Constraint Optimization Method For Non-Traditional Pseudotree Arrangements∗ James Atlas Computer and Information Sciences University of Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Computer and Information Sciences University of Delaware Newark, DE 19716 decker@cis.udel.edu ABSTRACT Distributed Constraint Optimization (DCOP) is a general framework that can model complex problems in multi-<br>agent</br> systems.",
                "Several current algorithms that solve general DCOP instances, including ADOPT and DPOP, arrange agents into a traditional pseudotree structure.",
                "We introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements.",
                "Our algorithm correctly solves DCOP instances for pseudotrees that include edges between nodes in separate branches.",
                "The algorithm also solves instances with traditional pseudotree arrangements using the same procedure as DPOP.",
                "We compare our algorithm with DPOP using several metrics including the induced width of the pseudotrees, the maximum dimensionality of messages and computation, and the maximum sequential path cost through the algorithm.",
                "We prove that for some problem instances it is not possible to generate a traditional pseudotree using edge-traversal heuristics that will outperform a cross-edged pseudotree.",
                "We use multiple heuristics to generate pseudotrees and choose the best pseudotree in linear space-time complexity.",
                "For some problem instances we observe significant improvements in message and computation sizes compared to DPOP.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent Systems General Terms Algorithms 1.",
                "INTRODUCTION Many historical problems in the AI community can be transformed into Constraint Satisfaction Problems (CSP).",
                "With the advent of distributed AI, multi-<br>agent</br> systems became a popular way to model the complex interactions and coordination required to solve distributed problems.",
                "CSPs were originally extended to distributed <br>agent</br> environments in [9].",
                "Early domains for distributed constraint satisfaction problems (DisCSP) included job shop scheduling [1] and resource allocation [2].",
                "Many domains for <br>agent</br> systems, especially teamwork coordination, distributed scheduling, and sensor networks, involve overly constrained problems that are difficult or impossible to satisfy for every constraint.",
                "Recent approaches to solving problems in these domains rely on optimization techniques that map constraints into multi-valued utility functions.",
                "Instead of finding an assignment that satisfies all constraints, these approaches find an assignment that produces a high level of global utility.",
                "This extension to the original DisCSP approach has become popular in multi-<br>agent</br> systems, and has been labeled the Distributed Constraint Optimization Problem (DCOP) [1].",
                "Current algorithms that solve complete DCOPs use two main approaches: search and dynamic programming.",
                "Search based algorithms that originated from DisCSP typically use some form of backtracking [10] or bounds propagation, as in ADOPT [3].",
                "Dynamic programming based algorithms include DPOP and its extensions [5, 6, 7].",
                "To date, both categories of algorithms arrange agents into a traditional pseudotree to solve the problem.",
                "It has been shown in [6] that any constraint graph can be mapped into a traditional pseudotree.",
                "However, it was also shown that finding the optimal pseudotree was NP-Hard.",
                "We began to investigate the performance of traditional pseudotrees generated by current edge-traversal heuristics.",
                "We found that these heuristics often produced little parallelism as the pseudotrees tended to have high depth and low branching factors.",
                "We suspected that there could be other ways to arrange the pseudotrees that would provide increased parallelism and smaller message sizes.",
                "After exploring these other arrangements we found that cross-edged pseudotrees provide shorter depths and higher branching factors than the traditional pseudotrees.",
                "Our hypothesis was that these crossedged pseudotrees would outperform traditional pseudotrees for some problem types.",
                "In this paper we introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements which include cross-edged pseudotrees.",
                "We begin with a definition of 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, traditional pseudotrees, and cross-edged pseudotrees.",
                "We then provide a summary of the original DPOP algorithm and introduce our DCPOP algorithm.",
                "We discuss the complexity of our algorithm as well as the impact of pseudotree generation heuristics.",
                "We then show that our Distributed Cross-edged Pseudotree Optimization Procedure (DCPOP) performs significantly better in practice than the original DPOP algorithm for some problem instances.",
                "We conclude with a selection of ideas for future work and extensions for DCPOP. 2.",
                "PROBLEM DEFINITION DCOP has been formalized in slightly different ways in recent literature, so we will adopt the definition as presented in [6].",
                "A Distributed Constraint Optimization Problem with n nodes and m constraints consists of the tuple < X, D, U > where: • X = {x1,..,xn} is a set of variables, each one assigned to a unique <br>agent</br> • D = {d1,..,dn} is a set of finite domains for each variable • U = {u1,..,um} is a set of utility functions such that each function involves a subset of variables in X and defines a utility for each combination of values among these variables An optimal solution to a DCOP instance consists of an assignment of values in D to X such that the sum of utilities in U is maximal.",
                "Problem domains that require minimum cost instead of maximum utility can map costs into negative utilities.",
                "The utility functions represent soft constraints but can also represent hard constraints by using arbitrarily large negative values.",
                "For this paper we only consider binary utility functions involving two variables.",
                "Higher order utility functions can be modeled with minor changes to the algorithm, but they also substantially increase the complexity. 2.1 Traditional Pseudotrees Pseudotrees are a common structure used in search procedures to allow parallel processing of independent branches.",
                "As defined in [6], a pseudotree is an arrangement of a graph G into a rooted tree T such that vertices in G that share an edge are in the same branch in T. A back-edge is an edge between a node X and any node which lies on the path from X to the root (excluding Xs parent).",
                "Figure 1 shows a pseudotree with four nodes, three edges (A-B, B-C, BD), and one back-edge (A-C).",
                "Also defined in [6] are four types of relationships between nodes exist in a pseudotree: • P(X) - the parent of a node X: the single node higher in the pseudotree that is connected to X directly through a tree edge • C(X) - the children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through tree edges • PP(X) - the pseudo-parents of a node X: the set of nodes higher in the pseudotree that are connected to X directly through back-edges (In Figure 1, A = PP(C)) • PC(X) - the pseudo-children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through back-edges (In Figure 1, C = PC(A)) Figure 1: A traditional pseudotree.",
                "Solid line edges represent parent-child relationships and the dashed line represents a pseudo-parent-pseudo-child relationship.",
                "Figure 2: A cross-edged pseudotree.",
                "Solid line edges represent parent-child relationships, the dashed line represents a pseudoparent-pseudo-child relationship, and the dotted line represents a branch-parent-branch-child relationship.",
                "The bolded node, B, is the merge point for node E. 2.2 Cross-edged Pseudotrees We define a cross-edge as an edge from node X to a node Y that is above X but not in the path from X to the root.",
                "A cross-edged pseudotree is a traditional pseudotree with the addition of cross-edges.",
                "Figure 2 shows a cross-edged pseudotree with a cross-edge (D-E).",
                "In a cross-edged pseudotree we designate certain edges as primary.",
                "The set of primary edges defines a spanning tree of the nodes.",
                "The parent, child, pseudo-parent, and pseudo-child relationships from the traditional pseudotree are now defined in the context of this primary edge spanning tree.",
                "This definition also yields two additional types of relationships that may exist between nodes: • BP(X) - the branch-parents of a node X: the set of nodes higher in the pseudotree that are connected to X but are not in the primary path from X to the root (In Figure 2, D = BP(E)) • BC(X) - the branch-children of a node X: the set of nodes lower in the pseudotree that are connected to X but are not in any primary path from X to any leaf node (In Figure 2, E = BC(D)) 2.3 Pseudotree Generation 742 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-<br>agent</br> Systems (AAMAS 07) Current algorithms usually have a pre-execution phase to generate a traditional pseudotree from a general DCOP instance.",
                "Our DCPOP algorithm generates a cross-edged pseudotree in the same fashion.",
                "First, the DCOP instance < X, D, U > translates directly into a graph with X as the set of vertices and an edge for each pair of variables represented in U.",
                "Next, various heuristics are used to arrange this graph into a pseudotree.",
                "One common heuristic is to perform a guided depth-first search (DFS) as the resulting traversal is a pseudotree, and a DFS can easily be performed in a distributed fashion.",
                "We define an edge-traversal based method as any method that produces a pseudotree in which all parent/child pairs share an edge in the original graph.",
                "This includes DFS, breadth-first search, and best-first search based traversals.",
                "Our heuristics that generate cross-edged pseudotrees use a distributed best-first search traversal. 3.",
                "DPOP ALGORITHM The original DPOP algorithm operates in three main phases.",
                "The first phase generates a traditional pseudotree from the DCOP instance using a distributed algorithm.",
                "The second phase joins utility hypercubes from children and the local node and propagates them towards the root.",
                "The third phase chooses an assignment for each domain in a top down fashion beginning with the <br>agent</br> at the root node.",
                "The complexity of DPOP depends on the size of the largest computation and utility message during phase two.",
                "It has been shown that this size directly corresponds to the induced width of the pseudotree generated in phase one [6].",
                "DPOP uses polynomial time heuristics to generate the pseudotree since finding the minimum induced width pseudotree is NP-hard.",
                "Several distributed edgetraversal heuristics have been developed to find low width pseudotrees [8].",
                "At the end of the first phase, each <br>agent</br> knows its parent, children, pseudo-parents, and pseudo-children. 3.1 Utility Propagation Agents located at leaf nodes in the pseudotree begin the process by calculating a local utility hypercube.",
                "This hypercube at node X contains summed utilities for each combination of values in the domains for P(X) and PP(X).",
                "This hypercube has dimensional size equal to the number of pseudo-parents plus one.",
                "A message containing this hypercube is sent to P(X).",
                "Agents located at non-leaf nodes wait for all messages from children to arrive.",
                "Once the <br>agent</br> at node Y has all utility messages, it calculates its local utility hypercube which includes domains for P(Y), PP(Y), and Y.",
                "The local utility hypercube is then joined with all of the hypercubes from the child messages.",
                "At this point all utilities involving node Y are known, and the domain for Y may be safely eliminated from the joined hypercube.",
                "This elimination process chooses the best utility over the domain of Y for each combination of the remaining domains.",
                "A message containing this hypercube is now sent to P(Y).",
                "The dimensional size of this hypercube depends on the number of overlapping domains in received messages and the local utility hypercube.",
                "This dynamic programming based propagation phase continues until the <br>agent</br> at the root node of the pseudotree has received all messages from its children. 3.2 Value Propagation Value propagation begins when the <br>agent</br> at the root node Z has received all messages from its children.",
                "Since Z has no parents or pseudo-parents, it simply combines the utility hypercubes received from its children.",
                "The combined hypercube contains only values for the domain for Z.",
                "At this point the <br>agent</br> at node Z simply chooses the assignment for its domain that has the best utility.",
                "A value propagation message with this assignment is sent to each node in C(Z).",
                "Each other node then receives a value propagation message from its parent and chooses the assignment for its domain that has the best utility given the assignments received in the message.",
                "The node adds its domain assignment to the assignments it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen an assignment for their domain. 4.",
                "DCPOP ALGORITHM Our extension to the original DPOP algorithm, shown in Algorithm 1, shares the same three phases.",
                "The first phase generates the cross-edged pseudotree for the DCOP instance.",
                "The second phase merges branches and propagates the utility hypercubes.",
                "The third phase chooses assignments for domains at branch merge points and in a top down fashion, beginning with the <br>agent</br> at the root node.",
                "For the first phase we generate a pseudotree using several distributed heuristics and select the one with lowest overall complexity.",
                "The complexity of the computation and utility message size in DCPOP does not directly correspond to the induced width of the cross-edged pseudotree.",
                "Instead, we use a polynomial time method for calculating the maximum computation and utility message size for a given cross-edged pseudotree.",
                "A description of this method and the pseudotree selection process appears in Section 5.",
                "At the end of the first phase, each <br>agent</br> knows its parent, children, pseudo-parents, pseudo-children, branch-parents, and branch-children. 4.1 Merging Branches and Utility Propagation In the original DPOP algorithm a node X only had utility functions involving its parent and its pseudo-parents.",
                "In DCPOP, a node X is allowed to have a utility function involving a branch-parent.",
                "The concept of a branch can be seen in Figure 2 with node E representing our node X.",
                "The two distinct paths from node E to node B are called branches of E. The single node where all branches of E meet is node B, which is called the merge point of E. Agents with nodes that have branch-parents begin by sending a utility propagation message to each branch-parent.",
                "This message includes a two dimensional utility hypercube with domains for the node X and the branch-parent BP(X).",
                "It also includes a branch information structure which contains the origination node of the branch, X, the total number of branches originating from X, and the number of branches originating from X that are merged into a single representation by this branch information structure (this number starts at 1).",
                "Intuitively when the number of merged branches equals the total number of originating branches, the algorithm has reached the merge point for X.",
                "In Figure 2, node E sends a utility propagation message to its branch-parent, node D. This message has dimensions for the domains of E and D, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "As in the original DPOP utility propagation phase, an <br>agent</br> at leaf node X sends a utility propagation message to its parent.",
                "In DCPOP this message contains dimensions for the domains of P(X) and PP(X).",
                "If node X also has branch-parents, then the utility propagation message also contains a dimension for the domain of X, and will include a branch information structure.",
                "In Figure 2, node E sends a utility propagation message to its parent, node C. This message has dimensions for the domains of E and C, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "When a node Y receives utility propagation messages from all of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-<br>agent</br> Systems (AAMAS 07) 743 its children and branch-children, it merges any branches with the same origination node X.",
                "The merged branch information structure accumulates the number of merged branches for X.",
                "If the cumulative total number of merged branches equals the total number of branches, then Y is the merge point for X.",
                "This means that the utility hypercubes present at Y contain all information about the valuations for utility functions involving node X.",
                "In addition to the typical elimination of the domain of Y from the utility hypercubes, we can now safely eliminate the domain of X from the utility hypercubes.",
                "To illustrate this process, we will examine what happens in the second phase for node B in Figure 2.",
                "In the second phase Node B receives two utility propagation messages.",
                "The first comes from node C and includes dimensions for domains E, B, and A.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "The second comes from node D and includes dimensions for domains E and B.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "Node B then merges the branch information structures from both messages because they have the same origination, node E. Since the number of merged branches originating from E is now 2 and the total branches originating from E is 2, node B now eliminates the dimensions for domain E. Node B also eliminates the dimension for its own domain, leaving only information about domain A. Node B then sends a utility propagation message to node A, containing only one dimension for the domain of A.",
                "Although not possible in DPOP, this method of utility propagation and dimension elimination may produce hypercubes at node Y that do not share any domains.",
                "In DCPOP we do not join domain independent hypercubes, but instead may send multiple hypercubes in the utility propagation message sent to the parent of Y.",
                "This lazy approach to joins helps to reduce message sizes. 4.2 Value Propagation As in DPOP, value propagation begins when the <br>agent</br> at the root node Z has received all messages from its children.",
                "At this point the <br>agent</br> at node Z chooses the assignment for its domain that has the best utility.",
                "If Z is the merge point for the branches of some node X, Z will also choose the assignment for the domain of X.",
                "Thus any node that is a merge point will choose assignments for a domain other than its own.",
                "These assignments are then passed down the primary edge hierarchy.",
                "If node X in the hierarchy has branch-parents, then the value assignment message from P(X) will contain an assignment for the domain of X.",
                "Every node in the hierarchy adds any assignments it has chosen to the ones it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen or received an assignment for their domain. 4.3 Proof of Correctness We will prove the correctness of DCPOP by first noting that DCPOP fully extends DPOP and then examining the two cases for value assignment in DCPOP.",
                "Given a traditional pseudotree as input, the DCPOP algorithm execution is identical to DPOP.",
                "Using a traditional pseudotree arrangement no nodes have branch-parents or branch-children since all edges are either back-edges or tree edges.",
                "Thus the DCPOP algorithm using a traditional pseudotree sends only utility propagation messages that contain domains belonging to the parent or pseudo-parents of a node.",
                "Since no node has any branch-parents, no branches exist, and thus no node serves as a merge point for any other node.",
                "Thus all value propagation assignments are chosen at the node of the assignment domain.",
                "For DCPOP execution with cross-edged pseudotrees, some nodes serve as merge points.",
                "We note that any node X that is not a merge point assigns its value exactly as in DPOP.",
                "The local utility hypercube at X contains domains for X, P(X), PP(X), and BC(X).",
                "As in DPOP the value assignment message received at X includes the values assigned to P(X) and PP(X).",
                "Also, since X is not a merge point, all assignments to BC(X) must have been calculated at merge points higher in the tree and are in the value assignment message from P(X).",
                "Thus after eliminating domains for which assignments are known, only the domain of X is left.",
                "The <br>agent</br> at node X can now correctly choose the assignment with maximum utility for its own domain.",
                "If node X is a merge point for some branch-child Y, we know that X must be a node along the path from Y to the root, and from P(Y) and all BP(Y) to the root.",
                "From the algorithm, we know that Y necessarily has all information from C(Y), PC(Y), and BC(Y) since it waits for their messages.",
                "Node X has information about all nodes below it in the tree, which would include Y, P(Y), BP(Y), and those PP(Y) that are below X in the tree.",
                "For any PP(Y) above X in the tree, X receives the assignment for the domain of PP(Y) in the value assignment message from P(X).",
                "Thus X has utility information about all of the utility functions of which Y is a part.",
                "By eliminating domains included in the value assignment message, node X is left with a local utility hypercube with domains for X and Y.",
                "The <br>agent</br> at node X can now correctly choose the assignments with maximum utility for the domains of X and Y. 4.4 Complexity Analysis The first phase of DCPOP sends one message to each P(X), PP(X), and BP(X).",
                "The second phase sends one value assignment message to each C(X).",
                "Thus, DCPOP produces a linear number of messages with respect to the number of edges (utility functions) in the cross-edged pseudotree and the original DCOP instance.",
                "The actual complexity of DCPOP depends on two additional measurements: message size and computation size.",
                "Message size and computation size in DCPOP depend on the number of overlapping branches as well as the number of overlapping back-edges.",
                "It was shown in [6] that the number of overlapping back-edges is equal to the induced width of the pseudotree.",
                "In a poorly constructed cross-edged pseudotree, the number of overlapping branches at node X can be as large as the total number of descendants of X.",
                "Thus, the total message size in DCPOP in a poorly constructed instance can be space-exponential in the total number of nodes in the graph.",
                "However, in practice a well constructed cross-edged pseudotree can achieve much better results.",
                "Later we address the issue of choosing well constructed crossedged pseudotrees from a set.",
                "We introduce an additional measurement of the maximum sequential path cost through the algorithm.",
                "This measurement directly relates to the maximum amount of parallelism achievable by the algorithm.",
                "To take this measurement we first store the total computation size for each node during phase two and three.",
                "This computation size represents the number of individual accesses to a value in a hypercube at each node.",
                "For example, a join between two domains of size 4 costs 4 ∗ 4 = 16.",
                "Two directed acyclic graphs (DAG) can then be drawn; one with the utility propagation messages as edges and the phase two costs at nodes, and the other with value assignment messages and the phase three costs at nodes.",
                "The maximum sequential path cost is equal to the sum of the longest path on each DAG from the root to any leaf node. 5.",
                "HEURISTICS In our assessment of complexity in DCPOP we focused on the worst case possibly produced by the algorithm.",
                "We acknowledge 744 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-<br>agent</br> Systems (AAMAS 07) Algorithm 1 DCPOP Algorithm 1: DCPOP(X; D; U) Each <br>agent</br> Xi executes: Phase 1: pseudotree creation 2: elect leader from all Xj ∈ X 3: elected leader initiates pseudotree creation 4: afterwards, Xi knows P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) and PC(Xi) Phase 2: UTIL message propagation 5: if |BP(Xi)| > 0 then 6: BRANCHXi ← |BP(Xi)| + 1 7: for all Xk ∈BP(Xi) do 8: UTILXi (Xk) ←Compute utils(Xi, Xk) 9: Send message(Xk,UTILXi (Xk),BRANCHXi ) 10: if |C(Xi)| = 0(i.e.",
                "Xi is a leaf node) then 11: UTILXi (P(Xi)) ← Compute utils(P(Xi),PP(Xi)) for all PP(Xi) 12: Send message(P(Xi), UTILXi (P(Xi)),BRANCHXi ) 13: Send message(PP(Xi), empty UTIL, empty BRANCH) to all PP(Xi) 14: activate UTIL Message handler() Phase 3: VALUE message propagation 15: activate VALUE Message handler() END ALGORITHM UTIL Message handler(Xk,UTILXk (Xi), BRANCHXk ) 16: store UTILXk (Xi),BRANCHXk (Xi) 17: if UTIL messages from all children and branch children arrived then 18: for all Bj ∈BRANCH(Xi) do 19: if Bj is merged then 20: join all hypercubes where Bj ∈UTIL(Xi) 21: eliminate Bj from the joined hypercube 22: if P(Xi) == null (that means Xi is the root) then 23: v ∗ i ← Choose optimal(null) 24: Send VALUE(Xi, v ∗ i) to all C(Xi) 25: else 26: UTILXi (P(Xi)) ← Compute utils(P(Xi), PP(Xi)) 27: Send message(P(Xi),UTILXi (P(Xi)), BRANCHXi (P(Xi))) VALUE Message handler(VALUEXi ,P(Xi)) 28: add all Xk ← v ∗ k ∈VALUEXi ,P(Xi) to <br>agent</br> view 29: Xi ← v ∗ i =Choose optimal(<br>agent</br> view) 30: Send VALUEXl , Xi to all Xl ∈C(Xi) that in real world problems the generation of the pseudotree has a significant impact on the actual performance.",
                "The problem of finding the best pseudotree for a given DCOP instance is NP-Hard.",
                "Thus a heuristic is used for generation, and the performance of the algorithm depends on the pseudotree found by the heuristic.",
                "Some previous research focused on finding heuristics to generate good pseudotrees [8].",
                "While we have developed some heuristics that generate good cross-edged pseudotrees for use with DCPOP, our focus has been to use multiple heuristics and then select the best pseudotree from the generated pseudotrees.",
                "We consider only heuristics that run in polynomial time with respect to the number of nodes in the original DCOP instance.",
                "The actual DCPOP algorithm has worst case exponential complexity, but we can calculate the maximum message size, computation size, and sequential path cost for a given cross-edged pseudotree in linear space-time complexity.",
                "To do this, we simply run the algorithm without attempting to calculate any of the local utility hypercubes or optimal value assignments.",
                "Instead, messages include dimensional and branch information but no utility hypercubes.",
                "After each heuristic completes its generation of a pseudotree, we execute the measurement procedure and propagate the measurement information up to the chosen root in that pseudotree.",
                "The root then broadcasts the total complexity for that heuristic to all nodes.",
                "After all heuristics have had a chance to complete, every node knows which heuristic produced the best pseudotree.",
                "Each node then proceeds to begin the DCPOP algorithm using its knowledge of the pseudotree generated by the best heuristic.",
                "The heuristics used to generate traditional pseudotrees perform a distributed DFS traversal.",
                "The general distributed algorithm uses a token passing mechanism and a linear number of messages.",
                "Improved DFS based heuristics use a special procedure to choose the root node, and also provide an ordering function over the neighbors of a node to determine the order of path recursion.",
                "The DFS based heuristics used in our experiments come from the work done in [4, 8]. 5.1 The best-first cross-edged pseudotree heuristic The heuristics used to generate cross-edged pseudotrees perform a best-first traversal.",
                "A general distributed best-first algorithm for node expansion is presented in Algorithm 2.",
                "An evaluation function at each node provides the values that are used to determine the next best node to expand.",
                "Note that in this algorithm each node only exchanges its best value with its neighbors.",
                "In our experiments we used several evaluation functions that took as arguments an ordered list of ancestors and a node, which contains a list of neighbors (with each neighbors placement depth in the tree if it was placed).",
                "From these we can calculate branchparents, branch-children, and unknown relationships for a potential node placement.",
                "The best overall function calculated the value as ancestors−(branchparents+branchchildren) with the number of unknown relationships being a tiebreak.",
                "After completion each node has knowledge of its parent and ancestors, so it can easily determine which connected nodes are pseudo-parents, branchparents, pseudo-children, and branch-children.",
                "The complexity of the best-first traversal depends on the complexity of the evaluation function.",
                "Assuming a complexity of O(V ) for the evaluation function, which is the case for our best overall function, the best-first traversal is O(V · E) which is at worst O(n3 ).",
                "For each v ∈ V we perform a place operation, and find the next node to place using the getBestNeighbor operation.",
                "The place operation is at most O(V ) because of the sent messages.",
                "Finding the next node uses recursion and traverses only already placed The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-<br>agent</br> Systems (AAMAS 07) 745 Algorithm 2 Distributed Best-First Search Algorithm root ← electedleader next(root, ∅) place(node, parent) node.parent ← parent node.ancestors ← parent.ancestors ∪ parent send placement message (node, node.ancestors) to all neighbors of node next(current, previous) if current is not placed then place(current, previous) next(current, ∅) else best ← getBestNeighbor(current, previous) if best = ∅ then if previous = ∅ then terminate, all nodes are placed next(previous, ∅) else next(best, current) getBestNeighbor(current, previous) best ← ∅; score ← 0 for all n ∈ current.neighbors do if n! = previous then if n is placed then nscore ← getBestNeighbor(n, current) else nscore ← evaluate(current, n) if nscore > score then score ← nscore best ← n return best, score nodes, so it has O(V ) recursions.",
                "Each recursion performs a recursive getBestNeighbor operation that traverses all placed nodes and their neighbors.",
                "This operation is O(V · E), but results can be cached using only O(V ) space at each node.",
                "Thus we have O(V ·(V +V +V ·E)) = O(V 2 ·E).",
                "If we are smart about evaluating local changes when each node receives placement messages from its neighbors and cache the results the getBestNeighbor operation is only O(E).",
                "This increases the complexity of the place operation, but for all placements the total complexity is only O(V · E).",
                "Thus we have an overall complexity of O(V ·E+V ·(V +E)) = O(V ·E). 6.",
                "COMPARISON OF COMPLEXITY IN DPOP AND DCPOP We have already shown that given the same input, DCPOP performs the same as DPOP.",
                "We also have shown that we can accurately predict performance of a given pseudotree in linear spacetime complexity.",
                "If we use a constant number of heuristics to generate the set of pseudotrees, we can choose the best pseudotree in linear space-time complexity.",
                "We will now show that there exists a DCOP instance for which a cross-edged pseudotree outperforms all possible traditional pseudotrees (based on edge-traversal heuristics).",
                "In Figure 3(a) we have a DCOP instance with six nodes.",
                "This is a bipartite graph with each partition fully connected to the other (a) (b) (c) Figure 3: (a) The DCOP instance (b) A traditional pseudotree arrangement for the DCOP instance (c) A cross-edged pseudotree arrangement for the DCOP instance partition.",
                "In Figure 3(b) we see a traditional pseudotree arrangement for this DCOP instance.",
                "It is easy to see that any edgetraversal based heuristic cannot expand two nodes from the same partition in succession.",
                "We also see that no node can have more than one child because any such arrangement would be an invalid pseudotree.",
                "Thus any traditional pseudotree arrangement for this DCOP instance must take the form of Figure 3(b).",
                "We can see that the back-edges F-B and F-A overlap node C. Node C also has a parent E, and a back-edge with D. Using the original DPOP algorithm (or DCPOP since they are identical in this case), we find that the computation at node C involves five domains: A, B, C, D, and E. In contrast, the cross-edged pseudotree arrangement in Figure 3(c) requires only a maximum of four domains in any computation during DCPOP.",
                "Since node A is the merge point for branches from both B and C, we can see that each of the nodes D, E, and F have two overlapping branches.",
                "In addition each of these nodes has node A as its parent.",
                "Using the DCPOP algorithm we find that the computation at node D (or E or F) involves four domains: A, B, C, and D (or E or F).",
                "Since no better traditional pseudotree arrangement can be created using an edge-traversal heuristic, we have shown that DCPOP can outperform DPOP even if we use the optimal pseudotree found through edge-traversal.",
                "We acknowledge that pseudotree arrangements that allow parent-child relationships without an actual constraint can solve the problem in Figure 3(a) with maximum computation size of four domains.",
                "However, current heuristics used with DPOP do not produce such pseudotrees, and such a heuristic would be difficult to distribute since each node would require information about nodes with which it has no constraint.",
                "Also, while we do not prove it here, cross-edged pseudotrees can produce smaller message sizes than such pseudotrees even if the computation size is similar.",
                "In practice, since finding the best pseudotree arrangement is NP-Hard, we find that heuristics that produce cross-edged pseudotrees often produce significantly smaller computation and message sizes. 7.",
                "EXPERIMENTAL RESULTS 746 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-<br>agent</br> Systems (AAMAS 07) Existing performance metrics for DCOP algorithms include the total number of messages, synchronous clock cycles, and message size.",
                "We have already shown that the total number of messages is linear with respect to the number of constraints in the DCOP instance.",
                "We also introduced the maximum sequential path cost (PC) as a measurement of the maximum amount of parallelism achievable by the algorithm.",
                "The maximum sequential path cost is equal to the sum of the computations performed on the longest path from the root to any leaf node.",
                "We also include as metrics the maximum computation size in number of dimensions (CD) and maximum message size in number of dimensions (MD).",
                "To analyze the relative complexity of a given DCOP instance, we find the minimum induced width (IW) of any traditional pseudotree produced by a heuristic for the original DPOP. 7.1 Generic DCOP instances For our initial tests we randomly generated two sets of problems with 3000 cases in each.",
                "Each problem was generated by assigning a random number (picked from a range) of constraints to each variable.",
                "The generator then created binary constraints until each variable reached its maximum number of constraints.",
                "The first set uses 20 variables, and the best DPOP IW ranges from 1 to 16 with an average of 8.5.",
                "The second set uses 100 variables, and the best DPOP IW ranged from 2 to 68 with an average of 39.3.",
                "Since most of the problems in the second set were too complex to actually compute the solution, we took measurements of the metrics using the techniques described earlier in Section 5 without actually solving the problem.",
                "Results are shown for the first set in Table 1 and for the second set in Table 2.",
                "For the two problem sets we split the cases into low density and high density categories.",
                "Low density cases consist of those problems that have a best DPOP IW less than or equal to half of the total number of nodes (e.g.",
                "IW ≤ 10 for the 20 node problems and IW ≤ 50 for the 100 node problems).",
                "High density problems consist of the remainder of the problem sets.",
                "In both Table 1 and Table 2 we have listed performance metrics for the original DPOP algorithm, the DCPOP algorithm using only cross-edged pseudotrees (DCPOP-CE), and the DCPOP algorithm using traditional and cross-edged pseudotrees (DCPOP-All).",
                "The pseudotrees used for DPOP were generated using 5 heuristics: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB, and DFS MCN BEC.",
                "These are all versions of the guided DFS traversal discussed in Section 5.",
                "The cross-edged pseudotrees used for DCPOP-CE were generated using 5 heuristics: MCN, LCN, MCN A-B, LCN A-B, and LCSG A-B.",
                "These are all versions of the best-first traversal discussed in Section 5.",
                "For both DPOP and DCPOP-CE we chose the best pseudotree produced by their respective 5 heuristics for each problem in the set.",
                "For DCPOP-All we chose the best pseudotree produced by all 10 heuristics for each problem in the set.",
                "For the CD and MD metrics the value shown is the average number of dimensions.",
                "For the PC metric the value shown is the natural logarithm of the maximum sequential path cost (since the actual value grows exponentially with the complexity of the problem).",
                "The final row in both tables is a measurement of improvement of DCPOP-All over DPOP.",
                "For the CD and MD metrics the value shown is a reduction in number of dimensions.",
                "For the PC metric the value shown is a percentage reduction in the maximum sequential path cost (% = DP OP −DCP OP DCP OP ∗ 100).",
                "Notice that DCPOPAll outperforms DPOP on all metrics.",
                "This logically follows from our earlier assertion that given the same input, DCPOP performs exactly the same as DPOP.",
                "Thus given the choice between the pseudotrees produced by all 10 heuristics, DCPOP-All will always outLow Density High Density Algorithm CD MD PC CD MD PC DPOP 7.81 6.81 3.78 13.34 12.34 5.34 DCPOP-CE 7.94 6.73 3.74 12.83 11.43 5.07 DCPOP-All 7.62 6.49 3.66 12.72 11.36 5.05 Improvement 0.18 0.32 13% 0.62 0.98 36% Table 1: 20 node problems Low Density High Density Algorithm CD MD PC CD MD PC DPOP 33.35 32.35 14.55 58.51 57.50 19.90 DCPOP-CE 33.49 29.17 15.22 57.11 50.03 20.01 DCPOP-All 32.35 29.57 14.10 56.33 51.17 18.84 Improvement 1.00 2.78 104% 2.18 6.33 256% Table 2: 100 node problems Figure 4: Computation Dimension Size Figure 5: Message Dimension Size The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-<br>agent</br> Systems (AAMAS 07) 747 Figure 6: Path Cost DCPOP Improvement Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Table 3: Meeting Scheduling Problems perform DPOP.",
                "Another trend we notice is that the improvement is greater for high density problems than low density problems.",
                "We show this trend in greater detail in Figures 4, 5, and 6.",
                "Notice how the improvement increases as the complexity of the problem increases. 7.2 Meeting Scheduling Problem In addition to our initial generic DCOP tests, we ran a series of tests on the Meeting Scheduling Problem (MSP) as described in [6].",
                "The problem setup includes a number of people that are grouped into departments.",
                "Each person must attend a specified number of meetings.",
                "Meetings can be held within departments or among departments, and can be assigned to one of eight time slots.",
                "The MSP maps to a DCOP instance where each variable represents the time slot that a specific person will attend a specific meeting.",
                "All variables that belong to the same person have mutual exclusion constraints placed so that the person cannot attend more than one meeting during the same time slot.",
                "All variables that belong to the same meeting have equality constraints so that all of the participants choose the same time slot.",
                "Unary constraints are placed on each variable to account for a persons valuation of each meeting and time slot.",
                "For our tests we generated 100 sample problems for each combination of agents and meetings.",
                "Results are shown in Table 3.",
                "The values in the first five columns represent (in left to right order), the total number of agents, the total number of meetings, the total number of variables, the average total number of constraints, and the average minimum IW produced by a traditional pseudotree.",
                "The last three columns show the same metrics we used for the generic DCOP instances, except this time we only show the improvements of DCPOP-All over DPOP.",
                "Performance is better on average for all MSP instances, but again we see larger improvements for more complex problem instances. 8.",
                "CONCLUSIONS AND FUTURE WORK We presented a complete, distributed algorithm that solves general DCOP instances using cross-edged pseudotree arrangements.",
                "Our algorithm extends the DPOP algorithm by adding additional utility propagation messages, and introducing the concept of branch merging during the utility propagation phase.",
                "Our algorithm also allows value assignments to occur at higher level merge points for lower level nodes.",
                "We have shown that DCPOP fully extends DPOP by performing the same operations given the same input.",
                "We have also shown through some examples and experimental data that DCPOP can achieve greater performance for some problem instances by extending the allowable input set to include cross-edged pseudotrees.",
                "We placed particular emphasis on the role that edge-traversal heuristics play in the generation of pseudotrees.",
                "We have shown that the performance penalty is minimal to generate multiple heuristics, and that we can choose the best generated pseudotree in linear space-time complexity.",
                "Given the importance of a good pseudotree for performance, future work will include new heuristics to find better pseudotrees.",
                "Future work will also include adapting existing DPOP extensions [5, 7] that support different problem domains for use with DCPOP. 9.",
                "REFERENCES [1] J. Liu and K. P. Sycara.",
                "Exploiting problem structure for distributed constraint optimization.",
                "In V. Lesser, editor, Proceedings of the First International Conference on Multi-<br>agent</br> Systems, pages 246-254, San Francisco, CA, 1995.",
                "MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni.",
                "A dynamic distributed constraint satisfaction approach to resource allocation.",
                "Lecture Notes in Computer Science, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe, and M. Yokoo.",
                "An asynchronous complete method for distributed constraint optimization.",
                "In AAMAS 03, 2003. [4] A. Petcu.",
                "Frodo: A framework for open/distributed constraint optimization.",
                "Technical Report No. 2006/001 2006/001, Swiss Federal Institute of Technology (EPFL), Lausanne (Switzerland), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu and B. Faltings.",
                "A-dpop: Approximations in distributed optimization.",
                "In poster in CP 2005, pages 802-806, Sitges, Spain, October 2005. [6] A. Petcu and B. Faltings.",
                "Dpop: A scalable method for multiagent constraint optimization.",
                "In IJCAI 05, pages 266-271, Edinburgh, Scotland, Aug 2005. [7] A. Petcu, B. Faltings, and D. Parkes.",
                "M-dpop: Faithful distributed implementation of efficient social choice problems.",
                "In AAMAS 06, pages 1397-1404, Hakodate, Japan, May 2006. [8] G. Ushakov.",
                "Solving meeting scheduling problems using distributed pseudotree-optimization procedure.",
                "Masters thesis, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "Distributed constraint satisfaction for formalizing distributed problem solving.",
                "In International Conference on Distributed Computing Systems, pages 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "The distributed constraint satisfaction problem: Formalization and algorithms.",
                "Knowledge and Data Engineering, 10(5):673-685, 1998. 748 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-<br>agent</br> Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "A Complete Distributed Constraint Optimization Method For Non-Traditional Pseudotree Arrangements∗ James Atlas Computer and Information Sciences University of Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Computer and Information Sciences University of Delaware Newark, DE 19716 decker@cis.udel.edu ABSTRACT Distributed Constraint Optimization (DCOP) is a general framework that can model complex problems in multi-<br>agent</br> systems.",
                "With the advent of distributed AI, multi-<br>agent</br> systems became a popular way to model the complex interactions and coordination required to solve distributed problems.",
                "CSPs were originally extended to distributed <br>agent</br> environments in [9].",
                "Many domains for <br>agent</br> systems, especially teamwork coordination, distributed scheduling, and sensor networks, involve overly constrained problems that are difficult or impossible to satisfy for every constraint.",
                "This extension to the original DisCSP approach has become popular in multi-<br>agent</br> systems, and has been labeled the Distributed Constraint Optimization Problem (DCOP) [1]."
            ],
            "translated_annotated_samples": [
                "Un Método Completo de Optimización de Restricciones Distribuidas para Arreglos de Pseudotree No Tradicionales∗ James Atlas Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 decker@cis.udel.edu RESUMEN La Optimización de Restricciones Distribuidas (DCOP) es un marco general que puede modelar problemas complejos en sistemas multi<br>agente</br>.",
                "Con la llegada de la inteligencia artificial distribuida, los sistemas multi<br>agente</br> se convirtieron en una forma popular de modelar las interacciones complejas y la coordinación necesaria para resolver problemas distribuidos.",
                "Los CSPs fueron originalmente extendidos a entornos de <br>agente</br>s distribuidos en [9].",
                "Muchos dominios para sistemas de <br>agente</br>s, especialmente coordinación de trabajo en equipo, programación distribuida y redes de sensores, implican problemas excesivamente restringidos que son difíciles o imposibles de satisfacer para cada restricción.",
                "Esta extensión al enfoque original de DisCSP se ha vuelto popular en sistemas multi<br>agente</br>, y ha sido etiquetada como Problema de Optimización de Restricciones Distribuidas (DCOP) [1]."
            ],
            "translated_text": "Un Método Completo de Optimización de Restricciones Distribuidas para Arreglos de Pseudotree No Tradicionales∗ James Atlas Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 decker@cis.udel.edu RESUMEN La Optimización de Restricciones Distribuidas (DCOP) es un marco general que puede modelar problemas complejos en sistemas multi<br>agente</br>. Varios algoritmos actuales que resuelven instancias generales de DCOP, incluyendo ADOPT y DPOP, organizan a los agentes en una estructura de pseudobosque tradicional. Introducimos una extensión al algoritmo DPOP que maneja un conjunto extendido de disposiciones de pseudobosque. Nuestro algoritmo resuelve correctamente instancias de DCOP para pseudobosques que incluyen aristas entre nodos en ramas separadas. El algoritmo también resuelve instancias con arreglos de pseudobosque tradicionales utilizando el mismo procedimiento que DPOP. Comparamos nuestro algoritmo con DPOP utilizando varios métricos, incluyendo el ancho inducido de los pseudobosques, la dimensionalidad máxima de los mensajes y la computación, y el costo máximo de la ruta secuencial a través del algoritmo. Demostramos que para algunas instancias del problema no es posible generar un pseudoárbol tradicional utilizando heurísticas de recorrido de aristas que supere a un pseudoárbol con aristas cruzadas. Utilizamos múltiples heurísticas para generar pseudoárboles y elegir el mejor pseudoárbol en complejidad espacio-temporal lineal. Para algunas instancias del problema observamos mejoras significativas en los tamaños de los mensajes y cálculos en comparación con DPOP. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Algoritmos 1. INTRODUCCIÓN Muchos problemas históricos en la comunidad de IA pueden transformarse en Problemas de Satisfacción de Restricciones (CSP). Con la llegada de la inteligencia artificial distribuida, los sistemas multi<br>agente</br> se convirtieron en una forma popular de modelar las interacciones complejas y la coordinación necesaria para resolver problemas distribuidos. Los CSPs fueron originalmente extendidos a entornos de <br>agente</br>s distribuidos en [9]. Los primeros dominios para problemas de satisfacción de restricciones distribuidas (DisCSP) incluyeron la programación de talleres de trabajo [1] y la asignación de recursos [2]. Muchos dominios para sistemas de <br>agente</br>s, especialmente coordinación de trabajo en equipo, programación distribuida y redes de sensores, implican problemas excesivamente restringidos que son difíciles o imposibles de satisfacer para cada restricción. Los enfoques recientes para resolver problemas en estos dominios se basan en técnicas de optimización que mapean restricciones en funciones de utilidad multivaluadas. En lugar de encontrar una asignación que satisfaga todas las restricciones, estos enfoques encuentran una asignación que produce un alto nivel de utilidad global. Esta extensión al enfoque original de DisCSP se ha vuelto popular en sistemas multi<br>agente</br>, y ha sido etiquetada como Problema de Optimización de Restricciones Distribuidas (DCOP) [1]. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "maximum sequential path cost": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Complete Distributed Constraint Optimization Method For Non-Traditional Pseudotree Arrangements∗ James Atlas Computer and Information Sciences University of Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Computer and Information Sciences University of Delaware Newark, DE 19716 decker@cis.udel.edu ABSTRACT Distributed Constraint Optimization (DCOP) is a general framework that can model complex problems in multi-agent systems.",
                "Several current algorithms that solve general DCOP instances, including ADOPT and DPOP, arrange agents into a traditional pseudotree structure.",
                "We introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements.",
                "Our algorithm correctly solves DCOP instances for pseudotrees that include edges between nodes in separate branches.",
                "The algorithm also solves instances with traditional pseudotree arrangements using the same procedure as DPOP.",
                "We compare our algorithm with DPOP using several metrics including the induced width of the pseudotrees, the maximum dimensionality of messages and computation, and the <br>maximum sequential path cost</br> through the algorithm.",
                "We prove that for some problem instances it is not possible to generate a traditional pseudotree using edge-traversal heuristics that will outperform a cross-edged pseudotree.",
                "We use multiple heuristics to generate pseudotrees and choose the best pseudotree in linear space-time complexity.",
                "For some problem instances we observe significant improvements in message and computation sizes compared to DPOP.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent Systems General Terms Algorithms 1.",
                "INTRODUCTION Many historical problems in the AI community can be transformed into Constraint Satisfaction Problems (CSP).",
                "With the advent of distributed AI, multi-agent systems became a popular way to model the complex interactions and coordination required to solve distributed problems.",
                "CSPs were originally extended to distributed agent environments in [9].",
                "Early domains for distributed constraint satisfaction problems (DisCSP) included job shop scheduling [1] and resource allocation [2].",
                "Many domains for agent systems, especially teamwork coordination, distributed scheduling, and sensor networks, involve overly constrained problems that are difficult or impossible to satisfy for every constraint.",
                "Recent approaches to solving problems in these domains rely on optimization techniques that map constraints into multi-valued utility functions.",
                "Instead of finding an assignment that satisfies all constraints, these approaches find an assignment that produces a high level of global utility.",
                "This extension to the original DisCSP approach has become popular in multi-agent systems, and has been labeled the Distributed Constraint Optimization Problem (DCOP) [1].",
                "Current algorithms that solve complete DCOPs use two main approaches: search and dynamic programming.",
                "Search based algorithms that originated from DisCSP typically use some form of backtracking [10] or bounds propagation, as in ADOPT [3].",
                "Dynamic programming based algorithms include DPOP and its extensions [5, 6, 7].",
                "To date, both categories of algorithms arrange agents into a traditional pseudotree to solve the problem.",
                "It has been shown in [6] that any constraint graph can be mapped into a traditional pseudotree.",
                "However, it was also shown that finding the optimal pseudotree was NP-Hard.",
                "We began to investigate the performance of traditional pseudotrees generated by current edge-traversal heuristics.",
                "We found that these heuristics often produced little parallelism as the pseudotrees tended to have high depth and low branching factors.",
                "We suspected that there could be other ways to arrange the pseudotrees that would provide increased parallelism and smaller message sizes.",
                "After exploring these other arrangements we found that cross-edged pseudotrees provide shorter depths and higher branching factors than the traditional pseudotrees.",
                "Our hypothesis was that these crossedged pseudotrees would outperform traditional pseudotrees for some problem types.",
                "In this paper we introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements which include cross-edged pseudotrees.",
                "We begin with a definition of 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, traditional pseudotrees, and cross-edged pseudotrees.",
                "We then provide a summary of the original DPOP algorithm and introduce our DCPOP algorithm.",
                "We discuss the complexity of our algorithm as well as the impact of pseudotree generation heuristics.",
                "We then show that our Distributed Cross-edged Pseudotree Optimization Procedure (DCPOP) performs significantly better in practice than the original DPOP algorithm for some problem instances.",
                "We conclude with a selection of ideas for future work and extensions for DCPOP. 2.",
                "PROBLEM DEFINITION DCOP has been formalized in slightly different ways in recent literature, so we will adopt the definition as presented in [6].",
                "A Distributed Constraint Optimization Problem with n nodes and m constraints consists of the tuple < X, D, U > where: • X = {x1,..,xn} is a set of variables, each one assigned to a unique agent • D = {d1,..,dn} is a set of finite domains for each variable • U = {u1,..,um} is a set of utility functions such that each function involves a subset of variables in X and defines a utility for each combination of values among these variables An optimal solution to a DCOP instance consists of an assignment of values in D to X such that the sum of utilities in U is maximal.",
                "Problem domains that require minimum cost instead of maximum utility can map costs into negative utilities.",
                "The utility functions represent soft constraints but can also represent hard constraints by using arbitrarily large negative values.",
                "For this paper we only consider binary utility functions involving two variables.",
                "Higher order utility functions can be modeled with minor changes to the algorithm, but they also substantially increase the complexity. 2.1 Traditional Pseudotrees Pseudotrees are a common structure used in search procedures to allow parallel processing of independent branches.",
                "As defined in [6], a pseudotree is an arrangement of a graph G into a rooted tree T such that vertices in G that share an edge are in the same branch in T. A back-edge is an edge between a node X and any node which lies on the path from X to the root (excluding Xs parent).",
                "Figure 1 shows a pseudotree with four nodes, three edges (A-B, B-C, BD), and one back-edge (A-C).",
                "Also defined in [6] are four types of relationships between nodes exist in a pseudotree: • P(X) - the parent of a node X: the single node higher in the pseudotree that is connected to X directly through a tree edge • C(X) - the children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through tree edges • PP(X) - the pseudo-parents of a node X: the set of nodes higher in the pseudotree that are connected to X directly through back-edges (In Figure 1, A = PP(C)) • PC(X) - the pseudo-children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through back-edges (In Figure 1, C = PC(A)) Figure 1: A traditional pseudotree.",
                "Solid line edges represent parent-child relationships and the dashed line represents a pseudo-parent-pseudo-child relationship.",
                "Figure 2: A cross-edged pseudotree.",
                "Solid line edges represent parent-child relationships, the dashed line represents a pseudoparent-pseudo-child relationship, and the dotted line represents a branch-parent-branch-child relationship.",
                "The bolded node, B, is the merge point for node E. 2.2 Cross-edged Pseudotrees We define a cross-edge as an edge from node X to a node Y that is above X but not in the path from X to the root.",
                "A cross-edged pseudotree is a traditional pseudotree with the addition of cross-edges.",
                "Figure 2 shows a cross-edged pseudotree with a cross-edge (D-E).",
                "In a cross-edged pseudotree we designate certain edges as primary.",
                "The set of primary edges defines a spanning tree of the nodes.",
                "The parent, child, pseudo-parent, and pseudo-child relationships from the traditional pseudotree are now defined in the context of this primary edge spanning tree.",
                "This definition also yields two additional types of relationships that may exist between nodes: • BP(X) - the branch-parents of a node X: the set of nodes higher in the pseudotree that are connected to X but are not in the primary path from X to the root (In Figure 2, D = BP(E)) • BC(X) - the branch-children of a node X: the set of nodes lower in the pseudotree that are connected to X but are not in any primary path from X to any leaf node (In Figure 2, E = BC(D)) 2.3 Pseudotree Generation 742 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Current algorithms usually have a pre-execution phase to generate a traditional pseudotree from a general DCOP instance.",
                "Our DCPOP algorithm generates a cross-edged pseudotree in the same fashion.",
                "First, the DCOP instance < X, D, U > translates directly into a graph with X as the set of vertices and an edge for each pair of variables represented in U.",
                "Next, various heuristics are used to arrange this graph into a pseudotree.",
                "One common heuristic is to perform a guided depth-first search (DFS) as the resulting traversal is a pseudotree, and a DFS can easily be performed in a distributed fashion.",
                "We define an edge-traversal based method as any method that produces a pseudotree in which all parent/child pairs share an edge in the original graph.",
                "This includes DFS, breadth-first search, and best-first search based traversals.",
                "Our heuristics that generate cross-edged pseudotrees use a distributed best-first search traversal. 3.",
                "DPOP ALGORITHM The original DPOP algorithm operates in three main phases.",
                "The first phase generates a traditional pseudotree from the DCOP instance using a distributed algorithm.",
                "The second phase joins utility hypercubes from children and the local node and propagates them towards the root.",
                "The third phase chooses an assignment for each domain in a top down fashion beginning with the agent at the root node.",
                "The complexity of DPOP depends on the size of the largest computation and utility message during phase two.",
                "It has been shown that this size directly corresponds to the induced width of the pseudotree generated in phase one [6].",
                "DPOP uses polynomial time heuristics to generate the pseudotree since finding the minimum induced width pseudotree is NP-hard.",
                "Several distributed edgetraversal heuristics have been developed to find low width pseudotrees [8].",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, and pseudo-children. 3.1 Utility Propagation Agents located at leaf nodes in the pseudotree begin the process by calculating a local utility hypercube.",
                "This hypercube at node X contains summed utilities for each combination of values in the domains for P(X) and PP(X).",
                "This hypercube has dimensional size equal to the number of pseudo-parents plus one.",
                "A message containing this hypercube is sent to P(X).",
                "Agents located at non-leaf nodes wait for all messages from children to arrive.",
                "Once the agent at node Y has all utility messages, it calculates its local utility hypercube which includes domains for P(Y), PP(Y), and Y.",
                "The local utility hypercube is then joined with all of the hypercubes from the child messages.",
                "At this point all utilities involving node Y are known, and the domain for Y may be safely eliminated from the joined hypercube.",
                "This elimination process chooses the best utility over the domain of Y for each combination of the remaining domains.",
                "A message containing this hypercube is now sent to P(Y).",
                "The dimensional size of this hypercube depends on the number of overlapping domains in received messages and the local utility hypercube.",
                "This dynamic programming based propagation phase continues until the agent at the root node of the pseudotree has received all messages from its children. 3.2 Value Propagation Value propagation begins when the agent at the root node Z has received all messages from its children.",
                "Since Z has no parents or pseudo-parents, it simply combines the utility hypercubes received from its children.",
                "The combined hypercube contains only values for the domain for Z.",
                "At this point the agent at node Z simply chooses the assignment for its domain that has the best utility.",
                "A value propagation message with this assignment is sent to each node in C(Z).",
                "Each other node then receives a value propagation message from its parent and chooses the assignment for its domain that has the best utility given the assignments received in the message.",
                "The node adds its domain assignment to the assignments it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen an assignment for their domain. 4.",
                "DCPOP ALGORITHM Our extension to the original DPOP algorithm, shown in Algorithm 1, shares the same three phases.",
                "The first phase generates the cross-edged pseudotree for the DCOP instance.",
                "The second phase merges branches and propagates the utility hypercubes.",
                "The third phase chooses assignments for domains at branch merge points and in a top down fashion, beginning with the agent at the root node.",
                "For the first phase we generate a pseudotree using several distributed heuristics and select the one with lowest overall complexity.",
                "The complexity of the computation and utility message size in DCPOP does not directly correspond to the induced width of the cross-edged pseudotree.",
                "Instead, we use a polynomial time method for calculating the maximum computation and utility message size for a given cross-edged pseudotree.",
                "A description of this method and the pseudotree selection process appears in Section 5.",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, pseudo-children, branch-parents, and branch-children. 4.1 Merging Branches and Utility Propagation In the original DPOP algorithm a node X only had utility functions involving its parent and its pseudo-parents.",
                "In DCPOP, a node X is allowed to have a utility function involving a branch-parent.",
                "The concept of a branch can be seen in Figure 2 with node E representing our node X.",
                "The two distinct paths from node E to node B are called branches of E. The single node where all branches of E meet is node B, which is called the merge point of E. Agents with nodes that have branch-parents begin by sending a utility propagation message to each branch-parent.",
                "This message includes a two dimensional utility hypercube with domains for the node X and the branch-parent BP(X).",
                "It also includes a branch information structure which contains the origination node of the branch, X, the total number of branches originating from X, and the number of branches originating from X that are merged into a single representation by this branch information structure (this number starts at 1).",
                "Intuitively when the number of merged branches equals the total number of originating branches, the algorithm has reached the merge point for X.",
                "In Figure 2, node E sends a utility propagation message to its branch-parent, node D. This message has dimensions for the domains of E and D, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "As in the original DPOP utility propagation phase, an agent at leaf node X sends a utility propagation message to its parent.",
                "In DCPOP this message contains dimensions for the domains of P(X) and PP(X).",
                "If node X also has branch-parents, then the utility propagation message also contains a dimension for the domain of X, and will include a branch information structure.",
                "In Figure 2, node E sends a utility propagation message to its parent, node C. This message has dimensions for the domains of E and C, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "When a node Y receives utility propagation messages from all of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 743 its children and branch-children, it merges any branches with the same origination node X.",
                "The merged branch information structure accumulates the number of merged branches for X.",
                "If the cumulative total number of merged branches equals the total number of branches, then Y is the merge point for X.",
                "This means that the utility hypercubes present at Y contain all information about the valuations for utility functions involving node X.",
                "In addition to the typical elimination of the domain of Y from the utility hypercubes, we can now safely eliminate the domain of X from the utility hypercubes.",
                "To illustrate this process, we will examine what happens in the second phase for node B in Figure 2.",
                "In the second phase Node B receives two utility propagation messages.",
                "The first comes from node C and includes dimensions for domains E, B, and A.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "The second comes from node D and includes dimensions for domains E and B.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "Node B then merges the branch information structures from both messages because they have the same origination, node E. Since the number of merged branches originating from E is now 2 and the total branches originating from E is 2, node B now eliminates the dimensions for domain E. Node B also eliminates the dimension for its own domain, leaving only information about domain A. Node B then sends a utility propagation message to node A, containing only one dimension for the domain of A.",
                "Although not possible in DPOP, this method of utility propagation and dimension elimination may produce hypercubes at node Y that do not share any domains.",
                "In DCPOP we do not join domain independent hypercubes, but instead may send multiple hypercubes in the utility propagation message sent to the parent of Y.",
                "This lazy approach to joins helps to reduce message sizes. 4.2 Value Propagation As in DPOP, value propagation begins when the agent at the root node Z has received all messages from its children.",
                "At this point the agent at node Z chooses the assignment for its domain that has the best utility.",
                "If Z is the merge point for the branches of some node X, Z will also choose the assignment for the domain of X.",
                "Thus any node that is a merge point will choose assignments for a domain other than its own.",
                "These assignments are then passed down the primary edge hierarchy.",
                "If node X in the hierarchy has branch-parents, then the value assignment message from P(X) will contain an assignment for the domain of X.",
                "Every node in the hierarchy adds any assignments it has chosen to the ones it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen or received an assignment for their domain. 4.3 Proof of Correctness We will prove the correctness of DCPOP by first noting that DCPOP fully extends DPOP and then examining the two cases for value assignment in DCPOP.",
                "Given a traditional pseudotree as input, the DCPOP algorithm execution is identical to DPOP.",
                "Using a traditional pseudotree arrangement no nodes have branch-parents or branch-children since all edges are either back-edges or tree edges.",
                "Thus the DCPOP algorithm using a traditional pseudotree sends only utility propagation messages that contain domains belonging to the parent or pseudo-parents of a node.",
                "Since no node has any branch-parents, no branches exist, and thus no node serves as a merge point for any other node.",
                "Thus all value propagation assignments are chosen at the node of the assignment domain.",
                "For DCPOP execution with cross-edged pseudotrees, some nodes serve as merge points.",
                "We note that any node X that is not a merge point assigns its value exactly as in DPOP.",
                "The local utility hypercube at X contains domains for X, P(X), PP(X), and BC(X).",
                "As in DPOP the value assignment message received at X includes the values assigned to P(X) and PP(X).",
                "Also, since X is not a merge point, all assignments to BC(X) must have been calculated at merge points higher in the tree and are in the value assignment message from P(X).",
                "Thus after eliminating domains for which assignments are known, only the domain of X is left.",
                "The agent at node X can now correctly choose the assignment with maximum utility for its own domain.",
                "If node X is a merge point for some branch-child Y, we know that X must be a node along the path from Y to the root, and from P(Y) and all BP(Y) to the root.",
                "From the algorithm, we know that Y necessarily has all information from C(Y), PC(Y), and BC(Y) since it waits for their messages.",
                "Node X has information about all nodes below it in the tree, which would include Y, P(Y), BP(Y), and those PP(Y) that are below X in the tree.",
                "For any PP(Y) above X in the tree, X receives the assignment for the domain of PP(Y) in the value assignment message from P(X).",
                "Thus X has utility information about all of the utility functions of which Y is a part.",
                "By eliminating domains included in the value assignment message, node X is left with a local utility hypercube with domains for X and Y.",
                "The agent at node X can now correctly choose the assignments with maximum utility for the domains of X and Y. 4.4 Complexity Analysis The first phase of DCPOP sends one message to each P(X), PP(X), and BP(X).",
                "The second phase sends one value assignment message to each C(X).",
                "Thus, DCPOP produces a linear number of messages with respect to the number of edges (utility functions) in the cross-edged pseudotree and the original DCOP instance.",
                "The actual complexity of DCPOP depends on two additional measurements: message size and computation size.",
                "Message size and computation size in DCPOP depend on the number of overlapping branches as well as the number of overlapping back-edges.",
                "It was shown in [6] that the number of overlapping back-edges is equal to the induced width of the pseudotree.",
                "In a poorly constructed cross-edged pseudotree, the number of overlapping branches at node X can be as large as the total number of descendants of X.",
                "Thus, the total message size in DCPOP in a poorly constructed instance can be space-exponential in the total number of nodes in the graph.",
                "However, in practice a well constructed cross-edged pseudotree can achieve much better results.",
                "Later we address the issue of choosing well constructed crossedged pseudotrees from a set.",
                "We introduce an additional measurement of the <br>maximum sequential path cost</br> through the algorithm.",
                "This measurement directly relates to the maximum amount of parallelism achievable by the algorithm.",
                "To take this measurement we first store the total computation size for each node during phase two and three.",
                "This computation size represents the number of individual accesses to a value in a hypercube at each node.",
                "For example, a join between two domains of size 4 costs 4 ∗ 4 = 16.",
                "Two directed acyclic graphs (DAG) can then be drawn; one with the utility propagation messages as edges and the phase two costs at nodes, and the other with value assignment messages and the phase three costs at nodes.",
                "The <br>maximum sequential path cost</br> is equal to the sum of the longest path on each DAG from the root to any leaf node. 5.",
                "HEURISTICS In our assessment of complexity in DCPOP we focused on the worst case possibly produced by the algorithm.",
                "We acknowledge 744 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Algorithm 1 DCPOP Algorithm 1: DCPOP(X; D; U) Each agent Xi executes: Phase 1: pseudotree creation 2: elect leader from all Xj ∈ X 3: elected leader initiates pseudotree creation 4: afterwards, Xi knows P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) and PC(Xi) Phase 2: UTIL message propagation 5: if |BP(Xi)| > 0 then 6: BRANCHXi ← |BP(Xi)| + 1 7: for all Xk ∈BP(Xi) do 8: UTILXi (Xk) ←Compute utils(Xi, Xk) 9: Send message(Xk,UTILXi (Xk),BRANCHXi ) 10: if |C(Xi)| = 0(i.e.",
                "Xi is a leaf node) then 11: UTILXi (P(Xi)) ← Compute utils(P(Xi),PP(Xi)) for all PP(Xi) 12: Send message(P(Xi), UTILXi (P(Xi)),BRANCHXi ) 13: Send message(PP(Xi), empty UTIL, empty BRANCH) to all PP(Xi) 14: activate UTIL Message handler() Phase 3: VALUE message propagation 15: activate VALUE Message handler() END ALGORITHM UTIL Message handler(Xk,UTILXk (Xi), BRANCHXk ) 16: store UTILXk (Xi),BRANCHXk (Xi) 17: if UTIL messages from all children and branch children arrived then 18: for all Bj ∈BRANCH(Xi) do 19: if Bj is merged then 20: join all hypercubes where Bj ∈UTIL(Xi) 21: eliminate Bj from the joined hypercube 22: if P(Xi) == null (that means Xi is the root) then 23: v ∗ i ← Choose optimal(null) 24: Send VALUE(Xi, v ∗ i) to all C(Xi) 25: else 26: UTILXi (P(Xi)) ← Compute utils(P(Xi), PP(Xi)) 27: Send message(P(Xi),UTILXi (P(Xi)), BRANCHXi (P(Xi))) VALUE Message handler(VALUEXi ,P(Xi)) 28: add all Xk ← v ∗ k ∈VALUEXi ,P(Xi) to agent view 29: Xi ← v ∗ i =Choose optimal(agent view) 30: Send VALUEXl , Xi to all Xl ∈C(Xi) that in real world problems the generation of the pseudotree has a significant impact on the actual performance.",
                "The problem of finding the best pseudotree for a given DCOP instance is NP-Hard.",
                "Thus a heuristic is used for generation, and the performance of the algorithm depends on the pseudotree found by the heuristic.",
                "Some previous research focused on finding heuristics to generate good pseudotrees [8].",
                "While we have developed some heuristics that generate good cross-edged pseudotrees for use with DCPOP, our focus has been to use multiple heuristics and then select the best pseudotree from the generated pseudotrees.",
                "We consider only heuristics that run in polynomial time with respect to the number of nodes in the original DCOP instance.",
                "The actual DCPOP algorithm has worst case exponential complexity, but we can calculate the maximum message size, computation size, and sequential path cost for a given cross-edged pseudotree in linear space-time complexity.",
                "To do this, we simply run the algorithm without attempting to calculate any of the local utility hypercubes or optimal value assignments.",
                "Instead, messages include dimensional and branch information but no utility hypercubes.",
                "After each heuristic completes its generation of a pseudotree, we execute the measurement procedure and propagate the measurement information up to the chosen root in that pseudotree.",
                "The root then broadcasts the total complexity for that heuristic to all nodes.",
                "After all heuristics have had a chance to complete, every node knows which heuristic produced the best pseudotree.",
                "Each node then proceeds to begin the DCPOP algorithm using its knowledge of the pseudotree generated by the best heuristic.",
                "The heuristics used to generate traditional pseudotrees perform a distributed DFS traversal.",
                "The general distributed algorithm uses a token passing mechanism and a linear number of messages.",
                "Improved DFS based heuristics use a special procedure to choose the root node, and also provide an ordering function over the neighbors of a node to determine the order of path recursion.",
                "The DFS based heuristics used in our experiments come from the work done in [4, 8]. 5.1 The best-first cross-edged pseudotree heuristic The heuristics used to generate cross-edged pseudotrees perform a best-first traversal.",
                "A general distributed best-first algorithm for node expansion is presented in Algorithm 2.",
                "An evaluation function at each node provides the values that are used to determine the next best node to expand.",
                "Note that in this algorithm each node only exchanges its best value with its neighbors.",
                "In our experiments we used several evaluation functions that took as arguments an ordered list of ancestors and a node, which contains a list of neighbors (with each neighbors placement depth in the tree if it was placed).",
                "From these we can calculate branchparents, branch-children, and unknown relationships for a potential node placement.",
                "The best overall function calculated the value as ancestors−(branchparents+branchchildren) with the number of unknown relationships being a tiebreak.",
                "After completion each node has knowledge of its parent and ancestors, so it can easily determine which connected nodes are pseudo-parents, branchparents, pseudo-children, and branch-children.",
                "The complexity of the best-first traversal depends on the complexity of the evaluation function.",
                "Assuming a complexity of O(V ) for the evaluation function, which is the case for our best overall function, the best-first traversal is O(V · E) which is at worst O(n3 ).",
                "For each v ∈ V we perform a place operation, and find the next node to place using the getBestNeighbor operation.",
                "The place operation is at most O(V ) because of the sent messages.",
                "Finding the next node uses recursion and traverses only already placed The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 745 Algorithm 2 Distributed Best-First Search Algorithm root ← electedleader next(root, ∅) place(node, parent) node.parent ← parent node.ancestors ← parent.ancestors ∪ parent send placement message (node, node.ancestors) to all neighbors of node next(current, previous) if current is not placed then place(current, previous) next(current, ∅) else best ← getBestNeighbor(current, previous) if best = ∅ then if previous = ∅ then terminate, all nodes are placed next(previous, ∅) else next(best, current) getBestNeighbor(current, previous) best ← ∅; score ← 0 for all n ∈ current.neighbors do if n! = previous then if n is placed then nscore ← getBestNeighbor(n, current) else nscore ← evaluate(current, n) if nscore > score then score ← nscore best ← n return best, score nodes, so it has O(V ) recursions.",
                "Each recursion performs a recursive getBestNeighbor operation that traverses all placed nodes and their neighbors.",
                "This operation is O(V · E), but results can be cached using only O(V ) space at each node.",
                "Thus we have O(V ·(V +V +V ·E)) = O(V 2 ·E).",
                "If we are smart about evaluating local changes when each node receives placement messages from its neighbors and cache the results the getBestNeighbor operation is only O(E).",
                "This increases the complexity of the place operation, but for all placements the total complexity is only O(V · E).",
                "Thus we have an overall complexity of O(V ·E+V ·(V +E)) = O(V ·E). 6.",
                "COMPARISON OF COMPLEXITY IN DPOP AND DCPOP We have already shown that given the same input, DCPOP performs the same as DPOP.",
                "We also have shown that we can accurately predict performance of a given pseudotree in linear spacetime complexity.",
                "If we use a constant number of heuristics to generate the set of pseudotrees, we can choose the best pseudotree in linear space-time complexity.",
                "We will now show that there exists a DCOP instance for which a cross-edged pseudotree outperforms all possible traditional pseudotrees (based on edge-traversal heuristics).",
                "In Figure 3(a) we have a DCOP instance with six nodes.",
                "This is a bipartite graph with each partition fully connected to the other (a) (b) (c) Figure 3: (a) The DCOP instance (b) A traditional pseudotree arrangement for the DCOP instance (c) A cross-edged pseudotree arrangement for the DCOP instance partition.",
                "In Figure 3(b) we see a traditional pseudotree arrangement for this DCOP instance.",
                "It is easy to see that any edgetraversal based heuristic cannot expand two nodes from the same partition in succession.",
                "We also see that no node can have more than one child because any such arrangement would be an invalid pseudotree.",
                "Thus any traditional pseudotree arrangement for this DCOP instance must take the form of Figure 3(b).",
                "We can see that the back-edges F-B and F-A overlap node C. Node C also has a parent E, and a back-edge with D. Using the original DPOP algorithm (or DCPOP since they are identical in this case), we find that the computation at node C involves five domains: A, B, C, D, and E. In contrast, the cross-edged pseudotree arrangement in Figure 3(c) requires only a maximum of four domains in any computation during DCPOP.",
                "Since node A is the merge point for branches from both B and C, we can see that each of the nodes D, E, and F have two overlapping branches.",
                "In addition each of these nodes has node A as its parent.",
                "Using the DCPOP algorithm we find that the computation at node D (or E or F) involves four domains: A, B, C, and D (or E or F).",
                "Since no better traditional pseudotree arrangement can be created using an edge-traversal heuristic, we have shown that DCPOP can outperform DPOP even if we use the optimal pseudotree found through edge-traversal.",
                "We acknowledge that pseudotree arrangements that allow parent-child relationships without an actual constraint can solve the problem in Figure 3(a) with maximum computation size of four domains.",
                "However, current heuristics used with DPOP do not produce such pseudotrees, and such a heuristic would be difficult to distribute since each node would require information about nodes with which it has no constraint.",
                "Also, while we do not prove it here, cross-edged pseudotrees can produce smaller message sizes than such pseudotrees even if the computation size is similar.",
                "In practice, since finding the best pseudotree arrangement is NP-Hard, we find that heuristics that produce cross-edged pseudotrees often produce significantly smaller computation and message sizes. 7.",
                "EXPERIMENTAL RESULTS 746 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Existing performance metrics for DCOP algorithms include the total number of messages, synchronous clock cycles, and message size.",
                "We have already shown that the total number of messages is linear with respect to the number of constraints in the DCOP instance.",
                "We also introduced the <br>maximum sequential path cost</br> (PC) as a measurement of the maximum amount of parallelism achievable by the algorithm.",
                "The <br>maximum sequential path cost</br> is equal to the sum of the computations performed on the longest path from the root to any leaf node.",
                "We also include as metrics the maximum computation size in number of dimensions (CD) and maximum message size in number of dimensions (MD).",
                "To analyze the relative complexity of a given DCOP instance, we find the minimum induced width (IW) of any traditional pseudotree produced by a heuristic for the original DPOP. 7.1 Generic DCOP instances For our initial tests we randomly generated two sets of problems with 3000 cases in each.",
                "Each problem was generated by assigning a random number (picked from a range) of constraints to each variable.",
                "The generator then created binary constraints until each variable reached its maximum number of constraints.",
                "The first set uses 20 variables, and the best DPOP IW ranges from 1 to 16 with an average of 8.5.",
                "The second set uses 100 variables, and the best DPOP IW ranged from 2 to 68 with an average of 39.3.",
                "Since most of the problems in the second set were too complex to actually compute the solution, we took measurements of the metrics using the techniques described earlier in Section 5 without actually solving the problem.",
                "Results are shown for the first set in Table 1 and for the second set in Table 2.",
                "For the two problem sets we split the cases into low density and high density categories.",
                "Low density cases consist of those problems that have a best DPOP IW less than or equal to half of the total number of nodes (e.g.",
                "IW ≤ 10 for the 20 node problems and IW ≤ 50 for the 100 node problems).",
                "High density problems consist of the remainder of the problem sets.",
                "In both Table 1 and Table 2 we have listed performance metrics for the original DPOP algorithm, the DCPOP algorithm using only cross-edged pseudotrees (DCPOP-CE), and the DCPOP algorithm using traditional and cross-edged pseudotrees (DCPOP-All).",
                "The pseudotrees used for DPOP were generated using 5 heuristics: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB, and DFS MCN BEC.",
                "These are all versions of the guided DFS traversal discussed in Section 5.",
                "The cross-edged pseudotrees used for DCPOP-CE were generated using 5 heuristics: MCN, LCN, MCN A-B, LCN A-B, and LCSG A-B.",
                "These are all versions of the best-first traversal discussed in Section 5.",
                "For both DPOP and DCPOP-CE we chose the best pseudotree produced by their respective 5 heuristics for each problem in the set.",
                "For DCPOP-All we chose the best pseudotree produced by all 10 heuristics for each problem in the set.",
                "For the CD and MD metrics the value shown is the average number of dimensions.",
                "For the PC metric the value shown is the natural logarithm of the <br>maximum sequential path cost</br> (since the actual value grows exponentially with the complexity of the problem).",
                "The final row in both tables is a measurement of improvement of DCPOP-All over DPOP.",
                "For the CD and MD metrics the value shown is a reduction in number of dimensions.",
                "For the PC metric the value shown is a percentage reduction in the <br>maximum sequential path cost</br> (% = DP OP −DCP OP DCP OP ∗ 100).",
                "Notice that DCPOPAll outperforms DPOP on all metrics.",
                "This logically follows from our earlier assertion that given the same input, DCPOP performs exactly the same as DPOP.",
                "Thus given the choice between the pseudotrees produced by all 10 heuristics, DCPOP-All will always outLow Density High Density Algorithm CD MD PC CD MD PC DPOP 7.81 6.81 3.78 13.34 12.34 5.34 DCPOP-CE 7.94 6.73 3.74 12.83 11.43 5.07 DCPOP-All 7.62 6.49 3.66 12.72 11.36 5.05 Improvement 0.18 0.32 13% 0.62 0.98 36% Table 1: 20 node problems Low Density High Density Algorithm CD MD PC CD MD PC DPOP 33.35 32.35 14.55 58.51 57.50 19.90 DCPOP-CE 33.49 29.17 15.22 57.11 50.03 20.01 DCPOP-All 32.35 29.57 14.10 56.33 51.17 18.84 Improvement 1.00 2.78 104% 2.18 6.33 256% Table 2: 100 node problems Figure 4: Computation Dimension Size Figure 5: Message Dimension Size The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 747 Figure 6: Path Cost DCPOP Improvement Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Table 3: Meeting Scheduling Problems perform DPOP.",
                "Another trend we notice is that the improvement is greater for high density problems than low density problems.",
                "We show this trend in greater detail in Figures 4, 5, and 6.",
                "Notice how the improvement increases as the complexity of the problem increases. 7.2 Meeting Scheduling Problem In addition to our initial generic DCOP tests, we ran a series of tests on the Meeting Scheduling Problem (MSP) as described in [6].",
                "The problem setup includes a number of people that are grouped into departments.",
                "Each person must attend a specified number of meetings.",
                "Meetings can be held within departments or among departments, and can be assigned to one of eight time slots.",
                "The MSP maps to a DCOP instance where each variable represents the time slot that a specific person will attend a specific meeting.",
                "All variables that belong to the same person have mutual exclusion constraints placed so that the person cannot attend more than one meeting during the same time slot.",
                "All variables that belong to the same meeting have equality constraints so that all of the participants choose the same time slot.",
                "Unary constraints are placed on each variable to account for a persons valuation of each meeting and time slot.",
                "For our tests we generated 100 sample problems for each combination of agents and meetings.",
                "Results are shown in Table 3.",
                "The values in the first five columns represent (in left to right order), the total number of agents, the total number of meetings, the total number of variables, the average total number of constraints, and the average minimum IW produced by a traditional pseudotree.",
                "The last three columns show the same metrics we used for the generic DCOP instances, except this time we only show the improvements of DCPOP-All over DPOP.",
                "Performance is better on average for all MSP instances, but again we see larger improvements for more complex problem instances. 8.",
                "CONCLUSIONS AND FUTURE WORK We presented a complete, distributed algorithm that solves general DCOP instances using cross-edged pseudotree arrangements.",
                "Our algorithm extends the DPOP algorithm by adding additional utility propagation messages, and introducing the concept of branch merging during the utility propagation phase.",
                "Our algorithm also allows value assignments to occur at higher level merge points for lower level nodes.",
                "We have shown that DCPOP fully extends DPOP by performing the same operations given the same input.",
                "We have also shown through some examples and experimental data that DCPOP can achieve greater performance for some problem instances by extending the allowable input set to include cross-edged pseudotrees.",
                "We placed particular emphasis on the role that edge-traversal heuristics play in the generation of pseudotrees.",
                "We have shown that the performance penalty is minimal to generate multiple heuristics, and that we can choose the best generated pseudotree in linear space-time complexity.",
                "Given the importance of a good pseudotree for performance, future work will include new heuristics to find better pseudotrees.",
                "Future work will also include adapting existing DPOP extensions [5, 7] that support different problem domains for use with DCPOP. 9.",
                "REFERENCES [1] J. Liu and K. P. Sycara.",
                "Exploiting problem structure for distributed constraint optimization.",
                "In V. Lesser, editor, Proceedings of the First International Conference on Multi-Agent Systems, pages 246-254, San Francisco, CA, 1995.",
                "MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni.",
                "A dynamic distributed constraint satisfaction approach to resource allocation.",
                "Lecture Notes in Computer Science, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe, and M. Yokoo.",
                "An asynchronous complete method for distributed constraint optimization.",
                "In AAMAS 03, 2003. [4] A. Petcu.",
                "Frodo: A framework for open/distributed constraint optimization.",
                "Technical Report No. 2006/001 2006/001, Swiss Federal Institute of Technology (EPFL), Lausanne (Switzerland), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu and B. Faltings.",
                "A-dpop: Approximations in distributed optimization.",
                "In poster in CP 2005, pages 802-806, Sitges, Spain, October 2005. [6] A. Petcu and B. Faltings.",
                "Dpop: A scalable method for multiagent constraint optimization.",
                "In IJCAI 05, pages 266-271, Edinburgh, Scotland, Aug 2005. [7] A. Petcu, B. Faltings, and D. Parkes.",
                "M-dpop: Faithful distributed implementation of efficient social choice problems.",
                "In AAMAS 06, pages 1397-1404, Hakodate, Japan, May 2006. [8] G. Ushakov.",
                "Solving meeting scheduling problems using distributed pseudotree-optimization procedure.",
                "Masters thesis, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "Distributed constraint satisfaction for formalizing distributed problem solving.",
                "In International Conference on Distributed Computing Systems, pages 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "The distributed constraint satisfaction problem: Formalization and algorithms.",
                "Knowledge and Data Engineering, 10(5):673-685, 1998. 748 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "We compare our algorithm with DPOP using several metrics including the induced width of the pseudotrees, the maximum dimensionality of messages and computation, and the <br>maximum sequential path cost</br> through the algorithm.",
                "We introduce an additional measurement of the <br>maximum sequential path cost</br> through the algorithm.",
                "The <br>maximum sequential path cost</br> is equal to the sum of the longest path on each DAG from the root to any leaf node. 5.",
                "We also introduced the <br>maximum sequential path cost</br> (PC) as a measurement of the maximum amount of parallelism achievable by the algorithm.",
                "The <br>maximum sequential path cost</br> is equal to the sum of the computations performed on the longest path from the root to any leaf node."
            ],
            "translated_annotated_samples": [
                "Comparamos nuestro algoritmo con DPOP utilizando varios métricos, incluyendo el ancho inducido de los pseudobosques, la dimensionalidad máxima de los mensajes y la computación, y el <br>costo máximo de la ruta secuencial</br> a través del algoritmo.",
                "Introducimos una medida adicional del <br>costo máximo de la ruta secuencial</br> a través del algoritmo.",
                "El <br>costo máximo del camino secuencial</br> es igual a la suma del camino más largo en cada DAG desde la raíz hasta cualquier nodo hoja.",
                "También introdujimos el <br>costo de camino secuencial máximo</br> (PC) como una medida de la máxima cantidad de paralelismo alcanzable por el algoritmo.",
                "El <br>costo máximo de la ruta secuencial</br> es igual a la suma de los cálculos realizados en la ruta más larga desde la raíz hasta cualquier nodo hoja."
            ],
            "translated_text": "Un Método Completo de Optimización de Restricciones Distribuidas para Arreglos de Pseudotree No Tradicionales∗ James Atlas Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 decker@cis.udel.edu RESUMEN La Optimización de Restricciones Distribuidas (DCOP) es un marco general que puede modelar problemas complejos en sistemas multiagente. Varios algoritmos actuales que resuelven instancias generales de DCOP, incluyendo ADOPT y DPOP, organizan a los agentes en una estructura de pseudobosque tradicional. Introducimos una extensión al algoritmo DPOP que maneja un conjunto extendido de disposiciones de pseudobosque. Nuestro algoritmo resuelve correctamente instancias de DCOP para pseudobosques que incluyen aristas entre nodos en ramas separadas. El algoritmo también resuelve instancias con arreglos de pseudobosque tradicionales utilizando el mismo procedimiento que DPOP. Comparamos nuestro algoritmo con DPOP utilizando varios métricos, incluyendo el ancho inducido de los pseudobosques, la dimensionalidad máxima de los mensajes y la computación, y el <br>costo máximo de la ruta secuencial</br> a través del algoritmo. Demostramos que para algunas instancias del problema no es posible generar un pseudoárbol tradicional utilizando heurísticas de recorrido de aristas que supere a un pseudoárbol con aristas cruzadas. Utilizamos múltiples heurísticas para generar pseudoárboles y elegir el mejor pseudoárbol en complejidad espacio-temporal lineal. Para algunas instancias del problema observamos mejoras significativas en los tamaños de los mensajes y cálculos en comparación con DPOP. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Algoritmos 1. INTRODUCCIÓN Muchos problemas históricos en la comunidad de IA pueden transformarse en Problemas de Satisfacción de Restricciones (CSP). Con la llegada de la inteligencia artificial distribuida, los sistemas multiagente se convirtieron en una forma popular de modelar las interacciones complejas y la coordinación necesaria para resolver problemas distribuidos. Los CSPs fueron originalmente extendidos a entornos de agentes distribuidos en [9]. Los primeros dominios para problemas de satisfacción de restricciones distribuidas (DisCSP) incluyeron la programación de talleres de trabajo [1] y la asignación de recursos [2]. Muchos dominios para sistemas de agentes, especialmente coordinación de trabajo en equipo, programación distribuida y redes de sensores, implican problemas excesivamente restringidos que son difíciles o imposibles de satisfacer para cada restricción. Los enfoques recientes para resolver problemas en estos dominios se basan en técnicas de optimización que mapean restricciones en funciones de utilidad multivaluadas. En lugar de encontrar una asignación que satisfaga todas las restricciones, estos enfoques encuentran una asignación que produce un alto nivel de utilidad global. Esta extensión al enfoque original de DisCSP se ha vuelto popular en sistemas multiagente, y ha sido etiquetada como Problema de Optimización de Restricciones Distribuidas (DCOP) [1]. Los algoritmos actuales que resuelven DCOPs completos utilizan dos enfoques principales: búsqueda y programación dinámica. Los algoritmos basados en búsqueda que se originaron a partir de DisCSP típicamente utilizan alguna forma de retroceso [10] o propagación de límites, como en ADOPT [3]. Los algoritmos basados en programación dinámica incluyen DPOP y sus extensiones [5, 6, 7]. Hasta la fecha, ambas categorías de algoritmos organizan agentes en un pseudoárbol tradicional para resolver el problema. Se ha demostrado en [6] que cualquier grafo de restricciones puede ser mapeado en un pseudoárbol tradicional. Sin embargo, también se demostró que encontrar el pseudoárbol óptimo era NP-Difícil. Comenzamos a investigar el rendimiento de los pseudobosques tradicionales generados por las heurísticas actuales de recorrido de aristas. Descubrimos que estas heurísticas a menudo generaban poco paralelismo, ya que los pseudárboles tendían a tener una gran profundidad y bajos factores de ramificación. Sospechábamos que podría haber otras formas de organizar los pseudobosques que proporcionarían un mayor paralelismo y tamaños de mensaje más pequeños. Después de explorar estos otros arreglos, descubrimos que los pseudobosques de bordes cruzados proporcionan profundidades más cortas y factores de ramificación más altos que los pseudobosques tradicionales. Nuestra hipótesis era que estos pseudorboles cruzados superarían a los pseudorboles tradicionales en algunos tipos de problemas. En este artículo presentamos una extensión al algoritmo DPOP que maneja un conjunto ampliado de disposiciones de pseudobosque que incluyen pseudobosques con aristas cruzadas. Comenzamos con una definición de 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, pseudobosques tradicionales y pseudobosques de bordes cruzados. Luego proporcionamos un resumen del algoritmo DPOP original e introducimos nuestro algoritmo DCPOP. Discutimos la complejidad de nuestro algoritmo, así como el impacto de las heurísticas de generación de pseudobosques. Luego demostramos que nuestro Procedimiento de Optimización de Pseudotree de Bordes Cruzados Distribuido (DCPOP) funciona significativamente mejor en la práctica que el algoritmo DPOP original para algunas instancias del problema. Concluimos con una selección de ideas para trabajos futuros y extensiones para DCPOP. 2. La DEFINICIÓN DEL PROBLEMA DCOP ha sido formalizada de maneras ligeramente diferentes en la literatura reciente, por lo que adoptaremos la definición presentada en [6]. Un Problema de Optimización de Restricciones Distribuidas con n nodos y m restricciones consiste en la tupla < X, D, U > donde: • X = {x1,..,xn} es un conjunto de variables, cada una asignada a un agente único • D = {d1,..,dn} es un conjunto de dominios finitos para cada variable • U = {u1,..,um} es un conjunto de funciones de utilidad tales que cada función involucra un subconjunto de variables en X y define una utilidad para cada combinación de valores entre estas variables. Una solución óptima para una instancia de DCOP consiste en una asignación de valores en D a X tal que la suma de las utilidades en U sea máxima. Los dominios de problemas que requieren un costo mínimo en lugar de una utilidad máxima pueden mapear los costos en utilidades negativas. Las funciones de utilidad representan restricciones suaves pero también pueden representar restricciones fuertes mediante el uso de valores negativos arbitrariamente grandes. Para este artículo solo consideramos funciones de utilidad binarias que involucran dos variables. Las funciones de utilidad de orden superior pueden ser modeladas con cambios menores en el algoritmo, pero también aumentan sustancialmente la complejidad. 2.1 Pseudárboles Tradicionales Los pseudárboles son una estructura común utilizada en procedimientos de búsqueda para permitir el procesamiento paralelo de ramas independientes. Como se define en [6], un pseudoárbol es un arreglo de un grafo G en un árbol raíz T de tal manera que los vértices en G que comparten una arista están en la misma rama en T. Una arista de retroceso es una arista entre un nodo X y cualquier nodo que se encuentre en el camino desde X hasta la raíz (excluyendo al padre de X). La Figura 1 muestra un pseudoárbol con cuatro nodos, tres aristas (A-B, B-C, BD) y una arista de retroceso (A-C). También se definen en [6] cuatro tipos de relaciones entre nodos que existen en un pseudoárbol: • P(X) - el padre de un nodo X: el único nodo más alto en el pseudoárbol que está conectado a X directamente a través de un borde de árbol • C(X) - los hijos de un nodo X: el conjunto de nodos más bajos en el pseudo Las líneas sólidas representan relaciones padre-hijo y la línea discontinua representa una relación pseudo-padre-pseudo-hijo. Figura 2: Un pseudoárbol de bordes cruzados. Las líneas sólidas representan relaciones padre-hijo, la línea discontinua representa una relación pseudo-padre-pseudo-hijo, y la línea punteada representa una relación rama-padre-rama-hijo. El nodo en negrita, B, es el punto de fusión para el nodo E. 2.2 Pseudárboles con aristas cruzadas Definimos una arista cruzada como una arista de un nodo X a un nodo Y que está por encima de X pero no en el camino desde X hasta la raíz. Un pseudoárbol de bordes cruzados es un pseudoárbol tradicional con la adición de bordes cruzados. La Figura 2 muestra un pseudoárbol con una arista cruzada (D-E). En un pseudoárbol de bordes cruzados designamos ciertos bordes como primarios. El conjunto de aristas primarias define un árbol de expansión de los nodos. Las relaciones de padre, hijo, pseudo-padre y pseudo-hijo del pseudotree tradicional ahora están definidas en el contexto de este árbol de expansión de borde primario. Esta definición también produce dos tipos adicionales de relaciones que pueden existir entre nodos: • BP(X) - los nodos padres de rama de un nodo X: el conjunto de nodos más altos en el pseudoárbol que están conectados a X pero no están en el camino principal desde X hasta la raíz (En la Figura 2, D = BP(E)) • BC(X) - los nodos hijos de rama de un nodo X: el conjunto de nodos más bajos en el pseudo La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Los algoritmos actuales suelen tener una fase de pre-ejecución para generar un pseudoárbol tradicional a partir de una instancia general de DCOP. Nuestro algoritmo DCPOP genera un pseudoárbol de bordes cruzados de la misma manera. Primero, la instancia DCOP < X, D, U > se traduce directamente en un grafo con X como el conjunto de vértices y una arista para cada par de variables representadas en U. A continuación, se utilizan varias heurísticas para organizar este grafo en un pseudoárbol. Un heurístico común es realizar una búsqueda en profundidad guiada (DFS, por sus siglas en inglés) ya que el recorrido resultante es un pseudoárbol, y un DFS se puede realizar fácilmente de manera distribuida. Definimos un método basado en el recorrido de aristas como cualquier método que produce un pseudoárbol en el que todos los pares padre/hijo comparten una arista en el grafo original. Esto incluye recorridos basados en DFS, búsqueda en anchura y búsqueda de mejor primero. Nuestras heurísticas que generan pseudobosques de bordes cruzados utilizan un recorrido de búsqueda mejor primero distribuido. 3. ALGORITMO DPOP El algoritmo DPOP original opera en tres fases principales. La primera fase genera un pseudoárbol tradicional a partir de la instancia de DCOP utilizando un algoritmo distribuido. La segunda fase une hipercubos de utilidad de los nodos hijos y el nodo local y los propaga hacia la raíz. La tercera fase elige una asignación para cada dominio de arriba hacia abajo, comenzando con el agente en el nodo raíz. La complejidad de DPOP depende del tamaño del cálculo más grande y del mensaje de utilidad durante la fase dos. Se ha demostrado que este tamaño corresponde directamente al ancho inducido del pseudoárbol generado en la fase uno [6]. DPOP utiliza heurísticas de tiempo polinómico para generar el pseudoárbol, ya que encontrar el pseudoárbol de ancho inducido mínimo es NP-duro. Se han desarrollado varias heurísticas de recorrido de borde distribuido para encontrar pseudobosques de ancho reducido [8]. Al final de la primera fase, cada agente conoce a su padre, hijos, pseudo-padres y pseudo-hijos. 3.1 Propagación de utilidad Los agentes ubicados en los nodos hoja del pseudoárbol comienzan el proceso calculando un hipercubo de utilidad local. Este hipercubo en el nodo X contiene las utilidades sumadas para cada combinación de valores en los dominios de P(X) y PP(X). Este hipercubo tiene un tamaño dimensional igual al número de pseudo-padres más uno. Un mensaje que contiene este hipercubo se envía a P(X). Los agentes ubicados en nodos no hoja esperan a que lleguen todos los mensajes de los nodos hijos. Una vez que el agente en el nodo Y tiene todos los mensajes de utilidad, calcula su hipercubo de utilidad local que incluye los dominios de P(Y), PP(Y) y Y. El hipercubo de utilidad local se une luego con todos los hipercubos de los mensajes hijos. En este punto, todas las utilidades que involucran al nodo Y son conocidas, y el dominio de Y puede ser eliminado de forma segura del hipercubo unido. Este proceso de eliminación elige la mejor utilidad sobre el dominio de Y para cada combinación de los dominios restantes. Un mensaje que contiene este hipercubo se envía ahora a P(Y). El tamaño dimensional de este hipercubo depende del número de dominios superpuestos en los mensajes recibidos y del hipercubo de utilidad local. Esta fase de propagación basada en programación dinámica continúa hasta que el agente en el nodo raíz del pseudoárbol haya recibido todos los mensajes de sus hijos. 3.2 Propagación de Valor La propagación de valor comienza cuando el agente en el nodo raíz Z ha recibido todos los mensajes de sus hijos. Dado que Z no tiene padres ni pseudo-padres, simplemente combina los hipercubos de utilidad recibidos de sus hijos. El hipercubo combinado contiene solo valores para el dominio de Z. En este punto, el agente en el nodo Z simplemente elige la asignación para su dominio que tiene la mejor utilidad. Un mensaje de propagación de valor con esta asignación se envía a cada nodo en C(Z). Cada nodo luego recibe un mensaje de propagación de valor de su padre y elige la asignación para su dominio que tenga la mejor utilidad dadas las asignaciones recibidas en el mensaje. El nodo agrega su asignación de dominio a las asignaciones que recibió y pasa el conjunto de asignaciones a sus hijos. El algoritmo está completo cuando todos los nodos han elegido una asignación para su dominio. ALGORITMO DCPOP Nuestra extensión al algoritmo DPOP original, mostrada en el Algoritmo 1, comparte las mismas tres fases. La primera fase genera el pseudoárbol de bordes cruzados para la instancia de DCOP. La segunda fase fusiona ramas y propaga los hipercubos de utilidad. La tercera fase elige asignaciones para dominios en los puntos de fusión de ramas y de arriba hacia abajo, comenzando con el agente en el nodo raíz. Para la primera fase generamos un pseudoárbol utilizando varios heurísticos distribuidos y seleccionamos el que tenga la menor complejidad general. La complejidad de la computación y el tamaño del mensaje de utilidad en DCPOP no corresponden directamente al ancho inducido del pseudoárbol de aristas cruzadas. En cambio, utilizamos un método de tiempo polinómico para calcular el tamaño máximo de computación y utilidad del mensaje para un pseudoárbol de bordes cruzados dado. Una descripción de este método y el proceso de selección de pseudodendrogramas aparece en la Sección 5. Al final de la primera fase, cada agente conoce a su padre, hijos, pseudo-padres, pseudo-hijos, padres de rama e hijos de rama. 4.1 Fusión de Ramas y Propagación de Utilidad En el algoritmo DPOP original, un nodo X solo tenía funciones de utilidad que involucraban a su padre y a sus pseudo-padres. En DCPOP, se permite que un nodo X tenga una función de utilidad que involucre a un padre de rama. El concepto de una rama se puede ver en la Figura 2 con el nodo E representando nuestro nodo X. Las dos rutas distintas desde el nodo E hasta el nodo B se llaman ramas de E. El único nodo donde se encuentran todas las ramas de E es el nodo B, que se llama punto de fusión de E. Los agentes con nodos que tienen padres de rama comienzan enviando un mensaje de propagación de utilidad a cada padre de rama. Este mensaje incluye un hipercubo de utilidad bidimensional con dominios para el nodo X y el nodo padre de la rama BP(X). También incluye una estructura de información de rama que contiene el nodo de origen de la rama, X, el número total de ramas que se originan en X y el número de ramas que se originan en X y se fusionan en una representación única por esta estructura de información de rama (este número comienza en 1). Intuitivamente, cuando el número de ramas fusionadas es igual al número total de ramas originales, el algoritmo ha alcanzado el punto de fusión para X. En la Figura 2, el nodo E envía un mensaje de propagación de utilidad a su nodo padre de rama, el nodo D. Este mensaje tiene dimensiones para los dominios de E y D, e incluye información de rama con un origen en E, 2 ramas totales y 1 rama fusionada. Como en la fase de propagación de utilidad de la utilidad DPOP original, un agente en el nodo hoja X envía un mensaje de propagación de utilidad a su padre. En DCPOP, este mensaje contiene dimensiones para los dominios de P(X) y PP(X). Si el nodo X también tiene padres de rama, entonces el mensaje de propagación de utilidad también contiene una dimensión para el dominio de X e incluirá una estructura de información de rama. En la Figura 2, el nodo E envía un mensaje de propagación de utilidad a su padre, el nodo C. Este mensaje tiene dimensiones para los dominios de E y C, e incluye información de rama con un origen en E, 2 ramas en total y 1 rama fusionada. Cuando un nodo Y recibe mensajes de propagación de utilidad de todos de The Sixth Intl. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), 743 sus hijos y sus hijos de rama, fusiona cualquier rama con el mismo nodo de origen X. La estructura de información de la rama fusionada acumula el número de ramas fusionadas para X. Si el número total acumulado de ramas fusionadas es igual al número total de ramas, entonces Y es el punto de fusión para X. Esto significa que los hipercubos de utilidad presentes en Y contienen toda la información sobre las valoraciones de las funciones de utilidad que involucran al nodo X. Además de la eliminación típica del dominio de Y de los hipercubos de utilidad, ahora podemos eliminar de forma segura el dominio de X de los hipercubos de utilidad. Para ilustrar este proceso, examinaremos lo que sucede en la segunda fase para el nodo B en la Figura 2. En la segunda fase, el Nodo B recibe dos mensajes de propagación de utilidad. El primero proviene del nodo C e incluye dimensiones para los dominios E, B y A. También tiene una estructura de información de ramas con origen en E, 2 ramas en total y 1 rama fusionada. El segundo proviene del nodo D e incluye dimensiones para los dominios E y B. También tiene una estructura de información de rama con origen en E, 2 ramas en total y 1 rama fusionada. El nodo B luego fusiona las estructuras de información de rama de ambos mensajes porque tienen la misma procedencia, el nodo E. Dado que el número de ramas fusionadas que provienen de E es ahora 2 y el total de ramas que provienen de E es 2, el nodo B elimina las dimensiones para el dominio E. El nodo B también elimina la dimensión para su propio dominio, dejando solo información sobre el dominio A. Luego, el nodo B envía un mensaje de propagación de utilidad al nodo A, que contiene solo una dimensión para el dominio de A. Aunque no sea posible en DPOP, este método de propagación de utilidad y eliminación de dimensiones puede producir hipercubos en el nodo Y que no comparten ningún dominio. En DCPOP no unimos hipercubos independientes de dominio, sino que en su lugar podemos enviar múltiples hipercubos en el mensaje de propagación de utilidad enviado al padre de Y. Este enfoque perezoso de las uniones ayuda a reducir el tamaño de los mensajes. 4.2 Propagación de valores Al igual que en DPOP, la propagación de valores comienza cuando el agente en el nodo raíz Z ha recibido todos los mensajes de sus hijos. En este punto, el agente en el nodo Z elige la asignación para su dominio que tiene la mejor utilidad. Si Z es el punto de fusión de las ramas de algún nodo X, Z también elegirá la asignación para el dominio de X. Por lo tanto, cualquier nodo que sea un punto de fusión elegirá asignaciones para un dominio que no sea el suyo propio. Estas tareas luego se pasan por la jerarquía de la cadena de mando principal. Si el nodo X en la jerarquía tiene padres de rama, entonces el mensaje de asignación de valor de P(X) contendrá una asignación para el dominio de X. Cada nodo en la jerarquía agrega cualquier tarea que haya elegido a las que recibió y pasa el conjunto de tareas a sus hijos. El algoritmo está completo cuando todos los nodos han elegido o recibido una asignación para su dominio. 4.3 Prueba de Corrección Demostraremos la corrección de DCPOP notando primero que DCPOP extiende completamente DPOP y luego examinando los dos casos para la asignación de valores en DCPOP. Dado un pseudoárbol tradicional como entrada, la ejecución del algoritmo DCPOP es idéntica a DPOP. Usando un arreglo de pseudodendrograma tradicional, ningún nodo tiene padres de rama o hijos de rama, ya que todas las aristas son aristas de retroceso o aristas de árbol. Por lo tanto, el algoritmo DCPOP utilizando un pseudoárbol tradicional envía solo mensajes de propagación de utilidad que contienen dominios pertenecientes al padre o pseudo-padres de un nodo. Dado que ningún nodo tiene ramas-padres, no existen ramas, y por lo tanto ningún nodo sirve como punto de fusión para ningún otro nodo. Por lo tanto, todas las asignaciones de propagación de valor se eligen en el nodo del dominio de la asignación. Para la ejecución de DCPOP con pseudárboles de bordes cruzados, algunos nodos actúan como puntos de fusión. Observamos que cualquier nodo X que no sea un punto de fusión asigna su valor exactamente como en DPOP. El hipercubo de utilidad local en X contiene dominios para X, P(X), PP(X) y BC(X). Como en DPOP, el mensaje de asignación de valores recibido en X incluye los valores asignados a P(X) y PP(X). Además, dado que X no es un punto de fusión, todas las asignaciones a BC(X) deben haber sido calculadas en puntos de fusión más altos en el árbol y están en el mensaje de asignación de valor de P(X). Por lo tanto, después de eliminar los dominios para los cuales se conocen las asignaciones, solo queda el dominio de X. El agente en el nodo X ahora puede elegir correctamente la asignación con la máxima utilidad para su propio dominio. Si el nodo X es un punto de fusión para alguna rama-hijo Y, sabemos que X debe ser un nodo a lo largo del camino desde Y hasta la raíz, y desde P(Y) y todos los BP(Y) hasta la raíz. A partir del algoritmo, sabemos que Y necesariamente tiene toda la información de C(Y), PC(Y) y BC(Y) ya que espera sus mensajes. El nodo X tiene información sobre todos los nodos debajo de él en el árbol, lo cual incluiría a Y, P(Y), BP(Y) y aquellos PP(Y) que están debajo de X en el árbol. Para cualquier PP(Y) por encima de X en el árbol, X recibe la asignación para el dominio de PP(Y) en el mensaje de asignación de valor de P(X). Por lo tanto, X tiene información de utilidad sobre todas las funciones de utilidad de las cuales Y forma parte. Al eliminar los dominios incluidos en el mensaje de asignación de valor, el nodo X se queda con un hipercubo de utilidad local con dominios para X e Y. El agente en el nodo X ahora puede elegir correctamente las asignaciones con la máxima utilidad para los dominios de X e Y. 4.4 Análisis de complejidad La primera fase de DCPOP envía un mensaje a cada P(X), PP(X) y BP(X). La segunda fase envía un mensaje de asignación de valor a cada C(X). Por lo tanto, DCPOP produce un número lineal de mensajes con respecto al número de aristas (funciones de utilidad) en el pseudoárbol de aristas cruzadas y la instancia original de DCOP. La complejidad real de DCPOP depende de dos medidas adicionales: el tamaño del mensaje y el tamaño de la computación. El tamaño del mensaje y el tamaño de la computación en DCPOP dependen del número de ramas superpuestas, así como del número de aristas de retroceso superpuestas. Se demostró en [6] que el número de aristas traslapadas es igual al ancho inducido del pseudoárbol. En un pseudoárbol de bordes cruzados mal construido, el número de ramas superpuestas en el nodo X puede ser tan grande como el número total de descendientes de X. Por lo tanto, el tamaño total del mensaje en DCPOP en una instancia mal construida puede ser exponencial en el espacio en el número total de nodos en el grafo. Sin embargo, en la práctica, un pseudoárbol bien construido con bordes cruzados puede lograr resultados mucho mejores. Más tarde abordaremos el tema de elegir pseudobosques cruzados bien construidos de un conjunto. Introducimos una medida adicional del <br>costo máximo de la ruta secuencial</br> a través del algoritmo. Esta medida se relaciona directamente con la cantidad máxima de paralelismo que puede lograr el algoritmo. Para tomar esta medida, primero almacenamos el tamaño total de cálculo para cada nodo durante las fases dos y tres. Este tamaño de cálculo representa el número de accesos individuales a un valor en un hipercubo en cada nodo. Por ejemplo, una unión entre dos dominios de tamaño 4 cuesta 4 ∗ 4 = 16. Dos grafos acíclicos dirigidos (DAG) pueden ser dibujados; uno con los mensajes de propagación de utilidad como aristas y los costos de la fase dos en los nodos, y el otro con los mensajes de asignación de valor y los costos de la fase tres en los nodos. El <br>costo máximo del camino secuencial</br> es igual a la suma del camino más largo en cada DAG desde la raíz hasta cualquier nodo hoja. HEURÍSTICAS En nuestra evaluación de la complejidad en DCPOP nos enfocamos en el peor caso posiblemente producido por el algoritmo. Reconocemos 744 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Algoritmo 1 DCPOP Algoritmo 1: DCPOP(X; D; U) Cada agente Xi ejecuta: Fase 1: creación de pseudotree 2: elegir líder de todos los Xj ∈ X 3: líder elegido inicia la creación de pseudotree 4: después, Xi conoce P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) y PC(Xi) Fase 2: propagación de mensajes UTIL 5: si |BP(Xi)| > 0 entonces 6: BRANCHXi ← |BP(Xi)| + 1 7: para todos Xk ∈BP(Xi) hacer 8: UTILXi (Xk) ← Calcular utils(Xi, Xk) 9: Enviar mensaje(Xk,UTILXi (Xk),BRANCHXi ) 10: si |C(Xi)| = 0 (es decir, Si Xi es un nodo hoja, entonces 11: UTILXi (P(Xi)) ← Calcular utils(P(Xi),PP(Xi)) para todos los PP(Xi) 12: Enviar mensaje(P(Xi), UTILXi (P(Xi)), BRANCHXi ) 13: Enviar mensaje(PP(Xi), UTIL vacío, BRANCH vacío) a todos los PP(Xi) 14: Activar el manejador de mensajes UTIL() Fase 3: Propagación de mensajes de VALOR 15: Activar el manejador de mensajes de VALOR() FIN ALGORITMO Manejador de mensajes UTIL(Xk, UTILXk (Xi), BRANCHXk ) 16: Almacenar UTILXk (Xi), BRANCHXk (Xi) 17: Si han llegado mensajes UTIL de todos los hijos y los hijos de la rama, entonces 18: Para todos los Bj ∈ BRANCH(Xi) hacer 19: Si Bj está fusionado, entonces 20: Unir todos los hipercubos donde Bj ∈ UTIL(Xi) 21: Eliminar Bj del hipercubo unido 22: Si P(Xi) == nulo (eso significa que Xi es la raíz) entonces 23: v ∗ i ← Elegir óptimo(nulo) 24: Enviar VALOR(Xi, v ∗ i) a todos los C(Xi) 25: De lo contrario 26: UTILXi (P(Xi)) ← Calcular utils(P(Xi), PP(Xi)) 27: Enviar mensaje(P(Xi), UTILXi (P(Xi)), BRANCHXi (P(Xi))) Manejador de mensajes de VALOR(VALORXi , P(Xi)) 28: Agregar todos los Xk ← v ∗ k ∈ VALORXi , P(Xi) a la vista del agente 29: Xi ← v ∗ i = Elegir óptimo(vista del agente) 30: Enviar VALORXl , Xi a todos los Xl ∈ C(Xi) que en problemas del mundo real la generación del pseudoárbol tiene un impacto significativo en el rendimiento real. El problema de encontrar la mejor pseudotree para una instancia de DCOP dada es NP-Difícil. Por lo tanto, se utiliza una heurística para la generación, y el rendimiento del algoritmo depende del pseudoárbol encontrado por la heurística. Algunas investigaciones previas se centraron en encontrar heurísticas para generar buenas pseudorboles [8]. Si bien hemos desarrollado algunas heurísticas que generan buenos pseudoárboles cruzados para usar con DCPOP, nuestro enfoque ha sido utilizar múltiples heurísticas y luego seleccionar el mejor pseudo Consideramos solo heurísticas que se ejecuten en tiempo polinómico con respecto al número de nodos en la instancia original del DCOP. El algoritmo DCPOP actual tiene una complejidad exponencial en el peor de los casos, pero podemos calcular el tamaño máximo del mensaje, el tamaño de la computación y el costo de la ruta secuencial para un pseudoárbol de bordes cruzados dado en complejidad espacio-temporal lineal. Para hacer esto, simplemente ejecutamos el algoritmo sin intentar calcular ninguno de los hipercubos de utilidad local o asignaciones de valor óptimo. En cambio, los mensajes incluyen información dimensional y de ramificación pero no hipercubos de utilidad. Después de que cada heurística complete la generación de un pseudoárbol, ejecutamos el procedimiento de medición y propagamos la información de la medición hasta la raíz elegida en ese pseudo La raíz luego transmite la complejidad total de esa heurística a todos los nodos. Después de que todas las heurísticas hayan tenido la oportunidad de completarse, cada nodo sabe qué heurística produjo el mejor pseudoárbol. Cada nodo luego procede a comenzar el algoritmo DCPOP utilizando su conocimiento del pseudoárbol generado por la mejor heurística. Las heurísticas utilizadas para generar pseudárboles tradicionales realizan un recorrido DFS distribuido. El algoritmo distribuido general utiliza un mecanismo de paso de token y un número lineal de mensajes. Las heurísticas mejoradas basadas en DFS utilizan un procedimiento especial para elegir el nodo raíz, y también proporcionan una función de ordenación sobre los vecinos de un nodo para determinar el orden de la recursión de caminos. Las heurísticas basadas en DFS utilizadas en nuestros experimentos provienen del trabajo realizado en [4, 8]. 5.1 La heurística de pseudotree cruzado de mejor primer recorrido. Las heurísticas utilizadas para generar pseudárboles cruzados realizan un recorrido de mejor primer recorrido. Se presenta un algoritmo general distribuido de mejor primero para la expansión de nodos en el Algoritmo 2. Una función de evaluación en cada nodo proporciona los valores que se utilizan para determinar el siguiente mejor nodo a expandir. Ten en cuenta que en este algoritmo cada nodo solo intercambia su mejor valor con sus vecinos. En nuestros experimentos utilizamos varias funciones de evaluación que tomaban como argumentos una lista ordenada de ancestros y un nodo, que contiene una lista de vecinos (con la profundidad de colocación de cada vecino en el árbol). A partir de estos podemos calcular los padres de la rama, los hijos de la rama y las relaciones desconocidas para una posible ubicación del nodo. La mejor función general calculó el valor como ancestros - (padres de rama + hijos de rama) con el número de relaciones desconocidas como criterio de desempate. Después de completarse, cada nodo tiene conocimiento de su padre y ancestros, por lo que puede determinar fácilmente qué nodos conectados son pseudo-padres, padres de rama, pseudo-hijos e hijos de rama. La complejidad de la travesía de mejor primero depende de la complejidad de la función de evaluación. Suponiendo una complejidad de O(V) para la función de evaluación, que es el caso de nuestra mejor función general, el recorrido de mejor primero es O(V · E), lo que en el peor de los casos es O(n3). Para cada v ∈ V realizamos una operación de colocación y encontramos el siguiente nodo a colocar usando la operación getBestNeighbor. La complejidad de la operación del lugar es a lo sumo O(V) debido a los mensajes enviados. Encontrar el siguiente nodo utiliza recursión y recorre solo los ya colocados The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 745 Algoritmo 2 Algoritmo de Búsqueda Distribuida de Mejor Primero root ← líder elegido next(root, ∅) place(nodo, padre) nodo.padre ← padre nodo.ancestros ← padre.ancestros ∪ padre enviar mensaje de ubicación (nodo, nodo.ancestros) a todos los vecinos de nodo next(actual, anterior) si actual no está ubicado entonces place(actual, anterior) next(actual, ∅) else mejor ← obtenerMejorVecino(actual, anterior) si mejor = ∅ entonces si anterior = ∅ entonces terminar, todos los nodos están ubicados next(anterior, ∅) else next(mejor, actual) obtenerMejorVecino(actual, anterior) mejor ← ∅; puntaje ← 0 para todo n ∈ vecinos de actual hacer si n! = anterior entonces si n está ubicado entonces puntajeN ← obtenerMejorVecino(n, actual) else puntajeN ← evaluar(actual, n) si puntajeN > puntaje entonces puntaje ← puntajeN mejor ← n return mejor, puntaje nodos, por lo que tiene O(V) recursiones. Cada recursión realiza una operación recursiva getBestNeighbor que recorre todos los nodos colocados y sus vecinos. Esta operación es O(V · E), pero los resultados se pueden almacenar en caché utilizando solo O(V) espacio en cada nodo. Así que tenemos O(V ·(V +V +V ·E)) = O(V 2 ·E). Si somos inteligentes al evaluar los cambios locales cuando cada nodo recibe mensajes de ubicación de sus vecinos y almacenamos en caché los resultados, la operación getBestNeighbor es solo O(E). Esto aumenta la complejidad de la operación de ubicación, pero para todas las ubicaciones la complejidad total es solo O(V · E). Por lo tanto, tenemos una complejidad general de O(V ·E+V ·(V +E)) = O(V ·E). 6. COMPARACIÓN DE COMPLEJIDAD EN DPOP Y DCPOP Ya hemos demostrado que, dado el mismo input, DCPOP se desempeña igual que DPOP. También hemos demostrado que podemos predecir con precisión el rendimiento de un pseudoárbol dado en complejidad temporal lineal. Si usamos un número constante de heurísticas para generar el conjunto de pseudobosques, podemos elegir el mejor pseudobosque con complejidad lineal en espacio y tiempo. Ahora demostraremos que existe una instancia de DCOP para la cual un pseudoárbol de bordes cruzados supera a todos los posibles pseudoárboles tradicionales (basados en heurísticas de recorrido de bordes). En la Figura 3(a) tenemos una instancia de DCOP con seis nodos. Este es un grafo bipartito con cada partición completamente conectada a la otra (a) (b) (c) Figura 3: (a) La instancia de DCOP (b) Un arreglo de pseudobosque tradicional para la instancia de DCOP (c) Un arreglo de pseudobosque con aristas cruzadas para la partición de la instancia de DCOP. En la Figura 3(b) vemos un arreglo tradicional de pseudotree para esta instancia de DCOP. Es fácil ver que cualquier heurística basada en el recorrido de aristas no puede expandir dos nodos de la misma partición sucesivamente. También observamos que ningún nodo puede tener más de un hijo porque cualquier disposición de este tipo sería un pseudoárbol inválido. Por lo tanto, cualquier disposición tradicional de pseudodendrograma para esta instancia de DCOP debe tener la forma de la Figura 3(b). Podemos ver que las aristas de retroceso F-B y F-A se superponen al nodo C. El nodo C también tiene un padre E y una arista de retroceso con D. Utilizando el algoritmo DPOP original (o DCPOP ya que son idénticos en este caso), encontramos que el cálculo en el nodo C implica cinco dominios: A, B, C, D y E. En contraste, el arreglo de pseudonodos con aristas cruzadas en la Figura 3(c) requiere un máximo de cuatro dominios en cualquier cálculo durante DCPOP. Dado que el nodo A es el punto de fusión de las ramas tanto de B como de C, podemos ver que cada uno de los nodos D, E y F tiene dos ramas superpuestas. Además, cada uno de estos nodos tiene al nodo A como su padre. Usando el algoritmo DCPOP, encontramos que el cálculo en el nodo D (o E o F) implica cuatro dominios: A, B, C y D (o E o F). Dado que no se puede crear una disposición de pseudobosque tradicional mejor utilizando una heurística de recorrido de aristas, hemos demostrado que DCPOP puede superar a DPOP incluso si utilizamos el pseudobosque óptimo encontrado a través del recorrido de aristas. Reconocemos que los arreglos de pseudodistribución de árboles que permiten relaciones padre-hijo sin una restricción real pueden resolver el problema en la Figura 3(a) con un tamaño de cálculo máximo de cuatro dominios. Sin embargo, las heurísticas actuales utilizadas con DPOP no producen tales pseudobosques, y sería difícil distribuir una heurística así, ya que cada nodo requeriría información sobre nodos con los que no tiene restricciones. Además, aunque no lo demostramos aquí, los pseudobosques de bordes cruzados pueden producir tamaños de mensaje más pequeños que tales pseudobosques, incluso si el tamaño de la computación es similar. En la práctica, dado que encontrar la mejor disposición de pseudoramas es NP-Difícil, observamos que las heurísticas que producen pseudoramas con aristas cruzadas a menudo generan tamaños de cálculo y mensajes significativamente más pequeños. 7. RESULTADOS EXPERIMENTALES 746 El Sexto Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Los métricos de rendimiento existentes para algoritmos DCOP incluyen el número total de mensajes, ciclos de reloj síncronos y tamaño de mensaje. Ya hemos demostrado que el número total de mensajes es lineal con respecto al número de restricciones en la instancia de DCOP. También introdujimos el <br>costo de camino secuencial máximo</br> (PC) como una medida de la máxima cantidad de paralelismo alcanzable por el algoritmo. El <br>costo máximo de la ruta secuencial</br> es igual a la suma de los cálculos realizados en la ruta más larga desde la raíz hasta cualquier nodo hoja. ",
            "candidates": [],
            "error": [
                [
                    "costo máximo de la ruta secuencial",
                    "costo máximo de la ruta secuencial",
                    "costo máximo del camino secuencial",
                    "costo de camino secuencial máximo",
                    "costo máximo de la ruta secuencial"
                ]
            ]
        },
        "edge-traversal heuristic": {
            "translated_key": "heurística de recorrido de aristas",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Complete Distributed Constraint Optimization Method For Non-Traditional Pseudotree Arrangements∗ James Atlas Computer and Information Sciences University of Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Computer and Information Sciences University of Delaware Newark, DE 19716 decker@cis.udel.edu ABSTRACT Distributed Constraint Optimization (DCOP) is a general framework that can model complex problems in multi-agent systems.",
                "Several current algorithms that solve general DCOP instances, including ADOPT and DPOP, arrange agents into a traditional pseudotree structure.",
                "We introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements.",
                "Our algorithm correctly solves DCOP instances for pseudotrees that include edges between nodes in separate branches.",
                "The algorithm also solves instances with traditional pseudotree arrangements using the same procedure as DPOP.",
                "We compare our algorithm with DPOP using several metrics including the induced width of the pseudotrees, the maximum dimensionality of messages and computation, and the maximum sequential path cost through the algorithm.",
                "We prove that for some problem instances it is not possible to generate a traditional pseudotree using edge-traversal heuristics that will outperform a cross-edged pseudotree.",
                "We use multiple heuristics to generate pseudotrees and choose the best pseudotree in linear space-time complexity.",
                "For some problem instances we observe significant improvements in message and computation sizes compared to DPOP.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent Systems General Terms Algorithms 1.",
                "INTRODUCTION Many historical problems in the AI community can be transformed into Constraint Satisfaction Problems (CSP).",
                "With the advent of distributed AI, multi-agent systems became a popular way to model the complex interactions and coordination required to solve distributed problems.",
                "CSPs were originally extended to distributed agent environments in [9].",
                "Early domains for distributed constraint satisfaction problems (DisCSP) included job shop scheduling [1] and resource allocation [2].",
                "Many domains for agent systems, especially teamwork coordination, distributed scheduling, and sensor networks, involve overly constrained problems that are difficult or impossible to satisfy for every constraint.",
                "Recent approaches to solving problems in these domains rely on optimization techniques that map constraints into multi-valued utility functions.",
                "Instead of finding an assignment that satisfies all constraints, these approaches find an assignment that produces a high level of global utility.",
                "This extension to the original DisCSP approach has become popular in multi-agent systems, and has been labeled the Distributed Constraint Optimization Problem (DCOP) [1].",
                "Current algorithms that solve complete DCOPs use two main approaches: search and dynamic programming.",
                "Search based algorithms that originated from DisCSP typically use some form of backtracking [10] or bounds propagation, as in ADOPT [3].",
                "Dynamic programming based algorithms include DPOP and its extensions [5, 6, 7].",
                "To date, both categories of algorithms arrange agents into a traditional pseudotree to solve the problem.",
                "It has been shown in [6] that any constraint graph can be mapped into a traditional pseudotree.",
                "However, it was also shown that finding the optimal pseudotree was NP-Hard.",
                "We began to investigate the performance of traditional pseudotrees generated by current edge-traversal heuristics.",
                "We found that these heuristics often produced little parallelism as the pseudotrees tended to have high depth and low branching factors.",
                "We suspected that there could be other ways to arrange the pseudotrees that would provide increased parallelism and smaller message sizes.",
                "After exploring these other arrangements we found that cross-edged pseudotrees provide shorter depths and higher branching factors than the traditional pseudotrees.",
                "Our hypothesis was that these crossedged pseudotrees would outperform traditional pseudotrees for some problem types.",
                "In this paper we introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements which include cross-edged pseudotrees.",
                "We begin with a definition of 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, traditional pseudotrees, and cross-edged pseudotrees.",
                "We then provide a summary of the original DPOP algorithm and introduce our DCPOP algorithm.",
                "We discuss the complexity of our algorithm as well as the impact of pseudotree generation heuristics.",
                "We then show that our Distributed Cross-edged Pseudotree Optimization Procedure (DCPOP) performs significantly better in practice than the original DPOP algorithm for some problem instances.",
                "We conclude with a selection of ideas for future work and extensions for DCPOP. 2.",
                "PROBLEM DEFINITION DCOP has been formalized in slightly different ways in recent literature, so we will adopt the definition as presented in [6].",
                "A Distributed Constraint Optimization Problem with n nodes and m constraints consists of the tuple < X, D, U > where: • X = {x1,..,xn} is a set of variables, each one assigned to a unique agent • D = {d1,..,dn} is a set of finite domains for each variable • U = {u1,..,um} is a set of utility functions such that each function involves a subset of variables in X and defines a utility for each combination of values among these variables An optimal solution to a DCOP instance consists of an assignment of values in D to X such that the sum of utilities in U is maximal.",
                "Problem domains that require minimum cost instead of maximum utility can map costs into negative utilities.",
                "The utility functions represent soft constraints but can also represent hard constraints by using arbitrarily large negative values.",
                "For this paper we only consider binary utility functions involving two variables.",
                "Higher order utility functions can be modeled with minor changes to the algorithm, but they also substantially increase the complexity. 2.1 Traditional Pseudotrees Pseudotrees are a common structure used in search procedures to allow parallel processing of independent branches.",
                "As defined in [6], a pseudotree is an arrangement of a graph G into a rooted tree T such that vertices in G that share an edge are in the same branch in T. A back-edge is an edge between a node X and any node which lies on the path from X to the root (excluding Xs parent).",
                "Figure 1 shows a pseudotree with four nodes, three edges (A-B, B-C, BD), and one back-edge (A-C).",
                "Also defined in [6] are four types of relationships between nodes exist in a pseudotree: • P(X) - the parent of a node X: the single node higher in the pseudotree that is connected to X directly through a tree edge • C(X) - the children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through tree edges • PP(X) - the pseudo-parents of a node X: the set of nodes higher in the pseudotree that are connected to X directly through back-edges (In Figure 1, A = PP(C)) • PC(X) - the pseudo-children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through back-edges (In Figure 1, C = PC(A)) Figure 1: A traditional pseudotree.",
                "Solid line edges represent parent-child relationships and the dashed line represents a pseudo-parent-pseudo-child relationship.",
                "Figure 2: A cross-edged pseudotree.",
                "Solid line edges represent parent-child relationships, the dashed line represents a pseudoparent-pseudo-child relationship, and the dotted line represents a branch-parent-branch-child relationship.",
                "The bolded node, B, is the merge point for node E. 2.2 Cross-edged Pseudotrees We define a cross-edge as an edge from node X to a node Y that is above X but not in the path from X to the root.",
                "A cross-edged pseudotree is a traditional pseudotree with the addition of cross-edges.",
                "Figure 2 shows a cross-edged pseudotree with a cross-edge (D-E).",
                "In a cross-edged pseudotree we designate certain edges as primary.",
                "The set of primary edges defines a spanning tree of the nodes.",
                "The parent, child, pseudo-parent, and pseudo-child relationships from the traditional pseudotree are now defined in the context of this primary edge spanning tree.",
                "This definition also yields two additional types of relationships that may exist between nodes: • BP(X) - the branch-parents of a node X: the set of nodes higher in the pseudotree that are connected to X but are not in the primary path from X to the root (In Figure 2, D = BP(E)) • BC(X) - the branch-children of a node X: the set of nodes lower in the pseudotree that are connected to X but are not in any primary path from X to any leaf node (In Figure 2, E = BC(D)) 2.3 Pseudotree Generation 742 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Current algorithms usually have a pre-execution phase to generate a traditional pseudotree from a general DCOP instance.",
                "Our DCPOP algorithm generates a cross-edged pseudotree in the same fashion.",
                "First, the DCOP instance < X, D, U > translates directly into a graph with X as the set of vertices and an edge for each pair of variables represented in U.",
                "Next, various heuristics are used to arrange this graph into a pseudotree.",
                "One common heuristic is to perform a guided depth-first search (DFS) as the resulting traversal is a pseudotree, and a DFS can easily be performed in a distributed fashion.",
                "We define an edge-traversal based method as any method that produces a pseudotree in which all parent/child pairs share an edge in the original graph.",
                "This includes DFS, breadth-first search, and best-first search based traversals.",
                "Our heuristics that generate cross-edged pseudotrees use a distributed best-first search traversal. 3.",
                "DPOP ALGORITHM The original DPOP algorithm operates in three main phases.",
                "The first phase generates a traditional pseudotree from the DCOP instance using a distributed algorithm.",
                "The second phase joins utility hypercubes from children and the local node and propagates them towards the root.",
                "The third phase chooses an assignment for each domain in a top down fashion beginning with the agent at the root node.",
                "The complexity of DPOP depends on the size of the largest computation and utility message during phase two.",
                "It has been shown that this size directly corresponds to the induced width of the pseudotree generated in phase one [6].",
                "DPOP uses polynomial time heuristics to generate the pseudotree since finding the minimum induced width pseudotree is NP-hard.",
                "Several distributed edgetraversal heuristics have been developed to find low width pseudotrees [8].",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, and pseudo-children. 3.1 Utility Propagation Agents located at leaf nodes in the pseudotree begin the process by calculating a local utility hypercube.",
                "This hypercube at node X contains summed utilities for each combination of values in the domains for P(X) and PP(X).",
                "This hypercube has dimensional size equal to the number of pseudo-parents plus one.",
                "A message containing this hypercube is sent to P(X).",
                "Agents located at non-leaf nodes wait for all messages from children to arrive.",
                "Once the agent at node Y has all utility messages, it calculates its local utility hypercube which includes domains for P(Y), PP(Y), and Y.",
                "The local utility hypercube is then joined with all of the hypercubes from the child messages.",
                "At this point all utilities involving node Y are known, and the domain for Y may be safely eliminated from the joined hypercube.",
                "This elimination process chooses the best utility over the domain of Y for each combination of the remaining domains.",
                "A message containing this hypercube is now sent to P(Y).",
                "The dimensional size of this hypercube depends on the number of overlapping domains in received messages and the local utility hypercube.",
                "This dynamic programming based propagation phase continues until the agent at the root node of the pseudotree has received all messages from its children. 3.2 Value Propagation Value propagation begins when the agent at the root node Z has received all messages from its children.",
                "Since Z has no parents or pseudo-parents, it simply combines the utility hypercubes received from its children.",
                "The combined hypercube contains only values for the domain for Z.",
                "At this point the agent at node Z simply chooses the assignment for its domain that has the best utility.",
                "A value propagation message with this assignment is sent to each node in C(Z).",
                "Each other node then receives a value propagation message from its parent and chooses the assignment for its domain that has the best utility given the assignments received in the message.",
                "The node adds its domain assignment to the assignments it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen an assignment for their domain. 4.",
                "DCPOP ALGORITHM Our extension to the original DPOP algorithm, shown in Algorithm 1, shares the same three phases.",
                "The first phase generates the cross-edged pseudotree for the DCOP instance.",
                "The second phase merges branches and propagates the utility hypercubes.",
                "The third phase chooses assignments for domains at branch merge points and in a top down fashion, beginning with the agent at the root node.",
                "For the first phase we generate a pseudotree using several distributed heuristics and select the one with lowest overall complexity.",
                "The complexity of the computation and utility message size in DCPOP does not directly correspond to the induced width of the cross-edged pseudotree.",
                "Instead, we use a polynomial time method for calculating the maximum computation and utility message size for a given cross-edged pseudotree.",
                "A description of this method and the pseudotree selection process appears in Section 5.",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, pseudo-children, branch-parents, and branch-children. 4.1 Merging Branches and Utility Propagation In the original DPOP algorithm a node X only had utility functions involving its parent and its pseudo-parents.",
                "In DCPOP, a node X is allowed to have a utility function involving a branch-parent.",
                "The concept of a branch can be seen in Figure 2 with node E representing our node X.",
                "The two distinct paths from node E to node B are called branches of E. The single node where all branches of E meet is node B, which is called the merge point of E. Agents with nodes that have branch-parents begin by sending a utility propagation message to each branch-parent.",
                "This message includes a two dimensional utility hypercube with domains for the node X and the branch-parent BP(X).",
                "It also includes a branch information structure which contains the origination node of the branch, X, the total number of branches originating from X, and the number of branches originating from X that are merged into a single representation by this branch information structure (this number starts at 1).",
                "Intuitively when the number of merged branches equals the total number of originating branches, the algorithm has reached the merge point for X.",
                "In Figure 2, node E sends a utility propagation message to its branch-parent, node D. This message has dimensions for the domains of E and D, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "As in the original DPOP utility propagation phase, an agent at leaf node X sends a utility propagation message to its parent.",
                "In DCPOP this message contains dimensions for the domains of P(X) and PP(X).",
                "If node X also has branch-parents, then the utility propagation message also contains a dimension for the domain of X, and will include a branch information structure.",
                "In Figure 2, node E sends a utility propagation message to its parent, node C. This message has dimensions for the domains of E and C, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "When a node Y receives utility propagation messages from all of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 743 its children and branch-children, it merges any branches with the same origination node X.",
                "The merged branch information structure accumulates the number of merged branches for X.",
                "If the cumulative total number of merged branches equals the total number of branches, then Y is the merge point for X.",
                "This means that the utility hypercubes present at Y contain all information about the valuations for utility functions involving node X.",
                "In addition to the typical elimination of the domain of Y from the utility hypercubes, we can now safely eliminate the domain of X from the utility hypercubes.",
                "To illustrate this process, we will examine what happens in the second phase for node B in Figure 2.",
                "In the second phase Node B receives two utility propagation messages.",
                "The first comes from node C and includes dimensions for domains E, B, and A.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "The second comes from node D and includes dimensions for domains E and B.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "Node B then merges the branch information structures from both messages because they have the same origination, node E. Since the number of merged branches originating from E is now 2 and the total branches originating from E is 2, node B now eliminates the dimensions for domain E. Node B also eliminates the dimension for its own domain, leaving only information about domain A. Node B then sends a utility propagation message to node A, containing only one dimension for the domain of A.",
                "Although not possible in DPOP, this method of utility propagation and dimension elimination may produce hypercubes at node Y that do not share any domains.",
                "In DCPOP we do not join domain independent hypercubes, but instead may send multiple hypercubes in the utility propagation message sent to the parent of Y.",
                "This lazy approach to joins helps to reduce message sizes. 4.2 Value Propagation As in DPOP, value propagation begins when the agent at the root node Z has received all messages from its children.",
                "At this point the agent at node Z chooses the assignment for its domain that has the best utility.",
                "If Z is the merge point for the branches of some node X, Z will also choose the assignment for the domain of X.",
                "Thus any node that is a merge point will choose assignments for a domain other than its own.",
                "These assignments are then passed down the primary edge hierarchy.",
                "If node X in the hierarchy has branch-parents, then the value assignment message from P(X) will contain an assignment for the domain of X.",
                "Every node in the hierarchy adds any assignments it has chosen to the ones it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen or received an assignment for their domain. 4.3 Proof of Correctness We will prove the correctness of DCPOP by first noting that DCPOP fully extends DPOP and then examining the two cases for value assignment in DCPOP.",
                "Given a traditional pseudotree as input, the DCPOP algorithm execution is identical to DPOP.",
                "Using a traditional pseudotree arrangement no nodes have branch-parents or branch-children since all edges are either back-edges or tree edges.",
                "Thus the DCPOP algorithm using a traditional pseudotree sends only utility propagation messages that contain domains belonging to the parent or pseudo-parents of a node.",
                "Since no node has any branch-parents, no branches exist, and thus no node serves as a merge point for any other node.",
                "Thus all value propagation assignments are chosen at the node of the assignment domain.",
                "For DCPOP execution with cross-edged pseudotrees, some nodes serve as merge points.",
                "We note that any node X that is not a merge point assigns its value exactly as in DPOP.",
                "The local utility hypercube at X contains domains for X, P(X), PP(X), and BC(X).",
                "As in DPOP the value assignment message received at X includes the values assigned to P(X) and PP(X).",
                "Also, since X is not a merge point, all assignments to BC(X) must have been calculated at merge points higher in the tree and are in the value assignment message from P(X).",
                "Thus after eliminating domains for which assignments are known, only the domain of X is left.",
                "The agent at node X can now correctly choose the assignment with maximum utility for its own domain.",
                "If node X is a merge point for some branch-child Y, we know that X must be a node along the path from Y to the root, and from P(Y) and all BP(Y) to the root.",
                "From the algorithm, we know that Y necessarily has all information from C(Y), PC(Y), and BC(Y) since it waits for their messages.",
                "Node X has information about all nodes below it in the tree, which would include Y, P(Y), BP(Y), and those PP(Y) that are below X in the tree.",
                "For any PP(Y) above X in the tree, X receives the assignment for the domain of PP(Y) in the value assignment message from P(X).",
                "Thus X has utility information about all of the utility functions of which Y is a part.",
                "By eliminating domains included in the value assignment message, node X is left with a local utility hypercube with domains for X and Y.",
                "The agent at node X can now correctly choose the assignments with maximum utility for the domains of X and Y. 4.4 Complexity Analysis The first phase of DCPOP sends one message to each P(X), PP(X), and BP(X).",
                "The second phase sends one value assignment message to each C(X).",
                "Thus, DCPOP produces a linear number of messages with respect to the number of edges (utility functions) in the cross-edged pseudotree and the original DCOP instance.",
                "The actual complexity of DCPOP depends on two additional measurements: message size and computation size.",
                "Message size and computation size in DCPOP depend on the number of overlapping branches as well as the number of overlapping back-edges.",
                "It was shown in [6] that the number of overlapping back-edges is equal to the induced width of the pseudotree.",
                "In a poorly constructed cross-edged pseudotree, the number of overlapping branches at node X can be as large as the total number of descendants of X.",
                "Thus, the total message size in DCPOP in a poorly constructed instance can be space-exponential in the total number of nodes in the graph.",
                "However, in practice a well constructed cross-edged pseudotree can achieve much better results.",
                "Later we address the issue of choosing well constructed crossedged pseudotrees from a set.",
                "We introduce an additional measurement of the maximum sequential path cost through the algorithm.",
                "This measurement directly relates to the maximum amount of parallelism achievable by the algorithm.",
                "To take this measurement we first store the total computation size for each node during phase two and three.",
                "This computation size represents the number of individual accesses to a value in a hypercube at each node.",
                "For example, a join between two domains of size 4 costs 4 ∗ 4 = 16.",
                "Two directed acyclic graphs (DAG) can then be drawn; one with the utility propagation messages as edges and the phase two costs at nodes, and the other with value assignment messages and the phase three costs at nodes.",
                "The maximum sequential path cost is equal to the sum of the longest path on each DAG from the root to any leaf node. 5.",
                "HEURISTICS In our assessment of complexity in DCPOP we focused on the worst case possibly produced by the algorithm.",
                "We acknowledge 744 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Algorithm 1 DCPOP Algorithm 1: DCPOP(X; D; U) Each agent Xi executes: Phase 1: pseudotree creation 2: elect leader from all Xj ∈ X 3: elected leader initiates pseudotree creation 4: afterwards, Xi knows P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) and PC(Xi) Phase 2: UTIL message propagation 5: if |BP(Xi)| > 0 then 6: BRANCHXi ← |BP(Xi)| + 1 7: for all Xk ∈BP(Xi) do 8: UTILXi (Xk) ←Compute utils(Xi, Xk) 9: Send message(Xk,UTILXi (Xk),BRANCHXi ) 10: if |C(Xi)| = 0(i.e.",
                "Xi is a leaf node) then 11: UTILXi (P(Xi)) ← Compute utils(P(Xi),PP(Xi)) for all PP(Xi) 12: Send message(P(Xi), UTILXi (P(Xi)),BRANCHXi ) 13: Send message(PP(Xi), empty UTIL, empty BRANCH) to all PP(Xi) 14: activate UTIL Message handler() Phase 3: VALUE message propagation 15: activate VALUE Message handler() END ALGORITHM UTIL Message handler(Xk,UTILXk (Xi), BRANCHXk ) 16: store UTILXk (Xi),BRANCHXk (Xi) 17: if UTIL messages from all children and branch children arrived then 18: for all Bj ∈BRANCH(Xi) do 19: if Bj is merged then 20: join all hypercubes where Bj ∈UTIL(Xi) 21: eliminate Bj from the joined hypercube 22: if P(Xi) == null (that means Xi is the root) then 23: v ∗ i ← Choose optimal(null) 24: Send VALUE(Xi, v ∗ i) to all C(Xi) 25: else 26: UTILXi (P(Xi)) ← Compute utils(P(Xi), PP(Xi)) 27: Send message(P(Xi),UTILXi (P(Xi)), BRANCHXi (P(Xi))) VALUE Message handler(VALUEXi ,P(Xi)) 28: add all Xk ← v ∗ k ∈VALUEXi ,P(Xi) to agent view 29: Xi ← v ∗ i =Choose optimal(agent view) 30: Send VALUEXl , Xi to all Xl ∈C(Xi) that in real world problems the generation of the pseudotree has a significant impact on the actual performance.",
                "The problem of finding the best pseudotree for a given DCOP instance is NP-Hard.",
                "Thus a heuristic is used for generation, and the performance of the algorithm depends on the pseudotree found by the heuristic.",
                "Some previous research focused on finding heuristics to generate good pseudotrees [8].",
                "While we have developed some heuristics that generate good cross-edged pseudotrees for use with DCPOP, our focus has been to use multiple heuristics and then select the best pseudotree from the generated pseudotrees.",
                "We consider only heuristics that run in polynomial time with respect to the number of nodes in the original DCOP instance.",
                "The actual DCPOP algorithm has worst case exponential complexity, but we can calculate the maximum message size, computation size, and sequential path cost for a given cross-edged pseudotree in linear space-time complexity.",
                "To do this, we simply run the algorithm without attempting to calculate any of the local utility hypercubes or optimal value assignments.",
                "Instead, messages include dimensional and branch information but no utility hypercubes.",
                "After each heuristic completes its generation of a pseudotree, we execute the measurement procedure and propagate the measurement information up to the chosen root in that pseudotree.",
                "The root then broadcasts the total complexity for that heuristic to all nodes.",
                "After all heuristics have had a chance to complete, every node knows which heuristic produced the best pseudotree.",
                "Each node then proceeds to begin the DCPOP algorithm using its knowledge of the pseudotree generated by the best heuristic.",
                "The heuristics used to generate traditional pseudotrees perform a distributed DFS traversal.",
                "The general distributed algorithm uses a token passing mechanism and a linear number of messages.",
                "Improved DFS based heuristics use a special procedure to choose the root node, and also provide an ordering function over the neighbors of a node to determine the order of path recursion.",
                "The DFS based heuristics used in our experiments come from the work done in [4, 8]. 5.1 The best-first cross-edged pseudotree heuristic The heuristics used to generate cross-edged pseudotrees perform a best-first traversal.",
                "A general distributed best-first algorithm for node expansion is presented in Algorithm 2.",
                "An evaluation function at each node provides the values that are used to determine the next best node to expand.",
                "Note that in this algorithm each node only exchanges its best value with its neighbors.",
                "In our experiments we used several evaluation functions that took as arguments an ordered list of ancestors and a node, which contains a list of neighbors (with each neighbors placement depth in the tree if it was placed).",
                "From these we can calculate branchparents, branch-children, and unknown relationships for a potential node placement.",
                "The best overall function calculated the value as ancestors−(branchparents+branchchildren) with the number of unknown relationships being a tiebreak.",
                "After completion each node has knowledge of its parent and ancestors, so it can easily determine which connected nodes are pseudo-parents, branchparents, pseudo-children, and branch-children.",
                "The complexity of the best-first traversal depends on the complexity of the evaluation function.",
                "Assuming a complexity of O(V ) for the evaluation function, which is the case for our best overall function, the best-first traversal is O(V · E) which is at worst O(n3 ).",
                "For each v ∈ V we perform a place operation, and find the next node to place using the getBestNeighbor operation.",
                "The place operation is at most O(V ) because of the sent messages.",
                "Finding the next node uses recursion and traverses only already placed The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 745 Algorithm 2 Distributed Best-First Search Algorithm root ← electedleader next(root, ∅) place(node, parent) node.parent ← parent node.ancestors ← parent.ancestors ∪ parent send placement message (node, node.ancestors) to all neighbors of node next(current, previous) if current is not placed then place(current, previous) next(current, ∅) else best ← getBestNeighbor(current, previous) if best = ∅ then if previous = ∅ then terminate, all nodes are placed next(previous, ∅) else next(best, current) getBestNeighbor(current, previous) best ← ∅; score ← 0 for all n ∈ current.neighbors do if n! = previous then if n is placed then nscore ← getBestNeighbor(n, current) else nscore ← evaluate(current, n) if nscore > score then score ← nscore best ← n return best, score nodes, so it has O(V ) recursions.",
                "Each recursion performs a recursive getBestNeighbor operation that traverses all placed nodes and their neighbors.",
                "This operation is O(V · E), but results can be cached using only O(V ) space at each node.",
                "Thus we have O(V ·(V +V +V ·E)) = O(V 2 ·E).",
                "If we are smart about evaluating local changes when each node receives placement messages from its neighbors and cache the results the getBestNeighbor operation is only O(E).",
                "This increases the complexity of the place operation, but for all placements the total complexity is only O(V · E).",
                "Thus we have an overall complexity of O(V ·E+V ·(V +E)) = O(V ·E). 6.",
                "COMPARISON OF COMPLEXITY IN DPOP AND DCPOP We have already shown that given the same input, DCPOP performs the same as DPOP.",
                "We also have shown that we can accurately predict performance of a given pseudotree in linear spacetime complexity.",
                "If we use a constant number of heuristics to generate the set of pseudotrees, we can choose the best pseudotree in linear space-time complexity.",
                "We will now show that there exists a DCOP instance for which a cross-edged pseudotree outperforms all possible traditional pseudotrees (based on edge-traversal heuristics).",
                "In Figure 3(a) we have a DCOP instance with six nodes.",
                "This is a bipartite graph with each partition fully connected to the other (a) (b) (c) Figure 3: (a) The DCOP instance (b) A traditional pseudotree arrangement for the DCOP instance (c) A cross-edged pseudotree arrangement for the DCOP instance partition.",
                "In Figure 3(b) we see a traditional pseudotree arrangement for this DCOP instance.",
                "It is easy to see that any edgetraversal based heuristic cannot expand two nodes from the same partition in succession.",
                "We also see that no node can have more than one child because any such arrangement would be an invalid pseudotree.",
                "Thus any traditional pseudotree arrangement for this DCOP instance must take the form of Figure 3(b).",
                "We can see that the back-edges F-B and F-A overlap node C. Node C also has a parent E, and a back-edge with D. Using the original DPOP algorithm (or DCPOP since they are identical in this case), we find that the computation at node C involves five domains: A, B, C, D, and E. In contrast, the cross-edged pseudotree arrangement in Figure 3(c) requires only a maximum of four domains in any computation during DCPOP.",
                "Since node A is the merge point for branches from both B and C, we can see that each of the nodes D, E, and F have two overlapping branches.",
                "In addition each of these nodes has node A as its parent.",
                "Using the DCPOP algorithm we find that the computation at node D (or E or F) involves four domains: A, B, C, and D (or E or F).",
                "Since no better traditional pseudotree arrangement can be created using an <br>edge-traversal heuristic</br>, we have shown that DCPOP can outperform DPOP even if we use the optimal pseudotree found through edge-traversal.",
                "We acknowledge that pseudotree arrangements that allow parent-child relationships without an actual constraint can solve the problem in Figure 3(a) with maximum computation size of four domains.",
                "However, current heuristics used with DPOP do not produce such pseudotrees, and such a heuristic would be difficult to distribute since each node would require information about nodes with which it has no constraint.",
                "Also, while we do not prove it here, cross-edged pseudotrees can produce smaller message sizes than such pseudotrees even if the computation size is similar.",
                "In practice, since finding the best pseudotree arrangement is NP-Hard, we find that heuristics that produce cross-edged pseudotrees often produce significantly smaller computation and message sizes. 7.",
                "EXPERIMENTAL RESULTS 746 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Existing performance metrics for DCOP algorithms include the total number of messages, synchronous clock cycles, and message size.",
                "We have already shown that the total number of messages is linear with respect to the number of constraints in the DCOP instance.",
                "We also introduced the maximum sequential path cost (PC) as a measurement of the maximum amount of parallelism achievable by the algorithm.",
                "The maximum sequential path cost is equal to the sum of the computations performed on the longest path from the root to any leaf node.",
                "We also include as metrics the maximum computation size in number of dimensions (CD) and maximum message size in number of dimensions (MD).",
                "To analyze the relative complexity of a given DCOP instance, we find the minimum induced width (IW) of any traditional pseudotree produced by a heuristic for the original DPOP. 7.1 Generic DCOP instances For our initial tests we randomly generated two sets of problems with 3000 cases in each.",
                "Each problem was generated by assigning a random number (picked from a range) of constraints to each variable.",
                "The generator then created binary constraints until each variable reached its maximum number of constraints.",
                "The first set uses 20 variables, and the best DPOP IW ranges from 1 to 16 with an average of 8.5.",
                "The second set uses 100 variables, and the best DPOP IW ranged from 2 to 68 with an average of 39.3.",
                "Since most of the problems in the second set were too complex to actually compute the solution, we took measurements of the metrics using the techniques described earlier in Section 5 without actually solving the problem.",
                "Results are shown for the first set in Table 1 and for the second set in Table 2.",
                "For the two problem sets we split the cases into low density and high density categories.",
                "Low density cases consist of those problems that have a best DPOP IW less than or equal to half of the total number of nodes (e.g.",
                "IW ≤ 10 for the 20 node problems and IW ≤ 50 for the 100 node problems).",
                "High density problems consist of the remainder of the problem sets.",
                "In both Table 1 and Table 2 we have listed performance metrics for the original DPOP algorithm, the DCPOP algorithm using only cross-edged pseudotrees (DCPOP-CE), and the DCPOP algorithm using traditional and cross-edged pseudotrees (DCPOP-All).",
                "The pseudotrees used for DPOP were generated using 5 heuristics: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB, and DFS MCN BEC.",
                "These are all versions of the guided DFS traversal discussed in Section 5.",
                "The cross-edged pseudotrees used for DCPOP-CE were generated using 5 heuristics: MCN, LCN, MCN A-B, LCN A-B, and LCSG A-B.",
                "These are all versions of the best-first traversal discussed in Section 5.",
                "For both DPOP and DCPOP-CE we chose the best pseudotree produced by their respective 5 heuristics for each problem in the set.",
                "For DCPOP-All we chose the best pseudotree produced by all 10 heuristics for each problem in the set.",
                "For the CD and MD metrics the value shown is the average number of dimensions.",
                "For the PC metric the value shown is the natural logarithm of the maximum sequential path cost (since the actual value grows exponentially with the complexity of the problem).",
                "The final row in both tables is a measurement of improvement of DCPOP-All over DPOP.",
                "For the CD and MD metrics the value shown is a reduction in number of dimensions.",
                "For the PC metric the value shown is a percentage reduction in the maximum sequential path cost (% = DP OP −DCP OP DCP OP ∗ 100).",
                "Notice that DCPOPAll outperforms DPOP on all metrics.",
                "This logically follows from our earlier assertion that given the same input, DCPOP performs exactly the same as DPOP.",
                "Thus given the choice between the pseudotrees produced by all 10 heuristics, DCPOP-All will always outLow Density High Density Algorithm CD MD PC CD MD PC DPOP 7.81 6.81 3.78 13.34 12.34 5.34 DCPOP-CE 7.94 6.73 3.74 12.83 11.43 5.07 DCPOP-All 7.62 6.49 3.66 12.72 11.36 5.05 Improvement 0.18 0.32 13% 0.62 0.98 36% Table 1: 20 node problems Low Density High Density Algorithm CD MD PC CD MD PC DPOP 33.35 32.35 14.55 58.51 57.50 19.90 DCPOP-CE 33.49 29.17 15.22 57.11 50.03 20.01 DCPOP-All 32.35 29.57 14.10 56.33 51.17 18.84 Improvement 1.00 2.78 104% 2.18 6.33 256% Table 2: 100 node problems Figure 4: Computation Dimension Size Figure 5: Message Dimension Size The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 747 Figure 6: Path Cost DCPOP Improvement Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Table 3: Meeting Scheduling Problems perform DPOP.",
                "Another trend we notice is that the improvement is greater for high density problems than low density problems.",
                "We show this trend in greater detail in Figures 4, 5, and 6.",
                "Notice how the improvement increases as the complexity of the problem increases. 7.2 Meeting Scheduling Problem In addition to our initial generic DCOP tests, we ran a series of tests on the Meeting Scheduling Problem (MSP) as described in [6].",
                "The problem setup includes a number of people that are grouped into departments.",
                "Each person must attend a specified number of meetings.",
                "Meetings can be held within departments or among departments, and can be assigned to one of eight time slots.",
                "The MSP maps to a DCOP instance where each variable represents the time slot that a specific person will attend a specific meeting.",
                "All variables that belong to the same person have mutual exclusion constraints placed so that the person cannot attend more than one meeting during the same time slot.",
                "All variables that belong to the same meeting have equality constraints so that all of the participants choose the same time slot.",
                "Unary constraints are placed on each variable to account for a persons valuation of each meeting and time slot.",
                "For our tests we generated 100 sample problems for each combination of agents and meetings.",
                "Results are shown in Table 3.",
                "The values in the first five columns represent (in left to right order), the total number of agents, the total number of meetings, the total number of variables, the average total number of constraints, and the average minimum IW produced by a traditional pseudotree.",
                "The last three columns show the same metrics we used for the generic DCOP instances, except this time we only show the improvements of DCPOP-All over DPOP.",
                "Performance is better on average for all MSP instances, but again we see larger improvements for more complex problem instances. 8.",
                "CONCLUSIONS AND FUTURE WORK We presented a complete, distributed algorithm that solves general DCOP instances using cross-edged pseudotree arrangements.",
                "Our algorithm extends the DPOP algorithm by adding additional utility propagation messages, and introducing the concept of branch merging during the utility propagation phase.",
                "Our algorithm also allows value assignments to occur at higher level merge points for lower level nodes.",
                "We have shown that DCPOP fully extends DPOP by performing the same operations given the same input.",
                "We have also shown through some examples and experimental data that DCPOP can achieve greater performance for some problem instances by extending the allowable input set to include cross-edged pseudotrees.",
                "We placed particular emphasis on the role that edge-traversal heuristics play in the generation of pseudotrees.",
                "We have shown that the performance penalty is minimal to generate multiple heuristics, and that we can choose the best generated pseudotree in linear space-time complexity.",
                "Given the importance of a good pseudotree for performance, future work will include new heuristics to find better pseudotrees.",
                "Future work will also include adapting existing DPOP extensions [5, 7] that support different problem domains for use with DCPOP. 9.",
                "REFERENCES [1] J. Liu and K. P. Sycara.",
                "Exploiting problem structure for distributed constraint optimization.",
                "In V. Lesser, editor, Proceedings of the First International Conference on Multi-Agent Systems, pages 246-254, San Francisco, CA, 1995.",
                "MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni.",
                "A dynamic distributed constraint satisfaction approach to resource allocation.",
                "Lecture Notes in Computer Science, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe, and M. Yokoo.",
                "An asynchronous complete method for distributed constraint optimization.",
                "In AAMAS 03, 2003. [4] A. Petcu.",
                "Frodo: A framework for open/distributed constraint optimization.",
                "Technical Report No. 2006/001 2006/001, Swiss Federal Institute of Technology (EPFL), Lausanne (Switzerland), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu and B. Faltings.",
                "A-dpop: Approximations in distributed optimization.",
                "In poster in CP 2005, pages 802-806, Sitges, Spain, October 2005. [6] A. Petcu and B. Faltings.",
                "Dpop: A scalable method for multiagent constraint optimization.",
                "In IJCAI 05, pages 266-271, Edinburgh, Scotland, Aug 2005. [7] A. Petcu, B. Faltings, and D. Parkes.",
                "M-dpop: Faithful distributed implementation of efficient social choice problems.",
                "In AAMAS 06, pages 1397-1404, Hakodate, Japan, May 2006. [8] G. Ushakov.",
                "Solving meeting scheduling problems using distributed pseudotree-optimization procedure.",
                "Masters thesis, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "Distributed constraint satisfaction for formalizing distributed problem solving.",
                "In International Conference on Distributed Computing Systems, pages 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "The distributed constraint satisfaction problem: Formalization and algorithms.",
                "Knowledge and Data Engineering, 10(5):673-685, 1998. 748 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "Since no better traditional pseudotree arrangement can be created using an <br>edge-traversal heuristic</br>, we have shown that DCPOP can outperform DPOP even if we use the optimal pseudotree found through edge-traversal."
            ],
            "translated_annotated_samples": [
                "Dado que no se puede crear una disposición de pseudobosque tradicional mejor utilizando una <br>heurística de recorrido de aristas</br>, hemos demostrado que DCPOP puede superar a DPOP incluso si utilizamos el pseudobosque óptimo encontrado a través del recorrido de aristas."
            ],
            "translated_text": "Un Método Completo de Optimización de Restricciones Distribuidas para Arreglos de Pseudotree No Tradicionales∗ James Atlas Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 decker@cis.udel.edu RESUMEN La Optimización de Restricciones Distribuidas (DCOP) es un marco general que puede modelar problemas complejos en sistemas multiagente. Varios algoritmos actuales que resuelven instancias generales de DCOP, incluyendo ADOPT y DPOP, organizan a los agentes en una estructura de pseudobosque tradicional. Introducimos una extensión al algoritmo DPOP que maneja un conjunto extendido de disposiciones de pseudobosque. Nuestro algoritmo resuelve correctamente instancias de DCOP para pseudobosques que incluyen aristas entre nodos en ramas separadas. El algoritmo también resuelve instancias con arreglos de pseudobosque tradicionales utilizando el mismo procedimiento que DPOP. Comparamos nuestro algoritmo con DPOP utilizando varios métricos, incluyendo el ancho inducido de los pseudobosques, la dimensionalidad máxima de los mensajes y la computación, y el costo máximo de la ruta secuencial a través del algoritmo. Demostramos que para algunas instancias del problema no es posible generar un pseudoárbol tradicional utilizando heurísticas de recorrido de aristas que supere a un pseudoárbol con aristas cruzadas. Utilizamos múltiples heurísticas para generar pseudoárboles y elegir el mejor pseudoárbol en complejidad espacio-temporal lineal. Para algunas instancias del problema observamos mejoras significativas en los tamaños de los mensajes y cálculos en comparación con DPOP. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Algoritmos 1. INTRODUCCIÓN Muchos problemas históricos en la comunidad de IA pueden transformarse en Problemas de Satisfacción de Restricciones (CSP). Con la llegada de la inteligencia artificial distribuida, los sistemas multiagente se convirtieron en una forma popular de modelar las interacciones complejas y la coordinación necesaria para resolver problemas distribuidos. Los CSPs fueron originalmente extendidos a entornos de agentes distribuidos en [9]. Los primeros dominios para problemas de satisfacción de restricciones distribuidas (DisCSP) incluyeron la programación de talleres de trabajo [1] y la asignación de recursos [2]. Muchos dominios para sistemas de agentes, especialmente coordinación de trabajo en equipo, programación distribuida y redes de sensores, implican problemas excesivamente restringidos que son difíciles o imposibles de satisfacer para cada restricción. Los enfoques recientes para resolver problemas en estos dominios se basan en técnicas de optimización que mapean restricciones en funciones de utilidad multivaluadas. En lugar de encontrar una asignación que satisfaga todas las restricciones, estos enfoques encuentran una asignación que produce un alto nivel de utilidad global. Esta extensión al enfoque original de DisCSP se ha vuelto popular en sistemas multiagente, y ha sido etiquetada como Problema de Optimización de Restricciones Distribuidas (DCOP) [1]. Los algoritmos actuales que resuelven DCOPs completos utilizan dos enfoques principales: búsqueda y programación dinámica. Los algoritmos basados en búsqueda que se originaron a partir de DisCSP típicamente utilizan alguna forma de retroceso [10] o propagación de límites, como en ADOPT [3]. Los algoritmos basados en programación dinámica incluyen DPOP y sus extensiones [5, 6, 7]. Hasta la fecha, ambas categorías de algoritmos organizan agentes en un pseudoárbol tradicional para resolver el problema. Se ha demostrado en [6] que cualquier grafo de restricciones puede ser mapeado en un pseudoárbol tradicional. Sin embargo, también se demostró que encontrar el pseudoárbol óptimo era NP-Difícil. Comenzamos a investigar el rendimiento de los pseudobosques tradicionales generados por las heurísticas actuales de recorrido de aristas. Descubrimos que estas heurísticas a menudo generaban poco paralelismo, ya que los pseudárboles tendían a tener una gran profundidad y bajos factores de ramificación. Sospechábamos que podría haber otras formas de organizar los pseudobosques que proporcionarían un mayor paralelismo y tamaños de mensaje más pequeños. Después de explorar estos otros arreglos, descubrimos que los pseudobosques de bordes cruzados proporcionan profundidades más cortas y factores de ramificación más altos que los pseudobosques tradicionales. Nuestra hipótesis era que estos pseudorboles cruzados superarían a los pseudorboles tradicionales en algunos tipos de problemas. En este artículo presentamos una extensión al algoritmo DPOP que maneja un conjunto ampliado de disposiciones de pseudobosque que incluyen pseudobosques con aristas cruzadas. Comenzamos con una definición de 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, pseudobosques tradicionales y pseudobosques de bordes cruzados. Luego proporcionamos un resumen del algoritmo DPOP original e introducimos nuestro algoritmo DCPOP. Discutimos la complejidad de nuestro algoritmo, así como el impacto de las heurísticas de generación de pseudobosques. Luego demostramos que nuestro Procedimiento de Optimización de Pseudotree de Bordes Cruzados Distribuido (DCPOP) funciona significativamente mejor en la práctica que el algoritmo DPOP original para algunas instancias del problema. Concluimos con una selección de ideas para trabajos futuros y extensiones para DCPOP. 2. La DEFINICIÓN DEL PROBLEMA DCOP ha sido formalizada de maneras ligeramente diferentes en la literatura reciente, por lo que adoptaremos la definición presentada en [6]. Un Problema de Optimización de Restricciones Distribuidas con n nodos y m restricciones consiste en la tupla < X, D, U > donde: • X = {x1,..,xn} es un conjunto de variables, cada una asignada a un agente único • D = {d1,..,dn} es un conjunto de dominios finitos para cada variable • U = {u1,..,um} es un conjunto de funciones de utilidad tales que cada función involucra un subconjunto de variables en X y define una utilidad para cada combinación de valores entre estas variables. Una solución óptima para una instancia de DCOP consiste en una asignación de valores en D a X tal que la suma de las utilidades en U sea máxima. Los dominios de problemas que requieren un costo mínimo en lugar de una utilidad máxima pueden mapear los costos en utilidades negativas. Las funciones de utilidad representan restricciones suaves pero también pueden representar restricciones fuertes mediante el uso de valores negativos arbitrariamente grandes. Para este artículo solo consideramos funciones de utilidad binarias que involucran dos variables. Las funciones de utilidad de orden superior pueden ser modeladas con cambios menores en el algoritmo, pero también aumentan sustancialmente la complejidad. 2.1 Pseudárboles Tradicionales Los pseudárboles son una estructura común utilizada en procedimientos de búsqueda para permitir el procesamiento paralelo de ramas independientes. Como se define en [6], un pseudoárbol es un arreglo de un grafo G en un árbol raíz T de tal manera que los vértices en G que comparten una arista están en la misma rama en T. Una arista de retroceso es una arista entre un nodo X y cualquier nodo que se encuentre en el camino desde X hasta la raíz (excluyendo al padre de X). La Figura 1 muestra un pseudoárbol con cuatro nodos, tres aristas (A-B, B-C, BD) y una arista de retroceso (A-C). También se definen en [6] cuatro tipos de relaciones entre nodos que existen en un pseudoárbol: • P(X) - el padre de un nodo X: el único nodo más alto en el pseudoárbol que está conectado a X directamente a través de un borde de árbol • C(X) - los hijos de un nodo X: el conjunto de nodos más bajos en el pseudo Las líneas sólidas representan relaciones padre-hijo y la línea discontinua representa una relación pseudo-padre-pseudo-hijo. Figura 2: Un pseudoárbol de bordes cruzados. Las líneas sólidas representan relaciones padre-hijo, la línea discontinua representa una relación pseudo-padre-pseudo-hijo, y la línea punteada representa una relación rama-padre-rama-hijo. El nodo en negrita, B, es el punto de fusión para el nodo E. 2.2 Pseudárboles con aristas cruzadas Definimos una arista cruzada como una arista de un nodo X a un nodo Y que está por encima de X pero no en el camino desde X hasta la raíz. Un pseudoárbol de bordes cruzados es un pseudoárbol tradicional con la adición de bordes cruzados. La Figura 2 muestra un pseudoárbol con una arista cruzada (D-E). En un pseudoárbol de bordes cruzados designamos ciertos bordes como primarios. El conjunto de aristas primarias define un árbol de expansión de los nodos. Las relaciones de padre, hijo, pseudo-padre y pseudo-hijo del pseudotree tradicional ahora están definidas en el contexto de este árbol de expansión de borde primario. Esta definición también produce dos tipos adicionales de relaciones que pueden existir entre nodos: • BP(X) - los nodos padres de rama de un nodo X: el conjunto de nodos más altos en el pseudoárbol que están conectados a X pero no están en el camino principal desde X hasta la raíz (En la Figura 2, D = BP(E)) • BC(X) - los nodos hijos de rama de un nodo X: el conjunto de nodos más bajos en el pseudo La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Los algoritmos actuales suelen tener una fase de pre-ejecución para generar un pseudoárbol tradicional a partir de una instancia general de DCOP. Nuestro algoritmo DCPOP genera un pseudoárbol de bordes cruzados de la misma manera. Primero, la instancia DCOP < X, D, U > se traduce directamente en un grafo con X como el conjunto de vértices y una arista para cada par de variables representadas en U. A continuación, se utilizan varias heurísticas para organizar este grafo en un pseudoárbol. Un heurístico común es realizar una búsqueda en profundidad guiada (DFS, por sus siglas en inglés) ya que el recorrido resultante es un pseudoárbol, y un DFS se puede realizar fácilmente de manera distribuida. Definimos un método basado en el recorrido de aristas como cualquier método que produce un pseudoárbol en el que todos los pares padre/hijo comparten una arista en el grafo original. Esto incluye recorridos basados en DFS, búsqueda en anchura y búsqueda de mejor primero. Nuestras heurísticas que generan pseudobosques de bordes cruzados utilizan un recorrido de búsqueda mejor primero distribuido. 3. ALGORITMO DPOP El algoritmo DPOP original opera en tres fases principales. La primera fase genera un pseudoárbol tradicional a partir de la instancia de DCOP utilizando un algoritmo distribuido. La segunda fase une hipercubos de utilidad de los nodos hijos y el nodo local y los propaga hacia la raíz. La tercera fase elige una asignación para cada dominio de arriba hacia abajo, comenzando con el agente en el nodo raíz. La complejidad de DPOP depende del tamaño del cálculo más grande y del mensaje de utilidad durante la fase dos. Se ha demostrado que este tamaño corresponde directamente al ancho inducido del pseudoárbol generado en la fase uno [6]. DPOP utiliza heurísticas de tiempo polinómico para generar el pseudoárbol, ya que encontrar el pseudoárbol de ancho inducido mínimo es NP-duro. Se han desarrollado varias heurísticas de recorrido de borde distribuido para encontrar pseudobosques de ancho reducido [8]. Al final de la primera fase, cada agente conoce a su padre, hijos, pseudo-padres y pseudo-hijos. 3.1 Propagación de utilidad Los agentes ubicados en los nodos hoja del pseudoárbol comienzan el proceso calculando un hipercubo de utilidad local. Este hipercubo en el nodo X contiene las utilidades sumadas para cada combinación de valores en los dominios de P(X) y PP(X). Este hipercubo tiene un tamaño dimensional igual al número de pseudo-padres más uno. Un mensaje que contiene este hipercubo se envía a P(X). Los agentes ubicados en nodos no hoja esperan a que lleguen todos los mensajes de los nodos hijos. Una vez que el agente en el nodo Y tiene todos los mensajes de utilidad, calcula su hipercubo de utilidad local que incluye los dominios de P(Y), PP(Y) y Y. El hipercubo de utilidad local se une luego con todos los hipercubos de los mensajes hijos. En este punto, todas las utilidades que involucran al nodo Y son conocidas, y el dominio de Y puede ser eliminado de forma segura del hipercubo unido. Este proceso de eliminación elige la mejor utilidad sobre el dominio de Y para cada combinación de los dominios restantes. Un mensaje que contiene este hipercubo se envía ahora a P(Y). El tamaño dimensional de este hipercubo depende del número de dominios superpuestos en los mensajes recibidos y del hipercubo de utilidad local. Esta fase de propagación basada en programación dinámica continúa hasta que el agente en el nodo raíz del pseudoárbol haya recibido todos los mensajes de sus hijos. 3.2 Propagación de Valor La propagación de valor comienza cuando el agente en el nodo raíz Z ha recibido todos los mensajes de sus hijos. Dado que Z no tiene padres ni pseudo-padres, simplemente combina los hipercubos de utilidad recibidos de sus hijos. El hipercubo combinado contiene solo valores para el dominio de Z. En este punto, el agente en el nodo Z simplemente elige la asignación para su dominio que tiene la mejor utilidad. Un mensaje de propagación de valor con esta asignación se envía a cada nodo en C(Z). Cada nodo luego recibe un mensaje de propagación de valor de su padre y elige la asignación para su dominio que tenga la mejor utilidad dadas las asignaciones recibidas en el mensaje. El nodo agrega su asignación de dominio a las asignaciones que recibió y pasa el conjunto de asignaciones a sus hijos. El algoritmo está completo cuando todos los nodos han elegido una asignación para su dominio. ALGORITMO DCPOP Nuestra extensión al algoritmo DPOP original, mostrada en el Algoritmo 1, comparte las mismas tres fases. La primera fase genera el pseudoárbol de bordes cruzados para la instancia de DCOP. La segunda fase fusiona ramas y propaga los hipercubos de utilidad. La tercera fase elige asignaciones para dominios en los puntos de fusión de ramas y de arriba hacia abajo, comenzando con el agente en el nodo raíz. Para la primera fase generamos un pseudoárbol utilizando varios heurísticos distribuidos y seleccionamos el que tenga la menor complejidad general. La complejidad de la computación y el tamaño del mensaje de utilidad en DCPOP no corresponden directamente al ancho inducido del pseudoárbol de aristas cruzadas. En cambio, utilizamos un método de tiempo polinómico para calcular el tamaño máximo de computación y utilidad del mensaje para un pseudoárbol de bordes cruzados dado. Una descripción de este método y el proceso de selección de pseudodendrogramas aparece en la Sección 5. Al final de la primera fase, cada agente conoce a su padre, hijos, pseudo-padres, pseudo-hijos, padres de rama e hijos de rama. 4.1 Fusión de Ramas y Propagación de Utilidad En el algoritmo DPOP original, un nodo X solo tenía funciones de utilidad que involucraban a su padre y a sus pseudo-padres. En DCPOP, se permite que un nodo X tenga una función de utilidad que involucre a un padre de rama. El concepto de una rama se puede ver en la Figura 2 con el nodo E representando nuestro nodo X. Las dos rutas distintas desde el nodo E hasta el nodo B se llaman ramas de E. El único nodo donde se encuentran todas las ramas de E es el nodo B, que se llama punto de fusión de E. Los agentes con nodos que tienen padres de rama comienzan enviando un mensaje de propagación de utilidad a cada padre de rama. Este mensaje incluye un hipercubo de utilidad bidimensional con dominios para el nodo X y el nodo padre de la rama BP(X). También incluye una estructura de información de rama que contiene el nodo de origen de la rama, X, el número total de ramas que se originan en X y el número de ramas que se originan en X y se fusionan en una representación única por esta estructura de información de rama (este número comienza en 1). Intuitivamente, cuando el número de ramas fusionadas es igual al número total de ramas originales, el algoritmo ha alcanzado el punto de fusión para X. En la Figura 2, el nodo E envía un mensaje de propagación de utilidad a su nodo padre de rama, el nodo D. Este mensaje tiene dimensiones para los dominios de E y D, e incluye información de rama con un origen en E, 2 ramas totales y 1 rama fusionada. Como en la fase de propagación de utilidad de la utilidad DPOP original, un agente en el nodo hoja X envía un mensaje de propagación de utilidad a su padre. En DCPOP, este mensaje contiene dimensiones para los dominios de P(X) y PP(X). Si el nodo X también tiene padres de rama, entonces el mensaje de propagación de utilidad también contiene una dimensión para el dominio de X e incluirá una estructura de información de rama. En la Figura 2, el nodo E envía un mensaje de propagación de utilidad a su padre, el nodo C. Este mensaje tiene dimensiones para los dominios de E y C, e incluye información de rama con un origen en E, 2 ramas en total y 1 rama fusionada. Cuando un nodo Y recibe mensajes de propagación de utilidad de todos de The Sixth Intl. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), 743 sus hijos y sus hijos de rama, fusiona cualquier rama con el mismo nodo de origen X. La estructura de información de la rama fusionada acumula el número de ramas fusionadas para X. Si el número total acumulado de ramas fusionadas es igual al número total de ramas, entonces Y es el punto de fusión para X. Esto significa que los hipercubos de utilidad presentes en Y contienen toda la información sobre las valoraciones de las funciones de utilidad que involucran al nodo X. Además de la eliminación típica del dominio de Y de los hipercubos de utilidad, ahora podemos eliminar de forma segura el dominio de X de los hipercubos de utilidad. Para ilustrar este proceso, examinaremos lo que sucede en la segunda fase para el nodo B en la Figura 2. En la segunda fase, el Nodo B recibe dos mensajes de propagación de utilidad. El primero proviene del nodo C e incluye dimensiones para los dominios E, B y A. También tiene una estructura de información de ramas con origen en E, 2 ramas en total y 1 rama fusionada. El segundo proviene del nodo D e incluye dimensiones para los dominios E y B. También tiene una estructura de información de rama con origen en E, 2 ramas en total y 1 rama fusionada. El nodo B luego fusiona las estructuras de información de rama de ambos mensajes porque tienen la misma procedencia, el nodo E. Dado que el número de ramas fusionadas que provienen de E es ahora 2 y el total de ramas que provienen de E es 2, el nodo B elimina las dimensiones para el dominio E. El nodo B también elimina la dimensión para su propio dominio, dejando solo información sobre el dominio A. Luego, el nodo B envía un mensaje de propagación de utilidad al nodo A, que contiene solo una dimensión para el dominio de A. Aunque no sea posible en DPOP, este método de propagación de utilidad y eliminación de dimensiones puede producir hipercubos en el nodo Y que no comparten ningún dominio. En DCPOP no unimos hipercubos independientes de dominio, sino que en su lugar podemos enviar múltiples hipercubos en el mensaje de propagación de utilidad enviado al padre de Y. Este enfoque perezoso de las uniones ayuda a reducir el tamaño de los mensajes. 4.2 Propagación de valores Al igual que en DPOP, la propagación de valores comienza cuando el agente en el nodo raíz Z ha recibido todos los mensajes de sus hijos. En este punto, el agente en el nodo Z elige la asignación para su dominio que tiene la mejor utilidad. Si Z es el punto de fusión de las ramas de algún nodo X, Z también elegirá la asignación para el dominio de X. Por lo tanto, cualquier nodo que sea un punto de fusión elegirá asignaciones para un dominio que no sea el suyo propio. Estas tareas luego se pasan por la jerarquía de la cadena de mando principal. Si el nodo X en la jerarquía tiene padres de rama, entonces el mensaje de asignación de valor de P(X) contendrá una asignación para el dominio de X. Cada nodo en la jerarquía agrega cualquier tarea que haya elegido a las que recibió y pasa el conjunto de tareas a sus hijos. El algoritmo está completo cuando todos los nodos han elegido o recibido una asignación para su dominio. 4.3 Prueba de Corrección Demostraremos la corrección de DCPOP notando primero que DCPOP extiende completamente DPOP y luego examinando los dos casos para la asignación de valores en DCPOP. Dado un pseudoárbol tradicional como entrada, la ejecución del algoritmo DCPOP es idéntica a DPOP. Usando un arreglo de pseudodendrograma tradicional, ningún nodo tiene padres de rama o hijos de rama, ya que todas las aristas son aristas de retroceso o aristas de árbol. Por lo tanto, el algoritmo DCPOP utilizando un pseudoárbol tradicional envía solo mensajes de propagación de utilidad que contienen dominios pertenecientes al padre o pseudo-padres de un nodo. Dado que ningún nodo tiene ramas-padres, no existen ramas, y por lo tanto ningún nodo sirve como punto de fusión para ningún otro nodo. Por lo tanto, todas las asignaciones de propagación de valor se eligen en el nodo del dominio de la asignación. Para la ejecución de DCPOP con pseudárboles de bordes cruzados, algunos nodos actúan como puntos de fusión. Observamos que cualquier nodo X que no sea un punto de fusión asigna su valor exactamente como en DPOP. El hipercubo de utilidad local en X contiene dominios para X, P(X), PP(X) y BC(X). Como en DPOP, el mensaje de asignación de valores recibido en X incluye los valores asignados a P(X) y PP(X). Además, dado que X no es un punto de fusión, todas las asignaciones a BC(X) deben haber sido calculadas en puntos de fusión más altos en el árbol y están en el mensaje de asignación de valor de P(X). Por lo tanto, después de eliminar los dominios para los cuales se conocen las asignaciones, solo queda el dominio de X. El agente en el nodo X ahora puede elegir correctamente la asignación con la máxima utilidad para su propio dominio. Si el nodo X es un punto de fusión para alguna rama-hijo Y, sabemos que X debe ser un nodo a lo largo del camino desde Y hasta la raíz, y desde P(Y) y todos los BP(Y) hasta la raíz. A partir del algoritmo, sabemos que Y necesariamente tiene toda la información de C(Y), PC(Y) y BC(Y) ya que espera sus mensajes. El nodo X tiene información sobre todos los nodos debajo de él en el árbol, lo cual incluiría a Y, P(Y), BP(Y) y aquellos PP(Y) que están debajo de X en el árbol. Para cualquier PP(Y) por encima de X en el árbol, X recibe la asignación para el dominio de PP(Y) en el mensaje de asignación de valor de P(X). Por lo tanto, X tiene información de utilidad sobre todas las funciones de utilidad de las cuales Y forma parte. Al eliminar los dominios incluidos en el mensaje de asignación de valor, el nodo X se queda con un hipercubo de utilidad local con dominios para X e Y. El agente en el nodo X ahora puede elegir correctamente las asignaciones con la máxima utilidad para los dominios de X e Y. 4.4 Análisis de complejidad La primera fase de DCPOP envía un mensaje a cada P(X), PP(X) y BP(X). La segunda fase envía un mensaje de asignación de valor a cada C(X). Por lo tanto, DCPOP produce un número lineal de mensajes con respecto al número de aristas (funciones de utilidad) en el pseudoárbol de aristas cruzadas y la instancia original de DCOP. La complejidad real de DCPOP depende de dos medidas adicionales: el tamaño del mensaje y el tamaño de la computación. El tamaño del mensaje y el tamaño de la computación en DCPOP dependen del número de ramas superpuestas, así como del número de aristas de retroceso superpuestas. Se demostró en [6] que el número de aristas traslapadas es igual al ancho inducido del pseudoárbol. En un pseudoárbol de bordes cruzados mal construido, el número de ramas superpuestas en el nodo X puede ser tan grande como el número total de descendientes de X. Por lo tanto, el tamaño total del mensaje en DCPOP en una instancia mal construida puede ser exponencial en el espacio en el número total de nodos en el grafo. Sin embargo, en la práctica, un pseudoárbol bien construido con bordes cruzados puede lograr resultados mucho mejores. Más tarde abordaremos el tema de elegir pseudobosques cruzados bien construidos de un conjunto. Introducimos una medida adicional del costo máximo de la ruta secuencial a través del algoritmo. Esta medida se relaciona directamente con la cantidad máxima de paralelismo que puede lograr el algoritmo. Para tomar esta medida, primero almacenamos el tamaño total de cálculo para cada nodo durante las fases dos y tres. Este tamaño de cálculo representa el número de accesos individuales a un valor en un hipercubo en cada nodo. Por ejemplo, una unión entre dos dominios de tamaño 4 cuesta 4 ∗ 4 = 16. Dos grafos acíclicos dirigidos (DAG) pueden ser dibujados; uno con los mensajes de propagación de utilidad como aristas y los costos de la fase dos en los nodos, y el otro con los mensajes de asignación de valor y los costos de la fase tres en los nodos. El costo máximo del camino secuencial es igual a la suma del camino más largo en cada DAG desde la raíz hasta cualquier nodo hoja. HEURÍSTICAS En nuestra evaluación de la complejidad en DCPOP nos enfocamos en el peor caso posiblemente producido por el algoritmo. Reconocemos 744 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Algoritmo 1 DCPOP Algoritmo 1: DCPOP(X; D; U) Cada agente Xi ejecuta: Fase 1: creación de pseudotree 2: elegir líder de todos los Xj ∈ X 3: líder elegido inicia la creación de pseudotree 4: después, Xi conoce P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) y PC(Xi) Fase 2: propagación de mensajes UTIL 5: si |BP(Xi)| > 0 entonces 6: BRANCHXi ← |BP(Xi)| + 1 7: para todos Xk ∈BP(Xi) hacer 8: UTILXi (Xk) ← Calcular utils(Xi, Xk) 9: Enviar mensaje(Xk,UTILXi (Xk),BRANCHXi ) 10: si |C(Xi)| = 0 (es decir, Si Xi es un nodo hoja, entonces 11: UTILXi (P(Xi)) ← Calcular utils(P(Xi),PP(Xi)) para todos los PP(Xi) 12: Enviar mensaje(P(Xi), UTILXi (P(Xi)), BRANCHXi ) 13: Enviar mensaje(PP(Xi), UTIL vacío, BRANCH vacío) a todos los PP(Xi) 14: Activar el manejador de mensajes UTIL() Fase 3: Propagación de mensajes de VALOR 15: Activar el manejador de mensajes de VALOR() FIN ALGORITMO Manejador de mensajes UTIL(Xk, UTILXk (Xi), BRANCHXk ) 16: Almacenar UTILXk (Xi), BRANCHXk (Xi) 17: Si han llegado mensajes UTIL de todos los hijos y los hijos de la rama, entonces 18: Para todos los Bj ∈ BRANCH(Xi) hacer 19: Si Bj está fusionado, entonces 20: Unir todos los hipercubos donde Bj ∈ UTIL(Xi) 21: Eliminar Bj del hipercubo unido 22: Si P(Xi) == nulo (eso significa que Xi es la raíz) entonces 23: v ∗ i ← Elegir óptimo(nulo) 24: Enviar VALOR(Xi, v ∗ i) a todos los C(Xi) 25: De lo contrario 26: UTILXi (P(Xi)) ← Calcular utils(P(Xi), PP(Xi)) 27: Enviar mensaje(P(Xi), UTILXi (P(Xi)), BRANCHXi (P(Xi))) Manejador de mensajes de VALOR(VALORXi , P(Xi)) 28: Agregar todos los Xk ← v ∗ k ∈ VALORXi , P(Xi) a la vista del agente 29: Xi ← v ∗ i = Elegir óptimo(vista del agente) 30: Enviar VALORXl , Xi a todos los Xl ∈ C(Xi) que en problemas del mundo real la generación del pseudoárbol tiene un impacto significativo en el rendimiento real. El problema de encontrar la mejor pseudotree para una instancia de DCOP dada es NP-Difícil. Por lo tanto, se utiliza una heurística para la generación, y el rendimiento del algoritmo depende del pseudoárbol encontrado por la heurística. Algunas investigaciones previas se centraron en encontrar heurísticas para generar buenas pseudorboles [8]. Si bien hemos desarrollado algunas heurísticas que generan buenos pseudoárboles cruzados para usar con DCPOP, nuestro enfoque ha sido utilizar múltiples heurísticas y luego seleccionar el mejor pseudo Consideramos solo heurísticas que se ejecuten en tiempo polinómico con respecto al número de nodos en la instancia original del DCOP. El algoritmo DCPOP actual tiene una complejidad exponencial en el peor de los casos, pero podemos calcular el tamaño máximo del mensaje, el tamaño de la computación y el costo de la ruta secuencial para un pseudoárbol de bordes cruzados dado en complejidad espacio-temporal lineal. Para hacer esto, simplemente ejecutamos el algoritmo sin intentar calcular ninguno de los hipercubos de utilidad local o asignaciones de valor óptimo. En cambio, los mensajes incluyen información dimensional y de ramificación pero no hipercubos de utilidad. Después de que cada heurística complete la generación de un pseudoárbol, ejecutamos el procedimiento de medición y propagamos la información de la medición hasta la raíz elegida en ese pseudo La raíz luego transmite la complejidad total de esa heurística a todos los nodos. Después de que todas las heurísticas hayan tenido la oportunidad de completarse, cada nodo sabe qué heurística produjo el mejor pseudoárbol. Cada nodo luego procede a comenzar el algoritmo DCPOP utilizando su conocimiento del pseudoárbol generado por la mejor heurística. Las heurísticas utilizadas para generar pseudárboles tradicionales realizan un recorrido DFS distribuido. El algoritmo distribuido general utiliza un mecanismo de paso de token y un número lineal de mensajes. Las heurísticas mejoradas basadas en DFS utilizan un procedimiento especial para elegir el nodo raíz, y también proporcionan una función de ordenación sobre los vecinos de un nodo para determinar el orden de la recursión de caminos. Las heurísticas basadas en DFS utilizadas en nuestros experimentos provienen del trabajo realizado en [4, 8]. 5.1 La heurística de pseudotree cruzado de mejor primer recorrido. Las heurísticas utilizadas para generar pseudárboles cruzados realizan un recorrido de mejor primer recorrido. Se presenta un algoritmo general distribuido de mejor primero para la expansión de nodos en el Algoritmo 2. Una función de evaluación en cada nodo proporciona los valores que se utilizan para determinar el siguiente mejor nodo a expandir. Ten en cuenta que en este algoritmo cada nodo solo intercambia su mejor valor con sus vecinos. En nuestros experimentos utilizamos varias funciones de evaluación que tomaban como argumentos una lista ordenada de ancestros y un nodo, que contiene una lista de vecinos (con la profundidad de colocación de cada vecino en el árbol). A partir de estos podemos calcular los padres de la rama, los hijos de la rama y las relaciones desconocidas para una posible ubicación del nodo. La mejor función general calculó el valor como ancestros - (padres de rama + hijos de rama) con el número de relaciones desconocidas como criterio de desempate. Después de completarse, cada nodo tiene conocimiento de su padre y ancestros, por lo que puede determinar fácilmente qué nodos conectados son pseudo-padres, padres de rama, pseudo-hijos e hijos de rama. La complejidad de la travesía de mejor primero depende de la complejidad de la función de evaluación. Suponiendo una complejidad de O(V) para la función de evaluación, que es el caso de nuestra mejor función general, el recorrido de mejor primero es O(V · E), lo que en el peor de los casos es O(n3). Para cada v ∈ V realizamos una operación de colocación y encontramos el siguiente nodo a colocar usando la operación getBestNeighbor. La complejidad de la operación del lugar es a lo sumo O(V) debido a los mensajes enviados. Encontrar el siguiente nodo utiliza recursión y recorre solo los ya colocados The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 745 Algoritmo 2 Algoritmo de Búsqueda Distribuida de Mejor Primero root ← líder elegido next(root, ∅) place(nodo, padre) nodo.padre ← padre nodo.ancestros ← padre.ancestros ∪ padre enviar mensaje de ubicación (nodo, nodo.ancestros) a todos los vecinos de nodo next(actual, anterior) si actual no está ubicado entonces place(actual, anterior) next(actual, ∅) else mejor ← obtenerMejorVecino(actual, anterior) si mejor = ∅ entonces si anterior = ∅ entonces terminar, todos los nodos están ubicados next(anterior, ∅) else next(mejor, actual) obtenerMejorVecino(actual, anterior) mejor ← ∅; puntaje ← 0 para todo n ∈ vecinos de actual hacer si n! = anterior entonces si n está ubicado entonces puntajeN ← obtenerMejorVecino(n, actual) else puntajeN ← evaluar(actual, n) si puntajeN > puntaje entonces puntaje ← puntajeN mejor ← n return mejor, puntaje nodos, por lo que tiene O(V) recursiones. Cada recursión realiza una operación recursiva getBestNeighbor que recorre todos los nodos colocados y sus vecinos. Esta operación es O(V · E), pero los resultados se pueden almacenar en caché utilizando solo O(V) espacio en cada nodo. Así que tenemos O(V ·(V +V +V ·E)) = O(V 2 ·E). Si somos inteligentes al evaluar los cambios locales cuando cada nodo recibe mensajes de ubicación de sus vecinos y almacenamos en caché los resultados, la operación getBestNeighbor es solo O(E). Esto aumenta la complejidad de la operación de ubicación, pero para todas las ubicaciones la complejidad total es solo O(V · E). Por lo tanto, tenemos una complejidad general de O(V ·E+V ·(V +E)) = O(V ·E). 6. COMPARACIÓN DE COMPLEJIDAD EN DPOP Y DCPOP Ya hemos demostrado que, dado el mismo input, DCPOP se desempeña igual que DPOP. También hemos demostrado que podemos predecir con precisión el rendimiento de un pseudoárbol dado en complejidad temporal lineal. Si usamos un número constante de heurísticas para generar el conjunto de pseudobosques, podemos elegir el mejor pseudobosque con complejidad lineal en espacio y tiempo. Ahora demostraremos que existe una instancia de DCOP para la cual un pseudoárbol de bordes cruzados supera a todos los posibles pseudoárboles tradicionales (basados en heurísticas de recorrido de bordes). En la Figura 3(a) tenemos una instancia de DCOP con seis nodos. Este es un grafo bipartito con cada partición completamente conectada a la otra (a) (b) (c) Figura 3: (a) La instancia de DCOP (b) Un arreglo de pseudobosque tradicional para la instancia de DCOP (c) Un arreglo de pseudobosque con aristas cruzadas para la partición de la instancia de DCOP. En la Figura 3(b) vemos un arreglo tradicional de pseudotree para esta instancia de DCOP. Es fácil ver que cualquier heurística basada en el recorrido de aristas no puede expandir dos nodos de la misma partición sucesivamente. También observamos que ningún nodo puede tener más de un hijo porque cualquier disposición de este tipo sería un pseudoárbol inválido. Por lo tanto, cualquier disposición tradicional de pseudodendrograma para esta instancia de DCOP debe tener la forma de la Figura 3(b). Podemos ver que las aristas de retroceso F-B y F-A se superponen al nodo C. El nodo C también tiene un padre E y una arista de retroceso con D. Utilizando el algoritmo DPOP original (o DCPOP ya que son idénticos en este caso), encontramos que el cálculo en el nodo C implica cinco dominios: A, B, C, D y E. En contraste, el arreglo de pseudonodos con aristas cruzadas en la Figura 3(c) requiere un máximo de cuatro dominios en cualquier cálculo durante DCPOP. Dado que el nodo A es el punto de fusión de las ramas tanto de B como de C, podemos ver que cada uno de los nodos D, E y F tiene dos ramas superpuestas. Además, cada uno de estos nodos tiene al nodo A como su padre. Usando el algoritmo DCPOP, encontramos que el cálculo en el nodo D (o E o F) implica cuatro dominios: A, B, C y D (o E o F). Dado que no se puede crear una disposición de pseudobosque tradicional mejor utilizando una <br>heurística de recorrido de aristas</br>, hemos demostrado que DCPOP puede superar a DPOP incluso si utilizamos el pseudobosque óptimo encontrado a través del recorrido de aristas. Reconocemos que los arreglos de pseudodistribución de árboles que permiten relaciones padre-hijo sin una restricción real pueden resolver el problema en la Figura 3(a) con un tamaño de cálculo máximo de cuatro dominios. Sin embargo, las heurísticas actuales utilizadas con DPOP no producen tales pseudobosques, y sería difícil distribuir una heurística así, ya que cada nodo requeriría información sobre nodos con los que no tiene restricciones. Además, aunque no lo demostramos aquí, los pseudobosques de bordes cruzados pueden producir tamaños de mensaje más pequeños que tales pseudobosques, incluso si el tamaño de la computación es similar. En la práctica, dado que encontrar la mejor disposición de pseudoramas es NP-Difícil, observamos que las heurísticas que producen pseudoramas con aristas cruzadas a menudo generan tamaños de cálculo y mensajes significativamente más pequeños. 7. RESULTADOS EXPERIMENTALES 746 El Sexto Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Los métricos de rendimiento existentes para algoritmos DCOP incluyen el número total de mensajes, ciclos de reloj síncronos y tamaño de mensaje. Ya hemos demostrado que el número total de mensajes es lineal con respecto al número de restricciones en la instancia de DCOP. También introdujimos el costo de camino secuencial máximo (PC) como una medida de la máxima cantidad de paralelismo alcanzable por el algoritmo. El costo máximo de la ruta secuencial es igual a la suma de los cálculos realizados en la ruta más larga desde la raíz hasta cualquier nodo hoja. También incluimos como métricas el tamaño máximo de cálculo en número de dimensiones (CD) y el tamaño máximo de mensaje en número de dimensiones (MD). Para analizar la complejidad relativa de una instancia DCOP dada, encontramos el ancho inducido mínimo (IW) de cualquier pseudobosque tradicional producido por una heurística para el DPOP original. 7.1 Instancias genéricas de DCOP Para nuestras pruebas iniciales generamos aleatoriamente dos conjuntos de problemas con 3000 casos en cada uno. Cada problema fue generado asignando un número aleatorio (elegido de un rango) de restricciones a cada variable. El generador luego creó restricciones binarias hasta que cada variable alcanzó su número máximo de restricciones. El primer conjunto utiliza 20 variables, y el mejor DPOP IW varía de 1 a 16 con un promedio de 8.5. El segundo conjunto utiliza 100 variables, y el mejor DPOP IW osciló entre 2 y 68 con un promedio de 39.3. Dado que la mayoría de los problemas en el segundo conjunto eran demasiado complejos para calcular la solución, tomamos medidas de las métricas utilizando las técnicas descritas anteriormente en la Sección 5 sin resolver realmente el problema. Los resultados se muestran para el primer conjunto en la Tabla 1 y para el segundo conjunto en la Tabla 2. Para los dos conjuntos de problemas dividimos los casos en categorías de baja densidad y alta densidad. Los casos de baja densidad consisten en aquellos problemas que tienen un mejor DPOP IW menor o igual a la mitad del número total de nodos (por ejemplo, IW ≤ 10 para los problemas de 20 nodos e IW ≤ 50 para los problemas de 100 nodos. Los problemas de alta densidad consisten en el resto de los conjuntos de problemas. En ambas Tabla 1 y Tabla 2 hemos enumerado las métricas de rendimiento para el algoritmo DPOP original, el algoritmo DCPOP utilizando solo pseudobosques de bordes cruzados (DCPOP-CE), y el algoritmo DCPOP utilizando pseudobosques tradicionales y de bordes cruzados (DCPOP-All). Los pseudobosques utilizados para DPOP fueron generados utilizando 5 heurísticas: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB y DFS MCN BEC. Estas son todas las versiones del recorrido DFS guiado discutidas en la Sección 5. Los pseudobosques de bordes cruzados utilizados para DCPOP-CE fueron generados utilizando 5 heurísticas: MCN, LCN, MCN A-B, LCN A-B y LCSG A-B. Estas son todas las versiones del recorrido de mejor primero discutidas en la Sección 5. Para tanto DPOP como DCPOP-CE elegimos el mejor pseudoárbol producido por sus respectivas 5 heurísticas para cada problema en el conjunto. Para DCPOP-All elegimos la mejor pseudotree producida por las 10 heurísticas para cada problema en el conjunto. Para las métricas de CD y MD, el valor mostrado es el número promedio de dimensiones. Para la métrica de PC, el valor mostrado es el logaritmo natural del costo de ruta secuencial máximo (ya que el valor real crece exponencialmente con la complejidad del problema). La última fila en ambas tablas es una medida de mejora de DCPOP-All sobre DPOP. Para las métricas CD y MD, el valor mostrado es una reducción en el número de dimensiones. Para la métrica de PC, el valor mostrado es una reducción porcentual en el costo máximo de la ruta secuencial (% = DP OP −DCP OP DCP OP ∗ 100). Observa que DCPOP supera a DPOP en todas las métricas. Esto se sigue lógicamente de nuestra afirmación anterior de que, dada la misma entrada, DCPOP se comporta exactamente igual que DPOP. Así, dada la elección entre los pseudobosques producidos por las 10 heurísticas, DCPOP-All siempre superará a DCPOP-CE y DPOP. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 6: Mejora del Costo del Camino DCPOP Reunión Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Tabla 3: Problemas de Programación de Reuniones realizan DPOP. Otra tendencia que observamos es que la mejora es mayor para problemas de alta densidad que para problemas de baja densidad. Mostramos esta tendencia con mayor detalle en las Figuras 4, 5 y 6. Observa cómo la mejora aumenta a medida que aumenta la complejidad del problema. 7.2 Problema de Programación de Reuniones Además de nuestras pruebas genéricas iniciales de DCOP, realizamos una serie de pruebas en el Problema de Programación de Reuniones (MSP) como se describe en [6]. La configuración del problema incluye un número de personas agrupadas en departamentos. Cada persona debe asistir a un número específico de reuniones. Las reuniones pueden llevarse a cabo dentro de los departamentos o entre departamentos, y pueden asignarse a uno de los ocho horarios disponibles. El MSP se mapea a una instancia de DCOP donde cada variable representa el intervalo de tiempo en el que una persona específica asistirá a una reunión específica. Todas las variables que pertenecen a la misma persona tienen restricciones de exclusión mutua para que la persona no pueda asistir a más de una reunión durante el mismo intervalo de tiempo. Todas las variables que pertenecen a la misma reunión tienen restricciones de igualdad para que todos los participantes elijan el mismo horario. Se imponen restricciones unarias en cada variable para tener en cuenta la valoración de una persona de cada reunión y franja horaria. Para nuestros tests generamos 100 problemas de muestra para cada combinación de agentes y reuniones. Los resultados se muestran en la Tabla 3. Los valores en las primeras cinco columnas representan (en orden de izquierda a derecha), el número total de agentes, el número total de reuniones, el número total de variables, el promedio total de restricciones y el promedio mínimo de IW producido por un pseudoárbol tradicional. Las últimas tres columnas muestran las mismas métricas que utilizamos para las instancias genéricas de DCOP, excepto que esta vez solo mostramos las mejoras de DCPOP-All sobre DPOP. El rendimiento es mejor en promedio para todas las instancias de MSP, pero nuevamente vemos mejoras más grandes para instancias de problemas más complejos. 8. CONCLUSIONES Y TRABAJO FUTURO Presentamos un algoritmo completo y distribuido que resuelve instancias generales de DCOP utilizando arreglos de pseudoramas cruzados. Nuestro algoritmo extiende el algoritmo DPOP al agregar mensajes adicionales de propagación de utilidad e introducir el concepto de fusión de ramas durante la fase de propagación de utilidad. Nuestro algoritmo también permite que las asignaciones de valor ocurran en puntos de fusión de nivel superior para nodos de nivel inferior. Hemos demostrado que DCPOP extiende completamente DPOP al realizar las mismas operaciones dadas las mismas entradas. También hemos demostrado a través de algunos ejemplos y datos experimentales que DCPOP puede lograr un mejor rendimiento para algunas instancias del problema al extender el conjunto de entrada permitido para incluir pseudobosques cruzados. Damos especial énfasis al papel que desempeñan las heurísticas de recorrido de bordes en la generación de pseudobosques. Hemos demostrado que la penalización en el rendimiento es mínima para generar múltiples heurísticas, y que podemos elegir el mejor pseudoárbol generado en complejidad lineal de espacio-tiempo. Dada la importancia de un buen pseudoárbol para el rendimiento, el trabajo futuro incluirá nuevas heurísticas para encontrar mejores pseudo El trabajo futuro también incluirá adaptar las extensiones existentes de DPOP [5, 7] que soportan diferentes dominios de problemas para su uso con DCPOP. 9. REFERENCIAS [1] J. Liu y K. P. Sycara. Explotando la estructura del problema para la optimización distribuida de restricciones. En V. Lesser, editor, Actas de la Primera Conferencia Internacional sobre Sistemas Multiagente, páginas 246-254, San Francisco, CA, 1995. MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, y S. Kulkarni. Un enfoque dinámico distribuido de satisfacción de restricciones para la asignación de recursos. Notas de conferencia en Ciencias de la Computación, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe y M. Yokoo. Un método completo asíncrono para la optimización de restricciones distribuidas. En AAMAS 03, 2003. [4] A. Petcu. Frodo: Un marco para la optimización de restricciones abiertas/distribuidas. Informe técnico No. 2006/001, Instituto Federal Suizo de Tecnología (EPFL), Lausana (Suiza), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu y B. Faltings. A-dpop: Aproximaciones en optimización distribuida. En póster en CP 2005, páginas 802-806, Sitges, España, octubre de 2005. [6] A. Petcu y B. Faltings. Dpop: Un método escalable para la optimización de restricciones multiagente. En IJCAI 05, páginas 266-271, Edimburgo, Escocia, agosto de 2005. [7] A. Petcu, B. Faltings y D. Parkes. M-dpop: Implementación distribuida fiel de problemas eficientes de elección social. En AAMAS 06, páginas 1397-1404, Hakodate, Japón, mayo de 2006. [8] G. Ushakov. Resolviendo problemas de programación de reuniones utilizando un procedimiento de optimización distribuido de pseudobosque. Tesis de maestría, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida y K. Kuwabara. Satisfacción de restricciones distribuida para formalizar la resolución de problemas distribuidos. En la Conferencia Internacional sobre Sistemas de Computación Distribuida, páginas 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida y K. Kuwabara. El problema de satisfacción de restricciones distribuidas: Formalización y algoritmos. Ingeniería del Conocimiento y de Datos, 10(5):673-685, 1998. 748 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "cross-edged pseudotree": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Complete Distributed Constraint Optimization Method For Non-Traditional Pseudotree Arrangements∗ James Atlas Computer and Information Sciences University of Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Computer and Information Sciences University of Delaware Newark, DE 19716 decker@cis.udel.edu ABSTRACT Distributed Constraint Optimization (DCOP) is a general framework that can model complex problems in multi-agent systems.",
                "Several current algorithms that solve general DCOP instances, including ADOPT and DPOP, arrange agents into a traditional pseudotree structure.",
                "We introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements.",
                "Our algorithm correctly solves DCOP instances for pseudotrees that include edges between nodes in separate branches.",
                "The algorithm also solves instances with traditional pseudotree arrangements using the same procedure as DPOP.",
                "We compare our algorithm with DPOP using several metrics including the induced width of the pseudotrees, the maximum dimensionality of messages and computation, and the maximum sequential path cost through the algorithm.",
                "We prove that for some problem instances it is not possible to generate a traditional pseudotree using edge-traversal heuristics that will outperform a <br>cross-edged pseudotree</br>.",
                "We use multiple heuristics to generate pseudotrees and choose the best pseudotree in linear space-time complexity.",
                "For some problem instances we observe significant improvements in message and computation sizes compared to DPOP.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent Systems General Terms Algorithms 1.",
                "INTRODUCTION Many historical problems in the AI community can be transformed into Constraint Satisfaction Problems (CSP).",
                "With the advent of distributed AI, multi-agent systems became a popular way to model the complex interactions and coordination required to solve distributed problems.",
                "CSPs were originally extended to distributed agent environments in [9].",
                "Early domains for distributed constraint satisfaction problems (DisCSP) included job shop scheduling [1] and resource allocation [2].",
                "Many domains for agent systems, especially teamwork coordination, distributed scheduling, and sensor networks, involve overly constrained problems that are difficult or impossible to satisfy for every constraint.",
                "Recent approaches to solving problems in these domains rely on optimization techniques that map constraints into multi-valued utility functions.",
                "Instead of finding an assignment that satisfies all constraints, these approaches find an assignment that produces a high level of global utility.",
                "This extension to the original DisCSP approach has become popular in multi-agent systems, and has been labeled the Distributed Constraint Optimization Problem (DCOP) [1].",
                "Current algorithms that solve complete DCOPs use two main approaches: search and dynamic programming.",
                "Search based algorithms that originated from DisCSP typically use some form of backtracking [10] or bounds propagation, as in ADOPT [3].",
                "Dynamic programming based algorithms include DPOP and its extensions [5, 6, 7].",
                "To date, both categories of algorithms arrange agents into a traditional pseudotree to solve the problem.",
                "It has been shown in [6] that any constraint graph can be mapped into a traditional pseudotree.",
                "However, it was also shown that finding the optimal pseudotree was NP-Hard.",
                "We began to investigate the performance of traditional pseudotrees generated by current edge-traversal heuristics.",
                "We found that these heuristics often produced little parallelism as the pseudotrees tended to have high depth and low branching factors.",
                "We suspected that there could be other ways to arrange the pseudotrees that would provide increased parallelism and smaller message sizes.",
                "After exploring these other arrangements we found that cross-edged pseudotrees provide shorter depths and higher branching factors than the traditional pseudotrees.",
                "Our hypothesis was that these crossedged pseudotrees would outperform traditional pseudotrees for some problem types.",
                "In this paper we introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements which include cross-edged pseudotrees.",
                "We begin with a definition of 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, traditional pseudotrees, and cross-edged pseudotrees.",
                "We then provide a summary of the original DPOP algorithm and introduce our DCPOP algorithm.",
                "We discuss the complexity of our algorithm as well as the impact of pseudotree generation heuristics.",
                "We then show that our Distributed <br>cross-edged pseudotree</br> Optimization Procedure (DCPOP) performs significantly better in practice than the original DPOP algorithm for some problem instances.",
                "We conclude with a selection of ideas for future work and extensions for DCPOP. 2.",
                "PROBLEM DEFINITION DCOP has been formalized in slightly different ways in recent literature, so we will adopt the definition as presented in [6].",
                "A Distributed Constraint Optimization Problem with n nodes and m constraints consists of the tuple < X, D, U > where: • X = {x1,..,xn} is a set of variables, each one assigned to a unique agent • D = {d1,..,dn} is a set of finite domains for each variable • U = {u1,..,um} is a set of utility functions such that each function involves a subset of variables in X and defines a utility for each combination of values among these variables An optimal solution to a DCOP instance consists of an assignment of values in D to X such that the sum of utilities in U is maximal.",
                "Problem domains that require minimum cost instead of maximum utility can map costs into negative utilities.",
                "The utility functions represent soft constraints but can also represent hard constraints by using arbitrarily large negative values.",
                "For this paper we only consider binary utility functions involving two variables.",
                "Higher order utility functions can be modeled with minor changes to the algorithm, but they also substantially increase the complexity. 2.1 Traditional Pseudotrees Pseudotrees are a common structure used in search procedures to allow parallel processing of independent branches.",
                "As defined in [6], a pseudotree is an arrangement of a graph G into a rooted tree T such that vertices in G that share an edge are in the same branch in T. A back-edge is an edge between a node X and any node which lies on the path from X to the root (excluding Xs parent).",
                "Figure 1 shows a pseudotree with four nodes, three edges (A-B, B-C, BD), and one back-edge (A-C).",
                "Also defined in [6] are four types of relationships between nodes exist in a pseudotree: • P(X) - the parent of a node X: the single node higher in the pseudotree that is connected to X directly through a tree edge • C(X) - the children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through tree edges • PP(X) - the pseudo-parents of a node X: the set of nodes higher in the pseudotree that are connected to X directly through back-edges (In Figure 1, A = PP(C)) • PC(X) - the pseudo-children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through back-edges (In Figure 1, C = PC(A)) Figure 1: A traditional pseudotree.",
                "Solid line edges represent parent-child relationships and the dashed line represents a pseudo-parent-pseudo-child relationship.",
                "Figure 2: A <br>cross-edged pseudotree</br>.",
                "Solid line edges represent parent-child relationships, the dashed line represents a pseudoparent-pseudo-child relationship, and the dotted line represents a branch-parent-branch-child relationship.",
                "The bolded node, B, is the merge point for node E. 2.2 Cross-edged Pseudotrees We define a cross-edge as an edge from node X to a node Y that is above X but not in the path from X to the root.",
                "A <br>cross-edged pseudotree</br> is a traditional pseudotree with the addition of cross-edges.",
                "Figure 2 shows a <br>cross-edged pseudotree</br> with a cross-edge (D-E).",
                "In a <br>cross-edged pseudotree</br> we designate certain edges as primary.",
                "The set of primary edges defines a spanning tree of the nodes.",
                "The parent, child, pseudo-parent, and pseudo-child relationships from the traditional pseudotree are now defined in the context of this primary edge spanning tree.",
                "This definition also yields two additional types of relationships that may exist between nodes: • BP(X) - the branch-parents of a node X: the set of nodes higher in the pseudotree that are connected to X but are not in the primary path from X to the root (In Figure 2, D = BP(E)) • BC(X) - the branch-children of a node X: the set of nodes lower in the pseudotree that are connected to X but are not in any primary path from X to any leaf node (In Figure 2, E = BC(D)) 2.3 Pseudotree Generation 742 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Current algorithms usually have a pre-execution phase to generate a traditional pseudotree from a general DCOP instance.",
                "Our DCPOP algorithm generates a <br>cross-edged pseudotree</br> in the same fashion.",
                "First, the DCOP instance < X, D, U > translates directly into a graph with X as the set of vertices and an edge for each pair of variables represented in U.",
                "Next, various heuristics are used to arrange this graph into a pseudotree.",
                "One common heuristic is to perform a guided depth-first search (DFS) as the resulting traversal is a pseudotree, and a DFS can easily be performed in a distributed fashion.",
                "We define an edge-traversal based method as any method that produces a pseudotree in which all parent/child pairs share an edge in the original graph.",
                "This includes DFS, breadth-first search, and best-first search based traversals.",
                "Our heuristics that generate cross-edged pseudotrees use a distributed best-first search traversal. 3.",
                "DPOP ALGORITHM The original DPOP algorithm operates in three main phases.",
                "The first phase generates a traditional pseudotree from the DCOP instance using a distributed algorithm.",
                "The second phase joins utility hypercubes from children and the local node and propagates them towards the root.",
                "The third phase chooses an assignment for each domain in a top down fashion beginning with the agent at the root node.",
                "The complexity of DPOP depends on the size of the largest computation and utility message during phase two.",
                "It has been shown that this size directly corresponds to the induced width of the pseudotree generated in phase one [6].",
                "DPOP uses polynomial time heuristics to generate the pseudotree since finding the minimum induced width pseudotree is NP-hard.",
                "Several distributed edgetraversal heuristics have been developed to find low width pseudotrees [8].",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, and pseudo-children. 3.1 Utility Propagation Agents located at leaf nodes in the pseudotree begin the process by calculating a local utility hypercube.",
                "This hypercube at node X contains summed utilities for each combination of values in the domains for P(X) and PP(X).",
                "This hypercube has dimensional size equal to the number of pseudo-parents plus one.",
                "A message containing this hypercube is sent to P(X).",
                "Agents located at non-leaf nodes wait for all messages from children to arrive.",
                "Once the agent at node Y has all utility messages, it calculates its local utility hypercube which includes domains for P(Y), PP(Y), and Y.",
                "The local utility hypercube is then joined with all of the hypercubes from the child messages.",
                "At this point all utilities involving node Y are known, and the domain for Y may be safely eliminated from the joined hypercube.",
                "This elimination process chooses the best utility over the domain of Y for each combination of the remaining domains.",
                "A message containing this hypercube is now sent to P(Y).",
                "The dimensional size of this hypercube depends on the number of overlapping domains in received messages and the local utility hypercube.",
                "This dynamic programming based propagation phase continues until the agent at the root node of the pseudotree has received all messages from its children. 3.2 Value Propagation Value propagation begins when the agent at the root node Z has received all messages from its children.",
                "Since Z has no parents or pseudo-parents, it simply combines the utility hypercubes received from its children.",
                "The combined hypercube contains only values for the domain for Z.",
                "At this point the agent at node Z simply chooses the assignment for its domain that has the best utility.",
                "A value propagation message with this assignment is sent to each node in C(Z).",
                "Each other node then receives a value propagation message from its parent and chooses the assignment for its domain that has the best utility given the assignments received in the message.",
                "The node adds its domain assignment to the assignments it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen an assignment for their domain. 4.",
                "DCPOP ALGORITHM Our extension to the original DPOP algorithm, shown in Algorithm 1, shares the same three phases.",
                "The first phase generates the <br>cross-edged pseudotree</br> for the DCOP instance.",
                "The second phase merges branches and propagates the utility hypercubes.",
                "The third phase chooses assignments for domains at branch merge points and in a top down fashion, beginning with the agent at the root node.",
                "For the first phase we generate a pseudotree using several distributed heuristics and select the one with lowest overall complexity.",
                "The complexity of the computation and utility message size in DCPOP does not directly correspond to the induced width of the <br>cross-edged pseudotree</br>.",
                "Instead, we use a polynomial time method for calculating the maximum computation and utility message size for a given <br>cross-edged pseudotree</br>.",
                "A description of this method and the pseudotree selection process appears in Section 5.",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, pseudo-children, branch-parents, and branch-children. 4.1 Merging Branches and Utility Propagation In the original DPOP algorithm a node X only had utility functions involving its parent and its pseudo-parents.",
                "In DCPOP, a node X is allowed to have a utility function involving a branch-parent.",
                "The concept of a branch can be seen in Figure 2 with node E representing our node X.",
                "The two distinct paths from node E to node B are called branches of E. The single node where all branches of E meet is node B, which is called the merge point of E. Agents with nodes that have branch-parents begin by sending a utility propagation message to each branch-parent.",
                "This message includes a two dimensional utility hypercube with domains for the node X and the branch-parent BP(X).",
                "It also includes a branch information structure which contains the origination node of the branch, X, the total number of branches originating from X, and the number of branches originating from X that are merged into a single representation by this branch information structure (this number starts at 1).",
                "Intuitively when the number of merged branches equals the total number of originating branches, the algorithm has reached the merge point for X.",
                "In Figure 2, node E sends a utility propagation message to its branch-parent, node D. This message has dimensions for the domains of E and D, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "As in the original DPOP utility propagation phase, an agent at leaf node X sends a utility propagation message to its parent.",
                "In DCPOP this message contains dimensions for the domains of P(X) and PP(X).",
                "If node X also has branch-parents, then the utility propagation message also contains a dimension for the domain of X, and will include a branch information structure.",
                "In Figure 2, node E sends a utility propagation message to its parent, node C. This message has dimensions for the domains of E and C, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "When a node Y receives utility propagation messages from all of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 743 its children and branch-children, it merges any branches with the same origination node X.",
                "The merged branch information structure accumulates the number of merged branches for X.",
                "If the cumulative total number of merged branches equals the total number of branches, then Y is the merge point for X.",
                "This means that the utility hypercubes present at Y contain all information about the valuations for utility functions involving node X.",
                "In addition to the typical elimination of the domain of Y from the utility hypercubes, we can now safely eliminate the domain of X from the utility hypercubes.",
                "To illustrate this process, we will examine what happens in the second phase for node B in Figure 2.",
                "In the second phase Node B receives two utility propagation messages.",
                "The first comes from node C and includes dimensions for domains E, B, and A.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "The second comes from node D and includes dimensions for domains E and B.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "Node B then merges the branch information structures from both messages because they have the same origination, node E. Since the number of merged branches originating from E is now 2 and the total branches originating from E is 2, node B now eliminates the dimensions for domain E. Node B also eliminates the dimension for its own domain, leaving only information about domain A. Node B then sends a utility propagation message to node A, containing only one dimension for the domain of A.",
                "Although not possible in DPOP, this method of utility propagation and dimension elimination may produce hypercubes at node Y that do not share any domains.",
                "In DCPOP we do not join domain independent hypercubes, but instead may send multiple hypercubes in the utility propagation message sent to the parent of Y.",
                "This lazy approach to joins helps to reduce message sizes. 4.2 Value Propagation As in DPOP, value propagation begins when the agent at the root node Z has received all messages from its children.",
                "At this point the agent at node Z chooses the assignment for its domain that has the best utility.",
                "If Z is the merge point for the branches of some node X, Z will also choose the assignment for the domain of X.",
                "Thus any node that is a merge point will choose assignments for a domain other than its own.",
                "These assignments are then passed down the primary edge hierarchy.",
                "If node X in the hierarchy has branch-parents, then the value assignment message from P(X) will contain an assignment for the domain of X.",
                "Every node in the hierarchy adds any assignments it has chosen to the ones it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen or received an assignment for their domain. 4.3 Proof of Correctness We will prove the correctness of DCPOP by first noting that DCPOP fully extends DPOP and then examining the two cases for value assignment in DCPOP.",
                "Given a traditional pseudotree as input, the DCPOP algorithm execution is identical to DPOP.",
                "Using a traditional pseudotree arrangement no nodes have branch-parents or branch-children since all edges are either back-edges or tree edges.",
                "Thus the DCPOP algorithm using a traditional pseudotree sends only utility propagation messages that contain domains belonging to the parent or pseudo-parents of a node.",
                "Since no node has any branch-parents, no branches exist, and thus no node serves as a merge point for any other node.",
                "Thus all value propagation assignments are chosen at the node of the assignment domain.",
                "For DCPOP execution with cross-edged pseudotrees, some nodes serve as merge points.",
                "We note that any node X that is not a merge point assigns its value exactly as in DPOP.",
                "The local utility hypercube at X contains domains for X, P(X), PP(X), and BC(X).",
                "As in DPOP the value assignment message received at X includes the values assigned to P(X) and PP(X).",
                "Also, since X is not a merge point, all assignments to BC(X) must have been calculated at merge points higher in the tree and are in the value assignment message from P(X).",
                "Thus after eliminating domains for which assignments are known, only the domain of X is left.",
                "The agent at node X can now correctly choose the assignment with maximum utility for its own domain.",
                "If node X is a merge point for some branch-child Y, we know that X must be a node along the path from Y to the root, and from P(Y) and all BP(Y) to the root.",
                "From the algorithm, we know that Y necessarily has all information from C(Y), PC(Y), and BC(Y) since it waits for their messages.",
                "Node X has information about all nodes below it in the tree, which would include Y, P(Y), BP(Y), and those PP(Y) that are below X in the tree.",
                "For any PP(Y) above X in the tree, X receives the assignment for the domain of PP(Y) in the value assignment message from P(X).",
                "Thus X has utility information about all of the utility functions of which Y is a part.",
                "By eliminating domains included in the value assignment message, node X is left with a local utility hypercube with domains for X and Y.",
                "The agent at node X can now correctly choose the assignments with maximum utility for the domains of X and Y. 4.4 Complexity Analysis The first phase of DCPOP sends one message to each P(X), PP(X), and BP(X).",
                "The second phase sends one value assignment message to each C(X).",
                "Thus, DCPOP produces a linear number of messages with respect to the number of edges (utility functions) in the <br>cross-edged pseudotree</br> and the original DCOP instance.",
                "The actual complexity of DCPOP depends on two additional measurements: message size and computation size.",
                "Message size and computation size in DCPOP depend on the number of overlapping branches as well as the number of overlapping back-edges.",
                "It was shown in [6] that the number of overlapping back-edges is equal to the induced width of the pseudotree.",
                "In a poorly constructed <br>cross-edged pseudotree</br>, the number of overlapping branches at node X can be as large as the total number of descendants of X.",
                "Thus, the total message size in DCPOP in a poorly constructed instance can be space-exponential in the total number of nodes in the graph.",
                "However, in practice a well constructed <br>cross-edged pseudotree</br> can achieve much better results.",
                "Later we address the issue of choosing well constructed crossedged pseudotrees from a set.",
                "We introduce an additional measurement of the maximum sequential path cost through the algorithm.",
                "This measurement directly relates to the maximum amount of parallelism achievable by the algorithm.",
                "To take this measurement we first store the total computation size for each node during phase two and three.",
                "This computation size represents the number of individual accesses to a value in a hypercube at each node.",
                "For example, a join between two domains of size 4 costs 4 ∗ 4 = 16.",
                "Two directed acyclic graphs (DAG) can then be drawn; one with the utility propagation messages as edges and the phase two costs at nodes, and the other with value assignment messages and the phase three costs at nodes.",
                "The maximum sequential path cost is equal to the sum of the longest path on each DAG from the root to any leaf node. 5.",
                "HEURISTICS In our assessment of complexity in DCPOP we focused on the worst case possibly produced by the algorithm.",
                "We acknowledge 744 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Algorithm 1 DCPOP Algorithm 1: DCPOP(X; D; U) Each agent Xi executes: Phase 1: pseudotree creation 2: elect leader from all Xj ∈ X 3: elected leader initiates pseudotree creation 4: afterwards, Xi knows P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) and PC(Xi) Phase 2: UTIL message propagation 5: if |BP(Xi)| > 0 then 6: BRANCHXi ← |BP(Xi)| + 1 7: for all Xk ∈BP(Xi) do 8: UTILXi (Xk) ←Compute utils(Xi, Xk) 9: Send message(Xk,UTILXi (Xk),BRANCHXi ) 10: if |C(Xi)| = 0(i.e.",
                "Xi is a leaf node) then 11: UTILXi (P(Xi)) ← Compute utils(P(Xi),PP(Xi)) for all PP(Xi) 12: Send message(P(Xi), UTILXi (P(Xi)),BRANCHXi ) 13: Send message(PP(Xi), empty UTIL, empty BRANCH) to all PP(Xi) 14: activate UTIL Message handler() Phase 3: VALUE message propagation 15: activate VALUE Message handler() END ALGORITHM UTIL Message handler(Xk,UTILXk (Xi), BRANCHXk ) 16: store UTILXk (Xi),BRANCHXk (Xi) 17: if UTIL messages from all children and branch children arrived then 18: for all Bj ∈BRANCH(Xi) do 19: if Bj is merged then 20: join all hypercubes where Bj ∈UTIL(Xi) 21: eliminate Bj from the joined hypercube 22: if P(Xi) == null (that means Xi is the root) then 23: v ∗ i ← Choose optimal(null) 24: Send VALUE(Xi, v ∗ i) to all C(Xi) 25: else 26: UTILXi (P(Xi)) ← Compute utils(P(Xi), PP(Xi)) 27: Send message(P(Xi),UTILXi (P(Xi)), BRANCHXi (P(Xi))) VALUE Message handler(VALUEXi ,P(Xi)) 28: add all Xk ← v ∗ k ∈VALUEXi ,P(Xi) to agent view 29: Xi ← v ∗ i =Choose optimal(agent view) 30: Send VALUEXl , Xi to all Xl ∈C(Xi) that in real world problems the generation of the pseudotree has a significant impact on the actual performance.",
                "The problem of finding the best pseudotree for a given DCOP instance is NP-Hard.",
                "Thus a heuristic is used for generation, and the performance of the algorithm depends on the pseudotree found by the heuristic.",
                "Some previous research focused on finding heuristics to generate good pseudotrees [8].",
                "While we have developed some heuristics that generate good cross-edged pseudotrees for use with DCPOP, our focus has been to use multiple heuristics and then select the best pseudotree from the generated pseudotrees.",
                "We consider only heuristics that run in polynomial time with respect to the number of nodes in the original DCOP instance.",
                "The actual DCPOP algorithm has worst case exponential complexity, but we can calculate the maximum message size, computation size, and sequential path cost for a given <br>cross-edged pseudotree</br> in linear space-time complexity.",
                "To do this, we simply run the algorithm without attempting to calculate any of the local utility hypercubes or optimal value assignments.",
                "Instead, messages include dimensional and branch information but no utility hypercubes.",
                "After each heuristic completes its generation of a pseudotree, we execute the measurement procedure and propagate the measurement information up to the chosen root in that pseudotree.",
                "The root then broadcasts the total complexity for that heuristic to all nodes.",
                "After all heuristics have had a chance to complete, every node knows which heuristic produced the best pseudotree.",
                "Each node then proceeds to begin the DCPOP algorithm using its knowledge of the pseudotree generated by the best heuristic.",
                "The heuristics used to generate traditional pseudotrees perform a distributed DFS traversal.",
                "The general distributed algorithm uses a token passing mechanism and a linear number of messages.",
                "Improved DFS based heuristics use a special procedure to choose the root node, and also provide an ordering function over the neighbors of a node to determine the order of path recursion.",
                "The DFS based heuristics used in our experiments come from the work done in [4, 8]. 5.1 The best-first <br>cross-edged pseudotree</br> heuristic The heuristics used to generate cross-edged pseudotrees perform a best-first traversal.",
                "A general distributed best-first algorithm for node expansion is presented in Algorithm 2.",
                "An evaluation function at each node provides the values that are used to determine the next best node to expand.",
                "Note that in this algorithm each node only exchanges its best value with its neighbors.",
                "In our experiments we used several evaluation functions that took as arguments an ordered list of ancestors and a node, which contains a list of neighbors (with each neighbors placement depth in the tree if it was placed).",
                "From these we can calculate branchparents, branch-children, and unknown relationships for a potential node placement.",
                "The best overall function calculated the value as ancestors−(branchparents+branchchildren) with the number of unknown relationships being a tiebreak.",
                "After completion each node has knowledge of its parent and ancestors, so it can easily determine which connected nodes are pseudo-parents, branchparents, pseudo-children, and branch-children.",
                "The complexity of the best-first traversal depends on the complexity of the evaluation function.",
                "Assuming a complexity of O(V ) for the evaluation function, which is the case for our best overall function, the best-first traversal is O(V · E) which is at worst O(n3 ).",
                "For each v ∈ V we perform a place operation, and find the next node to place using the getBestNeighbor operation.",
                "The place operation is at most O(V ) because of the sent messages.",
                "Finding the next node uses recursion and traverses only already placed The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 745 Algorithm 2 Distributed Best-First Search Algorithm root ← electedleader next(root, ∅) place(node, parent) node.parent ← parent node.ancestors ← parent.ancestors ∪ parent send placement message (node, node.ancestors) to all neighbors of node next(current, previous) if current is not placed then place(current, previous) next(current, ∅) else best ← getBestNeighbor(current, previous) if best = ∅ then if previous = ∅ then terminate, all nodes are placed next(previous, ∅) else next(best, current) getBestNeighbor(current, previous) best ← ∅; score ← 0 for all n ∈ current.neighbors do if n! = previous then if n is placed then nscore ← getBestNeighbor(n, current) else nscore ← evaluate(current, n) if nscore > score then score ← nscore best ← n return best, score nodes, so it has O(V ) recursions.",
                "Each recursion performs a recursive getBestNeighbor operation that traverses all placed nodes and their neighbors.",
                "This operation is O(V · E), but results can be cached using only O(V ) space at each node.",
                "Thus we have O(V ·(V +V +V ·E)) = O(V 2 ·E).",
                "If we are smart about evaluating local changes when each node receives placement messages from its neighbors and cache the results the getBestNeighbor operation is only O(E).",
                "This increases the complexity of the place operation, but for all placements the total complexity is only O(V · E).",
                "Thus we have an overall complexity of O(V ·E+V ·(V +E)) = O(V ·E). 6.",
                "COMPARISON OF COMPLEXITY IN DPOP AND DCPOP We have already shown that given the same input, DCPOP performs the same as DPOP.",
                "We also have shown that we can accurately predict performance of a given pseudotree in linear spacetime complexity.",
                "If we use a constant number of heuristics to generate the set of pseudotrees, we can choose the best pseudotree in linear space-time complexity.",
                "We will now show that there exists a DCOP instance for which a <br>cross-edged pseudotree</br> outperforms all possible traditional pseudotrees (based on edge-traversal heuristics).",
                "In Figure 3(a) we have a DCOP instance with six nodes.",
                "This is a bipartite graph with each partition fully connected to the other (a) (b) (c) Figure 3: (a) The DCOP instance (b) A traditional pseudotree arrangement for the DCOP instance (c) A <br>cross-edged pseudotree</br> arrangement for the DCOP instance partition.",
                "In Figure 3(b) we see a traditional pseudotree arrangement for this DCOP instance.",
                "It is easy to see that any edgetraversal based heuristic cannot expand two nodes from the same partition in succession.",
                "We also see that no node can have more than one child because any such arrangement would be an invalid pseudotree.",
                "Thus any traditional pseudotree arrangement for this DCOP instance must take the form of Figure 3(b).",
                "We can see that the back-edges F-B and F-A overlap node C. Node C also has a parent E, and a back-edge with D. Using the original DPOP algorithm (or DCPOP since they are identical in this case), we find that the computation at node C involves five domains: A, B, C, D, and E. In contrast, the <br>cross-edged pseudotree</br> arrangement in Figure 3(c) requires only a maximum of four domains in any computation during DCPOP.",
                "Since node A is the merge point for branches from both B and C, we can see that each of the nodes D, E, and F have two overlapping branches.",
                "In addition each of these nodes has node A as its parent.",
                "Using the DCPOP algorithm we find that the computation at node D (or E or F) involves four domains: A, B, C, and D (or E or F).",
                "Since no better traditional pseudotree arrangement can be created using an edge-traversal heuristic, we have shown that DCPOP can outperform DPOP even if we use the optimal pseudotree found through edge-traversal.",
                "We acknowledge that pseudotree arrangements that allow parent-child relationships without an actual constraint can solve the problem in Figure 3(a) with maximum computation size of four domains.",
                "However, current heuristics used with DPOP do not produce such pseudotrees, and such a heuristic would be difficult to distribute since each node would require information about nodes with which it has no constraint.",
                "Also, while we do not prove it here, cross-edged pseudotrees can produce smaller message sizes than such pseudotrees even if the computation size is similar.",
                "In practice, since finding the best pseudotree arrangement is NP-Hard, we find that heuristics that produce cross-edged pseudotrees often produce significantly smaller computation and message sizes. 7.",
                "EXPERIMENTAL RESULTS 746 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Existing performance metrics for DCOP algorithms include the total number of messages, synchronous clock cycles, and message size.",
                "We have already shown that the total number of messages is linear with respect to the number of constraints in the DCOP instance.",
                "We also introduced the maximum sequential path cost (PC) as a measurement of the maximum amount of parallelism achievable by the algorithm.",
                "The maximum sequential path cost is equal to the sum of the computations performed on the longest path from the root to any leaf node.",
                "We also include as metrics the maximum computation size in number of dimensions (CD) and maximum message size in number of dimensions (MD).",
                "To analyze the relative complexity of a given DCOP instance, we find the minimum induced width (IW) of any traditional pseudotree produced by a heuristic for the original DPOP. 7.1 Generic DCOP instances For our initial tests we randomly generated two sets of problems with 3000 cases in each.",
                "Each problem was generated by assigning a random number (picked from a range) of constraints to each variable.",
                "The generator then created binary constraints until each variable reached its maximum number of constraints.",
                "The first set uses 20 variables, and the best DPOP IW ranges from 1 to 16 with an average of 8.5.",
                "The second set uses 100 variables, and the best DPOP IW ranged from 2 to 68 with an average of 39.3.",
                "Since most of the problems in the second set were too complex to actually compute the solution, we took measurements of the metrics using the techniques described earlier in Section 5 without actually solving the problem.",
                "Results are shown for the first set in Table 1 and for the second set in Table 2.",
                "For the two problem sets we split the cases into low density and high density categories.",
                "Low density cases consist of those problems that have a best DPOP IW less than or equal to half of the total number of nodes (e.g.",
                "IW ≤ 10 for the 20 node problems and IW ≤ 50 for the 100 node problems).",
                "High density problems consist of the remainder of the problem sets.",
                "In both Table 1 and Table 2 we have listed performance metrics for the original DPOP algorithm, the DCPOP algorithm using only cross-edged pseudotrees (DCPOP-CE), and the DCPOP algorithm using traditional and cross-edged pseudotrees (DCPOP-All).",
                "The pseudotrees used for DPOP were generated using 5 heuristics: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB, and DFS MCN BEC.",
                "These are all versions of the guided DFS traversal discussed in Section 5.",
                "The cross-edged pseudotrees used for DCPOP-CE were generated using 5 heuristics: MCN, LCN, MCN A-B, LCN A-B, and LCSG A-B.",
                "These are all versions of the best-first traversal discussed in Section 5.",
                "For both DPOP and DCPOP-CE we chose the best pseudotree produced by their respective 5 heuristics for each problem in the set.",
                "For DCPOP-All we chose the best pseudotree produced by all 10 heuristics for each problem in the set.",
                "For the CD and MD metrics the value shown is the average number of dimensions.",
                "For the PC metric the value shown is the natural logarithm of the maximum sequential path cost (since the actual value grows exponentially with the complexity of the problem).",
                "The final row in both tables is a measurement of improvement of DCPOP-All over DPOP.",
                "For the CD and MD metrics the value shown is a reduction in number of dimensions.",
                "For the PC metric the value shown is a percentage reduction in the maximum sequential path cost (% = DP OP −DCP OP DCP OP ∗ 100).",
                "Notice that DCPOPAll outperforms DPOP on all metrics.",
                "This logically follows from our earlier assertion that given the same input, DCPOP performs exactly the same as DPOP.",
                "Thus given the choice between the pseudotrees produced by all 10 heuristics, DCPOP-All will always outLow Density High Density Algorithm CD MD PC CD MD PC DPOP 7.81 6.81 3.78 13.34 12.34 5.34 DCPOP-CE 7.94 6.73 3.74 12.83 11.43 5.07 DCPOP-All 7.62 6.49 3.66 12.72 11.36 5.05 Improvement 0.18 0.32 13% 0.62 0.98 36% Table 1: 20 node problems Low Density High Density Algorithm CD MD PC CD MD PC DPOP 33.35 32.35 14.55 58.51 57.50 19.90 DCPOP-CE 33.49 29.17 15.22 57.11 50.03 20.01 DCPOP-All 32.35 29.57 14.10 56.33 51.17 18.84 Improvement 1.00 2.78 104% 2.18 6.33 256% Table 2: 100 node problems Figure 4: Computation Dimension Size Figure 5: Message Dimension Size The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 747 Figure 6: Path Cost DCPOP Improvement Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Table 3: Meeting Scheduling Problems perform DPOP.",
                "Another trend we notice is that the improvement is greater for high density problems than low density problems.",
                "We show this trend in greater detail in Figures 4, 5, and 6.",
                "Notice how the improvement increases as the complexity of the problem increases. 7.2 Meeting Scheduling Problem In addition to our initial generic DCOP tests, we ran a series of tests on the Meeting Scheduling Problem (MSP) as described in [6].",
                "The problem setup includes a number of people that are grouped into departments.",
                "Each person must attend a specified number of meetings.",
                "Meetings can be held within departments or among departments, and can be assigned to one of eight time slots.",
                "The MSP maps to a DCOP instance where each variable represents the time slot that a specific person will attend a specific meeting.",
                "All variables that belong to the same person have mutual exclusion constraints placed so that the person cannot attend more than one meeting during the same time slot.",
                "All variables that belong to the same meeting have equality constraints so that all of the participants choose the same time slot.",
                "Unary constraints are placed on each variable to account for a persons valuation of each meeting and time slot.",
                "For our tests we generated 100 sample problems for each combination of agents and meetings.",
                "Results are shown in Table 3.",
                "The values in the first five columns represent (in left to right order), the total number of agents, the total number of meetings, the total number of variables, the average total number of constraints, and the average minimum IW produced by a traditional pseudotree.",
                "The last three columns show the same metrics we used for the generic DCOP instances, except this time we only show the improvements of DCPOP-All over DPOP.",
                "Performance is better on average for all MSP instances, but again we see larger improvements for more complex problem instances. 8.",
                "CONCLUSIONS AND FUTURE WORK We presented a complete, distributed algorithm that solves general DCOP instances using <br>cross-edged pseudotree</br> arrangements.",
                "Our algorithm extends the DPOP algorithm by adding additional utility propagation messages, and introducing the concept of branch merging during the utility propagation phase.",
                "Our algorithm also allows value assignments to occur at higher level merge points for lower level nodes.",
                "We have shown that DCPOP fully extends DPOP by performing the same operations given the same input.",
                "We have also shown through some examples and experimental data that DCPOP can achieve greater performance for some problem instances by extending the allowable input set to include cross-edged pseudotrees.",
                "We placed particular emphasis on the role that edge-traversal heuristics play in the generation of pseudotrees.",
                "We have shown that the performance penalty is minimal to generate multiple heuristics, and that we can choose the best generated pseudotree in linear space-time complexity.",
                "Given the importance of a good pseudotree for performance, future work will include new heuristics to find better pseudotrees.",
                "Future work will also include adapting existing DPOP extensions [5, 7] that support different problem domains for use with DCPOP. 9.",
                "REFERENCES [1] J. Liu and K. P. Sycara.",
                "Exploiting problem structure for distributed constraint optimization.",
                "In V. Lesser, editor, Proceedings of the First International Conference on Multi-Agent Systems, pages 246-254, San Francisco, CA, 1995.",
                "MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni.",
                "A dynamic distributed constraint satisfaction approach to resource allocation.",
                "Lecture Notes in Computer Science, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe, and M. Yokoo.",
                "An asynchronous complete method for distributed constraint optimization.",
                "In AAMAS 03, 2003. [4] A. Petcu.",
                "Frodo: A framework for open/distributed constraint optimization.",
                "Technical Report No. 2006/001 2006/001, Swiss Federal Institute of Technology (EPFL), Lausanne (Switzerland), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu and B. Faltings.",
                "A-dpop: Approximations in distributed optimization.",
                "In poster in CP 2005, pages 802-806, Sitges, Spain, October 2005. [6] A. Petcu and B. Faltings.",
                "Dpop: A scalable method for multiagent constraint optimization.",
                "In IJCAI 05, pages 266-271, Edinburgh, Scotland, Aug 2005. [7] A. Petcu, B. Faltings, and D. Parkes.",
                "M-dpop: Faithful distributed implementation of efficient social choice problems.",
                "In AAMAS 06, pages 1397-1404, Hakodate, Japan, May 2006. [8] G. Ushakov.",
                "Solving meeting scheduling problems using distributed pseudotree-optimization procedure.",
                "Masters thesis, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "Distributed constraint satisfaction for formalizing distributed problem solving.",
                "In International Conference on Distributed Computing Systems, pages 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "The distributed constraint satisfaction problem: Formalization and algorithms.",
                "Knowledge and Data Engineering, 10(5):673-685, 1998. 748 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "We prove that for some problem instances it is not possible to generate a traditional pseudotree using edge-traversal heuristics that will outperform a <br>cross-edged pseudotree</br>.",
                "We then show that our Distributed <br>cross-edged pseudotree</br> Optimization Procedure (DCPOP) performs significantly better in practice than the original DPOP algorithm for some problem instances.",
                "Figure 2: A <br>cross-edged pseudotree</br>.",
                "A <br>cross-edged pseudotree</br> is a traditional pseudotree with the addition of cross-edges.",
                "Figure 2 shows a <br>cross-edged pseudotree</br> with a cross-edge (D-E)."
            ],
            "translated_annotated_samples": [
                "Demostramos que para algunas instancias del problema no es posible generar un pseudoárbol tradicional utilizando heurísticas de recorrido de aristas que supere a un <br>pseudoárbol con aristas cruzadas</br>.",
                "Luego demostramos que nuestro Procedimiento de Optimización de Pseudotree de Bordes Cruzados Distribuido (DCPOP) funciona significativamente mejor en la práctica que el algoritmo DPOP original para algunas instancias del problema.",
                "Figura 2: Un <br>pseudoárbol de bordes cruzados</br>.",
                "Un <br>pseudoárbol de bordes cruzados</br> es un pseudoárbol tradicional con la adición de bordes cruzados.",
                "La Figura 2 muestra un <br>pseudoárbol con una arista cruzada</br> (D-E)."
            ],
            "translated_text": "Un Método Completo de Optimización de Restricciones Distribuidas para Arreglos de Pseudotree No Tradicionales∗ James Atlas Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 decker@cis.udel.edu RESUMEN La Optimización de Restricciones Distribuidas (DCOP) es un marco general que puede modelar problemas complejos en sistemas multiagente. Varios algoritmos actuales que resuelven instancias generales de DCOP, incluyendo ADOPT y DPOP, organizan a los agentes en una estructura de pseudobosque tradicional. Introducimos una extensión al algoritmo DPOP que maneja un conjunto extendido de disposiciones de pseudobosque. Nuestro algoritmo resuelve correctamente instancias de DCOP para pseudobosques que incluyen aristas entre nodos en ramas separadas. El algoritmo también resuelve instancias con arreglos de pseudobosque tradicionales utilizando el mismo procedimiento que DPOP. Comparamos nuestro algoritmo con DPOP utilizando varios métricos, incluyendo el ancho inducido de los pseudobosques, la dimensionalidad máxima de los mensajes y la computación, y el costo máximo de la ruta secuencial a través del algoritmo. Demostramos que para algunas instancias del problema no es posible generar un pseudoárbol tradicional utilizando heurísticas de recorrido de aristas que supere a un <br>pseudoárbol con aristas cruzadas</br>. Utilizamos múltiples heurísticas para generar pseudoárboles y elegir el mejor pseudoárbol en complejidad espacio-temporal lineal. Para algunas instancias del problema observamos mejoras significativas en los tamaños de los mensajes y cálculos en comparación con DPOP. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Algoritmos 1. INTRODUCCIÓN Muchos problemas históricos en la comunidad de IA pueden transformarse en Problemas de Satisfacción de Restricciones (CSP). Con la llegada de la inteligencia artificial distribuida, los sistemas multiagente se convirtieron en una forma popular de modelar las interacciones complejas y la coordinación necesaria para resolver problemas distribuidos. Los CSPs fueron originalmente extendidos a entornos de agentes distribuidos en [9]. Los primeros dominios para problemas de satisfacción de restricciones distribuidas (DisCSP) incluyeron la programación de talleres de trabajo [1] y la asignación de recursos [2]. Muchos dominios para sistemas de agentes, especialmente coordinación de trabajo en equipo, programación distribuida y redes de sensores, implican problemas excesivamente restringidos que son difíciles o imposibles de satisfacer para cada restricción. Los enfoques recientes para resolver problemas en estos dominios se basan en técnicas de optimización que mapean restricciones en funciones de utilidad multivaluadas. En lugar de encontrar una asignación que satisfaga todas las restricciones, estos enfoques encuentran una asignación que produce un alto nivel de utilidad global. Esta extensión al enfoque original de DisCSP se ha vuelto popular en sistemas multiagente, y ha sido etiquetada como Problema de Optimización de Restricciones Distribuidas (DCOP) [1]. Los algoritmos actuales que resuelven DCOPs completos utilizan dos enfoques principales: búsqueda y programación dinámica. Los algoritmos basados en búsqueda que se originaron a partir de DisCSP típicamente utilizan alguna forma de retroceso [10] o propagación de límites, como en ADOPT [3]. Los algoritmos basados en programación dinámica incluyen DPOP y sus extensiones [5, 6, 7]. Hasta la fecha, ambas categorías de algoritmos organizan agentes en un pseudoárbol tradicional para resolver el problema. Se ha demostrado en [6] que cualquier grafo de restricciones puede ser mapeado en un pseudoárbol tradicional. Sin embargo, también se demostró que encontrar el pseudoárbol óptimo era NP-Difícil. Comenzamos a investigar el rendimiento de los pseudobosques tradicionales generados por las heurísticas actuales de recorrido de aristas. Descubrimos que estas heurísticas a menudo generaban poco paralelismo, ya que los pseudárboles tendían a tener una gran profundidad y bajos factores de ramificación. Sospechábamos que podría haber otras formas de organizar los pseudobosques que proporcionarían un mayor paralelismo y tamaños de mensaje más pequeños. Después de explorar estos otros arreglos, descubrimos que los pseudobosques de bordes cruzados proporcionan profundidades más cortas y factores de ramificación más altos que los pseudobosques tradicionales. Nuestra hipótesis era que estos pseudorboles cruzados superarían a los pseudorboles tradicionales en algunos tipos de problemas. En este artículo presentamos una extensión al algoritmo DPOP que maneja un conjunto ampliado de disposiciones de pseudobosque que incluyen pseudobosques con aristas cruzadas. Comenzamos con una definición de 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, pseudobosques tradicionales y pseudobosques de bordes cruzados. Luego proporcionamos un resumen del algoritmo DPOP original e introducimos nuestro algoritmo DCPOP. Discutimos la complejidad de nuestro algoritmo, así como el impacto de las heurísticas de generación de pseudobosques. Luego demostramos que nuestro Procedimiento de Optimización de Pseudotree de Bordes Cruzados Distribuido (DCPOP) funciona significativamente mejor en la práctica que el algoritmo DPOP original para algunas instancias del problema. Concluimos con una selección de ideas para trabajos futuros y extensiones para DCPOP. 2. La DEFINICIÓN DEL PROBLEMA DCOP ha sido formalizada de maneras ligeramente diferentes en la literatura reciente, por lo que adoptaremos la definición presentada en [6]. Un Problema de Optimización de Restricciones Distribuidas con n nodos y m restricciones consiste en la tupla < X, D, U > donde: • X = {x1,..,xn} es un conjunto de variables, cada una asignada a un agente único • D = {d1,..,dn} es un conjunto de dominios finitos para cada variable • U = {u1,..,um} es un conjunto de funciones de utilidad tales que cada función involucra un subconjunto de variables en X y define una utilidad para cada combinación de valores entre estas variables. Una solución óptima para una instancia de DCOP consiste en una asignación de valores en D a X tal que la suma de las utilidades en U sea máxima. Los dominios de problemas que requieren un costo mínimo en lugar de una utilidad máxima pueden mapear los costos en utilidades negativas. Las funciones de utilidad representan restricciones suaves pero también pueden representar restricciones fuertes mediante el uso de valores negativos arbitrariamente grandes. Para este artículo solo consideramos funciones de utilidad binarias que involucran dos variables. Las funciones de utilidad de orden superior pueden ser modeladas con cambios menores en el algoritmo, pero también aumentan sustancialmente la complejidad. 2.1 Pseudárboles Tradicionales Los pseudárboles son una estructura común utilizada en procedimientos de búsqueda para permitir el procesamiento paralelo de ramas independientes. Como se define en [6], un pseudoárbol es un arreglo de un grafo G en un árbol raíz T de tal manera que los vértices en G que comparten una arista están en la misma rama en T. Una arista de retroceso es una arista entre un nodo X y cualquier nodo que se encuentre en el camino desde X hasta la raíz (excluyendo al padre de X). La Figura 1 muestra un pseudoárbol con cuatro nodos, tres aristas (A-B, B-C, BD) y una arista de retroceso (A-C). También se definen en [6] cuatro tipos de relaciones entre nodos que existen en un pseudoárbol: • P(X) - el padre de un nodo X: el único nodo más alto en el pseudoárbol que está conectado a X directamente a través de un borde de árbol • C(X) - los hijos de un nodo X: el conjunto de nodos más bajos en el pseudo Las líneas sólidas representan relaciones padre-hijo y la línea discontinua representa una relación pseudo-padre-pseudo-hijo. Figura 2: Un <br>pseudoárbol de bordes cruzados</br>. Las líneas sólidas representan relaciones padre-hijo, la línea discontinua representa una relación pseudo-padre-pseudo-hijo, y la línea punteada representa una relación rama-padre-rama-hijo. El nodo en negrita, B, es el punto de fusión para el nodo E. 2.2 Pseudárboles con aristas cruzadas Definimos una arista cruzada como una arista de un nodo X a un nodo Y que está por encima de X pero no en el camino desde X hasta la raíz. Un <br>pseudoárbol de bordes cruzados</br> es un pseudoárbol tradicional con la adición de bordes cruzados. La Figura 2 muestra un <br>pseudoárbol con una arista cruzada</br> (D-E). ",
            "candidates": [],
            "error": [
                [
                    "pseudoárbol con aristas cruzadas",
                    "pseudoárbol de bordes cruzados",
                    "pseudoárbol de bordes cruzados",
                    "pseudoárbol con una arista cruzada"
                ]
            ]
        },
        "job shop scheduling": {
            "translated_key": "programación de talleres de trabajo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Complete Distributed Constraint Optimization Method For Non-Traditional Pseudotree Arrangements∗ James Atlas Computer and Information Sciences University of Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Computer and Information Sciences University of Delaware Newark, DE 19716 decker@cis.udel.edu ABSTRACT Distributed Constraint Optimization (DCOP) is a general framework that can model complex problems in multi-agent systems.",
                "Several current algorithms that solve general DCOP instances, including ADOPT and DPOP, arrange agents into a traditional pseudotree structure.",
                "We introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements.",
                "Our algorithm correctly solves DCOP instances for pseudotrees that include edges between nodes in separate branches.",
                "The algorithm also solves instances with traditional pseudotree arrangements using the same procedure as DPOP.",
                "We compare our algorithm with DPOP using several metrics including the induced width of the pseudotrees, the maximum dimensionality of messages and computation, and the maximum sequential path cost through the algorithm.",
                "We prove that for some problem instances it is not possible to generate a traditional pseudotree using edge-traversal heuristics that will outperform a cross-edged pseudotree.",
                "We use multiple heuristics to generate pseudotrees and choose the best pseudotree in linear space-time complexity.",
                "For some problem instances we observe significant improvements in message and computation sizes compared to DPOP.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent Systems General Terms Algorithms 1.",
                "INTRODUCTION Many historical problems in the AI community can be transformed into Constraint Satisfaction Problems (CSP).",
                "With the advent of distributed AI, multi-agent systems became a popular way to model the complex interactions and coordination required to solve distributed problems.",
                "CSPs were originally extended to distributed agent environments in [9].",
                "Early domains for distributed constraint satisfaction problems (DisCSP) included <br>job shop scheduling</br> [1] and resource allocation [2].",
                "Many domains for agent systems, especially teamwork coordination, distributed scheduling, and sensor networks, involve overly constrained problems that are difficult or impossible to satisfy for every constraint.",
                "Recent approaches to solving problems in these domains rely on optimization techniques that map constraints into multi-valued utility functions.",
                "Instead of finding an assignment that satisfies all constraints, these approaches find an assignment that produces a high level of global utility.",
                "This extension to the original DisCSP approach has become popular in multi-agent systems, and has been labeled the Distributed Constraint Optimization Problem (DCOP) [1].",
                "Current algorithms that solve complete DCOPs use two main approaches: search and dynamic programming.",
                "Search based algorithms that originated from DisCSP typically use some form of backtracking [10] or bounds propagation, as in ADOPT [3].",
                "Dynamic programming based algorithms include DPOP and its extensions [5, 6, 7].",
                "To date, both categories of algorithms arrange agents into a traditional pseudotree to solve the problem.",
                "It has been shown in [6] that any constraint graph can be mapped into a traditional pseudotree.",
                "However, it was also shown that finding the optimal pseudotree was NP-Hard.",
                "We began to investigate the performance of traditional pseudotrees generated by current edge-traversal heuristics.",
                "We found that these heuristics often produced little parallelism as the pseudotrees tended to have high depth and low branching factors.",
                "We suspected that there could be other ways to arrange the pseudotrees that would provide increased parallelism and smaller message sizes.",
                "After exploring these other arrangements we found that cross-edged pseudotrees provide shorter depths and higher branching factors than the traditional pseudotrees.",
                "Our hypothesis was that these crossedged pseudotrees would outperform traditional pseudotrees for some problem types.",
                "In this paper we introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements which include cross-edged pseudotrees.",
                "We begin with a definition of 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, traditional pseudotrees, and cross-edged pseudotrees.",
                "We then provide a summary of the original DPOP algorithm and introduce our DCPOP algorithm.",
                "We discuss the complexity of our algorithm as well as the impact of pseudotree generation heuristics.",
                "We then show that our Distributed Cross-edged Pseudotree Optimization Procedure (DCPOP) performs significantly better in practice than the original DPOP algorithm for some problem instances.",
                "We conclude with a selection of ideas for future work and extensions for DCPOP. 2.",
                "PROBLEM DEFINITION DCOP has been formalized in slightly different ways in recent literature, so we will adopt the definition as presented in [6].",
                "A Distributed Constraint Optimization Problem with n nodes and m constraints consists of the tuple < X, D, U > where: • X = {x1,..,xn} is a set of variables, each one assigned to a unique agent • D = {d1,..,dn} is a set of finite domains for each variable • U = {u1,..,um} is a set of utility functions such that each function involves a subset of variables in X and defines a utility for each combination of values among these variables An optimal solution to a DCOP instance consists of an assignment of values in D to X such that the sum of utilities in U is maximal.",
                "Problem domains that require minimum cost instead of maximum utility can map costs into negative utilities.",
                "The utility functions represent soft constraints but can also represent hard constraints by using arbitrarily large negative values.",
                "For this paper we only consider binary utility functions involving two variables.",
                "Higher order utility functions can be modeled with minor changes to the algorithm, but they also substantially increase the complexity. 2.1 Traditional Pseudotrees Pseudotrees are a common structure used in search procedures to allow parallel processing of independent branches.",
                "As defined in [6], a pseudotree is an arrangement of a graph G into a rooted tree T such that vertices in G that share an edge are in the same branch in T. A back-edge is an edge between a node X and any node which lies on the path from X to the root (excluding Xs parent).",
                "Figure 1 shows a pseudotree with four nodes, three edges (A-B, B-C, BD), and one back-edge (A-C).",
                "Also defined in [6] are four types of relationships between nodes exist in a pseudotree: • P(X) - the parent of a node X: the single node higher in the pseudotree that is connected to X directly through a tree edge • C(X) - the children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through tree edges • PP(X) - the pseudo-parents of a node X: the set of nodes higher in the pseudotree that are connected to X directly through back-edges (In Figure 1, A = PP(C)) • PC(X) - the pseudo-children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through back-edges (In Figure 1, C = PC(A)) Figure 1: A traditional pseudotree.",
                "Solid line edges represent parent-child relationships and the dashed line represents a pseudo-parent-pseudo-child relationship.",
                "Figure 2: A cross-edged pseudotree.",
                "Solid line edges represent parent-child relationships, the dashed line represents a pseudoparent-pseudo-child relationship, and the dotted line represents a branch-parent-branch-child relationship.",
                "The bolded node, B, is the merge point for node E. 2.2 Cross-edged Pseudotrees We define a cross-edge as an edge from node X to a node Y that is above X but not in the path from X to the root.",
                "A cross-edged pseudotree is a traditional pseudotree with the addition of cross-edges.",
                "Figure 2 shows a cross-edged pseudotree with a cross-edge (D-E).",
                "In a cross-edged pseudotree we designate certain edges as primary.",
                "The set of primary edges defines a spanning tree of the nodes.",
                "The parent, child, pseudo-parent, and pseudo-child relationships from the traditional pseudotree are now defined in the context of this primary edge spanning tree.",
                "This definition also yields two additional types of relationships that may exist between nodes: • BP(X) - the branch-parents of a node X: the set of nodes higher in the pseudotree that are connected to X but are not in the primary path from X to the root (In Figure 2, D = BP(E)) • BC(X) - the branch-children of a node X: the set of nodes lower in the pseudotree that are connected to X but are not in any primary path from X to any leaf node (In Figure 2, E = BC(D)) 2.3 Pseudotree Generation 742 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Current algorithms usually have a pre-execution phase to generate a traditional pseudotree from a general DCOP instance.",
                "Our DCPOP algorithm generates a cross-edged pseudotree in the same fashion.",
                "First, the DCOP instance < X, D, U > translates directly into a graph with X as the set of vertices and an edge for each pair of variables represented in U.",
                "Next, various heuristics are used to arrange this graph into a pseudotree.",
                "One common heuristic is to perform a guided depth-first search (DFS) as the resulting traversal is a pseudotree, and a DFS can easily be performed in a distributed fashion.",
                "We define an edge-traversal based method as any method that produces a pseudotree in which all parent/child pairs share an edge in the original graph.",
                "This includes DFS, breadth-first search, and best-first search based traversals.",
                "Our heuristics that generate cross-edged pseudotrees use a distributed best-first search traversal. 3.",
                "DPOP ALGORITHM The original DPOP algorithm operates in three main phases.",
                "The first phase generates a traditional pseudotree from the DCOP instance using a distributed algorithm.",
                "The second phase joins utility hypercubes from children and the local node and propagates them towards the root.",
                "The third phase chooses an assignment for each domain in a top down fashion beginning with the agent at the root node.",
                "The complexity of DPOP depends on the size of the largest computation and utility message during phase two.",
                "It has been shown that this size directly corresponds to the induced width of the pseudotree generated in phase one [6].",
                "DPOP uses polynomial time heuristics to generate the pseudotree since finding the minimum induced width pseudotree is NP-hard.",
                "Several distributed edgetraversal heuristics have been developed to find low width pseudotrees [8].",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, and pseudo-children. 3.1 Utility Propagation Agents located at leaf nodes in the pseudotree begin the process by calculating a local utility hypercube.",
                "This hypercube at node X contains summed utilities for each combination of values in the domains for P(X) and PP(X).",
                "This hypercube has dimensional size equal to the number of pseudo-parents plus one.",
                "A message containing this hypercube is sent to P(X).",
                "Agents located at non-leaf nodes wait for all messages from children to arrive.",
                "Once the agent at node Y has all utility messages, it calculates its local utility hypercube which includes domains for P(Y), PP(Y), and Y.",
                "The local utility hypercube is then joined with all of the hypercubes from the child messages.",
                "At this point all utilities involving node Y are known, and the domain for Y may be safely eliminated from the joined hypercube.",
                "This elimination process chooses the best utility over the domain of Y for each combination of the remaining domains.",
                "A message containing this hypercube is now sent to P(Y).",
                "The dimensional size of this hypercube depends on the number of overlapping domains in received messages and the local utility hypercube.",
                "This dynamic programming based propagation phase continues until the agent at the root node of the pseudotree has received all messages from its children. 3.2 Value Propagation Value propagation begins when the agent at the root node Z has received all messages from its children.",
                "Since Z has no parents or pseudo-parents, it simply combines the utility hypercubes received from its children.",
                "The combined hypercube contains only values for the domain for Z.",
                "At this point the agent at node Z simply chooses the assignment for its domain that has the best utility.",
                "A value propagation message with this assignment is sent to each node in C(Z).",
                "Each other node then receives a value propagation message from its parent and chooses the assignment for its domain that has the best utility given the assignments received in the message.",
                "The node adds its domain assignment to the assignments it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen an assignment for their domain. 4.",
                "DCPOP ALGORITHM Our extension to the original DPOP algorithm, shown in Algorithm 1, shares the same three phases.",
                "The first phase generates the cross-edged pseudotree for the DCOP instance.",
                "The second phase merges branches and propagates the utility hypercubes.",
                "The third phase chooses assignments for domains at branch merge points and in a top down fashion, beginning with the agent at the root node.",
                "For the first phase we generate a pseudotree using several distributed heuristics and select the one with lowest overall complexity.",
                "The complexity of the computation and utility message size in DCPOP does not directly correspond to the induced width of the cross-edged pseudotree.",
                "Instead, we use a polynomial time method for calculating the maximum computation and utility message size for a given cross-edged pseudotree.",
                "A description of this method and the pseudotree selection process appears in Section 5.",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, pseudo-children, branch-parents, and branch-children. 4.1 Merging Branches and Utility Propagation In the original DPOP algorithm a node X only had utility functions involving its parent and its pseudo-parents.",
                "In DCPOP, a node X is allowed to have a utility function involving a branch-parent.",
                "The concept of a branch can be seen in Figure 2 with node E representing our node X.",
                "The two distinct paths from node E to node B are called branches of E. The single node where all branches of E meet is node B, which is called the merge point of E. Agents with nodes that have branch-parents begin by sending a utility propagation message to each branch-parent.",
                "This message includes a two dimensional utility hypercube with domains for the node X and the branch-parent BP(X).",
                "It also includes a branch information structure which contains the origination node of the branch, X, the total number of branches originating from X, and the number of branches originating from X that are merged into a single representation by this branch information structure (this number starts at 1).",
                "Intuitively when the number of merged branches equals the total number of originating branches, the algorithm has reached the merge point for X.",
                "In Figure 2, node E sends a utility propagation message to its branch-parent, node D. This message has dimensions for the domains of E and D, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "As in the original DPOP utility propagation phase, an agent at leaf node X sends a utility propagation message to its parent.",
                "In DCPOP this message contains dimensions for the domains of P(X) and PP(X).",
                "If node X also has branch-parents, then the utility propagation message also contains a dimension for the domain of X, and will include a branch information structure.",
                "In Figure 2, node E sends a utility propagation message to its parent, node C. This message has dimensions for the domains of E and C, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "When a node Y receives utility propagation messages from all of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 743 its children and branch-children, it merges any branches with the same origination node X.",
                "The merged branch information structure accumulates the number of merged branches for X.",
                "If the cumulative total number of merged branches equals the total number of branches, then Y is the merge point for X.",
                "This means that the utility hypercubes present at Y contain all information about the valuations for utility functions involving node X.",
                "In addition to the typical elimination of the domain of Y from the utility hypercubes, we can now safely eliminate the domain of X from the utility hypercubes.",
                "To illustrate this process, we will examine what happens in the second phase for node B in Figure 2.",
                "In the second phase Node B receives two utility propagation messages.",
                "The first comes from node C and includes dimensions for domains E, B, and A.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "The second comes from node D and includes dimensions for domains E and B.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "Node B then merges the branch information structures from both messages because they have the same origination, node E. Since the number of merged branches originating from E is now 2 and the total branches originating from E is 2, node B now eliminates the dimensions for domain E. Node B also eliminates the dimension for its own domain, leaving only information about domain A. Node B then sends a utility propagation message to node A, containing only one dimension for the domain of A.",
                "Although not possible in DPOP, this method of utility propagation and dimension elimination may produce hypercubes at node Y that do not share any domains.",
                "In DCPOP we do not join domain independent hypercubes, but instead may send multiple hypercubes in the utility propagation message sent to the parent of Y.",
                "This lazy approach to joins helps to reduce message sizes. 4.2 Value Propagation As in DPOP, value propagation begins when the agent at the root node Z has received all messages from its children.",
                "At this point the agent at node Z chooses the assignment for its domain that has the best utility.",
                "If Z is the merge point for the branches of some node X, Z will also choose the assignment for the domain of X.",
                "Thus any node that is a merge point will choose assignments for a domain other than its own.",
                "These assignments are then passed down the primary edge hierarchy.",
                "If node X in the hierarchy has branch-parents, then the value assignment message from P(X) will contain an assignment for the domain of X.",
                "Every node in the hierarchy adds any assignments it has chosen to the ones it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen or received an assignment for their domain. 4.3 Proof of Correctness We will prove the correctness of DCPOP by first noting that DCPOP fully extends DPOP and then examining the two cases for value assignment in DCPOP.",
                "Given a traditional pseudotree as input, the DCPOP algorithm execution is identical to DPOP.",
                "Using a traditional pseudotree arrangement no nodes have branch-parents or branch-children since all edges are either back-edges or tree edges.",
                "Thus the DCPOP algorithm using a traditional pseudotree sends only utility propagation messages that contain domains belonging to the parent or pseudo-parents of a node.",
                "Since no node has any branch-parents, no branches exist, and thus no node serves as a merge point for any other node.",
                "Thus all value propagation assignments are chosen at the node of the assignment domain.",
                "For DCPOP execution with cross-edged pseudotrees, some nodes serve as merge points.",
                "We note that any node X that is not a merge point assigns its value exactly as in DPOP.",
                "The local utility hypercube at X contains domains for X, P(X), PP(X), and BC(X).",
                "As in DPOP the value assignment message received at X includes the values assigned to P(X) and PP(X).",
                "Also, since X is not a merge point, all assignments to BC(X) must have been calculated at merge points higher in the tree and are in the value assignment message from P(X).",
                "Thus after eliminating domains for which assignments are known, only the domain of X is left.",
                "The agent at node X can now correctly choose the assignment with maximum utility for its own domain.",
                "If node X is a merge point for some branch-child Y, we know that X must be a node along the path from Y to the root, and from P(Y) and all BP(Y) to the root.",
                "From the algorithm, we know that Y necessarily has all information from C(Y), PC(Y), and BC(Y) since it waits for their messages.",
                "Node X has information about all nodes below it in the tree, which would include Y, P(Y), BP(Y), and those PP(Y) that are below X in the tree.",
                "For any PP(Y) above X in the tree, X receives the assignment for the domain of PP(Y) in the value assignment message from P(X).",
                "Thus X has utility information about all of the utility functions of which Y is a part.",
                "By eliminating domains included in the value assignment message, node X is left with a local utility hypercube with domains for X and Y.",
                "The agent at node X can now correctly choose the assignments with maximum utility for the domains of X and Y. 4.4 Complexity Analysis The first phase of DCPOP sends one message to each P(X), PP(X), and BP(X).",
                "The second phase sends one value assignment message to each C(X).",
                "Thus, DCPOP produces a linear number of messages with respect to the number of edges (utility functions) in the cross-edged pseudotree and the original DCOP instance.",
                "The actual complexity of DCPOP depends on two additional measurements: message size and computation size.",
                "Message size and computation size in DCPOP depend on the number of overlapping branches as well as the number of overlapping back-edges.",
                "It was shown in [6] that the number of overlapping back-edges is equal to the induced width of the pseudotree.",
                "In a poorly constructed cross-edged pseudotree, the number of overlapping branches at node X can be as large as the total number of descendants of X.",
                "Thus, the total message size in DCPOP in a poorly constructed instance can be space-exponential in the total number of nodes in the graph.",
                "However, in practice a well constructed cross-edged pseudotree can achieve much better results.",
                "Later we address the issue of choosing well constructed crossedged pseudotrees from a set.",
                "We introduce an additional measurement of the maximum sequential path cost through the algorithm.",
                "This measurement directly relates to the maximum amount of parallelism achievable by the algorithm.",
                "To take this measurement we first store the total computation size for each node during phase two and three.",
                "This computation size represents the number of individual accesses to a value in a hypercube at each node.",
                "For example, a join between two domains of size 4 costs 4 ∗ 4 = 16.",
                "Two directed acyclic graphs (DAG) can then be drawn; one with the utility propagation messages as edges and the phase two costs at nodes, and the other with value assignment messages and the phase three costs at nodes.",
                "The maximum sequential path cost is equal to the sum of the longest path on each DAG from the root to any leaf node. 5.",
                "HEURISTICS In our assessment of complexity in DCPOP we focused on the worst case possibly produced by the algorithm.",
                "We acknowledge 744 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Algorithm 1 DCPOP Algorithm 1: DCPOP(X; D; U) Each agent Xi executes: Phase 1: pseudotree creation 2: elect leader from all Xj ∈ X 3: elected leader initiates pseudotree creation 4: afterwards, Xi knows P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) and PC(Xi) Phase 2: UTIL message propagation 5: if |BP(Xi)| > 0 then 6: BRANCHXi ← |BP(Xi)| + 1 7: for all Xk ∈BP(Xi) do 8: UTILXi (Xk) ←Compute utils(Xi, Xk) 9: Send message(Xk,UTILXi (Xk),BRANCHXi ) 10: if |C(Xi)| = 0(i.e.",
                "Xi is a leaf node) then 11: UTILXi (P(Xi)) ← Compute utils(P(Xi),PP(Xi)) for all PP(Xi) 12: Send message(P(Xi), UTILXi (P(Xi)),BRANCHXi ) 13: Send message(PP(Xi), empty UTIL, empty BRANCH) to all PP(Xi) 14: activate UTIL Message handler() Phase 3: VALUE message propagation 15: activate VALUE Message handler() END ALGORITHM UTIL Message handler(Xk,UTILXk (Xi), BRANCHXk ) 16: store UTILXk (Xi),BRANCHXk (Xi) 17: if UTIL messages from all children and branch children arrived then 18: for all Bj ∈BRANCH(Xi) do 19: if Bj is merged then 20: join all hypercubes where Bj ∈UTIL(Xi) 21: eliminate Bj from the joined hypercube 22: if P(Xi) == null (that means Xi is the root) then 23: v ∗ i ← Choose optimal(null) 24: Send VALUE(Xi, v ∗ i) to all C(Xi) 25: else 26: UTILXi (P(Xi)) ← Compute utils(P(Xi), PP(Xi)) 27: Send message(P(Xi),UTILXi (P(Xi)), BRANCHXi (P(Xi))) VALUE Message handler(VALUEXi ,P(Xi)) 28: add all Xk ← v ∗ k ∈VALUEXi ,P(Xi) to agent view 29: Xi ← v ∗ i =Choose optimal(agent view) 30: Send VALUEXl , Xi to all Xl ∈C(Xi) that in real world problems the generation of the pseudotree has a significant impact on the actual performance.",
                "The problem of finding the best pseudotree for a given DCOP instance is NP-Hard.",
                "Thus a heuristic is used for generation, and the performance of the algorithm depends on the pseudotree found by the heuristic.",
                "Some previous research focused on finding heuristics to generate good pseudotrees [8].",
                "While we have developed some heuristics that generate good cross-edged pseudotrees for use with DCPOP, our focus has been to use multiple heuristics and then select the best pseudotree from the generated pseudotrees.",
                "We consider only heuristics that run in polynomial time with respect to the number of nodes in the original DCOP instance.",
                "The actual DCPOP algorithm has worst case exponential complexity, but we can calculate the maximum message size, computation size, and sequential path cost for a given cross-edged pseudotree in linear space-time complexity.",
                "To do this, we simply run the algorithm without attempting to calculate any of the local utility hypercubes or optimal value assignments.",
                "Instead, messages include dimensional and branch information but no utility hypercubes.",
                "After each heuristic completes its generation of a pseudotree, we execute the measurement procedure and propagate the measurement information up to the chosen root in that pseudotree.",
                "The root then broadcasts the total complexity for that heuristic to all nodes.",
                "After all heuristics have had a chance to complete, every node knows which heuristic produced the best pseudotree.",
                "Each node then proceeds to begin the DCPOP algorithm using its knowledge of the pseudotree generated by the best heuristic.",
                "The heuristics used to generate traditional pseudotrees perform a distributed DFS traversal.",
                "The general distributed algorithm uses a token passing mechanism and a linear number of messages.",
                "Improved DFS based heuristics use a special procedure to choose the root node, and also provide an ordering function over the neighbors of a node to determine the order of path recursion.",
                "The DFS based heuristics used in our experiments come from the work done in [4, 8]. 5.1 The best-first cross-edged pseudotree heuristic The heuristics used to generate cross-edged pseudotrees perform a best-first traversal.",
                "A general distributed best-first algorithm for node expansion is presented in Algorithm 2.",
                "An evaluation function at each node provides the values that are used to determine the next best node to expand.",
                "Note that in this algorithm each node only exchanges its best value with its neighbors.",
                "In our experiments we used several evaluation functions that took as arguments an ordered list of ancestors and a node, which contains a list of neighbors (with each neighbors placement depth in the tree if it was placed).",
                "From these we can calculate branchparents, branch-children, and unknown relationships for a potential node placement.",
                "The best overall function calculated the value as ancestors−(branchparents+branchchildren) with the number of unknown relationships being a tiebreak.",
                "After completion each node has knowledge of its parent and ancestors, so it can easily determine which connected nodes are pseudo-parents, branchparents, pseudo-children, and branch-children.",
                "The complexity of the best-first traversal depends on the complexity of the evaluation function.",
                "Assuming a complexity of O(V ) for the evaluation function, which is the case for our best overall function, the best-first traversal is O(V · E) which is at worst O(n3 ).",
                "For each v ∈ V we perform a place operation, and find the next node to place using the getBestNeighbor operation.",
                "The place operation is at most O(V ) because of the sent messages.",
                "Finding the next node uses recursion and traverses only already placed The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 745 Algorithm 2 Distributed Best-First Search Algorithm root ← electedleader next(root, ∅) place(node, parent) node.parent ← parent node.ancestors ← parent.ancestors ∪ parent send placement message (node, node.ancestors) to all neighbors of node next(current, previous) if current is not placed then place(current, previous) next(current, ∅) else best ← getBestNeighbor(current, previous) if best = ∅ then if previous = ∅ then terminate, all nodes are placed next(previous, ∅) else next(best, current) getBestNeighbor(current, previous) best ← ∅; score ← 0 for all n ∈ current.neighbors do if n! = previous then if n is placed then nscore ← getBestNeighbor(n, current) else nscore ← evaluate(current, n) if nscore > score then score ← nscore best ← n return best, score nodes, so it has O(V ) recursions.",
                "Each recursion performs a recursive getBestNeighbor operation that traverses all placed nodes and their neighbors.",
                "This operation is O(V · E), but results can be cached using only O(V ) space at each node.",
                "Thus we have O(V ·(V +V +V ·E)) = O(V 2 ·E).",
                "If we are smart about evaluating local changes when each node receives placement messages from its neighbors and cache the results the getBestNeighbor operation is only O(E).",
                "This increases the complexity of the place operation, but for all placements the total complexity is only O(V · E).",
                "Thus we have an overall complexity of O(V ·E+V ·(V +E)) = O(V ·E). 6.",
                "COMPARISON OF COMPLEXITY IN DPOP AND DCPOP We have already shown that given the same input, DCPOP performs the same as DPOP.",
                "We also have shown that we can accurately predict performance of a given pseudotree in linear spacetime complexity.",
                "If we use a constant number of heuristics to generate the set of pseudotrees, we can choose the best pseudotree in linear space-time complexity.",
                "We will now show that there exists a DCOP instance for which a cross-edged pseudotree outperforms all possible traditional pseudotrees (based on edge-traversal heuristics).",
                "In Figure 3(a) we have a DCOP instance with six nodes.",
                "This is a bipartite graph with each partition fully connected to the other (a) (b) (c) Figure 3: (a) The DCOP instance (b) A traditional pseudotree arrangement for the DCOP instance (c) A cross-edged pseudotree arrangement for the DCOP instance partition.",
                "In Figure 3(b) we see a traditional pseudotree arrangement for this DCOP instance.",
                "It is easy to see that any edgetraversal based heuristic cannot expand two nodes from the same partition in succession.",
                "We also see that no node can have more than one child because any such arrangement would be an invalid pseudotree.",
                "Thus any traditional pseudotree arrangement for this DCOP instance must take the form of Figure 3(b).",
                "We can see that the back-edges F-B and F-A overlap node C. Node C also has a parent E, and a back-edge with D. Using the original DPOP algorithm (or DCPOP since they are identical in this case), we find that the computation at node C involves five domains: A, B, C, D, and E. In contrast, the cross-edged pseudotree arrangement in Figure 3(c) requires only a maximum of four domains in any computation during DCPOP.",
                "Since node A is the merge point for branches from both B and C, we can see that each of the nodes D, E, and F have two overlapping branches.",
                "In addition each of these nodes has node A as its parent.",
                "Using the DCPOP algorithm we find that the computation at node D (or E or F) involves four domains: A, B, C, and D (or E or F).",
                "Since no better traditional pseudotree arrangement can be created using an edge-traversal heuristic, we have shown that DCPOP can outperform DPOP even if we use the optimal pseudotree found through edge-traversal.",
                "We acknowledge that pseudotree arrangements that allow parent-child relationships without an actual constraint can solve the problem in Figure 3(a) with maximum computation size of four domains.",
                "However, current heuristics used with DPOP do not produce such pseudotrees, and such a heuristic would be difficult to distribute since each node would require information about nodes with which it has no constraint.",
                "Also, while we do not prove it here, cross-edged pseudotrees can produce smaller message sizes than such pseudotrees even if the computation size is similar.",
                "In practice, since finding the best pseudotree arrangement is NP-Hard, we find that heuristics that produce cross-edged pseudotrees often produce significantly smaller computation and message sizes. 7.",
                "EXPERIMENTAL RESULTS 746 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Existing performance metrics for DCOP algorithms include the total number of messages, synchronous clock cycles, and message size.",
                "We have already shown that the total number of messages is linear with respect to the number of constraints in the DCOP instance.",
                "We also introduced the maximum sequential path cost (PC) as a measurement of the maximum amount of parallelism achievable by the algorithm.",
                "The maximum sequential path cost is equal to the sum of the computations performed on the longest path from the root to any leaf node.",
                "We also include as metrics the maximum computation size in number of dimensions (CD) and maximum message size in number of dimensions (MD).",
                "To analyze the relative complexity of a given DCOP instance, we find the minimum induced width (IW) of any traditional pseudotree produced by a heuristic for the original DPOP. 7.1 Generic DCOP instances For our initial tests we randomly generated two sets of problems with 3000 cases in each.",
                "Each problem was generated by assigning a random number (picked from a range) of constraints to each variable.",
                "The generator then created binary constraints until each variable reached its maximum number of constraints.",
                "The first set uses 20 variables, and the best DPOP IW ranges from 1 to 16 with an average of 8.5.",
                "The second set uses 100 variables, and the best DPOP IW ranged from 2 to 68 with an average of 39.3.",
                "Since most of the problems in the second set were too complex to actually compute the solution, we took measurements of the metrics using the techniques described earlier in Section 5 without actually solving the problem.",
                "Results are shown for the first set in Table 1 and for the second set in Table 2.",
                "For the two problem sets we split the cases into low density and high density categories.",
                "Low density cases consist of those problems that have a best DPOP IW less than or equal to half of the total number of nodes (e.g.",
                "IW ≤ 10 for the 20 node problems and IW ≤ 50 for the 100 node problems).",
                "High density problems consist of the remainder of the problem sets.",
                "In both Table 1 and Table 2 we have listed performance metrics for the original DPOP algorithm, the DCPOP algorithm using only cross-edged pseudotrees (DCPOP-CE), and the DCPOP algorithm using traditional and cross-edged pseudotrees (DCPOP-All).",
                "The pseudotrees used for DPOP were generated using 5 heuristics: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB, and DFS MCN BEC.",
                "These are all versions of the guided DFS traversal discussed in Section 5.",
                "The cross-edged pseudotrees used for DCPOP-CE were generated using 5 heuristics: MCN, LCN, MCN A-B, LCN A-B, and LCSG A-B.",
                "These are all versions of the best-first traversal discussed in Section 5.",
                "For both DPOP and DCPOP-CE we chose the best pseudotree produced by their respective 5 heuristics for each problem in the set.",
                "For DCPOP-All we chose the best pseudotree produced by all 10 heuristics for each problem in the set.",
                "For the CD and MD metrics the value shown is the average number of dimensions.",
                "For the PC metric the value shown is the natural logarithm of the maximum sequential path cost (since the actual value grows exponentially with the complexity of the problem).",
                "The final row in both tables is a measurement of improvement of DCPOP-All over DPOP.",
                "For the CD and MD metrics the value shown is a reduction in number of dimensions.",
                "For the PC metric the value shown is a percentage reduction in the maximum sequential path cost (% = DP OP −DCP OP DCP OP ∗ 100).",
                "Notice that DCPOPAll outperforms DPOP on all metrics.",
                "This logically follows from our earlier assertion that given the same input, DCPOP performs exactly the same as DPOP.",
                "Thus given the choice between the pseudotrees produced by all 10 heuristics, DCPOP-All will always outLow Density High Density Algorithm CD MD PC CD MD PC DPOP 7.81 6.81 3.78 13.34 12.34 5.34 DCPOP-CE 7.94 6.73 3.74 12.83 11.43 5.07 DCPOP-All 7.62 6.49 3.66 12.72 11.36 5.05 Improvement 0.18 0.32 13% 0.62 0.98 36% Table 1: 20 node problems Low Density High Density Algorithm CD MD PC CD MD PC DPOP 33.35 32.35 14.55 58.51 57.50 19.90 DCPOP-CE 33.49 29.17 15.22 57.11 50.03 20.01 DCPOP-All 32.35 29.57 14.10 56.33 51.17 18.84 Improvement 1.00 2.78 104% 2.18 6.33 256% Table 2: 100 node problems Figure 4: Computation Dimension Size Figure 5: Message Dimension Size The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 747 Figure 6: Path Cost DCPOP Improvement Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Table 3: Meeting Scheduling Problems perform DPOP.",
                "Another trend we notice is that the improvement is greater for high density problems than low density problems.",
                "We show this trend in greater detail in Figures 4, 5, and 6.",
                "Notice how the improvement increases as the complexity of the problem increases. 7.2 Meeting Scheduling Problem In addition to our initial generic DCOP tests, we ran a series of tests on the Meeting Scheduling Problem (MSP) as described in [6].",
                "The problem setup includes a number of people that are grouped into departments.",
                "Each person must attend a specified number of meetings.",
                "Meetings can be held within departments or among departments, and can be assigned to one of eight time slots.",
                "The MSP maps to a DCOP instance where each variable represents the time slot that a specific person will attend a specific meeting.",
                "All variables that belong to the same person have mutual exclusion constraints placed so that the person cannot attend more than one meeting during the same time slot.",
                "All variables that belong to the same meeting have equality constraints so that all of the participants choose the same time slot.",
                "Unary constraints are placed on each variable to account for a persons valuation of each meeting and time slot.",
                "For our tests we generated 100 sample problems for each combination of agents and meetings.",
                "Results are shown in Table 3.",
                "The values in the first five columns represent (in left to right order), the total number of agents, the total number of meetings, the total number of variables, the average total number of constraints, and the average minimum IW produced by a traditional pseudotree.",
                "The last three columns show the same metrics we used for the generic DCOP instances, except this time we only show the improvements of DCPOP-All over DPOP.",
                "Performance is better on average for all MSP instances, but again we see larger improvements for more complex problem instances. 8.",
                "CONCLUSIONS AND FUTURE WORK We presented a complete, distributed algorithm that solves general DCOP instances using cross-edged pseudotree arrangements.",
                "Our algorithm extends the DPOP algorithm by adding additional utility propagation messages, and introducing the concept of branch merging during the utility propagation phase.",
                "Our algorithm also allows value assignments to occur at higher level merge points for lower level nodes.",
                "We have shown that DCPOP fully extends DPOP by performing the same operations given the same input.",
                "We have also shown through some examples and experimental data that DCPOP can achieve greater performance for some problem instances by extending the allowable input set to include cross-edged pseudotrees.",
                "We placed particular emphasis on the role that edge-traversal heuristics play in the generation of pseudotrees.",
                "We have shown that the performance penalty is minimal to generate multiple heuristics, and that we can choose the best generated pseudotree in linear space-time complexity.",
                "Given the importance of a good pseudotree for performance, future work will include new heuristics to find better pseudotrees.",
                "Future work will also include adapting existing DPOP extensions [5, 7] that support different problem domains for use with DCPOP. 9.",
                "REFERENCES [1] J. Liu and K. P. Sycara.",
                "Exploiting problem structure for distributed constraint optimization.",
                "In V. Lesser, editor, Proceedings of the First International Conference on Multi-Agent Systems, pages 246-254, San Francisco, CA, 1995.",
                "MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni.",
                "A dynamic distributed constraint satisfaction approach to resource allocation.",
                "Lecture Notes in Computer Science, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe, and M. Yokoo.",
                "An asynchronous complete method for distributed constraint optimization.",
                "In AAMAS 03, 2003. [4] A. Petcu.",
                "Frodo: A framework for open/distributed constraint optimization.",
                "Technical Report No. 2006/001 2006/001, Swiss Federal Institute of Technology (EPFL), Lausanne (Switzerland), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu and B. Faltings.",
                "A-dpop: Approximations in distributed optimization.",
                "In poster in CP 2005, pages 802-806, Sitges, Spain, October 2005. [6] A. Petcu and B. Faltings.",
                "Dpop: A scalable method for multiagent constraint optimization.",
                "In IJCAI 05, pages 266-271, Edinburgh, Scotland, Aug 2005. [7] A. Petcu, B. Faltings, and D. Parkes.",
                "M-dpop: Faithful distributed implementation of efficient social choice problems.",
                "In AAMAS 06, pages 1397-1404, Hakodate, Japan, May 2006. [8] G. Ushakov.",
                "Solving meeting scheduling problems using distributed pseudotree-optimization procedure.",
                "Masters thesis, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "Distributed constraint satisfaction for formalizing distributed problem solving.",
                "In International Conference on Distributed Computing Systems, pages 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "The distributed constraint satisfaction problem: Formalization and algorithms.",
                "Knowledge and Data Engineering, 10(5):673-685, 1998. 748 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "Early domains for distributed constraint satisfaction problems (DisCSP) included <br>job shop scheduling</br> [1] and resource allocation [2]."
            ],
            "translated_annotated_samples": [
                "Los primeros dominios para problemas de satisfacción de restricciones distribuidas (DisCSP) incluyeron la <br>programación de talleres de trabajo</br> [1] y la asignación de recursos [2]."
            ],
            "translated_text": "Un Método Completo de Optimización de Restricciones Distribuidas para Arreglos de Pseudotree No Tradicionales∗ James Atlas Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 decker@cis.udel.edu RESUMEN La Optimización de Restricciones Distribuidas (DCOP) es un marco general que puede modelar problemas complejos en sistemas multiagente. Varios algoritmos actuales que resuelven instancias generales de DCOP, incluyendo ADOPT y DPOP, organizan a los agentes en una estructura de pseudobosque tradicional. Introducimos una extensión al algoritmo DPOP que maneja un conjunto extendido de disposiciones de pseudobosque. Nuestro algoritmo resuelve correctamente instancias de DCOP para pseudobosques que incluyen aristas entre nodos en ramas separadas. El algoritmo también resuelve instancias con arreglos de pseudobosque tradicionales utilizando el mismo procedimiento que DPOP. Comparamos nuestro algoritmo con DPOP utilizando varios métricos, incluyendo el ancho inducido de los pseudobosques, la dimensionalidad máxima de los mensajes y la computación, y el costo máximo de la ruta secuencial a través del algoritmo. Demostramos que para algunas instancias del problema no es posible generar un pseudoárbol tradicional utilizando heurísticas de recorrido de aristas que supere a un pseudoárbol con aristas cruzadas. Utilizamos múltiples heurísticas para generar pseudoárboles y elegir el mejor pseudoárbol en complejidad espacio-temporal lineal. Para algunas instancias del problema observamos mejoras significativas en los tamaños de los mensajes y cálculos en comparación con DPOP. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Algoritmos 1. INTRODUCCIÓN Muchos problemas históricos en la comunidad de IA pueden transformarse en Problemas de Satisfacción de Restricciones (CSP). Con la llegada de la inteligencia artificial distribuida, los sistemas multiagente se convirtieron en una forma popular de modelar las interacciones complejas y la coordinación necesaria para resolver problemas distribuidos. Los CSPs fueron originalmente extendidos a entornos de agentes distribuidos en [9]. Los primeros dominios para problemas de satisfacción de restricciones distribuidas (DisCSP) incluyeron la <br>programación de talleres de trabajo</br> [1] y la asignación de recursos [2]. Muchos dominios para sistemas de agentes, especialmente coordinación de trabajo en equipo, programación distribuida y redes de sensores, implican problemas excesivamente restringidos que son difíciles o imposibles de satisfacer para cada restricción. Los enfoques recientes para resolver problemas en estos dominios se basan en técnicas de optimización que mapean restricciones en funciones de utilidad multivaluadas. En lugar de encontrar una asignación que satisfaga todas las restricciones, estos enfoques encuentran una asignación que produce un alto nivel de utilidad global. Esta extensión al enfoque original de DisCSP se ha vuelto popular en sistemas multiagente, y ha sido etiquetada como Problema de Optimización de Restricciones Distribuidas (DCOP) [1]. Los algoritmos actuales que resuelven DCOPs completos utilizan dos enfoques principales: búsqueda y programación dinámica. Los algoritmos basados en búsqueda que se originaron a partir de DisCSP típicamente utilizan alguna forma de retroceso [10] o propagación de límites, como en ADOPT [3]. Los algoritmos basados en programación dinámica incluyen DPOP y sus extensiones [5, 6, 7]. Hasta la fecha, ambas categorías de algoritmos organizan agentes en un pseudoárbol tradicional para resolver el problema. Se ha demostrado en [6] que cualquier grafo de restricciones puede ser mapeado en un pseudoárbol tradicional. Sin embargo, también se demostró que encontrar el pseudoárbol óptimo era NP-Difícil. Comenzamos a investigar el rendimiento de los pseudobosques tradicionales generados por las heurísticas actuales de recorrido de aristas. Descubrimos que estas heurísticas a menudo generaban poco paralelismo, ya que los pseudárboles tendían a tener una gran profundidad y bajos factores de ramificación. Sospechábamos que podría haber otras formas de organizar los pseudobosques que proporcionarían un mayor paralelismo y tamaños de mensaje más pequeños. Después de explorar estos otros arreglos, descubrimos que los pseudobosques de bordes cruzados proporcionan profundidades más cortas y factores de ramificación más altos que los pseudobosques tradicionales. Nuestra hipótesis era que estos pseudorboles cruzados superarían a los pseudorboles tradicionales en algunos tipos de problemas. En este artículo presentamos una extensión al algoritmo DPOP que maneja un conjunto ampliado de disposiciones de pseudobosque que incluyen pseudobosques con aristas cruzadas. Comenzamos con una definición de 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, pseudobosques tradicionales y pseudobosques de bordes cruzados. Luego proporcionamos un resumen del algoritmo DPOP original e introducimos nuestro algoritmo DCPOP. Discutimos la complejidad de nuestro algoritmo, así como el impacto de las heurísticas de generación de pseudobosques. Luego demostramos que nuestro Procedimiento de Optimización de Pseudotree de Bordes Cruzados Distribuido (DCPOP) funciona significativamente mejor en la práctica que el algoritmo DPOP original para algunas instancias del problema. Concluimos con una selección de ideas para trabajos futuros y extensiones para DCPOP. 2. La DEFINICIÓN DEL PROBLEMA DCOP ha sido formalizada de maneras ligeramente diferentes en la literatura reciente, por lo que adoptaremos la definición presentada en [6]. Un Problema de Optimización de Restricciones Distribuidas con n nodos y m restricciones consiste en la tupla < X, D, U > donde: • X = {x1,..,xn} es un conjunto de variables, cada una asignada a un agente único • D = {d1,..,dn} es un conjunto de dominios finitos para cada variable • U = {u1,..,um} es un conjunto de funciones de utilidad tales que cada función involucra un subconjunto de variables en X y define una utilidad para cada combinación de valores entre estas variables. Una solución óptima para una instancia de DCOP consiste en una asignación de valores en D a X tal que la suma de las utilidades en U sea máxima. Los dominios de problemas que requieren un costo mínimo en lugar de una utilidad máxima pueden mapear los costos en utilidades negativas. Las funciones de utilidad representan restricciones suaves pero también pueden representar restricciones fuertes mediante el uso de valores negativos arbitrariamente grandes. Para este artículo solo consideramos funciones de utilidad binarias que involucran dos variables. Las funciones de utilidad de orden superior pueden ser modeladas con cambios menores en el algoritmo, pero también aumentan sustancialmente la complejidad. 2.1 Pseudárboles Tradicionales Los pseudárboles son una estructura común utilizada en procedimientos de búsqueda para permitir el procesamiento paralelo de ramas independientes. Como se define en [6], un pseudoárbol es un arreglo de un grafo G en un árbol raíz T de tal manera que los vértices en G que comparten una arista están en la misma rama en T. Una arista de retroceso es una arista entre un nodo X y cualquier nodo que se encuentre en el camino desde X hasta la raíz (excluyendo al padre de X). La Figura 1 muestra un pseudoárbol con cuatro nodos, tres aristas (A-B, B-C, BD) y una arista de retroceso (A-C). También se definen en [6] cuatro tipos de relaciones entre nodos que existen en un pseudoárbol: • P(X) - el padre de un nodo X: el único nodo más alto en el pseudoárbol que está conectado a X directamente a través de un borde de árbol • C(X) - los hijos de un nodo X: el conjunto de nodos más bajos en el pseudo Las líneas sólidas representan relaciones padre-hijo y la línea discontinua representa una relación pseudo-padre-pseudo-hijo. Figura 2: Un pseudoárbol de bordes cruzados. Las líneas sólidas representan relaciones padre-hijo, la línea discontinua representa una relación pseudo-padre-pseudo-hijo, y la línea punteada representa una relación rama-padre-rama-hijo. El nodo en negrita, B, es el punto de fusión para el nodo E. 2.2 Pseudárboles con aristas cruzadas Definimos una arista cruzada como una arista de un nodo X a un nodo Y que está por encima de X pero no en el camino desde X hasta la raíz. Un pseudoárbol de bordes cruzados es un pseudoárbol tradicional con la adición de bordes cruzados. La Figura 2 muestra un pseudoárbol con una arista cruzada (D-E). En un pseudoárbol de bordes cruzados designamos ciertos bordes como primarios. El conjunto de aristas primarias define un árbol de expansión de los nodos. Las relaciones de padre, hijo, pseudo-padre y pseudo-hijo del pseudotree tradicional ahora están definidas en el contexto de este árbol de expansión de borde primario. Esta definición también produce dos tipos adicionales de relaciones que pueden existir entre nodos: • BP(X) - los nodos padres de rama de un nodo X: el conjunto de nodos más altos en el pseudoárbol que están conectados a X pero no están en el camino principal desde X hasta la raíz (En la Figura 2, D = BP(E)) • BC(X) - los nodos hijos de rama de un nodo X: el conjunto de nodos más bajos en el pseudo La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Los algoritmos actuales suelen tener una fase de pre-ejecución para generar un pseudoárbol tradicional a partir de una instancia general de DCOP. Nuestro algoritmo DCPOP genera un pseudoárbol de bordes cruzados de la misma manera. Primero, la instancia DCOP < X, D, U > se traduce directamente en un grafo con X como el conjunto de vértices y una arista para cada par de variables representadas en U. A continuación, se utilizan varias heurísticas para organizar este grafo en un pseudoárbol. Un heurístico común es realizar una búsqueda en profundidad guiada (DFS, por sus siglas en inglés) ya que el recorrido resultante es un pseudoárbol, y un DFS se puede realizar fácilmente de manera distribuida. Definimos un método basado en el recorrido de aristas como cualquier método que produce un pseudoárbol en el que todos los pares padre/hijo comparten una arista en el grafo original. Esto incluye recorridos basados en DFS, búsqueda en anchura y búsqueda de mejor primero. Nuestras heurísticas que generan pseudobosques de bordes cruzados utilizan un recorrido de búsqueda mejor primero distribuido. 3. ALGORITMO DPOP El algoritmo DPOP original opera en tres fases principales. La primera fase genera un pseudoárbol tradicional a partir de la instancia de DCOP utilizando un algoritmo distribuido. La segunda fase une hipercubos de utilidad de los nodos hijos y el nodo local y los propaga hacia la raíz. La tercera fase elige una asignación para cada dominio de arriba hacia abajo, comenzando con el agente en el nodo raíz. La complejidad de DPOP depende del tamaño del cálculo más grande y del mensaje de utilidad durante la fase dos. Se ha demostrado que este tamaño corresponde directamente al ancho inducido del pseudoárbol generado en la fase uno [6]. DPOP utiliza heurísticas de tiempo polinómico para generar el pseudoárbol, ya que encontrar el pseudoárbol de ancho inducido mínimo es NP-duro. Se han desarrollado varias heurísticas de recorrido de borde distribuido para encontrar pseudobosques de ancho reducido [8]. Al final de la primera fase, cada agente conoce a su padre, hijos, pseudo-padres y pseudo-hijos. 3.1 Propagación de utilidad Los agentes ubicados en los nodos hoja del pseudoárbol comienzan el proceso calculando un hipercubo de utilidad local. Este hipercubo en el nodo X contiene las utilidades sumadas para cada combinación de valores en los dominios de P(X) y PP(X). Este hipercubo tiene un tamaño dimensional igual al número de pseudo-padres más uno. Un mensaje que contiene este hipercubo se envía a P(X). Los agentes ubicados en nodos no hoja esperan a que lleguen todos los mensajes de los nodos hijos. Una vez que el agente en el nodo Y tiene todos los mensajes de utilidad, calcula su hipercubo de utilidad local que incluye los dominios de P(Y), PP(Y) y Y. El hipercubo de utilidad local se une luego con todos los hipercubos de los mensajes hijos. En este punto, todas las utilidades que involucran al nodo Y son conocidas, y el dominio de Y puede ser eliminado de forma segura del hipercubo unido. Este proceso de eliminación elige la mejor utilidad sobre el dominio de Y para cada combinación de los dominios restantes. Un mensaje que contiene este hipercubo se envía ahora a P(Y). El tamaño dimensional de este hipercubo depende del número de dominios superpuestos en los mensajes recibidos y del hipercubo de utilidad local. Esta fase de propagación basada en programación dinámica continúa hasta que el agente en el nodo raíz del pseudoárbol haya recibido todos los mensajes de sus hijos. 3.2 Propagación de Valor La propagación de valor comienza cuando el agente en el nodo raíz Z ha recibido todos los mensajes de sus hijos. Dado que Z no tiene padres ni pseudo-padres, simplemente combina los hipercubos de utilidad recibidos de sus hijos. El hipercubo combinado contiene solo valores para el dominio de Z. En este punto, el agente en el nodo Z simplemente elige la asignación para su dominio que tiene la mejor utilidad. Un mensaje de propagación de valor con esta asignación se envía a cada nodo en C(Z). Cada nodo luego recibe un mensaje de propagación de valor de su padre y elige la asignación para su dominio que tenga la mejor utilidad dadas las asignaciones recibidas en el mensaje. El nodo agrega su asignación de dominio a las asignaciones que recibió y pasa el conjunto de asignaciones a sus hijos. El algoritmo está completo cuando todos los nodos han elegido una asignación para su dominio. ALGORITMO DCPOP Nuestra extensión al algoritmo DPOP original, mostrada en el Algoritmo 1, comparte las mismas tres fases. La primera fase genera el pseudoárbol de bordes cruzados para la instancia de DCOP. La segunda fase fusiona ramas y propaga los hipercubos de utilidad. La tercera fase elige asignaciones para dominios en los puntos de fusión de ramas y de arriba hacia abajo, comenzando con el agente en el nodo raíz. Para la primera fase generamos un pseudoárbol utilizando varios heurísticos distribuidos y seleccionamos el que tenga la menor complejidad general. La complejidad de la computación y el tamaño del mensaje de utilidad en DCPOP no corresponden directamente al ancho inducido del pseudoárbol de aristas cruzadas. En cambio, utilizamos un método de tiempo polinómico para calcular el tamaño máximo de computación y utilidad del mensaje para un pseudoárbol de bordes cruzados dado. Una descripción de este método y el proceso de selección de pseudodendrogramas aparece en la Sección 5. Al final de la primera fase, cada agente conoce a su padre, hijos, pseudo-padres, pseudo-hijos, padres de rama e hijos de rama. 4.1 Fusión de Ramas y Propagación de Utilidad En el algoritmo DPOP original, un nodo X solo tenía funciones de utilidad que involucraban a su padre y a sus pseudo-padres. En DCPOP, se permite que un nodo X tenga una función de utilidad que involucre a un padre de rama. El concepto de una rama se puede ver en la Figura 2 con el nodo E representando nuestro nodo X. Las dos rutas distintas desde el nodo E hasta el nodo B se llaman ramas de E. El único nodo donde se encuentran todas las ramas de E es el nodo B, que se llama punto de fusión de E. Los agentes con nodos que tienen padres de rama comienzan enviando un mensaje de propagación de utilidad a cada padre de rama. Este mensaje incluye un hipercubo de utilidad bidimensional con dominios para el nodo X y el nodo padre de la rama BP(X). También incluye una estructura de información de rama que contiene el nodo de origen de la rama, X, el número total de ramas que se originan en X y el número de ramas que se originan en X y se fusionan en una representación única por esta estructura de información de rama (este número comienza en 1). Intuitivamente, cuando el número de ramas fusionadas es igual al número total de ramas originales, el algoritmo ha alcanzado el punto de fusión para X. En la Figura 2, el nodo E envía un mensaje de propagación de utilidad a su nodo padre de rama, el nodo D. Este mensaje tiene dimensiones para los dominios de E y D, e incluye información de rama con un origen en E, 2 ramas totales y 1 rama fusionada. Como en la fase de propagación de utilidad de la utilidad DPOP original, un agente en el nodo hoja X envía un mensaje de propagación de utilidad a su padre. En DCPOP, este mensaje contiene dimensiones para los dominios de P(X) y PP(X). Si el nodo X también tiene padres de rama, entonces el mensaje de propagación de utilidad también contiene una dimensión para el dominio de X e incluirá una estructura de información de rama. En la Figura 2, el nodo E envía un mensaje de propagación de utilidad a su padre, el nodo C. Este mensaje tiene dimensiones para los dominios de E y C, e incluye información de rama con un origen en E, 2 ramas en total y 1 rama fusionada. Cuando un nodo Y recibe mensajes de propagación de utilidad de todos de The Sixth Intl. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), 743 sus hijos y sus hijos de rama, fusiona cualquier rama con el mismo nodo de origen X. La estructura de información de la rama fusionada acumula el número de ramas fusionadas para X. Si el número total acumulado de ramas fusionadas es igual al número total de ramas, entonces Y es el punto de fusión para X. Esto significa que los hipercubos de utilidad presentes en Y contienen toda la información sobre las valoraciones de las funciones de utilidad que involucran al nodo X. Además de la eliminación típica del dominio de Y de los hipercubos de utilidad, ahora podemos eliminar de forma segura el dominio de X de los hipercubos de utilidad. Para ilustrar este proceso, examinaremos lo que sucede en la segunda fase para el nodo B en la Figura 2. En la segunda fase, el Nodo B recibe dos mensajes de propagación de utilidad. El primero proviene del nodo C e incluye dimensiones para los dominios E, B y A. También tiene una estructura de información de ramas con origen en E, 2 ramas en total y 1 rama fusionada. El segundo proviene del nodo D e incluye dimensiones para los dominios E y B. También tiene una estructura de información de rama con origen en E, 2 ramas en total y 1 rama fusionada. El nodo B luego fusiona las estructuras de información de rama de ambos mensajes porque tienen la misma procedencia, el nodo E. Dado que el número de ramas fusionadas que provienen de E es ahora 2 y el total de ramas que provienen de E es 2, el nodo B elimina las dimensiones para el dominio E. El nodo B también elimina la dimensión para su propio dominio, dejando solo información sobre el dominio A. Luego, el nodo B envía un mensaje de propagación de utilidad al nodo A, que contiene solo una dimensión para el dominio de A. Aunque no sea posible en DPOP, este método de propagación de utilidad y eliminación de dimensiones puede producir hipercubos en el nodo Y que no comparten ningún dominio. En DCPOP no unimos hipercubos independientes de dominio, sino que en su lugar podemos enviar múltiples hipercubos en el mensaje de propagación de utilidad enviado al padre de Y. Este enfoque perezoso de las uniones ayuda a reducir el tamaño de los mensajes. 4.2 Propagación de valores Al igual que en DPOP, la propagación de valores comienza cuando el agente en el nodo raíz Z ha recibido todos los mensajes de sus hijos. En este punto, el agente en el nodo Z elige la asignación para su dominio que tiene la mejor utilidad. Si Z es el punto de fusión de las ramas de algún nodo X, Z también elegirá la asignación para el dominio de X. Por lo tanto, cualquier nodo que sea un punto de fusión elegirá asignaciones para un dominio que no sea el suyo propio. Estas tareas luego se pasan por la jerarquía de la cadena de mando principal. Si el nodo X en la jerarquía tiene padres de rama, entonces el mensaje de asignación de valor de P(X) contendrá una asignación para el dominio de X. Cada nodo en la jerarquía agrega cualquier tarea que haya elegido a las que recibió y pasa el conjunto de tareas a sus hijos. El algoritmo está completo cuando todos los nodos han elegido o recibido una asignación para su dominio. 4.3 Prueba de Corrección Demostraremos la corrección de DCPOP notando primero que DCPOP extiende completamente DPOP y luego examinando los dos casos para la asignación de valores en DCPOP. Dado un pseudoárbol tradicional como entrada, la ejecución del algoritmo DCPOP es idéntica a DPOP. Usando un arreglo de pseudodendrograma tradicional, ningún nodo tiene padres de rama o hijos de rama, ya que todas las aristas son aristas de retroceso o aristas de árbol. Por lo tanto, el algoritmo DCPOP utilizando un pseudoárbol tradicional envía solo mensajes de propagación de utilidad que contienen dominios pertenecientes al padre o pseudo-padres de un nodo. Dado que ningún nodo tiene ramas-padres, no existen ramas, y por lo tanto ningún nodo sirve como punto de fusión para ningún otro nodo. Por lo tanto, todas las asignaciones de propagación de valor se eligen en el nodo del dominio de la asignación. Para la ejecución de DCPOP con pseudárboles de bordes cruzados, algunos nodos actúan como puntos de fusión. Observamos que cualquier nodo X que no sea un punto de fusión asigna su valor exactamente como en DPOP. El hipercubo de utilidad local en X contiene dominios para X, P(X), PP(X) y BC(X). Como en DPOP, el mensaje de asignación de valores recibido en X incluye los valores asignados a P(X) y PP(X). Además, dado que X no es un punto de fusión, todas las asignaciones a BC(X) deben haber sido calculadas en puntos de fusión más altos en el árbol y están en el mensaje de asignación de valor de P(X). Por lo tanto, después de eliminar los dominios para los cuales se conocen las asignaciones, solo queda el dominio de X. El agente en el nodo X ahora puede elegir correctamente la asignación con la máxima utilidad para su propio dominio. Si el nodo X es un punto de fusión para alguna rama-hijo Y, sabemos que X debe ser un nodo a lo largo del camino desde Y hasta la raíz, y desde P(Y) y todos los BP(Y) hasta la raíz. A partir del algoritmo, sabemos que Y necesariamente tiene toda la información de C(Y), PC(Y) y BC(Y) ya que espera sus mensajes. El nodo X tiene información sobre todos los nodos debajo de él en el árbol, lo cual incluiría a Y, P(Y), BP(Y) y aquellos PP(Y) que están debajo de X en el árbol. Para cualquier PP(Y) por encima de X en el árbol, X recibe la asignación para el dominio de PP(Y) en el mensaje de asignación de valor de P(X). Por lo tanto, X tiene información de utilidad sobre todas las funciones de utilidad de las cuales Y forma parte. Al eliminar los dominios incluidos en el mensaje de asignación de valor, el nodo X se queda con un hipercubo de utilidad local con dominios para X e Y. El agente en el nodo X ahora puede elegir correctamente las asignaciones con la máxima utilidad para los dominios de X e Y. 4.4 Análisis de complejidad La primera fase de DCPOP envía un mensaje a cada P(X), PP(X) y BP(X). La segunda fase envía un mensaje de asignación de valor a cada C(X). Por lo tanto, DCPOP produce un número lineal de mensajes con respecto al número de aristas (funciones de utilidad) en el pseudoárbol de aristas cruzadas y la instancia original de DCOP. La complejidad real de DCPOP depende de dos medidas adicionales: el tamaño del mensaje y el tamaño de la computación. El tamaño del mensaje y el tamaño de la computación en DCPOP dependen del número de ramas superpuestas, así como del número de aristas de retroceso superpuestas. Se demostró en [6] que el número de aristas traslapadas es igual al ancho inducido del pseudoárbol. En un pseudoárbol de bordes cruzados mal construido, el número de ramas superpuestas en el nodo X puede ser tan grande como el número total de descendientes de X. Por lo tanto, el tamaño total del mensaje en DCPOP en una instancia mal construida puede ser exponencial en el espacio en el número total de nodos en el grafo. Sin embargo, en la práctica, un pseudoárbol bien construido con bordes cruzados puede lograr resultados mucho mejores. Más tarde abordaremos el tema de elegir pseudobosques cruzados bien construidos de un conjunto. Introducimos una medida adicional del costo máximo de la ruta secuencial a través del algoritmo. Esta medida se relaciona directamente con la cantidad máxima de paralelismo que puede lograr el algoritmo. Para tomar esta medida, primero almacenamos el tamaño total de cálculo para cada nodo durante las fases dos y tres. Este tamaño de cálculo representa el número de accesos individuales a un valor en un hipercubo en cada nodo. Por ejemplo, una unión entre dos dominios de tamaño 4 cuesta 4 ∗ 4 = 16. Dos grafos acíclicos dirigidos (DAG) pueden ser dibujados; uno con los mensajes de propagación de utilidad como aristas y los costos de la fase dos en los nodos, y el otro con los mensajes de asignación de valor y los costos de la fase tres en los nodos. El costo máximo del camino secuencial es igual a la suma del camino más largo en cada DAG desde la raíz hasta cualquier nodo hoja. HEURÍSTICAS En nuestra evaluación de la complejidad en DCPOP nos enfocamos en el peor caso posiblemente producido por el algoritmo. Reconocemos 744 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Algoritmo 1 DCPOP Algoritmo 1: DCPOP(X; D; U) Cada agente Xi ejecuta: Fase 1: creación de pseudotree 2: elegir líder de todos los Xj ∈ X 3: líder elegido inicia la creación de pseudotree 4: después, Xi conoce P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) y PC(Xi) Fase 2: propagación de mensajes UTIL 5: si |BP(Xi)| > 0 entonces 6: BRANCHXi ← |BP(Xi)| + 1 7: para todos Xk ∈BP(Xi) hacer 8: UTILXi (Xk) ← Calcular utils(Xi, Xk) 9: Enviar mensaje(Xk,UTILXi (Xk),BRANCHXi ) 10: si |C(Xi)| = 0 (es decir, Si Xi es un nodo hoja, entonces 11: UTILXi (P(Xi)) ← Calcular utils(P(Xi),PP(Xi)) para todos los PP(Xi) 12: Enviar mensaje(P(Xi), UTILXi (P(Xi)), BRANCHXi ) 13: Enviar mensaje(PP(Xi), UTIL vacío, BRANCH vacío) a todos los PP(Xi) 14: Activar el manejador de mensajes UTIL() Fase 3: Propagación de mensajes de VALOR 15: Activar el manejador de mensajes de VALOR() FIN ALGORITMO Manejador de mensajes UTIL(Xk, UTILXk (Xi), BRANCHXk ) 16: Almacenar UTILXk (Xi), BRANCHXk (Xi) 17: Si han llegado mensajes UTIL de todos los hijos y los hijos de la rama, entonces 18: Para todos los Bj ∈ BRANCH(Xi) hacer 19: Si Bj está fusionado, entonces 20: Unir todos los hipercubos donde Bj ∈ UTIL(Xi) 21: Eliminar Bj del hipercubo unido 22: Si P(Xi) == nulo (eso significa que Xi es la raíz) entonces 23: v ∗ i ← Elegir óptimo(nulo) 24: Enviar VALOR(Xi, v ∗ i) a todos los C(Xi) 25: De lo contrario 26: UTILXi (P(Xi)) ← Calcular utils(P(Xi), PP(Xi)) 27: Enviar mensaje(P(Xi), UTILXi (P(Xi)), BRANCHXi (P(Xi))) Manejador de mensajes de VALOR(VALORXi , P(Xi)) 28: Agregar todos los Xk ← v ∗ k ∈ VALORXi , P(Xi) a la vista del agente 29: Xi ← v ∗ i = Elegir óptimo(vista del agente) 30: Enviar VALORXl , Xi a todos los Xl ∈ C(Xi) que en problemas del mundo real la generación del pseudoárbol tiene un impacto significativo en el rendimiento real. El problema de encontrar la mejor pseudotree para una instancia de DCOP dada es NP-Difícil. Por lo tanto, se utiliza una heurística para la generación, y el rendimiento del algoritmo depende del pseudoárbol encontrado por la heurística. Algunas investigaciones previas se centraron en encontrar heurísticas para generar buenas pseudorboles [8]. Si bien hemos desarrollado algunas heurísticas que generan buenos pseudoárboles cruzados para usar con DCPOP, nuestro enfoque ha sido utilizar múltiples heurísticas y luego seleccionar el mejor pseudo Consideramos solo heurísticas que se ejecuten en tiempo polinómico con respecto al número de nodos en la instancia original del DCOP. El algoritmo DCPOP actual tiene una complejidad exponencial en el peor de los casos, pero podemos calcular el tamaño máximo del mensaje, el tamaño de la computación y el costo de la ruta secuencial para un pseudoárbol de bordes cruzados dado en complejidad espacio-temporal lineal. Para hacer esto, simplemente ejecutamos el algoritmo sin intentar calcular ninguno de los hipercubos de utilidad local o asignaciones de valor óptimo. En cambio, los mensajes incluyen información dimensional y de ramificación pero no hipercubos de utilidad. Después de que cada heurística complete la generación de un pseudoárbol, ejecutamos el procedimiento de medición y propagamos la información de la medición hasta la raíz elegida en ese pseudo La raíz luego transmite la complejidad total de esa heurística a todos los nodos. Después de que todas las heurísticas hayan tenido la oportunidad de completarse, cada nodo sabe qué heurística produjo el mejor pseudoárbol. Cada nodo luego procede a comenzar el algoritmo DCPOP utilizando su conocimiento del pseudoárbol generado por la mejor heurística. Las heurísticas utilizadas para generar pseudárboles tradicionales realizan un recorrido DFS distribuido. El algoritmo distribuido general utiliza un mecanismo de paso de token y un número lineal de mensajes. Las heurísticas mejoradas basadas en DFS utilizan un procedimiento especial para elegir el nodo raíz, y también proporcionan una función de ordenación sobre los vecinos de un nodo para determinar el orden de la recursión de caminos. Las heurísticas basadas en DFS utilizadas en nuestros experimentos provienen del trabajo realizado en [4, 8]. 5.1 La heurística de pseudotree cruzado de mejor primer recorrido. Las heurísticas utilizadas para generar pseudárboles cruzados realizan un recorrido de mejor primer recorrido. Se presenta un algoritmo general distribuido de mejor primero para la expansión de nodos en el Algoritmo 2. Una función de evaluación en cada nodo proporciona los valores que se utilizan para determinar el siguiente mejor nodo a expandir. Ten en cuenta que en este algoritmo cada nodo solo intercambia su mejor valor con sus vecinos. En nuestros experimentos utilizamos varias funciones de evaluación que tomaban como argumentos una lista ordenada de ancestros y un nodo, que contiene una lista de vecinos (con la profundidad de colocación de cada vecino en el árbol). A partir de estos podemos calcular los padres de la rama, los hijos de la rama y las relaciones desconocidas para una posible ubicación del nodo. La mejor función general calculó el valor como ancestros - (padres de rama + hijos de rama) con el número de relaciones desconocidas como criterio de desempate. Después de completarse, cada nodo tiene conocimiento de su padre y ancestros, por lo que puede determinar fácilmente qué nodos conectados son pseudo-padres, padres de rama, pseudo-hijos e hijos de rama. La complejidad de la travesía de mejor primero depende de la complejidad de la función de evaluación. Suponiendo una complejidad de O(V) para la función de evaluación, que es el caso de nuestra mejor función general, el recorrido de mejor primero es O(V · E), lo que en el peor de los casos es O(n3). Para cada v ∈ V realizamos una operación de colocación y encontramos el siguiente nodo a colocar usando la operación getBestNeighbor. La complejidad de la operación del lugar es a lo sumo O(V) debido a los mensajes enviados. Encontrar el siguiente nodo utiliza recursión y recorre solo los ya colocados The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 745 Algoritmo 2 Algoritmo de Búsqueda Distribuida de Mejor Primero root ← líder elegido next(root, ∅) place(nodo, padre) nodo.padre ← padre nodo.ancestros ← padre.ancestros ∪ padre enviar mensaje de ubicación (nodo, nodo.ancestros) a todos los vecinos de nodo next(actual, anterior) si actual no está ubicado entonces place(actual, anterior) next(actual, ∅) else mejor ← obtenerMejorVecino(actual, anterior) si mejor = ∅ entonces si anterior = ∅ entonces terminar, todos los nodos están ubicados next(anterior, ∅) else next(mejor, actual) obtenerMejorVecino(actual, anterior) mejor ← ∅; puntaje ← 0 para todo n ∈ vecinos de actual hacer si n! = anterior entonces si n está ubicado entonces puntajeN ← obtenerMejorVecino(n, actual) else puntajeN ← evaluar(actual, n) si puntajeN > puntaje entonces puntaje ← puntajeN mejor ← n return mejor, puntaje nodos, por lo que tiene O(V) recursiones. Cada recursión realiza una operación recursiva getBestNeighbor que recorre todos los nodos colocados y sus vecinos. Esta operación es O(V · E), pero los resultados se pueden almacenar en caché utilizando solo O(V) espacio en cada nodo. Así que tenemos O(V ·(V +V +V ·E)) = O(V 2 ·E). Si somos inteligentes al evaluar los cambios locales cuando cada nodo recibe mensajes de ubicación de sus vecinos y almacenamos en caché los resultados, la operación getBestNeighbor es solo O(E). Esto aumenta la complejidad de la operación de ubicación, pero para todas las ubicaciones la complejidad total es solo O(V · E). Por lo tanto, tenemos una complejidad general de O(V ·E+V ·(V +E)) = O(V ·E). 6. COMPARACIÓN DE COMPLEJIDAD EN DPOP Y DCPOP Ya hemos demostrado que, dado el mismo input, DCPOP se desempeña igual que DPOP. También hemos demostrado que podemos predecir con precisión el rendimiento de un pseudoárbol dado en complejidad temporal lineal. Si usamos un número constante de heurísticas para generar el conjunto de pseudobosques, podemos elegir el mejor pseudobosque con complejidad lineal en espacio y tiempo. Ahora demostraremos que existe una instancia de DCOP para la cual un pseudoárbol de bordes cruzados supera a todos los posibles pseudoárboles tradicionales (basados en heurísticas de recorrido de bordes). En la Figura 3(a) tenemos una instancia de DCOP con seis nodos. Este es un grafo bipartito con cada partición completamente conectada a la otra (a) (b) (c) Figura 3: (a) La instancia de DCOP (b) Un arreglo de pseudobosque tradicional para la instancia de DCOP (c) Un arreglo de pseudobosque con aristas cruzadas para la partición de la instancia de DCOP. En la Figura 3(b) vemos un arreglo tradicional de pseudotree para esta instancia de DCOP. Es fácil ver que cualquier heurística basada en el recorrido de aristas no puede expandir dos nodos de la misma partición sucesivamente. También observamos que ningún nodo puede tener más de un hijo porque cualquier disposición de este tipo sería un pseudoárbol inválido. Por lo tanto, cualquier disposición tradicional de pseudodendrograma para esta instancia de DCOP debe tener la forma de la Figura 3(b). Podemos ver que las aristas de retroceso F-B y F-A se superponen al nodo C. El nodo C también tiene un padre E y una arista de retroceso con D. Utilizando el algoritmo DPOP original (o DCPOP ya que son idénticos en este caso), encontramos que el cálculo en el nodo C implica cinco dominios: A, B, C, D y E. En contraste, el arreglo de pseudonodos con aristas cruzadas en la Figura 3(c) requiere un máximo de cuatro dominios en cualquier cálculo durante DCPOP. Dado que el nodo A es el punto de fusión de las ramas tanto de B como de C, podemos ver que cada uno de los nodos D, E y F tiene dos ramas superpuestas. Además, cada uno de estos nodos tiene al nodo A como su padre. Usando el algoritmo DCPOP, encontramos que el cálculo en el nodo D (o E o F) implica cuatro dominios: A, B, C y D (o E o F). Dado que no se puede crear una disposición de pseudobosque tradicional mejor utilizando una heurística de recorrido de aristas, hemos demostrado que DCPOP puede superar a DPOP incluso si utilizamos el pseudobosque óptimo encontrado a través del recorrido de aristas. Reconocemos que los arreglos de pseudodistribución de árboles que permiten relaciones padre-hijo sin una restricción real pueden resolver el problema en la Figura 3(a) con un tamaño de cálculo máximo de cuatro dominios. Sin embargo, las heurísticas actuales utilizadas con DPOP no producen tales pseudobosques, y sería difícil distribuir una heurística así, ya que cada nodo requeriría información sobre nodos con los que no tiene restricciones. Además, aunque no lo demostramos aquí, los pseudobosques de bordes cruzados pueden producir tamaños de mensaje más pequeños que tales pseudobosques, incluso si el tamaño de la computación es similar. En la práctica, dado que encontrar la mejor disposición de pseudoramas es NP-Difícil, observamos que las heurísticas que producen pseudoramas con aristas cruzadas a menudo generan tamaños de cálculo y mensajes significativamente más pequeños. 7. RESULTADOS EXPERIMENTALES 746 El Sexto Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Los métricos de rendimiento existentes para algoritmos DCOP incluyen el número total de mensajes, ciclos de reloj síncronos y tamaño de mensaje. Ya hemos demostrado que el número total de mensajes es lineal con respecto al número de restricciones en la instancia de DCOP. También introdujimos el costo de camino secuencial máximo (PC) como una medida de la máxima cantidad de paralelismo alcanzable por el algoritmo. El costo máximo de la ruta secuencial es igual a la suma de los cálculos realizados en la ruta más larga desde la raíz hasta cualquier nodo hoja. También incluimos como métricas el tamaño máximo de cálculo en número de dimensiones (CD) y el tamaño máximo de mensaje en número de dimensiones (MD). Para analizar la complejidad relativa de una instancia DCOP dada, encontramos el ancho inducido mínimo (IW) de cualquier pseudobosque tradicional producido por una heurística para el DPOP original. 7.1 Instancias genéricas de DCOP Para nuestras pruebas iniciales generamos aleatoriamente dos conjuntos de problemas con 3000 casos en cada uno. Cada problema fue generado asignando un número aleatorio (elegido de un rango) de restricciones a cada variable. El generador luego creó restricciones binarias hasta que cada variable alcanzó su número máximo de restricciones. El primer conjunto utiliza 20 variables, y el mejor DPOP IW varía de 1 a 16 con un promedio de 8.5. El segundo conjunto utiliza 100 variables, y el mejor DPOP IW osciló entre 2 y 68 con un promedio de 39.3. Dado que la mayoría de los problemas en el segundo conjunto eran demasiado complejos para calcular la solución, tomamos medidas de las métricas utilizando las técnicas descritas anteriormente en la Sección 5 sin resolver realmente el problema. Los resultados se muestran para el primer conjunto en la Tabla 1 y para el segundo conjunto en la Tabla 2. Para los dos conjuntos de problemas dividimos los casos en categorías de baja densidad y alta densidad. Los casos de baja densidad consisten en aquellos problemas que tienen un mejor DPOP IW menor o igual a la mitad del número total de nodos (por ejemplo, IW ≤ 10 para los problemas de 20 nodos e IW ≤ 50 para los problemas de 100 nodos. Los problemas de alta densidad consisten en el resto de los conjuntos de problemas. En ambas Tabla 1 y Tabla 2 hemos enumerado las métricas de rendimiento para el algoritmo DPOP original, el algoritmo DCPOP utilizando solo pseudobosques de bordes cruzados (DCPOP-CE), y el algoritmo DCPOP utilizando pseudobosques tradicionales y de bordes cruzados (DCPOP-All). Los pseudobosques utilizados para DPOP fueron generados utilizando 5 heurísticas: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB y DFS MCN BEC. Estas son todas las versiones del recorrido DFS guiado discutidas en la Sección 5. Los pseudobosques de bordes cruzados utilizados para DCPOP-CE fueron generados utilizando 5 heurísticas: MCN, LCN, MCN A-B, LCN A-B y LCSG A-B. Estas son todas las versiones del recorrido de mejor primero discutidas en la Sección 5. Para tanto DPOP como DCPOP-CE elegimos el mejor pseudoárbol producido por sus respectivas 5 heurísticas para cada problema en el conjunto. Para DCPOP-All elegimos la mejor pseudotree producida por las 10 heurísticas para cada problema en el conjunto. Para las métricas de CD y MD, el valor mostrado es el número promedio de dimensiones. Para la métrica de PC, el valor mostrado es el logaritmo natural del costo de ruta secuencial máximo (ya que el valor real crece exponencialmente con la complejidad del problema). La última fila en ambas tablas es una medida de mejora de DCPOP-All sobre DPOP. Para las métricas CD y MD, el valor mostrado es una reducción en el número de dimensiones. Para la métrica de PC, el valor mostrado es una reducción porcentual en el costo máximo de la ruta secuencial (% = DP OP −DCP OP DCP OP ∗ 100). Observa que DCPOP supera a DPOP en todas las métricas. Esto se sigue lógicamente de nuestra afirmación anterior de que, dada la misma entrada, DCPOP se comporta exactamente igual que DPOP. Así, dada la elección entre los pseudobosques producidos por las 10 heurísticas, DCPOP-All siempre superará a DCPOP-CE y DPOP. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 6: Mejora del Costo del Camino DCPOP Reunión Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Tabla 3: Problemas de Programación de Reuniones realizan DPOP. Otra tendencia que observamos es que la mejora es mayor para problemas de alta densidad que para problemas de baja densidad. Mostramos esta tendencia con mayor detalle en las Figuras 4, 5 y 6. Observa cómo la mejora aumenta a medida que aumenta la complejidad del problema. 7.2 Problema de Programación de Reuniones Además de nuestras pruebas genéricas iniciales de DCOP, realizamos una serie de pruebas en el Problema de Programación de Reuniones (MSP) como se describe en [6]. La configuración del problema incluye un número de personas agrupadas en departamentos. Cada persona debe asistir a un número específico de reuniones. Las reuniones pueden llevarse a cabo dentro de los departamentos o entre departamentos, y pueden asignarse a uno de los ocho horarios disponibles. El MSP se mapea a una instancia de DCOP donde cada variable representa el intervalo de tiempo en el que una persona específica asistirá a una reunión específica. Todas las variables que pertenecen a la misma persona tienen restricciones de exclusión mutua para que la persona no pueda asistir a más de una reunión durante el mismo intervalo de tiempo. Todas las variables que pertenecen a la misma reunión tienen restricciones de igualdad para que todos los participantes elijan el mismo horario. Se imponen restricciones unarias en cada variable para tener en cuenta la valoración de una persona de cada reunión y franja horaria. Para nuestros tests generamos 100 problemas de muestra para cada combinación de agentes y reuniones. Los resultados se muestran en la Tabla 3. Los valores en las primeras cinco columnas representan (en orden de izquierda a derecha), el número total de agentes, el número total de reuniones, el número total de variables, el promedio total de restricciones y el promedio mínimo de IW producido por un pseudoárbol tradicional. Las últimas tres columnas muestran las mismas métricas que utilizamos para las instancias genéricas de DCOP, excepto que esta vez solo mostramos las mejoras de DCPOP-All sobre DPOP. El rendimiento es mejor en promedio para todas las instancias de MSP, pero nuevamente vemos mejoras más grandes para instancias de problemas más complejos. 8. CONCLUSIONES Y TRABAJO FUTURO Presentamos un algoritmo completo y distribuido que resuelve instancias generales de DCOP utilizando arreglos de pseudoramas cruzados. Nuestro algoritmo extiende el algoritmo DPOP al agregar mensajes adicionales de propagación de utilidad e introducir el concepto de fusión de ramas durante la fase de propagación de utilidad. Nuestro algoritmo también permite que las asignaciones de valor ocurran en puntos de fusión de nivel superior para nodos de nivel inferior. Hemos demostrado que DCPOP extiende completamente DPOP al realizar las mismas operaciones dadas las mismas entradas. También hemos demostrado a través de algunos ejemplos y datos experimentales que DCPOP puede lograr un mejor rendimiento para algunas instancias del problema al extender el conjunto de entrada permitido para incluir pseudobosques cruzados. Damos especial énfasis al papel que desempeñan las heurísticas de recorrido de bordes en la generación de pseudobosques. Hemos demostrado que la penalización en el rendimiento es mínima para generar múltiples heurísticas, y que podemos elegir el mejor pseudoárbol generado en complejidad lineal de espacio-tiempo. Dada la importancia de un buen pseudoárbol para el rendimiento, el trabajo futuro incluirá nuevas heurísticas para encontrar mejores pseudo El trabajo futuro también incluirá adaptar las extensiones existentes de DPOP [5, 7] que soportan diferentes dominios de problemas para su uso con DCPOP. 9. REFERENCIAS [1] J. Liu y K. P. Sycara. Explotando la estructura del problema para la optimización distribuida de restricciones. En V. Lesser, editor, Actas de la Primera Conferencia Internacional sobre Sistemas Multiagente, páginas 246-254, San Francisco, CA, 1995. MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, y S. Kulkarni. Un enfoque dinámico distribuido de satisfacción de restricciones para la asignación de recursos. Notas de conferencia en Ciencias de la Computación, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe y M. Yokoo. Un método completo asíncrono para la optimización de restricciones distribuidas. En AAMAS 03, 2003. [4] A. Petcu. Frodo: Un marco para la optimización de restricciones abiertas/distribuidas. Informe técnico No. 2006/001, Instituto Federal Suizo de Tecnología (EPFL), Lausana (Suiza), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu y B. Faltings. A-dpop: Aproximaciones en optimización distribuida. En póster en CP 2005, páginas 802-806, Sitges, España, octubre de 2005. [6] A. Petcu y B. Faltings. Dpop: Un método escalable para la optimización de restricciones multiagente. En IJCAI 05, páginas 266-271, Edimburgo, Escocia, agosto de 2005. [7] A. Petcu, B. Faltings y D. Parkes. M-dpop: Implementación distribuida fiel de problemas eficientes de elección social. En AAMAS 06, páginas 1397-1404, Hakodate, Japón, mayo de 2006. [8] G. Ushakov. Resolviendo problemas de programación de reuniones utilizando un procedimiento de optimización distribuido de pseudobosque. Tesis de maestría, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida y K. Kuwabara. Satisfacción de restricciones distribuida para formalizar la resolución de problemas distribuidos. En la Conferencia Internacional sobre Sistemas de Computación Distribuida, páginas 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida y K. Kuwabara. El problema de satisfacción de restricciones distribuidas: Formalización y algoritmos. Ingeniería del Conocimiento y de Datos, 10(5):673-685, 1998. 748 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "resource allocation": {
            "translated_key": "asignación de recursos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Complete Distributed Constraint Optimization Method For Non-Traditional Pseudotree Arrangements∗ James Atlas Computer and Information Sciences University of Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Computer and Information Sciences University of Delaware Newark, DE 19716 decker@cis.udel.edu ABSTRACT Distributed Constraint Optimization (DCOP) is a general framework that can model complex problems in multi-agent systems.",
                "Several current algorithms that solve general DCOP instances, including ADOPT and DPOP, arrange agents into a traditional pseudotree structure.",
                "We introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements.",
                "Our algorithm correctly solves DCOP instances for pseudotrees that include edges between nodes in separate branches.",
                "The algorithm also solves instances with traditional pseudotree arrangements using the same procedure as DPOP.",
                "We compare our algorithm with DPOP using several metrics including the induced width of the pseudotrees, the maximum dimensionality of messages and computation, and the maximum sequential path cost through the algorithm.",
                "We prove that for some problem instances it is not possible to generate a traditional pseudotree using edge-traversal heuristics that will outperform a cross-edged pseudotree.",
                "We use multiple heuristics to generate pseudotrees and choose the best pseudotree in linear space-time complexity.",
                "For some problem instances we observe significant improvements in message and computation sizes compared to DPOP.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent Systems General Terms Algorithms 1.",
                "INTRODUCTION Many historical problems in the AI community can be transformed into Constraint Satisfaction Problems (CSP).",
                "With the advent of distributed AI, multi-agent systems became a popular way to model the complex interactions and coordination required to solve distributed problems.",
                "CSPs were originally extended to distributed agent environments in [9].",
                "Early domains for distributed constraint satisfaction problems (DisCSP) included job shop scheduling [1] and <br>resource allocation</br> [2].",
                "Many domains for agent systems, especially teamwork coordination, distributed scheduling, and sensor networks, involve overly constrained problems that are difficult or impossible to satisfy for every constraint.",
                "Recent approaches to solving problems in these domains rely on optimization techniques that map constraints into multi-valued utility functions.",
                "Instead of finding an assignment that satisfies all constraints, these approaches find an assignment that produces a high level of global utility.",
                "This extension to the original DisCSP approach has become popular in multi-agent systems, and has been labeled the Distributed Constraint Optimization Problem (DCOP) [1].",
                "Current algorithms that solve complete DCOPs use two main approaches: search and dynamic programming.",
                "Search based algorithms that originated from DisCSP typically use some form of backtracking [10] or bounds propagation, as in ADOPT [3].",
                "Dynamic programming based algorithms include DPOP and its extensions [5, 6, 7].",
                "To date, both categories of algorithms arrange agents into a traditional pseudotree to solve the problem.",
                "It has been shown in [6] that any constraint graph can be mapped into a traditional pseudotree.",
                "However, it was also shown that finding the optimal pseudotree was NP-Hard.",
                "We began to investigate the performance of traditional pseudotrees generated by current edge-traversal heuristics.",
                "We found that these heuristics often produced little parallelism as the pseudotrees tended to have high depth and low branching factors.",
                "We suspected that there could be other ways to arrange the pseudotrees that would provide increased parallelism and smaller message sizes.",
                "After exploring these other arrangements we found that cross-edged pseudotrees provide shorter depths and higher branching factors than the traditional pseudotrees.",
                "Our hypothesis was that these crossedged pseudotrees would outperform traditional pseudotrees for some problem types.",
                "In this paper we introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements which include cross-edged pseudotrees.",
                "We begin with a definition of 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, traditional pseudotrees, and cross-edged pseudotrees.",
                "We then provide a summary of the original DPOP algorithm and introduce our DCPOP algorithm.",
                "We discuss the complexity of our algorithm as well as the impact of pseudotree generation heuristics.",
                "We then show that our Distributed Cross-edged Pseudotree Optimization Procedure (DCPOP) performs significantly better in practice than the original DPOP algorithm for some problem instances.",
                "We conclude with a selection of ideas for future work and extensions for DCPOP. 2.",
                "PROBLEM DEFINITION DCOP has been formalized in slightly different ways in recent literature, so we will adopt the definition as presented in [6].",
                "A Distributed Constraint Optimization Problem with n nodes and m constraints consists of the tuple < X, D, U > where: • X = {x1,..,xn} is a set of variables, each one assigned to a unique agent • D = {d1,..,dn} is a set of finite domains for each variable • U = {u1,..,um} is a set of utility functions such that each function involves a subset of variables in X and defines a utility for each combination of values among these variables An optimal solution to a DCOP instance consists of an assignment of values in D to X such that the sum of utilities in U is maximal.",
                "Problem domains that require minimum cost instead of maximum utility can map costs into negative utilities.",
                "The utility functions represent soft constraints but can also represent hard constraints by using arbitrarily large negative values.",
                "For this paper we only consider binary utility functions involving two variables.",
                "Higher order utility functions can be modeled with minor changes to the algorithm, but they also substantially increase the complexity. 2.1 Traditional Pseudotrees Pseudotrees are a common structure used in search procedures to allow parallel processing of independent branches.",
                "As defined in [6], a pseudotree is an arrangement of a graph G into a rooted tree T such that vertices in G that share an edge are in the same branch in T. A back-edge is an edge between a node X and any node which lies on the path from X to the root (excluding Xs parent).",
                "Figure 1 shows a pseudotree with four nodes, three edges (A-B, B-C, BD), and one back-edge (A-C).",
                "Also defined in [6] are four types of relationships between nodes exist in a pseudotree: • P(X) - the parent of a node X: the single node higher in the pseudotree that is connected to X directly through a tree edge • C(X) - the children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through tree edges • PP(X) - the pseudo-parents of a node X: the set of nodes higher in the pseudotree that are connected to X directly through back-edges (In Figure 1, A = PP(C)) • PC(X) - the pseudo-children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through back-edges (In Figure 1, C = PC(A)) Figure 1: A traditional pseudotree.",
                "Solid line edges represent parent-child relationships and the dashed line represents a pseudo-parent-pseudo-child relationship.",
                "Figure 2: A cross-edged pseudotree.",
                "Solid line edges represent parent-child relationships, the dashed line represents a pseudoparent-pseudo-child relationship, and the dotted line represents a branch-parent-branch-child relationship.",
                "The bolded node, B, is the merge point for node E. 2.2 Cross-edged Pseudotrees We define a cross-edge as an edge from node X to a node Y that is above X but not in the path from X to the root.",
                "A cross-edged pseudotree is a traditional pseudotree with the addition of cross-edges.",
                "Figure 2 shows a cross-edged pseudotree with a cross-edge (D-E).",
                "In a cross-edged pseudotree we designate certain edges as primary.",
                "The set of primary edges defines a spanning tree of the nodes.",
                "The parent, child, pseudo-parent, and pseudo-child relationships from the traditional pseudotree are now defined in the context of this primary edge spanning tree.",
                "This definition also yields two additional types of relationships that may exist between nodes: • BP(X) - the branch-parents of a node X: the set of nodes higher in the pseudotree that are connected to X but are not in the primary path from X to the root (In Figure 2, D = BP(E)) • BC(X) - the branch-children of a node X: the set of nodes lower in the pseudotree that are connected to X but are not in any primary path from X to any leaf node (In Figure 2, E = BC(D)) 2.3 Pseudotree Generation 742 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Current algorithms usually have a pre-execution phase to generate a traditional pseudotree from a general DCOP instance.",
                "Our DCPOP algorithm generates a cross-edged pseudotree in the same fashion.",
                "First, the DCOP instance < X, D, U > translates directly into a graph with X as the set of vertices and an edge for each pair of variables represented in U.",
                "Next, various heuristics are used to arrange this graph into a pseudotree.",
                "One common heuristic is to perform a guided depth-first search (DFS) as the resulting traversal is a pseudotree, and a DFS can easily be performed in a distributed fashion.",
                "We define an edge-traversal based method as any method that produces a pseudotree in which all parent/child pairs share an edge in the original graph.",
                "This includes DFS, breadth-first search, and best-first search based traversals.",
                "Our heuristics that generate cross-edged pseudotrees use a distributed best-first search traversal. 3.",
                "DPOP ALGORITHM The original DPOP algorithm operates in three main phases.",
                "The first phase generates a traditional pseudotree from the DCOP instance using a distributed algorithm.",
                "The second phase joins utility hypercubes from children and the local node and propagates them towards the root.",
                "The third phase chooses an assignment for each domain in a top down fashion beginning with the agent at the root node.",
                "The complexity of DPOP depends on the size of the largest computation and utility message during phase two.",
                "It has been shown that this size directly corresponds to the induced width of the pseudotree generated in phase one [6].",
                "DPOP uses polynomial time heuristics to generate the pseudotree since finding the minimum induced width pseudotree is NP-hard.",
                "Several distributed edgetraversal heuristics have been developed to find low width pseudotrees [8].",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, and pseudo-children. 3.1 Utility Propagation Agents located at leaf nodes in the pseudotree begin the process by calculating a local utility hypercube.",
                "This hypercube at node X contains summed utilities for each combination of values in the domains for P(X) and PP(X).",
                "This hypercube has dimensional size equal to the number of pseudo-parents plus one.",
                "A message containing this hypercube is sent to P(X).",
                "Agents located at non-leaf nodes wait for all messages from children to arrive.",
                "Once the agent at node Y has all utility messages, it calculates its local utility hypercube which includes domains for P(Y), PP(Y), and Y.",
                "The local utility hypercube is then joined with all of the hypercubes from the child messages.",
                "At this point all utilities involving node Y are known, and the domain for Y may be safely eliminated from the joined hypercube.",
                "This elimination process chooses the best utility over the domain of Y for each combination of the remaining domains.",
                "A message containing this hypercube is now sent to P(Y).",
                "The dimensional size of this hypercube depends on the number of overlapping domains in received messages and the local utility hypercube.",
                "This dynamic programming based propagation phase continues until the agent at the root node of the pseudotree has received all messages from its children. 3.2 Value Propagation Value propagation begins when the agent at the root node Z has received all messages from its children.",
                "Since Z has no parents or pseudo-parents, it simply combines the utility hypercubes received from its children.",
                "The combined hypercube contains only values for the domain for Z.",
                "At this point the agent at node Z simply chooses the assignment for its domain that has the best utility.",
                "A value propagation message with this assignment is sent to each node in C(Z).",
                "Each other node then receives a value propagation message from its parent and chooses the assignment for its domain that has the best utility given the assignments received in the message.",
                "The node adds its domain assignment to the assignments it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen an assignment for their domain. 4.",
                "DCPOP ALGORITHM Our extension to the original DPOP algorithm, shown in Algorithm 1, shares the same three phases.",
                "The first phase generates the cross-edged pseudotree for the DCOP instance.",
                "The second phase merges branches and propagates the utility hypercubes.",
                "The third phase chooses assignments for domains at branch merge points and in a top down fashion, beginning with the agent at the root node.",
                "For the first phase we generate a pseudotree using several distributed heuristics and select the one with lowest overall complexity.",
                "The complexity of the computation and utility message size in DCPOP does not directly correspond to the induced width of the cross-edged pseudotree.",
                "Instead, we use a polynomial time method for calculating the maximum computation and utility message size for a given cross-edged pseudotree.",
                "A description of this method and the pseudotree selection process appears in Section 5.",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, pseudo-children, branch-parents, and branch-children. 4.1 Merging Branches and Utility Propagation In the original DPOP algorithm a node X only had utility functions involving its parent and its pseudo-parents.",
                "In DCPOP, a node X is allowed to have a utility function involving a branch-parent.",
                "The concept of a branch can be seen in Figure 2 with node E representing our node X.",
                "The two distinct paths from node E to node B are called branches of E. The single node where all branches of E meet is node B, which is called the merge point of E. Agents with nodes that have branch-parents begin by sending a utility propagation message to each branch-parent.",
                "This message includes a two dimensional utility hypercube with domains for the node X and the branch-parent BP(X).",
                "It also includes a branch information structure which contains the origination node of the branch, X, the total number of branches originating from X, and the number of branches originating from X that are merged into a single representation by this branch information structure (this number starts at 1).",
                "Intuitively when the number of merged branches equals the total number of originating branches, the algorithm has reached the merge point for X.",
                "In Figure 2, node E sends a utility propagation message to its branch-parent, node D. This message has dimensions for the domains of E and D, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "As in the original DPOP utility propagation phase, an agent at leaf node X sends a utility propagation message to its parent.",
                "In DCPOP this message contains dimensions for the domains of P(X) and PP(X).",
                "If node X also has branch-parents, then the utility propagation message also contains a dimension for the domain of X, and will include a branch information structure.",
                "In Figure 2, node E sends a utility propagation message to its parent, node C. This message has dimensions for the domains of E and C, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "When a node Y receives utility propagation messages from all of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 743 its children and branch-children, it merges any branches with the same origination node X.",
                "The merged branch information structure accumulates the number of merged branches for X.",
                "If the cumulative total number of merged branches equals the total number of branches, then Y is the merge point for X.",
                "This means that the utility hypercubes present at Y contain all information about the valuations for utility functions involving node X.",
                "In addition to the typical elimination of the domain of Y from the utility hypercubes, we can now safely eliminate the domain of X from the utility hypercubes.",
                "To illustrate this process, we will examine what happens in the second phase for node B in Figure 2.",
                "In the second phase Node B receives two utility propagation messages.",
                "The first comes from node C and includes dimensions for domains E, B, and A.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "The second comes from node D and includes dimensions for domains E and B.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "Node B then merges the branch information structures from both messages because they have the same origination, node E. Since the number of merged branches originating from E is now 2 and the total branches originating from E is 2, node B now eliminates the dimensions for domain E. Node B also eliminates the dimension for its own domain, leaving only information about domain A. Node B then sends a utility propagation message to node A, containing only one dimension for the domain of A.",
                "Although not possible in DPOP, this method of utility propagation and dimension elimination may produce hypercubes at node Y that do not share any domains.",
                "In DCPOP we do not join domain independent hypercubes, but instead may send multiple hypercubes in the utility propagation message sent to the parent of Y.",
                "This lazy approach to joins helps to reduce message sizes. 4.2 Value Propagation As in DPOP, value propagation begins when the agent at the root node Z has received all messages from its children.",
                "At this point the agent at node Z chooses the assignment for its domain that has the best utility.",
                "If Z is the merge point for the branches of some node X, Z will also choose the assignment for the domain of X.",
                "Thus any node that is a merge point will choose assignments for a domain other than its own.",
                "These assignments are then passed down the primary edge hierarchy.",
                "If node X in the hierarchy has branch-parents, then the value assignment message from P(X) will contain an assignment for the domain of X.",
                "Every node in the hierarchy adds any assignments it has chosen to the ones it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen or received an assignment for their domain. 4.3 Proof of Correctness We will prove the correctness of DCPOP by first noting that DCPOP fully extends DPOP and then examining the two cases for value assignment in DCPOP.",
                "Given a traditional pseudotree as input, the DCPOP algorithm execution is identical to DPOP.",
                "Using a traditional pseudotree arrangement no nodes have branch-parents or branch-children since all edges are either back-edges or tree edges.",
                "Thus the DCPOP algorithm using a traditional pseudotree sends only utility propagation messages that contain domains belonging to the parent or pseudo-parents of a node.",
                "Since no node has any branch-parents, no branches exist, and thus no node serves as a merge point for any other node.",
                "Thus all value propagation assignments are chosen at the node of the assignment domain.",
                "For DCPOP execution with cross-edged pseudotrees, some nodes serve as merge points.",
                "We note that any node X that is not a merge point assigns its value exactly as in DPOP.",
                "The local utility hypercube at X contains domains for X, P(X), PP(X), and BC(X).",
                "As in DPOP the value assignment message received at X includes the values assigned to P(X) and PP(X).",
                "Also, since X is not a merge point, all assignments to BC(X) must have been calculated at merge points higher in the tree and are in the value assignment message from P(X).",
                "Thus after eliminating domains for which assignments are known, only the domain of X is left.",
                "The agent at node X can now correctly choose the assignment with maximum utility for its own domain.",
                "If node X is a merge point for some branch-child Y, we know that X must be a node along the path from Y to the root, and from P(Y) and all BP(Y) to the root.",
                "From the algorithm, we know that Y necessarily has all information from C(Y), PC(Y), and BC(Y) since it waits for their messages.",
                "Node X has information about all nodes below it in the tree, which would include Y, P(Y), BP(Y), and those PP(Y) that are below X in the tree.",
                "For any PP(Y) above X in the tree, X receives the assignment for the domain of PP(Y) in the value assignment message from P(X).",
                "Thus X has utility information about all of the utility functions of which Y is a part.",
                "By eliminating domains included in the value assignment message, node X is left with a local utility hypercube with domains for X and Y.",
                "The agent at node X can now correctly choose the assignments with maximum utility for the domains of X and Y. 4.4 Complexity Analysis The first phase of DCPOP sends one message to each P(X), PP(X), and BP(X).",
                "The second phase sends one value assignment message to each C(X).",
                "Thus, DCPOP produces a linear number of messages with respect to the number of edges (utility functions) in the cross-edged pseudotree and the original DCOP instance.",
                "The actual complexity of DCPOP depends on two additional measurements: message size and computation size.",
                "Message size and computation size in DCPOP depend on the number of overlapping branches as well as the number of overlapping back-edges.",
                "It was shown in [6] that the number of overlapping back-edges is equal to the induced width of the pseudotree.",
                "In a poorly constructed cross-edged pseudotree, the number of overlapping branches at node X can be as large as the total number of descendants of X.",
                "Thus, the total message size in DCPOP in a poorly constructed instance can be space-exponential in the total number of nodes in the graph.",
                "However, in practice a well constructed cross-edged pseudotree can achieve much better results.",
                "Later we address the issue of choosing well constructed crossedged pseudotrees from a set.",
                "We introduce an additional measurement of the maximum sequential path cost through the algorithm.",
                "This measurement directly relates to the maximum amount of parallelism achievable by the algorithm.",
                "To take this measurement we first store the total computation size for each node during phase two and three.",
                "This computation size represents the number of individual accesses to a value in a hypercube at each node.",
                "For example, a join between two domains of size 4 costs 4 ∗ 4 = 16.",
                "Two directed acyclic graphs (DAG) can then be drawn; one with the utility propagation messages as edges and the phase two costs at nodes, and the other with value assignment messages and the phase three costs at nodes.",
                "The maximum sequential path cost is equal to the sum of the longest path on each DAG from the root to any leaf node. 5.",
                "HEURISTICS In our assessment of complexity in DCPOP we focused on the worst case possibly produced by the algorithm.",
                "We acknowledge 744 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Algorithm 1 DCPOP Algorithm 1: DCPOP(X; D; U) Each agent Xi executes: Phase 1: pseudotree creation 2: elect leader from all Xj ∈ X 3: elected leader initiates pseudotree creation 4: afterwards, Xi knows P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) and PC(Xi) Phase 2: UTIL message propagation 5: if |BP(Xi)| > 0 then 6: BRANCHXi ← |BP(Xi)| + 1 7: for all Xk ∈BP(Xi) do 8: UTILXi (Xk) ←Compute utils(Xi, Xk) 9: Send message(Xk,UTILXi (Xk),BRANCHXi ) 10: if |C(Xi)| = 0(i.e.",
                "Xi is a leaf node) then 11: UTILXi (P(Xi)) ← Compute utils(P(Xi),PP(Xi)) for all PP(Xi) 12: Send message(P(Xi), UTILXi (P(Xi)),BRANCHXi ) 13: Send message(PP(Xi), empty UTIL, empty BRANCH) to all PP(Xi) 14: activate UTIL Message handler() Phase 3: VALUE message propagation 15: activate VALUE Message handler() END ALGORITHM UTIL Message handler(Xk,UTILXk (Xi), BRANCHXk ) 16: store UTILXk (Xi),BRANCHXk (Xi) 17: if UTIL messages from all children and branch children arrived then 18: for all Bj ∈BRANCH(Xi) do 19: if Bj is merged then 20: join all hypercubes where Bj ∈UTIL(Xi) 21: eliminate Bj from the joined hypercube 22: if P(Xi) == null (that means Xi is the root) then 23: v ∗ i ← Choose optimal(null) 24: Send VALUE(Xi, v ∗ i) to all C(Xi) 25: else 26: UTILXi (P(Xi)) ← Compute utils(P(Xi), PP(Xi)) 27: Send message(P(Xi),UTILXi (P(Xi)), BRANCHXi (P(Xi))) VALUE Message handler(VALUEXi ,P(Xi)) 28: add all Xk ← v ∗ k ∈VALUEXi ,P(Xi) to agent view 29: Xi ← v ∗ i =Choose optimal(agent view) 30: Send VALUEXl , Xi to all Xl ∈C(Xi) that in real world problems the generation of the pseudotree has a significant impact on the actual performance.",
                "The problem of finding the best pseudotree for a given DCOP instance is NP-Hard.",
                "Thus a heuristic is used for generation, and the performance of the algorithm depends on the pseudotree found by the heuristic.",
                "Some previous research focused on finding heuristics to generate good pseudotrees [8].",
                "While we have developed some heuristics that generate good cross-edged pseudotrees for use with DCPOP, our focus has been to use multiple heuristics and then select the best pseudotree from the generated pseudotrees.",
                "We consider only heuristics that run in polynomial time with respect to the number of nodes in the original DCOP instance.",
                "The actual DCPOP algorithm has worst case exponential complexity, but we can calculate the maximum message size, computation size, and sequential path cost for a given cross-edged pseudotree in linear space-time complexity.",
                "To do this, we simply run the algorithm without attempting to calculate any of the local utility hypercubes or optimal value assignments.",
                "Instead, messages include dimensional and branch information but no utility hypercubes.",
                "After each heuristic completes its generation of a pseudotree, we execute the measurement procedure and propagate the measurement information up to the chosen root in that pseudotree.",
                "The root then broadcasts the total complexity for that heuristic to all nodes.",
                "After all heuristics have had a chance to complete, every node knows which heuristic produced the best pseudotree.",
                "Each node then proceeds to begin the DCPOP algorithm using its knowledge of the pseudotree generated by the best heuristic.",
                "The heuristics used to generate traditional pseudotrees perform a distributed DFS traversal.",
                "The general distributed algorithm uses a token passing mechanism and a linear number of messages.",
                "Improved DFS based heuristics use a special procedure to choose the root node, and also provide an ordering function over the neighbors of a node to determine the order of path recursion.",
                "The DFS based heuristics used in our experiments come from the work done in [4, 8]. 5.1 The best-first cross-edged pseudotree heuristic The heuristics used to generate cross-edged pseudotrees perform a best-first traversal.",
                "A general distributed best-first algorithm for node expansion is presented in Algorithm 2.",
                "An evaluation function at each node provides the values that are used to determine the next best node to expand.",
                "Note that in this algorithm each node only exchanges its best value with its neighbors.",
                "In our experiments we used several evaluation functions that took as arguments an ordered list of ancestors and a node, which contains a list of neighbors (with each neighbors placement depth in the tree if it was placed).",
                "From these we can calculate branchparents, branch-children, and unknown relationships for a potential node placement.",
                "The best overall function calculated the value as ancestors−(branchparents+branchchildren) with the number of unknown relationships being a tiebreak.",
                "After completion each node has knowledge of its parent and ancestors, so it can easily determine which connected nodes are pseudo-parents, branchparents, pseudo-children, and branch-children.",
                "The complexity of the best-first traversal depends on the complexity of the evaluation function.",
                "Assuming a complexity of O(V ) for the evaluation function, which is the case for our best overall function, the best-first traversal is O(V · E) which is at worst O(n3 ).",
                "For each v ∈ V we perform a place operation, and find the next node to place using the getBestNeighbor operation.",
                "The place operation is at most O(V ) because of the sent messages.",
                "Finding the next node uses recursion and traverses only already placed The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 745 Algorithm 2 Distributed Best-First Search Algorithm root ← electedleader next(root, ∅) place(node, parent) node.parent ← parent node.ancestors ← parent.ancestors ∪ parent send placement message (node, node.ancestors) to all neighbors of node next(current, previous) if current is not placed then place(current, previous) next(current, ∅) else best ← getBestNeighbor(current, previous) if best = ∅ then if previous = ∅ then terminate, all nodes are placed next(previous, ∅) else next(best, current) getBestNeighbor(current, previous) best ← ∅; score ← 0 for all n ∈ current.neighbors do if n! = previous then if n is placed then nscore ← getBestNeighbor(n, current) else nscore ← evaluate(current, n) if nscore > score then score ← nscore best ← n return best, score nodes, so it has O(V ) recursions.",
                "Each recursion performs a recursive getBestNeighbor operation that traverses all placed nodes and their neighbors.",
                "This operation is O(V · E), but results can be cached using only O(V ) space at each node.",
                "Thus we have O(V ·(V +V +V ·E)) = O(V 2 ·E).",
                "If we are smart about evaluating local changes when each node receives placement messages from its neighbors and cache the results the getBestNeighbor operation is only O(E).",
                "This increases the complexity of the place operation, but for all placements the total complexity is only O(V · E).",
                "Thus we have an overall complexity of O(V ·E+V ·(V +E)) = O(V ·E). 6.",
                "COMPARISON OF COMPLEXITY IN DPOP AND DCPOP We have already shown that given the same input, DCPOP performs the same as DPOP.",
                "We also have shown that we can accurately predict performance of a given pseudotree in linear spacetime complexity.",
                "If we use a constant number of heuristics to generate the set of pseudotrees, we can choose the best pseudotree in linear space-time complexity.",
                "We will now show that there exists a DCOP instance for which a cross-edged pseudotree outperforms all possible traditional pseudotrees (based on edge-traversal heuristics).",
                "In Figure 3(a) we have a DCOP instance with six nodes.",
                "This is a bipartite graph with each partition fully connected to the other (a) (b) (c) Figure 3: (a) The DCOP instance (b) A traditional pseudotree arrangement for the DCOP instance (c) A cross-edged pseudotree arrangement for the DCOP instance partition.",
                "In Figure 3(b) we see a traditional pseudotree arrangement for this DCOP instance.",
                "It is easy to see that any edgetraversal based heuristic cannot expand two nodes from the same partition in succession.",
                "We also see that no node can have more than one child because any such arrangement would be an invalid pseudotree.",
                "Thus any traditional pseudotree arrangement for this DCOP instance must take the form of Figure 3(b).",
                "We can see that the back-edges F-B and F-A overlap node C. Node C also has a parent E, and a back-edge with D. Using the original DPOP algorithm (or DCPOP since they are identical in this case), we find that the computation at node C involves five domains: A, B, C, D, and E. In contrast, the cross-edged pseudotree arrangement in Figure 3(c) requires only a maximum of four domains in any computation during DCPOP.",
                "Since node A is the merge point for branches from both B and C, we can see that each of the nodes D, E, and F have two overlapping branches.",
                "In addition each of these nodes has node A as its parent.",
                "Using the DCPOP algorithm we find that the computation at node D (or E or F) involves four domains: A, B, C, and D (or E or F).",
                "Since no better traditional pseudotree arrangement can be created using an edge-traversal heuristic, we have shown that DCPOP can outperform DPOP even if we use the optimal pseudotree found through edge-traversal.",
                "We acknowledge that pseudotree arrangements that allow parent-child relationships without an actual constraint can solve the problem in Figure 3(a) with maximum computation size of four domains.",
                "However, current heuristics used with DPOP do not produce such pseudotrees, and such a heuristic would be difficult to distribute since each node would require information about nodes with which it has no constraint.",
                "Also, while we do not prove it here, cross-edged pseudotrees can produce smaller message sizes than such pseudotrees even if the computation size is similar.",
                "In practice, since finding the best pseudotree arrangement is NP-Hard, we find that heuristics that produce cross-edged pseudotrees often produce significantly smaller computation and message sizes. 7.",
                "EXPERIMENTAL RESULTS 746 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Existing performance metrics for DCOP algorithms include the total number of messages, synchronous clock cycles, and message size.",
                "We have already shown that the total number of messages is linear with respect to the number of constraints in the DCOP instance.",
                "We also introduced the maximum sequential path cost (PC) as a measurement of the maximum amount of parallelism achievable by the algorithm.",
                "The maximum sequential path cost is equal to the sum of the computations performed on the longest path from the root to any leaf node.",
                "We also include as metrics the maximum computation size in number of dimensions (CD) and maximum message size in number of dimensions (MD).",
                "To analyze the relative complexity of a given DCOP instance, we find the minimum induced width (IW) of any traditional pseudotree produced by a heuristic for the original DPOP. 7.1 Generic DCOP instances For our initial tests we randomly generated two sets of problems with 3000 cases in each.",
                "Each problem was generated by assigning a random number (picked from a range) of constraints to each variable.",
                "The generator then created binary constraints until each variable reached its maximum number of constraints.",
                "The first set uses 20 variables, and the best DPOP IW ranges from 1 to 16 with an average of 8.5.",
                "The second set uses 100 variables, and the best DPOP IW ranged from 2 to 68 with an average of 39.3.",
                "Since most of the problems in the second set were too complex to actually compute the solution, we took measurements of the metrics using the techniques described earlier in Section 5 without actually solving the problem.",
                "Results are shown for the first set in Table 1 and for the second set in Table 2.",
                "For the two problem sets we split the cases into low density and high density categories.",
                "Low density cases consist of those problems that have a best DPOP IW less than or equal to half of the total number of nodes (e.g.",
                "IW ≤ 10 for the 20 node problems and IW ≤ 50 for the 100 node problems).",
                "High density problems consist of the remainder of the problem sets.",
                "In both Table 1 and Table 2 we have listed performance metrics for the original DPOP algorithm, the DCPOP algorithm using only cross-edged pseudotrees (DCPOP-CE), and the DCPOP algorithm using traditional and cross-edged pseudotrees (DCPOP-All).",
                "The pseudotrees used for DPOP were generated using 5 heuristics: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB, and DFS MCN BEC.",
                "These are all versions of the guided DFS traversal discussed in Section 5.",
                "The cross-edged pseudotrees used for DCPOP-CE were generated using 5 heuristics: MCN, LCN, MCN A-B, LCN A-B, and LCSG A-B.",
                "These are all versions of the best-first traversal discussed in Section 5.",
                "For both DPOP and DCPOP-CE we chose the best pseudotree produced by their respective 5 heuristics for each problem in the set.",
                "For DCPOP-All we chose the best pseudotree produced by all 10 heuristics for each problem in the set.",
                "For the CD and MD metrics the value shown is the average number of dimensions.",
                "For the PC metric the value shown is the natural logarithm of the maximum sequential path cost (since the actual value grows exponentially with the complexity of the problem).",
                "The final row in both tables is a measurement of improvement of DCPOP-All over DPOP.",
                "For the CD and MD metrics the value shown is a reduction in number of dimensions.",
                "For the PC metric the value shown is a percentage reduction in the maximum sequential path cost (% = DP OP −DCP OP DCP OP ∗ 100).",
                "Notice that DCPOPAll outperforms DPOP on all metrics.",
                "This logically follows from our earlier assertion that given the same input, DCPOP performs exactly the same as DPOP.",
                "Thus given the choice between the pseudotrees produced by all 10 heuristics, DCPOP-All will always outLow Density High Density Algorithm CD MD PC CD MD PC DPOP 7.81 6.81 3.78 13.34 12.34 5.34 DCPOP-CE 7.94 6.73 3.74 12.83 11.43 5.07 DCPOP-All 7.62 6.49 3.66 12.72 11.36 5.05 Improvement 0.18 0.32 13% 0.62 0.98 36% Table 1: 20 node problems Low Density High Density Algorithm CD MD PC CD MD PC DPOP 33.35 32.35 14.55 58.51 57.50 19.90 DCPOP-CE 33.49 29.17 15.22 57.11 50.03 20.01 DCPOP-All 32.35 29.57 14.10 56.33 51.17 18.84 Improvement 1.00 2.78 104% 2.18 6.33 256% Table 2: 100 node problems Figure 4: Computation Dimension Size Figure 5: Message Dimension Size The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 747 Figure 6: Path Cost DCPOP Improvement Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Table 3: Meeting Scheduling Problems perform DPOP.",
                "Another trend we notice is that the improvement is greater for high density problems than low density problems.",
                "We show this trend in greater detail in Figures 4, 5, and 6.",
                "Notice how the improvement increases as the complexity of the problem increases. 7.2 Meeting Scheduling Problem In addition to our initial generic DCOP tests, we ran a series of tests on the Meeting Scheduling Problem (MSP) as described in [6].",
                "The problem setup includes a number of people that are grouped into departments.",
                "Each person must attend a specified number of meetings.",
                "Meetings can be held within departments or among departments, and can be assigned to one of eight time slots.",
                "The MSP maps to a DCOP instance where each variable represents the time slot that a specific person will attend a specific meeting.",
                "All variables that belong to the same person have mutual exclusion constraints placed so that the person cannot attend more than one meeting during the same time slot.",
                "All variables that belong to the same meeting have equality constraints so that all of the participants choose the same time slot.",
                "Unary constraints are placed on each variable to account for a persons valuation of each meeting and time slot.",
                "For our tests we generated 100 sample problems for each combination of agents and meetings.",
                "Results are shown in Table 3.",
                "The values in the first five columns represent (in left to right order), the total number of agents, the total number of meetings, the total number of variables, the average total number of constraints, and the average minimum IW produced by a traditional pseudotree.",
                "The last three columns show the same metrics we used for the generic DCOP instances, except this time we only show the improvements of DCPOP-All over DPOP.",
                "Performance is better on average for all MSP instances, but again we see larger improvements for more complex problem instances. 8.",
                "CONCLUSIONS AND FUTURE WORK We presented a complete, distributed algorithm that solves general DCOP instances using cross-edged pseudotree arrangements.",
                "Our algorithm extends the DPOP algorithm by adding additional utility propagation messages, and introducing the concept of branch merging during the utility propagation phase.",
                "Our algorithm also allows value assignments to occur at higher level merge points for lower level nodes.",
                "We have shown that DCPOP fully extends DPOP by performing the same operations given the same input.",
                "We have also shown through some examples and experimental data that DCPOP can achieve greater performance for some problem instances by extending the allowable input set to include cross-edged pseudotrees.",
                "We placed particular emphasis on the role that edge-traversal heuristics play in the generation of pseudotrees.",
                "We have shown that the performance penalty is minimal to generate multiple heuristics, and that we can choose the best generated pseudotree in linear space-time complexity.",
                "Given the importance of a good pseudotree for performance, future work will include new heuristics to find better pseudotrees.",
                "Future work will also include adapting existing DPOP extensions [5, 7] that support different problem domains for use with DCPOP. 9.",
                "REFERENCES [1] J. Liu and K. P. Sycara.",
                "Exploiting problem structure for distributed constraint optimization.",
                "In V. Lesser, editor, Proceedings of the First International Conference on Multi-Agent Systems, pages 246-254, San Francisco, CA, 1995.",
                "MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni.",
                "A dynamic distributed constraint satisfaction approach to <br>resource allocation</br>.",
                "Lecture Notes in Computer Science, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe, and M. Yokoo.",
                "An asynchronous complete method for distributed constraint optimization.",
                "In AAMAS 03, 2003. [4] A. Petcu.",
                "Frodo: A framework for open/distributed constraint optimization.",
                "Technical Report No. 2006/001 2006/001, Swiss Federal Institute of Technology (EPFL), Lausanne (Switzerland), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu and B. Faltings.",
                "A-dpop: Approximations in distributed optimization.",
                "In poster in CP 2005, pages 802-806, Sitges, Spain, October 2005. [6] A. Petcu and B. Faltings.",
                "Dpop: A scalable method for multiagent constraint optimization.",
                "In IJCAI 05, pages 266-271, Edinburgh, Scotland, Aug 2005. [7] A. Petcu, B. Faltings, and D. Parkes.",
                "M-dpop: Faithful distributed implementation of efficient social choice problems.",
                "In AAMAS 06, pages 1397-1404, Hakodate, Japan, May 2006. [8] G. Ushakov.",
                "Solving meeting scheduling problems using distributed pseudotree-optimization procedure.",
                "Masters thesis, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "Distributed constraint satisfaction for formalizing distributed problem solving.",
                "In International Conference on Distributed Computing Systems, pages 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "The distributed constraint satisfaction problem: Formalization and algorithms.",
                "Knowledge and Data Engineering, 10(5):673-685, 1998. 748 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "Early domains for distributed constraint satisfaction problems (DisCSP) included job shop scheduling [1] and <br>resource allocation</br> [2].",
                "A dynamic distributed constraint satisfaction approach to <br>resource allocation</br>."
            ],
            "translated_annotated_samples": [
                "Los primeros dominios para problemas de satisfacción de restricciones distribuidas (DisCSP) incluyeron la programación de talleres de trabajo [1] y la <br>asignación de recursos</br> [2].",
                "Un enfoque dinámico distribuido de satisfacción de restricciones para la <br>asignación de recursos</br>."
            ],
            "translated_text": "Un Método Completo de Optimización de Restricciones Distribuidas para Arreglos de Pseudotree No Tradicionales∗ James Atlas Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 decker@cis.udel.edu RESUMEN La Optimización de Restricciones Distribuidas (DCOP) es un marco general que puede modelar problemas complejos en sistemas multiagente. Varios algoritmos actuales que resuelven instancias generales de DCOP, incluyendo ADOPT y DPOP, organizan a los agentes en una estructura de pseudobosque tradicional. Introducimos una extensión al algoritmo DPOP que maneja un conjunto extendido de disposiciones de pseudobosque. Nuestro algoritmo resuelve correctamente instancias de DCOP para pseudobosques que incluyen aristas entre nodos en ramas separadas. El algoritmo también resuelve instancias con arreglos de pseudobosque tradicionales utilizando el mismo procedimiento que DPOP. Comparamos nuestro algoritmo con DPOP utilizando varios métricos, incluyendo el ancho inducido de los pseudobosques, la dimensionalidad máxima de los mensajes y la computación, y el costo máximo de la ruta secuencial a través del algoritmo. Demostramos que para algunas instancias del problema no es posible generar un pseudoárbol tradicional utilizando heurísticas de recorrido de aristas que supere a un pseudoárbol con aristas cruzadas. Utilizamos múltiples heurísticas para generar pseudoárboles y elegir el mejor pseudoárbol en complejidad espacio-temporal lineal. Para algunas instancias del problema observamos mejoras significativas en los tamaños de los mensajes y cálculos en comparación con DPOP. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Algoritmos 1. INTRODUCCIÓN Muchos problemas históricos en la comunidad de IA pueden transformarse en Problemas de Satisfacción de Restricciones (CSP). Con la llegada de la inteligencia artificial distribuida, los sistemas multiagente se convirtieron en una forma popular de modelar las interacciones complejas y la coordinación necesaria para resolver problemas distribuidos. Los CSPs fueron originalmente extendidos a entornos de agentes distribuidos en [9]. Los primeros dominios para problemas de satisfacción de restricciones distribuidas (DisCSP) incluyeron la programación de talleres de trabajo [1] y la <br>asignación de recursos</br> [2]. Muchos dominios para sistemas de agentes, especialmente coordinación de trabajo en equipo, programación distribuida y redes de sensores, implican problemas excesivamente restringidos que son difíciles o imposibles de satisfacer para cada restricción. Los enfoques recientes para resolver problemas en estos dominios se basan en técnicas de optimización que mapean restricciones en funciones de utilidad multivaluadas. En lugar de encontrar una asignación que satisfaga todas las restricciones, estos enfoques encuentran una asignación que produce un alto nivel de utilidad global. Esta extensión al enfoque original de DisCSP se ha vuelto popular en sistemas multiagente, y ha sido etiquetada como Problema de Optimización de Restricciones Distribuidas (DCOP) [1]. Los algoritmos actuales que resuelven DCOPs completos utilizan dos enfoques principales: búsqueda y programación dinámica. Los algoritmos basados en búsqueda que se originaron a partir de DisCSP típicamente utilizan alguna forma de retroceso [10] o propagación de límites, como en ADOPT [3]. Los algoritmos basados en programación dinámica incluyen DPOP y sus extensiones [5, 6, 7]. Hasta la fecha, ambas categorías de algoritmos organizan agentes en un pseudoárbol tradicional para resolver el problema. Se ha demostrado en [6] que cualquier grafo de restricciones puede ser mapeado en un pseudoárbol tradicional. Sin embargo, también se demostró que encontrar el pseudoárbol óptimo era NP-Difícil. Comenzamos a investigar el rendimiento de los pseudobosques tradicionales generados por las heurísticas actuales de recorrido de aristas. Descubrimos que estas heurísticas a menudo generaban poco paralelismo, ya que los pseudárboles tendían a tener una gran profundidad y bajos factores de ramificación. Sospechábamos que podría haber otras formas de organizar los pseudobosques que proporcionarían un mayor paralelismo y tamaños de mensaje más pequeños. Después de explorar estos otros arreglos, descubrimos que los pseudobosques de bordes cruzados proporcionan profundidades más cortas y factores de ramificación más altos que los pseudobosques tradicionales. Nuestra hipótesis era que estos pseudorboles cruzados superarían a los pseudorboles tradicionales en algunos tipos de problemas. En este artículo presentamos una extensión al algoritmo DPOP que maneja un conjunto ampliado de disposiciones de pseudobosque que incluyen pseudobosques con aristas cruzadas. Comenzamos con una definición de 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, pseudobosques tradicionales y pseudobosques de bordes cruzados. Luego proporcionamos un resumen del algoritmo DPOP original e introducimos nuestro algoritmo DCPOP. Discutimos la complejidad de nuestro algoritmo, así como el impacto de las heurísticas de generación de pseudobosques. Luego demostramos que nuestro Procedimiento de Optimización de Pseudotree de Bordes Cruzados Distribuido (DCPOP) funciona significativamente mejor en la práctica que el algoritmo DPOP original para algunas instancias del problema. Concluimos con una selección de ideas para trabajos futuros y extensiones para DCPOP. 2. La DEFINICIÓN DEL PROBLEMA DCOP ha sido formalizada de maneras ligeramente diferentes en la literatura reciente, por lo que adoptaremos la definición presentada en [6]. Un Problema de Optimización de Restricciones Distribuidas con n nodos y m restricciones consiste en la tupla < X, D, U > donde: • X = {x1,..,xn} es un conjunto de variables, cada una asignada a un agente único • D = {d1,..,dn} es un conjunto de dominios finitos para cada variable • U = {u1,..,um} es un conjunto de funciones de utilidad tales que cada función involucra un subconjunto de variables en X y define una utilidad para cada combinación de valores entre estas variables. Una solución óptima para una instancia de DCOP consiste en una asignación de valores en D a X tal que la suma de las utilidades en U sea máxima. Los dominios de problemas que requieren un costo mínimo en lugar de una utilidad máxima pueden mapear los costos en utilidades negativas. Las funciones de utilidad representan restricciones suaves pero también pueden representar restricciones fuertes mediante el uso de valores negativos arbitrariamente grandes. Para este artículo solo consideramos funciones de utilidad binarias que involucran dos variables. Las funciones de utilidad de orden superior pueden ser modeladas con cambios menores en el algoritmo, pero también aumentan sustancialmente la complejidad. 2.1 Pseudárboles Tradicionales Los pseudárboles son una estructura común utilizada en procedimientos de búsqueda para permitir el procesamiento paralelo de ramas independientes. Como se define en [6], un pseudoárbol es un arreglo de un grafo G en un árbol raíz T de tal manera que los vértices en G que comparten una arista están en la misma rama en T. Una arista de retroceso es una arista entre un nodo X y cualquier nodo que se encuentre en el camino desde X hasta la raíz (excluyendo al padre de X). La Figura 1 muestra un pseudoárbol con cuatro nodos, tres aristas (A-B, B-C, BD) y una arista de retroceso (A-C). También se definen en [6] cuatro tipos de relaciones entre nodos que existen en un pseudoárbol: • P(X) - el padre de un nodo X: el único nodo más alto en el pseudoárbol que está conectado a X directamente a través de un borde de árbol • C(X) - los hijos de un nodo X: el conjunto de nodos más bajos en el pseudo Las líneas sólidas representan relaciones padre-hijo y la línea discontinua representa una relación pseudo-padre-pseudo-hijo. Figura 2: Un pseudoárbol de bordes cruzados. Las líneas sólidas representan relaciones padre-hijo, la línea discontinua representa una relación pseudo-padre-pseudo-hijo, y la línea punteada representa una relación rama-padre-rama-hijo. El nodo en negrita, B, es el punto de fusión para el nodo E. 2.2 Pseudárboles con aristas cruzadas Definimos una arista cruzada como una arista de un nodo X a un nodo Y que está por encima de X pero no en el camino desde X hasta la raíz. Un pseudoárbol de bordes cruzados es un pseudoárbol tradicional con la adición de bordes cruzados. La Figura 2 muestra un pseudoárbol con una arista cruzada (D-E). En un pseudoárbol de bordes cruzados designamos ciertos bordes como primarios. El conjunto de aristas primarias define un árbol de expansión de los nodos. Las relaciones de padre, hijo, pseudo-padre y pseudo-hijo del pseudotree tradicional ahora están definidas en el contexto de este árbol de expansión de borde primario. Esta definición también produce dos tipos adicionales de relaciones que pueden existir entre nodos: • BP(X) - los nodos padres de rama de un nodo X: el conjunto de nodos más altos en el pseudoárbol que están conectados a X pero no están en el camino principal desde X hasta la raíz (En la Figura 2, D = BP(E)) • BC(X) - los nodos hijos de rama de un nodo X: el conjunto de nodos más bajos en el pseudo La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Los algoritmos actuales suelen tener una fase de pre-ejecución para generar un pseudoárbol tradicional a partir de una instancia general de DCOP. Nuestro algoritmo DCPOP genera un pseudoárbol de bordes cruzados de la misma manera. Primero, la instancia DCOP < X, D, U > se traduce directamente en un grafo con X como el conjunto de vértices y una arista para cada par de variables representadas en U. A continuación, se utilizan varias heurísticas para organizar este grafo en un pseudoárbol. Un heurístico común es realizar una búsqueda en profundidad guiada (DFS, por sus siglas en inglés) ya que el recorrido resultante es un pseudoárbol, y un DFS se puede realizar fácilmente de manera distribuida. Definimos un método basado en el recorrido de aristas como cualquier método que produce un pseudoárbol en el que todos los pares padre/hijo comparten una arista en el grafo original. Esto incluye recorridos basados en DFS, búsqueda en anchura y búsqueda de mejor primero. Nuestras heurísticas que generan pseudobosques de bordes cruzados utilizan un recorrido de búsqueda mejor primero distribuido. 3. ALGORITMO DPOP El algoritmo DPOP original opera en tres fases principales. La primera fase genera un pseudoárbol tradicional a partir de la instancia de DCOP utilizando un algoritmo distribuido. La segunda fase une hipercubos de utilidad de los nodos hijos y el nodo local y los propaga hacia la raíz. La tercera fase elige una asignación para cada dominio de arriba hacia abajo, comenzando con el agente en el nodo raíz. La complejidad de DPOP depende del tamaño del cálculo más grande y del mensaje de utilidad durante la fase dos. Se ha demostrado que este tamaño corresponde directamente al ancho inducido del pseudoárbol generado en la fase uno [6]. DPOP utiliza heurísticas de tiempo polinómico para generar el pseudoárbol, ya que encontrar el pseudoárbol de ancho inducido mínimo es NP-duro. Se han desarrollado varias heurísticas de recorrido de borde distribuido para encontrar pseudobosques de ancho reducido [8]. Al final de la primera fase, cada agente conoce a su padre, hijos, pseudo-padres y pseudo-hijos. 3.1 Propagación de utilidad Los agentes ubicados en los nodos hoja del pseudoárbol comienzan el proceso calculando un hipercubo de utilidad local. Este hipercubo en el nodo X contiene las utilidades sumadas para cada combinación de valores en los dominios de P(X) y PP(X). Este hipercubo tiene un tamaño dimensional igual al número de pseudo-padres más uno. Un mensaje que contiene este hipercubo se envía a P(X). Los agentes ubicados en nodos no hoja esperan a que lleguen todos los mensajes de los nodos hijos. Una vez que el agente en el nodo Y tiene todos los mensajes de utilidad, calcula su hipercubo de utilidad local que incluye los dominios de P(Y), PP(Y) y Y. El hipercubo de utilidad local se une luego con todos los hipercubos de los mensajes hijos. En este punto, todas las utilidades que involucran al nodo Y son conocidas, y el dominio de Y puede ser eliminado de forma segura del hipercubo unido. Este proceso de eliminación elige la mejor utilidad sobre el dominio de Y para cada combinación de los dominios restantes. Un mensaje que contiene este hipercubo se envía ahora a P(Y). El tamaño dimensional de este hipercubo depende del número de dominios superpuestos en los mensajes recibidos y del hipercubo de utilidad local. Esta fase de propagación basada en programación dinámica continúa hasta que el agente en el nodo raíz del pseudoárbol haya recibido todos los mensajes de sus hijos. 3.2 Propagación de Valor La propagación de valor comienza cuando el agente en el nodo raíz Z ha recibido todos los mensajes de sus hijos. Dado que Z no tiene padres ni pseudo-padres, simplemente combina los hipercubos de utilidad recibidos de sus hijos. El hipercubo combinado contiene solo valores para el dominio de Z. En este punto, el agente en el nodo Z simplemente elige la asignación para su dominio que tiene la mejor utilidad. Un mensaje de propagación de valor con esta asignación se envía a cada nodo en C(Z). Cada nodo luego recibe un mensaje de propagación de valor de su padre y elige la asignación para su dominio que tenga la mejor utilidad dadas las asignaciones recibidas en el mensaje. El nodo agrega su asignación de dominio a las asignaciones que recibió y pasa el conjunto de asignaciones a sus hijos. El algoritmo está completo cuando todos los nodos han elegido una asignación para su dominio. ALGORITMO DCPOP Nuestra extensión al algoritmo DPOP original, mostrada en el Algoritmo 1, comparte las mismas tres fases. La primera fase genera el pseudoárbol de bordes cruzados para la instancia de DCOP. La segunda fase fusiona ramas y propaga los hipercubos de utilidad. La tercera fase elige asignaciones para dominios en los puntos de fusión de ramas y de arriba hacia abajo, comenzando con el agente en el nodo raíz. Para la primera fase generamos un pseudoárbol utilizando varios heurísticos distribuidos y seleccionamos el que tenga la menor complejidad general. La complejidad de la computación y el tamaño del mensaje de utilidad en DCPOP no corresponden directamente al ancho inducido del pseudoárbol de aristas cruzadas. En cambio, utilizamos un método de tiempo polinómico para calcular el tamaño máximo de computación y utilidad del mensaje para un pseudoárbol de bordes cruzados dado. Una descripción de este método y el proceso de selección de pseudodendrogramas aparece en la Sección 5. Al final de la primera fase, cada agente conoce a su padre, hijos, pseudo-padres, pseudo-hijos, padres de rama e hijos de rama. 4.1 Fusión de Ramas y Propagación de Utilidad En el algoritmo DPOP original, un nodo X solo tenía funciones de utilidad que involucraban a su padre y a sus pseudo-padres. En DCPOP, se permite que un nodo X tenga una función de utilidad que involucre a un padre de rama. El concepto de una rama se puede ver en la Figura 2 con el nodo E representando nuestro nodo X. Las dos rutas distintas desde el nodo E hasta el nodo B se llaman ramas de E. El único nodo donde se encuentran todas las ramas de E es el nodo B, que se llama punto de fusión de E. Los agentes con nodos que tienen padres de rama comienzan enviando un mensaje de propagación de utilidad a cada padre de rama. Este mensaje incluye un hipercubo de utilidad bidimensional con dominios para el nodo X y el nodo padre de la rama BP(X). También incluye una estructura de información de rama que contiene el nodo de origen de la rama, X, el número total de ramas que se originan en X y el número de ramas que se originan en X y se fusionan en una representación única por esta estructura de información de rama (este número comienza en 1). Intuitivamente, cuando el número de ramas fusionadas es igual al número total de ramas originales, el algoritmo ha alcanzado el punto de fusión para X. En la Figura 2, el nodo E envía un mensaje de propagación de utilidad a su nodo padre de rama, el nodo D. Este mensaje tiene dimensiones para los dominios de E y D, e incluye información de rama con un origen en E, 2 ramas totales y 1 rama fusionada. Como en la fase de propagación de utilidad de la utilidad DPOP original, un agente en el nodo hoja X envía un mensaje de propagación de utilidad a su padre. En DCPOP, este mensaje contiene dimensiones para los dominios de P(X) y PP(X). Si el nodo X también tiene padres de rama, entonces el mensaje de propagación de utilidad también contiene una dimensión para el dominio de X e incluirá una estructura de información de rama. En la Figura 2, el nodo E envía un mensaje de propagación de utilidad a su padre, el nodo C. Este mensaje tiene dimensiones para los dominios de E y C, e incluye información de rama con un origen en E, 2 ramas en total y 1 rama fusionada. Cuando un nodo Y recibe mensajes de propagación de utilidad de todos de The Sixth Intl. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), 743 sus hijos y sus hijos de rama, fusiona cualquier rama con el mismo nodo de origen X. La estructura de información de la rama fusionada acumula el número de ramas fusionadas para X. Si el número total acumulado de ramas fusionadas es igual al número total de ramas, entonces Y es el punto de fusión para X. Esto significa que los hipercubos de utilidad presentes en Y contienen toda la información sobre las valoraciones de las funciones de utilidad que involucran al nodo X. Además de la eliminación típica del dominio de Y de los hipercubos de utilidad, ahora podemos eliminar de forma segura el dominio de X de los hipercubos de utilidad. Para ilustrar este proceso, examinaremos lo que sucede en la segunda fase para el nodo B en la Figura 2. En la segunda fase, el Nodo B recibe dos mensajes de propagación de utilidad. El primero proviene del nodo C e incluye dimensiones para los dominios E, B y A. También tiene una estructura de información de ramas con origen en E, 2 ramas en total y 1 rama fusionada. El segundo proviene del nodo D e incluye dimensiones para los dominios E y B. También tiene una estructura de información de rama con origen en E, 2 ramas en total y 1 rama fusionada. El nodo B luego fusiona las estructuras de información de rama de ambos mensajes porque tienen la misma procedencia, el nodo E. Dado que el número de ramas fusionadas que provienen de E es ahora 2 y el total de ramas que provienen de E es 2, el nodo B elimina las dimensiones para el dominio E. El nodo B también elimina la dimensión para su propio dominio, dejando solo información sobre el dominio A. Luego, el nodo B envía un mensaje de propagación de utilidad al nodo A, que contiene solo una dimensión para el dominio de A. Aunque no sea posible en DPOP, este método de propagación de utilidad y eliminación de dimensiones puede producir hipercubos en el nodo Y que no comparten ningún dominio. En DCPOP no unimos hipercubos independientes de dominio, sino que en su lugar podemos enviar múltiples hipercubos en el mensaje de propagación de utilidad enviado al padre de Y. Este enfoque perezoso de las uniones ayuda a reducir el tamaño de los mensajes. 4.2 Propagación de valores Al igual que en DPOP, la propagación de valores comienza cuando el agente en el nodo raíz Z ha recibido todos los mensajes de sus hijos. En este punto, el agente en el nodo Z elige la asignación para su dominio que tiene la mejor utilidad. Si Z es el punto de fusión de las ramas de algún nodo X, Z también elegirá la asignación para el dominio de X. Por lo tanto, cualquier nodo que sea un punto de fusión elegirá asignaciones para un dominio que no sea el suyo propio. Estas tareas luego se pasan por la jerarquía de la cadena de mando principal. Si el nodo X en la jerarquía tiene padres de rama, entonces el mensaje de asignación de valor de P(X) contendrá una asignación para el dominio de X. Cada nodo en la jerarquía agrega cualquier tarea que haya elegido a las que recibió y pasa el conjunto de tareas a sus hijos. El algoritmo está completo cuando todos los nodos han elegido o recibido una asignación para su dominio. 4.3 Prueba de Corrección Demostraremos la corrección de DCPOP notando primero que DCPOP extiende completamente DPOP y luego examinando los dos casos para la asignación de valores en DCPOP. Dado un pseudoárbol tradicional como entrada, la ejecución del algoritmo DCPOP es idéntica a DPOP. Usando un arreglo de pseudodendrograma tradicional, ningún nodo tiene padres de rama o hijos de rama, ya que todas las aristas son aristas de retroceso o aristas de árbol. Por lo tanto, el algoritmo DCPOP utilizando un pseudoárbol tradicional envía solo mensajes de propagación de utilidad que contienen dominios pertenecientes al padre o pseudo-padres de un nodo. Dado que ningún nodo tiene ramas-padres, no existen ramas, y por lo tanto ningún nodo sirve como punto de fusión para ningún otro nodo. Por lo tanto, todas las asignaciones de propagación de valor se eligen en el nodo del dominio de la asignación. Para la ejecución de DCPOP con pseudárboles de bordes cruzados, algunos nodos actúan como puntos de fusión. Observamos que cualquier nodo X que no sea un punto de fusión asigna su valor exactamente como en DPOP. El hipercubo de utilidad local en X contiene dominios para X, P(X), PP(X) y BC(X). Como en DPOP, el mensaje de asignación de valores recibido en X incluye los valores asignados a P(X) y PP(X). Además, dado que X no es un punto de fusión, todas las asignaciones a BC(X) deben haber sido calculadas en puntos de fusión más altos en el árbol y están en el mensaje de asignación de valor de P(X). Por lo tanto, después de eliminar los dominios para los cuales se conocen las asignaciones, solo queda el dominio de X. El agente en el nodo X ahora puede elegir correctamente la asignación con la máxima utilidad para su propio dominio. Si el nodo X es un punto de fusión para alguna rama-hijo Y, sabemos que X debe ser un nodo a lo largo del camino desde Y hasta la raíz, y desde P(Y) y todos los BP(Y) hasta la raíz. A partir del algoritmo, sabemos que Y necesariamente tiene toda la información de C(Y), PC(Y) y BC(Y) ya que espera sus mensajes. El nodo X tiene información sobre todos los nodos debajo de él en el árbol, lo cual incluiría a Y, P(Y), BP(Y) y aquellos PP(Y) que están debajo de X en el árbol. Para cualquier PP(Y) por encima de X en el árbol, X recibe la asignación para el dominio de PP(Y) en el mensaje de asignación de valor de P(X). Por lo tanto, X tiene información de utilidad sobre todas las funciones de utilidad de las cuales Y forma parte. Al eliminar los dominios incluidos en el mensaje de asignación de valor, el nodo X se queda con un hipercubo de utilidad local con dominios para X e Y. El agente en el nodo X ahora puede elegir correctamente las asignaciones con la máxima utilidad para los dominios de X e Y. 4.4 Análisis de complejidad La primera fase de DCPOP envía un mensaje a cada P(X), PP(X) y BP(X). La segunda fase envía un mensaje de asignación de valor a cada C(X). Por lo tanto, DCPOP produce un número lineal de mensajes con respecto al número de aristas (funciones de utilidad) en el pseudoárbol de aristas cruzadas y la instancia original de DCOP. La complejidad real de DCPOP depende de dos medidas adicionales: el tamaño del mensaje y el tamaño de la computación. El tamaño del mensaje y el tamaño de la computación en DCPOP dependen del número de ramas superpuestas, así como del número de aristas de retroceso superpuestas. Se demostró en [6] que el número de aristas traslapadas es igual al ancho inducido del pseudoárbol. En un pseudoárbol de bordes cruzados mal construido, el número de ramas superpuestas en el nodo X puede ser tan grande como el número total de descendientes de X. Por lo tanto, el tamaño total del mensaje en DCPOP en una instancia mal construida puede ser exponencial en el espacio en el número total de nodos en el grafo. Sin embargo, en la práctica, un pseudoárbol bien construido con bordes cruzados puede lograr resultados mucho mejores. Más tarde abordaremos el tema de elegir pseudobosques cruzados bien construidos de un conjunto. Introducimos una medida adicional del costo máximo de la ruta secuencial a través del algoritmo. Esta medida se relaciona directamente con la cantidad máxima de paralelismo que puede lograr el algoritmo. Para tomar esta medida, primero almacenamos el tamaño total de cálculo para cada nodo durante las fases dos y tres. Este tamaño de cálculo representa el número de accesos individuales a un valor en un hipercubo en cada nodo. Por ejemplo, una unión entre dos dominios de tamaño 4 cuesta 4 ∗ 4 = 16. Dos grafos acíclicos dirigidos (DAG) pueden ser dibujados; uno con los mensajes de propagación de utilidad como aristas y los costos de la fase dos en los nodos, y el otro con los mensajes de asignación de valor y los costos de la fase tres en los nodos. El costo máximo del camino secuencial es igual a la suma del camino más largo en cada DAG desde la raíz hasta cualquier nodo hoja. HEURÍSTICAS En nuestra evaluación de la complejidad en DCPOP nos enfocamos en el peor caso posiblemente producido por el algoritmo. Reconocemos 744 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Algoritmo 1 DCPOP Algoritmo 1: DCPOP(X; D; U) Cada agente Xi ejecuta: Fase 1: creación de pseudotree 2: elegir líder de todos los Xj ∈ X 3: líder elegido inicia la creación de pseudotree 4: después, Xi conoce P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) y PC(Xi) Fase 2: propagación de mensajes UTIL 5: si |BP(Xi)| > 0 entonces 6: BRANCHXi ← |BP(Xi)| + 1 7: para todos Xk ∈BP(Xi) hacer 8: UTILXi (Xk) ← Calcular utils(Xi, Xk) 9: Enviar mensaje(Xk,UTILXi (Xk),BRANCHXi ) 10: si |C(Xi)| = 0 (es decir, Si Xi es un nodo hoja, entonces 11: UTILXi (P(Xi)) ← Calcular utils(P(Xi),PP(Xi)) para todos los PP(Xi) 12: Enviar mensaje(P(Xi), UTILXi (P(Xi)), BRANCHXi ) 13: Enviar mensaje(PP(Xi), UTIL vacío, BRANCH vacío) a todos los PP(Xi) 14: Activar el manejador de mensajes UTIL() Fase 3: Propagación de mensajes de VALOR 15: Activar el manejador de mensajes de VALOR() FIN ALGORITMO Manejador de mensajes UTIL(Xk, UTILXk (Xi), BRANCHXk ) 16: Almacenar UTILXk (Xi), BRANCHXk (Xi) 17: Si han llegado mensajes UTIL de todos los hijos y los hijos de la rama, entonces 18: Para todos los Bj ∈ BRANCH(Xi) hacer 19: Si Bj está fusionado, entonces 20: Unir todos los hipercubos donde Bj ∈ UTIL(Xi) 21: Eliminar Bj del hipercubo unido 22: Si P(Xi) == nulo (eso significa que Xi es la raíz) entonces 23: v ∗ i ← Elegir óptimo(nulo) 24: Enviar VALOR(Xi, v ∗ i) a todos los C(Xi) 25: De lo contrario 26: UTILXi (P(Xi)) ← Calcular utils(P(Xi), PP(Xi)) 27: Enviar mensaje(P(Xi), UTILXi (P(Xi)), BRANCHXi (P(Xi))) Manejador de mensajes de VALOR(VALORXi , P(Xi)) 28: Agregar todos los Xk ← v ∗ k ∈ VALORXi , P(Xi) a la vista del agente 29: Xi ← v ∗ i = Elegir óptimo(vista del agente) 30: Enviar VALORXl , Xi a todos los Xl ∈ C(Xi) que en problemas del mundo real la generación del pseudoárbol tiene un impacto significativo en el rendimiento real. El problema de encontrar la mejor pseudotree para una instancia de DCOP dada es NP-Difícil. Por lo tanto, se utiliza una heurística para la generación, y el rendimiento del algoritmo depende del pseudoárbol encontrado por la heurística. Algunas investigaciones previas se centraron en encontrar heurísticas para generar buenas pseudorboles [8]. Si bien hemos desarrollado algunas heurísticas que generan buenos pseudoárboles cruzados para usar con DCPOP, nuestro enfoque ha sido utilizar múltiples heurísticas y luego seleccionar el mejor pseudo Consideramos solo heurísticas que se ejecuten en tiempo polinómico con respecto al número de nodos en la instancia original del DCOP. El algoritmo DCPOP actual tiene una complejidad exponencial en el peor de los casos, pero podemos calcular el tamaño máximo del mensaje, el tamaño de la computación y el costo de la ruta secuencial para un pseudoárbol de bordes cruzados dado en complejidad espacio-temporal lineal. Para hacer esto, simplemente ejecutamos el algoritmo sin intentar calcular ninguno de los hipercubos de utilidad local o asignaciones de valor óptimo. En cambio, los mensajes incluyen información dimensional y de ramificación pero no hipercubos de utilidad. Después de que cada heurística complete la generación de un pseudoárbol, ejecutamos el procedimiento de medición y propagamos la información de la medición hasta la raíz elegida en ese pseudo La raíz luego transmite la complejidad total de esa heurística a todos los nodos. Después de que todas las heurísticas hayan tenido la oportunidad de completarse, cada nodo sabe qué heurística produjo el mejor pseudoárbol. Cada nodo luego procede a comenzar el algoritmo DCPOP utilizando su conocimiento del pseudoárbol generado por la mejor heurística. Las heurísticas utilizadas para generar pseudárboles tradicionales realizan un recorrido DFS distribuido. El algoritmo distribuido general utiliza un mecanismo de paso de token y un número lineal de mensajes. Las heurísticas mejoradas basadas en DFS utilizan un procedimiento especial para elegir el nodo raíz, y también proporcionan una función de ordenación sobre los vecinos de un nodo para determinar el orden de la recursión de caminos. Las heurísticas basadas en DFS utilizadas en nuestros experimentos provienen del trabajo realizado en [4, 8]. 5.1 La heurística de pseudotree cruzado de mejor primer recorrido. Las heurísticas utilizadas para generar pseudárboles cruzados realizan un recorrido de mejor primer recorrido. Se presenta un algoritmo general distribuido de mejor primero para la expansión de nodos en el Algoritmo 2. Una función de evaluación en cada nodo proporciona los valores que se utilizan para determinar el siguiente mejor nodo a expandir. Ten en cuenta que en este algoritmo cada nodo solo intercambia su mejor valor con sus vecinos. En nuestros experimentos utilizamos varias funciones de evaluación que tomaban como argumentos una lista ordenada de ancestros y un nodo, que contiene una lista de vecinos (con la profundidad de colocación de cada vecino en el árbol). A partir de estos podemos calcular los padres de la rama, los hijos de la rama y las relaciones desconocidas para una posible ubicación del nodo. La mejor función general calculó el valor como ancestros - (padres de rama + hijos de rama) con el número de relaciones desconocidas como criterio de desempate. Después de completarse, cada nodo tiene conocimiento de su padre y ancestros, por lo que puede determinar fácilmente qué nodos conectados son pseudo-padres, padres de rama, pseudo-hijos e hijos de rama. La complejidad de la travesía de mejor primero depende de la complejidad de la función de evaluación. Suponiendo una complejidad de O(V) para la función de evaluación, que es el caso de nuestra mejor función general, el recorrido de mejor primero es O(V · E), lo que en el peor de los casos es O(n3). Para cada v ∈ V realizamos una operación de colocación y encontramos el siguiente nodo a colocar usando la operación getBestNeighbor. La complejidad de la operación del lugar es a lo sumo O(V) debido a los mensajes enviados. Encontrar el siguiente nodo utiliza recursión y recorre solo los ya colocados The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 745 Algoritmo 2 Algoritmo de Búsqueda Distribuida de Mejor Primero root ← líder elegido next(root, ∅) place(nodo, padre) nodo.padre ← padre nodo.ancestros ← padre.ancestros ∪ padre enviar mensaje de ubicación (nodo, nodo.ancestros) a todos los vecinos de nodo next(actual, anterior) si actual no está ubicado entonces place(actual, anterior) next(actual, ∅) else mejor ← obtenerMejorVecino(actual, anterior) si mejor = ∅ entonces si anterior = ∅ entonces terminar, todos los nodos están ubicados next(anterior, ∅) else next(mejor, actual) obtenerMejorVecino(actual, anterior) mejor ← ∅; puntaje ← 0 para todo n ∈ vecinos de actual hacer si n! = anterior entonces si n está ubicado entonces puntajeN ← obtenerMejorVecino(n, actual) else puntajeN ← evaluar(actual, n) si puntajeN > puntaje entonces puntaje ← puntajeN mejor ← n return mejor, puntaje nodos, por lo que tiene O(V) recursiones. Cada recursión realiza una operación recursiva getBestNeighbor que recorre todos los nodos colocados y sus vecinos. Esta operación es O(V · E), pero los resultados se pueden almacenar en caché utilizando solo O(V) espacio en cada nodo. Así que tenemos O(V ·(V +V +V ·E)) = O(V 2 ·E). Si somos inteligentes al evaluar los cambios locales cuando cada nodo recibe mensajes de ubicación de sus vecinos y almacenamos en caché los resultados, la operación getBestNeighbor es solo O(E). Esto aumenta la complejidad de la operación de ubicación, pero para todas las ubicaciones la complejidad total es solo O(V · E). Por lo tanto, tenemos una complejidad general de O(V ·E+V ·(V +E)) = O(V ·E). 6. COMPARACIÓN DE COMPLEJIDAD EN DPOP Y DCPOP Ya hemos demostrado que, dado el mismo input, DCPOP se desempeña igual que DPOP. También hemos demostrado que podemos predecir con precisión el rendimiento de un pseudoárbol dado en complejidad temporal lineal. Si usamos un número constante de heurísticas para generar el conjunto de pseudobosques, podemos elegir el mejor pseudobosque con complejidad lineal en espacio y tiempo. Ahora demostraremos que existe una instancia de DCOP para la cual un pseudoárbol de bordes cruzados supera a todos los posibles pseudoárboles tradicionales (basados en heurísticas de recorrido de bordes). En la Figura 3(a) tenemos una instancia de DCOP con seis nodos. Este es un grafo bipartito con cada partición completamente conectada a la otra (a) (b) (c) Figura 3: (a) La instancia de DCOP (b) Un arreglo de pseudobosque tradicional para la instancia de DCOP (c) Un arreglo de pseudobosque con aristas cruzadas para la partición de la instancia de DCOP. En la Figura 3(b) vemos un arreglo tradicional de pseudotree para esta instancia de DCOP. Es fácil ver que cualquier heurística basada en el recorrido de aristas no puede expandir dos nodos de la misma partición sucesivamente. También observamos que ningún nodo puede tener más de un hijo porque cualquier disposición de este tipo sería un pseudoárbol inválido. Por lo tanto, cualquier disposición tradicional de pseudodendrograma para esta instancia de DCOP debe tener la forma de la Figura 3(b). Podemos ver que las aristas de retroceso F-B y F-A se superponen al nodo C. El nodo C también tiene un padre E y una arista de retroceso con D. Utilizando el algoritmo DPOP original (o DCPOP ya que son idénticos en este caso), encontramos que el cálculo en el nodo C implica cinco dominios: A, B, C, D y E. En contraste, el arreglo de pseudonodos con aristas cruzadas en la Figura 3(c) requiere un máximo de cuatro dominios en cualquier cálculo durante DCPOP. Dado que el nodo A es el punto de fusión de las ramas tanto de B como de C, podemos ver que cada uno de los nodos D, E y F tiene dos ramas superpuestas. Además, cada uno de estos nodos tiene al nodo A como su padre. Usando el algoritmo DCPOP, encontramos que el cálculo en el nodo D (o E o F) implica cuatro dominios: A, B, C y D (o E o F). Dado que no se puede crear una disposición de pseudobosque tradicional mejor utilizando una heurística de recorrido de aristas, hemos demostrado que DCPOP puede superar a DPOP incluso si utilizamos el pseudobosque óptimo encontrado a través del recorrido de aristas. Reconocemos que los arreglos de pseudodistribución de árboles que permiten relaciones padre-hijo sin una restricción real pueden resolver el problema en la Figura 3(a) con un tamaño de cálculo máximo de cuatro dominios. Sin embargo, las heurísticas actuales utilizadas con DPOP no producen tales pseudobosques, y sería difícil distribuir una heurística así, ya que cada nodo requeriría información sobre nodos con los que no tiene restricciones. Además, aunque no lo demostramos aquí, los pseudobosques de bordes cruzados pueden producir tamaños de mensaje más pequeños que tales pseudobosques, incluso si el tamaño de la computación es similar. En la práctica, dado que encontrar la mejor disposición de pseudoramas es NP-Difícil, observamos que las heurísticas que producen pseudoramas con aristas cruzadas a menudo generan tamaños de cálculo y mensajes significativamente más pequeños. 7. RESULTADOS EXPERIMENTALES 746 El Sexto Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Los métricos de rendimiento existentes para algoritmos DCOP incluyen el número total de mensajes, ciclos de reloj síncronos y tamaño de mensaje. Ya hemos demostrado que el número total de mensajes es lineal con respecto al número de restricciones en la instancia de DCOP. También introdujimos el costo de camino secuencial máximo (PC) como una medida de la máxima cantidad de paralelismo alcanzable por el algoritmo. El costo máximo de la ruta secuencial es igual a la suma de los cálculos realizados en la ruta más larga desde la raíz hasta cualquier nodo hoja. También incluimos como métricas el tamaño máximo de cálculo en número de dimensiones (CD) y el tamaño máximo de mensaje en número de dimensiones (MD). Para analizar la complejidad relativa de una instancia DCOP dada, encontramos el ancho inducido mínimo (IW) de cualquier pseudobosque tradicional producido por una heurística para el DPOP original. 7.1 Instancias genéricas de DCOP Para nuestras pruebas iniciales generamos aleatoriamente dos conjuntos de problemas con 3000 casos en cada uno. Cada problema fue generado asignando un número aleatorio (elegido de un rango) de restricciones a cada variable. El generador luego creó restricciones binarias hasta que cada variable alcanzó su número máximo de restricciones. El primer conjunto utiliza 20 variables, y el mejor DPOP IW varía de 1 a 16 con un promedio de 8.5. El segundo conjunto utiliza 100 variables, y el mejor DPOP IW osciló entre 2 y 68 con un promedio de 39.3. Dado que la mayoría de los problemas en el segundo conjunto eran demasiado complejos para calcular la solución, tomamos medidas de las métricas utilizando las técnicas descritas anteriormente en la Sección 5 sin resolver realmente el problema. Los resultados se muestran para el primer conjunto en la Tabla 1 y para el segundo conjunto en la Tabla 2. Para los dos conjuntos de problemas dividimos los casos en categorías de baja densidad y alta densidad. Los casos de baja densidad consisten en aquellos problemas que tienen un mejor DPOP IW menor o igual a la mitad del número total de nodos (por ejemplo, IW ≤ 10 para los problemas de 20 nodos e IW ≤ 50 para los problemas de 100 nodos. Los problemas de alta densidad consisten en el resto de los conjuntos de problemas. En ambas Tabla 1 y Tabla 2 hemos enumerado las métricas de rendimiento para el algoritmo DPOP original, el algoritmo DCPOP utilizando solo pseudobosques de bordes cruzados (DCPOP-CE), y el algoritmo DCPOP utilizando pseudobosques tradicionales y de bordes cruzados (DCPOP-All). Los pseudobosques utilizados para DPOP fueron generados utilizando 5 heurísticas: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB y DFS MCN BEC. Estas son todas las versiones del recorrido DFS guiado discutidas en la Sección 5. Los pseudobosques de bordes cruzados utilizados para DCPOP-CE fueron generados utilizando 5 heurísticas: MCN, LCN, MCN A-B, LCN A-B y LCSG A-B. Estas son todas las versiones del recorrido de mejor primero discutidas en la Sección 5. Para tanto DPOP como DCPOP-CE elegimos el mejor pseudoárbol producido por sus respectivas 5 heurísticas para cada problema en el conjunto. Para DCPOP-All elegimos la mejor pseudotree producida por las 10 heurísticas para cada problema en el conjunto. Para las métricas de CD y MD, el valor mostrado es el número promedio de dimensiones. Para la métrica de PC, el valor mostrado es el logaritmo natural del costo de ruta secuencial máximo (ya que el valor real crece exponencialmente con la complejidad del problema). La última fila en ambas tablas es una medida de mejora de DCPOP-All sobre DPOP. Para las métricas CD y MD, el valor mostrado es una reducción en el número de dimensiones. Para la métrica de PC, el valor mostrado es una reducción porcentual en el costo máximo de la ruta secuencial (% = DP OP −DCP OP DCP OP ∗ 100). Observa que DCPOP supera a DPOP en todas las métricas. Esto se sigue lógicamente de nuestra afirmación anterior de que, dada la misma entrada, DCPOP se comporta exactamente igual que DPOP. Así, dada la elección entre los pseudobosques producidos por las 10 heurísticas, DCPOP-All siempre superará a DCPOP-CE y DPOP. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 6: Mejora del Costo del Camino DCPOP Reunión Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Tabla 3: Problemas de Programación de Reuniones realizan DPOP. Otra tendencia que observamos es que la mejora es mayor para problemas de alta densidad que para problemas de baja densidad. Mostramos esta tendencia con mayor detalle en las Figuras 4, 5 y 6. Observa cómo la mejora aumenta a medida que aumenta la complejidad del problema. 7.2 Problema de Programación de Reuniones Además de nuestras pruebas genéricas iniciales de DCOP, realizamos una serie de pruebas en el Problema de Programación de Reuniones (MSP) como se describe en [6]. La configuración del problema incluye un número de personas agrupadas en departamentos. Cada persona debe asistir a un número específico de reuniones. Las reuniones pueden llevarse a cabo dentro de los departamentos o entre departamentos, y pueden asignarse a uno de los ocho horarios disponibles. El MSP se mapea a una instancia de DCOP donde cada variable representa el intervalo de tiempo en el que una persona específica asistirá a una reunión específica. Todas las variables que pertenecen a la misma persona tienen restricciones de exclusión mutua para que la persona no pueda asistir a más de una reunión durante el mismo intervalo de tiempo. Todas las variables que pertenecen a la misma reunión tienen restricciones de igualdad para que todos los participantes elijan el mismo horario. Se imponen restricciones unarias en cada variable para tener en cuenta la valoración de una persona de cada reunión y franja horaria. Para nuestros tests generamos 100 problemas de muestra para cada combinación de agentes y reuniones. Los resultados se muestran en la Tabla 3. Los valores en las primeras cinco columnas representan (en orden de izquierda a derecha), el número total de agentes, el número total de reuniones, el número total de variables, el promedio total de restricciones y el promedio mínimo de IW producido por un pseudoárbol tradicional. Las últimas tres columnas muestran las mismas métricas que utilizamos para las instancias genéricas de DCOP, excepto que esta vez solo mostramos las mejoras de DCPOP-All sobre DPOP. El rendimiento es mejor en promedio para todas las instancias de MSP, pero nuevamente vemos mejoras más grandes para instancias de problemas más complejos. 8. CONCLUSIONES Y TRABAJO FUTURO Presentamos un algoritmo completo y distribuido que resuelve instancias generales de DCOP utilizando arreglos de pseudoramas cruzados. Nuestro algoritmo extiende el algoritmo DPOP al agregar mensajes adicionales de propagación de utilidad e introducir el concepto de fusión de ramas durante la fase de propagación de utilidad. Nuestro algoritmo también permite que las asignaciones de valor ocurran en puntos de fusión de nivel superior para nodos de nivel inferior. Hemos demostrado que DCPOP extiende completamente DPOP al realizar las mismas operaciones dadas las mismas entradas. También hemos demostrado a través de algunos ejemplos y datos experimentales que DCPOP puede lograr un mejor rendimiento para algunas instancias del problema al extender el conjunto de entrada permitido para incluir pseudobosques cruzados. Damos especial énfasis al papel que desempeñan las heurísticas de recorrido de bordes en la generación de pseudobosques. Hemos demostrado que la penalización en el rendimiento es mínima para generar múltiples heurísticas, y que podemos elegir el mejor pseudoárbol generado en complejidad lineal de espacio-tiempo. Dada la importancia de un buen pseudoárbol para el rendimiento, el trabajo futuro incluirá nuevas heurísticas para encontrar mejores pseudo El trabajo futuro también incluirá adaptar las extensiones existentes de DPOP [5, 7] que soportan diferentes dominios de problemas para su uso con DCPOP. 9. REFERENCIAS [1] J. Liu y K. P. Sycara. Explotando la estructura del problema para la optimización distribuida de restricciones. En V. Lesser, editor, Actas de la Primera Conferencia Internacional sobre Sistemas Multiagente, páginas 246-254, San Francisco, CA, 1995. MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, y S. Kulkarni. Un enfoque dinámico distribuido de satisfacción de restricciones para la <br>asignación de recursos</br>. Notas de conferencia en Ciencias de la Computación, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe y M. Yokoo. Un método completo asíncrono para la optimización de restricciones distribuidas. En AAMAS 03, 2003. [4] A. Petcu. Frodo: Un marco para la optimización de restricciones abiertas/distribuidas. Informe técnico No. 2006/001, Instituto Federal Suizo de Tecnología (EPFL), Lausana (Suiza), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu y B. Faltings. A-dpop: Aproximaciones en optimización distribuida. En póster en CP 2005, páginas 802-806, Sitges, España, octubre de 2005. [6] A. Petcu y B. Faltings. Dpop: Un método escalable para la optimización de restricciones multiagente. En IJCAI 05, páginas 266-271, Edimburgo, Escocia, agosto de 2005. [7] A. Petcu, B. Faltings y D. Parkes. M-dpop: Implementación distribuida fiel de problemas eficientes de elección social. En AAMAS 06, páginas 1397-1404, Hakodate, Japón, mayo de 2006. [8] G. Ushakov. Resolviendo problemas de programación de reuniones utilizando un procedimiento de optimización distribuido de pseudobosque. Tesis de maestría, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida y K. Kuwabara. Satisfacción de restricciones distribuida para formalizar la resolución de problemas distribuidos. En la Conferencia Internacional sobre Sistemas de Computación Distribuida, páginas 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida y K. Kuwabara. El problema de satisfacción de restricciones distribuidas: Formalización y algoritmos. Ingeniería del Conocimiento y de Datos, 10(5):673-685, 1998. 748 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "teamwork coordination": {
            "translated_key": "coordinación de trabajo en equipo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Complete Distributed Constraint Optimization Method For Non-Traditional Pseudotree Arrangements∗ James Atlas Computer and Information Sciences University of Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Computer and Information Sciences University of Delaware Newark, DE 19716 decker@cis.udel.edu ABSTRACT Distributed Constraint Optimization (DCOP) is a general framework that can model complex problems in multi-agent systems.",
                "Several current algorithms that solve general DCOP instances, including ADOPT and DPOP, arrange agents into a traditional pseudotree structure.",
                "We introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements.",
                "Our algorithm correctly solves DCOP instances for pseudotrees that include edges between nodes in separate branches.",
                "The algorithm also solves instances with traditional pseudotree arrangements using the same procedure as DPOP.",
                "We compare our algorithm with DPOP using several metrics including the induced width of the pseudotrees, the maximum dimensionality of messages and computation, and the maximum sequential path cost through the algorithm.",
                "We prove that for some problem instances it is not possible to generate a traditional pseudotree using edge-traversal heuristics that will outperform a cross-edged pseudotree.",
                "We use multiple heuristics to generate pseudotrees and choose the best pseudotree in linear space-time complexity.",
                "For some problem instances we observe significant improvements in message and computation sizes compared to DPOP.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent Systems General Terms Algorithms 1.",
                "INTRODUCTION Many historical problems in the AI community can be transformed into Constraint Satisfaction Problems (CSP).",
                "With the advent of distributed AI, multi-agent systems became a popular way to model the complex interactions and coordination required to solve distributed problems.",
                "CSPs were originally extended to distributed agent environments in [9].",
                "Early domains for distributed constraint satisfaction problems (DisCSP) included job shop scheduling [1] and resource allocation [2].",
                "Many domains for agent systems, especially <br>teamwork coordination</br>, distributed scheduling, and sensor networks, involve overly constrained problems that are difficult or impossible to satisfy for every constraint.",
                "Recent approaches to solving problems in these domains rely on optimization techniques that map constraints into multi-valued utility functions.",
                "Instead of finding an assignment that satisfies all constraints, these approaches find an assignment that produces a high level of global utility.",
                "This extension to the original DisCSP approach has become popular in multi-agent systems, and has been labeled the Distributed Constraint Optimization Problem (DCOP) [1].",
                "Current algorithms that solve complete DCOPs use two main approaches: search and dynamic programming.",
                "Search based algorithms that originated from DisCSP typically use some form of backtracking [10] or bounds propagation, as in ADOPT [3].",
                "Dynamic programming based algorithms include DPOP and its extensions [5, 6, 7].",
                "To date, both categories of algorithms arrange agents into a traditional pseudotree to solve the problem.",
                "It has been shown in [6] that any constraint graph can be mapped into a traditional pseudotree.",
                "However, it was also shown that finding the optimal pseudotree was NP-Hard.",
                "We began to investigate the performance of traditional pseudotrees generated by current edge-traversal heuristics.",
                "We found that these heuristics often produced little parallelism as the pseudotrees tended to have high depth and low branching factors.",
                "We suspected that there could be other ways to arrange the pseudotrees that would provide increased parallelism and smaller message sizes.",
                "After exploring these other arrangements we found that cross-edged pseudotrees provide shorter depths and higher branching factors than the traditional pseudotrees.",
                "Our hypothesis was that these crossedged pseudotrees would outperform traditional pseudotrees for some problem types.",
                "In this paper we introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements which include cross-edged pseudotrees.",
                "We begin with a definition of 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, traditional pseudotrees, and cross-edged pseudotrees.",
                "We then provide a summary of the original DPOP algorithm and introduce our DCPOP algorithm.",
                "We discuss the complexity of our algorithm as well as the impact of pseudotree generation heuristics.",
                "We then show that our Distributed Cross-edged Pseudotree Optimization Procedure (DCPOP) performs significantly better in practice than the original DPOP algorithm for some problem instances.",
                "We conclude with a selection of ideas for future work and extensions for DCPOP. 2.",
                "PROBLEM DEFINITION DCOP has been formalized in slightly different ways in recent literature, so we will adopt the definition as presented in [6].",
                "A Distributed Constraint Optimization Problem with n nodes and m constraints consists of the tuple < X, D, U > where: • X = {x1,..,xn} is a set of variables, each one assigned to a unique agent • D = {d1,..,dn} is a set of finite domains for each variable • U = {u1,..,um} is a set of utility functions such that each function involves a subset of variables in X and defines a utility for each combination of values among these variables An optimal solution to a DCOP instance consists of an assignment of values in D to X such that the sum of utilities in U is maximal.",
                "Problem domains that require minimum cost instead of maximum utility can map costs into negative utilities.",
                "The utility functions represent soft constraints but can also represent hard constraints by using arbitrarily large negative values.",
                "For this paper we only consider binary utility functions involving two variables.",
                "Higher order utility functions can be modeled with minor changes to the algorithm, but they also substantially increase the complexity. 2.1 Traditional Pseudotrees Pseudotrees are a common structure used in search procedures to allow parallel processing of independent branches.",
                "As defined in [6], a pseudotree is an arrangement of a graph G into a rooted tree T such that vertices in G that share an edge are in the same branch in T. A back-edge is an edge between a node X and any node which lies on the path from X to the root (excluding Xs parent).",
                "Figure 1 shows a pseudotree with four nodes, three edges (A-B, B-C, BD), and one back-edge (A-C).",
                "Also defined in [6] are four types of relationships between nodes exist in a pseudotree: • P(X) - the parent of a node X: the single node higher in the pseudotree that is connected to X directly through a tree edge • C(X) - the children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through tree edges • PP(X) - the pseudo-parents of a node X: the set of nodes higher in the pseudotree that are connected to X directly through back-edges (In Figure 1, A = PP(C)) • PC(X) - the pseudo-children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through back-edges (In Figure 1, C = PC(A)) Figure 1: A traditional pseudotree.",
                "Solid line edges represent parent-child relationships and the dashed line represents a pseudo-parent-pseudo-child relationship.",
                "Figure 2: A cross-edged pseudotree.",
                "Solid line edges represent parent-child relationships, the dashed line represents a pseudoparent-pseudo-child relationship, and the dotted line represents a branch-parent-branch-child relationship.",
                "The bolded node, B, is the merge point for node E. 2.2 Cross-edged Pseudotrees We define a cross-edge as an edge from node X to a node Y that is above X but not in the path from X to the root.",
                "A cross-edged pseudotree is a traditional pseudotree with the addition of cross-edges.",
                "Figure 2 shows a cross-edged pseudotree with a cross-edge (D-E).",
                "In a cross-edged pseudotree we designate certain edges as primary.",
                "The set of primary edges defines a spanning tree of the nodes.",
                "The parent, child, pseudo-parent, and pseudo-child relationships from the traditional pseudotree are now defined in the context of this primary edge spanning tree.",
                "This definition also yields two additional types of relationships that may exist between nodes: • BP(X) - the branch-parents of a node X: the set of nodes higher in the pseudotree that are connected to X but are not in the primary path from X to the root (In Figure 2, D = BP(E)) • BC(X) - the branch-children of a node X: the set of nodes lower in the pseudotree that are connected to X but are not in any primary path from X to any leaf node (In Figure 2, E = BC(D)) 2.3 Pseudotree Generation 742 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Current algorithms usually have a pre-execution phase to generate a traditional pseudotree from a general DCOP instance.",
                "Our DCPOP algorithm generates a cross-edged pseudotree in the same fashion.",
                "First, the DCOP instance < X, D, U > translates directly into a graph with X as the set of vertices and an edge for each pair of variables represented in U.",
                "Next, various heuristics are used to arrange this graph into a pseudotree.",
                "One common heuristic is to perform a guided depth-first search (DFS) as the resulting traversal is a pseudotree, and a DFS can easily be performed in a distributed fashion.",
                "We define an edge-traversal based method as any method that produces a pseudotree in which all parent/child pairs share an edge in the original graph.",
                "This includes DFS, breadth-first search, and best-first search based traversals.",
                "Our heuristics that generate cross-edged pseudotrees use a distributed best-first search traversal. 3.",
                "DPOP ALGORITHM The original DPOP algorithm operates in three main phases.",
                "The first phase generates a traditional pseudotree from the DCOP instance using a distributed algorithm.",
                "The second phase joins utility hypercubes from children and the local node and propagates them towards the root.",
                "The third phase chooses an assignment for each domain in a top down fashion beginning with the agent at the root node.",
                "The complexity of DPOP depends on the size of the largest computation and utility message during phase two.",
                "It has been shown that this size directly corresponds to the induced width of the pseudotree generated in phase one [6].",
                "DPOP uses polynomial time heuristics to generate the pseudotree since finding the minimum induced width pseudotree is NP-hard.",
                "Several distributed edgetraversal heuristics have been developed to find low width pseudotrees [8].",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, and pseudo-children. 3.1 Utility Propagation Agents located at leaf nodes in the pseudotree begin the process by calculating a local utility hypercube.",
                "This hypercube at node X contains summed utilities for each combination of values in the domains for P(X) and PP(X).",
                "This hypercube has dimensional size equal to the number of pseudo-parents plus one.",
                "A message containing this hypercube is sent to P(X).",
                "Agents located at non-leaf nodes wait for all messages from children to arrive.",
                "Once the agent at node Y has all utility messages, it calculates its local utility hypercube which includes domains for P(Y), PP(Y), and Y.",
                "The local utility hypercube is then joined with all of the hypercubes from the child messages.",
                "At this point all utilities involving node Y are known, and the domain for Y may be safely eliminated from the joined hypercube.",
                "This elimination process chooses the best utility over the domain of Y for each combination of the remaining domains.",
                "A message containing this hypercube is now sent to P(Y).",
                "The dimensional size of this hypercube depends on the number of overlapping domains in received messages and the local utility hypercube.",
                "This dynamic programming based propagation phase continues until the agent at the root node of the pseudotree has received all messages from its children. 3.2 Value Propagation Value propagation begins when the agent at the root node Z has received all messages from its children.",
                "Since Z has no parents or pseudo-parents, it simply combines the utility hypercubes received from its children.",
                "The combined hypercube contains only values for the domain for Z.",
                "At this point the agent at node Z simply chooses the assignment for its domain that has the best utility.",
                "A value propagation message with this assignment is sent to each node in C(Z).",
                "Each other node then receives a value propagation message from its parent and chooses the assignment for its domain that has the best utility given the assignments received in the message.",
                "The node adds its domain assignment to the assignments it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen an assignment for their domain. 4.",
                "DCPOP ALGORITHM Our extension to the original DPOP algorithm, shown in Algorithm 1, shares the same three phases.",
                "The first phase generates the cross-edged pseudotree for the DCOP instance.",
                "The second phase merges branches and propagates the utility hypercubes.",
                "The third phase chooses assignments for domains at branch merge points and in a top down fashion, beginning with the agent at the root node.",
                "For the first phase we generate a pseudotree using several distributed heuristics and select the one with lowest overall complexity.",
                "The complexity of the computation and utility message size in DCPOP does not directly correspond to the induced width of the cross-edged pseudotree.",
                "Instead, we use a polynomial time method for calculating the maximum computation and utility message size for a given cross-edged pseudotree.",
                "A description of this method and the pseudotree selection process appears in Section 5.",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, pseudo-children, branch-parents, and branch-children. 4.1 Merging Branches and Utility Propagation In the original DPOP algorithm a node X only had utility functions involving its parent and its pseudo-parents.",
                "In DCPOP, a node X is allowed to have a utility function involving a branch-parent.",
                "The concept of a branch can be seen in Figure 2 with node E representing our node X.",
                "The two distinct paths from node E to node B are called branches of E. The single node where all branches of E meet is node B, which is called the merge point of E. Agents with nodes that have branch-parents begin by sending a utility propagation message to each branch-parent.",
                "This message includes a two dimensional utility hypercube with domains for the node X and the branch-parent BP(X).",
                "It also includes a branch information structure which contains the origination node of the branch, X, the total number of branches originating from X, and the number of branches originating from X that are merged into a single representation by this branch information structure (this number starts at 1).",
                "Intuitively when the number of merged branches equals the total number of originating branches, the algorithm has reached the merge point for X.",
                "In Figure 2, node E sends a utility propagation message to its branch-parent, node D. This message has dimensions for the domains of E and D, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "As in the original DPOP utility propagation phase, an agent at leaf node X sends a utility propagation message to its parent.",
                "In DCPOP this message contains dimensions for the domains of P(X) and PP(X).",
                "If node X also has branch-parents, then the utility propagation message also contains a dimension for the domain of X, and will include a branch information structure.",
                "In Figure 2, node E sends a utility propagation message to its parent, node C. This message has dimensions for the domains of E and C, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "When a node Y receives utility propagation messages from all of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 743 its children and branch-children, it merges any branches with the same origination node X.",
                "The merged branch information structure accumulates the number of merged branches for X.",
                "If the cumulative total number of merged branches equals the total number of branches, then Y is the merge point for X.",
                "This means that the utility hypercubes present at Y contain all information about the valuations for utility functions involving node X.",
                "In addition to the typical elimination of the domain of Y from the utility hypercubes, we can now safely eliminate the domain of X from the utility hypercubes.",
                "To illustrate this process, we will examine what happens in the second phase for node B in Figure 2.",
                "In the second phase Node B receives two utility propagation messages.",
                "The first comes from node C and includes dimensions for domains E, B, and A.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "The second comes from node D and includes dimensions for domains E and B.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "Node B then merges the branch information structures from both messages because they have the same origination, node E. Since the number of merged branches originating from E is now 2 and the total branches originating from E is 2, node B now eliminates the dimensions for domain E. Node B also eliminates the dimension for its own domain, leaving only information about domain A. Node B then sends a utility propagation message to node A, containing only one dimension for the domain of A.",
                "Although not possible in DPOP, this method of utility propagation and dimension elimination may produce hypercubes at node Y that do not share any domains.",
                "In DCPOP we do not join domain independent hypercubes, but instead may send multiple hypercubes in the utility propagation message sent to the parent of Y.",
                "This lazy approach to joins helps to reduce message sizes. 4.2 Value Propagation As in DPOP, value propagation begins when the agent at the root node Z has received all messages from its children.",
                "At this point the agent at node Z chooses the assignment for its domain that has the best utility.",
                "If Z is the merge point for the branches of some node X, Z will also choose the assignment for the domain of X.",
                "Thus any node that is a merge point will choose assignments for a domain other than its own.",
                "These assignments are then passed down the primary edge hierarchy.",
                "If node X in the hierarchy has branch-parents, then the value assignment message from P(X) will contain an assignment for the domain of X.",
                "Every node in the hierarchy adds any assignments it has chosen to the ones it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen or received an assignment for their domain. 4.3 Proof of Correctness We will prove the correctness of DCPOP by first noting that DCPOP fully extends DPOP and then examining the two cases for value assignment in DCPOP.",
                "Given a traditional pseudotree as input, the DCPOP algorithm execution is identical to DPOP.",
                "Using a traditional pseudotree arrangement no nodes have branch-parents or branch-children since all edges are either back-edges or tree edges.",
                "Thus the DCPOP algorithm using a traditional pseudotree sends only utility propagation messages that contain domains belonging to the parent or pseudo-parents of a node.",
                "Since no node has any branch-parents, no branches exist, and thus no node serves as a merge point for any other node.",
                "Thus all value propagation assignments are chosen at the node of the assignment domain.",
                "For DCPOP execution with cross-edged pseudotrees, some nodes serve as merge points.",
                "We note that any node X that is not a merge point assigns its value exactly as in DPOP.",
                "The local utility hypercube at X contains domains for X, P(X), PP(X), and BC(X).",
                "As in DPOP the value assignment message received at X includes the values assigned to P(X) and PP(X).",
                "Also, since X is not a merge point, all assignments to BC(X) must have been calculated at merge points higher in the tree and are in the value assignment message from P(X).",
                "Thus after eliminating domains for which assignments are known, only the domain of X is left.",
                "The agent at node X can now correctly choose the assignment with maximum utility for its own domain.",
                "If node X is a merge point for some branch-child Y, we know that X must be a node along the path from Y to the root, and from P(Y) and all BP(Y) to the root.",
                "From the algorithm, we know that Y necessarily has all information from C(Y), PC(Y), and BC(Y) since it waits for their messages.",
                "Node X has information about all nodes below it in the tree, which would include Y, P(Y), BP(Y), and those PP(Y) that are below X in the tree.",
                "For any PP(Y) above X in the tree, X receives the assignment for the domain of PP(Y) in the value assignment message from P(X).",
                "Thus X has utility information about all of the utility functions of which Y is a part.",
                "By eliminating domains included in the value assignment message, node X is left with a local utility hypercube with domains for X and Y.",
                "The agent at node X can now correctly choose the assignments with maximum utility for the domains of X and Y. 4.4 Complexity Analysis The first phase of DCPOP sends one message to each P(X), PP(X), and BP(X).",
                "The second phase sends one value assignment message to each C(X).",
                "Thus, DCPOP produces a linear number of messages with respect to the number of edges (utility functions) in the cross-edged pseudotree and the original DCOP instance.",
                "The actual complexity of DCPOP depends on two additional measurements: message size and computation size.",
                "Message size and computation size in DCPOP depend on the number of overlapping branches as well as the number of overlapping back-edges.",
                "It was shown in [6] that the number of overlapping back-edges is equal to the induced width of the pseudotree.",
                "In a poorly constructed cross-edged pseudotree, the number of overlapping branches at node X can be as large as the total number of descendants of X.",
                "Thus, the total message size in DCPOP in a poorly constructed instance can be space-exponential in the total number of nodes in the graph.",
                "However, in practice a well constructed cross-edged pseudotree can achieve much better results.",
                "Later we address the issue of choosing well constructed crossedged pseudotrees from a set.",
                "We introduce an additional measurement of the maximum sequential path cost through the algorithm.",
                "This measurement directly relates to the maximum amount of parallelism achievable by the algorithm.",
                "To take this measurement we first store the total computation size for each node during phase two and three.",
                "This computation size represents the number of individual accesses to a value in a hypercube at each node.",
                "For example, a join between two domains of size 4 costs 4 ∗ 4 = 16.",
                "Two directed acyclic graphs (DAG) can then be drawn; one with the utility propagation messages as edges and the phase two costs at nodes, and the other with value assignment messages and the phase three costs at nodes.",
                "The maximum sequential path cost is equal to the sum of the longest path on each DAG from the root to any leaf node. 5.",
                "HEURISTICS In our assessment of complexity in DCPOP we focused on the worst case possibly produced by the algorithm.",
                "We acknowledge 744 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Algorithm 1 DCPOP Algorithm 1: DCPOP(X; D; U) Each agent Xi executes: Phase 1: pseudotree creation 2: elect leader from all Xj ∈ X 3: elected leader initiates pseudotree creation 4: afterwards, Xi knows P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) and PC(Xi) Phase 2: UTIL message propagation 5: if |BP(Xi)| > 0 then 6: BRANCHXi ← |BP(Xi)| + 1 7: for all Xk ∈BP(Xi) do 8: UTILXi (Xk) ←Compute utils(Xi, Xk) 9: Send message(Xk,UTILXi (Xk),BRANCHXi ) 10: if |C(Xi)| = 0(i.e.",
                "Xi is a leaf node) then 11: UTILXi (P(Xi)) ← Compute utils(P(Xi),PP(Xi)) for all PP(Xi) 12: Send message(P(Xi), UTILXi (P(Xi)),BRANCHXi ) 13: Send message(PP(Xi), empty UTIL, empty BRANCH) to all PP(Xi) 14: activate UTIL Message handler() Phase 3: VALUE message propagation 15: activate VALUE Message handler() END ALGORITHM UTIL Message handler(Xk,UTILXk (Xi), BRANCHXk ) 16: store UTILXk (Xi),BRANCHXk (Xi) 17: if UTIL messages from all children and branch children arrived then 18: for all Bj ∈BRANCH(Xi) do 19: if Bj is merged then 20: join all hypercubes where Bj ∈UTIL(Xi) 21: eliminate Bj from the joined hypercube 22: if P(Xi) == null (that means Xi is the root) then 23: v ∗ i ← Choose optimal(null) 24: Send VALUE(Xi, v ∗ i) to all C(Xi) 25: else 26: UTILXi (P(Xi)) ← Compute utils(P(Xi), PP(Xi)) 27: Send message(P(Xi),UTILXi (P(Xi)), BRANCHXi (P(Xi))) VALUE Message handler(VALUEXi ,P(Xi)) 28: add all Xk ← v ∗ k ∈VALUEXi ,P(Xi) to agent view 29: Xi ← v ∗ i =Choose optimal(agent view) 30: Send VALUEXl , Xi to all Xl ∈C(Xi) that in real world problems the generation of the pseudotree has a significant impact on the actual performance.",
                "The problem of finding the best pseudotree for a given DCOP instance is NP-Hard.",
                "Thus a heuristic is used for generation, and the performance of the algorithm depends on the pseudotree found by the heuristic.",
                "Some previous research focused on finding heuristics to generate good pseudotrees [8].",
                "While we have developed some heuristics that generate good cross-edged pseudotrees for use with DCPOP, our focus has been to use multiple heuristics and then select the best pseudotree from the generated pseudotrees.",
                "We consider only heuristics that run in polynomial time with respect to the number of nodes in the original DCOP instance.",
                "The actual DCPOP algorithm has worst case exponential complexity, but we can calculate the maximum message size, computation size, and sequential path cost for a given cross-edged pseudotree in linear space-time complexity.",
                "To do this, we simply run the algorithm without attempting to calculate any of the local utility hypercubes or optimal value assignments.",
                "Instead, messages include dimensional and branch information but no utility hypercubes.",
                "After each heuristic completes its generation of a pseudotree, we execute the measurement procedure and propagate the measurement information up to the chosen root in that pseudotree.",
                "The root then broadcasts the total complexity for that heuristic to all nodes.",
                "After all heuristics have had a chance to complete, every node knows which heuristic produced the best pseudotree.",
                "Each node then proceeds to begin the DCPOP algorithm using its knowledge of the pseudotree generated by the best heuristic.",
                "The heuristics used to generate traditional pseudotrees perform a distributed DFS traversal.",
                "The general distributed algorithm uses a token passing mechanism and a linear number of messages.",
                "Improved DFS based heuristics use a special procedure to choose the root node, and also provide an ordering function over the neighbors of a node to determine the order of path recursion.",
                "The DFS based heuristics used in our experiments come from the work done in [4, 8]. 5.1 The best-first cross-edged pseudotree heuristic The heuristics used to generate cross-edged pseudotrees perform a best-first traversal.",
                "A general distributed best-first algorithm for node expansion is presented in Algorithm 2.",
                "An evaluation function at each node provides the values that are used to determine the next best node to expand.",
                "Note that in this algorithm each node only exchanges its best value with its neighbors.",
                "In our experiments we used several evaluation functions that took as arguments an ordered list of ancestors and a node, which contains a list of neighbors (with each neighbors placement depth in the tree if it was placed).",
                "From these we can calculate branchparents, branch-children, and unknown relationships for a potential node placement.",
                "The best overall function calculated the value as ancestors−(branchparents+branchchildren) with the number of unknown relationships being a tiebreak.",
                "After completion each node has knowledge of its parent and ancestors, so it can easily determine which connected nodes are pseudo-parents, branchparents, pseudo-children, and branch-children.",
                "The complexity of the best-first traversal depends on the complexity of the evaluation function.",
                "Assuming a complexity of O(V ) for the evaluation function, which is the case for our best overall function, the best-first traversal is O(V · E) which is at worst O(n3 ).",
                "For each v ∈ V we perform a place operation, and find the next node to place using the getBestNeighbor operation.",
                "The place operation is at most O(V ) because of the sent messages.",
                "Finding the next node uses recursion and traverses only already placed The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 745 Algorithm 2 Distributed Best-First Search Algorithm root ← electedleader next(root, ∅) place(node, parent) node.parent ← parent node.ancestors ← parent.ancestors ∪ parent send placement message (node, node.ancestors) to all neighbors of node next(current, previous) if current is not placed then place(current, previous) next(current, ∅) else best ← getBestNeighbor(current, previous) if best = ∅ then if previous = ∅ then terminate, all nodes are placed next(previous, ∅) else next(best, current) getBestNeighbor(current, previous) best ← ∅; score ← 0 for all n ∈ current.neighbors do if n! = previous then if n is placed then nscore ← getBestNeighbor(n, current) else nscore ← evaluate(current, n) if nscore > score then score ← nscore best ← n return best, score nodes, so it has O(V ) recursions.",
                "Each recursion performs a recursive getBestNeighbor operation that traverses all placed nodes and their neighbors.",
                "This operation is O(V · E), but results can be cached using only O(V ) space at each node.",
                "Thus we have O(V ·(V +V +V ·E)) = O(V 2 ·E).",
                "If we are smart about evaluating local changes when each node receives placement messages from its neighbors and cache the results the getBestNeighbor operation is only O(E).",
                "This increases the complexity of the place operation, but for all placements the total complexity is only O(V · E).",
                "Thus we have an overall complexity of O(V ·E+V ·(V +E)) = O(V ·E). 6.",
                "COMPARISON OF COMPLEXITY IN DPOP AND DCPOP We have already shown that given the same input, DCPOP performs the same as DPOP.",
                "We also have shown that we can accurately predict performance of a given pseudotree in linear spacetime complexity.",
                "If we use a constant number of heuristics to generate the set of pseudotrees, we can choose the best pseudotree in linear space-time complexity.",
                "We will now show that there exists a DCOP instance for which a cross-edged pseudotree outperforms all possible traditional pseudotrees (based on edge-traversal heuristics).",
                "In Figure 3(a) we have a DCOP instance with six nodes.",
                "This is a bipartite graph with each partition fully connected to the other (a) (b) (c) Figure 3: (a) The DCOP instance (b) A traditional pseudotree arrangement for the DCOP instance (c) A cross-edged pseudotree arrangement for the DCOP instance partition.",
                "In Figure 3(b) we see a traditional pseudotree arrangement for this DCOP instance.",
                "It is easy to see that any edgetraversal based heuristic cannot expand two nodes from the same partition in succession.",
                "We also see that no node can have more than one child because any such arrangement would be an invalid pseudotree.",
                "Thus any traditional pseudotree arrangement for this DCOP instance must take the form of Figure 3(b).",
                "We can see that the back-edges F-B and F-A overlap node C. Node C also has a parent E, and a back-edge with D. Using the original DPOP algorithm (or DCPOP since they are identical in this case), we find that the computation at node C involves five domains: A, B, C, D, and E. In contrast, the cross-edged pseudotree arrangement in Figure 3(c) requires only a maximum of four domains in any computation during DCPOP.",
                "Since node A is the merge point for branches from both B and C, we can see that each of the nodes D, E, and F have two overlapping branches.",
                "In addition each of these nodes has node A as its parent.",
                "Using the DCPOP algorithm we find that the computation at node D (or E or F) involves four domains: A, B, C, and D (or E or F).",
                "Since no better traditional pseudotree arrangement can be created using an edge-traversal heuristic, we have shown that DCPOP can outperform DPOP even if we use the optimal pseudotree found through edge-traversal.",
                "We acknowledge that pseudotree arrangements that allow parent-child relationships without an actual constraint can solve the problem in Figure 3(a) with maximum computation size of four domains.",
                "However, current heuristics used with DPOP do not produce such pseudotrees, and such a heuristic would be difficult to distribute since each node would require information about nodes with which it has no constraint.",
                "Also, while we do not prove it here, cross-edged pseudotrees can produce smaller message sizes than such pseudotrees even if the computation size is similar.",
                "In practice, since finding the best pseudotree arrangement is NP-Hard, we find that heuristics that produce cross-edged pseudotrees often produce significantly smaller computation and message sizes. 7.",
                "EXPERIMENTAL RESULTS 746 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Existing performance metrics for DCOP algorithms include the total number of messages, synchronous clock cycles, and message size.",
                "We have already shown that the total number of messages is linear with respect to the number of constraints in the DCOP instance.",
                "We also introduced the maximum sequential path cost (PC) as a measurement of the maximum amount of parallelism achievable by the algorithm.",
                "The maximum sequential path cost is equal to the sum of the computations performed on the longest path from the root to any leaf node.",
                "We also include as metrics the maximum computation size in number of dimensions (CD) and maximum message size in number of dimensions (MD).",
                "To analyze the relative complexity of a given DCOP instance, we find the minimum induced width (IW) of any traditional pseudotree produced by a heuristic for the original DPOP. 7.1 Generic DCOP instances For our initial tests we randomly generated two sets of problems with 3000 cases in each.",
                "Each problem was generated by assigning a random number (picked from a range) of constraints to each variable.",
                "The generator then created binary constraints until each variable reached its maximum number of constraints.",
                "The first set uses 20 variables, and the best DPOP IW ranges from 1 to 16 with an average of 8.5.",
                "The second set uses 100 variables, and the best DPOP IW ranged from 2 to 68 with an average of 39.3.",
                "Since most of the problems in the second set were too complex to actually compute the solution, we took measurements of the metrics using the techniques described earlier in Section 5 without actually solving the problem.",
                "Results are shown for the first set in Table 1 and for the second set in Table 2.",
                "For the two problem sets we split the cases into low density and high density categories.",
                "Low density cases consist of those problems that have a best DPOP IW less than or equal to half of the total number of nodes (e.g.",
                "IW ≤ 10 for the 20 node problems and IW ≤ 50 for the 100 node problems).",
                "High density problems consist of the remainder of the problem sets.",
                "In both Table 1 and Table 2 we have listed performance metrics for the original DPOP algorithm, the DCPOP algorithm using only cross-edged pseudotrees (DCPOP-CE), and the DCPOP algorithm using traditional and cross-edged pseudotrees (DCPOP-All).",
                "The pseudotrees used for DPOP were generated using 5 heuristics: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB, and DFS MCN BEC.",
                "These are all versions of the guided DFS traversal discussed in Section 5.",
                "The cross-edged pseudotrees used for DCPOP-CE were generated using 5 heuristics: MCN, LCN, MCN A-B, LCN A-B, and LCSG A-B.",
                "These are all versions of the best-first traversal discussed in Section 5.",
                "For both DPOP and DCPOP-CE we chose the best pseudotree produced by their respective 5 heuristics for each problem in the set.",
                "For DCPOP-All we chose the best pseudotree produced by all 10 heuristics for each problem in the set.",
                "For the CD and MD metrics the value shown is the average number of dimensions.",
                "For the PC metric the value shown is the natural logarithm of the maximum sequential path cost (since the actual value grows exponentially with the complexity of the problem).",
                "The final row in both tables is a measurement of improvement of DCPOP-All over DPOP.",
                "For the CD and MD metrics the value shown is a reduction in number of dimensions.",
                "For the PC metric the value shown is a percentage reduction in the maximum sequential path cost (% = DP OP −DCP OP DCP OP ∗ 100).",
                "Notice that DCPOPAll outperforms DPOP on all metrics.",
                "This logically follows from our earlier assertion that given the same input, DCPOP performs exactly the same as DPOP.",
                "Thus given the choice between the pseudotrees produced by all 10 heuristics, DCPOP-All will always outLow Density High Density Algorithm CD MD PC CD MD PC DPOP 7.81 6.81 3.78 13.34 12.34 5.34 DCPOP-CE 7.94 6.73 3.74 12.83 11.43 5.07 DCPOP-All 7.62 6.49 3.66 12.72 11.36 5.05 Improvement 0.18 0.32 13% 0.62 0.98 36% Table 1: 20 node problems Low Density High Density Algorithm CD MD PC CD MD PC DPOP 33.35 32.35 14.55 58.51 57.50 19.90 DCPOP-CE 33.49 29.17 15.22 57.11 50.03 20.01 DCPOP-All 32.35 29.57 14.10 56.33 51.17 18.84 Improvement 1.00 2.78 104% 2.18 6.33 256% Table 2: 100 node problems Figure 4: Computation Dimension Size Figure 5: Message Dimension Size The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 747 Figure 6: Path Cost DCPOP Improvement Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Table 3: Meeting Scheduling Problems perform DPOP.",
                "Another trend we notice is that the improvement is greater for high density problems than low density problems.",
                "We show this trend in greater detail in Figures 4, 5, and 6.",
                "Notice how the improvement increases as the complexity of the problem increases. 7.2 Meeting Scheduling Problem In addition to our initial generic DCOP tests, we ran a series of tests on the Meeting Scheduling Problem (MSP) as described in [6].",
                "The problem setup includes a number of people that are grouped into departments.",
                "Each person must attend a specified number of meetings.",
                "Meetings can be held within departments or among departments, and can be assigned to one of eight time slots.",
                "The MSP maps to a DCOP instance where each variable represents the time slot that a specific person will attend a specific meeting.",
                "All variables that belong to the same person have mutual exclusion constraints placed so that the person cannot attend more than one meeting during the same time slot.",
                "All variables that belong to the same meeting have equality constraints so that all of the participants choose the same time slot.",
                "Unary constraints are placed on each variable to account for a persons valuation of each meeting and time slot.",
                "For our tests we generated 100 sample problems for each combination of agents and meetings.",
                "Results are shown in Table 3.",
                "The values in the first five columns represent (in left to right order), the total number of agents, the total number of meetings, the total number of variables, the average total number of constraints, and the average minimum IW produced by a traditional pseudotree.",
                "The last three columns show the same metrics we used for the generic DCOP instances, except this time we only show the improvements of DCPOP-All over DPOP.",
                "Performance is better on average for all MSP instances, but again we see larger improvements for more complex problem instances. 8.",
                "CONCLUSIONS AND FUTURE WORK We presented a complete, distributed algorithm that solves general DCOP instances using cross-edged pseudotree arrangements.",
                "Our algorithm extends the DPOP algorithm by adding additional utility propagation messages, and introducing the concept of branch merging during the utility propagation phase.",
                "Our algorithm also allows value assignments to occur at higher level merge points for lower level nodes.",
                "We have shown that DCPOP fully extends DPOP by performing the same operations given the same input.",
                "We have also shown through some examples and experimental data that DCPOP can achieve greater performance for some problem instances by extending the allowable input set to include cross-edged pseudotrees.",
                "We placed particular emphasis on the role that edge-traversal heuristics play in the generation of pseudotrees.",
                "We have shown that the performance penalty is minimal to generate multiple heuristics, and that we can choose the best generated pseudotree in linear space-time complexity.",
                "Given the importance of a good pseudotree for performance, future work will include new heuristics to find better pseudotrees.",
                "Future work will also include adapting existing DPOP extensions [5, 7] that support different problem domains for use with DCPOP. 9.",
                "REFERENCES [1] J. Liu and K. P. Sycara.",
                "Exploiting problem structure for distributed constraint optimization.",
                "In V. Lesser, editor, Proceedings of the First International Conference on Multi-Agent Systems, pages 246-254, San Francisco, CA, 1995.",
                "MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni.",
                "A dynamic distributed constraint satisfaction approach to resource allocation.",
                "Lecture Notes in Computer Science, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe, and M. Yokoo.",
                "An asynchronous complete method for distributed constraint optimization.",
                "In AAMAS 03, 2003. [4] A. Petcu.",
                "Frodo: A framework for open/distributed constraint optimization.",
                "Technical Report No. 2006/001 2006/001, Swiss Federal Institute of Technology (EPFL), Lausanne (Switzerland), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu and B. Faltings.",
                "A-dpop: Approximations in distributed optimization.",
                "In poster in CP 2005, pages 802-806, Sitges, Spain, October 2005. [6] A. Petcu and B. Faltings.",
                "Dpop: A scalable method for multiagent constraint optimization.",
                "In IJCAI 05, pages 266-271, Edinburgh, Scotland, Aug 2005. [7] A. Petcu, B. Faltings, and D. Parkes.",
                "M-dpop: Faithful distributed implementation of efficient social choice problems.",
                "In AAMAS 06, pages 1397-1404, Hakodate, Japan, May 2006. [8] G. Ushakov.",
                "Solving meeting scheduling problems using distributed pseudotree-optimization procedure.",
                "Masters thesis, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "Distributed constraint satisfaction for formalizing distributed problem solving.",
                "In International Conference on Distributed Computing Systems, pages 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "The distributed constraint satisfaction problem: Formalization and algorithms.",
                "Knowledge and Data Engineering, 10(5):673-685, 1998. 748 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "Many domains for agent systems, especially <br>teamwork coordination</br>, distributed scheduling, and sensor networks, involve overly constrained problems that are difficult or impossible to satisfy for every constraint."
            ],
            "translated_annotated_samples": [
                "Muchos dominios para sistemas de agentes, especialmente <br>coordinación de trabajo en equipo</br>, programación distribuida y redes de sensores, implican problemas excesivamente restringidos que son difíciles o imposibles de satisfacer para cada restricción."
            ],
            "translated_text": "Un Método Completo de Optimización de Restricciones Distribuidas para Arreglos de Pseudotree No Tradicionales∗ James Atlas Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 decker@cis.udel.edu RESUMEN La Optimización de Restricciones Distribuidas (DCOP) es un marco general que puede modelar problemas complejos en sistemas multiagente. Varios algoritmos actuales que resuelven instancias generales de DCOP, incluyendo ADOPT y DPOP, organizan a los agentes en una estructura de pseudobosque tradicional. Introducimos una extensión al algoritmo DPOP que maneja un conjunto extendido de disposiciones de pseudobosque. Nuestro algoritmo resuelve correctamente instancias de DCOP para pseudobosques que incluyen aristas entre nodos en ramas separadas. El algoritmo también resuelve instancias con arreglos de pseudobosque tradicionales utilizando el mismo procedimiento que DPOP. Comparamos nuestro algoritmo con DPOP utilizando varios métricos, incluyendo el ancho inducido de los pseudobosques, la dimensionalidad máxima de los mensajes y la computación, y el costo máximo de la ruta secuencial a través del algoritmo. Demostramos que para algunas instancias del problema no es posible generar un pseudoárbol tradicional utilizando heurísticas de recorrido de aristas que supere a un pseudoárbol con aristas cruzadas. Utilizamos múltiples heurísticas para generar pseudoárboles y elegir el mejor pseudoárbol en complejidad espacio-temporal lineal. Para algunas instancias del problema observamos mejoras significativas en los tamaños de los mensajes y cálculos en comparación con DPOP. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Algoritmos 1. INTRODUCCIÓN Muchos problemas históricos en la comunidad de IA pueden transformarse en Problemas de Satisfacción de Restricciones (CSP). Con la llegada de la inteligencia artificial distribuida, los sistemas multiagente se convirtieron en una forma popular de modelar las interacciones complejas y la coordinación necesaria para resolver problemas distribuidos. Los CSPs fueron originalmente extendidos a entornos de agentes distribuidos en [9]. Los primeros dominios para problemas de satisfacción de restricciones distribuidas (DisCSP) incluyeron la programación de talleres de trabajo [1] y la asignación de recursos [2]. Muchos dominios para sistemas de agentes, especialmente <br>coordinación de trabajo en equipo</br>, programación distribuida y redes de sensores, implican problemas excesivamente restringidos que son difíciles o imposibles de satisfacer para cada restricción. Los enfoques recientes para resolver problemas en estos dominios se basan en técnicas de optimización que mapean restricciones en funciones de utilidad multivaluadas. En lugar de encontrar una asignación que satisfaga todas las restricciones, estos enfoques encuentran una asignación que produce un alto nivel de utilidad global. Esta extensión al enfoque original de DisCSP se ha vuelto popular en sistemas multiagente, y ha sido etiquetada como Problema de Optimización de Restricciones Distribuidas (DCOP) [1]. Los algoritmos actuales que resuelven DCOPs completos utilizan dos enfoques principales: búsqueda y programación dinámica. Los algoritmos basados en búsqueda que se originaron a partir de DisCSP típicamente utilizan alguna forma de retroceso [10] o propagación de límites, como en ADOPT [3]. Los algoritmos basados en programación dinámica incluyen DPOP y sus extensiones [5, 6, 7]. Hasta la fecha, ambas categorías de algoritmos organizan agentes en un pseudoárbol tradicional para resolver el problema. Se ha demostrado en [6] que cualquier grafo de restricciones puede ser mapeado en un pseudoárbol tradicional. Sin embargo, también se demostró que encontrar el pseudoárbol óptimo era NP-Difícil. Comenzamos a investigar el rendimiento de los pseudobosques tradicionales generados por las heurísticas actuales de recorrido de aristas. Descubrimos que estas heurísticas a menudo generaban poco paralelismo, ya que los pseudárboles tendían a tener una gran profundidad y bajos factores de ramificación. Sospechábamos que podría haber otras formas de organizar los pseudobosques que proporcionarían un mayor paralelismo y tamaños de mensaje más pequeños. Después de explorar estos otros arreglos, descubrimos que los pseudobosques de bordes cruzados proporcionan profundidades más cortas y factores de ramificación más altos que los pseudobosques tradicionales. Nuestra hipótesis era que estos pseudorboles cruzados superarían a los pseudorboles tradicionales en algunos tipos de problemas. En este artículo presentamos una extensión al algoritmo DPOP que maneja un conjunto ampliado de disposiciones de pseudobosque que incluyen pseudobosques con aristas cruzadas. Comenzamos con una definición de 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, pseudobosques tradicionales y pseudobosques de bordes cruzados. Luego proporcionamos un resumen del algoritmo DPOP original e introducimos nuestro algoritmo DCPOP. Discutimos la complejidad de nuestro algoritmo, así como el impacto de las heurísticas de generación de pseudobosques. Luego demostramos que nuestro Procedimiento de Optimización de Pseudotree de Bordes Cruzados Distribuido (DCPOP) funciona significativamente mejor en la práctica que el algoritmo DPOP original para algunas instancias del problema. Concluimos con una selección de ideas para trabajos futuros y extensiones para DCPOP. 2. La DEFINICIÓN DEL PROBLEMA DCOP ha sido formalizada de maneras ligeramente diferentes en la literatura reciente, por lo que adoptaremos la definición presentada en [6]. Un Problema de Optimización de Restricciones Distribuidas con n nodos y m restricciones consiste en la tupla < X, D, U > donde: • X = {x1,..,xn} es un conjunto de variables, cada una asignada a un agente único • D = {d1,..,dn} es un conjunto de dominios finitos para cada variable • U = {u1,..,um} es un conjunto de funciones de utilidad tales que cada función involucra un subconjunto de variables en X y define una utilidad para cada combinación de valores entre estas variables. Una solución óptima para una instancia de DCOP consiste en una asignación de valores en D a X tal que la suma de las utilidades en U sea máxima. Los dominios de problemas que requieren un costo mínimo en lugar de una utilidad máxima pueden mapear los costos en utilidades negativas. Las funciones de utilidad representan restricciones suaves pero también pueden representar restricciones fuertes mediante el uso de valores negativos arbitrariamente grandes. Para este artículo solo consideramos funciones de utilidad binarias que involucran dos variables. Las funciones de utilidad de orden superior pueden ser modeladas con cambios menores en el algoritmo, pero también aumentan sustancialmente la complejidad. 2.1 Pseudárboles Tradicionales Los pseudárboles son una estructura común utilizada en procedimientos de búsqueda para permitir el procesamiento paralelo de ramas independientes. Como se define en [6], un pseudoárbol es un arreglo de un grafo G en un árbol raíz T de tal manera que los vértices en G que comparten una arista están en la misma rama en T. Una arista de retroceso es una arista entre un nodo X y cualquier nodo que se encuentre en el camino desde X hasta la raíz (excluyendo al padre de X). La Figura 1 muestra un pseudoárbol con cuatro nodos, tres aristas (A-B, B-C, BD) y una arista de retroceso (A-C). También se definen en [6] cuatro tipos de relaciones entre nodos que existen en un pseudoárbol: • P(X) - el padre de un nodo X: el único nodo más alto en el pseudoárbol que está conectado a X directamente a través de un borde de árbol • C(X) - los hijos de un nodo X: el conjunto de nodos más bajos en el pseudo Las líneas sólidas representan relaciones padre-hijo y la línea discontinua representa una relación pseudo-padre-pseudo-hijo. Figura 2: Un pseudoárbol de bordes cruzados. Las líneas sólidas representan relaciones padre-hijo, la línea discontinua representa una relación pseudo-padre-pseudo-hijo, y la línea punteada representa una relación rama-padre-rama-hijo. El nodo en negrita, B, es el punto de fusión para el nodo E. 2.2 Pseudárboles con aristas cruzadas Definimos una arista cruzada como una arista de un nodo X a un nodo Y que está por encima de X pero no en el camino desde X hasta la raíz. Un pseudoárbol de bordes cruzados es un pseudoárbol tradicional con la adición de bordes cruzados. La Figura 2 muestra un pseudoárbol con una arista cruzada (D-E). En un pseudoárbol de bordes cruzados designamos ciertos bordes como primarios. El conjunto de aristas primarias define un árbol de expansión de los nodos. Las relaciones de padre, hijo, pseudo-padre y pseudo-hijo del pseudotree tradicional ahora están definidas en el contexto de este árbol de expansión de borde primario. Esta definición también produce dos tipos adicionales de relaciones que pueden existir entre nodos: • BP(X) - los nodos padres de rama de un nodo X: el conjunto de nodos más altos en el pseudoárbol que están conectados a X pero no están en el camino principal desde X hasta la raíz (En la Figura 2, D = BP(E)) • BC(X) - los nodos hijos de rama de un nodo X: el conjunto de nodos más bajos en el pseudo La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Los algoritmos actuales suelen tener una fase de pre-ejecución para generar un pseudoárbol tradicional a partir de una instancia general de DCOP. Nuestro algoritmo DCPOP genera un pseudoárbol de bordes cruzados de la misma manera. Primero, la instancia DCOP < X, D, U > se traduce directamente en un grafo con X como el conjunto de vértices y una arista para cada par de variables representadas en U. A continuación, se utilizan varias heurísticas para organizar este grafo en un pseudoárbol. Un heurístico común es realizar una búsqueda en profundidad guiada (DFS, por sus siglas en inglés) ya que el recorrido resultante es un pseudoárbol, y un DFS se puede realizar fácilmente de manera distribuida. Definimos un método basado en el recorrido de aristas como cualquier método que produce un pseudoárbol en el que todos los pares padre/hijo comparten una arista en el grafo original. Esto incluye recorridos basados en DFS, búsqueda en anchura y búsqueda de mejor primero. Nuestras heurísticas que generan pseudobosques de bordes cruzados utilizan un recorrido de búsqueda mejor primero distribuido. 3. ALGORITMO DPOP El algoritmo DPOP original opera en tres fases principales. La primera fase genera un pseudoárbol tradicional a partir de la instancia de DCOP utilizando un algoritmo distribuido. La segunda fase une hipercubos de utilidad de los nodos hijos y el nodo local y los propaga hacia la raíz. La tercera fase elige una asignación para cada dominio de arriba hacia abajo, comenzando con el agente en el nodo raíz. La complejidad de DPOP depende del tamaño del cálculo más grande y del mensaje de utilidad durante la fase dos. Se ha demostrado que este tamaño corresponde directamente al ancho inducido del pseudoárbol generado en la fase uno [6]. DPOP utiliza heurísticas de tiempo polinómico para generar el pseudoárbol, ya que encontrar el pseudoárbol de ancho inducido mínimo es NP-duro. Se han desarrollado varias heurísticas de recorrido de borde distribuido para encontrar pseudobosques de ancho reducido [8]. Al final de la primera fase, cada agente conoce a su padre, hijos, pseudo-padres y pseudo-hijos. 3.1 Propagación de utilidad Los agentes ubicados en los nodos hoja del pseudoárbol comienzan el proceso calculando un hipercubo de utilidad local. Este hipercubo en el nodo X contiene las utilidades sumadas para cada combinación de valores en los dominios de P(X) y PP(X). Este hipercubo tiene un tamaño dimensional igual al número de pseudo-padres más uno. Un mensaje que contiene este hipercubo se envía a P(X). Los agentes ubicados en nodos no hoja esperan a que lleguen todos los mensajes de los nodos hijos. Una vez que el agente en el nodo Y tiene todos los mensajes de utilidad, calcula su hipercubo de utilidad local que incluye los dominios de P(Y), PP(Y) y Y. El hipercubo de utilidad local se une luego con todos los hipercubos de los mensajes hijos. En este punto, todas las utilidades que involucran al nodo Y son conocidas, y el dominio de Y puede ser eliminado de forma segura del hipercubo unido. Este proceso de eliminación elige la mejor utilidad sobre el dominio de Y para cada combinación de los dominios restantes. Un mensaje que contiene este hipercubo se envía ahora a P(Y). El tamaño dimensional de este hipercubo depende del número de dominios superpuestos en los mensajes recibidos y del hipercubo de utilidad local. Esta fase de propagación basada en programación dinámica continúa hasta que el agente en el nodo raíz del pseudoárbol haya recibido todos los mensajes de sus hijos. 3.2 Propagación de Valor La propagación de valor comienza cuando el agente en el nodo raíz Z ha recibido todos los mensajes de sus hijos. Dado que Z no tiene padres ni pseudo-padres, simplemente combina los hipercubos de utilidad recibidos de sus hijos. El hipercubo combinado contiene solo valores para el dominio de Z. En este punto, el agente en el nodo Z simplemente elige la asignación para su dominio que tiene la mejor utilidad. Un mensaje de propagación de valor con esta asignación se envía a cada nodo en C(Z). Cada nodo luego recibe un mensaje de propagación de valor de su padre y elige la asignación para su dominio que tenga la mejor utilidad dadas las asignaciones recibidas en el mensaje. El nodo agrega su asignación de dominio a las asignaciones que recibió y pasa el conjunto de asignaciones a sus hijos. El algoritmo está completo cuando todos los nodos han elegido una asignación para su dominio. ALGORITMO DCPOP Nuestra extensión al algoritmo DPOP original, mostrada en el Algoritmo 1, comparte las mismas tres fases. La primera fase genera el pseudoárbol de bordes cruzados para la instancia de DCOP. La segunda fase fusiona ramas y propaga los hipercubos de utilidad. La tercera fase elige asignaciones para dominios en los puntos de fusión de ramas y de arriba hacia abajo, comenzando con el agente en el nodo raíz. Para la primera fase generamos un pseudoárbol utilizando varios heurísticos distribuidos y seleccionamos el que tenga la menor complejidad general. La complejidad de la computación y el tamaño del mensaje de utilidad en DCPOP no corresponden directamente al ancho inducido del pseudoárbol de aristas cruzadas. En cambio, utilizamos un método de tiempo polinómico para calcular el tamaño máximo de computación y utilidad del mensaje para un pseudoárbol de bordes cruzados dado. Una descripción de este método y el proceso de selección de pseudodendrogramas aparece en la Sección 5. Al final de la primera fase, cada agente conoce a su padre, hijos, pseudo-padres, pseudo-hijos, padres de rama e hijos de rama. 4.1 Fusión de Ramas y Propagación de Utilidad En el algoritmo DPOP original, un nodo X solo tenía funciones de utilidad que involucraban a su padre y a sus pseudo-padres. En DCPOP, se permite que un nodo X tenga una función de utilidad que involucre a un padre de rama. El concepto de una rama se puede ver en la Figura 2 con el nodo E representando nuestro nodo X. Las dos rutas distintas desde el nodo E hasta el nodo B se llaman ramas de E. El único nodo donde se encuentran todas las ramas de E es el nodo B, que se llama punto de fusión de E. Los agentes con nodos que tienen padres de rama comienzan enviando un mensaje de propagación de utilidad a cada padre de rama. Este mensaje incluye un hipercubo de utilidad bidimensional con dominios para el nodo X y el nodo padre de la rama BP(X). También incluye una estructura de información de rama que contiene el nodo de origen de la rama, X, el número total de ramas que se originan en X y el número de ramas que se originan en X y se fusionan en una representación única por esta estructura de información de rama (este número comienza en 1). Intuitivamente, cuando el número de ramas fusionadas es igual al número total de ramas originales, el algoritmo ha alcanzado el punto de fusión para X. En la Figura 2, el nodo E envía un mensaje de propagación de utilidad a su nodo padre de rama, el nodo D. Este mensaje tiene dimensiones para los dominios de E y D, e incluye información de rama con un origen en E, 2 ramas totales y 1 rama fusionada. Como en la fase de propagación de utilidad de la utilidad DPOP original, un agente en el nodo hoja X envía un mensaje de propagación de utilidad a su padre. En DCPOP, este mensaje contiene dimensiones para los dominios de P(X) y PP(X). Si el nodo X también tiene padres de rama, entonces el mensaje de propagación de utilidad también contiene una dimensión para el dominio de X e incluirá una estructura de información de rama. En la Figura 2, el nodo E envía un mensaje de propagación de utilidad a su padre, el nodo C. Este mensaje tiene dimensiones para los dominios de E y C, e incluye información de rama con un origen en E, 2 ramas en total y 1 rama fusionada. Cuando un nodo Y recibe mensajes de propagación de utilidad de todos de The Sixth Intl. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), 743 sus hijos y sus hijos de rama, fusiona cualquier rama con el mismo nodo de origen X. La estructura de información de la rama fusionada acumula el número de ramas fusionadas para X. Si el número total acumulado de ramas fusionadas es igual al número total de ramas, entonces Y es el punto de fusión para X. Esto significa que los hipercubos de utilidad presentes en Y contienen toda la información sobre las valoraciones de las funciones de utilidad que involucran al nodo X. Además de la eliminación típica del dominio de Y de los hipercubos de utilidad, ahora podemos eliminar de forma segura el dominio de X de los hipercubos de utilidad. Para ilustrar este proceso, examinaremos lo que sucede en la segunda fase para el nodo B en la Figura 2. En la segunda fase, el Nodo B recibe dos mensajes de propagación de utilidad. El primero proviene del nodo C e incluye dimensiones para los dominios E, B y A. También tiene una estructura de información de ramas con origen en E, 2 ramas en total y 1 rama fusionada. El segundo proviene del nodo D e incluye dimensiones para los dominios E y B. También tiene una estructura de información de rama con origen en E, 2 ramas en total y 1 rama fusionada. El nodo B luego fusiona las estructuras de información de rama de ambos mensajes porque tienen la misma procedencia, el nodo E. Dado que el número de ramas fusionadas que provienen de E es ahora 2 y el total de ramas que provienen de E es 2, el nodo B elimina las dimensiones para el dominio E. El nodo B también elimina la dimensión para su propio dominio, dejando solo información sobre el dominio A. Luego, el nodo B envía un mensaje de propagación de utilidad al nodo A, que contiene solo una dimensión para el dominio de A. Aunque no sea posible en DPOP, este método de propagación de utilidad y eliminación de dimensiones puede producir hipercubos en el nodo Y que no comparten ningún dominio. En DCPOP no unimos hipercubos independientes de dominio, sino que en su lugar podemos enviar múltiples hipercubos en el mensaje de propagación de utilidad enviado al padre de Y. Este enfoque perezoso de las uniones ayuda a reducir el tamaño de los mensajes. 4.2 Propagación de valores Al igual que en DPOP, la propagación de valores comienza cuando el agente en el nodo raíz Z ha recibido todos los mensajes de sus hijos. En este punto, el agente en el nodo Z elige la asignación para su dominio que tiene la mejor utilidad. Si Z es el punto de fusión de las ramas de algún nodo X, Z también elegirá la asignación para el dominio de X. Por lo tanto, cualquier nodo que sea un punto de fusión elegirá asignaciones para un dominio que no sea el suyo propio. Estas tareas luego se pasan por la jerarquía de la cadena de mando principal. Si el nodo X en la jerarquía tiene padres de rama, entonces el mensaje de asignación de valor de P(X) contendrá una asignación para el dominio de X. Cada nodo en la jerarquía agrega cualquier tarea que haya elegido a las que recibió y pasa el conjunto de tareas a sus hijos. El algoritmo está completo cuando todos los nodos han elegido o recibido una asignación para su dominio. 4.3 Prueba de Corrección Demostraremos la corrección de DCPOP notando primero que DCPOP extiende completamente DPOP y luego examinando los dos casos para la asignación de valores en DCPOP. Dado un pseudoárbol tradicional como entrada, la ejecución del algoritmo DCPOP es idéntica a DPOP. Usando un arreglo de pseudodendrograma tradicional, ningún nodo tiene padres de rama o hijos de rama, ya que todas las aristas son aristas de retroceso o aristas de árbol. Por lo tanto, el algoritmo DCPOP utilizando un pseudoárbol tradicional envía solo mensajes de propagación de utilidad que contienen dominios pertenecientes al padre o pseudo-padres de un nodo. Dado que ningún nodo tiene ramas-padres, no existen ramas, y por lo tanto ningún nodo sirve como punto de fusión para ningún otro nodo. Por lo tanto, todas las asignaciones de propagación de valor se eligen en el nodo del dominio de la asignación. Para la ejecución de DCPOP con pseudárboles de bordes cruzados, algunos nodos actúan como puntos de fusión. Observamos que cualquier nodo X que no sea un punto de fusión asigna su valor exactamente como en DPOP. El hipercubo de utilidad local en X contiene dominios para X, P(X), PP(X) y BC(X). Como en DPOP, el mensaje de asignación de valores recibido en X incluye los valores asignados a P(X) y PP(X). Además, dado que X no es un punto de fusión, todas las asignaciones a BC(X) deben haber sido calculadas en puntos de fusión más altos en el árbol y están en el mensaje de asignación de valor de P(X). Por lo tanto, después de eliminar los dominios para los cuales se conocen las asignaciones, solo queda el dominio de X. El agente en el nodo X ahora puede elegir correctamente la asignación con la máxima utilidad para su propio dominio. Si el nodo X es un punto de fusión para alguna rama-hijo Y, sabemos que X debe ser un nodo a lo largo del camino desde Y hasta la raíz, y desde P(Y) y todos los BP(Y) hasta la raíz. A partir del algoritmo, sabemos que Y necesariamente tiene toda la información de C(Y), PC(Y) y BC(Y) ya que espera sus mensajes. El nodo X tiene información sobre todos los nodos debajo de él en el árbol, lo cual incluiría a Y, P(Y), BP(Y) y aquellos PP(Y) que están debajo de X en el árbol. Para cualquier PP(Y) por encima de X en el árbol, X recibe la asignación para el dominio de PP(Y) en el mensaje de asignación de valor de P(X). Por lo tanto, X tiene información de utilidad sobre todas las funciones de utilidad de las cuales Y forma parte. Al eliminar los dominios incluidos en el mensaje de asignación de valor, el nodo X se queda con un hipercubo de utilidad local con dominios para X e Y. El agente en el nodo X ahora puede elegir correctamente las asignaciones con la máxima utilidad para los dominios de X e Y. 4.4 Análisis de complejidad La primera fase de DCPOP envía un mensaje a cada P(X), PP(X) y BP(X). La segunda fase envía un mensaje de asignación de valor a cada C(X). Por lo tanto, DCPOP produce un número lineal de mensajes con respecto al número de aristas (funciones de utilidad) en el pseudoárbol de aristas cruzadas y la instancia original de DCOP. La complejidad real de DCPOP depende de dos medidas adicionales: el tamaño del mensaje y el tamaño de la computación. El tamaño del mensaje y el tamaño de la computación en DCPOP dependen del número de ramas superpuestas, así como del número de aristas de retroceso superpuestas. Se demostró en [6] que el número de aristas traslapadas es igual al ancho inducido del pseudoárbol. En un pseudoárbol de bordes cruzados mal construido, el número de ramas superpuestas en el nodo X puede ser tan grande como el número total de descendientes de X. Por lo tanto, el tamaño total del mensaje en DCPOP en una instancia mal construida puede ser exponencial en el espacio en el número total de nodos en el grafo. Sin embargo, en la práctica, un pseudoárbol bien construido con bordes cruzados puede lograr resultados mucho mejores. Más tarde abordaremos el tema de elegir pseudobosques cruzados bien construidos de un conjunto. Introducimos una medida adicional del costo máximo de la ruta secuencial a través del algoritmo. Esta medida se relaciona directamente con la cantidad máxima de paralelismo que puede lograr el algoritmo. Para tomar esta medida, primero almacenamos el tamaño total de cálculo para cada nodo durante las fases dos y tres. Este tamaño de cálculo representa el número de accesos individuales a un valor en un hipercubo en cada nodo. Por ejemplo, una unión entre dos dominios de tamaño 4 cuesta 4 ∗ 4 = 16. Dos grafos acíclicos dirigidos (DAG) pueden ser dibujados; uno con los mensajes de propagación de utilidad como aristas y los costos de la fase dos en los nodos, y el otro con los mensajes de asignación de valor y los costos de la fase tres en los nodos. El costo máximo del camino secuencial es igual a la suma del camino más largo en cada DAG desde la raíz hasta cualquier nodo hoja. HEURÍSTICAS En nuestra evaluación de la complejidad en DCPOP nos enfocamos en el peor caso posiblemente producido por el algoritmo. Reconocemos 744 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Algoritmo 1 DCPOP Algoritmo 1: DCPOP(X; D; U) Cada agente Xi ejecuta: Fase 1: creación de pseudotree 2: elegir líder de todos los Xj ∈ X 3: líder elegido inicia la creación de pseudotree 4: después, Xi conoce P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) y PC(Xi) Fase 2: propagación de mensajes UTIL 5: si |BP(Xi)| > 0 entonces 6: BRANCHXi ← |BP(Xi)| + 1 7: para todos Xk ∈BP(Xi) hacer 8: UTILXi (Xk) ← Calcular utils(Xi, Xk) 9: Enviar mensaje(Xk,UTILXi (Xk),BRANCHXi ) 10: si |C(Xi)| = 0 (es decir, Si Xi es un nodo hoja, entonces 11: UTILXi (P(Xi)) ← Calcular utils(P(Xi),PP(Xi)) para todos los PP(Xi) 12: Enviar mensaje(P(Xi), UTILXi (P(Xi)), BRANCHXi ) 13: Enviar mensaje(PP(Xi), UTIL vacío, BRANCH vacío) a todos los PP(Xi) 14: Activar el manejador de mensajes UTIL() Fase 3: Propagación de mensajes de VALOR 15: Activar el manejador de mensajes de VALOR() FIN ALGORITMO Manejador de mensajes UTIL(Xk, UTILXk (Xi), BRANCHXk ) 16: Almacenar UTILXk (Xi), BRANCHXk (Xi) 17: Si han llegado mensajes UTIL de todos los hijos y los hijos de la rama, entonces 18: Para todos los Bj ∈ BRANCH(Xi) hacer 19: Si Bj está fusionado, entonces 20: Unir todos los hipercubos donde Bj ∈ UTIL(Xi) 21: Eliminar Bj del hipercubo unido 22: Si P(Xi) == nulo (eso significa que Xi es la raíz) entonces 23: v ∗ i ← Elegir óptimo(nulo) 24: Enviar VALOR(Xi, v ∗ i) a todos los C(Xi) 25: De lo contrario 26: UTILXi (P(Xi)) ← Calcular utils(P(Xi), PP(Xi)) 27: Enviar mensaje(P(Xi), UTILXi (P(Xi)), BRANCHXi (P(Xi))) Manejador de mensajes de VALOR(VALORXi , P(Xi)) 28: Agregar todos los Xk ← v ∗ k ∈ VALORXi , P(Xi) a la vista del agente 29: Xi ← v ∗ i = Elegir óptimo(vista del agente) 30: Enviar VALORXl , Xi a todos los Xl ∈ C(Xi) que en problemas del mundo real la generación del pseudoárbol tiene un impacto significativo en el rendimiento real. El problema de encontrar la mejor pseudotree para una instancia de DCOP dada es NP-Difícil. Por lo tanto, se utiliza una heurística para la generación, y el rendimiento del algoritmo depende del pseudoárbol encontrado por la heurística. Algunas investigaciones previas se centraron en encontrar heurísticas para generar buenas pseudorboles [8]. Si bien hemos desarrollado algunas heurísticas que generan buenos pseudoárboles cruzados para usar con DCPOP, nuestro enfoque ha sido utilizar múltiples heurísticas y luego seleccionar el mejor pseudo Consideramos solo heurísticas que se ejecuten en tiempo polinómico con respecto al número de nodos en la instancia original del DCOP. El algoritmo DCPOP actual tiene una complejidad exponencial en el peor de los casos, pero podemos calcular el tamaño máximo del mensaje, el tamaño de la computación y el costo de la ruta secuencial para un pseudoárbol de bordes cruzados dado en complejidad espacio-temporal lineal. Para hacer esto, simplemente ejecutamos el algoritmo sin intentar calcular ninguno de los hipercubos de utilidad local o asignaciones de valor óptimo. En cambio, los mensajes incluyen información dimensional y de ramificación pero no hipercubos de utilidad. Después de que cada heurística complete la generación de un pseudoárbol, ejecutamos el procedimiento de medición y propagamos la información de la medición hasta la raíz elegida en ese pseudo La raíz luego transmite la complejidad total de esa heurística a todos los nodos. Después de que todas las heurísticas hayan tenido la oportunidad de completarse, cada nodo sabe qué heurística produjo el mejor pseudoárbol. Cada nodo luego procede a comenzar el algoritmo DCPOP utilizando su conocimiento del pseudoárbol generado por la mejor heurística. Las heurísticas utilizadas para generar pseudárboles tradicionales realizan un recorrido DFS distribuido. El algoritmo distribuido general utiliza un mecanismo de paso de token y un número lineal de mensajes. Las heurísticas mejoradas basadas en DFS utilizan un procedimiento especial para elegir el nodo raíz, y también proporcionan una función de ordenación sobre los vecinos de un nodo para determinar el orden de la recursión de caminos. Las heurísticas basadas en DFS utilizadas en nuestros experimentos provienen del trabajo realizado en [4, 8]. 5.1 La heurística de pseudotree cruzado de mejor primer recorrido. Las heurísticas utilizadas para generar pseudárboles cruzados realizan un recorrido de mejor primer recorrido. Se presenta un algoritmo general distribuido de mejor primero para la expansión de nodos en el Algoritmo 2. Una función de evaluación en cada nodo proporciona los valores que se utilizan para determinar el siguiente mejor nodo a expandir. Ten en cuenta que en este algoritmo cada nodo solo intercambia su mejor valor con sus vecinos. En nuestros experimentos utilizamos varias funciones de evaluación que tomaban como argumentos una lista ordenada de ancestros y un nodo, que contiene una lista de vecinos (con la profundidad de colocación de cada vecino en el árbol). A partir de estos podemos calcular los padres de la rama, los hijos de la rama y las relaciones desconocidas para una posible ubicación del nodo. La mejor función general calculó el valor como ancestros - (padres de rama + hijos de rama) con el número de relaciones desconocidas como criterio de desempate. Después de completarse, cada nodo tiene conocimiento de su padre y ancestros, por lo que puede determinar fácilmente qué nodos conectados son pseudo-padres, padres de rama, pseudo-hijos e hijos de rama. La complejidad de la travesía de mejor primero depende de la complejidad de la función de evaluación. Suponiendo una complejidad de O(V) para la función de evaluación, que es el caso de nuestra mejor función general, el recorrido de mejor primero es O(V · E), lo que en el peor de los casos es O(n3). Para cada v ∈ V realizamos una operación de colocación y encontramos el siguiente nodo a colocar usando la operación getBestNeighbor. La complejidad de la operación del lugar es a lo sumo O(V) debido a los mensajes enviados. Encontrar el siguiente nodo utiliza recursión y recorre solo los ya colocados The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 745 Algoritmo 2 Algoritmo de Búsqueda Distribuida de Mejor Primero root ← líder elegido next(root, ∅) place(nodo, padre) nodo.padre ← padre nodo.ancestros ← padre.ancestros ∪ padre enviar mensaje de ubicación (nodo, nodo.ancestros) a todos los vecinos de nodo next(actual, anterior) si actual no está ubicado entonces place(actual, anterior) next(actual, ∅) else mejor ← obtenerMejorVecino(actual, anterior) si mejor = ∅ entonces si anterior = ∅ entonces terminar, todos los nodos están ubicados next(anterior, ∅) else next(mejor, actual) obtenerMejorVecino(actual, anterior) mejor ← ∅; puntaje ← 0 para todo n ∈ vecinos de actual hacer si n! = anterior entonces si n está ubicado entonces puntajeN ← obtenerMejorVecino(n, actual) else puntajeN ← evaluar(actual, n) si puntajeN > puntaje entonces puntaje ← puntajeN mejor ← n return mejor, puntaje nodos, por lo que tiene O(V) recursiones. Cada recursión realiza una operación recursiva getBestNeighbor que recorre todos los nodos colocados y sus vecinos. Esta operación es O(V · E), pero los resultados se pueden almacenar en caché utilizando solo O(V) espacio en cada nodo. Así que tenemos O(V ·(V +V +V ·E)) = O(V 2 ·E). Si somos inteligentes al evaluar los cambios locales cuando cada nodo recibe mensajes de ubicación de sus vecinos y almacenamos en caché los resultados, la operación getBestNeighbor es solo O(E). Esto aumenta la complejidad de la operación de ubicación, pero para todas las ubicaciones la complejidad total es solo O(V · E). Por lo tanto, tenemos una complejidad general de O(V ·E+V ·(V +E)) = O(V ·E). 6. COMPARACIÓN DE COMPLEJIDAD EN DPOP Y DCPOP Ya hemos demostrado que, dado el mismo input, DCPOP se desempeña igual que DPOP. También hemos demostrado que podemos predecir con precisión el rendimiento de un pseudoárbol dado en complejidad temporal lineal. Si usamos un número constante de heurísticas para generar el conjunto de pseudobosques, podemos elegir el mejor pseudobosque con complejidad lineal en espacio y tiempo. Ahora demostraremos que existe una instancia de DCOP para la cual un pseudoárbol de bordes cruzados supera a todos los posibles pseudoárboles tradicionales (basados en heurísticas de recorrido de bordes). En la Figura 3(a) tenemos una instancia de DCOP con seis nodos. Este es un grafo bipartito con cada partición completamente conectada a la otra (a) (b) (c) Figura 3: (a) La instancia de DCOP (b) Un arreglo de pseudobosque tradicional para la instancia de DCOP (c) Un arreglo de pseudobosque con aristas cruzadas para la partición de la instancia de DCOP. En la Figura 3(b) vemos un arreglo tradicional de pseudotree para esta instancia de DCOP. Es fácil ver que cualquier heurística basada en el recorrido de aristas no puede expandir dos nodos de la misma partición sucesivamente. También observamos que ningún nodo puede tener más de un hijo porque cualquier disposición de este tipo sería un pseudoárbol inválido. Por lo tanto, cualquier disposición tradicional de pseudodendrograma para esta instancia de DCOP debe tener la forma de la Figura 3(b). Podemos ver que las aristas de retroceso F-B y F-A se superponen al nodo C. El nodo C también tiene un padre E y una arista de retroceso con D. Utilizando el algoritmo DPOP original (o DCPOP ya que son idénticos en este caso), encontramos que el cálculo en el nodo C implica cinco dominios: A, B, C, D y E. En contraste, el arreglo de pseudonodos con aristas cruzadas en la Figura 3(c) requiere un máximo de cuatro dominios en cualquier cálculo durante DCPOP. Dado que el nodo A es el punto de fusión de las ramas tanto de B como de C, podemos ver que cada uno de los nodos D, E y F tiene dos ramas superpuestas. Además, cada uno de estos nodos tiene al nodo A como su padre. Usando el algoritmo DCPOP, encontramos que el cálculo en el nodo D (o E o F) implica cuatro dominios: A, B, C y D (o E o F). Dado que no se puede crear una disposición de pseudobosque tradicional mejor utilizando una heurística de recorrido de aristas, hemos demostrado que DCPOP puede superar a DPOP incluso si utilizamos el pseudobosque óptimo encontrado a través del recorrido de aristas. Reconocemos que los arreglos de pseudodistribución de árboles que permiten relaciones padre-hijo sin una restricción real pueden resolver el problema en la Figura 3(a) con un tamaño de cálculo máximo de cuatro dominios. Sin embargo, las heurísticas actuales utilizadas con DPOP no producen tales pseudobosques, y sería difícil distribuir una heurística así, ya que cada nodo requeriría información sobre nodos con los que no tiene restricciones. Además, aunque no lo demostramos aquí, los pseudobosques de bordes cruzados pueden producir tamaños de mensaje más pequeños que tales pseudobosques, incluso si el tamaño de la computación es similar. En la práctica, dado que encontrar la mejor disposición de pseudoramas es NP-Difícil, observamos que las heurísticas que producen pseudoramas con aristas cruzadas a menudo generan tamaños de cálculo y mensajes significativamente más pequeños. 7. RESULTADOS EXPERIMENTALES 746 El Sexto Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Los métricos de rendimiento existentes para algoritmos DCOP incluyen el número total de mensajes, ciclos de reloj síncronos y tamaño de mensaje. Ya hemos demostrado que el número total de mensajes es lineal con respecto al número de restricciones en la instancia de DCOP. También introdujimos el costo de camino secuencial máximo (PC) como una medida de la máxima cantidad de paralelismo alcanzable por el algoritmo. El costo máximo de la ruta secuencial es igual a la suma de los cálculos realizados en la ruta más larga desde la raíz hasta cualquier nodo hoja. También incluimos como métricas el tamaño máximo de cálculo en número de dimensiones (CD) y el tamaño máximo de mensaje en número de dimensiones (MD). Para analizar la complejidad relativa de una instancia DCOP dada, encontramos el ancho inducido mínimo (IW) de cualquier pseudobosque tradicional producido por una heurística para el DPOP original. 7.1 Instancias genéricas de DCOP Para nuestras pruebas iniciales generamos aleatoriamente dos conjuntos de problemas con 3000 casos en cada uno. Cada problema fue generado asignando un número aleatorio (elegido de un rango) de restricciones a cada variable. El generador luego creó restricciones binarias hasta que cada variable alcanzó su número máximo de restricciones. El primer conjunto utiliza 20 variables, y el mejor DPOP IW varía de 1 a 16 con un promedio de 8.5. El segundo conjunto utiliza 100 variables, y el mejor DPOP IW osciló entre 2 y 68 con un promedio de 39.3. Dado que la mayoría de los problemas en el segundo conjunto eran demasiado complejos para calcular la solución, tomamos medidas de las métricas utilizando las técnicas descritas anteriormente en la Sección 5 sin resolver realmente el problema. Los resultados se muestran para el primer conjunto en la Tabla 1 y para el segundo conjunto en la Tabla 2. Para los dos conjuntos de problemas dividimos los casos en categorías de baja densidad y alta densidad. Los casos de baja densidad consisten en aquellos problemas que tienen un mejor DPOP IW menor o igual a la mitad del número total de nodos (por ejemplo, IW ≤ 10 para los problemas de 20 nodos e IW ≤ 50 para los problemas de 100 nodos. Los problemas de alta densidad consisten en el resto de los conjuntos de problemas. En ambas Tabla 1 y Tabla 2 hemos enumerado las métricas de rendimiento para el algoritmo DPOP original, el algoritmo DCPOP utilizando solo pseudobosques de bordes cruzados (DCPOP-CE), y el algoritmo DCPOP utilizando pseudobosques tradicionales y de bordes cruzados (DCPOP-All). Los pseudobosques utilizados para DPOP fueron generados utilizando 5 heurísticas: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB y DFS MCN BEC. Estas son todas las versiones del recorrido DFS guiado discutidas en la Sección 5. Los pseudobosques de bordes cruzados utilizados para DCPOP-CE fueron generados utilizando 5 heurísticas: MCN, LCN, MCN A-B, LCN A-B y LCSG A-B. Estas son todas las versiones del recorrido de mejor primero discutidas en la Sección 5. Para tanto DPOP como DCPOP-CE elegimos el mejor pseudoárbol producido por sus respectivas 5 heurísticas para cada problema en el conjunto. Para DCPOP-All elegimos la mejor pseudotree producida por las 10 heurísticas para cada problema en el conjunto. Para las métricas de CD y MD, el valor mostrado es el número promedio de dimensiones. Para la métrica de PC, el valor mostrado es el logaritmo natural del costo de ruta secuencial máximo (ya que el valor real crece exponencialmente con la complejidad del problema). La última fila en ambas tablas es una medida de mejora de DCPOP-All sobre DPOP. Para las métricas CD y MD, el valor mostrado es una reducción en el número de dimensiones. Para la métrica de PC, el valor mostrado es una reducción porcentual en el costo máximo de la ruta secuencial (% = DP OP −DCP OP DCP OP ∗ 100). Observa que DCPOP supera a DPOP en todas las métricas. Esto se sigue lógicamente de nuestra afirmación anterior de que, dada la misma entrada, DCPOP se comporta exactamente igual que DPOP. Así, dada la elección entre los pseudobosques producidos por las 10 heurísticas, DCPOP-All siempre superará a DCPOP-CE y DPOP. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 6: Mejora del Costo del Camino DCPOP Reunión Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Tabla 3: Problemas de Programación de Reuniones realizan DPOP. Otra tendencia que observamos es que la mejora es mayor para problemas de alta densidad que para problemas de baja densidad. Mostramos esta tendencia con mayor detalle en las Figuras 4, 5 y 6. Observa cómo la mejora aumenta a medida que aumenta la complejidad del problema. 7.2 Problema de Programación de Reuniones Además de nuestras pruebas genéricas iniciales de DCOP, realizamos una serie de pruebas en el Problema de Programación de Reuniones (MSP) como se describe en [6]. La configuración del problema incluye un número de personas agrupadas en departamentos. Cada persona debe asistir a un número específico de reuniones. Las reuniones pueden llevarse a cabo dentro de los departamentos o entre departamentos, y pueden asignarse a uno de los ocho horarios disponibles. El MSP se mapea a una instancia de DCOP donde cada variable representa el intervalo de tiempo en el que una persona específica asistirá a una reunión específica. Todas las variables que pertenecen a la misma persona tienen restricciones de exclusión mutua para que la persona no pueda asistir a más de una reunión durante el mismo intervalo de tiempo. Todas las variables que pertenecen a la misma reunión tienen restricciones de igualdad para que todos los participantes elijan el mismo horario. Se imponen restricciones unarias en cada variable para tener en cuenta la valoración de una persona de cada reunión y franja horaria. Para nuestros tests generamos 100 problemas de muestra para cada combinación de agentes y reuniones. Los resultados se muestran en la Tabla 3. Los valores en las primeras cinco columnas representan (en orden de izquierda a derecha), el número total de agentes, el número total de reuniones, el número total de variables, el promedio total de restricciones y el promedio mínimo de IW producido por un pseudoárbol tradicional. Las últimas tres columnas muestran las mismas métricas que utilizamos para las instancias genéricas de DCOP, excepto que esta vez solo mostramos las mejoras de DCPOP-All sobre DPOP. El rendimiento es mejor en promedio para todas las instancias de MSP, pero nuevamente vemos mejoras más grandes para instancias de problemas más complejos. 8. CONCLUSIONES Y TRABAJO FUTURO Presentamos un algoritmo completo y distribuido que resuelve instancias generales de DCOP utilizando arreglos de pseudoramas cruzados. Nuestro algoritmo extiende el algoritmo DPOP al agregar mensajes adicionales de propagación de utilidad e introducir el concepto de fusión de ramas durante la fase de propagación de utilidad. Nuestro algoritmo también permite que las asignaciones de valor ocurran en puntos de fusión de nivel superior para nodos de nivel inferior. Hemos demostrado que DCPOP extiende completamente DPOP al realizar las mismas operaciones dadas las mismas entradas. También hemos demostrado a través de algunos ejemplos y datos experimentales que DCPOP puede lograr un mejor rendimiento para algunas instancias del problema al extender el conjunto de entrada permitido para incluir pseudobosques cruzados. Damos especial énfasis al papel que desempeñan las heurísticas de recorrido de bordes en la generación de pseudobosques. Hemos demostrado que la penalización en el rendimiento es mínima para generar múltiples heurísticas, y que podemos elegir el mejor pseudoárbol generado en complejidad lineal de espacio-tiempo. Dada la importancia de un buen pseudoárbol para el rendimiento, el trabajo futuro incluirá nuevas heurísticas para encontrar mejores pseudo El trabajo futuro también incluirá adaptar las extensiones existentes de DPOP [5, 7] que soportan diferentes dominios de problemas para su uso con DCPOP. 9. REFERENCIAS [1] J. Liu y K. P. Sycara. Explotando la estructura del problema para la optimización distribuida de restricciones. En V. Lesser, editor, Actas de la Primera Conferencia Internacional sobre Sistemas Multiagente, páginas 246-254, San Francisco, CA, 1995. MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, y S. Kulkarni. Un enfoque dinámico distribuido de satisfacción de restricciones para la asignación de recursos. Notas de conferencia en Ciencias de la Computación, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe y M. Yokoo. Un método completo asíncrono para la optimización de restricciones distribuidas. En AAMAS 03, 2003. [4] A. Petcu. Frodo: Un marco para la optimización de restricciones abiertas/distribuidas. Informe técnico No. 2006/001, Instituto Federal Suizo de Tecnología (EPFL), Lausana (Suiza), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu y B. Faltings. A-dpop: Aproximaciones en optimización distribuida. En póster en CP 2005, páginas 802-806, Sitges, España, octubre de 2005. [6] A. Petcu y B. Faltings. Dpop: Un método escalable para la optimización de restricciones multiagente. En IJCAI 05, páginas 266-271, Edimburgo, Escocia, agosto de 2005. [7] A. Petcu, B. Faltings y D. Parkes. M-dpop: Implementación distribuida fiel de problemas eficientes de elección social. En AAMAS 06, páginas 1397-1404, Hakodate, Japón, mayo de 2006. [8] G. Ushakov. Resolviendo problemas de programación de reuniones utilizando un procedimiento de optimización distribuido de pseudobosque. Tesis de maestría, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida y K. Kuwabara. Satisfacción de restricciones distribuida para formalizar la resolución de problemas distribuidos. En la Conferencia Internacional sobre Sistemas de Computación Distribuida, páginas 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida y K. Kuwabara. El problema de satisfacción de restricciones distribuidas: Formalización y algoritmos. Ingeniería del Conocimiento y de Datos, 10(5):673-685, 1998. 748 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "multi-valued utility function": {
            "translated_key": "funciones de utilidad multivaluadas",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Complete Distributed Constraint Optimization Method For Non-Traditional Pseudotree Arrangements∗ James Atlas Computer and Information Sciences University of Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Computer and Information Sciences University of Delaware Newark, DE 19716 decker@cis.udel.edu ABSTRACT Distributed Constraint Optimization (DCOP) is a general framework that can model complex problems in multi-agent systems.",
                "Several current algorithms that solve general DCOP instances, including ADOPT and DPOP, arrange agents into a traditional pseudotree structure.",
                "We introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements.",
                "Our algorithm correctly solves DCOP instances for pseudotrees that include edges between nodes in separate branches.",
                "The algorithm also solves instances with traditional pseudotree arrangements using the same procedure as DPOP.",
                "We compare our algorithm with DPOP using several metrics including the induced width of the pseudotrees, the maximum dimensionality of messages and computation, and the maximum sequential path cost through the algorithm.",
                "We prove that for some problem instances it is not possible to generate a traditional pseudotree using edge-traversal heuristics that will outperform a cross-edged pseudotree.",
                "We use multiple heuristics to generate pseudotrees and choose the best pseudotree in linear space-time complexity.",
                "For some problem instances we observe significant improvements in message and computation sizes compared to DPOP.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent Systems General Terms Algorithms 1.",
                "INTRODUCTION Many historical problems in the AI community can be transformed into Constraint Satisfaction Problems (CSP).",
                "With the advent of distributed AI, multi-agent systems became a popular way to model the complex interactions and coordination required to solve distributed problems.",
                "CSPs were originally extended to distributed agent environments in [9].",
                "Early domains for distributed constraint satisfaction problems (DisCSP) included job shop scheduling [1] and resource allocation [2].",
                "Many domains for agent systems, especially teamwork coordination, distributed scheduling, and sensor networks, involve overly constrained problems that are difficult or impossible to satisfy for every constraint.",
                "Recent approaches to solving problems in these domains rely on optimization techniques that map constraints into <br>multi-valued utility function</br>s.",
                "Instead of finding an assignment that satisfies all constraints, these approaches find an assignment that produces a high level of global utility.",
                "This extension to the original DisCSP approach has become popular in multi-agent systems, and has been labeled the Distributed Constraint Optimization Problem (DCOP) [1].",
                "Current algorithms that solve complete DCOPs use two main approaches: search and dynamic programming.",
                "Search based algorithms that originated from DisCSP typically use some form of backtracking [10] or bounds propagation, as in ADOPT [3].",
                "Dynamic programming based algorithms include DPOP and its extensions [5, 6, 7].",
                "To date, both categories of algorithms arrange agents into a traditional pseudotree to solve the problem.",
                "It has been shown in [6] that any constraint graph can be mapped into a traditional pseudotree.",
                "However, it was also shown that finding the optimal pseudotree was NP-Hard.",
                "We began to investigate the performance of traditional pseudotrees generated by current edge-traversal heuristics.",
                "We found that these heuristics often produced little parallelism as the pseudotrees tended to have high depth and low branching factors.",
                "We suspected that there could be other ways to arrange the pseudotrees that would provide increased parallelism and smaller message sizes.",
                "After exploring these other arrangements we found that cross-edged pseudotrees provide shorter depths and higher branching factors than the traditional pseudotrees.",
                "Our hypothesis was that these crossedged pseudotrees would outperform traditional pseudotrees for some problem types.",
                "In this paper we introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements which include cross-edged pseudotrees.",
                "We begin with a definition of 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, traditional pseudotrees, and cross-edged pseudotrees.",
                "We then provide a summary of the original DPOP algorithm and introduce our DCPOP algorithm.",
                "We discuss the complexity of our algorithm as well as the impact of pseudotree generation heuristics.",
                "We then show that our Distributed Cross-edged Pseudotree Optimization Procedure (DCPOP) performs significantly better in practice than the original DPOP algorithm for some problem instances.",
                "We conclude with a selection of ideas for future work and extensions for DCPOP. 2.",
                "PROBLEM DEFINITION DCOP has been formalized in slightly different ways in recent literature, so we will adopt the definition as presented in [6].",
                "A Distributed Constraint Optimization Problem with n nodes and m constraints consists of the tuple < X, D, U > where: • X = {x1,..,xn} is a set of variables, each one assigned to a unique agent • D = {d1,..,dn} is a set of finite domains for each variable • U = {u1,..,um} is a set of utility functions such that each function involves a subset of variables in X and defines a utility for each combination of values among these variables An optimal solution to a DCOP instance consists of an assignment of values in D to X such that the sum of utilities in U is maximal.",
                "Problem domains that require minimum cost instead of maximum utility can map costs into negative utilities.",
                "The utility functions represent soft constraints but can also represent hard constraints by using arbitrarily large negative values.",
                "For this paper we only consider binary utility functions involving two variables.",
                "Higher order utility functions can be modeled with minor changes to the algorithm, but they also substantially increase the complexity. 2.1 Traditional Pseudotrees Pseudotrees are a common structure used in search procedures to allow parallel processing of independent branches.",
                "As defined in [6], a pseudotree is an arrangement of a graph G into a rooted tree T such that vertices in G that share an edge are in the same branch in T. A back-edge is an edge between a node X and any node which lies on the path from X to the root (excluding Xs parent).",
                "Figure 1 shows a pseudotree with four nodes, three edges (A-B, B-C, BD), and one back-edge (A-C).",
                "Also defined in [6] are four types of relationships between nodes exist in a pseudotree: • P(X) - the parent of a node X: the single node higher in the pseudotree that is connected to X directly through a tree edge • C(X) - the children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through tree edges • PP(X) - the pseudo-parents of a node X: the set of nodes higher in the pseudotree that are connected to X directly through back-edges (In Figure 1, A = PP(C)) • PC(X) - the pseudo-children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through back-edges (In Figure 1, C = PC(A)) Figure 1: A traditional pseudotree.",
                "Solid line edges represent parent-child relationships and the dashed line represents a pseudo-parent-pseudo-child relationship.",
                "Figure 2: A cross-edged pseudotree.",
                "Solid line edges represent parent-child relationships, the dashed line represents a pseudoparent-pseudo-child relationship, and the dotted line represents a branch-parent-branch-child relationship.",
                "The bolded node, B, is the merge point for node E. 2.2 Cross-edged Pseudotrees We define a cross-edge as an edge from node X to a node Y that is above X but not in the path from X to the root.",
                "A cross-edged pseudotree is a traditional pseudotree with the addition of cross-edges.",
                "Figure 2 shows a cross-edged pseudotree with a cross-edge (D-E).",
                "In a cross-edged pseudotree we designate certain edges as primary.",
                "The set of primary edges defines a spanning tree of the nodes.",
                "The parent, child, pseudo-parent, and pseudo-child relationships from the traditional pseudotree are now defined in the context of this primary edge spanning tree.",
                "This definition also yields two additional types of relationships that may exist between nodes: • BP(X) - the branch-parents of a node X: the set of nodes higher in the pseudotree that are connected to X but are not in the primary path from X to the root (In Figure 2, D = BP(E)) • BC(X) - the branch-children of a node X: the set of nodes lower in the pseudotree that are connected to X but are not in any primary path from X to any leaf node (In Figure 2, E = BC(D)) 2.3 Pseudotree Generation 742 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Current algorithms usually have a pre-execution phase to generate a traditional pseudotree from a general DCOP instance.",
                "Our DCPOP algorithm generates a cross-edged pseudotree in the same fashion.",
                "First, the DCOP instance < X, D, U > translates directly into a graph with X as the set of vertices and an edge for each pair of variables represented in U.",
                "Next, various heuristics are used to arrange this graph into a pseudotree.",
                "One common heuristic is to perform a guided depth-first search (DFS) as the resulting traversal is a pseudotree, and a DFS can easily be performed in a distributed fashion.",
                "We define an edge-traversal based method as any method that produces a pseudotree in which all parent/child pairs share an edge in the original graph.",
                "This includes DFS, breadth-first search, and best-first search based traversals.",
                "Our heuristics that generate cross-edged pseudotrees use a distributed best-first search traversal. 3.",
                "DPOP ALGORITHM The original DPOP algorithm operates in three main phases.",
                "The first phase generates a traditional pseudotree from the DCOP instance using a distributed algorithm.",
                "The second phase joins utility hypercubes from children and the local node and propagates them towards the root.",
                "The third phase chooses an assignment for each domain in a top down fashion beginning with the agent at the root node.",
                "The complexity of DPOP depends on the size of the largest computation and utility message during phase two.",
                "It has been shown that this size directly corresponds to the induced width of the pseudotree generated in phase one [6].",
                "DPOP uses polynomial time heuristics to generate the pseudotree since finding the minimum induced width pseudotree is NP-hard.",
                "Several distributed edgetraversal heuristics have been developed to find low width pseudotrees [8].",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, and pseudo-children. 3.1 Utility Propagation Agents located at leaf nodes in the pseudotree begin the process by calculating a local utility hypercube.",
                "This hypercube at node X contains summed utilities for each combination of values in the domains for P(X) and PP(X).",
                "This hypercube has dimensional size equal to the number of pseudo-parents plus one.",
                "A message containing this hypercube is sent to P(X).",
                "Agents located at non-leaf nodes wait for all messages from children to arrive.",
                "Once the agent at node Y has all utility messages, it calculates its local utility hypercube which includes domains for P(Y), PP(Y), and Y.",
                "The local utility hypercube is then joined with all of the hypercubes from the child messages.",
                "At this point all utilities involving node Y are known, and the domain for Y may be safely eliminated from the joined hypercube.",
                "This elimination process chooses the best utility over the domain of Y for each combination of the remaining domains.",
                "A message containing this hypercube is now sent to P(Y).",
                "The dimensional size of this hypercube depends on the number of overlapping domains in received messages and the local utility hypercube.",
                "This dynamic programming based propagation phase continues until the agent at the root node of the pseudotree has received all messages from its children. 3.2 Value Propagation Value propagation begins when the agent at the root node Z has received all messages from its children.",
                "Since Z has no parents or pseudo-parents, it simply combines the utility hypercubes received from its children.",
                "The combined hypercube contains only values for the domain for Z.",
                "At this point the agent at node Z simply chooses the assignment for its domain that has the best utility.",
                "A value propagation message with this assignment is sent to each node in C(Z).",
                "Each other node then receives a value propagation message from its parent and chooses the assignment for its domain that has the best utility given the assignments received in the message.",
                "The node adds its domain assignment to the assignments it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen an assignment for their domain. 4.",
                "DCPOP ALGORITHM Our extension to the original DPOP algorithm, shown in Algorithm 1, shares the same three phases.",
                "The first phase generates the cross-edged pseudotree for the DCOP instance.",
                "The second phase merges branches and propagates the utility hypercubes.",
                "The third phase chooses assignments for domains at branch merge points and in a top down fashion, beginning with the agent at the root node.",
                "For the first phase we generate a pseudotree using several distributed heuristics and select the one with lowest overall complexity.",
                "The complexity of the computation and utility message size in DCPOP does not directly correspond to the induced width of the cross-edged pseudotree.",
                "Instead, we use a polynomial time method for calculating the maximum computation and utility message size for a given cross-edged pseudotree.",
                "A description of this method and the pseudotree selection process appears in Section 5.",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, pseudo-children, branch-parents, and branch-children. 4.1 Merging Branches and Utility Propagation In the original DPOP algorithm a node X only had utility functions involving its parent and its pseudo-parents.",
                "In DCPOP, a node X is allowed to have a utility function involving a branch-parent.",
                "The concept of a branch can be seen in Figure 2 with node E representing our node X.",
                "The two distinct paths from node E to node B are called branches of E. The single node where all branches of E meet is node B, which is called the merge point of E. Agents with nodes that have branch-parents begin by sending a utility propagation message to each branch-parent.",
                "This message includes a two dimensional utility hypercube with domains for the node X and the branch-parent BP(X).",
                "It also includes a branch information structure which contains the origination node of the branch, X, the total number of branches originating from X, and the number of branches originating from X that are merged into a single representation by this branch information structure (this number starts at 1).",
                "Intuitively when the number of merged branches equals the total number of originating branches, the algorithm has reached the merge point for X.",
                "In Figure 2, node E sends a utility propagation message to its branch-parent, node D. This message has dimensions for the domains of E and D, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "As in the original DPOP utility propagation phase, an agent at leaf node X sends a utility propagation message to its parent.",
                "In DCPOP this message contains dimensions for the domains of P(X) and PP(X).",
                "If node X also has branch-parents, then the utility propagation message also contains a dimension for the domain of X, and will include a branch information structure.",
                "In Figure 2, node E sends a utility propagation message to its parent, node C. This message has dimensions for the domains of E and C, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "When a node Y receives utility propagation messages from all of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 743 its children and branch-children, it merges any branches with the same origination node X.",
                "The merged branch information structure accumulates the number of merged branches for X.",
                "If the cumulative total number of merged branches equals the total number of branches, then Y is the merge point for X.",
                "This means that the utility hypercubes present at Y contain all information about the valuations for utility functions involving node X.",
                "In addition to the typical elimination of the domain of Y from the utility hypercubes, we can now safely eliminate the domain of X from the utility hypercubes.",
                "To illustrate this process, we will examine what happens in the second phase for node B in Figure 2.",
                "In the second phase Node B receives two utility propagation messages.",
                "The first comes from node C and includes dimensions for domains E, B, and A.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "The second comes from node D and includes dimensions for domains E and B.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "Node B then merges the branch information structures from both messages because they have the same origination, node E. Since the number of merged branches originating from E is now 2 and the total branches originating from E is 2, node B now eliminates the dimensions for domain E. Node B also eliminates the dimension for its own domain, leaving only information about domain A. Node B then sends a utility propagation message to node A, containing only one dimension for the domain of A.",
                "Although not possible in DPOP, this method of utility propagation and dimension elimination may produce hypercubes at node Y that do not share any domains.",
                "In DCPOP we do not join domain independent hypercubes, but instead may send multiple hypercubes in the utility propagation message sent to the parent of Y.",
                "This lazy approach to joins helps to reduce message sizes. 4.2 Value Propagation As in DPOP, value propagation begins when the agent at the root node Z has received all messages from its children.",
                "At this point the agent at node Z chooses the assignment for its domain that has the best utility.",
                "If Z is the merge point for the branches of some node X, Z will also choose the assignment for the domain of X.",
                "Thus any node that is a merge point will choose assignments for a domain other than its own.",
                "These assignments are then passed down the primary edge hierarchy.",
                "If node X in the hierarchy has branch-parents, then the value assignment message from P(X) will contain an assignment for the domain of X.",
                "Every node in the hierarchy adds any assignments it has chosen to the ones it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen or received an assignment for their domain. 4.3 Proof of Correctness We will prove the correctness of DCPOP by first noting that DCPOP fully extends DPOP and then examining the two cases for value assignment in DCPOP.",
                "Given a traditional pseudotree as input, the DCPOP algorithm execution is identical to DPOP.",
                "Using a traditional pseudotree arrangement no nodes have branch-parents or branch-children since all edges are either back-edges or tree edges.",
                "Thus the DCPOP algorithm using a traditional pseudotree sends only utility propagation messages that contain domains belonging to the parent or pseudo-parents of a node.",
                "Since no node has any branch-parents, no branches exist, and thus no node serves as a merge point for any other node.",
                "Thus all value propagation assignments are chosen at the node of the assignment domain.",
                "For DCPOP execution with cross-edged pseudotrees, some nodes serve as merge points.",
                "We note that any node X that is not a merge point assigns its value exactly as in DPOP.",
                "The local utility hypercube at X contains domains for X, P(X), PP(X), and BC(X).",
                "As in DPOP the value assignment message received at X includes the values assigned to P(X) and PP(X).",
                "Also, since X is not a merge point, all assignments to BC(X) must have been calculated at merge points higher in the tree and are in the value assignment message from P(X).",
                "Thus after eliminating domains for which assignments are known, only the domain of X is left.",
                "The agent at node X can now correctly choose the assignment with maximum utility for its own domain.",
                "If node X is a merge point for some branch-child Y, we know that X must be a node along the path from Y to the root, and from P(Y) and all BP(Y) to the root.",
                "From the algorithm, we know that Y necessarily has all information from C(Y), PC(Y), and BC(Y) since it waits for their messages.",
                "Node X has information about all nodes below it in the tree, which would include Y, P(Y), BP(Y), and those PP(Y) that are below X in the tree.",
                "For any PP(Y) above X in the tree, X receives the assignment for the domain of PP(Y) in the value assignment message from P(X).",
                "Thus X has utility information about all of the utility functions of which Y is a part.",
                "By eliminating domains included in the value assignment message, node X is left with a local utility hypercube with domains for X and Y.",
                "The agent at node X can now correctly choose the assignments with maximum utility for the domains of X and Y. 4.4 Complexity Analysis The first phase of DCPOP sends one message to each P(X), PP(X), and BP(X).",
                "The second phase sends one value assignment message to each C(X).",
                "Thus, DCPOP produces a linear number of messages with respect to the number of edges (utility functions) in the cross-edged pseudotree and the original DCOP instance.",
                "The actual complexity of DCPOP depends on two additional measurements: message size and computation size.",
                "Message size and computation size in DCPOP depend on the number of overlapping branches as well as the number of overlapping back-edges.",
                "It was shown in [6] that the number of overlapping back-edges is equal to the induced width of the pseudotree.",
                "In a poorly constructed cross-edged pseudotree, the number of overlapping branches at node X can be as large as the total number of descendants of X.",
                "Thus, the total message size in DCPOP in a poorly constructed instance can be space-exponential in the total number of nodes in the graph.",
                "However, in practice a well constructed cross-edged pseudotree can achieve much better results.",
                "Later we address the issue of choosing well constructed crossedged pseudotrees from a set.",
                "We introduce an additional measurement of the maximum sequential path cost through the algorithm.",
                "This measurement directly relates to the maximum amount of parallelism achievable by the algorithm.",
                "To take this measurement we first store the total computation size for each node during phase two and three.",
                "This computation size represents the number of individual accesses to a value in a hypercube at each node.",
                "For example, a join between two domains of size 4 costs 4 ∗ 4 = 16.",
                "Two directed acyclic graphs (DAG) can then be drawn; one with the utility propagation messages as edges and the phase two costs at nodes, and the other with value assignment messages and the phase three costs at nodes.",
                "The maximum sequential path cost is equal to the sum of the longest path on each DAG from the root to any leaf node. 5.",
                "HEURISTICS In our assessment of complexity in DCPOP we focused on the worst case possibly produced by the algorithm.",
                "We acknowledge 744 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Algorithm 1 DCPOP Algorithm 1: DCPOP(X; D; U) Each agent Xi executes: Phase 1: pseudotree creation 2: elect leader from all Xj ∈ X 3: elected leader initiates pseudotree creation 4: afterwards, Xi knows P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) and PC(Xi) Phase 2: UTIL message propagation 5: if |BP(Xi)| > 0 then 6: BRANCHXi ← |BP(Xi)| + 1 7: for all Xk ∈BP(Xi) do 8: UTILXi (Xk) ←Compute utils(Xi, Xk) 9: Send message(Xk,UTILXi (Xk),BRANCHXi ) 10: if |C(Xi)| = 0(i.e.",
                "Xi is a leaf node) then 11: UTILXi (P(Xi)) ← Compute utils(P(Xi),PP(Xi)) for all PP(Xi) 12: Send message(P(Xi), UTILXi (P(Xi)),BRANCHXi ) 13: Send message(PP(Xi), empty UTIL, empty BRANCH) to all PP(Xi) 14: activate UTIL Message handler() Phase 3: VALUE message propagation 15: activate VALUE Message handler() END ALGORITHM UTIL Message handler(Xk,UTILXk (Xi), BRANCHXk ) 16: store UTILXk (Xi),BRANCHXk (Xi) 17: if UTIL messages from all children and branch children arrived then 18: for all Bj ∈BRANCH(Xi) do 19: if Bj is merged then 20: join all hypercubes where Bj ∈UTIL(Xi) 21: eliminate Bj from the joined hypercube 22: if P(Xi) == null (that means Xi is the root) then 23: v ∗ i ← Choose optimal(null) 24: Send VALUE(Xi, v ∗ i) to all C(Xi) 25: else 26: UTILXi (P(Xi)) ← Compute utils(P(Xi), PP(Xi)) 27: Send message(P(Xi),UTILXi (P(Xi)), BRANCHXi (P(Xi))) VALUE Message handler(VALUEXi ,P(Xi)) 28: add all Xk ← v ∗ k ∈VALUEXi ,P(Xi) to agent view 29: Xi ← v ∗ i =Choose optimal(agent view) 30: Send VALUEXl , Xi to all Xl ∈C(Xi) that in real world problems the generation of the pseudotree has a significant impact on the actual performance.",
                "The problem of finding the best pseudotree for a given DCOP instance is NP-Hard.",
                "Thus a heuristic is used for generation, and the performance of the algorithm depends on the pseudotree found by the heuristic.",
                "Some previous research focused on finding heuristics to generate good pseudotrees [8].",
                "While we have developed some heuristics that generate good cross-edged pseudotrees for use with DCPOP, our focus has been to use multiple heuristics and then select the best pseudotree from the generated pseudotrees.",
                "We consider only heuristics that run in polynomial time with respect to the number of nodes in the original DCOP instance.",
                "The actual DCPOP algorithm has worst case exponential complexity, but we can calculate the maximum message size, computation size, and sequential path cost for a given cross-edged pseudotree in linear space-time complexity.",
                "To do this, we simply run the algorithm without attempting to calculate any of the local utility hypercubes or optimal value assignments.",
                "Instead, messages include dimensional and branch information but no utility hypercubes.",
                "After each heuristic completes its generation of a pseudotree, we execute the measurement procedure and propagate the measurement information up to the chosen root in that pseudotree.",
                "The root then broadcasts the total complexity for that heuristic to all nodes.",
                "After all heuristics have had a chance to complete, every node knows which heuristic produced the best pseudotree.",
                "Each node then proceeds to begin the DCPOP algorithm using its knowledge of the pseudotree generated by the best heuristic.",
                "The heuristics used to generate traditional pseudotrees perform a distributed DFS traversal.",
                "The general distributed algorithm uses a token passing mechanism and a linear number of messages.",
                "Improved DFS based heuristics use a special procedure to choose the root node, and also provide an ordering function over the neighbors of a node to determine the order of path recursion.",
                "The DFS based heuristics used in our experiments come from the work done in [4, 8]. 5.1 The best-first cross-edged pseudotree heuristic The heuristics used to generate cross-edged pseudotrees perform a best-first traversal.",
                "A general distributed best-first algorithm for node expansion is presented in Algorithm 2.",
                "An evaluation function at each node provides the values that are used to determine the next best node to expand.",
                "Note that in this algorithm each node only exchanges its best value with its neighbors.",
                "In our experiments we used several evaluation functions that took as arguments an ordered list of ancestors and a node, which contains a list of neighbors (with each neighbors placement depth in the tree if it was placed).",
                "From these we can calculate branchparents, branch-children, and unknown relationships for a potential node placement.",
                "The best overall function calculated the value as ancestors−(branchparents+branchchildren) with the number of unknown relationships being a tiebreak.",
                "After completion each node has knowledge of its parent and ancestors, so it can easily determine which connected nodes are pseudo-parents, branchparents, pseudo-children, and branch-children.",
                "The complexity of the best-first traversal depends on the complexity of the evaluation function.",
                "Assuming a complexity of O(V ) for the evaluation function, which is the case for our best overall function, the best-first traversal is O(V · E) which is at worst O(n3 ).",
                "For each v ∈ V we perform a place operation, and find the next node to place using the getBestNeighbor operation.",
                "The place operation is at most O(V ) because of the sent messages.",
                "Finding the next node uses recursion and traverses only already placed The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 745 Algorithm 2 Distributed Best-First Search Algorithm root ← electedleader next(root, ∅) place(node, parent) node.parent ← parent node.ancestors ← parent.ancestors ∪ parent send placement message (node, node.ancestors) to all neighbors of node next(current, previous) if current is not placed then place(current, previous) next(current, ∅) else best ← getBestNeighbor(current, previous) if best = ∅ then if previous = ∅ then terminate, all nodes are placed next(previous, ∅) else next(best, current) getBestNeighbor(current, previous) best ← ∅; score ← 0 for all n ∈ current.neighbors do if n! = previous then if n is placed then nscore ← getBestNeighbor(n, current) else nscore ← evaluate(current, n) if nscore > score then score ← nscore best ← n return best, score nodes, so it has O(V ) recursions.",
                "Each recursion performs a recursive getBestNeighbor operation that traverses all placed nodes and their neighbors.",
                "This operation is O(V · E), but results can be cached using only O(V ) space at each node.",
                "Thus we have O(V ·(V +V +V ·E)) = O(V 2 ·E).",
                "If we are smart about evaluating local changes when each node receives placement messages from its neighbors and cache the results the getBestNeighbor operation is only O(E).",
                "This increases the complexity of the place operation, but for all placements the total complexity is only O(V · E).",
                "Thus we have an overall complexity of O(V ·E+V ·(V +E)) = O(V ·E). 6.",
                "COMPARISON OF COMPLEXITY IN DPOP AND DCPOP We have already shown that given the same input, DCPOP performs the same as DPOP.",
                "We also have shown that we can accurately predict performance of a given pseudotree in linear spacetime complexity.",
                "If we use a constant number of heuristics to generate the set of pseudotrees, we can choose the best pseudotree in linear space-time complexity.",
                "We will now show that there exists a DCOP instance for which a cross-edged pseudotree outperforms all possible traditional pseudotrees (based on edge-traversal heuristics).",
                "In Figure 3(a) we have a DCOP instance with six nodes.",
                "This is a bipartite graph with each partition fully connected to the other (a) (b) (c) Figure 3: (a) The DCOP instance (b) A traditional pseudotree arrangement for the DCOP instance (c) A cross-edged pseudotree arrangement for the DCOP instance partition.",
                "In Figure 3(b) we see a traditional pseudotree arrangement for this DCOP instance.",
                "It is easy to see that any edgetraversal based heuristic cannot expand two nodes from the same partition in succession.",
                "We also see that no node can have more than one child because any such arrangement would be an invalid pseudotree.",
                "Thus any traditional pseudotree arrangement for this DCOP instance must take the form of Figure 3(b).",
                "We can see that the back-edges F-B and F-A overlap node C. Node C also has a parent E, and a back-edge with D. Using the original DPOP algorithm (or DCPOP since they are identical in this case), we find that the computation at node C involves five domains: A, B, C, D, and E. In contrast, the cross-edged pseudotree arrangement in Figure 3(c) requires only a maximum of four domains in any computation during DCPOP.",
                "Since node A is the merge point for branches from both B and C, we can see that each of the nodes D, E, and F have two overlapping branches.",
                "In addition each of these nodes has node A as its parent.",
                "Using the DCPOP algorithm we find that the computation at node D (or E or F) involves four domains: A, B, C, and D (or E or F).",
                "Since no better traditional pseudotree arrangement can be created using an edge-traversal heuristic, we have shown that DCPOP can outperform DPOP even if we use the optimal pseudotree found through edge-traversal.",
                "We acknowledge that pseudotree arrangements that allow parent-child relationships without an actual constraint can solve the problem in Figure 3(a) with maximum computation size of four domains.",
                "However, current heuristics used with DPOP do not produce such pseudotrees, and such a heuristic would be difficult to distribute since each node would require information about nodes with which it has no constraint.",
                "Also, while we do not prove it here, cross-edged pseudotrees can produce smaller message sizes than such pseudotrees even if the computation size is similar.",
                "In practice, since finding the best pseudotree arrangement is NP-Hard, we find that heuristics that produce cross-edged pseudotrees often produce significantly smaller computation and message sizes. 7.",
                "EXPERIMENTAL RESULTS 746 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Existing performance metrics for DCOP algorithms include the total number of messages, synchronous clock cycles, and message size.",
                "We have already shown that the total number of messages is linear with respect to the number of constraints in the DCOP instance.",
                "We also introduced the maximum sequential path cost (PC) as a measurement of the maximum amount of parallelism achievable by the algorithm.",
                "The maximum sequential path cost is equal to the sum of the computations performed on the longest path from the root to any leaf node.",
                "We also include as metrics the maximum computation size in number of dimensions (CD) and maximum message size in number of dimensions (MD).",
                "To analyze the relative complexity of a given DCOP instance, we find the minimum induced width (IW) of any traditional pseudotree produced by a heuristic for the original DPOP. 7.1 Generic DCOP instances For our initial tests we randomly generated two sets of problems with 3000 cases in each.",
                "Each problem was generated by assigning a random number (picked from a range) of constraints to each variable.",
                "The generator then created binary constraints until each variable reached its maximum number of constraints.",
                "The first set uses 20 variables, and the best DPOP IW ranges from 1 to 16 with an average of 8.5.",
                "The second set uses 100 variables, and the best DPOP IW ranged from 2 to 68 with an average of 39.3.",
                "Since most of the problems in the second set were too complex to actually compute the solution, we took measurements of the metrics using the techniques described earlier in Section 5 without actually solving the problem.",
                "Results are shown for the first set in Table 1 and for the second set in Table 2.",
                "For the two problem sets we split the cases into low density and high density categories.",
                "Low density cases consist of those problems that have a best DPOP IW less than or equal to half of the total number of nodes (e.g.",
                "IW ≤ 10 for the 20 node problems and IW ≤ 50 for the 100 node problems).",
                "High density problems consist of the remainder of the problem sets.",
                "In both Table 1 and Table 2 we have listed performance metrics for the original DPOP algorithm, the DCPOP algorithm using only cross-edged pseudotrees (DCPOP-CE), and the DCPOP algorithm using traditional and cross-edged pseudotrees (DCPOP-All).",
                "The pseudotrees used for DPOP were generated using 5 heuristics: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB, and DFS MCN BEC.",
                "These are all versions of the guided DFS traversal discussed in Section 5.",
                "The cross-edged pseudotrees used for DCPOP-CE were generated using 5 heuristics: MCN, LCN, MCN A-B, LCN A-B, and LCSG A-B.",
                "These are all versions of the best-first traversal discussed in Section 5.",
                "For both DPOP and DCPOP-CE we chose the best pseudotree produced by their respective 5 heuristics for each problem in the set.",
                "For DCPOP-All we chose the best pseudotree produced by all 10 heuristics for each problem in the set.",
                "For the CD and MD metrics the value shown is the average number of dimensions.",
                "For the PC metric the value shown is the natural logarithm of the maximum sequential path cost (since the actual value grows exponentially with the complexity of the problem).",
                "The final row in both tables is a measurement of improvement of DCPOP-All over DPOP.",
                "For the CD and MD metrics the value shown is a reduction in number of dimensions.",
                "For the PC metric the value shown is a percentage reduction in the maximum sequential path cost (% = DP OP −DCP OP DCP OP ∗ 100).",
                "Notice that DCPOPAll outperforms DPOP on all metrics.",
                "This logically follows from our earlier assertion that given the same input, DCPOP performs exactly the same as DPOP.",
                "Thus given the choice between the pseudotrees produced by all 10 heuristics, DCPOP-All will always outLow Density High Density Algorithm CD MD PC CD MD PC DPOP 7.81 6.81 3.78 13.34 12.34 5.34 DCPOP-CE 7.94 6.73 3.74 12.83 11.43 5.07 DCPOP-All 7.62 6.49 3.66 12.72 11.36 5.05 Improvement 0.18 0.32 13% 0.62 0.98 36% Table 1: 20 node problems Low Density High Density Algorithm CD MD PC CD MD PC DPOP 33.35 32.35 14.55 58.51 57.50 19.90 DCPOP-CE 33.49 29.17 15.22 57.11 50.03 20.01 DCPOP-All 32.35 29.57 14.10 56.33 51.17 18.84 Improvement 1.00 2.78 104% 2.18 6.33 256% Table 2: 100 node problems Figure 4: Computation Dimension Size Figure 5: Message Dimension Size The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 747 Figure 6: Path Cost DCPOP Improvement Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Table 3: Meeting Scheduling Problems perform DPOP.",
                "Another trend we notice is that the improvement is greater for high density problems than low density problems.",
                "We show this trend in greater detail in Figures 4, 5, and 6.",
                "Notice how the improvement increases as the complexity of the problem increases. 7.2 Meeting Scheduling Problem In addition to our initial generic DCOP tests, we ran a series of tests on the Meeting Scheduling Problem (MSP) as described in [6].",
                "The problem setup includes a number of people that are grouped into departments.",
                "Each person must attend a specified number of meetings.",
                "Meetings can be held within departments or among departments, and can be assigned to one of eight time slots.",
                "The MSP maps to a DCOP instance where each variable represents the time slot that a specific person will attend a specific meeting.",
                "All variables that belong to the same person have mutual exclusion constraints placed so that the person cannot attend more than one meeting during the same time slot.",
                "All variables that belong to the same meeting have equality constraints so that all of the participants choose the same time slot.",
                "Unary constraints are placed on each variable to account for a persons valuation of each meeting and time slot.",
                "For our tests we generated 100 sample problems for each combination of agents and meetings.",
                "Results are shown in Table 3.",
                "The values in the first five columns represent (in left to right order), the total number of agents, the total number of meetings, the total number of variables, the average total number of constraints, and the average minimum IW produced by a traditional pseudotree.",
                "The last three columns show the same metrics we used for the generic DCOP instances, except this time we only show the improvements of DCPOP-All over DPOP.",
                "Performance is better on average for all MSP instances, but again we see larger improvements for more complex problem instances. 8.",
                "CONCLUSIONS AND FUTURE WORK We presented a complete, distributed algorithm that solves general DCOP instances using cross-edged pseudotree arrangements.",
                "Our algorithm extends the DPOP algorithm by adding additional utility propagation messages, and introducing the concept of branch merging during the utility propagation phase.",
                "Our algorithm also allows value assignments to occur at higher level merge points for lower level nodes.",
                "We have shown that DCPOP fully extends DPOP by performing the same operations given the same input.",
                "We have also shown through some examples and experimental data that DCPOP can achieve greater performance for some problem instances by extending the allowable input set to include cross-edged pseudotrees.",
                "We placed particular emphasis on the role that edge-traversal heuristics play in the generation of pseudotrees.",
                "We have shown that the performance penalty is minimal to generate multiple heuristics, and that we can choose the best generated pseudotree in linear space-time complexity.",
                "Given the importance of a good pseudotree for performance, future work will include new heuristics to find better pseudotrees.",
                "Future work will also include adapting existing DPOP extensions [5, 7] that support different problem domains for use with DCPOP. 9.",
                "REFERENCES [1] J. Liu and K. P. Sycara.",
                "Exploiting problem structure for distributed constraint optimization.",
                "In V. Lesser, editor, Proceedings of the First International Conference on Multi-Agent Systems, pages 246-254, San Francisco, CA, 1995.",
                "MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni.",
                "A dynamic distributed constraint satisfaction approach to resource allocation.",
                "Lecture Notes in Computer Science, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe, and M. Yokoo.",
                "An asynchronous complete method for distributed constraint optimization.",
                "In AAMAS 03, 2003. [4] A. Petcu.",
                "Frodo: A framework for open/distributed constraint optimization.",
                "Technical Report No. 2006/001 2006/001, Swiss Federal Institute of Technology (EPFL), Lausanne (Switzerland), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu and B. Faltings.",
                "A-dpop: Approximations in distributed optimization.",
                "In poster in CP 2005, pages 802-806, Sitges, Spain, October 2005. [6] A. Petcu and B. Faltings.",
                "Dpop: A scalable method for multiagent constraint optimization.",
                "In IJCAI 05, pages 266-271, Edinburgh, Scotland, Aug 2005. [7] A. Petcu, B. Faltings, and D. Parkes.",
                "M-dpop: Faithful distributed implementation of efficient social choice problems.",
                "In AAMAS 06, pages 1397-1404, Hakodate, Japan, May 2006. [8] G. Ushakov.",
                "Solving meeting scheduling problems using distributed pseudotree-optimization procedure.",
                "Masters thesis, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "Distributed constraint satisfaction for formalizing distributed problem solving.",
                "In International Conference on Distributed Computing Systems, pages 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "The distributed constraint satisfaction problem: Formalization and algorithms.",
                "Knowledge and Data Engineering, 10(5):673-685, 1998. 748 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "Recent approaches to solving problems in these domains rely on optimization techniques that map constraints into <br>multi-valued utility function</br>s."
            ],
            "translated_annotated_samples": [
                "Los enfoques recientes para resolver problemas en estos dominios se basan en técnicas de optimización que mapean restricciones en <br>funciones de utilidad multivaluadas</br>."
            ],
            "translated_text": "Un Método Completo de Optimización de Restricciones Distribuidas para Arreglos de Pseudotree No Tradicionales∗ James Atlas Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 decker@cis.udel.edu RESUMEN La Optimización de Restricciones Distribuidas (DCOP) es un marco general que puede modelar problemas complejos en sistemas multiagente. Varios algoritmos actuales que resuelven instancias generales de DCOP, incluyendo ADOPT y DPOP, organizan a los agentes en una estructura de pseudobosque tradicional. Introducimos una extensión al algoritmo DPOP que maneja un conjunto extendido de disposiciones de pseudobosque. Nuestro algoritmo resuelve correctamente instancias de DCOP para pseudobosques que incluyen aristas entre nodos en ramas separadas. El algoritmo también resuelve instancias con arreglos de pseudobosque tradicionales utilizando el mismo procedimiento que DPOP. Comparamos nuestro algoritmo con DPOP utilizando varios métricos, incluyendo el ancho inducido de los pseudobosques, la dimensionalidad máxima de los mensajes y la computación, y el costo máximo de la ruta secuencial a través del algoritmo. Demostramos que para algunas instancias del problema no es posible generar un pseudoárbol tradicional utilizando heurísticas de recorrido de aristas que supere a un pseudoárbol con aristas cruzadas. Utilizamos múltiples heurísticas para generar pseudoárboles y elegir el mejor pseudoárbol en complejidad espacio-temporal lineal. Para algunas instancias del problema observamos mejoras significativas en los tamaños de los mensajes y cálculos en comparación con DPOP. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Algoritmos 1. INTRODUCCIÓN Muchos problemas históricos en la comunidad de IA pueden transformarse en Problemas de Satisfacción de Restricciones (CSP). Con la llegada de la inteligencia artificial distribuida, los sistemas multiagente se convirtieron en una forma popular de modelar las interacciones complejas y la coordinación necesaria para resolver problemas distribuidos. Los CSPs fueron originalmente extendidos a entornos de agentes distribuidos en [9]. Los primeros dominios para problemas de satisfacción de restricciones distribuidas (DisCSP) incluyeron la programación de talleres de trabajo [1] y la asignación de recursos [2]. Muchos dominios para sistemas de agentes, especialmente coordinación de trabajo en equipo, programación distribuida y redes de sensores, implican problemas excesivamente restringidos que son difíciles o imposibles de satisfacer para cada restricción. Los enfoques recientes para resolver problemas en estos dominios se basan en técnicas de optimización que mapean restricciones en <br>funciones de utilidad multivaluadas</br>. En lugar de encontrar una asignación que satisfaga todas las restricciones, estos enfoques encuentran una asignación que produce un alto nivel de utilidad global. Esta extensión al enfoque original de DisCSP se ha vuelto popular en sistemas multiagente, y ha sido etiquetada como Problema de Optimización de Restricciones Distribuidas (DCOP) [1]. Los algoritmos actuales que resuelven DCOPs completos utilizan dos enfoques principales: búsqueda y programación dinámica. Los algoritmos basados en búsqueda que se originaron a partir de DisCSP típicamente utilizan alguna forma de retroceso [10] o propagación de límites, como en ADOPT [3]. Los algoritmos basados en programación dinámica incluyen DPOP y sus extensiones [5, 6, 7]. Hasta la fecha, ambas categorías de algoritmos organizan agentes en un pseudoárbol tradicional para resolver el problema. Se ha demostrado en [6] que cualquier grafo de restricciones puede ser mapeado en un pseudoárbol tradicional. Sin embargo, también se demostró que encontrar el pseudoárbol óptimo era NP-Difícil. Comenzamos a investigar el rendimiento de los pseudobosques tradicionales generados por las heurísticas actuales de recorrido de aristas. Descubrimos que estas heurísticas a menudo generaban poco paralelismo, ya que los pseudárboles tendían a tener una gran profundidad y bajos factores de ramificación. Sospechábamos que podría haber otras formas de organizar los pseudobosques que proporcionarían un mayor paralelismo y tamaños de mensaje más pequeños. Después de explorar estos otros arreglos, descubrimos que los pseudobosques de bordes cruzados proporcionan profundidades más cortas y factores de ramificación más altos que los pseudobosques tradicionales. Nuestra hipótesis era que estos pseudorboles cruzados superarían a los pseudorboles tradicionales en algunos tipos de problemas. En este artículo presentamos una extensión al algoritmo DPOP que maneja un conjunto ampliado de disposiciones de pseudobosque que incluyen pseudobosques con aristas cruzadas. Comenzamos con una definición de 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, pseudobosques tradicionales y pseudobosques de bordes cruzados. Luego proporcionamos un resumen del algoritmo DPOP original e introducimos nuestro algoritmo DCPOP. Discutimos la complejidad de nuestro algoritmo, así como el impacto de las heurísticas de generación de pseudobosques. Luego demostramos que nuestro Procedimiento de Optimización de Pseudotree de Bordes Cruzados Distribuido (DCPOP) funciona significativamente mejor en la práctica que el algoritmo DPOP original para algunas instancias del problema. Concluimos con una selección de ideas para trabajos futuros y extensiones para DCPOP. 2. La DEFINICIÓN DEL PROBLEMA DCOP ha sido formalizada de maneras ligeramente diferentes en la literatura reciente, por lo que adoptaremos la definición presentada en [6]. Un Problema de Optimización de Restricciones Distribuidas con n nodos y m restricciones consiste en la tupla < X, D, U > donde: • X = {x1,..,xn} es un conjunto de variables, cada una asignada a un agente único • D = {d1,..,dn} es un conjunto de dominios finitos para cada variable • U = {u1,..,um} es un conjunto de funciones de utilidad tales que cada función involucra un subconjunto de variables en X y define una utilidad para cada combinación de valores entre estas variables. Una solución óptima para una instancia de DCOP consiste en una asignación de valores en D a X tal que la suma de las utilidades en U sea máxima. Los dominios de problemas que requieren un costo mínimo en lugar de una utilidad máxima pueden mapear los costos en utilidades negativas. Las funciones de utilidad representan restricciones suaves pero también pueden representar restricciones fuertes mediante el uso de valores negativos arbitrariamente grandes. Para este artículo solo consideramos funciones de utilidad binarias que involucran dos variables. Las funciones de utilidad de orden superior pueden ser modeladas con cambios menores en el algoritmo, pero también aumentan sustancialmente la complejidad. 2.1 Pseudárboles Tradicionales Los pseudárboles son una estructura común utilizada en procedimientos de búsqueda para permitir el procesamiento paralelo de ramas independientes. Como se define en [6], un pseudoárbol es un arreglo de un grafo G en un árbol raíz T de tal manera que los vértices en G que comparten una arista están en la misma rama en T. Una arista de retroceso es una arista entre un nodo X y cualquier nodo que se encuentre en el camino desde X hasta la raíz (excluyendo al padre de X). La Figura 1 muestra un pseudoárbol con cuatro nodos, tres aristas (A-B, B-C, BD) y una arista de retroceso (A-C). También se definen en [6] cuatro tipos de relaciones entre nodos que existen en un pseudoárbol: • P(X) - el padre de un nodo X: el único nodo más alto en el pseudoárbol que está conectado a X directamente a través de un borde de árbol • C(X) - los hijos de un nodo X: el conjunto de nodos más bajos en el pseudo Las líneas sólidas representan relaciones padre-hijo y la línea discontinua representa una relación pseudo-padre-pseudo-hijo. Figura 2: Un pseudoárbol de bordes cruzados. Las líneas sólidas representan relaciones padre-hijo, la línea discontinua representa una relación pseudo-padre-pseudo-hijo, y la línea punteada representa una relación rama-padre-rama-hijo. El nodo en negrita, B, es el punto de fusión para el nodo E. 2.2 Pseudárboles con aristas cruzadas Definimos una arista cruzada como una arista de un nodo X a un nodo Y que está por encima de X pero no en el camino desde X hasta la raíz. Un pseudoárbol de bordes cruzados es un pseudoárbol tradicional con la adición de bordes cruzados. La Figura 2 muestra un pseudoárbol con una arista cruzada (D-E). En un pseudoárbol de bordes cruzados designamos ciertos bordes como primarios. El conjunto de aristas primarias define un árbol de expansión de los nodos. Las relaciones de padre, hijo, pseudo-padre y pseudo-hijo del pseudotree tradicional ahora están definidas en el contexto de este árbol de expansión de borde primario. Esta definición también produce dos tipos adicionales de relaciones que pueden existir entre nodos: • BP(X) - los nodos padres de rama de un nodo X: el conjunto de nodos más altos en el pseudoárbol que están conectados a X pero no están en el camino principal desde X hasta la raíz (En la Figura 2, D = BP(E)) • BC(X) - los nodos hijos de rama de un nodo X: el conjunto de nodos más bajos en el pseudo La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Los algoritmos actuales suelen tener una fase de pre-ejecución para generar un pseudoárbol tradicional a partir de una instancia general de DCOP. Nuestro algoritmo DCPOP genera un pseudoárbol de bordes cruzados de la misma manera. Primero, la instancia DCOP < X, D, U > se traduce directamente en un grafo con X como el conjunto de vértices y una arista para cada par de variables representadas en U. A continuación, se utilizan varias heurísticas para organizar este grafo en un pseudoárbol. Un heurístico común es realizar una búsqueda en profundidad guiada (DFS, por sus siglas en inglés) ya que el recorrido resultante es un pseudoárbol, y un DFS se puede realizar fácilmente de manera distribuida. Definimos un método basado en el recorrido de aristas como cualquier método que produce un pseudoárbol en el que todos los pares padre/hijo comparten una arista en el grafo original. Esto incluye recorridos basados en DFS, búsqueda en anchura y búsqueda de mejor primero. Nuestras heurísticas que generan pseudobosques de bordes cruzados utilizan un recorrido de búsqueda mejor primero distribuido. 3. ALGORITMO DPOP El algoritmo DPOP original opera en tres fases principales. La primera fase genera un pseudoárbol tradicional a partir de la instancia de DCOP utilizando un algoritmo distribuido. La segunda fase une hipercubos de utilidad de los nodos hijos y el nodo local y los propaga hacia la raíz. La tercera fase elige una asignación para cada dominio de arriba hacia abajo, comenzando con el agente en el nodo raíz. La complejidad de DPOP depende del tamaño del cálculo más grande y del mensaje de utilidad durante la fase dos. Se ha demostrado que este tamaño corresponde directamente al ancho inducido del pseudoárbol generado en la fase uno [6]. DPOP utiliza heurísticas de tiempo polinómico para generar el pseudoárbol, ya que encontrar el pseudoárbol de ancho inducido mínimo es NP-duro. Se han desarrollado varias heurísticas de recorrido de borde distribuido para encontrar pseudobosques de ancho reducido [8]. Al final de la primera fase, cada agente conoce a su padre, hijos, pseudo-padres y pseudo-hijos. 3.1 Propagación de utilidad Los agentes ubicados en los nodos hoja del pseudoárbol comienzan el proceso calculando un hipercubo de utilidad local. Este hipercubo en el nodo X contiene las utilidades sumadas para cada combinación de valores en los dominios de P(X) y PP(X). Este hipercubo tiene un tamaño dimensional igual al número de pseudo-padres más uno. Un mensaje que contiene este hipercubo se envía a P(X). Los agentes ubicados en nodos no hoja esperan a que lleguen todos los mensajes de los nodos hijos. Una vez que el agente en el nodo Y tiene todos los mensajes de utilidad, calcula su hipercubo de utilidad local que incluye los dominios de P(Y), PP(Y) y Y. El hipercubo de utilidad local se une luego con todos los hipercubos de los mensajes hijos. En este punto, todas las utilidades que involucran al nodo Y son conocidas, y el dominio de Y puede ser eliminado de forma segura del hipercubo unido. Este proceso de eliminación elige la mejor utilidad sobre el dominio de Y para cada combinación de los dominios restantes. Un mensaje que contiene este hipercubo se envía ahora a P(Y). El tamaño dimensional de este hipercubo depende del número de dominios superpuestos en los mensajes recibidos y del hipercubo de utilidad local. Esta fase de propagación basada en programación dinámica continúa hasta que el agente en el nodo raíz del pseudoárbol haya recibido todos los mensajes de sus hijos. 3.2 Propagación de Valor La propagación de valor comienza cuando el agente en el nodo raíz Z ha recibido todos los mensajes de sus hijos. Dado que Z no tiene padres ni pseudo-padres, simplemente combina los hipercubos de utilidad recibidos de sus hijos. El hipercubo combinado contiene solo valores para el dominio de Z. En este punto, el agente en el nodo Z simplemente elige la asignación para su dominio que tiene la mejor utilidad. Un mensaje de propagación de valor con esta asignación se envía a cada nodo en C(Z). Cada nodo luego recibe un mensaje de propagación de valor de su padre y elige la asignación para su dominio que tenga la mejor utilidad dadas las asignaciones recibidas en el mensaje. El nodo agrega su asignación de dominio a las asignaciones que recibió y pasa el conjunto de asignaciones a sus hijos. El algoritmo está completo cuando todos los nodos han elegido una asignación para su dominio. ALGORITMO DCPOP Nuestra extensión al algoritmo DPOP original, mostrada en el Algoritmo 1, comparte las mismas tres fases. La primera fase genera el pseudoárbol de bordes cruzados para la instancia de DCOP. La segunda fase fusiona ramas y propaga los hipercubos de utilidad. La tercera fase elige asignaciones para dominios en los puntos de fusión de ramas y de arriba hacia abajo, comenzando con el agente en el nodo raíz. Para la primera fase generamos un pseudoárbol utilizando varios heurísticos distribuidos y seleccionamos el que tenga la menor complejidad general. La complejidad de la computación y el tamaño del mensaje de utilidad en DCPOP no corresponden directamente al ancho inducido del pseudoárbol de aristas cruzadas. En cambio, utilizamos un método de tiempo polinómico para calcular el tamaño máximo de computación y utilidad del mensaje para un pseudoárbol de bordes cruzados dado. Una descripción de este método y el proceso de selección de pseudodendrogramas aparece en la Sección 5. Al final de la primera fase, cada agente conoce a su padre, hijos, pseudo-padres, pseudo-hijos, padres de rama e hijos de rama. 4.1 Fusión de Ramas y Propagación de Utilidad En el algoritmo DPOP original, un nodo X solo tenía funciones de utilidad que involucraban a su padre y a sus pseudo-padres. En DCPOP, se permite que un nodo X tenga una función de utilidad que involucre a un padre de rama. El concepto de una rama se puede ver en la Figura 2 con el nodo E representando nuestro nodo X. Las dos rutas distintas desde el nodo E hasta el nodo B se llaman ramas de E. El único nodo donde se encuentran todas las ramas de E es el nodo B, que se llama punto de fusión de E. Los agentes con nodos que tienen padres de rama comienzan enviando un mensaje de propagación de utilidad a cada padre de rama. Este mensaje incluye un hipercubo de utilidad bidimensional con dominios para el nodo X y el nodo padre de la rama BP(X). También incluye una estructura de información de rama que contiene el nodo de origen de la rama, X, el número total de ramas que se originan en X y el número de ramas que se originan en X y se fusionan en una representación única por esta estructura de información de rama (este número comienza en 1). Intuitivamente, cuando el número de ramas fusionadas es igual al número total de ramas originales, el algoritmo ha alcanzado el punto de fusión para X. En la Figura 2, el nodo E envía un mensaje de propagación de utilidad a su nodo padre de rama, el nodo D. Este mensaje tiene dimensiones para los dominios de E y D, e incluye información de rama con un origen en E, 2 ramas totales y 1 rama fusionada. Como en la fase de propagación de utilidad de la utilidad DPOP original, un agente en el nodo hoja X envía un mensaje de propagación de utilidad a su padre. En DCPOP, este mensaje contiene dimensiones para los dominios de P(X) y PP(X). Si el nodo X también tiene padres de rama, entonces el mensaje de propagación de utilidad también contiene una dimensión para el dominio de X e incluirá una estructura de información de rama. En la Figura 2, el nodo E envía un mensaje de propagación de utilidad a su padre, el nodo C. Este mensaje tiene dimensiones para los dominios de E y C, e incluye información de rama con un origen en E, 2 ramas en total y 1 rama fusionada. Cuando un nodo Y recibe mensajes de propagación de utilidad de todos de The Sixth Intl. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), 743 sus hijos y sus hijos de rama, fusiona cualquier rama con el mismo nodo de origen X. La estructura de información de la rama fusionada acumula el número de ramas fusionadas para X. Si el número total acumulado de ramas fusionadas es igual al número total de ramas, entonces Y es el punto de fusión para X. Esto significa que los hipercubos de utilidad presentes en Y contienen toda la información sobre las valoraciones de las funciones de utilidad que involucran al nodo X. Además de la eliminación típica del dominio de Y de los hipercubos de utilidad, ahora podemos eliminar de forma segura el dominio de X de los hipercubos de utilidad. Para ilustrar este proceso, examinaremos lo que sucede en la segunda fase para el nodo B en la Figura 2. En la segunda fase, el Nodo B recibe dos mensajes de propagación de utilidad. El primero proviene del nodo C e incluye dimensiones para los dominios E, B y A. También tiene una estructura de información de ramas con origen en E, 2 ramas en total y 1 rama fusionada. El segundo proviene del nodo D e incluye dimensiones para los dominios E y B. También tiene una estructura de información de rama con origen en E, 2 ramas en total y 1 rama fusionada. El nodo B luego fusiona las estructuras de información de rama de ambos mensajes porque tienen la misma procedencia, el nodo E. Dado que el número de ramas fusionadas que provienen de E es ahora 2 y el total de ramas que provienen de E es 2, el nodo B elimina las dimensiones para el dominio E. El nodo B también elimina la dimensión para su propio dominio, dejando solo información sobre el dominio A. Luego, el nodo B envía un mensaje de propagación de utilidad al nodo A, que contiene solo una dimensión para el dominio de A. Aunque no sea posible en DPOP, este método de propagación de utilidad y eliminación de dimensiones puede producir hipercubos en el nodo Y que no comparten ningún dominio. En DCPOP no unimos hipercubos independientes de dominio, sino que en su lugar podemos enviar múltiples hipercubos en el mensaje de propagación de utilidad enviado al padre de Y. Este enfoque perezoso de las uniones ayuda a reducir el tamaño de los mensajes. 4.2 Propagación de valores Al igual que en DPOP, la propagación de valores comienza cuando el agente en el nodo raíz Z ha recibido todos los mensajes de sus hijos. En este punto, el agente en el nodo Z elige la asignación para su dominio que tiene la mejor utilidad. Si Z es el punto de fusión de las ramas de algún nodo X, Z también elegirá la asignación para el dominio de X. Por lo tanto, cualquier nodo que sea un punto de fusión elegirá asignaciones para un dominio que no sea el suyo propio. Estas tareas luego se pasan por la jerarquía de la cadena de mando principal. Si el nodo X en la jerarquía tiene padres de rama, entonces el mensaje de asignación de valor de P(X) contendrá una asignación para el dominio de X. Cada nodo en la jerarquía agrega cualquier tarea que haya elegido a las que recibió y pasa el conjunto de tareas a sus hijos. El algoritmo está completo cuando todos los nodos han elegido o recibido una asignación para su dominio. 4.3 Prueba de Corrección Demostraremos la corrección de DCPOP notando primero que DCPOP extiende completamente DPOP y luego examinando los dos casos para la asignación de valores en DCPOP. Dado un pseudoárbol tradicional como entrada, la ejecución del algoritmo DCPOP es idéntica a DPOP. Usando un arreglo de pseudodendrograma tradicional, ningún nodo tiene padres de rama o hijos de rama, ya que todas las aristas son aristas de retroceso o aristas de árbol. Por lo tanto, el algoritmo DCPOP utilizando un pseudoárbol tradicional envía solo mensajes de propagación de utilidad que contienen dominios pertenecientes al padre o pseudo-padres de un nodo. Dado que ningún nodo tiene ramas-padres, no existen ramas, y por lo tanto ningún nodo sirve como punto de fusión para ningún otro nodo. Por lo tanto, todas las asignaciones de propagación de valor se eligen en el nodo del dominio de la asignación. Para la ejecución de DCPOP con pseudárboles de bordes cruzados, algunos nodos actúan como puntos de fusión. Observamos que cualquier nodo X que no sea un punto de fusión asigna su valor exactamente como en DPOP. El hipercubo de utilidad local en X contiene dominios para X, P(X), PP(X) y BC(X). Como en DPOP, el mensaje de asignación de valores recibido en X incluye los valores asignados a P(X) y PP(X). Además, dado que X no es un punto de fusión, todas las asignaciones a BC(X) deben haber sido calculadas en puntos de fusión más altos en el árbol y están en el mensaje de asignación de valor de P(X). Por lo tanto, después de eliminar los dominios para los cuales se conocen las asignaciones, solo queda el dominio de X. El agente en el nodo X ahora puede elegir correctamente la asignación con la máxima utilidad para su propio dominio. Si el nodo X es un punto de fusión para alguna rama-hijo Y, sabemos que X debe ser un nodo a lo largo del camino desde Y hasta la raíz, y desde P(Y) y todos los BP(Y) hasta la raíz. A partir del algoritmo, sabemos que Y necesariamente tiene toda la información de C(Y), PC(Y) y BC(Y) ya que espera sus mensajes. El nodo X tiene información sobre todos los nodos debajo de él en el árbol, lo cual incluiría a Y, P(Y), BP(Y) y aquellos PP(Y) que están debajo de X en el árbol. Para cualquier PP(Y) por encima de X en el árbol, X recibe la asignación para el dominio de PP(Y) en el mensaje de asignación de valor de P(X). Por lo tanto, X tiene información de utilidad sobre todas las funciones de utilidad de las cuales Y forma parte. Al eliminar los dominios incluidos en el mensaje de asignación de valor, el nodo X se queda con un hipercubo de utilidad local con dominios para X e Y. El agente en el nodo X ahora puede elegir correctamente las asignaciones con la máxima utilidad para los dominios de X e Y. 4.4 Análisis de complejidad La primera fase de DCPOP envía un mensaje a cada P(X), PP(X) y BP(X). La segunda fase envía un mensaje de asignación de valor a cada C(X). Por lo tanto, DCPOP produce un número lineal de mensajes con respecto al número de aristas (funciones de utilidad) en el pseudoárbol de aristas cruzadas y la instancia original de DCOP. La complejidad real de DCPOP depende de dos medidas adicionales: el tamaño del mensaje y el tamaño de la computación. El tamaño del mensaje y el tamaño de la computación en DCPOP dependen del número de ramas superpuestas, así como del número de aristas de retroceso superpuestas. Se demostró en [6] que el número de aristas traslapadas es igual al ancho inducido del pseudoárbol. En un pseudoárbol de bordes cruzados mal construido, el número de ramas superpuestas en el nodo X puede ser tan grande como el número total de descendientes de X. Por lo tanto, el tamaño total del mensaje en DCPOP en una instancia mal construida puede ser exponencial en el espacio en el número total de nodos en el grafo. Sin embargo, en la práctica, un pseudoárbol bien construido con bordes cruzados puede lograr resultados mucho mejores. Más tarde abordaremos el tema de elegir pseudobosques cruzados bien construidos de un conjunto. Introducimos una medida adicional del costo máximo de la ruta secuencial a través del algoritmo. Esta medida se relaciona directamente con la cantidad máxima de paralelismo que puede lograr el algoritmo. Para tomar esta medida, primero almacenamos el tamaño total de cálculo para cada nodo durante las fases dos y tres. Este tamaño de cálculo representa el número de accesos individuales a un valor en un hipercubo en cada nodo. Por ejemplo, una unión entre dos dominios de tamaño 4 cuesta 4 ∗ 4 = 16. Dos grafos acíclicos dirigidos (DAG) pueden ser dibujados; uno con los mensajes de propagación de utilidad como aristas y los costos de la fase dos en los nodos, y el otro con los mensajes de asignación de valor y los costos de la fase tres en los nodos. El costo máximo del camino secuencial es igual a la suma del camino más largo en cada DAG desde la raíz hasta cualquier nodo hoja. HEURÍSTICAS En nuestra evaluación de la complejidad en DCPOP nos enfocamos en el peor caso posiblemente producido por el algoritmo. Reconocemos 744 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Algoritmo 1 DCPOP Algoritmo 1: DCPOP(X; D; U) Cada agente Xi ejecuta: Fase 1: creación de pseudotree 2: elegir líder de todos los Xj ∈ X 3: líder elegido inicia la creación de pseudotree 4: después, Xi conoce P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) y PC(Xi) Fase 2: propagación de mensajes UTIL 5: si |BP(Xi)| > 0 entonces 6: BRANCHXi ← |BP(Xi)| + 1 7: para todos Xk ∈BP(Xi) hacer 8: UTILXi (Xk) ← Calcular utils(Xi, Xk) 9: Enviar mensaje(Xk,UTILXi (Xk),BRANCHXi ) 10: si |C(Xi)| = 0 (es decir, Si Xi es un nodo hoja, entonces 11: UTILXi (P(Xi)) ← Calcular utils(P(Xi),PP(Xi)) para todos los PP(Xi) 12: Enviar mensaje(P(Xi), UTILXi (P(Xi)), BRANCHXi ) 13: Enviar mensaje(PP(Xi), UTIL vacío, BRANCH vacío) a todos los PP(Xi) 14: Activar el manejador de mensajes UTIL() Fase 3: Propagación de mensajes de VALOR 15: Activar el manejador de mensajes de VALOR() FIN ALGORITMO Manejador de mensajes UTIL(Xk, UTILXk (Xi), BRANCHXk ) 16: Almacenar UTILXk (Xi), BRANCHXk (Xi) 17: Si han llegado mensajes UTIL de todos los hijos y los hijos de la rama, entonces 18: Para todos los Bj ∈ BRANCH(Xi) hacer 19: Si Bj está fusionado, entonces 20: Unir todos los hipercubos donde Bj ∈ UTIL(Xi) 21: Eliminar Bj del hipercubo unido 22: Si P(Xi) == nulo (eso significa que Xi es la raíz) entonces 23: v ∗ i ← Elegir óptimo(nulo) 24: Enviar VALOR(Xi, v ∗ i) a todos los C(Xi) 25: De lo contrario 26: UTILXi (P(Xi)) ← Calcular utils(P(Xi), PP(Xi)) 27: Enviar mensaje(P(Xi), UTILXi (P(Xi)), BRANCHXi (P(Xi))) Manejador de mensajes de VALOR(VALORXi , P(Xi)) 28: Agregar todos los Xk ← v ∗ k ∈ VALORXi , P(Xi) a la vista del agente 29: Xi ← v ∗ i = Elegir óptimo(vista del agente) 30: Enviar VALORXl , Xi a todos los Xl ∈ C(Xi) que en problemas del mundo real la generación del pseudoárbol tiene un impacto significativo en el rendimiento real. El problema de encontrar la mejor pseudotree para una instancia de DCOP dada es NP-Difícil. Por lo tanto, se utiliza una heurística para la generación, y el rendimiento del algoritmo depende del pseudoárbol encontrado por la heurística. Algunas investigaciones previas se centraron en encontrar heurísticas para generar buenas pseudorboles [8]. Si bien hemos desarrollado algunas heurísticas que generan buenos pseudoárboles cruzados para usar con DCPOP, nuestro enfoque ha sido utilizar múltiples heurísticas y luego seleccionar el mejor pseudo Consideramos solo heurísticas que se ejecuten en tiempo polinómico con respecto al número de nodos en la instancia original del DCOP. El algoritmo DCPOP actual tiene una complejidad exponencial en el peor de los casos, pero podemos calcular el tamaño máximo del mensaje, el tamaño de la computación y el costo de la ruta secuencial para un pseudoárbol de bordes cruzados dado en complejidad espacio-temporal lineal. Para hacer esto, simplemente ejecutamos el algoritmo sin intentar calcular ninguno de los hipercubos de utilidad local o asignaciones de valor óptimo. En cambio, los mensajes incluyen información dimensional y de ramificación pero no hipercubos de utilidad. Después de que cada heurística complete la generación de un pseudoárbol, ejecutamos el procedimiento de medición y propagamos la información de la medición hasta la raíz elegida en ese pseudo La raíz luego transmite la complejidad total de esa heurística a todos los nodos. Después de que todas las heurísticas hayan tenido la oportunidad de completarse, cada nodo sabe qué heurística produjo el mejor pseudoárbol. Cada nodo luego procede a comenzar el algoritmo DCPOP utilizando su conocimiento del pseudoárbol generado por la mejor heurística. Las heurísticas utilizadas para generar pseudárboles tradicionales realizan un recorrido DFS distribuido. El algoritmo distribuido general utiliza un mecanismo de paso de token y un número lineal de mensajes. Las heurísticas mejoradas basadas en DFS utilizan un procedimiento especial para elegir el nodo raíz, y también proporcionan una función de ordenación sobre los vecinos de un nodo para determinar el orden de la recursión de caminos. Las heurísticas basadas en DFS utilizadas en nuestros experimentos provienen del trabajo realizado en [4, 8]. 5.1 La heurística de pseudotree cruzado de mejor primer recorrido. Las heurísticas utilizadas para generar pseudárboles cruzados realizan un recorrido de mejor primer recorrido. Se presenta un algoritmo general distribuido de mejor primero para la expansión de nodos en el Algoritmo 2. Una función de evaluación en cada nodo proporciona los valores que se utilizan para determinar el siguiente mejor nodo a expandir. Ten en cuenta que en este algoritmo cada nodo solo intercambia su mejor valor con sus vecinos. En nuestros experimentos utilizamos varias funciones de evaluación que tomaban como argumentos una lista ordenada de ancestros y un nodo, que contiene una lista de vecinos (con la profundidad de colocación de cada vecino en el árbol). A partir de estos podemos calcular los padres de la rama, los hijos de la rama y las relaciones desconocidas para una posible ubicación del nodo. La mejor función general calculó el valor como ancestros - (padres de rama + hijos de rama) con el número de relaciones desconocidas como criterio de desempate. Después de completarse, cada nodo tiene conocimiento de su padre y ancestros, por lo que puede determinar fácilmente qué nodos conectados son pseudo-padres, padres de rama, pseudo-hijos e hijos de rama. La complejidad de la travesía de mejor primero depende de la complejidad de la función de evaluación. Suponiendo una complejidad de O(V) para la función de evaluación, que es el caso de nuestra mejor función general, el recorrido de mejor primero es O(V · E), lo que en el peor de los casos es O(n3). Para cada v ∈ V realizamos una operación de colocación y encontramos el siguiente nodo a colocar usando la operación getBestNeighbor. La complejidad de la operación del lugar es a lo sumo O(V) debido a los mensajes enviados. Encontrar el siguiente nodo utiliza recursión y recorre solo los ya colocados The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 745 Algoritmo 2 Algoritmo de Búsqueda Distribuida de Mejor Primero root ← líder elegido next(root, ∅) place(nodo, padre) nodo.padre ← padre nodo.ancestros ← padre.ancestros ∪ padre enviar mensaje de ubicación (nodo, nodo.ancestros) a todos los vecinos de nodo next(actual, anterior) si actual no está ubicado entonces place(actual, anterior) next(actual, ∅) else mejor ← obtenerMejorVecino(actual, anterior) si mejor = ∅ entonces si anterior = ∅ entonces terminar, todos los nodos están ubicados next(anterior, ∅) else next(mejor, actual) obtenerMejorVecino(actual, anterior) mejor ← ∅; puntaje ← 0 para todo n ∈ vecinos de actual hacer si n! = anterior entonces si n está ubicado entonces puntajeN ← obtenerMejorVecino(n, actual) else puntajeN ← evaluar(actual, n) si puntajeN > puntaje entonces puntaje ← puntajeN mejor ← n return mejor, puntaje nodos, por lo que tiene O(V) recursiones. Cada recursión realiza una operación recursiva getBestNeighbor que recorre todos los nodos colocados y sus vecinos. Esta operación es O(V · E), pero los resultados se pueden almacenar en caché utilizando solo O(V) espacio en cada nodo. Así que tenemos O(V ·(V +V +V ·E)) = O(V 2 ·E). Si somos inteligentes al evaluar los cambios locales cuando cada nodo recibe mensajes de ubicación de sus vecinos y almacenamos en caché los resultados, la operación getBestNeighbor es solo O(E). Esto aumenta la complejidad de la operación de ubicación, pero para todas las ubicaciones la complejidad total es solo O(V · E). Por lo tanto, tenemos una complejidad general de O(V ·E+V ·(V +E)) = O(V ·E). 6. COMPARACIÓN DE COMPLEJIDAD EN DPOP Y DCPOP Ya hemos demostrado que, dado el mismo input, DCPOP se desempeña igual que DPOP. También hemos demostrado que podemos predecir con precisión el rendimiento de un pseudoárbol dado en complejidad temporal lineal. Si usamos un número constante de heurísticas para generar el conjunto de pseudobosques, podemos elegir el mejor pseudobosque con complejidad lineal en espacio y tiempo. Ahora demostraremos que existe una instancia de DCOP para la cual un pseudoárbol de bordes cruzados supera a todos los posibles pseudoárboles tradicionales (basados en heurísticas de recorrido de bordes). En la Figura 3(a) tenemos una instancia de DCOP con seis nodos. Este es un grafo bipartito con cada partición completamente conectada a la otra (a) (b) (c) Figura 3: (a) La instancia de DCOP (b) Un arreglo de pseudobosque tradicional para la instancia de DCOP (c) Un arreglo de pseudobosque con aristas cruzadas para la partición de la instancia de DCOP. En la Figura 3(b) vemos un arreglo tradicional de pseudotree para esta instancia de DCOP. Es fácil ver que cualquier heurística basada en el recorrido de aristas no puede expandir dos nodos de la misma partición sucesivamente. También observamos que ningún nodo puede tener más de un hijo porque cualquier disposición de este tipo sería un pseudoárbol inválido. Por lo tanto, cualquier disposición tradicional de pseudodendrograma para esta instancia de DCOP debe tener la forma de la Figura 3(b). Podemos ver que las aristas de retroceso F-B y F-A se superponen al nodo C. El nodo C también tiene un padre E y una arista de retroceso con D. Utilizando el algoritmo DPOP original (o DCPOP ya que son idénticos en este caso), encontramos que el cálculo en el nodo C implica cinco dominios: A, B, C, D y E. En contraste, el arreglo de pseudonodos con aristas cruzadas en la Figura 3(c) requiere un máximo de cuatro dominios en cualquier cálculo durante DCPOP. Dado que el nodo A es el punto de fusión de las ramas tanto de B como de C, podemos ver que cada uno de los nodos D, E y F tiene dos ramas superpuestas. Además, cada uno de estos nodos tiene al nodo A como su padre. Usando el algoritmo DCPOP, encontramos que el cálculo en el nodo D (o E o F) implica cuatro dominios: A, B, C y D (o E o F). Dado que no se puede crear una disposición de pseudobosque tradicional mejor utilizando una heurística de recorrido de aristas, hemos demostrado que DCPOP puede superar a DPOP incluso si utilizamos el pseudobosque óptimo encontrado a través del recorrido de aristas. Reconocemos que los arreglos de pseudodistribución de árboles que permiten relaciones padre-hijo sin una restricción real pueden resolver el problema en la Figura 3(a) con un tamaño de cálculo máximo de cuatro dominios. Sin embargo, las heurísticas actuales utilizadas con DPOP no producen tales pseudobosques, y sería difícil distribuir una heurística así, ya que cada nodo requeriría información sobre nodos con los que no tiene restricciones. Además, aunque no lo demostramos aquí, los pseudobosques de bordes cruzados pueden producir tamaños de mensaje más pequeños que tales pseudobosques, incluso si el tamaño de la computación es similar. En la práctica, dado que encontrar la mejor disposición de pseudoramas es NP-Difícil, observamos que las heurísticas que producen pseudoramas con aristas cruzadas a menudo generan tamaños de cálculo y mensajes significativamente más pequeños. 7. RESULTADOS EXPERIMENTALES 746 El Sexto Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Los métricos de rendimiento existentes para algoritmos DCOP incluyen el número total de mensajes, ciclos de reloj síncronos y tamaño de mensaje. Ya hemos demostrado que el número total de mensajes es lineal con respecto al número de restricciones en la instancia de DCOP. También introdujimos el costo de camino secuencial máximo (PC) como una medida de la máxima cantidad de paralelismo alcanzable por el algoritmo. El costo máximo de la ruta secuencial es igual a la suma de los cálculos realizados en la ruta más larga desde la raíz hasta cualquier nodo hoja. También incluimos como métricas el tamaño máximo de cálculo en número de dimensiones (CD) y el tamaño máximo de mensaje en número de dimensiones (MD). Para analizar la complejidad relativa de una instancia DCOP dada, encontramos el ancho inducido mínimo (IW) de cualquier pseudobosque tradicional producido por una heurística para el DPOP original. 7.1 Instancias genéricas de DCOP Para nuestras pruebas iniciales generamos aleatoriamente dos conjuntos de problemas con 3000 casos en cada uno. Cada problema fue generado asignando un número aleatorio (elegido de un rango) de restricciones a cada variable. El generador luego creó restricciones binarias hasta que cada variable alcanzó su número máximo de restricciones. El primer conjunto utiliza 20 variables, y el mejor DPOP IW varía de 1 a 16 con un promedio de 8.5. El segundo conjunto utiliza 100 variables, y el mejor DPOP IW osciló entre 2 y 68 con un promedio de 39.3. Dado que la mayoría de los problemas en el segundo conjunto eran demasiado complejos para calcular la solución, tomamos medidas de las métricas utilizando las técnicas descritas anteriormente en la Sección 5 sin resolver realmente el problema. Los resultados se muestran para el primer conjunto en la Tabla 1 y para el segundo conjunto en la Tabla 2. Para los dos conjuntos de problemas dividimos los casos en categorías de baja densidad y alta densidad. Los casos de baja densidad consisten en aquellos problemas que tienen un mejor DPOP IW menor o igual a la mitad del número total de nodos (por ejemplo, IW ≤ 10 para los problemas de 20 nodos e IW ≤ 50 para los problemas de 100 nodos. Los problemas de alta densidad consisten en el resto de los conjuntos de problemas. En ambas Tabla 1 y Tabla 2 hemos enumerado las métricas de rendimiento para el algoritmo DPOP original, el algoritmo DCPOP utilizando solo pseudobosques de bordes cruzados (DCPOP-CE), y el algoritmo DCPOP utilizando pseudobosques tradicionales y de bordes cruzados (DCPOP-All). Los pseudobosques utilizados para DPOP fueron generados utilizando 5 heurísticas: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB y DFS MCN BEC. Estas son todas las versiones del recorrido DFS guiado discutidas en la Sección 5. Los pseudobosques de bordes cruzados utilizados para DCPOP-CE fueron generados utilizando 5 heurísticas: MCN, LCN, MCN A-B, LCN A-B y LCSG A-B. Estas son todas las versiones del recorrido de mejor primero discutidas en la Sección 5. Para tanto DPOP como DCPOP-CE elegimos el mejor pseudoárbol producido por sus respectivas 5 heurísticas para cada problema en el conjunto. Para DCPOP-All elegimos la mejor pseudotree producida por las 10 heurísticas para cada problema en el conjunto. Para las métricas de CD y MD, el valor mostrado es el número promedio de dimensiones. Para la métrica de PC, el valor mostrado es el logaritmo natural del costo de ruta secuencial máximo (ya que el valor real crece exponencialmente con la complejidad del problema). La última fila en ambas tablas es una medida de mejora de DCPOP-All sobre DPOP. Para las métricas CD y MD, el valor mostrado es una reducción en el número de dimensiones. Para la métrica de PC, el valor mostrado es una reducción porcentual en el costo máximo de la ruta secuencial (% = DP OP −DCP OP DCP OP ∗ 100). Observa que DCPOP supera a DPOP en todas las métricas. Esto se sigue lógicamente de nuestra afirmación anterior de que, dada la misma entrada, DCPOP se comporta exactamente igual que DPOP. Así, dada la elección entre los pseudobosques producidos por las 10 heurísticas, DCPOP-All siempre superará a DCPOP-CE y DPOP. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 6: Mejora del Costo del Camino DCPOP Reunión Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Tabla 3: Problemas de Programación de Reuniones realizan DPOP. Otra tendencia que observamos es que la mejora es mayor para problemas de alta densidad que para problemas de baja densidad. Mostramos esta tendencia con mayor detalle en las Figuras 4, 5 y 6. Observa cómo la mejora aumenta a medida que aumenta la complejidad del problema. 7.2 Problema de Programación de Reuniones Además de nuestras pruebas genéricas iniciales de DCOP, realizamos una serie de pruebas en el Problema de Programación de Reuniones (MSP) como se describe en [6]. La configuración del problema incluye un número de personas agrupadas en departamentos. Cada persona debe asistir a un número específico de reuniones. Las reuniones pueden llevarse a cabo dentro de los departamentos o entre departamentos, y pueden asignarse a uno de los ocho horarios disponibles. El MSP se mapea a una instancia de DCOP donde cada variable representa el intervalo de tiempo en el que una persona específica asistirá a una reunión específica. Todas las variables que pertenecen a la misma persona tienen restricciones de exclusión mutua para que la persona no pueda asistir a más de una reunión durante el mismo intervalo de tiempo. Todas las variables que pertenecen a la misma reunión tienen restricciones de igualdad para que todos los participantes elijan el mismo horario. Se imponen restricciones unarias en cada variable para tener en cuenta la valoración de una persona de cada reunión y franja horaria. Para nuestros tests generamos 100 problemas de muestra para cada combinación de agentes y reuniones. Los resultados se muestran en la Tabla 3. Los valores en las primeras cinco columnas representan (en orden de izquierda a derecha), el número total de agentes, el número total de reuniones, el número total de variables, el promedio total de restricciones y el promedio mínimo de IW producido por un pseudoárbol tradicional. Las últimas tres columnas muestran las mismas métricas que utilizamos para las instancias genéricas de DCOP, excepto que esta vez solo mostramos las mejoras de DCPOP-All sobre DPOP. El rendimiento es mejor en promedio para todas las instancias de MSP, pero nuevamente vemos mejoras más grandes para instancias de problemas más complejos. 8. CONCLUSIONES Y TRABAJO FUTURO Presentamos un algoritmo completo y distribuido que resuelve instancias generales de DCOP utilizando arreglos de pseudoramas cruzados. Nuestro algoritmo extiende el algoritmo DPOP al agregar mensajes adicionales de propagación de utilidad e introducir el concepto de fusión de ramas durante la fase de propagación de utilidad. Nuestro algoritmo también permite que las asignaciones de valor ocurran en puntos de fusión de nivel superior para nodos de nivel inferior. Hemos demostrado que DCPOP extiende completamente DPOP al realizar las mismas operaciones dadas las mismas entradas. También hemos demostrado a través de algunos ejemplos y datos experimentales que DCPOP puede lograr un mejor rendimiento para algunas instancias del problema al extender el conjunto de entrada permitido para incluir pseudobosques cruzados. Damos especial énfasis al papel que desempeñan las heurísticas de recorrido de bordes en la generación de pseudobosques. Hemos demostrado que la penalización en el rendimiento es mínima para generar múltiples heurísticas, y que podemos elegir el mejor pseudoárbol generado en complejidad lineal de espacio-tiempo. Dada la importancia de un buen pseudoárbol para el rendimiento, el trabajo futuro incluirá nuevas heurísticas para encontrar mejores pseudo El trabajo futuro también incluirá adaptar las extensiones existentes de DPOP [5, 7] que soportan diferentes dominios de problemas para su uso con DCPOP. 9. REFERENCIAS [1] J. Liu y K. P. Sycara. Explotando la estructura del problema para la optimización distribuida de restricciones. En V. Lesser, editor, Actas de la Primera Conferencia Internacional sobre Sistemas Multiagente, páginas 246-254, San Francisco, CA, 1995. MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, y S. Kulkarni. Un enfoque dinámico distribuido de satisfacción de restricciones para la asignación de recursos. Notas de conferencia en Ciencias de la Computación, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe y M. Yokoo. Un método completo asíncrono para la optimización de restricciones distribuidas. En AAMAS 03, 2003. [4] A. Petcu. Frodo: Un marco para la optimización de restricciones abiertas/distribuidas. Informe técnico No. 2006/001, Instituto Federal Suizo de Tecnología (EPFL), Lausana (Suiza), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu y B. Faltings. A-dpop: Aproximaciones en optimización distribuida. En póster en CP 2005, páginas 802-806, Sitges, España, octubre de 2005. [6] A. Petcu y B. Faltings. Dpop: Un método escalable para la optimización de restricciones multiagente. En IJCAI 05, páginas 266-271, Edimburgo, Escocia, agosto de 2005. [7] A. Petcu, B. Faltings y D. Parkes. M-dpop: Implementación distribuida fiel de problemas eficientes de elección social. En AAMAS 06, páginas 1397-1404, Hakodate, Japón, mayo de 2006. [8] G. Ushakov. Resolviendo problemas de programación de reuniones utilizando un procedimiento de optimización distribuido de pseudobosque. Tesis de maestría, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida y K. Kuwabara. Satisfacción de restricciones distribuida para formalizar la resolución de problemas distribuidos. En la Conferencia Internacional sobre Sistemas de Computación Distribuida, páginas 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida y K. Kuwabara. El problema de satisfacción de restricciones distribuidas: Formalización y algoritmos. Ingeniería del Conocimiento y de Datos, 10(5):673-685, 1998. 748 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "global utility": {
            "translated_key": "utilidad global",
            "is_in_text": true,
            "original_annotated_sentences": [
                "A Complete Distributed Constraint Optimization Method For Non-Traditional Pseudotree Arrangements∗ James Atlas Computer and Information Sciences University of Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Computer and Information Sciences University of Delaware Newark, DE 19716 decker@cis.udel.edu ABSTRACT Distributed Constraint Optimization (DCOP) is a general framework that can model complex problems in multi-agent systems.",
                "Several current algorithms that solve general DCOP instances, including ADOPT and DPOP, arrange agents into a traditional pseudotree structure.",
                "We introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements.",
                "Our algorithm correctly solves DCOP instances for pseudotrees that include edges between nodes in separate branches.",
                "The algorithm also solves instances with traditional pseudotree arrangements using the same procedure as DPOP.",
                "We compare our algorithm with DPOP using several metrics including the induced width of the pseudotrees, the maximum dimensionality of messages and computation, and the maximum sequential path cost through the algorithm.",
                "We prove that for some problem instances it is not possible to generate a traditional pseudotree using edge-traversal heuristics that will outperform a cross-edged pseudotree.",
                "We use multiple heuristics to generate pseudotrees and choose the best pseudotree in linear space-time complexity.",
                "For some problem instances we observe significant improvements in message and computation sizes compared to DPOP.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent Systems General Terms Algorithms 1.",
                "INTRODUCTION Many historical problems in the AI community can be transformed into Constraint Satisfaction Problems (CSP).",
                "With the advent of distributed AI, multi-agent systems became a popular way to model the complex interactions and coordination required to solve distributed problems.",
                "CSPs were originally extended to distributed agent environments in [9].",
                "Early domains for distributed constraint satisfaction problems (DisCSP) included job shop scheduling [1] and resource allocation [2].",
                "Many domains for agent systems, especially teamwork coordination, distributed scheduling, and sensor networks, involve overly constrained problems that are difficult or impossible to satisfy for every constraint.",
                "Recent approaches to solving problems in these domains rely on optimization techniques that map constraints into multi-valued utility functions.",
                "Instead of finding an assignment that satisfies all constraints, these approaches find an assignment that produces a high level of <br>global utility</br>.",
                "This extension to the original DisCSP approach has become popular in multi-agent systems, and has been labeled the Distributed Constraint Optimization Problem (DCOP) [1].",
                "Current algorithms that solve complete DCOPs use two main approaches: search and dynamic programming.",
                "Search based algorithms that originated from DisCSP typically use some form of backtracking [10] or bounds propagation, as in ADOPT [3].",
                "Dynamic programming based algorithms include DPOP and its extensions [5, 6, 7].",
                "To date, both categories of algorithms arrange agents into a traditional pseudotree to solve the problem.",
                "It has been shown in [6] that any constraint graph can be mapped into a traditional pseudotree.",
                "However, it was also shown that finding the optimal pseudotree was NP-Hard.",
                "We began to investigate the performance of traditional pseudotrees generated by current edge-traversal heuristics.",
                "We found that these heuristics often produced little parallelism as the pseudotrees tended to have high depth and low branching factors.",
                "We suspected that there could be other ways to arrange the pseudotrees that would provide increased parallelism and smaller message sizes.",
                "After exploring these other arrangements we found that cross-edged pseudotrees provide shorter depths and higher branching factors than the traditional pseudotrees.",
                "Our hypothesis was that these crossedged pseudotrees would outperform traditional pseudotrees for some problem types.",
                "In this paper we introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements which include cross-edged pseudotrees.",
                "We begin with a definition of 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, traditional pseudotrees, and cross-edged pseudotrees.",
                "We then provide a summary of the original DPOP algorithm and introduce our DCPOP algorithm.",
                "We discuss the complexity of our algorithm as well as the impact of pseudotree generation heuristics.",
                "We then show that our Distributed Cross-edged Pseudotree Optimization Procedure (DCPOP) performs significantly better in practice than the original DPOP algorithm for some problem instances.",
                "We conclude with a selection of ideas for future work and extensions for DCPOP. 2.",
                "PROBLEM DEFINITION DCOP has been formalized in slightly different ways in recent literature, so we will adopt the definition as presented in [6].",
                "A Distributed Constraint Optimization Problem with n nodes and m constraints consists of the tuple < X, D, U > where: • X = {x1,..,xn} is a set of variables, each one assigned to a unique agent • D = {d1,..,dn} is a set of finite domains for each variable • U = {u1,..,um} is a set of utility functions such that each function involves a subset of variables in X and defines a utility for each combination of values among these variables An optimal solution to a DCOP instance consists of an assignment of values in D to X such that the sum of utilities in U is maximal.",
                "Problem domains that require minimum cost instead of maximum utility can map costs into negative utilities.",
                "The utility functions represent soft constraints but can also represent hard constraints by using arbitrarily large negative values.",
                "For this paper we only consider binary utility functions involving two variables.",
                "Higher order utility functions can be modeled with minor changes to the algorithm, but they also substantially increase the complexity. 2.1 Traditional Pseudotrees Pseudotrees are a common structure used in search procedures to allow parallel processing of independent branches.",
                "As defined in [6], a pseudotree is an arrangement of a graph G into a rooted tree T such that vertices in G that share an edge are in the same branch in T. A back-edge is an edge between a node X and any node which lies on the path from X to the root (excluding Xs parent).",
                "Figure 1 shows a pseudotree with four nodes, three edges (A-B, B-C, BD), and one back-edge (A-C).",
                "Also defined in [6] are four types of relationships between nodes exist in a pseudotree: • P(X) - the parent of a node X: the single node higher in the pseudotree that is connected to X directly through a tree edge • C(X) - the children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through tree edges • PP(X) - the pseudo-parents of a node X: the set of nodes higher in the pseudotree that are connected to X directly through back-edges (In Figure 1, A = PP(C)) • PC(X) - the pseudo-children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through back-edges (In Figure 1, C = PC(A)) Figure 1: A traditional pseudotree.",
                "Solid line edges represent parent-child relationships and the dashed line represents a pseudo-parent-pseudo-child relationship.",
                "Figure 2: A cross-edged pseudotree.",
                "Solid line edges represent parent-child relationships, the dashed line represents a pseudoparent-pseudo-child relationship, and the dotted line represents a branch-parent-branch-child relationship.",
                "The bolded node, B, is the merge point for node E. 2.2 Cross-edged Pseudotrees We define a cross-edge as an edge from node X to a node Y that is above X but not in the path from X to the root.",
                "A cross-edged pseudotree is a traditional pseudotree with the addition of cross-edges.",
                "Figure 2 shows a cross-edged pseudotree with a cross-edge (D-E).",
                "In a cross-edged pseudotree we designate certain edges as primary.",
                "The set of primary edges defines a spanning tree of the nodes.",
                "The parent, child, pseudo-parent, and pseudo-child relationships from the traditional pseudotree are now defined in the context of this primary edge spanning tree.",
                "This definition also yields two additional types of relationships that may exist between nodes: • BP(X) - the branch-parents of a node X: the set of nodes higher in the pseudotree that are connected to X but are not in the primary path from X to the root (In Figure 2, D = BP(E)) • BC(X) - the branch-children of a node X: the set of nodes lower in the pseudotree that are connected to X but are not in any primary path from X to any leaf node (In Figure 2, E = BC(D)) 2.3 Pseudotree Generation 742 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Current algorithms usually have a pre-execution phase to generate a traditional pseudotree from a general DCOP instance.",
                "Our DCPOP algorithm generates a cross-edged pseudotree in the same fashion.",
                "First, the DCOP instance < X, D, U > translates directly into a graph with X as the set of vertices and an edge for each pair of variables represented in U.",
                "Next, various heuristics are used to arrange this graph into a pseudotree.",
                "One common heuristic is to perform a guided depth-first search (DFS) as the resulting traversal is a pseudotree, and a DFS can easily be performed in a distributed fashion.",
                "We define an edge-traversal based method as any method that produces a pseudotree in which all parent/child pairs share an edge in the original graph.",
                "This includes DFS, breadth-first search, and best-first search based traversals.",
                "Our heuristics that generate cross-edged pseudotrees use a distributed best-first search traversal. 3.",
                "DPOP ALGORITHM The original DPOP algorithm operates in three main phases.",
                "The first phase generates a traditional pseudotree from the DCOP instance using a distributed algorithm.",
                "The second phase joins utility hypercubes from children and the local node and propagates them towards the root.",
                "The third phase chooses an assignment for each domain in a top down fashion beginning with the agent at the root node.",
                "The complexity of DPOP depends on the size of the largest computation and utility message during phase two.",
                "It has been shown that this size directly corresponds to the induced width of the pseudotree generated in phase one [6].",
                "DPOP uses polynomial time heuristics to generate the pseudotree since finding the minimum induced width pseudotree is NP-hard.",
                "Several distributed edgetraversal heuristics have been developed to find low width pseudotrees [8].",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, and pseudo-children. 3.1 Utility Propagation Agents located at leaf nodes in the pseudotree begin the process by calculating a local utility hypercube.",
                "This hypercube at node X contains summed utilities for each combination of values in the domains for P(X) and PP(X).",
                "This hypercube has dimensional size equal to the number of pseudo-parents plus one.",
                "A message containing this hypercube is sent to P(X).",
                "Agents located at non-leaf nodes wait for all messages from children to arrive.",
                "Once the agent at node Y has all utility messages, it calculates its local utility hypercube which includes domains for P(Y), PP(Y), and Y.",
                "The local utility hypercube is then joined with all of the hypercubes from the child messages.",
                "At this point all utilities involving node Y are known, and the domain for Y may be safely eliminated from the joined hypercube.",
                "This elimination process chooses the best utility over the domain of Y for each combination of the remaining domains.",
                "A message containing this hypercube is now sent to P(Y).",
                "The dimensional size of this hypercube depends on the number of overlapping domains in received messages and the local utility hypercube.",
                "This dynamic programming based propagation phase continues until the agent at the root node of the pseudotree has received all messages from its children. 3.2 Value Propagation Value propagation begins when the agent at the root node Z has received all messages from its children.",
                "Since Z has no parents or pseudo-parents, it simply combines the utility hypercubes received from its children.",
                "The combined hypercube contains only values for the domain for Z.",
                "At this point the agent at node Z simply chooses the assignment for its domain that has the best utility.",
                "A value propagation message with this assignment is sent to each node in C(Z).",
                "Each other node then receives a value propagation message from its parent and chooses the assignment for its domain that has the best utility given the assignments received in the message.",
                "The node adds its domain assignment to the assignments it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen an assignment for their domain. 4.",
                "DCPOP ALGORITHM Our extension to the original DPOP algorithm, shown in Algorithm 1, shares the same three phases.",
                "The first phase generates the cross-edged pseudotree for the DCOP instance.",
                "The second phase merges branches and propagates the utility hypercubes.",
                "The third phase chooses assignments for domains at branch merge points and in a top down fashion, beginning with the agent at the root node.",
                "For the first phase we generate a pseudotree using several distributed heuristics and select the one with lowest overall complexity.",
                "The complexity of the computation and utility message size in DCPOP does not directly correspond to the induced width of the cross-edged pseudotree.",
                "Instead, we use a polynomial time method for calculating the maximum computation and utility message size for a given cross-edged pseudotree.",
                "A description of this method and the pseudotree selection process appears in Section 5.",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, pseudo-children, branch-parents, and branch-children. 4.1 Merging Branches and Utility Propagation In the original DPOP algorithm a node X only had utility functions involving its parent and its pseudo-parents.",
                "In DCPOP, a node X is allowed to have a utility function involving a branch-parent.",
                "The concept of a branch can be seen in Figure 2 with node E representing our node X.",
                "The two distinct paths from node E to node B are called branches of E. The single node where all branches of E meet is node B, which is called the merge point of E. Agents with nodes that have branch-parents begin by sending a utility propagation message to each branch-parent.",
                "This message includes a two dimensional utility hypercube with domains for the node X and the branch-parent BP(X).",
                "It also includes a branch information structure which contains the origination node of the branch, X, the total number of branches originating from X, and the number of branches originating from X that are merged into a single representation by this branch information structure (this number starts at 1).",
                "Intuitively when the number of merged branches equals the total number of originating branches, the algorithm has reached the merge point for X.",
                "In Figure 2, node E sends a utility propagation message to its branch-parent, node D. This message has dimensions for the domains of E and D, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "As in the original DPOP utility propagation phase, an agent at leaf node X sends a utility propagation message to its parent.",
                "In DCPOP this message contains dimensions for the domains of P(X) and PP(X).",
                "If node X also has branch-parents, then the utility propagation message also contains a dimension for the domain of X, and will include a branch information structure.",
                "In Figure 2, node E sends a utility propagation message to its parent, node C. This message has dimensions for the domains of E and C, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "When a node Y receives utility propagation messages from all of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 743 its children and branch-children, it merges any branches with the same origination node X.",
                "The merged branch information structure accumulates the number of merged branches for X.",
                "If the cumulative total number of merged branches equals the total number of branches, then Y is the merge point for X.",
                "This means that the utility hypercubes present at Y contain all information about the valuations for utility functions involving node X.",
                "In addition to the typical elimination of the domain of Y from the utility hypercubes, we can now safely eliminate the domain of X from the utility hypercubes.",
                "To illustrate this process, we will examine what happens in the second phase for node B in Figure 2.",
                "In the second phase Node B receives two utility propagation messages.",
                "The first comes from node C and includes dimensions for domains E, B, and A.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "The second comes from node D and includes dimensions for domains E and B.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "Node B then merges the branch information structures from both messages because they have the same origination, node E. Since the number of merged branches originating from E is now 2 and the total branches originating from E is 2, node B now eliminates the dimensions for domain E. Node B also eliminates the dimension for its own domain, leaving only information about domain A. Node B then sends a utility propagation message to node A, containing only one dimension for the domain of A.",
                "Although not possible in DPOP, this method of utility propagation and dimension elimination may produce hypercubes at node Y that do not share any domains.",
                "In DCPOP we do not join domain independent hypercubes, but instead may send multiple hypercubes in the utility propagation message sent to the parent of Y.",
                "This lazy approach to joins helps to reduce message sizes. 4.2 Value Propagation As in DPOP, value propagation begins when the agent at the root node Z has received all messages from its children.",
                "At this point the agent at node Z chooses the assignment for its domain that has the best utility.",
                "If Z is the merge point for the branches of some node X, Z will also choose the assignment for the domain of X.",
                "Thus any node that is a merge point will choose assignments for a domain other than its own.",
                "These assignments are then passed down the primary edge hierarchy.",
                "If node X in the hierarchy has branch-parents, then the value assignment message from P(X) will contain an assignment for the domain of X.",
                "Every node in the hierarchy adds any assignments it has chosen to the ones it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen or received an assignment for their domain. 4.3 Proof of Correctness We will prove the correctness of DCPOP by first noting that DCPOP fully extends DPOP and then examining the two cases for value assignment in DCPOP.",
                "Given a traditional pseudotree as input, the DCPOP algorithm execution is identical to DPOP.",
                "Using a traditional pseudotree arrangement no nodes have branch-parents or branch-children since all edges are either back-edges or tree edges.",
                "Thus the DCPOP algorithm using a traditional pseudotree sends only utility propagation messages that contain domains belonging to the parent or pseudo-parents of a node.",
                "Since no node has any branch-parents, no branches exist, and thus no node serves as a merge point for any other node.",
                "Thus all value propagation assignments are chosen at the node of the assignment domain.",
                "For DCPOP execution with cross-edged pseudotrees, some nodes serve as merge points.",
                "We note that any node X that is not a merge point assigns its value exactly as in DPOP.",
                "The local utility hypercube at X contains domains for X, P(X), PP(X), and BC(X).",
                "As in DPOP the value assignment message received at X includes the values assigned to P(X) and PP(X).",
                "Also, since X is not a merge point, all assignments to BC(X) must have been calculated at merge points higher in the tree and are in the value assignment message from P(X).",
                "Thus after eliminating domains for which assignments are known, only the domain of X is left.",
                "The agent at node X can now correctly choose the assignment with maximum utility for its own domain.",
                "If node X is a merge point for some branch-child Y, we know that X must be a node along the path from Y to the root, and from P(Y) and all BP(Y) to the root.",
                "From the algorithm, we know that Y necessarily has all information from C(Y), PC(Y), and BC(Y) since it waits for their messages.",
                "Node X has information about all nodes below it in the tree, which would include Y, P(Y), BP(Y), and those PP(Y) that are below X in the tree.",
                "For any PP(Y) above X in the tree, X receives the assignment for the domain of PP(Y) in the value assignment message from P(X).",
                "Thus X has utility information about all of the utility functions of which Y is a part.",
                "By eliminating domains included in the value assignment message, node X is left with a local utility hypercube with domains for X and Y.",
                "The agent at node X can now correctly choose the assignments with maximum utility for the domains of X and Y. 4.4 Complexity Analysis The first phase of DCPOP sends one message to each P(X), PP(X), and BP(X).",
                "The second phase sends one value assignment message to each C(X).",
                "Thus, DCPOP produces a linear number of messages with respect to the number of edges (utility functions) in the cross-edged pseudotree and the original DCOP instance.",
                "The actual complexity of DCPOP depends on two additional measurements: message size and computation size.",
                "Message size and computation size in DCPOP depend on the number of overlapping branches as well as the number of overlapping back-edges.",
                "It was shown in [6] that the number of overlapping back-edges is equal to the induced width of the pseudotree.",
                "In a poorly constructed cross-edged pseudotree, the number of overlapping branches at node X can be as large as the total number of descendants of X.",
                "Thus, the total message size in DCPOP in a poorly constructed instance can be space-exponential in the total number of nodes in the graph.",
                "However, in practice a well constructed cross-edged pseudotree can achieve much better results.",
                "Later we address the issue of choosing well constructed crossedged pseudotrees from a set.",
                "We introduce an additional measurement of the maximum sequential path cost through the algorithm.",
                "This measurement directly relates to the maximum amount of parallelism achievable by the algorithm.",
                "To take this measurement we first store the total computation size for each node during phase two and three.",
                "This computation size represents the number of individual accesses to a value in a hypercube at each node.",
                "For example, a join between two domains of size 4 costs 4 ∗ 4 = 16.",
                "Two directed acyclic graphs (DAG) can then be drawn; one with the utility propagation messages as edges and the phase two costs at nodes, and the other with value assignment messages and the phase three costs at nodes.",
                "The maximum sequential path cost is equal to the sum of the longest path on each DAG from the root to any leaf node. 5.",
                "HEURISTICS In our assessment of complexity in DCPOP we focused on the worst case possibly produced by the algorithm.",
                "We acknowledge 744 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Algorithm 1 DCPOP Algorithm 1: DCPOP(X; D; U) Each agent Xi executes: Phase 1: pseudotree creation 2: elect leader from all Xj ∈ X 3: elected leader initiates pseudotree creation 4: afterwards, Xi knows P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) and PC(Xi) Phase 2: UTIL message propagation 5: if |BP(Xi)| > 0 then 6: BRANCHXi ← |BP(Xi)| + 1 7: for all Xk ∈BP(Xi) do 8: UTILXi (Xk) ←Compute utils(Xi, Xk) 9: Send message(Xk,UTILXi (Xk),BRANCHXi ) 10: if |C(Xi)| = 0(i.e.",
                "Xi is a leaf node) then 11: UTILXi (P(Xi)) ← Compute utils(P(Xi),PP(Xi)) for all PP(Xi) 12: Send message(P(Xi), UTILXi (P(Xi)),BRANCHXi ) 13: Send message(PP(Xi), empty UTIL, empty BRANCH) to all PP(Xi) 14: activate UTIL Message handler() Phase 3: VALUE message propagation 15: activate VALUE Message handler() END ALGORITHM UTIL Message handler(Xk,UTILXk (Xi), BRANCHXk ) 16: store UTILXk (Xi),BRANCHXk (Xi) 17: if UTIL messages from all children and branch children arrived then 18: for all Bj ∈BRANCH(Xi) do 19: if Bj is merged then 20: join all hypercubes where Bj ∈UTIL(Xi) 21: eliminate Bj from the joined hypercube 22: if P(Xi) == null (that means Xi is the root) then 23: v ∗ i ← Choose optimal(null) 24: Send VALUE(Xi, v ∗ i) to all C(Xi) 25: else 26: UTILXi (P(Xi)) ← Compute utils(P(Xi), PP(Xi)) 27: Send message(P(Xi),UTILXi (P(Xi)), BRANCHXi (P(Xi))) VALUE Message handler(VALUEXi ,P(Xi)) 28: add all Xk ← v ∗ k ∈VALUEXi ,P(Xi) to agent view 29: Xi ← v ∗ i =Choose optimal(agent view) 30: Send VALUEXl , Xi to all Xl ∈C(Xi) that in real world problems the generation of the pseudotree has a significant impact on the actual performance.",
                "The problem of finding the best pseudotree for a given DCOP instance is NP-Hard.",
                "Thus a heuristic is used for generation, and the performance of the algorithm depends on the pseudotree found by the heuristic.",
                "Some previous research focused on finding heuristics to generate good pseudotrees [8].",
                "While we have developed some heuristics that generate good cross-edged pseudotrees for use with DCPOP, our focus has been to use multiple heuristics and then select the best pseudotree from the generated pseudotrees.",
                "We consider only heuristics that run in polynomial time with respect to the number of nodes in the original DCOP instance.",
                "The actual DCPOP algorithm has worst case exponential complexity, but we can calculate the maximum message size, computation size, and sequential path cost for a given cross-edged pseudotree in linear space-time complexity.",
                "To do this, we simply run the algorithm without attempting to calculate any of the local utility hypercubes or optimal value assignments.",
                "Instead, messages include dimensional and branch information but no utility hypercubes.",
                "After each heuristic completes its generation of a pseudotree, we execute the measurement procedure and propagate the measurement information up to the chosen root in that pseudotree.",
                "The root then broadcasts the total complexity for that heuristic to all nodes.",
                "After all heuristics have had a chance to complete, every node knows which heuristic produced the best pseudotree.",
                "Each node then proceeds to begin the DCPOP algorithm using its knowledge of the pseudotree generated by the best heuristic.",
                "The heuristics used to generate traditional pseudotrees perform a distributed DFS traversal.",
                "The general distributed algorithm uses a token passing mechanism and a linear number of messages.",
                "Improved DFS based heuristics use a special procedure to choose the root node, and also provide an ordering function over the neighbors of a node to determine the order of path recursion.",
                "The DFS based heuristics used in our experiments come from the work done in [4, 8]. 5.1 The best-first cross-edged pseudotree heuristic The heuristics used to generate cross-edged pseudotrees perform a best-first traversal.",
                "A general distributed best-first algorithm for node expansion is presented in Algorithm 2.",
                "An evaluation function at each node provides the values that are used to determine the next best node to expand.",
                "Note that in this algorithm each node only exchanges its best value with its neighbors.",
                "In our experiments we used several evaluation functions that took as arguments an ordered list of ancestors and a node, which contains a list of neighbors (with each neighbors placement depth in the tree if it was placed).",
                "From these we can calculate branchparents, branch-children, and unknown relationships for a potential node placement.",
                "The best overall function calculated the value as ancestors−(branchparents+branchchildren) with the number of unknown relationships being a tiebreak.",
                "After completion each node has knowledge of its parent and ancestors, so it can easily determine which connected nodes are pseudo-parents, branchparents, pseudo-children, and branch-children.",
                "The complexity of the best-first traversal depends on the complexity of the evaluation function.",
                "Assuming a complexity of O(V ) for the evaluation function, which is the case for our best overall function, the best-first traversal is O(V · E) which is at worst O(n3 ).",
                "For each v ∈ V we perform a place operation, and find the next node to place using the getBestNeighbor operation.",
                "The place operation is at most O(V ) because of the sent messages.",
                "Finding the next node uses recursion and traverses only already placed The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 745 Algorithm 2 Distributed Best-First Search Algorithm root ← electedleader next(root, ∅) place(node, parent) node.parent ← parent node.ancestors ← parent.ancestors ∪ parent send placement message (node, node.ancestors) to all neighbors of node next(current, previous) if current is not placed then place(current, previous) next(current, ∅) else best ← getBestNeighbor(current, previous) if best = ∅ then if previous = ∅ then terminate, all nodes are placed next(previous, ∅) else next(best, current) getBestNeighbor(current, previous) best ← ∅; score ← 0 for all n ∈ current.neighbors do if n! = previous then if n is placed then nscore ← getBestNeighbor(n, current) else nscore ← evaluate(current, n) if nscore > score then score ← nscore best ← n return best, score nodes, so it has O(V ) recursions.",
                "Each recursion performs a recursive getBestNeighbor operation that traverses all placed nodes and their neighbors.",
                "This operation is O(V · E), but results can be cached using only O(V ) space at each node.",
                "Thus we have O(V ·(V +V +V ·E)) = O(V 2 ·E).",
                "If we are smart about evaluating local changes when each node receives placement messages from its neighbors and cache the results the getBestNeighbor operation is only O(E).",
                "This increases the complexity of the place operation, but for all placements the total complexity is only O(V · E).",
                "Thus we have an overall complexity of O(V ·E+V ·(V +E)) = O(V ·E). 6.",
                "COMPARISON OF COMPLEXITY IN DPOP AND DCPOP We have already shown that given the same input, DCPOP performs the same as DPOP.",
                "We also have shown that we can accurately predict performance of a given pseudotree in linear spacetime complexity.",
                "If we use a constant number of heuristics to generate the set of pseudotrees, we can choose the best pseudotree in linear space-time complexity.",
                "We will now show that there exists a DCOP instance for which a cross-edged pseudotree outperforms all possible traditional pseudotrees (based on edge-traversal heuristics).",
                "In Figure 3(a) we have a DCOP instance with six nodes.",
                "This is a bipartite graph with each partition fully connected to the other (a) (b) (c) Figure 3: (a) The DCOP instance (b) A traditional pseudotree arrangement for the DCOP instance (c) A cross-edged pseudotree arrangement for the DCOP instance partition.",
                "In Figure 3(b) we see a traditional pseudotree arrangement for this DCOP instance.",
                "It is easy to see that any edgetraversal based heuristic cannot expand two nodes from the same partition in succession.",
                "We also see that no node can have more than one child because any such arrangement would be an invalid pseudotree.",
                "Thus any traditional pseudotree arrangement for this DCOP instance must take the form of Figure 3(b).",
                "We can see that the back-edges F-B and F-A overlap node C. Node C also has a parent E, and a back-edge with D. Using the original DPOP algorithm (or DCPOP since they are identical in this case), we find that the computation at node C involves five domains: A, B, C, D, and E. In contrast, the cross-edged pseudotree arrangement in Figure 3(c) requires only a maximum of four domains in any computation during DCPOP.",
                "Since node A is the merge point for branches from both B and C, we can see that each of the nodes D, E, and F have two overlapping branches.",
                "In addition each of these nodes has node A as its parent.",
                "Using the DCPOP algorithm we find that the computation at node D (or E or F) involves four domains: A, B, C, and D (or E or F).",
                "Since no better traditional pseudotree arrangement can be created using an edge-traversal heuristic, we have shown that DCPOP can outperform DPOP even if we use the optimal pseudotree found through edge-traversal.",
                "We acknowledge that pseudotree arrangements that allow parent-child relationships without an actual constraint can solve the problem in Figure 3(a) with maximum computation size of four domains.",
                "However, current heuristics used with DPOP do not produce such pseudotrees, and such a heuristic would be difficult to distribute since each node would require information about nodes with which it has no constraint.",
                "Also, while we do not prove it here, cross-edged pseudotrees can produce smaller message sizes than such pseudotrees even if the computation size is similar.",
                "In practice, since finding the best pseudotree arrangement is NP-Hard, we find that heuristics that produce cross-edged pseudotrees often produce significantly smaller computation and message sizes. 7.",
                "EXPERIMENTAL RESULTS 746 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Existing performance metrics for DCOP algorithms include the total number of messages, synchronous clock cycles, and message size.",
                "We have already shown that the total number of messages is linear with respect to the number of constraints in the DCOP instance.",
                "We also introduced the maximum sequential path cost (PC) as a measurement of the maximum amount of parallelism achievable by the algorithm.",
                "The maximum sequential path cost is equal to the sum of the computations performed on the longest path from the root to any leaf node.",
                "We also include as metrics the maximum computation size in number of dimensions (CD) and maximum message size in number of dimensions (MD).",
                "To analyze the relative complexity of a given DCOP instance, we find the minimum induced width (IW) of any traditional pseudotree produced by a heuristic for the original DPOP. 7.1 Generic DCOP instances For our initial tests we randomly generated two sets of problems with 3000 cases in each.",
                "Each problem was generated by assigning a random number (picked from a range) of constraints to each variable.",
                "The generator then created binary constraints until each variable reached its maximum number of constraints.",
                "The first set uses 20 variables, and the best DPOP IW ranges from 1 to 16 with an average of 8.5.",
                "The second set uses 100 variables, and the best DPOP IW ranged from 2 to 68 with an average of 39.3.",
                "Since most of the problems in the second set were too complex to actually compute the solution, we took measurements of the metrics using the techniques described earlier in Section 5 without actually solving the problem.",
                "Results are shown for the first set in Table 1 and for the second set in Table 2.",
                "For the two problem sets we split the cases into low density and high density categories.",
                "Low density cases consist of those problems that have a best DPOP IW less than or equal to half of the total number of nodes (e.g.",
                "IW ≤ 10 for the 20 node problems and IW ≤ 50 for the 100 node problems).",
                "High density problems consist of the remainder of the problem sets.",
                "In both Table 1 and Table 2 we have listed performance metrics for the original DPOP algorithm, the DCPOP algorithm using only cross-edged pseudotrees (DCPOP-CE), and the DCPOP algorithm using traditional and cross-edged pseudotrees (DCPOP-All).",
                "The pseudotrees used for DPOP were generated using 5 heuristics: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB, and DFS MCN BEC.",
                "These are all versions of the guided DFS traversal discussed in Section 5.",
                "The cross-edged pseudotrees used for DCPOP-CE were generated using 5 heuristics: MCN, LCN, MCN A-B, LCN A-B, and LCSG A-B.",
                "These are all versions of the best-first traversal discussed in Section 5.",
                "For both DPOP and DCPOP-CE we chose the best pseudotree produced by their respective 5 heuristics for each problem in the set.",
                "For DCPOP-All we chose the best pseudotree produced by all 10 heuristics for each problem in the set.",
                "For the CD and MD metrics the value shown is the average number of dimensions.",
                "For the PC metric the value shown is the natural logarithm of the maximum sequential path cost (since the actual value grows exponentially with the complexity of the problem).",
                "The final row in both tables is a measurement of improvement of DCPOP-All over DPOP.",
                "For the CD and MD metrics the value shown is a reduction in number of dimensions.",
                "For the PC metric the value shown is a percentage reduction in the maximum sequential path cost (% = DP OP −DCP OP DCP OP ∗ 100).",
                "Notice that DCPOPAll outperforms DPOP on all metrics.",
                "This logically follows from our earlier assertion that given the same input, DCPOP performs exactly the same as DPOP.",
                "Thus given the choice between the pseudotrees produced by all 10 heuristics, DCPOP-All will always outLow Density High Density Algorithm CD MD PC CD MD PC DPOP 7.81 6.81 3.78 13.34 12.34 5.34 DCPOP-CE 7.94 6.73 3.74 12.83 11.43 5.07 DCPOP-All 7.62 6.49 3.66 12.72 11.36 5.05 Improvement 0.18 0.32 13% 0.62 0.98 36% Table 1: 20 node problems Low Density High Density Algorithm CD MD PC CD MD PC DPOP 33.35 32.35 14.55 58.51 57.50 19.90 DCPOP-CE 33.49 29.17 15.22 57.11 50.03 20.01 DCPOP-All 32.35 29.57 14.10 56.33 51.17 18.84 Improvement 1.00 2.78 104% 2.18 6.33 256% Table 2: 100 node problems Figure 4: Computation Dimension Size Figure 5: Message Dimension Size The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 747 Figure 6: Path Cost DCPOP Improvement Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Table 3: Meeting Scheduling Problems perform DPOP.",
                "Another trend we notice is that the improvement is greater for high density problems than low density problems.",
                "We show this trend in greater detail in Figures 4, 5, and 6.",
                "Notice how the improvement increases as the complexity of the problem increases. 7.2 Meeting Scheduling Problem In addition to our initial generic DCOP tests, we ran a series of tests on the Meeting Scheduling Problem (MSP) as described in [6].",
                "The problem setup includes a number of people that are grouped into departments.",
                "Each person must attend a specified number of meetings.",
                "Meetings can be held within departments or among departments, and can be assigned to one of eight time slots.",
                "The MSP maps to a DCOP instance where each variable represents the time slot that a specific person will attend a specific meeting.",
                "All variables that belong to the same person have mutual exclusion constraints placed so that the person cannot attend more than one meeting during the same time slot.",
                "All variables that belong to the same meeting have equality constraints so that all of the participants choose the same time slot.",
                "Unary constraints are placed on each variable to account for a persons valuation of each meeting and time slot.",
                "For our tests we generated 100 sample problems for each combination of agents and meetings.",
                "Results are shown in Table 3.",
                "The values in the first five columns represent (in left to right order), the total number of agents, the total number of meetings, the total number of variables, the average total number of constraints, and the average minimum IW produced by a traditional pseudotree.",
                "The last three columns show the same metrics we used for the generic DCOP instances, except this time we only show the improvements of DCPOP-All over DPOP.",
                "Performance is better on average for all MSP instances, but again we see larger improvements for more complex problem instances. 8.",
                "CONCLUSIONS AND FUTURE WORK We presented a complete, distributed algorithm that solves general DCOP instances using cross-edged pseudotree arrangements.",
                "Our algorithm extends the DPOP algorithm by adding additional utility propagation messages, and introducing the concept of branch merging during the utility propagation phase.",
                "Our algorithm also allows value assignments to occur at higher level merge points for lower level nodes.",
                "We have shown that DCPOP fully extends DPOP by performing the same operations given the same input.",
                "We have also shown through some examples and experimental data that DCPOP can achieve greater performance for some problem instances by extending the allowable input set to include cross-edged pseudotrees.",
                "We placed particular emphasis on the role that edge-traversal heuristics play in the generation of pseudotrees.",
                "We have shown that the performance penalty is minimal to generate multiple heuristics, and that we can choose the best generated pseudotree in linear space-time complexity.",
                "Given the importance of a good pseudotree for performance, future work will include new heuristics to find better pseudotrees.",
                "Future work will also include adapting existing DPOP extensions [5, 7] that support different problem domains for use with DCPOP. 9.",
                "REFERENCES [1] J. Liu and K. P. Sycara.",
                "Exploiting problem structure for distributed constraint optimization.",
                "In V. Lesser, editor, Proceedings of the First International Conference on Multi-Agent Systems, pages 246-254, San Francisco, CA, 1995.",
                "MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni.",
                "A dynamic distributed constraint satisfaction approach to resource allocation.",
                "Lecture Notes in Computer Science, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe, and M. Yokoo.",
                "An asynchronous complete method for distributed constraint optimization.",
                "In AAMAS 03, 2003. [4] A. Petcu.",
                "Frodo: A framework for open/distributed constraint optimization.",
                "Technical Report No. 2006/001 2006/001, Swiss Federal Institute of Technology (EPFL), Lausanne (Switzerland), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu and B. Faltings.",
                "A-dpop: Approximations in distributed optimization.",
                "In poster in CP 2005, pages 802-806, Sitges, Spain, October 2005. [6] A. Petcu and B. Faltings.",
                "Dpop: A scalable method for multiagent constraint optimization.",
                "In IJCAI 05, pages 266-271, Edinburgh, Scotland, Aug 2005. [7] A. Petcu, B. Faltings, and D. Parkes.",
                "M-dpop: Faithful distributed implementation of efficient social choice problems.",
                "In AAMAS 06, pages 1397-1404, Hakodate, Japan, May 2006. [8] G. Ushakov.",
                "Solving meeting scheduling problems using distributed pseudotree-optimization procedure.",
                "Masters thesis, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "Distributed constraint satisfaction for formalizing distributed problem solving.",
                "In International Conference on Distributed Computing Systems, pages 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "The distributed constraint satisfaction problem: Formalization and algorithms.",
                "Knowledge and Data Engineering, 10(5):673-685, 1998. 748 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [
                "Instead of finding an assignment that satisfies all constraints, these approaches find an assignment that produces a high level of <br>global utility</br>."
            ],
            "translated_annotated_samples": [
                "En lugar de encontrar una asignación que satisfaga todas las restricciones, estos enfoques encuentran una asignación que produce un alto nivel de <br>utilidad global</br>."
            ],
            "translated_text": "Un Método Completo de Optimización de Restricciones Distribuidas para Arreglos de Pseudotree No Tradicionales∗ James Atlas Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Ciencias de la Computación e Informática Universidad de Delaware Newark, DE 19716 decker@cis.udel.edu RESUMEN La Optimización de Restricciones Distribuidas (DCOP) es un marco general que puede modelar problemas complejos en sistemas multiagente. Varios algoritmos actuales que resuelven instancias generales de DCOP, incluyendo ADOPT y DPOP, organizan a los agentes en una estructura de pseudobosque tradicional. Introducimos una extensión al algoritmo DPOP que maneja un conjunto extendido de disposiciones de pseudobosque. Nuestro algoritmo resuelve correctamente instancias de DCOP para pseudobosques que incluyen aristas entre nodos en ramas separadas. El algoritmo también resuelve instancias con arreglos de pseudobosque tradicionales utilizando el mismo procedimiento que DPOP. Comparamos nuestro algoritmo con DPOP utilizando varios métricos, incluyendo el ancho inducido de los pseudobosques, la dimensionalidad máxima de los mensajes y la computación, y el costo máximo de la ruta secuencial a través del algoritmo. Demostramos que para algunas instancias del problema no es posible generar un pseudoárbol tradicional utilizando heurísticas de recorrido de aristas que supere a un pseudoárbol con aristas cruzadas. Utilizamos múltiples heurísticas para generar pseudoárboles y elegir el mejor pseudoárbol en complejidad espacio-temporal lineal. Para algunas instancias del problema observamos mejoras significativas en los tamaños de los mensajes y cálculos en comparación con DPOP. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Algoritmos 1. INTRODUCCIÓN Muchos problemas históricos en la comunidad de IA pueden transformarse en Problemas de Satisfacción de Restricciones (CSP). Con la llegada de la inteligencia artificial distribuida, los sistemas multiagente se convirtieron en una forma popular de modelar las interacciones complejas y la coordinación necesaria para resolver problemas distribuidos. Los CSPs fueron originalmente extendidos a entornos de agentes distribuidos en [9]. Los primeros dominios para problemas de satisfacción de restricciones distribuidas (DisCSP) incluyeron la programación de talleres de trabajo [1] y la asignación de recursos [2]. Muchos dominios para sistemas de agentes, especialmente coordinación de trabajo en equipo, programación distribuida y redes de sensores, implican problemas excesivamente restringidos que son difíciles o imposibles de satisfacer para cada restricción. Los enfoques recientes para resolver problemas en estos dominios se basan en técnicas de optimización que mapean restricciones en funciones de utilidad multivaluadas. En lugar de encontrar una asignación que satisfaga todas las restricciones, estos enfoques encuentran una asignación que produce un alto nivel de <br>utilidad global</br>. Esta extensión al enfoque original de DisCSP se ha vuelto popular en sistemas multiagente, y ha sido etiquetada como Problema de Optimización de Restricciones Distribuidas (DCOP) [1]. Los algoritmos actuales que resuelven DCOPs completos utilizan dos enfoques principales: búsqueda y programación dinámica. Los algoritmos basados en búsqueda que se originaron a partir de DisCSP típicamente utilizan alguna forma de retroceso [10] o propagación de límites, como en ADOPT [3]. Los algoritmos basados en programación dinámica incluyen DPOP y sus extensiones [5, 6, 7]. Hasta la fecha, ambas categorías de algoritmos organizan agentes en un pseudoárbol tradicional para resolver el problema. Se ha demostrado en [6] que cualquier grafo de restricciones puede ser mapeado en un pseudoárbol tradicional. Sin embargo, también se demostró que encontrar el pseudoárbol óptimo era NP-Difícil. Comenzamos a investigar el rendimiento de los pseudobosques tradicionales generados por las heurísticas actuales de recorrido de aristas. Descubrimos que estas heurísticas a menudo generaban poco paralelismo, ya que los pseudárboles tendían a tener una gran profundidad y bajos factores de ramificación. Sospechábamos que podría haber otras formas de organizar los pseudobosques que proporcionarían un mayor paralelismo y tamaños de mensaje más pequeños. Después de explorar estos otros arreglos, descubrimos que los pseudobosques de bordes cruzados proporcionan profundidades más cortas y factores de ramificación más altos que los pseudobosques tradicionales. Nuestra hipótesis era que estos pseudorboles cruzados superarían a los pseudorboles tradicionales en algunos tipos de problemas. En este artículo presentamos una extensión al algoritmo DPOP que maneja un conjunto ampliado de disposiciones de pseudobosque que incluyen pseudobosques con aristas cruzadas. Comenzamos con una definición de 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, pseudobosques tradicionales y pseudobosques de bordes cruzados. Luego proporcionamos un resumen del algoritmo DPOP original e introducimos nuestro algoritmo DCPOP. Discutimos la complejidad de nuestro algoritmo, así como el impacto de las heurísticas de generación de pseudobosques. Luego demostramos que nuestro Procedimiento de Optimización de Pseudotree de Bordes Cruzados Distribuido (DCPOP) funciona significativamente mejor en la práctica que el algoritmo DPOP original para algunas instancias del problema. Concluimos con una selección de ideas para trabajos futuros y extensiones para DCPOP. 2. La DEFINICIÓN DEL PROBLEMA DCOP ha sido formalizada de maneras ligeramente diferentes en la literatura reciente, por lo que adoptaremos la definición presentada en [6]. Un Problema de Optimización de Restricciones Distribuidas con n nodos y m restricciones consiste en la tupla < X, D, U > donde: • X = {x1,..,xn} es un conjunto de variables, cada una asignada a un agente único • D = {d1,..,dn} es un conjunto de dominios finitos para cada variable • U = {u1,..,um} es un conjunto de funciones de utilidad tales que cada función involucra un subconjunto de variables en X y define una utilidad para cada combinación de valores entre estas variables. Una solución óptima para una instancia de DCOP consiste en una asignación de valores en D a X tal que la suma de las utilidades en U sea máxima. Los dominios de problemas que requieren un costo mínimo en lugar de una utilidad máxima pueden mapear los costos en utilidades negativas. Las funciones de utilidad representan restricciones suaves pero también pueden representar restricciones fuertes mediante el uso de valores negativos arbitrariamente grandes. Para este artículo solo consideramos funciones de utilidad binarias que involucran dos variables. Las funciones de utilidad de orden superior pueden ser modeladas con cambios menores en el algoritmo, pero también aumentan sustancialmente la complejidad. 2.1 Pseudárboles Tradicionales Los pseudárboles son una estructura común utilizada en procedimientos de búsqueda para permitir el procesamiento paralelo de ramas independientes. Como se define en [6], un pseudoárbol es un arreglo de un grafo G en un árbol raíz T de tal manera que los vértices en G que comparten una arista están en la misma rama en T. Una arista de retroceso es una arista entre un nodo X y cualquier nodo que se encuentre en el camino desde X hasta la raíz (excluyendo al padre de X). La Figura 1 muestra un pseudoárbol con cuatro nodos, tres aristas (A-B, B-C, BD) y una arista de retroceso (A-C). También se definen en [6] cuatro tipos de relaciones entre nodos que existen en un pseudoárbol: • P(X) - el padre de un nodo X: el único nodo más alto en el pseudoárbol que está conectado a X directamente a través de un borde de árbol • C(X) - los hijos de un nodo X: el conjunto de nodos más bajos en el pseudo Las líneas sólidas representan relaciones padre-hijo y la línea discontinua representa una relación pseudo-padre-pseudo-hijo. Figura 2: Un pseudoárbol de bordes cruzados. Las líneas sólidas representan relaciones padre-hijo, la línea discontinua representa una relación pseudo-padre-pseudo-hijo, y la línea punteada representa una relación rama-padre-rama-hijo. El nodo en negrita, B, es el punto de fusión para el nodo E. 2.2 Pseudárboles con aristas cruzadas Definimos una arista cruzada como una arista de un nodo X a un nodo Y que está por encima de X pero no en el camino desde X hasta la raíz. Un pseudoárbol de bordes cruzados es un pseudoárbol tradicional con la adición de bordes cruzados. La Figura 2 muestra un pseudoárbol con una arista cruzada (D-E). En un pseudoárbol de bordes cruzados designamos ciertos bordes como primarios. El conjunto de aristas primarias define un árbol de expansión de los nodos. Las relaciones de padre, hijo, pseudo-padre y pseudo-hijo del pseudotree tradicional ahora están definidas en el contexto de este árbol de expansión de borde primario. Esta definición también produce dos tipos adicionales de relaciones que pueden existir entre nodos: • BP(X) - los nodos padres de rama de un nodo X: el conjunto de nodos más altos en el pseudoárbol que están conectados a X pero no están en el camino principal desde X hasta la raíz (En la Figura 2, D = BP(E)) • BC(X) - los nodos hijos de rama de un nodo X: el conjunto de nodos más bajos en el pseudo La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Los algoritmos actuales suelen tener una fase de pre-ejecución para generar un pseudoárbol tradicional a partir de una instancia general de DCOP. Nuestro algoritmo DCPOP genera un pseudoárbol de bordes cruzados de la misma manera. Primero, la instancia DCOP < X, D, U > se traduce directamente en un grafo con X como el conjunto de vértices y una arista para cada par de variables representadas en U. A continuación, se utilizan varias heurísticas para organizar este grafo en un pseudoárbol. Un heurístico común es realizar una búsqueda en profundidad guiada (DFS, por sus siglas en inglés) ya que el recorrido resultante es un pseudoárbol, y un DFS se puede realizar fácilmente de manera distribuida. Definimos un método basado en el recorrido de aristas como cualquier método que produce un pseudoárbol en el que todos los pares padre/hijo comparten una arista en el grafo original. Esto incluye recorridos basados en DFS, búsqueda en anchura y búsqueda de mejor primero. Nuestras heurísticas que generan pseudobosques de bordes cruzados utilizan un recorrido de búsqueda mejor primero distribuido. 3. ALGORITMO DPOP El algoritmo DPOP original opera en tres fases principales. La primera fase genera un pseudoárbol tradicional a partir de la instancia de DCOP utilizando un algoritmo distribuido. La segunda fase une hipercubos de utilidad de los nodos hijos y el nodo local y los propaga hacia la raíz. La tercera fase elige una asignación para cada dominio de arriba hacia abajo, comenzando con el agente en el nodo raíz. La complejidad de DPOP depende del tamaño del cálculo más grande y del mensaje de utilidad durante la fase dos. Se ha demostrado que este tamaño corresponde directamente al ancho inducido del pseudoárbol generado en la fase uno [6]. DPOP utiliza heurísticas de tiempo polinómico para generar el pseudoárbol, ya que encontrar el pseudoárbol de ancho inducido mínimo es NP-duro. Se han desarrollado varias heurísticas de recorrido de borde distribuido para encontrar pseudobosques de ancho reducido [8]. Al final de la primera fase, cada agente conoce a su padre, hijos, pseudo-padres y pseudo-hijos. 3.1 Propagación de utilidad Los agentes ubicados en los nodos hoja del pseudoárbol comienzan el proceso calculando un hipercubo de utilidad local. Este hipercubo en el nodo X contiene las utilidades sumadas para cada combinación de valores en los dominios de P(X) y PP(X). Este hipercubo tiene un tamaño dimensional igual al número de pseudo-padres más uno. Un mensaje que contiene este hipercubo se envía a P(X). Los agentes ubicados en nodos no hoja esperan a que lleguen todos los mensajes de los nodos hijos. Una vez que el agente en el nodo Y tiene todos los mensajes de utilidad, calcula su hipercubo de utilidad local que incluye los dominios de P(Y), PP(Y) y Y. El hipercubo de utilidad local se une luego con todos los hipercubos de los mensajes hijos. En este punto, todas las utilidades que involucran al nodo Y son conocidas, y el dominio de Y puede ser eliminado de forma segura del hipercubo unido. Este proceso de eliminación elige la mejor utilidad sobre el dominio de Y para cada combinación de los dominios restantes. Un mensaje que contiene este hipercubo se envía ahora a P(Y). El tamaño dimensional de este hipercubo depende del número de dominios superpuestos en los mensajes recibidos y del hipercubo de utilidad local. Esta fase de propagación basada en programación dinámica continúa hasta que el agente en el nodo raíz del pseudoárbol haya recibido todos los mensajes de sus hijos. 3.2 Propagación de Valor La propagación de valor comienza cuando el agente en el nodo raíz Z ha recibido todos los mensajes de sus hijos. Dado que Z no tiene padres ni pseudo-padres, simplemente combina los hipercubos de utilidad recibidos de sus hijos. El hipercubo combinado contiene solo valores para el dominio de Z. En este punto, el agente en el nodo Z simplemente elige la asignación para su dominio que tiene la mejor utilidad. Un mensaje de propagación de valor con esta asignación se envía a cada nodo en C(Z). Cada nodo luego recibe un mensaje de propagación de valor de su padre y elige la asignación para su dominio que tenga la mejor utilidad dadas las asignaciones recibidas en el mensaje. El nodo agrega su asignación de dominio a las asignaciones que recibió y pasa el conjunto de asignaciones a sus hijos. El algoritmo está completo cuando todos los nodos han elegido una asignación para su dominio. ALGORITMO DCPOP Nuestra extensión al algoritmo DPOP original, mostrada en el Algoritmo 1, comparte las mismas tres fases. La primera fase genera el pseudoárbol de bordes cruzados para la instancia de DCOP. La segunda fase fusiona ramas y propaga los hipercubos de utilidad. La tercera fase elige asignaciones para dominios en los puntos de fusión de ramas y de arriba hacia abajo, comenzando con el agente en el nodo raíz. Para la primera fase generamos un pseudoárbol utilizando varios heurísticos distribuidos y seleccionamos el que tenga la menor complejidad general. La complejidad de la computación y el tamaño del mensaje de utilidad en DCPOP no corresponden directamente al ancho inducido del pseudoárbol de aristas cruzadas. En cambio, utilizamos un método de tiempo polinómico para calcular el tamaño máximo de computación y utilidad del mensaje para un pseudoárbol de bordes cruzados dado. Una descripción de este método y el proceso de selección de pseudodendrogramas aparece en la Sección 5. Al final de la primera fase, cada agente conoce a su padre, hijos, pseudo-padres, pseudo-hijos, padres de rama e hijos de rama. 4.1 Fusión de Ramas y Propagación de Utilidad En el algoritmo DPOP original, un nodo X solo tenía funciones de utilidad que involucraban a su padre y a sus pseudo-padres. En DCPOP, se permite que un nodo X tenga una función de utilidad que involucre a un padre de rama. El concepto de una rama se puede ver en la Figura 2 con el nodo E representando nuestro nodo X. Las dos rutas distintas desde el nodo E hasta el nodo B se llaman ramas de E. El único nodo donde se encuentran todas las ramas de E es el nodo B, que se llama punto de fusión de E. Los agentes con nodos que tienen padres de rama comienzan enviando un mensaje de propagación de utilidad a cada padre de rama. Este mensaje incluye un hipercubo de utilidad bidimensional con dominios para el nodo X y el nodo padre de la rama BP(X). También incluye una estructura de información de rama que contiene el nodo de origen de la rama, X, el número total de ramas que se originan en X y el número de ramas que se originan en X y se fusionan en una representación única por esta estructura de información de rama (este número comienza en 1). Intuitivamente, cuando el número de ramas fusionadas es igual al número total de ramas originales, el algoritmo ha alcanzado el punto de fusión para X. En la Figura 2, el nodo E envía un mensaje de propagación de utilidad a su nodo padre de rama, el nodo D. Este mensaje tiene dimensiones para los dominios de E y D, e incluye información de rama con un origen en E, 2 ramas totales y 1 rama fusionada. Como en la fase de propagación de utilidad de la utilidad DPOP original, un agente en el nodo hoja X envía un mensaje de propagación de utilidad a su padre. En DCPOP, este mensaje contiene dimensiones para los dominios de P(X) y PP(X). Si el nodo X también tiene padres de rama, entonces el mensaje de propagación de utilidad también contiene una dimensión para el dominio de X e incluirá una estructura de información de rama. En la Figura 2, el nodo E envía un mensaje de propagación de utilidad a su padre, el nodo C. Este mensaje tiene dimensiones para los dominios de E y C, e incluye información de rama con un origen en E, 2 ramas en total y 1 rama fusionada. Cuando un nodo Y recibe mensajes de propagación de utilidad de todos de The Sixth Intl. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), 743 sus hijos y sus hijos de rama, fusiona cualquier rama con el mismo nodo de origen X. La estructura de información de la rama fusionada acumula el número de ramas fusionadas para X. Si el número total acumulado de ramas fusionadas es igual al número total de ramas, entonces Y es el punto de fusión para X. Esto significa que los hipercubos de utilidad presentes en Y contienen toda la información sobre las valoraciones de las funciones de utilidad que involucran al nodo X. Además de la eliminación típica del dominio de Y de los hipercubos de utilidad, ahora podemos eliminar de forma segura el dominio de X de los hipercubos de utilidad. Para ilustrar este proceso, examinaremos lo que sucede en la segunda fase para el nodo B en la Figura 2. En la segunda fase, el Nodo B recibe dos mensajes de propagación de utilidad. El primero proviene del nodo C e incluye dimensiones para los dominios E, B y A. También tiene una estructura de información de ramas con origen en E, 2 ramas en total y 1 rama fusionada. El segundo proviene del nodo D e incluye dimensiones para los dominios E y B. También tiene una estructura de información de rama con origen en E, 2 ramas en total y 1 rama fusionada. El nodo B luego fusiona las estructuras de información de rama de ambos mensajes porque tienen la misma procedencia, el nodo E. Dado que el número de ramas fusionadas que provienen de E es ahora 2 y el total de ramas que provienen de E es 2, el nodo B elimina las dimensiones para el dominio E. El nodo B también elimina la dimensión para su propio dominio, dejando solo información sobre el dominio A. Luego, el nodo B envía un mensaje de propagación de utilidad al nodo A, que contiene solo una dimensión para el dominio de A. Aunque no sea posible en DPOP, este método de propagación de utilidad y eliminación de dimensiones puede producir hipercubos en el nodo Y que no comparten ningún dominio. En DCPOP no unimos hipercubos independientes de dominio, sino que en su lugar podemos enviar múltiples hipercubos en el mensaje de propagación de utilidad enviado al padre de Y. Este enfoque perezoso de las uniones ayuda a reducir el tamaño de los mensajes. 4.2 Propagación de valores Al igual que en DPOP, la propagación de valores comienza cuando el agente en el nodo raíz Z ha recibido todos los mensajes de sus hijos. En este punto, el agente en el nodo Z elige la asignación para su dominio que tiene la mejor utilidad. Si Z es el punto de fusión de las ramas de algún nodo X, Z también elegirá la asignación para el dominio de X. Por lo tanto, cualquier nodo que sea un punto de fusión elegirá asignaciones para un dominio que no sea el suyo propio. Estas tareas luego se pasan por la jerarquía de la cadena de mando principal. Si el nodo X en la jerarquía tiene padres de rama, entonces el mensaje de asignación de valor de P(X) contendrá una asignación para el dominio de X. Cada nodo en la jerarquía agrega cualquier tarea que haya elegido a las que recibió y pasa el conjunto de tareas a sus hijos. El algoritmo está completo cuando todos los nodos han elegido o recibido una asignación para su dominio. 4.3 Prueba de Corrección Demostraremos la corrección de DCPOP notando primero que DCPOP extiende completamente DPOP y luego examinando los dos casos para la asignación de valores en DCPOP. Dado un pseudoárbol tradicional como entrada, la ejecución del algoritmo DCPOP es idéntica a DPOP. Usando un arreglo de pseudodendrograma tradicional, ningún nodo tiene padres de rama o hijos de rama, ya que todas las aristas son aristas de retroceso o aristas de árbol. Por lo tanto, el algoritmo DCPOP utilizando un pseudoárbol tradicional envía solo mensajes de propagación de utilidad que contienen dominios pertenecientes al padre o pseudo-padres de un nodo. Dado que ningún nodo tiene ramas-padres, no existen ramas, y por lo tanto ningún nodo sirve como punto de fusión para ningún otro nodo. Por lo tanto, todas las asignaciones de propagación de valor se eligen en el nodo del dominio de la asignación. Para la ejecución de DCPOP con pseudárboles de bordes cruzados, algunos nodos actúan como puntos de fusión. Observamos que cualquier nodo X que no sea un punto de fusión asigna su valor exactamente como en DPOP. El hipercubo de utilidad local en X contiene dominios para X, P(X), PP(X) y BC(X). Como en DPOP, el mensaje de asignación de valores recibido en X incluye los valores asignados a P(X) y PP(X). Además, dado que X no es un punto de fusión, todas las asignaciones a BC(X) deben haber sido calculadas en puntos de fusión más altos en el árbol y están en el mensaje de asignación de valor de P(X). Por lo tanto, después de eliminar los dominios para los cuales se conocen las asignaciones, solo queda el dominio de X. El agente en el nodo X ahora puede elegir correctamente la asignación con la máxima utilidad para su propio dominio. Si el nodo X es un punto de fusión para alguna rama-hijo Y, sabemos que X debe ser un nodo a lo largo del camino desde Y hasta la raíz, y desde P(Y) y todos los BP(Y) hasta la raíz. A partir del algoritmo, sabemos que Y necesariamente tiene toda la información de C(Y), PC(Y) y BC(Y) ya que espera sus mensajes. El nodo X tiene información sobre todos los nodos debajo de él en el árbol, lo cual incluiría a Y, P(Y), BP(Y) y aquellos PP(Y) que están debajo de X en el árbol. Para cualquier PP(Y) por encima de X en el árbol, X recibe la asignación para el dominio de PP(Y) en el mensaje de asignación de valor de P(X). Por lo tanto, X tiene información de utilidad sobre todas las funciones de utilidad de las cuales Y forma parte. Al eliminar los dominios incluidos en el mensaje de asignación de valor, el nodo X se queda con un hipercubo de utilidad local con dominios para X e Y. El agente en el nodo X ahora puede elegir correctamente las asignaciones con la máxima utilidad para los dominios de X e Y. 4.4 Análisis de complejidad La primera fase de DCPOP envía un mensaje a cada P(X), PP(X) y BP(X). La segunda fase envía un mensaje de asignación de valor a cada C(X). Por lo tanto, DCPOP produce un número lineal de mensajes con respecto al número de aristas (funciones de utilidad) en el pseudoárbol de aristas cruzadas y la instancia original de DCOP. La complejidad real de DCPOP depende de dos medidas adicionales: el tamaño del mensaje y el tamaño de la computación. El tamaño del mensaje y el tamaño de la computación en DCPOP dependen del número de ramas superpuestas, así como del número de aristas de retroceso superpuestas. Se demostró en [6] que el número de aristas traslapadas es igual al ancho inducido del pseudoárbol. En un pseudoárbol de bordes cruzados mal construido, el número de ramas superpuestas en el nodo X puede ser tan grande como el número total de descendientes de X. Por lo tanto, el tamaño total del mensaje en DCPOP en una instancia mal construida puede ser exponencial en el espacio en el número total de nodos en el grafo. Sin embargo, en la práctica, un pseudoárbol bien construido con bordes cruzados puede lograr resultados mucho mejores. Más tarde abordaremos el tema de elegir pseudobosques cruzados bien construidos de un conjunto. Introducimos una medida adicional del costo máximo de la ruta secuencial a través del algoritmo. Esta medida se relaciona directamente con la cantidad máxima de paralelismo que puede lograr el algoritmo. Para tomar esta medida, primero almacenamos el tamaño total de cálculo para cada nodo durante las fases dos y tres. Este tamaño de cálculo representa el número de accesos individuales a un valor en un hipercubo en cada nodo. Por ejemplo, una unión entre dos dominios de tamaño 4 cuesta 4 ∗ 4 = 16. Dos grafos acíclicos dirigidos (DAG) pueden ser dibujados; uno con los mensajes de propagación de utilidad como aristas y los costos de la fase dos en los nodos, y el otro con los mensajes de asignación de valor y los costos de la fase tres en los nodos. El costo máximo del camino secuencial es igual a la suma del camino más largo en cada DAG desde la raíz hasta cualquier nodo hoja. HEURÍSTICAS En nuestra evaluación de la complejidad en DCPOP nos enfocamos en el peor caso posiblemente producido por el algoritmo. Reconocemos 744 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Algoritmo 1 DCPOP Algoritmo 1: DCPOP(X; D; U) Cada agente Xi ejecuta: Fase 1: creación de pseudotree 2: elegir líder de todos los Xj ∈ X 3: líder elegido inicia la creación de pseudotree 4: después, Xi conoce P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) y PC(Xi) Fase 2: propagación de mensajes UTIL 5: si |BP(Xi)| > 0 entonces 6: BRANCHXi ← |BP(Xi)| + 1 7: para todos Xk ∈BP(Xi) hacer 8: UTILXi (Xk) ← Calcular utils(Xi, Xk) 9: Enviar mensaje(Xk,UTILXi (Xk),BRANCHXi ) 10: si |C(Xi)| = 0 (es decir, Si Xi es un nodo hoja, entonces 11: UTILXi (P(Xi)) ← Calcular utils(P(Xi),PP(Xi)) para todos los PP(Xi) 12: Enviar mensaje(P(Xi), UTILXi (P(Xi)), BRANCHXi ) 13: Enviar mensaje(PP(Xi), UTIL vacío, BRANCH vacío) a todos los PP(Xi) 14: Activar el manejador de mensajes UTIL() Fase 3: Propagación de mensajes de VALOR 15: Activar el manejador de mensajes de VALOR() FIN ALGORITMO Manejador de mensajes UTIL(Xk, UTILXk (Xi), BRANCHXk ) 16: Almacenar UTILXk (Xi), BRANCHXk (Xi) 17: Si han llegado mensajes UTIL de todos los hijos y los hijos de la rama, entonces 18: Para todos los Bj ∈ BRANCH(Xi) hacer 19: Si Bj está fusionado, entonces 20: Unir todos los hipercubos donde Bj ∈ UTIL(Xi) 21: Eliminar Bj del hipercubo unido 22: Si P(Xi) == nulo (eso significa que Xi es la raíz) entonces 23: v ∗ i ← Elegir óptimo(nulo) 24: Enviar VALOR(Xi, v ∗ i) a todos los C(Xi) 25: De lo contrario 26: UTILXi (P(Xi)) ← Calcular utils(P(Xi), PP(Xi)) 27: Enviar mensaje(P(Xi), UTILXi (P(Xi)), BRANCHXi (P(Xi))) Manejador de mensajes de VALOR(VALORXi , P(Xi)) 28: Agregar todos los Xk ← v ∗ k ∈ VALORXi , P(Xi) a la vista del agente 29: Xi ← v ∗ i = Elegir óptimo(vista del agente) 30: Enviar VALORXl , Xi a todos los Xl ∈ C(Xi) que en problemas del mundo real la generación del pseudoárbol tiene un impacto significativo en el rendimiento real. El problema de encontrar la mejor pseudotree para una instancia de DCOP dada es NP-Difícil. Por lo tanto, se utiliza una heurística para la generación, y el rendimiento del algoritmo depende del pseudoárbol encontrado por la heurística. Algunas investigaciones previas se centraron en encontrar heurísticas para generar buenas pseudorboles [8]. Si bien hemos desarrollado algunas heurísticas que generan buenos pseudoárboles cruzados para usar con DCPOP, nuestro enfoque ha sido utilizar múltiples heurísticas y luego seleccionar el mejor pseudo Consideramos solo heurísticas que se ejecuten en tiempo polinómico con respecto al número de nodos en la instancia original del DCOP. El algoritmo DCPOP actual tiene una complejidad exponencial en el peor de los casos, pero podemos calcular el tamaño máximo del mensaje, el tamaño de la computación y el costo de la ruta secuencial para un pseudoárbol de bordes cruzados dado en complejidad espacio-temporal lineal. Para hacer esto, simplemente ejecutamos el algoritmo sin intentar calcular ninguno de los hipercubos de utilidad local o asignaciones de valor óptimo. En cambio, los mensajes incluyen información dimensional y de ramificación pero no hipercubos de utilidad. Después de que cada heurística complete la generación de un pseudoárbol, ejecutamos el procedimiento de medición y propagamos la información de la medición hasta la raíz elegida en ese pseudo La raíz luego transmite la complejidad total de esa heurística a todos los nodos. Después de que todas las heurísticas hayan tenido la oportunidad de completarse, cada nodo sabe qué heurística produjo el mejor pseudoárbol. Cada nodo luego procede a comenzar el algoritmo DCPOP utilizando su conocimiento del pseudoárbol generado por la mejor heurística. Las heurísticas utilizadas para generar pseudárboles tradicionales realizan un recorrido DFS distribuido. El algoritmo distribuido general utiliza un mecanismo de paso de token y un número lineal de mensajes. Las heurísticas mejoradas basadas en DFS utilizan un procedimiento especial para elegir el nodo raíz, y también proporcionan una función de ordenación sobre los vecinos de un nodo para determinar el orden de la recursión de caminos. Las heurísticas basadas en DFS utilizadas en nuestros experimentos provienen del trabajo realizado en [4, 8]. 5.1 La heurística de pseudotree cruzado de mejor primer recorrido. Las heurísticas utilizadas para generar pseudárboles cruzados realizan un recorrido de mejor primer recorrido. Se presenta un algoritmo general distribuido de mejor primero para la expansión de nodos en el Algoritmo 2. Una función de evaluación en cada nodo proporciona los valores que se utilizan para determinar el siguiente mejor nodo a expandir. Ten en cuenta que en este algoritmo cada nodo solo intercambia su mejor valor con sus vecinos. En nuestros experimentos utilizamos varias funciones de evaluación que tomaban como argumentos una lista ordenada de ancestros y un nodo, que contiene una lista de vecinos (con la profundidad de colocación de cada vecino en el árbol). A partir de estos podemos calcular los padres de la rama, los hijos de la rama y las relaciones desconocidas para una posible ubicación del nodo. La mejor función general calculó el valor como ancestros - (padres de rama + hijos de rama) con el número de relaciones desconocidas como criterio de desempate. Después de completarse, cada nodo tiene conocimiento de su padre y ancestros, por lo que puede determinar fácilmente qué nodos conectados son pseudo-padres, padres de rama, pseudo-hijos e hijos de rama. La complejidad de la travesía de mejor primero depende de la complejidad de la función de evaluación. Suponiendo una complejidad de O(V) para la función de evaluación, que es el caso de nuestra mejor función general, el recorrido de mejor primero es O(V · E), lo que en el peor de los casos es O(n3). Para cada v ∈ V realizamos una operación de colocación y encontramos el siguiente nodo a colocar usando la operación getBestNeighbor. La complejidad de la operación del lugar es a lo sumo O(V) debido a los mensajes enviados. Encontrar el siguiente nodo utiliza recursión y recorre solo los ya colocados The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 745 Algoritmo 2 Algoritmo de Búsqueda Distribuida de Mejor Primero root ← líder elegido next(root, ∅) place(nodo, padre) nodo.padre ← padre nodo.ancestros ← padre.ancestros ∪ padre enviar mensaje de ubicación (nodo, nodo.ancestros) a todos los vecinos de nodo next(actual, anterior) si actual no está ubicado entonces place(actual, anterior) next(actual, ∅) else mejor ← obtenerMejorVecino(actual, anterior) si mejor = ∅ entonces si anterior = ∅ entonces terminar, todos los nodos están ubicados next(anterior, ∅) else next(mejor, actual) obtenerMejorVecino(actual, anterior) mejor ← ∅; puntaje ← 0 para todo n ∈ vecinos de actual hacer si n! = anterior entonces si n está ubicado entonces puntajeN ← obtenerMejorVecino(n, actual) else puntajeN ← evaluar(actual, n) si puntajeN > puntaje entonces puntaje ← puntajeN mejor ← n return mejor, puntaje nodos, por lo que tiene O(V) recursiones. Cada recursión realiza una operación recursiva getBestNeighbor que recorre todos los nodos colocados y sus vecinos. Esta operación es O(V · E), pero los resultados se pueden almacenar en caché utilizando solo O(V) espacio en cada nodo. Así que tenemos O(V ·(V +V +V ·E)) = O(V 2 ·E). Si somos inteligentes al evaluar los cambios locales cuando cada nodo recibe mensajes de ubicación de sus vecinos y almacenamos en caché los resultados, la operación getBestNeighbor es solo O(E). Esto aumenta la complejidad de la operación de ubicación, pero para todas las ubicaciones la complejidad total es solo O(V · E). Por lo tanto, tenemos una complejidad general de O(V ·E+V ·(V +E)) = O(V ·E). 6. COMPARACIÓN DE COMPLEJIDAD EN DPOP Y DCPOP Ya hemos demostrado que, dado el mismo input, DCPOP se desempeña igual que DPOP. También hemos demostrado que podemos predecir con precisión el rendimiento de un pseudoárbol dado en complejidad temporal lineal. Si usamos un número constante de heurísticas para generar el conjunto de pseudobosques, podemos elegir el mejor pseudobosque con complejidad lineal en espacio y tiempo. Ahora demostraremos que existe una instancia de DCOP para la cual un pseudoárbol de bordes cruzados supera a todos los posibles pseudoárboles tradicionales (basados en heurísticas de recorrido de bordes). En la Figura 3(a) tenemos una instancia de DCOP con seis nodos. Este es un grafo bipartito con cada partición completamente conectada a la otra (a) (b) (c) Figura 3: (a) La instancia de DCOP (b) Un arreglo de pseudobosque tradicional para la instancia de DCOP (c) Un arreglo de pseudobosque con aristas cruzadas para la partición de la instancia de DCOP. En la Figura 3(b) vemos un arreglo tradicional de pseudotree para esta instancia de DCOP. Es fácil ver que cualquier heurística basada en el recorrido de aristas no puede expandir dos nodos de la misma partición sucesivamente. También observamos que ningún nodo puede tener más de un hijo porque cualquier disposición de este tipo sería un pseudoárbol inválido. Por lo tanto, cualquier disposición tradicional de pseudodendrograma para esta instancia de DCOP debe tener la forma de la Figura 3(b). Podemos ver que las aristas de retroceso F-B y F-A se superponen al nodo C. El nodo C también tiene un padre E y una arista de retroceso con D. Utilizando el algoritmo DPOP original (o DCPOP ya que son idénticos en este caso), encontramos que el cálculo en el nodo C implica cinco dominios: A, B, C, D y E. En contraste, el arreglo de pseudonodos con aristas cruzadas en la Figura 3(c) requiere un máximo de cuatro dominios en cualquier cálculo durante DCPOP. Dado que el nodo A es el punto de fusión de las ramas tanto de B como de C, podemos ver que cada uno de los nodos D, E y F tiene dos ramas superpuestas. Además, cada uno de estos nodos tiene al nodo A como su padre. Usando el algoritmo DCPOP, encontramos que el cálculo en el nodo D (o E o F) implica cuatro dominios: A, B, C y D (o E o F). Dado que no se puede crear una disposición de pseudobosque tradicional mejor utilizando una heurística de recorrido de aristas, hemos demostrado que DCPOP puede superar a DPOP incluso si utilizamos el pseudobosque óptimo encontrado a través del recorrido de aristas. Reconocemos que los arreglos de pseudodistribución de árboles que permiten relaciones padre-hijo sin una restricción real pueden resolver el problema en la Figura 3(a) con un tamaño de cálculo máximo de cuatro dominios. Sin embargo, las heurísticas actuales utilizadas con DPOP no producen tales pseudobosques, y sería difícil distribuir una heurística así, ya que cada nodo requeriría información sobre nodos con los que no tiene restricciones. Además, aunque no lo demostramos aquí, los pseudobosques de bordes cruzados pueden producir tamaños de mensaje más pequeños que tales pseudobosques, incluso si el tamaño de la computación es similar. En la práctica, dado que encontrar la mejor disposición de pseudoramas es NP-Difícil, observamos que las heurísticas que producen pseudoramas con aristas cruzadas a menudo generan tamaños de cálculo y mensajes significativamente más pequeños. 7. RESULTADOS EXPERIMENTALES 746 El Sexto Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Los métricos de rendimiento existentes para algoritmos DCOP incluyen el número total de mensajes, ciclos de reloj síncronos y tamaño de mensaje. Ya hemos demostrado que el número total de mensajes es lineal con respecto al número de restricciones en la instancia de DCOP. También introdujimos el costo de camino secuencial máximo (PC) como una medida de la máxima cantidad de paralelismo alcanzable por el algoritmo. El costo máximo de la ruta secuencial es igual a la suma de los cálculos realizados en la ruta más larga desde la raíz hasta cualquier nodo hoja. También incluimos como métricas el tamaño máximo de cálculo en número de dimensiones (CD) y el tamaño máximo de mensaje en número de dimensiones (MD). Para analizar la complejidad relativa de una instancia DCOP dada, encontramos el ancho inducido mínimo (IW) de cualquier pseudobosque tradicional producido por una heurística para el DPOP original. 7.1 Instancias genéricas de DCOP Para nuestras pruebas iniciales generamos aleatoriamente dos conjuntos de problemas con 3000 casos en cada uno. Cada problema fue generado asignando un número aleatorio (elegido de un rango) de restricciones a cada variable. El generador luego creó restricciones binarias hasta que cada variable alcanzó su número máximo de restricciones. El primer conjunto utiliza 20 variables, y el mejor DPOP IW varía de 1 a 16 con un promedio de 8.5. El segundo conjunto utiliza 100 variables, y el mejor DPOP IW osciló entre 2 y 68 con un promedio de 39.3. Dado que la mayoría de los problemas en el segundo conjunto eran demasiado complejos para calcular la solución, tomamos medidas de las métricas utilizando las técnicas descritas anteriormente en la Sección 5 sin resolver realmente el problema. Los resultados se muestran para el primer conjunto en la Tabla 1 y para el segundo conjunto en la Tabla 2. Para los dos conjuntos de problemas dividimos los casos en categorías de baja densidad y alta densidad. Los casos de baja densidad consisten en aquellos problemas que tienen un mejor DPOP IW menor o igual a la mitad del número total de nodos (por ejemplo, IW ≤ 10 para los problemas de 20 nodos e IW ≤ 50 para los problemas de 100 nodos. Los problemas de alta densidad consisten en el resto de los conjuntos de problemas. En ambas Tabla 1 y Tabla 2 hemos enumerado las métricas de rendimiento para el algoritmo DPOP original, el algoritmo DCPOP utilizando solo pseudobosques de bordes cruzados (DCPOP-CE), y el algoritmo DCPOP utilizando pseudobosques tradicionales y de bordes cruzados (DCPOP-All). Los pseudobosques utilizados para DPOP fueron generados utilizando 5 heurísticas: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB y DFS MCN BEC. Estas son todas las versiones del recorrido DFS guiado discutidas en la Sección 5. Los pseudobosques de bordes cruzados utilizados para DCPOP-CE fueron generados utilizando 5 heurísticas: MCN, LCN, MCN A-B, LCN A-B y LCSG A-B. Estas son todas las versiones del recorrido de mejor primero discutidas en la Sección 5. Para tanto DPOP como DCPOP-CE elegimos el mejor pseudoárbol producido por sus respectivas 5 heurísticas para cada problema en el conjunto. Para DCPOP-All elegimos la mejor pseudotree producida por las 10 heurísticas para cada problema en el conjunto. Para las métricas de CD y MD, el valor mostrado es el número promedio de dimensiones. Para la métrica de PC, el valor mostrado es el logaritmo natural del costo de ruta secuencial máximo (ya que el valor real crece exponencialmente con la complejidad del problema). La última fila en ambas tablas es una medida de mejora de DCPOP-All sobre DPOP. Para las métricas CD y MD, el valor mostrado es una reducción en el número de dimensiones. Para la métrica de PC, el valor mostrado es una reducción porcentual en el costo máximo de la ruta secuencial (% = DP OP −DCP OP DCP OP ∗ 100). Observa que DCPOP supera a DPOP en todas las métricas. Esto se sigue lógicamente de nuestra afirmación anterior de que, dada la misma entrada, DCPOP se comporta exactamente igual que DPOP. Así, dada la elección entre los pseudobosques producidos por las 10 heurísticas, DCPOP-All siempre superará a DCPOP-CE y DPOP. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 6: Mejora del Costo del Camino DCPOP Reunión Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Tabla 3: Problemas de Programación de Reuniones realizan DPOP. Otra tendencia que observamos es que la mejora es mayor para problemas de alta densidad que para problemas de baja densidad. Mostramos esta tendencia con mayor detalle en las Figuras 4, 5 y 6. Observa cómo la mejora aumenta a medida que aumenta la complejidad del problema. 7.2 Problema de Programación de Reuniones Además de nuestras pruebas genéricas iniciales de DCOP, realizamos una serie de pruebas en el Problema de Programación de Reuniones (MSP) como se describe en [6]. La configuración del problema incluye un número de personas agrupadas en departamentos. Cada persona debe asistir a un número específico de reuniones. Las reuniones pueden llevarse a cabo dentro de los departamentos o entre departamentos, y pueden asignarse a uno de los ocho horarios disponibles. El MSP se mapea a una instancia de DCOP donde cada variable representa el intervalo de tiempo en el que una persona específica asistirá a una reunión específica. Todas las variables que pertenecen a la misma persona tienen restricciones de exclusión mutua para que la persona no pueda asistir a más de una reunión durante el mismo intervalo de tiempo. Todas las variables que pertenecen a la misma reunión tienen restricciones de igualdad para que todos los participantes elijan el mismo horario. Se imponen restricciones unarias en cada variable para tener en cuenta la valoración de una persona de cada reunión y franja horaria. Para nuestros tests generamos 100 problemas de muestra para cada combinación de agentes y reuniones. Los resultados se muestran en la Tabla 3. Los valores en las primeras cinco columnas representan (en orden de izquierda a derecha), el número total de agentes, el número total de reuniones, el número total de variables, el promedio total de restricciones y el promedio mínimo de IW producido por un pseudoárbol tradicional. Las últimas tres columnas muestran las mismas métricas que utilizamos para las instancias genéricas de DCOP, excepto que esta vez solo mostramos las mejoras de DCPOP-All sobre DPOP. El rendimiento es mejor en promedio para todas las instancias de MSP, pero nuevamente vemos mejoras más grandes para instancias de problemas más complejos. 8. CONCLUSIONES Y TRABAJO FUTURO Presentamos un algoritmo completo y distribuido que resuelve instancias generales de DCOP utilizando arreglos de pseudoramas cruzados. Nuestro algoritmo extiende el algoritmo DPOP al agregar mensajes adicionales de propagación de utilidad e introducir el concepto de fusión de ramas durante la fase de propagación de utilidad. Nuestro algoritmo también permite que las asignaciones de valor ocurran en puntos de fusión de nivel superior para nodos de nivel inferior. Hemos demostrado que DCPOP extiende completamente DPOP al realizar las mismas operaciones dadas las mismas entradas. También hemos demostrado a través de algunos ejemplos y datos experimentales que DCPOP puede lograr un mejor rendimiento para algunas instancias del problema al extender el conjunto de entrada permitido para incluir pseudobosques cruzados. Damos especial énfasis al papel que desempeñan las heurísticas de recorrido de bordes en la generación de pseudobosques. Hemos demostrado que la penalización en el rendimiento es mínima para generar múltiples heurísticas, y que podemos elegir el mejor pseudoárbol generado en complejidad lineal de espacio-tiempo. Dada la importancia de un buen pseudoárbol para el rendimiento, el trabajo futuro incluirá nuevas heurísticas para encontrar mejores pseudo El trabajo futuro también incluirá adaptar las extensiones existentes de DPOP [5, 7] que soportan diferentes dominios de problemas para su uso con DCPOP. 9. REFERENCIAS [1] J. Liu y K. P. Sycara. Explotando la estructura del problema para la optimización distribuida de restricciones. En V. Lesser, editor, Actas de la Primera Conferencia Internacional sobre Sistemas Multiagente, páginas 246-254, San Francisco, CA, 1995. MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, y S. Kulkarni. Un enfoque dinámico distribuido de satisfacción de restricciones para la asignación de recursos. Notas de conferencia en Ciencias de la Computación, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe y M. Yokoo. Un método completo asíncrono para la optimización de restricciones distribuidas. En AAMAS 03, 2003. [4] A. Petcu. Frodo: Un marco para la optimización de restricciones abiertas/distribuidas. Informe técnico No. 2006/001, Instituto Federal Suizo de Tecnología (EPFL), Lausana (Suiza), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu y B. Faltings. A-dpop: Aproximaciones en optimización distribuida. En póster en CP 2005, páginas 802-806, Sitges, España, octubre de 2005. [6] A. Petcu y B. Faltings. Dpop: Un método escalable para la optimización de restricciones multiagente. En IJCAI 05, páginas 266-271, Edimburgo, Escocia, agosto de 2005. [7] A. Petcu, B. Faltings y D. Parkes. M-dpop: Implementación distribuida fiel de problemas eficientes de elección social. En AAMAS 06, páginas 1397-1404, Hakodate, Japón, mayo de 2006. [8] G. Ushakov. Resolviendo problemas de programación de reuniones utilizando un procedimiento de optimización distribuido de pseudobosque. Tesis de maestría, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida y K. Kuwabara. Satisfacción de restricciones distribuida para formalizar la resolución de problemas distribuidos. En la Conferencia Internacional sobre Sistemas de Computación Distribuida, páginas 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida y K. Kuwabara. El problema de satisfacción de restricciones distribuidas: Formalización y algoritmos. Ingeniería del Conocimiento y de Datos, 10(5):673-685, 1998. 748 La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "distribute constraint satisfaction and optimization": {
            "translated_key": "distribuir la satisfacción de restricciones y la optimización",
            "is_in_text": false,
            "original_annotated_sentences": [
                "A Complete Distributed Constraint Optimization Method For Non-Traditional Pseudotree Arrangements∗ James Atlas Computer and Information Sciences University of Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Computer and Information Sciences University of Delaware Newark, DE 19716 decker@cis.udel.edu ABSTRACT Distributed Constraint Optimization (DCOP) is a general framework that can model complex problems in multi-agent systems.",
                "Several current algorithms that solve general DCOP instances, including ADOPT and DPOP, arrange agents into a traditional pseudotree structure.",
                "We introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements.",
                "Our algorithm correctly solves DCOP instances for pseudotrees that include edges between nodes in separate branches.",
                "The algorithm also solves instances with traditional pseudotree arrangements using the same procedure as DPOP.",
                "We compare our algorithm with DPOP using several metrics including the induced width of the pseudotrees, the maximum dimensionality of messages and computation, and the maximum sequential path cost through the algorithm.",
                "We prove that for some problem instances it is not possible to generate a traditional pseudotree using edge-traversal heuristics that will outperform a cross-edged pseudotree.",
                "We use multiple heuristics to generate pseudotrees and choose the best pseudotree in linear space-time complexity.",
                "For some problem instances we observe significant improvements in message and computation sizes compared to DPOP.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent Systems General Terms Algorithms 1.",
                "INTRODUCTION Many historical problems in the AI community can be transformed into Constraint Satisfaction Problems (CSP).",
                "With the advent of distributed AI, multi-agent systems became a popular way to model the complex interactions and coordination required to solve distributed problems.",
                "CSPs were originally extended to distributed agent environments in [9].",
                "Early domains for distributed constraint satisfaction problems (DisCSP) included job shop scheduling [1] and resource allocation [2].",
                "Many domains for agent systems, especially teamwork coordination, distributed scheduling, and sensor networks, involve overly constrained problems that are difficult or impossible to satisfy for every constraint.",
                "Recent approaches to solving problems in these domains rely on optimization techniques that map constraints into multi-valued utility functions.",
                "Instead of finding an assignment that satisfies all constraints, these approaches find an assignment that produces a high level of global utility.",
                "This extension to the original DisCSP approach has become popular in multi-agent systems, and has been labeled the Distributed Constraint Optimization Problem (DCOP) [1].",
                "Current algorithms that solve complete DCOPs use two main approaches: search and dynamic programming.",
                "Search based algorithms that originated from DisCSP typically use some form of backtracking [10] or bounds propagation, as in ADOPT [3].",
                "Dynamic programming based algorithms include DPOP and its extensions [5, 6, 7].",
                "To date, both categories of algorithms arrange agents into a traditional pseudotree to solve the problem.",
                "It has been shown in [6] that any constraint graph can be mapped into a traditional pseudotree.",
                "However, it was also shown that finding the optimal pseudotree was NP-Hard.",
                "We began to investigate the performance of traditional pseudotrees generated by current edge-traversal heuristics.",
                "We found that these heuristics often produced little parallelism as the pseudotrees tended to have high depth and low branching factors.",
                "We suspected that there could be other ways to arrange the pseudotrees that would provide increased parallelism and smaller message sizes.",
                "After exploring these other arrangements we found that cross-edged pseudotrees provide shorter depths and higher branching factors than the traditional pseudotrees.",
                "Our hypothesis was that these crossedged pseudotrees would outperform traditional pseudotrees for some problem types.",
                "In this paper we introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements which include cross-edged pseudotrees.",
                "We begin with a definition of 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, traditional pseudotrees, and cross-edged pseudotrees.",
                "We then provide a summary of the original DPOP algorithm and introduce our DCPOP algorithm.",
                "We discuss the complexity of our algorithm as well as the impact of pseudotree generation heuristics.",
                "We then show that our Distributed Cross-edged Pseudotree Optimization Procedure (DCPOP) performs significantly better in practice than the original DPOP algorithm for some problem instances.",
                "We conclude with a selection of ideas for future work and extensions for DCPOP. 2.",
                "PROBLEM DEFINITION DCOP has been formalized in slightly different ways in recent literature, so we will adopt the definition as presented in [6].",
                "A Distributed Constraint Optimization Problem with n nodes and m constraints consists of the tuple < X, D, U > where: • X = {x1,..,xn} is a set of variables, each one assigned to a unique agent • D = {d1,..,dn} is a set of finite domains for each variable • U = {u1,..,um} is a set of utility functions such that each function involves a subset of variables in X and defines a utility for each combination of values among these variables An optimal solution to a DCOP instance consists of an assignment of values in D to X such that the sum of utilities in U is maximal.",
                "Problem domains that require minimum cost instead of maximum utility can map costs into negative utilities.",
                "The utility functions represent soft constraints but can also represent hard constraints by using arbitrarily large negative values.",
                "For this paper we only consider binary utility functions involving two variables.",
                "Higher order utility functions can be modeled with minor changes to the algorithm, but they also substantially increase the complexity. 2.1 Traditional Pseudotrees Pseudotrees are a common structure used in search procedures to allow parallel processing of independent branches.",
                "As defined in [6], a pseudotree is an arrangement of a graph G into a rooted tree T such that vertices in G that share an edge are in the same branch in T. A back-edge is an edge between a node X and any node which lies on the path from X to the root (excluding Xs parent).",
                "Figure 1 shows a pseudotree with four nodes, three edges (A-B, B-C, BD), and one back-edge (A-C).",
                "Also defined in [6] are four types of relationships between nodes exist in a pseudotree: • P(X) - the parent of a node X: the single node higher in the pseudotree that is connected to X directly through a tree edge • C(X) - the children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through tree edges • PP(X) - the pseudo-parents of a node X: the set of nodes higher in the pseudotree that are connected to X directly through back-edges (In Figure 1, A = PP(C)) • PC(X) - the pseudo-children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through back-edges (In Figure 1, C = PC(A)) Figure 1: A traditional pseudotree.",
                "Solid line edges represent parent-child relationships and the dashed line represents a pseudo-parent-pseudo-child relationship.",
                "Figure 2: A cross-edged pseudotree.",
                "Solid line edges represent parent-child relationships, the dashed line represents a pseudoparent-pseudo-child relationship, and the dotted line represents a branch-parent-branch-child relationship.",
                "The bolded node, B, is the merge point for node E. 2.2 Cross-edged Pseudotrees We define a cross-edge as an edge from node X to a node Y that is above X but not in the path from X to the root.",
                "A cross-edged pseudotree is a traditional pseudotree with the addition of cross-edges.",
                "Figure 2 shows a cross-edged pseudotree with a cross-edge (D-E).",
                "In a cross-edged pseudotree we designate certain edges as primary.",
                "The set of primary edges defines a spanning tree of the nodes.",
                "The parent, child, pseudo-parent, and pseudo-child relationships from the traditional pseudotree are now defined in the context of this primary edge spanning tree.",
                "This definition also yields two additional types of relationships that may exist between nodes: • BP(X) - the branch-parents of a node X: the set of nodes higher in the pseudotree that are connected to X but are not in the primary path from X to the root (In Figure 2, D = BP(E)) • BC(X) - the branch-children of a node X: the set of nodes lower in the pseudotree that are connected to X but are not in any primary path from X to any leaf node (In Figure 2, E = BC(D)) 2.3 Pseudotree Generation 742 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Current algorithms usually have a pre-execution phase to generate a traditional pseudotree from a general DCOP instance.",
                "Our DCPOP algorithm generates a cross-edged pseudotree in the same fashion.",
                "First, the DCOP instance < X, D, U > translates directly into a graph with X as the set of vertices and an edge for each pair of variables represented in U.",
                "Next, various heuristics are used to arrange this graph into a pseudotree.",
                "One common heuristic is to perform a guided depth-first search (DFS) as the resulting traversal is a pseudotree, and a DFS can easily be performed in a distributed fashion.",
                "We define an edge-traversal based method as any method that produces a pseudotree in which all parent/child pairs share an edge in the original graph.",
                "This includes DFS, breadth-first search, and best-first search based traversals.",
                "Our heuristics that generate cross-edged pseudotrees use a distributed best-first search traversal. 3.",
                "DPOP ALGORITHM The original DPOP algorithm operates in three main phases.",
                "The first phase generates a traditional pseudotree from the DCOP instance using a distributed algorithm.",
                "The second phase joins utility hypercubes from children and the local node and propagates them towards the root.",
                "The third phase chooses an assignment for each domain in a top down fashion beginning with the agent at the root node.",
                "The complexity of DPOP depends on the size of the largest computation and utility message during phase two.",
                "It has been shown that this size directly corresponds to the induced width of the pseudotree generated in phase one [6].",
                "DPOP uses polynomial time heuristics to generate the pseudotree since finding the minimum induced width pseudotree is NP-hard.",
                "Several distributed edgetraversal heuristics have been developed to find low width pseudotrees [8].",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, and pseudo-children. 3.1 Utility Propagation Agents located at leaf nodes in the pseudotree begin the process by calculating a local utility hypercube.",
                "This hypercube at node X contains summed utilities for each combination of values in the domains for P(X) and PP(X).",
                "This hypercube has dimensional size equal to the number of pseudo-parents plus one.",
                "A message containing this hypercube is sent to P(X).",
                "Agents located at non-leaf nodes wait for all messages from children to arrive.",
                "Once the agent at node Y has all utility messages, it calculates its local utility hypercube which includes domains for P(Y), PP(Y), and Y.",
                "The local utility hypercube is then joined with all of the hypercubes from the child messages.",
                "At this point all utilities involving node Y are known, and the domain for Y may be safely eliminated from the joined hypercube.",
                "This elimination process chooses the best utility over the domain of Y for each combination of the remaining domains.",
                "A message containing this hypercube is now sent to P(Y).",
                "The dimensional size of this hypercube depends on the number of overlapping domains in received messages and the local utility hypercube.",
                "This dynamic programming based propagation phase continues until the agent at the root node of the pseudotree has received all messages from its children. 3.2 Value Propagation Value propagation begins when the agent at the root node Z has received all messages from its children.",
                "Since Z has no parents or pseudo-parents, it simply combines the utility hypercubes received from its children.",
                "The combined hypercube contains only values for the domain for Z.",
                "At this point the agent at node Z simply chooses the assignment for its domain that has the best utility.",
                "A value propagation message with this assignment is sent to each node in C(Z).",
                "Each other node then receives a value propagation message from its parent and chooses the assignment for its domain that has the best utility given the assignments received in the message.",
                "The node adds its domain assignment to the assignments it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen an assignment for their domain. 4.",
                "DCPOP ALGORITHM Our extension to the original DPOP algorithm, shown in Algorithm 1, shares the same three phases.",
                "The first phase generates the cross-edged pseudotree for the DCOP instance.",
                "The second phase merges branches and propagates the utility hypercubes.",
                "The third phase chooses assignments for domains at branch merge points and in a top down fashion, beginning with the agent at the root node.",
                "For the first phase we generate a pseudotree using several distributed heuristics and select the one with lowest overall complexity.",
                "The complexity of the computation and utility message size in DCPOP does not directly correspond to the induced width of the cross-edged pseudotree.",
                "Instead, we use a polynomial time method for calculating the maximum computation and utility message size for a given cross-edged pseudotree.",
                "A description of this method and the pseudotree selection process appears in Section 5.",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, pseudo-children, branch-parents, and branch-children. 4.1 Merging Branches and Utility Propagation In the original DPOP algorithm a node X only had utility functions involving its parent and its pseudo-parents.",
                "In DCPOP, a node X is allowed to have a utility function involving a branch-parent.",
                "The concept of a branch can be seen in Figure 2 with node E representing our node X.",
                "The two distinct paths from node E to node B are called branches of E. The single node where all branches of E meet is node B, which is called the merge point of E. Agents with nodes that have branch-parents begin by sending a utility propagation message to each branch-parent.",
                "This message includes a two dimensional utility hypercube with domains for the node X and the branch-parent BP(X).",
                "It also includes a branch information structure which contains the origination node of the branch, X, the total number of branches originating from X, and the number of branches originating from X that are merged into a single representation by this branch information structure (this number starts at 1).",
                "Intuitively when the number of merged branches equals the total number of originating branches, the algorithm has reached the merge point for X.",
                "In Figure 2, node E sends a utility propagation message to its branch-parent, node D. This message has dimensions for the domains of E and D, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "As in the original DPOP utility propagation phase, an agent at leaf node X sends a utility propagation message to its parent.",
                "In DCPOP this message contains dimensions for the domains of P(X) and PP(X).",
                "If node X also has branch-parents, then the utility propagation message also contains a dimension for the domain of X, and will include a branch information structure.",
                "In Figure 2, node E sends a utility propagation message to its parent, node C. This message has dimensions for the domains of E and C, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "When a node Y receives utility propagation messages from all of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 743 its children and branch-children, it merges any branches with the same origination node X.",
                "The merged branch information structure accumulates the number of merged branches for X.",
                "If the cumulative total number of merged branches equals the total number of branches, then Y is the merge point for X.",
                "This means that the utility hypercubes present at Y contain all information about the valuations for utility functions involving node X.",
                "In addition to the typical elimination of the domain of Y from the utility hypercubes, we can now safely eliminate the domain of X from the utility hypercubes.",
                "To illustrate this process, we will examine what happens in the second phase for node B in Figure 2.",
                "In the second phase Node B receives two utility propagation messages.",
                "The first comes from node C and includes dimensions for domains E, B, and A.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "The second comes from node D and includes dimensions for domains E and B.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "Node B then merges the branch information structures from both messages because they have the same origination, node E. Since the number of merged branches originating from E is now 2 and the total branches originating from E is 2, node B now eliminates the dimensions for domain E. Node B also eliminates the dimension for its own domain, leaving only information about domain A. Node B then sends a utility propagation message to node A, containing only one dimension for the domain of A.",
                "Although not possible in DPOP, this method of utility propagation and dimension elimination may produce hypercubes at node Y that do not share any domains.",
                "In DCPOP we do not join domain independent hypercubes, but instead may send multiple hypercubes in the utility propagation message sent to the parent of Y.",
                "This lazy approach to joins helps to reduce message sizes. 4.2 Value Propagation As in DPOP, value propagation begins when the agent at the root node Z has received all messages from its children.",
                "At this point the agent at node Z chooses the assignment for its domain that has the best utility.",
                "If Z is the merge point for the branches of some node X, Z will also choose the assignment for the domain of X.",
                "Thus any node that is a merge point will choose assignments for a domain other than its own.",
                "These assignments are then passed down the primary edge hierarchy.",
                "If node X in the hierarchy has branch-parents, then the value assignment message from P(X) will contain an assignment for the domain of X.",
                "Every node in the hierarchy adds any assignments it has chosen to the ones it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen or received an assignment for their domain. 4.3 Proof of Correctness We will prove the correctness of DCPOP by first noting that DCPOP fully extends DPOP and then examining the two cases for value assignment in DCPOP.",
                "Given a traditional pseudotree as input, the DCPOP algorithm execution is identical to DPOP.",
                "Using a traditional pseudotree arrangement no nodes have branch-parents or branch-children since all edges are either back-edges or tree edges.",
                "Thus the DCPOP algorithm using a traditional pseudotree sends only utility propagation messages that contain domains belonging to the parent or pseudo-parents of a node.",
                "Since no node has any branch-parents, no branches exist, and thus no node serves as a merge point for any other node.",
                "Thus all value propagation assignments are chosen at the node of the assignment domain.",
                "For DCPOP execution with cross-edged pseudotrees, some nodes serve as merge points.",
                "We note that any node X that is not a merge point assigns its value exactly as in DPOP.",
                "The local utility hypercube at X contains domains for X, P(X), PP(X), and BC(X).",
                "As in DPOP the value assignment message received at X includes the values assigned to P(X) and PP(X).",
                "Also, since X is not a merge point, all assignments to BC(X) must have been calculated at merge points higher in the tree and are in the value assignment message from P(X).",
                "Thus after eliminating domains for which assignments are known, only the domain of X is left.",
                "The agent at node X can now correctly choose the assignment with maximum utility for its own domain.",
                "If node X is a merge point for some branch-child Y, we know that X must be a node along the path from Y to the root, and from P(Y) and all BP(Y) to the root.",
                "From the algorithm, we know that Y necessarily has all information from C(Y), PC(Y), and BC(Y) since it waits for their messages.",
                "Node X has information about all nodes below it in the tree, which would include Y, P(Y), BP(Y), and those PP(Y) that are below X in the tree.",
                "For any PP(Y) above X in the tree, X receives the assignment for the domain of PP(Y) in the value assignment message from P(X).",
                "Thus X has utility information about all of the utility functions of which Y is a part.",
                "By eliminating domains included in the value assignment message, node X is left with a local utility hypercube with domains for X and Y.",
                "The agent at node X can now correctly choose the assignments with maximum utility for the domains of X and Y. 4.4 Complexity Analysis The first phase of DCPOP sends one message to each P(X), PP(X), and BP(X).",
                "The second phase sends one value assignment message to each C(X).",
                "Thus, DCPOP produces a linear number of messages with respect to the number of edges (utility functions) in the cross-edged pseudotree and the original DCOP instance.",
                "The actual complexity of DCPOP depends on two additional measurements: message size and computation size.",
                "Message size and computation size in DCPOP depend on the number of overlapping branches as well as the number of overlapping back-edges.",
                "It was shown in [6] that the number of overlapping back-edges is equal to the induced width of the pseudotree.",
                "In a poorly constructed cross-edged pseudotree, the number of overlapping branches at node X can be as large as the total number of descendants of X.",
                "Thus, the total message size in DCPOP in a poorly constructed instance can be space-exponential in the total number of nodes in the graph.",
                "However, in practice a well constructed cross-edged pseudotree can achieve much better results.",
                "Later we address the issue of choosing well constructed crossedged pseudotrees from a set.",
                "We introduce an additional measurement of the maximum sequential path cost through the algorithm.",
                "This measurement directly relates to the maximum amount of parallelism achievable by the algorithm.",
                "To take this measurement we first store the total computation size for each node during phase two and three.",
                "This computation size represents the number of individual accesses to a value in a hypercube at each node.",
                "For example, a join between two domains of size 4 costs 4 ∗ 4 = 16.",
                "Two directed acyclic graphs (DAG) can then be drawn; one with the utility propagation messages as edges and the phase two costs at nodes, and the other with value assignment messages and the phase three costs at nodes.",
                "The maximum sequential path cost is equal to the sum of the longest path on each DAG from the root to any leaf node. 5.",
                "HEURISTICS In our assessment of complexity in DCPOP we focused on the worst case possibly produced by the algorithm.",
                "We acknowledge 744 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Algorithm 1 DCPOP Algorithm 1: DCPOP(X; D; U) Each agent Xi executes: Phase 1: pseudotree creation 2: elect leader from all Xj ∈ X 3: elected leader initiates pseudotree creation 4: afterwards, Xi knows P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) and PC(Xi) Phase 2: UTIL message propagation 5: if |BP(Xi)| > 0 then 6: BRANCHXi ← |BP(Xi)| + 1 7: for all Xk ∈BP(Xi) do 8: UTILXi (Xk) ←Compute utils(Xi, Xk) 9: Send message(Xk,UTILXi (Xk),BRANCHXi ) 10: if |C(Xi)| = 0(i.e.",
                "Xi is a leaf node) then 11: UTILXi (P(Xi)) ← Compute utils(P(Xi),PP(Xi)) for all PP(Xi) 12: Send message(P(Xi), UTILXi (P(Xi)),BRANCHXi ) 13: Send message(PP(Xi), empty UTIL, empty BRANCH) to all PP(Xi) 14: activate UTIL Message handler() Phase 3: VALUE message propagation 15: activate VALUE Message handler() END ALGORITHM UTIL Message handler(Xk,UTILXk (Xi), BRANCHXk ) 16: store UTILXk (Xi),BRANCHXk (Xi) 17: if UTIL messages from all children and branch children arrived then 18: for all Bj ∈BRANCH(Xi) do 19: if Bj is merged then 20: join all hypercubes where Bj ∈UTIL(Xi) 21: eliminate Bj from the joined hypercube 22: if P(Xi) == null (that means Xi is the root) then 23: v ∗ i ← Choose optimal(null) 24: Send VALUE(Xi, v ∗ i) to all C(Xi) 25: else 26: UTILXi (P(Xi)) ← Compute utils(P(Xi), PP(Xi)) 27: Send message(P(Xi),UTILXi (P(Xi)), BRANCHXi (P(Xi))) VALUE Message handler(VALUEXi ,P(Xi)) 28: add all Xk ← v ∗ k ∈VALUEXi ,P(Xi) to agent view 29: Xi ← v ∗ i =Choose optimal(agent view) 30: Send VALUEXl , Xi to all Xl ∈C(Xi) that in real world problems the generation of the pseudotree has a significant impact on the actual performance.",
                "The problem of finding the best pseudotree for a given DCOP instance is NP-Hard.",
                "Thus a heuristic is used for generation, and the performance of the algorithm depends on the pseudotree found by the heuristic.",
                "Some previous research focused on finding heuristics to generate good pseudotrees [8].",
                "While we have developed some heuristics that generate good cross-edged pseudotrees for use with DCPOP, our focus has been to use multiple heuristics and then select the best pseudotree from the generated pseudotrees.",
                "We consider only heuristics that run in polynomial time with respect to the number of nodes in the original DCOP instance.",
                "The actual DCPOP algorithm has worst case exponential complexity, but we can calculate the maximum message size, computation size, and sequential path cost for a given cross-edged pseudotree in linear space-time complexity.",
                "To do this, we simply run the algorithm without attempting to calculate any of the local utility hypercubes or optimal value assignments.",
                "Instead, messages include dimensional and branch information but no utility hypercubes.",
                "After each heuristic completes its generation of a pseudotree, we execute the measurement procedure and propagate the measurement information up to the chosen root in that pseudotree.",
                "The root then broadcasts the total complexity for that heuristic to all nodes.",
                "After all heuristics have had a chance to complete, every node knows which heuristic produced the best pseudotree.",
                "Each node then proceeds to begin the DCPOP algorithm using its knowledge of the pseudotree generated by the best heuristic.",
                "The heuristics used to generate traditional pseudotrees perform a distributed DFS traversal.",
                "The general distributed algorithm uses a token passing mechanism and a linear number of messages.",
                "Improved DFS based heuristics use a special procedure to choose the root node, and also provide an ordering function over the neighbors of a node to determine the order of path recursion.",
                "The DFS based heuristics used in our experiments come from the work done in [4, 8]. 5.1 The best-first cross-edged pseudotree heuristic The heuristics used to generate cross-edged pseudotrees perform a best-first traversal.",
                "A general distributed best-first algorithm for node expansion is presented in Algorithm 2.",
                "An evaluation function at each node provides the values that are used to determine the next best node to expand.",
                "Note that in this algorithm each node only exchanges its best value with its neighbors.",
                "In our experiments we used several evaluation functions that took as arguments an ordered list of ancestors and a node, which contains a list of neighbors (with each neighbors placement depth in the tree if it was placed).",
                "From these we can calculate branchparents, branch-children, and unknown relationships for a potential node placement.",
                "The best overall function calculated the value as ancestors−(branchparents+branchchildren) with the number of unknown relationships being a tiebreak.",
                "After completion each node has knowledge of its parent and ancestors, so it can easily determine which connected nodes are pseudo-parents, branchparents, pseudo-children, and branch-children.",
                "The complexity of the best-first traversal depends on the complexity of the evaluation function.",
                "Assuming a complexity of O(V ) for the evaluation function, which is the case for our best overall function, the best-first traversal is O(V · E) which is at worst O(n3 ).",
                "For each v ∈ V we perform a place operation, and find the next node to place using the getBestNeighbor operation.",
                "The place operation is at most O(V ) because of the sent messages.",
                "Finding the next node uses recursion and traverses only already placed The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 745 Algorithm 2 Distributed Best-First Search Algorithm root ← electedleader next(root, ∅) place(node, parent) node.parent ← parent node.ancestors ← parent.ancestors ∪ parent send placement message (node, node.ancestors) to all neighbors of node next(current, previous) if current is not placed then place(current, previous) next(current, ∅) else best ← getBestNeighbor(current, previous) if best = ∅ then if previous = ∅ then terminate, all nodes are placed next(previous, ∅) else next(best, current) getBestNeighbor(current, previous) best ← ∅; score ← 0 for all n ∈ current.neighbors do if n! = previous then if n is placed then nscore ← getBestNeighbor(n, current) else nscore ← evaluate(current, n) if nscore > score then score ← nscore best ← n return best, score nodes, so it has O(V ) recursions.",
                "Each recursion performs a recursive getBestNeighbor operation that traverses all placed nodes and their neighbors.",
                "This operation is O(V · E), but results can be cached using only O(V ) space at each node.",
                "Thus we have O(V ·(V +V +V ·E)) = O(V 2 ·E).",
                "If we are smart about evaluating local changes when each node receives placement messages from its neighbors and cache the results the getBestNeighbor operation is only O(E).",
                "This increases the complexity of the place operation, but for all placements the total complexity is only O(V · E).",
                "Thus we have an overall complexity of O(V ·E+V ·(V +E)) = O(V ·E). 6.",
                "COMPARISON OF COMPLEXITY IN DPOP AND DCPOP We have already shown that given the same input, DCPOP performs the same as DPOP.",
                "We also have shown that we can accurately predict performance of a given pseudotree in linear spacetime complexity.",
                "If we use a constant number of heuristics to generate the set of pseudotrees, we can choose the best pseudotree in linear space-time complexity.",
                "We will now show that there exists a DCOP instance for which a cross-edged pseudotree outperforms all possible traditional pseudotrees (based on edge-traversal heuristics).",
                "In Figure 3(a) we have a DCOP instance with six nodes.",
                "This is a bipartite graph with each partition fully connected to the other (a) (b) (c) Figure 3: (a) The DCOP instance (b) A traditional pseudotree arrangement for the DCOP instance (c) A cross-edged pseudotree arrangement for the DCOP instance partition.",
                "In Figure 3(b) we see a traditional pseudotree arrangement for this DCOP instance.",
                "It is easy to see that any edgetraversal based heuristic cannot expand two nodes from the same partition in succession.",
                "We also see that no node can have more than one child because any such arrangement would be an invalid pseudotree.",
                "Thus any traditional pseudotree arrangement for this DCOP instance must take the form of Figure 3(b).",
                "We can see that the back-edges F-B and F-A overlap node C. Node C also has a parent E, and a back-edge with D. Using the original DPOP algorithm (or DCPOP since they are identical in this case), we find that the computation at node C involves five domains: A, B, C, D, and E. In contrast, the cross-edged pseudotree arrangement in Figure 3(c) requires only a maximum of four domains in any computation during DCPOP.",
                "Since node A is the merge point for branches from both B and C, we can see that each of the nodes D, E, and F have two overlapping branches.",
                "In addition each of these nodes has node A as its parent.",
                "Using the DCPOP algorithm we find that the computation at node D (or E or F) involves four domains: A, B, C, and D (or E or F).",
                "Since no better traditional pseudotree arrangement can be created using an edge-traversal heuristic, we have shown that DCPOP can outperform DPOP even if we use the optimal pseudotree found through edge-traversal.",
                "We acknowledge that pseudotree arrangements that allow parent-child relationships without an actual constraint can solve the problem in Figure 3(a) with maximum computation size of four domains.",
                "However, current heuristics used with DPOP do not produce such pseudotrees, and such a heuristic would be difficult to distribute since each node would require information about nodes with which it has no constraint.",
                "Also, while we do not prove it here, cross-edged pseudotrees can produce smaller message sizes than such pseudotrees even if the computation size is similar.",
                "In practice, since finding the best pseudotree arrangement is NP-Hard, we find that heuristics that produce cross-edged pseudotrees often produce significantly smaller computation and message sizes. 7.",
                "EXPERIMENTAL RESULTS 746 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Existing performance metrics for DCOP algorithms include the total number of messages, synchronous clock cycles, and message size.",
                "We have already shown that the total number of messages is linear with respect to the number of constraints in the DCOP instance.",
                "We also introduced the maximum sequential path cost (PC) as a measurement of the maximum amount of parallelism achievable by the algorithm.",
                "The maximum sequential path cost is equal to the sum of the computations performed on the longest path from the root to any leaf node.",
                "We also include as metrics the maximum computation size in number of dimensions (CD) and maximum message size in number of dimensions (MD).",
                "To analyze the relative complexity of a given DCOP instance, we find the minimum induced width (IW) of any traditional pseudotree produced by a heuristic for the original DPOP. 7.1 Generic DCOP instances For our initial tests we randomly generated two sets of problems with 3000 cases in each.",
                "Each problem was generated by assigning a random number (picked from a range) of constraints to each variable.",
                "The generator then created binary constraints until each variable reached its maximum number of constraints.",
                "The first set uses 20 variables, and the best DPOP IW ranges from 1 to 16 with an average of 8.5.",
                "The second set uses 100 variables, and the best DPOP IW ranged from 2 to 68 with an average of 39.3.",
                "Since most of the problems in the second set were too complex to actually compute the solution, we took measurements of the metrics using the techniques described earlier in Section 5 without actually solving the problem.",
                "Results are shown for the first set in Table 1 and for the second set in Table 2.",
                "For the two problem sets we split the cases into low density and high density categories.",
                "Low density cases consist of those problems that have a best DPOP IW less than or equal to half of the total number of nodes (e.g.",
                "IW ≤ 10 for the 20 node problems and IW ≤ 50 for the 100 node problems).",
                "High density problems consist of the remainder of the problem sets.",
                "In both Table 1 and Table 2 we have listed performance metrics for the original DPOP algorithm, the DCPOP algorithm using only cross-edged pseudotrees (DCPOP-CE), and the DCPOP algorithm using traditional and cross-edged pseudotrees (DCPOP-All).",
                "The pseudotrees used for DPOP were generated using 5 heuristics: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB, and DFS MCN BEC.",
                "These are all versions of the guided DFS traversal discussed in Section 5.",
                "The cross-edged pseudotrees used for DCPOP-CE were generated using 5 heuristics: MCN, LCN, MCN A-B, LCN A-B, and LCSG A-B.",
                "These are all versions of the best-first traversal discussed in Section 5.",
                "For both DPOP and DCPOP-CE we chose the best pseudotree produced by their respective 5 heuristics for each problem in the set.",
                "For DCPOP-All we chose the best pseudotree produced by all 10 heuristics for each problem in the set.",
                "For the CD and MD metrics the value shown is the average number of dimensions.",
                "For the PC metric the value shown is the natural logarithm of the maximum sequential path cost (since the actual value grows exponentially with the complexity of the problem).",
                "The final row in both tables is a measurement of improvement of DCPOP-All over DPOP.",
                "For the CD and MD metrics the value shown is a reduction in number of dimensions.",
                "For the PC metric the value shown is a percentage reduction in the maximum sequential path cost (% = DP OP −DCP OP DCP OP ∗ 100).",
                "Notice that DCPOPAll outperforms DPOP on all metrics.",
                "This logically follows from our earlier assertion that given the same input, DCPOP performs exactly the same as DPOP.",
                "Thus given the choice between the pseudotrees produced by all 10 heuristics, DCPOP-All will always outLow Density High Density Algorithm CD MD PC CD MD PC DPOP 7.81 6.81 3.78 13.34 12.34 5.34 DCPOP-CE 7.94 6.73 3.74 12.83 11.43 5.07 DCPOP-All 7.62 6.49 3.66 12.72 11.36 5.05 Improvement 0.18 0.32 13% 0.62 0.98 36% Table 1: 20 node problems Low Density High Density Algorithm CD MD PC CD MD PC DPOP 33.35 32.35 14.55 58.51 57.50 19.90 DCPOP-CE 33.49 29.17 15.22 57.11 50.03 20.01 DCPOP-All 32.35 29.57 14.10 56.33 51.17 18.84 Improvement 1.00 2.78 104% 2.18 6.33 256% Table 2: 100 node problems Figure 4: Computation Dimension Size Figure 5: Message Dimension Size The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 747 Figure 6: Path Cost DCPOP Improvement Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Table 3: Meeting Scheduling Problems perform DPOP.",
                "Another trend we notice is that the improvement is greater for high density problems than low density problems.",
                "We show this trend in greater detail in Figures 4, 5, and 6.",
                "Notice how the improvement increases as the complexity of the problem increases. 7.2 Meeting Scheduling Problem In addition to our initial generic DCOP tests, we ran a series of tests on the Meeting Scheduling Problem (MSP) as described in [6].",
                "The problem setup includes a number of people that are grouped into departments.",
                "Each person must attend a specified number of meetings.",
                "Meetings can be held within departments or among departments, and can be assigned to one of eight time slots.",
                "The MSP maps to a DCOP instance where each variable represents the time slot that a specific person will attend a specific meeting.",
                "All variables that belong to the same person have mutual exclusion constraints placed so that the person cannot attend more than one meeting during the same time slot.",
                "All variables that belong to the same meeting have equality constraints so that all of the participants choose the same time slot.",
                "Unary constraints are placed on each variable to account for a persons valuation of each meeting and time slot.",
                "For our tests we generated 100 sample problems for each combination of agents and meetings.",
                "Results are shown in Table 3.",
                "The values in the first five columns represent (in left to right order), the total number of agents, the total number of meetings, the total number of variables, the average total number of constraints, and the average minimum IW produced by a traditional pseudotree.",
                "The last three columns show the same metrics we used for the generic DCOP instances, except this time we only show the improvements of DCPOP-All over DPOP.",
                "Performance is better on average for all MSP instances, but again we see larger improvements for more complex problem instances. 8.",
                "CONCLUSIONS AND FUTURE WORK We presented a complete, distributed algorithm that solves general DCOP instances using cross-edged pseudotree arrangements.",
                "Our algorithm extends the DPOP algorithm by adding additional utility propagation messages, and introducing the concept of branch merging during the utility propagation phase.",
                "Our algorithm also allows value assignments to occur at higher level merge points for lower level nodes.",
                "We have shown that DCPOP fully extends DPOP by performing the same operations given the same input.",
                "We have also shown through some examples and experimental data that DCPOP can achieve greater performance for some problem instances by extending the allowable input set to include cross-edged pseudotrees.",
                "We placed particular emphasis on the role that edge-traversal heuristics play in the generation of pseudotrees.",
                "We have shown that the performance penalty is minimal to generate multiple heuristics, and that we can choose the best generated pseudotree in linear space-time complexity.",
                "Given the importance of a good pseudotree for performance, future work will include new heuristics to find better pseudotrees.",
                "Future work will also include adapting existing DPOP extensions [5, 7] that support different problem domains for use with DCPOP. 9.",
                "REFERENCES [1] J. Liu and K. P. Sycara.",
                "Exploiting problem structure for distributed constraint optimization.",
                "In V. Lesser, editor, Proceedings of the First International Conference on Multi-Agent Systems, pages 246-254, San Francisco, CA, 1995.",
                "MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni.",
                "A dynamic distributed constraint satisfaction approach to resource allocation.",
                "Lecture Notes in Computer Science, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe, and M. Yokoo.",
                "An asynchronous complete method for distributed constraint optimization.",
                "In AAMAS 03, 2003. [4] A. Petcu.",
                "Frodo: A framework for open/distributed constraint optimization.",
                "Technical Report No. 2006/001 2006/001, Swiss Federal Institute of Technology (EPFL), Lausanne (Switzerland), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu and B. Faltings.",
                "A-dpop: Approximations in distributed optimization.",
                "In poster in CP 2005, pages 802-806, Sitges, Spain, October 2005. [6] A. Petcu and B. Faltings.",
                "Dpop: A scalable method for multiagent constraint optimization.",
                "In IJCAI 05, pages 266-271, Edinburgh, Scotland, Aug 2005. [7] A. Petcu, B. Faltings, and D. Parkes.",
                "M-dpop: Faithful distributed implementation of efficient social choice problems.",
                "In AAMAS 06, pages 1397-1404, Hakodate, Japan, May 2006. [8] G. Ushakov.",
                "Solving meeting scheduling problems using distributed pseudotree-optimization procedure.",
                "Masters thesis, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "Distributed constraint satisfaction for formalizing distributed problem solving.",
                "In International Conference on Distributed Computing Systems, pages 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "The distributed constraint satisfaction problem: Formalization and algorithms.",
                "Knowledge and Data Engineering, 10(5):673-685, 1998. 748 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "multi-agent coordination": {
            "translated_key": "coordinación de múltiples agentes",
            "is_in_text": false,
            "original_annotated_sentences": [
                "A Complete Distributed Constraint Optimization Method For Non-Traditional Pseudotree Arrangements∗ James Atlas Computer and Information Sciences University of Delaware Newark, DE 19716 atlas@cis.udel.edu Keith Decker Computer and Information Sciences University of Delaware Newark, DE 19716 decker@cis.udel.edu ABSTRACT Distributed Constraint Optimization (DCOP) is a general framework that can model complex problems in multi-agent systems.",
                "Several current algorithms that solve general DCOP instances, including ADOPT and DPOP, arrange agents into a traditional pseudotree structure.",
                "We introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements.",
                "Our algorithm correctly solves DCOP instances for pseudotrees that include edges between nodes in separate branches.",
                "The algorithm also solves instances with traditional pseudotree arrangements using the same procedure as DPOP.",
                "We compare our algorithm with DPOP using several metrics including the induced width of the pseudotrees, the maximum dimensionality of messages and computation, and the maximum sequential path cost through the algorithm.",
                "We prove that for some problem instances it is not possible to generate a traditional pseudotree using edge-traversal heuristics that will outperform a cross-edged pseudotree.",
                "We use multiple heuristics to generate pseudotrees and choose the best pseudotree in linear space-time complexity.",
                "For some problem instances we observe significant improvements in message and computation sizes compared to DPOP.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent Systems General Terms Algorithms 1.",
                "INTRODUCTION Many historical problems in the AI community can be transformed into Constraint Satisfaction Problems (CSP).",
                "With the advent of distributed AI, multi-agent systems became a popular way to model the complex interactions and coordination required to solve distributed problems.",
                "CSPs were originally extended to distributed agent environments in [9].",
                "Early domains for distributed constraint satisfaction problems (DisCSP) included job shop scheduling [1] and resource allocation [2].",
                "Many domains for agent systems, especially teamwork coordination, distributed scheduling, and sensor networks, involve overly constrained problems that are difficult or impossible to satisfy for every constraint.",
                "Recent approaches to solving problems in these domains rely on optimization techniques that map constraints into multi-valued utility functions.",
                "Instead of finding an assignment that satisfies all constraints, these approaches find an assignment that produces a high level of global utility.",
                "This extension to the original DisCSP approach has become popular in multi-agent systems, and has been labeled the Distributed Constraint Optimization Problem (DCOP) [1].",
                "Current algorithms that solve complete DCOPs use two main approaches: search and dynamic programming.",
                "Search based algorithms that originated from DisCSP typically use some form of backtracking [10] or bounds propagation, as in ADOPT [3].",
                "Dynamic programming based algorithms include DPOP and its extensions [5, 6, 7].",
                "To date, both categories of algorithms arrange agents into a traditional pseudotree to solve the problem.",
                "It has been shown in [6] that any constraint graph can be mapped into a traditional pseudotree.",
                "However, it was also shown that finding the optimal pseudotree was NP-Hard.",
                "We began to investigate the performance of traditional pseudotrees generated by current edge-traversal heuristics.",
                "We found that these heuristics often produced little parallelism as the pseudotrees tended to have high depth and low branching factors.",
                "We suspected that there could be other ways to arrange the pseudotrees that would provide increased parallelism and smaller message sizes.",
                "After exploring these other arrangements we found that cross-edged pseudotrees provide shorter depths and higher branching factors than the traditional pseudotrees.",
                "Our hypothesis was that these crossedged pseudotrees would outperform traditional pseudotrees for some problem types.",
                "In this paper we introduce an extension to the DPOP algorithm that handles an extended set of pseudotree arrangements which include cross-edged pseudotrees.",
                "We begin with a definition of 741 978-81-904262-7-5 (RPS) c 2007 IFAAMAS DCOP, traditional pseudotrees, and cross-edged pseudotrees.",
                "We then provide a summary of the original DPOP algorithm and introduce our DCPOP algorithm.",
                "We discuss the complexity of our algorithm as well as the impact of pseudotree generation heuristics.",
                "We then show that our Distributed Cross-edged Pseudotree Optimization Procedure (DCPOP) performs significantly better in practice than the original DPOP algorithm for some problem instances.",
                "We conclude with a selection of ideas for future work and extensions for DCPOP. 2.",
                "PROBLEM DEFINITION DCOP has been formalized in slightly different ways in recent literature, so we will adopt the definition as presented in [6].",
                "A Distributed Constraint Optimization Problem with n nodes and m constraints consists of the tuple < X, D, U > where: • X = {x1,..,xn} is a set of variables, each one assigned to a unique agent • D = {d1,..,dn} is a set of finite domains for each variable • U = {u1,..,um} is a set of utility functions such that each function involves a subset of variables in X and defines a utility for each combination of values among these variables An optimal solution to a DCOP instance consists of an assignment of values in D to X such that the sum of utilities in U is maximal.",
                "Problem domains that require minimum cost instead of maximum utility can map costs into negative utilities.",
                "The utility functions represent soft constraints but can also represent hard constraints by using arbitrarily large negative values.",
                "For this paper we only consider binary utility functions involving two variables.",
                "Higher order utility functions can be modeled with minor changes to the algorithm, but they also substantially increase the complexity. 2.1 Traditional Pseudotrees Pseudotrees are a common structure used in search procedures to allow parallel processing of independent branches.",
                "As defined in [6], a pseudotree is an arrangement of a graph G into a rooted tree T such that vertices in G that share an edge are in the same branch in T. A back-edge is an edge between a node X and any node which lies on the path from X to the root (excluding Xs parent).",
                "Figure 1 shows a pseudotree with four nodes, three edges (A-B, B-C, BD), and one back-edge (A-C).",
                "Also defined in [6] are four types of relationships between nodes exist in a pseudotree: • P(X) - the parent of a node X: the single node higher in the pseudotree that is connected to X directly through a tree edge • C(X) - the children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through tree edges • PP(X) - the pseudo-parents of a node X: the set of nodes higher in the pseudotree that are connected to X directly through back-edges (In Figure 1, A = PP(C)) • PC(X) - the pseudo-children of a node X: the set of nodes lower in the pseudotree that are connected to X directly through back-edges (In Figure 1, C = PC(A)) Figure 1: A traditional pseudotree.",
                "Solid line edges represent parent-child relationships and the dashed line represents a pseudo-parent-pseudo-child relationship.",
                "Figure 2: A cross-edged pseudotree.",
                "Solid line edges represent parent-child relationships, the dashed line represents a pseudoparent-pseudo-child relationship, and the dotted line represents a branch-parent-branch-child relationship.",
                "The bolded node, B, is the merge point for node E. 2.2 Cross-edged Pseudotrees We define a cross-edge as an edge from node X to a node Y that is above X but not in the path from X to the root.",
                "A cross-edged pseudotree is a traditional pseudotree with the addition of cross-edges.",
                "Figure 2 shows a cross-edged pseudotree with a cross-edge (D-E).",
                "In a cross-edged pseudotree we designate certain edges as primary.",
                "The set of primary edges defines a spanning tree of the nodes.",
                "The parent, child, pseudo-parent, and pseudo-child relationships from the traditional pseudotree are now defined in the context of this primary edge spanning tree.",
                "This definition also yields two additional types of relationships that may exist between nodes: • BP(X) - the branch-parents of a node X: the set of nodes higher in the pseudotree that are connected to X but are not in the primary path from X to the root (In Figure 2, D = BP(E)) • BC(X) - the branch-children of a node X: the set of nodes lower in the pseudotree that are connected to X but are not in any primary path from X to any leaf node (In Figure 2, E = BC(D)) 2.3 Pseudotree Generation 742 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Current algorithms usually have a pre-execution phase to generate a traditional pseudotree from a general DCOP instance.",
                "Our DCPOP algorithm generates a cross-edged pseudotree in the same fashion.",
                "First, the DCOP instance < X, D, U > translates directly into a graph with X as the set of vertices and an edge for each pair of variables represented in U.",
                "Next, various heuristics are used to arrange this graph into a pseudotree.",
                "One common heuristic is to perform a guided depth-first search (DFS) as the resulting traversal is a pseudotree, and a DFS can easily be performed in a distributed fashion.",
                "We define an edge-traversal based method as any method that produces a pseudotree in which all parent/child pairs share an edge in the original graph.",
                "This includes DFS, breadth-first search, and best-first search based traversals.",
                "Our heuristics that generate cross-edged pseudotrees use a distributed best-first search traversal. 3.",
                "DPOP ALGORITHM The original DPOP algorithm operates in three main phases.",
                "The first phase generates a traditional pseudotree from the DCOP instance using a distributed algorithm.",
                "The second phase joins utility hypercubes from children and the local node and propagates them towards the root.",
                "The third phase chooses an assignment for each domain in a top down fashion beginning with the agent at the root node.",
                "The complexity of DPOP depends on the size of the largest computation and utility message during phase two.",
                "It has been shown that this size directly corresponds to the induced width of the pseudotree generated in phase one [6].",
                "DPOP uses polynomial time heuristics to generate the pseudotree since finding the minimum induced width pseudotree is NP-hard.",
                "Several distributed edgetraversal heuristics have been developed to find low width pseudotrees [8].",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, and pseudo-children. 3.1 Utility Propagation Agents located at leaf nodes in the pseudotree begin the process by calculating a local utility hypercube.",
                "This hypercube at node X contains summed utilities for each combination of values in the domains for P(X) and PP(X).",
                "This hypercube has dimensional size equal to the number of pseudo-parents plus one.",
                "A message containing this hypercube is sent to P(X).",
                "Agents located at non-leaf nodes wait for all messages from children to arrive.",
                "Once the agent at node Y has all utility messages, it calculates its local utility hypercube which includes domains for P(Y), PP(Y), and Y.",
                "The local utility hypercube is then joined with all of the hypercubes from the child messages.",
                "At this point all utilities involving node Y are known, and the domain for Y may be safely eliminated from the joined hypercube.",
                "This elimination process chooses the best utility over the domain of Y for each combination of the remaining domains.",
                "A message containing this hypercube is now sent to P(Y).",
                "The dimensional size of this hypercube depends on the number of overlapping domains in received messages and the local utility hypercube.",
                "This dynamic programming based propagation phase continues until the agent at the root node of the pseudotree has received all messages from its children. 3.2 Value Propagation Value propagation begins when the agent at the root node Z has received all messages from its children.",
                "Since Z has no parents or pseudo-parents, it simply combines the utility hypercubes received from its children.",
                "The combined hypercube contains only values for the domain for Z.",
                "At this point the agent at node Z simply chooses the assignment for its domain that has the best utility.",
                "A value propagation message with this assignment is sent to each node in C(Z).",
                "Each other node then receives a value propagation message from its parent and chooses the assignment for its domain that has the best utility given the assignments received in the message.",
                "The node adds its domain assignment to the assignments it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen an assignment for their domain. 4.",
                "DCPOP ALGORITHM Our extension to the original DPOP algorithm, shown in Algorithm 1, shares the same three phases.",
                "The first phase generates the cross-edged pseudotree for the DCOP instance.",
                "The second phase merges branches and propagates the utility hypercubes.",
                "The third phase chooses assignments for domains at branch merge points and in a top down fashion, beginning with the agent at the root node.",
                "For the first phase we generate a pseudotree using several distributed heuristics and select the one with lowest overall complexity.",
                "The complexity of the computation and utility message size in DCPOP does not directly correspond to the induced width of the cross-edged pseudotree.",
                "Instead, we use a polynomial time method for calculating the maximum computation and utility message size for a given cross-edged pseudotree.",
                "A description of this method and the pseudotree selection process appears in Section 5.",
                "At the end of the first phase, each agent knows its parent, children, pseudo-parents, pseudo-children, branch-parents, and branch-children. 4.1 Merging Branches and Utility Propagation In the original DPOP algorithm a node X only had utility functions involving its parent and its pseudo-parents.",
                "In DCPOP, a node X is allowed to have a utility function involving a branch-parent.",
                "The concept of a branch can be seen in Figure 2 with node E representing our node X.",
                "The two distinct paths from node E to node B are called branches of E. The single node where all branches of E meet is node B, which is called the merge point of E. Agents with nodes that have branch-parents begin by sending a utility propagation message to each branch-parent.",
                "This message includes a two dimensional utility hypercube with domains for the node X and the branch-parent BP(X).",
                "It also includes a branch information structure which contains the origination node of the branch, X, the total number of branches originating from X, and the number of branches originating from X that are merged into a single representation by this branch information structure (this number starts at 1).",
                "Intuitively when the number of merged branches equals the total number of originating branches, the algorithm has reached the merge point for X.",
                "In Figure 2, node E sends a utility propagation message to its branch-parent, node D. This message has dimensions for the domains of E and D, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "As in the original DPOP utility propagation phase, an agent at leaf node X sends a utility propagation message to its parent.",
                "In DCPOP this message contains dimensions for the domains of P(X) and PP(X).",
                "If node X also has branch-parents, then the utility propagation message also contains a dimension for the domain of X, and will include a branch information structure.",
                "In Figure 2, node E sends a utility propagation message to its parent, node C. This message has dimensions for the domains of E and C, and includes branch information with an origin of E, 2 total branches, and 1 merged branch.",
                "When a node Y receives utility propagation messages from all of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 743 its children and branch-children, it merges any branches with the same origination node X.",
                "The merged branch information structure accumulates the number of merged branches for X.",
                "If the cumulative total number of merged branches equals the total number of branches, then Y is the merge point for X.",
                "This means that the utility hypercubes present at Y contain all information about the valuations for utility functions involving node X.",
                "In addition to the typical elimination of the domain of Y from the utility hypercubes, we can now safely eliminate the domain of X from the utility hypercubes.",
                "To illustrate this process, we will examine what happens in the second phase for node B in Figure 2.",
                "In the second phase Node B receives two utility propagation messages.",
                "The first comes from node C and includes dimensions for domains E, B, and A.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "The second comes from node D and includes dimensions for domains E and B.",
                "It also has a branch information structure with origin of E, 2 total branches, and 1 merged branch.",
                "Node B then merges the branch information structures from both messages because they have the same origination, node E. Since the number of merged branches originating from E is now 2 and the total branches originating from E is 2, node B now eliminates the dimensions for domain E. Node B also eliminates the dimension for its own domain, leaving only information about domain A. Node B then sends a utility propagation message to node A, containing only one dimension for the domain of A.",
                "Although not possible in DPOP, this method of utility propagation and dimension elimination may produce hypercubes at node Y that do not share any domains.",
                "In DCPOP we do not join domain independent hypercubes, but instead may send multiple hypercubes in the utility propagation message sent to the parent of Y.",
                "This lazy approach to joins helps to reduce message sizes. 4.2 Value Propagation As in DPOP, value propagation begins when the agent at the root node Z has received all messages from its children.",
                "At this point the agent at node Z chooses the assignment for its domain that has the best utility.",
                "If Z is the merge point for the branches of some node X, Z will also choose the assignment for the domain of X.",
                "Thus any node that is a merge point will choose assignments for a domain other than its own.",
                "These assignments are then passed down the primary edge hierarchy.",
                "If node X in the hierarchy has branch-parents, then the value assignment message from P(X) will contain an assignment for the domain of X.",
                "Every node in the hierarchy adds any assignments it has chosen to the ones it received and passes the set of assignments to its children.",
                "The algorithm is complete when all nodes have chosen or received an assignment for their domain. 4.3 Proof of Correctness We will prove the correctness of DCPOP by first noting that DCPOP fully extends DPOP and then examining the two cases for value assignment in DCPOP.",
                "Given a traditional pseudotree as input, the DCPOP algorithm execution is identical to DPOP.",
                "Using a traditional pseudotree arrangement no nodes have branch-parents or branch-children since all edges are either back-edges or tree edges.",
                "Thus the DCPOP algorithm using a traditional pseudotree sends only utility propagation messages that contain domains belonging to the parent or pseudo-parents of a node.",
                "Since no node has any branch-parents, no branches exist, and thus no node serves as a merge point for any other node.",
                "Thus all value propagation assignments are chosen at the node of the assignment domain.",
                "For DCPOP execution with cross-edged pseudotrees, some nodes serve as merge points.",
                "We note that any node X that is not a merge point assigns its value exactly as in DPOP.",
                "The local utility hypercube at X contains domains for X, P(X), PP(X), and BC(X).",
                "As in DPOP the value assignment message received at X includes the values assigned to P(X) and PP(X).",
                "Also, since X is not a merge point, all assignments to BC(X) must have been calculated at merge points higher in the tree and are in the value assignment message from P(X).",
                "Thus after eliminating domains for which assignments are known, only the domain of X is left.",
                "The agent at node X can now correctly choose the assignment with maximum utility for its own domain.",
                "If node X is a merge point for some branch-child Y, we know that X must be a node along the path from Y to the root, and from P(Y) and all BP(Y) to the root.",
                "From the algorithm, we know that Y necessarily has all information from C(Y), PC(Y), and BC(Y) since it waits for their messages.",
                "Node X has information about all nodes below it in the tree, which would include Y, P(Y), BP(Y), and those PP(Y) that are below X in the tree.",
                "For any PP(Y) above X in the tree, X receives the assignment for the domain of PP(Y) in the value assignment message from P(X).",
                "Thus X has utility information about all of the utility functions of which Y is a part.",
                "By eliminating domains included in the value assignment message, node X is left with a local utility hypercube with domains for X and Y.",
                "The agent at node X can now correctly choose the assignments with maximum utility for the domains of X and Y. 4.4 Complexity Analysis The first phase of DCPOP sends one message to each P(X), PP(X), and BP(X).",
                "The second phase sends one value assignment message to each C(X).",
                "Thus, DCPOP produces a linear number of messages with respect to the number of edges (utility functions) in the cross-edged pseudotree and the original DCOP instance.",
                "The actual complexity of DCPOP depends on two additional measurements: message size and computation size.",
                "Message size and computation size in DCPOP depend on the number of overlapping branches as well as the number of overlapping back-edges.",
                "It was shown in [6] that the number of overlapping back-edges is equal to the induced width of the pseudotree.",
                "In a poorly constructed cross-edged pseudotree, the number of overlapping branches at node X can be as large as the total number of descendants of X.",
                "Thus, the total message size in DCPOP in a poorly constructed instance can be space-exponential in the total number of nodes in the graph.",
                "However, in practice a well constructed cross-edged pseudotree can achieve much better results.",
                "Later we address the issue of choosing well constructed crossedged pseudotrees from a set.",
                "We introduce an additional measurement of the maximum sequential path cost through the algorithm.",
                "This measurement directly relates to the maximum amount of parallelism achievable by the algorithm.",
                "To take this measurement we first store the total computation size for each node during phase two and three.",
                "This computation size represents the number of individual accesses to a value in a hypercube at each node.",
                "For example, a join between two domains of size 4 costs 4 ∗ 4 = 16.",
                "Two directed acyclic graphs (DAG) can then be drawn; one with the utility propagation messages as edges and the phase two costs at nodes, and the other with value assignment messages and the phase three costs at nodes.",
                "The maximum sequential path cost is equal to the sum of the longest path on each DAG from the root to any leaf node. 5.",
                "HEURISTICS In our assessment of complexity in DCPOP we focused on the worst case possibly produced by the algorithm.",
                "We acknowledge 744 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Algorithm 1 DCPOP Algorithm 1: DCPOP(X; D; U) Each agent Xi executes: Phase 1: pseudotree creation 2: elect leader from all Xj ∈ X 3: elected leader initiates pseudotree creation 4: afterwards, Xi knows P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi) and PC(Xi) Phase 2: UTIL message propagation 5: if |BP(Xi)| > 0 then 6: BRANCHXi ← |BP(Xi)| + 1 7: for all Xk ∈BP(Xi) do 8: UTILXi (Xk) ←Compute utils(Xi, Xk) 9: Send message(Xk,UTILXi (Xk),BRANCHXi ) 10: if |C(Xi)| = 0(i.e.",
                "Xi is a leaf node) then 11: UTILXi (P(Xi)) ← Compute utils(P(Xi),PP(Xi)) for all PP(Xi) 12: Send message(P(Xi), UTILXi (P(Xi)),BRANCHXi ) 13: Send message(PP(Xi), empty UTIL, empty BRANCH) to all PP(Xi) 14: activate UTIL Message handler() Phase 3: VALUE message propagation 15: activate VALUE Message handler() END ALGORITHM UTIL Message handler(Xk,UTILXk (Xi), BRANCHXk ) 16: store UTILXk (Xi),BRANCHXk (Xi) 17: if UTIL messages from all children and branch children arrived then 18: for all Bj ∈BRANCH(Xi) do 19: if Bj is merged then 20: join all hypercubes where Bj ∈UTIL(Xi) 21: eliminate Bj from the joined hypercube 22: if P(Xi) == null (that means Xi is the root) then 23: v ∗ i ← Choose optimal(null) 24: Send VALUE(Xi, v ∗ i) to all C(Xi) 25: else 26: UTILXi (P(Xi)) ← Compute utils(P(Xi), PP(Xi)) 27: Send message(P(Xi),UTILXi (P(Xi)), BRANCHXi (P(Xi))) VALUE Message handler(VALUEXi ,P(Xi)) 28: add all Xk ← v ∗ k ∈VALUEXi ,P(Xi) to agent view 29: Xi ← v ∗ i =Choose optimal(agent view) 30: Send VALUEXl , Xi to all Xl ∈C(Xi) that in real world problems the generation of the pseudotree has a significant impact on the actual performance.",
                "The problem of finding the best pseudotree for a given DCOP instance is NP-Hard.",
                "Thus a heuristic is used for generation, and the performance of the algorithm depends on the pseudotree found by the heuristic.",
                "Some previous research focused on finding heuristics to generate good pseudotrees [8].",
                "While we have developed some heuristics that generate good cross-edged pseudotrees for use with DCPOP, our focus has been to use multiple heuristics and then select the best pseudotree from the generated pseudotrees.",
                "We consider only heuristics that run in polynomial time with respect to the number of nodes in the original DCOP instance.",
                "The actual DCPOP algorithm has worst case exponential complexity, but we can calculate the maximum message size, computation size, and sequential path cost for a given cross-edged pseudotree in linear space-time complexity.",
                "To do this, we simply run the algorithm without attempting to calculate any of the local utility hypercubes or optimal value assignments.",
                "Instead, messages include dimensional and branch information but no utility hypercubes.",
                "After each heuristic completes its generation of a pseudotree, we execute the measurement procedure and propagate the measurement information up to the chosen root in that pseudotree.",
                "The root then broadcasts the total complexity for that heuristic to all nodes.",
                "After all heuristics have had a chance to complete, every node knows which heuristic produced the best pseudotree.",
                "Each node then proceeds to begin the DCPOP algorithm using its knowledge of the pseudotree generated by the best heuristic.",
                "The heuristics used to generate traditional pseudotrees perform a distributed DFS traversal.",
                "The general distributed algorithm uses a token passing mechanism and a linear number of messages.",
                "Improved DFS based heuristics use a special procedure to choose the root node, and also provide an ordering function over the neighbors of a node to determine the order of path recursion.",
                "The DFS based heuristics used in our experiments come from the work done in [4, 8]. 5.1 The best-first cross-edged pseudotree heuristic The heuristics used to generate cross-edged pseudotrees perform a best-first traversal.",
                "A general distributed best-first algorithm for node expansion is presented in Algorithm 2.",
                "An evaluation function at each node provides the values that are used to determine the next best node to expand.",
                "Note that in this algorithm each node only exchanges its best value with its neighbors.",
                "In our experiments we used several evaluation functions that took as arguments an ordered list of ancestors and a node, which contains a list of neighbors (with each neighbors placement depth in the tree if it was placed).",
                "From these we can calculate branchparents, branch-children, and unknown relationships for a potential node placement.",
                "The best overall function calculated the value as ancestors−(branchparents+branchchildren) with the number of unknown relationships being a tiebreak.",
                "After completion each node has knowledge of its parent and ancestors, so it can easily determine which connected nodes are pseudo-parents, branchparents, pseudo-children, and branch-children.",
                "The complexity of the best-first traversal depends on the complexity of the evaluation function.",
                "Assuming a complexity of O(V ) for the evaluation function, which is the case for our best overall function, the best-first traversal is O(V · E) which is at worst O(n3 ).",
                "For each v ∈ V we perform a place operation, and find the next node to place using the getBestNeighbor operation.",
                "The place operation is at most O(V ) because of the sent messages.",
                "Finding the next node uses recursion and traverses only already placed The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 745 Algorithm 2 Distributed Best-First Search Algorithm root ← electedleader next(root, ∅) place(node, parent) node.parent ← parent node.ancestors ← parent.ancestors ∪ parent send placement message (node, node.ancestors) to all neighbors of node next(current, previous) if current is not placed then place(current, previous) next(current, ∅) else best ← getBestNeighbor(current, previous) if best = ∅ then if previous = ∅ then terminate, all nodes are placed next(previous, ∅) else next(best, current) getBestNeighbor(current, previous) best ← ∅; score ← 0 for all n ∈ current.neighbors do if n! = previous then if n is placed then nscore ← getBestNeighbor(n, current) else nscore ← evaluate(current, n) if nscore > score then score ← nscore best ← n return best, score nodes, so it has O(V ) recursions.",
                "Each recursion performs a recursive getBestNeighbor operation that traverses all placed nodes and their neighbors.",
                "This operation is O(V · E), but results can be cached using only O(V ) space at each node.",
                "Thus we have O(V ·(V +V +V ·E)) = O(V 2 ·E).",
                "If we are smart about evaluating local changes when each node receives placement messages from its neighbors and cache the results the getBestNeighbor operation is only O(E).",
                "This increases the complexity of the place operation, but for all placements the total complexity is only O(V · E).",
                "Thus we have an overall complexity of O(V ·E+V ·(V +E)) = O(V ·E). 6.",
                "COMPARISON OF COMPLEXITY IN DPOP AND DCPOP We have already shown that given the same input, DCPOP performs the same as DPOP.",
                "We also have shown that we can accurately predict performance of a given pseudotree in linear spacetime complexity.",
                "If we use a constant number of heuristics to generate the set of pseudotrees, we can choose the best pseudotree in linear space-time complexity.",
                "We will now show that there exists a DCOP instance for which a cross-edged pseudotree outperforms all possible traditional pseudotrees (based on edge-traversal heuristics).",
                "In Figure 3(a) we have a DCOP instance with six nodes.",
                "This is a bipartite graph with each partition fully connected to the other (a) (b) (c) Figure 3: (a) The DCOP instance (b) A traditional pseudotree arrangement for the DCOP instance (c) A cross-edged pseudotree arrangement for the DCOP instance partition.",
                "In Figure 3(b) we see a traditional pseudotree arrangement for this DCOP instance.",
                "It is easy to see that any edgetraversal based heuristic cannot expand two nodes from the same partition in succession.",
                "We also see that no node can have more than one child because any such arrangement would be an invalid pseudotree.",
                "Thus any traditional pseudotree arrangement for this DCOP instance must take the form of Figure 3(b).",
                "We can see that the back-edges F-B and F-A overlap node C. Node C also has a parent E, and a back-edge with D. Using the original DPOP algorithm (or DCPOP since they are identical in this case), we find that the computation at node C involves five domains: A, B, C, D, and E. In contrast, the cross-edged pseudotree arrangement in Figure 3(c) requires only a maximum of four domains in any computation during DCPOP.",
                "Since node A is the merge point for branches from both B and C, we can see that each of the nodes D, E, and F have two overlapping branches.",
                "In addition each of these nodes has node A as its parent.",
                "Using the DCPOP algorithm we find that the computation at node D (or E or F) involves four domains: A, B, C, and D (or E or F).",
                "Since no better traditional pseudotree arrangement can be created using an edge-traversal heuristic, we have shown that DCPOP can outperform DPOP even if we use the optimal pseudotree found through edge-traversal.",
                "We acknowledge that pseudotree arrangements that allow parent-child relationships without an actual constraint can solve the problem in Figure 3(a) with maximum computation size of four domains.",
                "However, current heuristics used with DPOP do not produce such pseudotrees, and such a heuristic would be difficult to distribute since each node would require information about nodes with which it has no constraint.",
                "Also, while we do not prove it here, cross-edged pseudotrees can produce smaller message sizes than such pseudotrees even if the computation size is similar.",
                "In practice, since finding the best pseudotree arrangement is NP-Hard, we find that heuristics that produce cross-edged pseudotrees often produce significantly smaller computation and message sizes. 7.",
                "EXPERIMENTAL RESULTS 746 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Existing performance metrics for DCOP algorithms include the total number of messages, synchronous clock cycles, and message size.",
                "We have already shown that the total number of messages is linear with respect to the number of constraints in the DCOP instance.",
                "We also introduced the maximum sequential path cost (PC) as a measurement of the maximum amount of parallelism achievable by the algorithm.",
                "The maximum sequential path cost is equal to the sum of the computations performed on the longest path from the root to any leaf node.",
                "We also include as metrics the maximum computation size in number of dimensions (CD) and maximum message size in number of dimensions (MD).",
                "To analyze the relative complexity of a given DCOP instance, we find the minimum induced width (IW) of any traditional pseudotree produced by a heuristic for the original DPOP. 7.1 Generic DCOP instances For our initial tests we randomly generated two sets of problems with 3000 cases in each.",
                "Each problem was generated by assigning a random number (picked from a range) of constraints to each variable.",
                "The generator then created binary constraints until each variable reached its maximum number of constraints.",
                "The first set uses 20 variables, and the best DPOP IW ranges from 1 to 16 with an average of 8.5.",
                "The second set uses 100 variables, and the best DPOP IW ranged from 2 to 68 with an average of 39.3.",
                "Since most of the problems in the second set were too complex to actually compute the solution, we took measurements of the metrics using the techniques described earlier in Section 5 without actually solving the problem.",
                "Results are shown for the first set in Table 1 and for the second set in Table 2.",
                "For the two problem sets we split the cases into low density and high density categories.",
                "Low density cases consist of those problems that have a best DPOP IW less than or equal to half of the total number of nodes (e.g.",
                "IW ≤ 10 for the 20 node problems and IW ≤ 50 for the 100 node problems).",
                "High density problems consist of the remainder of the problem sets.",
                "In both Table 1 and Table 2 we have listed performance metrics for the original DPOP algorithm, the DCPOP algorithm using only cross-edged pseudotrees (DCPOP-CE), and the DCPOP algorithm using traditional and cross-edged pseudotrees (DCPOP-All).",
                "The pseudotrees used for DPOP were generated using 5 heuristics: DFS, DFS MCN, DFS CLIQUE MCN, DFS MCN DSTB, and DFS MCN BEC.",
                "These are all versions of the guided DFS traversal discussed in Section 5.",
                "The cross-edged pseudotrees used for DCPOP-CE were generated using 5 heuristics: MCN, LCN, MCN A-B, LCN A-B, and LCSG A-B.",
                "These are all versions of the best-first traversal discussed in Section 5.",
                "For both DPOP and DCPOP-CE we chose the best pseudotree produced by their respective 5 heuristics for each problem in the set.",
                "For DCPOP-All we chose the best pseudotree produced by all 10 heuristics for each problem in the set.",
                "For the CD and MD metrics the value shown is the average number of dimensions.",
                "For the PC metric the value shown is the natural logarithm of the maximum sequential path cost (since the actual value grows exponentially with the complexity of the problem).",
                "The final row in both tables is a measurement of improvement of DCPOP-All over DPOP.",
                "For the CD and MD metrics the value shown is a reduction in number of dimensions.",
                "For the PC metric the value shown is a percentage reduction in the maximum sequential path cost (% = DP OP −DCP OP DCP OP ∗ 100).",
                "Notice that DCPOPAll outperforms DPOP on all metrics.",
                "This logically follows from our earlier assertion that given the same input, DCPOP performs exactly the same as DPOP.",
                "Thus given the choice between the pseudotrees produced by all 10 heuristics, DCPOP-All will always outLow Density High Density Algorithm CD MD PC CD MD PC DPOP 7.81 6.81 3.78 13.34 12.34 5.34 DCPOP-CE 7.94 6.73 3.74 12.83 11.43 5.07 DCPOP-All 7.62 6.49 3.66 12.72 11.36 5.05 Improvement 0.18 0.32 13% 0.62 0.98 36% Table 1: 20 node problems Low Density High Density Algorithm CD MD PC CD MD PC DPOP 33.35 32.35 14.55 58.51 57.50 19.90 DCPOP-CE 33.49 29.17 15.22 57.11 50.03 20.01 DCPOP-All 32.35 29.57 14.10 56.33 51.17 18.84 Improvement 1.00 2.78 104% 2.18 6.33 256% Table 2: 100 node problems Figure 4: Computation Dimension Size Figure 5: Message Dimension Size The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 747 Figure 6: Path Cost DCPOP Improvement Ag Mtg Vars Const IW CD MD PC 10 4 12 13.5 2.25 -0.01 -0.01 5.6% 30 14 44 57.6 3.63 0.09 0.09 10.9% 50 24 76 101.3 4.17 0.08 0.09 10.7% 100 49 156 212.9 5.04 0.16 0.20 30.0% 150 74 236 321.8 5.32 0.21 0.23 35.8% 200 99 316 434.2 5.66 0.18 0.22 29.5% Table 3: Meeting Scheduling Problems perform DPOP.",
                "Another trend we notice is that the improvement is greater for high density problems than low density problems.",
                "We show this trend in greater detail in Figures 4, 5, and 6.",
                "Notice how the improvement increases as the complexity of the problem increases. 7.2 Meeting Scheduling Problem In addition to our initial generic DCOP tests, we ran a series of tests on the Meeting Scheduling Problem (MSP) as described in [6].",
                "The problem setup includes a number of people that are grouped into departments.",
                "Each person must attend a specified number of meetings.",
                "Meetings can be held within departments or among departments, and can be assigned to one of eight time slots.",
                "The MSP maps to a DCOP instance where each variable represents the time slot that a specific person will attend a specific meeting.",
                "All variables that belong to the same person have mutual exclusion constraints placed so that the person cannot attend more than one meeting during the same time slot.",
                "All variables that belong to the same meeting have equality constraints so that all of the participants choose the same time slot.",
                "Unary constraints are placed on each variable to account for a persons valuation of each meeting and time slot.",
                "For our tests we generated 100 sample problems for each combination of agents and meetings.",
                "Results are shown in Table 3.",
                "The values in the first five columns represent (in left to right order), the total number of agents, the total number of meetings, the total number of variables, the average total number of constraints, and the average minimum IW produced by a traditional pseudotree.",
                "The last three columns show the same metrics we used for the generic DCOP instances, except this time we only show the improvements of DCPOP-All over DPOP.",
                "Performance is better on average for all MSP instances, but again we see larger improvements for more complex problem instances. 8.",
                "CONCLUSIONS AND FUTURE WORK We presented a complete, distributed algorithm that solves general DCOP instances using cross-edged pseudotree arrangements.",
                "Our algorithm extends the DPOP algorithm by adding additional utility propagation messages, and introducing the concept of branch merging during the utility propagation phase.",
                "Our algorithm also allows value assignments to occur at higher level merge points for lower level nodes.",
                "We have shown that DCPOP fully extends DPOP by performing the same operations given the same input.",
                "We have also shown through some examples and experimental data that DCPOP can achieve greater performance for some problem instances by extending the allowable input set to include cross-edged pseudotrees.",
                "We placed particular emphasis on the role that edge-traversal heuristics play in the generation of pseudotrees.",
                "We have shown that the performance penalty is minimal to generate multiple heuristics, and that we can choose the best generated pseudotree in linear space-time complexity.",
                "Given the importance of a good pseudotree for performance, future work will include new heuristics to find better pseudotrees.",
                "Future work will also include adapting existing DPOP extensions [5, 7] that support different problem domains for use with DCPOP. 9.",
                "REFERENCES [1] J. Liu and K. P. Sycara.",
                "Exploiting problem structure for distributed constraint optimization.",
                "In V. Lesser, editor, Proceedings of the First International Conference on Multi-Agent Systems, pages 246-254, San Francisco, CA, 1995.",
                "MIT Press. [2] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni.",
                "A dynamic distributed constraint satisfaction approach to resource allocation.",
                "Lecture Notes in Computer Science, 2239:685-700, 2001. [3] P. J. Modi, W. Shen, M. Tambe, and M. Yokoo.",
                "An asynchronous complete method for distributed constraint optimization.",
                "In AAMAS 03, 2003. [4] A. Petcu.",
                "Frodo: A framework for open/distributed constraint optimization.",
                "Technical Report No. 2006/001 2006/001, Swiss Federal Institute of Technology (EPFL), Lausanne (Switzerland), 2006. http://liawww.epfl.ch/frodo/. [5] A. Petcu and B. Faltings.",
                "A-dpop: Approximations in distributed optimization.",
                "In poster in CP 2005, pages 802-806, Sitges, Spain, October 2005. [6] A. Petcu and B. Faltings.",
                "Dpop: A scalable method for multiagent constraint optimization.",
                "In IJCAI 05, pages 266-271, Edinburgh, Scotland, Aug 2005. [7] A. Petcu, B. Faltings, and D. Parkes.",
                "M-dpop: Faithful distributed implementation of efficient social choice problems.",
                "In AAMAS 06, pages 1397-1404, Hakodate, Japan, May 2006. [8] G. Ushakov.",
                "Solving meeting scheduling problems using distributed pseudotree-optimization procedure.",
                "Masters thesis, ´Ecole Polytechnique F´ed´erale de Lausanne, 2005. [9] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "Distributed constraint satisfaction for formalizing distributed problem solving.",
                "In International Conference on Distributed Computing Systems, pages 614-621, 1992. [10] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara.",
                "The distributed constraint satisfaction problem: Formalization and algorithms.",
                "Knowledge and Data Engineering, 10(5):673-685, 1998. 748 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        }
    }
}