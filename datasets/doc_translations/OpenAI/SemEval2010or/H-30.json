{
    "id": "H-30",
    "original_text": "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness. Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies. In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval. The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion. Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques. We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique. Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets. We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation. Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1. INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative. A great deal of information is lost during the process of translating from the information need to the actual query. For this reason, there has been a strong interest in query expansion techniques. Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need. Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29]. Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22]. The MRF model generalizes the unigram, bigram, and other various dependence models [14]. Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8]. The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6]. Until now, the model has been solely used for ranking documents in response to a given query. In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE). There are three primary contributions of our work. First, LCE provides a mechanism for combining term dependence with query expansion. Previous query expansion techniques are based on bag of words models. Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion. Next, as we will show, the MRF model allows arbitrary features to be used within the model. Query expansion techniques in the past have implicitly only made use of term occurrence features. By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better. Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts. Most previous techniques, by default, generate terms independently. There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28]. Our approach is both formally motivated and a natural extension of the underlying model. The remainder of this paper is laid out as follows. In Section 2 we describe related query expansion approaches. Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique. In Section 4 we evaluate our proposed model and analyze the results. Finally, Section 5 concludes the paper and summarizes the major results. 2. RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21]. Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents. Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval. A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29]. Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model. Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration. This separates the content model from the background model. The content model is then interpolated with the original query model to form the expanded query. The other technique, relevance models, is more closely related to our work. Therefore, we go into the details of the model. Much like model-based feedback, relevance models estimate an improved query model. The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents. Instead, they model a more generalized notion of relevance, as we now show. Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence. It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q. In the pseudo-relevant case, these are the top ranked documents for query Q. Furthermore, it is assumed that P(D) is uniform over this set. These mild assumptions make computing the Bayesian posterior more practical. After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q). This clipped distribution is then interpolated with with the original, maximum likelihood query model [1]. This can be thought of as expanding the original query by k weighted terms. Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3. There has been relatively little work done in the area of query expansion in the context of dependence models [9]. However, there have been several attempts to expand using multi-term concepts. Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28]. Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics. However, it is not clear based on the analysis done how much the phrases helped over the single terms alone. Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19]. The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other. Results showed that combining single term and large window multi-term concepts significantly improved effectiveness. However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3. MODEL This section details our proposed latent concept expansion technique. As mentioned previously, the technique is an extension of the MRF model for information retrieval [14]. Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution. Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution. That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query. A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution. A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors. Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant. We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways. However, following previous work, we consider three simple variants [14]. These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs. We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable. Therefore, we allow cliques to share feature functions and parameters based on clique sets. That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter. This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets. We propose seven clique sets for use with information retrieval. The first three clique sets consist of cliques that contain one or more query terms and the document node. Features over these cliques should encode how well the terms in the clique configuration describe the document. These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query. Note that UD is a superset of OD. By tying the parameters among the cliques within each set we can control how much influence each type gets. This also avoids the problem of trying to determine how to estimate weights for each clique within the sets. Instead, we now must only estimate a single parameter per set. Next, we consider cliques that only contain query term nodes. These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node. Feature functions over these cliques should capture how compatible query terms are to one another. These clique features may take on the form of language models that impose well-formedness of the terms. Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query. Finally, there is the clique that only contains the document node. Features over this node can be used as a type of document prior, encoding document-centric properties. This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets. After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively. These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model. The correct choice of features depends largely on the retrieval task and the evaluation metric. Therefore, there is likely not to be a single, universally applicable set of features. To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used. Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few. Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others. Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14]. See Table 1 for a list of features used. These features attempt to capture term occurrence and term proximity. Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q). After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters. Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model. Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level. Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17]. That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric. For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25]. Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query. As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations. We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query. We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts. These latent concepts can consist of a single term, multiple terms, or some combination of the two. It is, therefore, our goal to recover these latent concepts given some original query. This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating. We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts. Similarly, the graph on the right illustrates an expanded graph that generates two term concepts. Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure. After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms. Since it is not practical to compute this summation, we must approximate it. We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q. Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q. This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score. Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents. For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using. We then select the k latent concepts with the highest likelihood given by Equation 3. A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek. Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models. Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner. It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models. There are important differences between MRFs/LCE and unigram language models/relevance models. See Figure 1 for graphical model representations of both models. Unigram language models and relevance models are based on the multinomial distribution. This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features. However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used. Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4. EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets. Table 2 provides a summary of the TREC data sets considered. The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections. For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes. All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23]. All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer. In all cases, only the title portion of the TREC topics are used to construct queries. We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting. We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets. For the unigram language model, the smoothing parameter was trained. For the MRF model, we train the model parameters (i.e. Λ) and model hyperparameters (i.e. α, β). For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc. Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms. Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set). The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q. This equation clearly shows how LCE differs from relevance models. When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework. Therefore, LCE adds two very important factors to the equation. First, it adds the ordered and unordered window features that are applied to the original query. Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets. The results, evaluated using mean average precision, are given in Table 3. As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model. In addition, LCE shows significant improvements over relevance models across all data sets. The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2. Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20. However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model. Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets. In fact, the MRF model outperforms relevance models on the WT10g data set. This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16]. Although our model has more free parameters than relevance models, there is surprisingly little overfitting. Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts. For each query, we expanded using a set of single term concepts and a set of two term concepts. The sets were chosen independently. Unfortunately, only negligible increases in mean average precision were observed. This result may be due to the fact that strong correlations exist between the single term expansion concepts. We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts. For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen. Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query. This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account. Another potential issue is the feature set used. Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts. Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts. Instead, the results introduce interesting open questions and directions for future exploration. LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE). The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model. In this section we analyze the robustness of these two methods. Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods. A highly robust expansion technique will significantly improve many queries and only minimally hurt a few. Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets. The analysis for the two data sets not shown is similar. The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline. As the results show, LCE exhibits strong robustness for each data set. For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14. Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger. For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22. Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14. As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets. In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection. Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set. When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining. For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations. Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model. In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection. It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies. This is not the case when generating multi-term concepts using our model. Instead, a majority of the concepts generated are well-formed and meaningful. There are several cases where the concepts are less coherent, such as mirror mirror mirror. In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood. Such examples are in the minority, however. Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query. As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope. It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query. Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept. One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model. For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood. However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model. Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence. In information retrieval, there has been a long-term interest in understanding the role of term dependence. Out of this research, two broad types of dependencies have been identified. The first type of dependence is syntactic dependence. This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26]. These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies. The second type is semantic dependence. Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3]. These techniques have been explored on both the query and document side. On the query side, this is typically done using some form of query expansion, such as relevance models or LCE. On the document side, this is done as document expansion or document smoothing [11, 13, 24]. Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal. Our model uses both types of dependencies. The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence. This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion. If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models. Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect. An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model. Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5. CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion. The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models. LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features. We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts. The concepts generated can be used in an alternative query suggestion module. We also showed that the model is highly effective. In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets. It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets. This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones. Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies. Future work will look at incorporating document-side dependencies, as well. Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6. REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade. UMass at TREC 2004: Novelty and HARD. In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack. Shortest-substring retrieval and ranking. ACM Trans. Inf. Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan. Query expansion using random walk models. In Proc. 14th Intl. Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft. Boolean queries and term dependencies in probabilistic retrieval models. Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis. The use of phrases and structured queries in information retrieval. In Proc. 14th Ann. Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi. NTCIR-5 query expansion experiments using term dependence models. In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan. Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods. In Proc. tenth Ann. Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao. Dependence language model for information retrieval. In Proc. 27th Ann. Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen. An evaluation of feedback in document retrieval using co-occurrence data. Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims. A support vector method for multivariate performance measures. In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee. Corpus structure, language models, and ad-hoc information retrieval. In Proc. 27th Ann. Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft. Relevance-based language models. In Proc. 24th Ann. Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft. Cluster-based retrieval using language models. In Proc. 27th Ann. Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft. A Markov random field model for term dependencies. In Proc. 28th Ann. Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft. Linear feature based models for information retrieval. Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft. Indri at terabyte track 2005. In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson. Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach. Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan. Experiments using the lemur toolkit. In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan. Why bigger windows are better than smaller ones. Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford. Okapi at trec-3. In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio. Relevance Feedback in Information Retrieval, pages 313-323. Prentice-Hall, 1971. [22] F. Song and W. B. Croft. A general language model for information retrieval. In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft. Indri: A language model-based serach engine for complex queries. In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai. Language model information retrieval with document expansion. In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller. Max-margin markov networks. In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen. A theoretical basis for the use of cooccurrence data in information retrieval. Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft. LDA-based document models for ad-hoc retrieval. In Proc. 29th Ann. Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft. Improving the effectiveness of information retrieval with local context analysis. ACM Trans. Inf. Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty. Model-based feedback in the language modeling approach to information retrieval. In Proc. 10th Intl. Conf. on Information and Knowledge Management, pages 403-410, 2001.",
    "original_translation": "Expansión de conceptos latentes utilizando campos aleatorios de Markov. Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Centro de Recuperación de Información Inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 RESUMEN La expansión de consultas, en forma de retroalimentación de pseudo relevancia o retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación. La mayoría de enfoques anteriores han ignorado problemas importantes, como el papel de las características y la importancia de modelar las dependencias entre términos. En este artículo, proponemos una técnica robusta de expansión de consultas basada en el modelo de campo aleatorio de Markov para la recuperación de información. La técnica, llamada expansión de conceptos latentes, proporciona un mecanismo para modelar las dependencias de términos durante la expansión. Además, el uso de características arbitrarias dentro del modelo proporciona un marco poderoso para ir más allá de las simples características de ocurrencia de términos que son utilizadas implícitamente por la mayoría de las otras técnicas de expansión. Evaluamos nuestra técnica frente a modelos de relevancia, una técnica de expansión de consultas de modelado de lenguaje de última generación. Nuestro modelo demuestra mejoras consistentes y significativas en la efectividad de recuperación en varios conjuntos de datos de TREC. También describimos cómo nuestra técnica puede ser utilizada para generar conceptos significativos de varios términos para tareas como sugerencia/reformulación de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales Algoritmos, Experimentación, Teoría 1. Los usuarios de los sistemas de recuperación de información deben expresar necesidades de información complejas en términos de expresiones booleanas, una lista corta de palabras clave, una oración, una pregunta o posiblemente un relato más extenso. Se pierde mucha información durante el proceso de traducción desde la necesidad de información hasta la consulta real. Por esta razón, ha habido un fuerte interés en las técnicas de expansión de consultas. Tales técnicas se utilizan para ampliar la consulta original y producir una representación que refleje mejor la necesidad de información subyacente. Las técnicas de expansión de consultas han sido ampliamente estudiadas para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la retroalimentación de pseudo-relevancia [12, 21, 28, 29]. Recientemente, se propuso un modelo de campo aleatorio de Markov (MRF) para la recuperación de información que va más allá de la simplista suposición de bolsa de palabras que subyace en BM25 y en el enfoque de modelado de lenguaje (unigrama) para la recuperación de información [20, 22]. El modelo MRF generaliza los modelos de unigrama, bigrama y otras diversas dependencias [14]. La mayoría de los modelos de dependencia de términos pasados no han logrado mostrar mejoras consistentes y significativas sobre las líneas de base de unigramas, con pocas excepciones [8]. El modelo MRF, sin embargo, ha demostrado ser altamente efectivo en una serie de tareas, incluyendo la recuperación ad hoc [14, 16], la búsqueda de páginas con nombres [16] y la búsqueda web en japonés [6]. Hasta ahora, el modelo ha sido utilizado únicamente para clasificar documentos en respuesta a una consulta dada. En este trabajo, mostramos cómo el modelo puede ser ampliado y utilizado para la expansión de consultas utilizando una técnica que llamamos expansión de conceptos latentes (LCE). Hay tres contribuciones principales de nuestro trabajo. Primero, LCE proporciona un mecanismo para combinar la dependencia de términos con la expansión de consultas. Las técnicas de expansión de consultas anteriores se basan en modelos de bolsa de palabras. Por lo tanto, al realizar la expansión de consultas utilizando el modelo MRF, podemos estudiar la dinámica entre la dependencia de términos y la expansión de consultas. A continuación, como mostraremos, el modelo MRF permite que se utilicen características arbitrarias dentro del modelo. Las técnicas de expansión de consultas en el pasado solo han hecho uso implícito de características de ocurrencia de términos. Al utilizar conjuntos de características más robustos, es posible producir términos de expansión mejores que discriminan de manera más efectiva entre documentos relevantes y no relevantes. Finalmente, nuestro enfoque propuesto proporciona de manera fluida un mecanismo para generar conceptos de una sola y múltiples términos. La mayoría de las técnicas anteriores, por defecto, generan términos de forma independiente. Ha habido varios enfoques que hacen uso de conceptos generalizados, sin embargo, dichos enfoques fueron algo heurísticos y realizados fuera del modelo [19, 28]. Nuestro enfoque está motivado tanto formalmente como es una extensión natural del modelo subyacente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2 describimos enfoques relacionados de expansión de consultas. La sección 3 proporciona una visión general del modelo MRF y detalla nuestra técnica propuesta de expansión de conceptos latentes. En la Sección 4 evaluamos nuestro modelo propuesto y analizamos los resultados. Finalmente, la Sección 5 concluye el artículo y resume los principales resultados. 2. TRABAJO RELACIONADO Uno de los enfoques clásicos y más ampliamente utilizados para la expansión de consultas es el algoritmo de Rocchio [21]. El enfoque de Rocchio, que fue desarrollado dentro del modelo de espacio vectorial, reajusta el vector de consulta original moviendo los pesos hacia el conjunto de documentos relevantes o pseudo-relevantes y alejándolos de los documentos no relevantes. Desafortunadamente, no es posible aplicar formalmente el enfoque de Rocchio a un modelo de recuperación estadística, como el modelado del lenguaje para la recuperación de información. Se han desarrollado varias técnicas de expansión de consultas formalizadas para el marco de modelado de lenguaje, incluyendo el feedback basado en el modelo de Zhai y Lafferty y los modelos de relevancia de Lavrenko y Crofts [12, 29]. Ambos enfoques intentan utilizar documentos pseudo-relevantes o relevantes para estimar un modelo de consulta mejor. El feedback basado en modelos encuentra el modelo que mejor describe los documentos relevantes teniendo en cuenta un modelo de fondo (ruido). Esto separa el modelo de contenido del modelo de fondo. El modelo de contenido se interpola con el modelo de consulta original para formar la consulta ampliada. La otra técnica, modelos de relevancia, está más relacionada con nuestro trabajo. Por lo tanto, entramos en los detalles del modelo. Al igual que el feedback basado en modelos, los modelos de relevancia estiman un modelo de consulta mejorado. La única diferencia entre los dos enfoques es que los modelos de relevancia no modelan explícitamente los documentos relevantes o pseudo-relevantes. En cambio, ellos modelan una noción más generalizada de relevancia, como mostraremos ahora. Dada una consulta Q, un modelo de relevancia es una distribución multinomial, P(·|Q), que codifica la probabilidad de cada término dado la consulta como evidencia. Se calcula como: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) donde RQ es el conjunto de documentos que son relevantes o pseudo relevantes para la consulta Q. En el caso pseudo-relevante, estos son los documentos mejor clasificados para la consulta Q. Además, se asume que P(D) es uniforme en este conjunto. Estas suposiciones suaves hacen que el cálculo del posterior bayesiano sea más práctico. Después de que el modelo es estimado, los documentos son clasificados por recortar el modelo de relevancia al elegir los k términos más probables de P(·|Q). Esta distribución recortada se interpola luego con el modelo de consulta de máxima verosimilitud original. Esto se puede considerar como la expansión de la consulta original por k términos ponderados. A lo largo del resto de este trabajo, nos referimos a esta instancia de modelos de relevancia como RM3. Ha habido relativamente poco trabajo realizado en el área de expansión de consultas en el contexto de modelos de dependencia [9]. Sin embargo, ha habido varios intentos de expandir utilizando conceptos de varios términos. El método de análisis de contexto local (LCA) de Xu y Crofts combinaba la recuperación a nivel de pasaje con la expansión de conceptos, donde los conceptos eran términos y frases simples [28]. Los conceptos de expansión fueron elegidos y ponderados utilizando una métrica basada en estadísticas de co-ocurrencia. Sin embargo, no está claro, basándose en el análisis realizado, cuánto ayudaron las frases en comparación con los términos individuales solos. Papka y Allan investigan el uso de retroalimentación de relevancia para realizar la expansión de conceptos de varios términos en el enrutamiento de documentos [19]. Los conceptos utilizados en su trabajo son más generales que los utilizados en el LCA e incluyen estructuras de lenguaje de consulta InQuery, como #UW50(casa blanca), que corresponde al concepto en el que los términos casa y blanca ocurren, en cualquier orden, dentro de 50 términos uno del otro. Los resultados mostraron que combinar conceptos de un solo término y conceptos de varios términos con una ventana grande mejoró significativamente la efectividad. Sin embargo, no está claro si el mismo enfoque también es efectivo para la recuperación ad hoc, debido a las diferencias en las tareas. 3. Este apartado detalla nuestra técnica propuesta de expansión de conceptos latentes. Como se mencionó anteriormente, la técnica es una extensión del modelo MRF para la recuperación de información [14]. Por lo tanto, comenzamos proporcionando una visión general del modelo MRF y nuestras extensiones propuestas. 3.1 MRFs para IR 3.1.1 Conceptos básicos Los campos aleatorios de Markov, que son modelos gráficos no dirigidos, proporcionan una forma compacta y robusta de modelar una distribución conjunta. Aquí estamos interesados en modelar la distribución conjunta sobre una consulta Q = q1, . . . , qn y un documento D. Se asume que la distribución subyacente sobre pares de documentos y consultas es una distribución de relevancia. Es decir, muestrear de la distribución proporciona pares de documentos y consultas, de modo que el documento sea relevante para la consulta. Un MRF se define por un grafo G y un conjunto de funciones de potencial no negativas sobre los cliques en G. Los nodos en el grafo representan las variables aleatorias y las aristas definen la semántica de independencia de la distribución. Un MRF cumple con la propiedad de Markov, la cual establece que un nodo es independiente de todos sus nodos no vecinos dado los valores observados de sus vecinos. Dado un grafo G, un conjunto de potenciales ψi y un vector de parámetros Λ, la distribución conjunta sobre Q y D está dada por: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) donde Z es una constante de normalización. Seguimos la convención común y parametrizamos los potenciales como ψi(c; Λ) = exp[λifi(c)], donde fi(c) es una función de características de valores reales. 3.1.2 Construcción de G Dada una consulta Q, el grafo G puede ser construido de varias maneras. Sin embargo, siguiendo el trabajo previo, consideramos tres variantes simples [14]. Estas variantes son independencia total, donde cada término de consulta es independiente de los demás dado un documento, dependencia secuencial, que asume que existe una dependencia entre los términos de consulta adyacentes, y dependencia total, que no hace suposiciones de independencia. 3.1.3 Parametrización Los MRFs suelen ser parametrizados comúnmente en función de los cliques máximos de G. Sin embargo, dicha parametrización es demasiado gruesa para nuestras necesidades. Necesitamos una parametrización que nos permita asociar funciones de características con cliques a un nivel más detallado, manteniendo al mismo tiempo el número de características, y por lo tanto el número de parámetros, razonable. Por lo tanto, permitimos que los grupos compartan funciones de características y parámetros basados en conjuntos de grupos. Es decir, todos los subgrupos dentro de un conjunto de subgrupos están asociados con la misma función de característica y comparten un solo parámetro. Esto une de manera efectiva los parámetros de las características asociadas con cada conjunto, lo que reduce significativamente el número de parámetros mientras aún proporciona un mecanismo para el ajuste fino en el nivel de conjuntos de cliques. Proponemos siete conjuntos de cliques para utilizar en la recuperación de información. Los primeros tres conjuntos de cliques consisten en cliques que contienen uno o más términos de consulta y el nodo del documento. Las características sobre estos grupos deberían codificar qué tan bien los términos en la configuración del grupo describen el documento. Estos conjuntos son: • TD - conjunto de cliques que contienen el nodo del documento y exactamente un término de consulta. • OD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en orden secuencial dentro de la consulta. • UD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en cualquier orden dentro de la consulta. Ten en cuenta que UD es un superconjunto de OD. Al atar los parámetros entre los grupos dentro de cada conjunto podemos controlar cuánta influencia recibe cada tipo. Esto también evita el problema de tratar de determinar cómo estimar los pesos para cada clique dentro de los conjuntos. En cambio, ahora solo debemos estimar un parámetro por conjunto. A continuación, consideramos cliques que solo contienen nodos de términos de consulta. Estas cliques, que no fueron consideradas en [14], se definen de manera análoga a las recién definidas, excepto que las cliques solo están formadas por nodos de términos de consulta y no contienen el nodo de documento. Las funciones de características sobre estos conjuntos deben capturar qué tan compatibles son entre sí los términos de consulta. Estas características de grupo pueden adoptar la forma de modelos de lenguaje que imponen la corrección de los términos. Por lo tanto, definimos los siguientes conjuntos de cliques dependientes de la consulta: • TQ - conjunto de cliques que contienen exactamente un término de la consulta. • OQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en orden secuencial dentro de la consulta. • UQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en cualquier orden dentro de la consulta. Finalmente, está la clique que solo contiene el nodo del documento. Las características sobre este nodo pueden ser utilizadas como un tipo de documento previo, codificando propiedades centradas en el documento. Este conjunto de cliques trivial es entonces: • D - conjunto de cliques que contiene solo el nodo único D. Observamos que nuestros conjuntos de cliques forman una cobertura de conjuntos sobre los cliques de G, pero no son una partición, ya que algunos cliques aparecen en múltiples conjuntos de cliques. Después de atar los parámetros en nuestros conjuntos de cliques y usar la forma de la función potencial exponencial, terminamos con la siguiente forma simplificada de la distribución conjunta: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - dependiente del documento y la consulta + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - dependiente de la consulta + λDfD(D) FD(D) - dependiente del documento − log ZΛ documento + independiente de la consulta donde FDQ, FQ y FD son funciones de conveniencia definidas por los componentes dependientes del documento y la consulta, dependientes de la consulta y dependientes del documento de la distribución conjunta, respectivamente. Estos se utilizarán para simplificar y clarificar las expresiones derivadas a lo largo del resto del documento. 3.1.4 Características Cualquier función de característica arbitraria sobre configuraciones de cliques puede ser utilizada en el modelo. La elección correcta de las características depende en gran medida de la tarea de recuperación y la métrica de evaluación. Por lo tanto, es probable que no exista un conjunto único y universalmente aplicable de características. Para dar una idea de la variedad de características que se pueden utilizar, ahora describimos brevemente posibles tipos de características que podrían ser utilizadas. Posibles características dependientes del término de consulta incluyen tf, idf, entidades nombradas, proximidad de términos y estilo de texto, por nombrar algunas. Se pueden utilizar muchos tipos de características dependientes del documento, como la longitud del documento, el PageRank, la legibilidad y el género, entre otros. Dado que nuestro objetivo aquí no es encontrar características óptimas, utilizamos un conjunto simple y fijo de características que han demostrado ser efectivas en trabajos anteriores [14]. Consulte la Tabla 1 para ver la lista de características utilizadas. Estas características intentan capturar la ocurrencia de términos y la proximidad entre términos. Una mejor selección de características en el futuro probablemente conducirá a una mayor efectividad. 3.1.5 Clasificación Dada una consulta Q, deseamos clasificar los documentos en orden descendente según PG,Λ(D|Q). Después de eliminar las expresiones independientes del documento del registro PG,Λ(Q, D), derivamos la siguiente función de clasificación: PG,Λ(D|Q) rango = FDQ(D, Q) + FD(D) (2), que es una simple combinación lineal ponderada de funciones de características que pueden calcularse eficientemente para grafos razonables. 3.1.6 Estimación de Parámetros Ahora que el modelo ha sido completamente especificado, el paso final es estimar los parámetros del modelo. Aunque los MRF son modelos generativos, no es apropiado entrenarlos utilizando la función de valor de características fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Tabla 1: Funciones de características utilizadas en el modelo de campo aleatorio de Markov. Aquí, tfw,D es el número de veces que el término w ocurre en el documento D, tf#1(qi...qi+k),D denota el número de veces que la frase exacta qi . . . qi+k ocurre en el documento D, tf#uw(qi...qj ),D es el número de veces que los términos qi, . . . qj aparecen ordenados o desordenados dentro de una ventana de N términos, y |D| es la longitud del documento D. Los valores de cf y |C| se definen de manera análoga a nivel de colección. Finalmente, α y β son hiperparámetros del modelo que controlan el suavizado para las características de términos únicos y frases, respectivamente. Enfoques convencionales basados en la verosimilitud debido a la divergencia métrica [17]. Es decir, es poco probable que la estimación de máxima verosimilitud sea la estimación que maximiza nuestra métrica de evaluación. Por esta razón, entrenamos de manera discriminativa nuestro modelo para maximizar directamente la métrica de evaluación considerada [14, 15, 25]. Dado que nuestro espacio de parámetros es pequeño, hacemos uso de una estrategia simple de escalada de colina, aunque son posibles otros enfoques más sofisticados [10]. 3.2 Expansión de Conceptos Latentes En esta sección describimos cómo este modelo MRF extendido puede ser utilizado de una manera novedosa para generar conceptos de un solo término y de varios términos que están relacionados temáticamente con alguna consulta original. Como mostraremos, los conceptos generados utilizando nuestra técnica pueden ser utilizados para la expansión de consultas u otras tareas, como sugerir formulaciones alternativas de consultas. Suponemos que cuando un usuario formula su consulta original, tiene en mente un conjunto de conceptos, pero solo puede expresar un pequeño número de ellos en forma de consulta. Tratamos los conceptos que el usuario tiene en mente, pero no expresó explícitamente en la consulta, como conceptos latentes. Estos conceptos latentes pueden consistir en un solo término, varios términos o alguna combinación de ambos. Por lo tanto, nuestro objetivo es recuperar estos conceptos latentes dada alguna consulta original. Esto se puede lograr dentro de nuestro marco de trabajo al expandir primero el grafo original G para incluir el tipo de concepto que nos interesa generar. Llamamos a este gráfico expandido H. En la Figura 1, el gráfico del medio proporciona un ejemplo de cómo construir un gráfico expandido que puede generar conceptos de un solo término. De manera similar, el gráfico de la derecha ilustra un gráfico ampliado que genera dos conceptos de términos. Aunque estos dos ejemplos hacen uso de la suposición de dependencia secuencial (es decir, dependencias entre términos de consulta adyacentes), es importante tener en cuenta que tanto la consulta original como los conceptos de expansión pueden utilizar cualquier estructura de independencia. Después de que H se construye, calculamos PH,Λ(E|Q), una distribución de probabilidad sobre conceptos latentes, de acuerdo a: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) donde R es el universo de todos los documentos posibles y E es un concepto latente que puede consistir en uno o más términos. Dado que no es práctico calcular esta suma, debemos aproximarla. Observamos que PH,Λ(Q, E, D) probablemente se concentra alrededor de aquellos documentos D que están altamente clasificados según la consulta Q. Por lo tanto, aproximamos PH,Λ(E|Q) sumando solo un pequeño subconjunto de documentos relevantes o pseudo-relevantes para la consulta Q. Esto se calcula de la siguiente manera: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) donde RQ es un conjunto de documentos relevantes o pseudo-relevantes para la consulta Q y todos los conjuntos de cliques se construyen utilizando H. Como vemos, la contribución de probabilidad para cada documento en RQ es una combinación de la puntuación original de la consulta para el documento (ver Ecuación 2), la puntuación del concepto E para el documento y la puntuación independiente del documento de E. Por lo tanto, esta ecuación puede interpretarse como la medida de qué tan bien Q y E explican los documentos mejor clasificados y la bondad de E, independientemente de los documentos. Para lograr la máxima robustez, utilizamos un conjunto diferente de parámetros para FQD(Q, D) y FQD(E, D), lo que nos permite ponderar de manera diferente las características de ventana ordenadas y no ordenadas para la consulta original y el concepto de expansión candidato. 3.2.1 Expansión de consulta Para utilizar este marco para la expansión de consultas, primero elegimos un grafo de expansión H que codifique la estructura de concepto latente en la que estamos interesados en expandir la consulta. Luego seleccionamos los k conceptos latentes con la mayor probabilidad dada por la Ecuación 3. Se construye un nuevo grafo G al aumentar el grafo original G con los k conceptos de expansión E1, . . . , Ek. Finalmente, los documentos se clasifican según PG ,Λ(D|Q, E1, . . . , Ek) utilizando la Ecuación 2. 3.2.2 Comparación con los Modelos de Relevancia. Al inspeccionar las Ecuaciones 1 y 3 se revela la estrecha conexión que existe entre LCE y los modelos de relevancia. Ambos modelos esencialmente calculan la probabilidad de un término (o concepto) de la misma manera. Es fácil ver que al igual que el modelo MRF puede ser visto como una generalización del modelado del lenguaje, también LCE puede ser visto como una generalización de los modelos de relevancia. Existen diferencias importantes entre los modelos de lenguaje MRFs/LCE y los modelos de lenguaje unigram/relevancia. Consulte la Figura 1 para ver las representaciones gráficas de ambos modelos. Los modelos de lenguaje unigrama y los modelos de relevancia se basan en la distribución multinomial. Esta suposición de distribución encasilla el modelo en la representación de bolsa de palabras y el uso implícito de características de ocurrencia de términos. Sin embargo, la distribución subyacente al modelo MRF nos permite ir más allá de ambas suposiciones, al modelar tanto las dependencias entre los términos de consulta como permitir el uso explícito de características arbitrarias. Ir más allá de la simplista suposición de la bolsa de palabras de esta manera resulta en un modelo general y robusto y, como mostramos en la siguiente sección, se traduce en mejoras significativas en la efectividad de recuperación. 4. RESULTADOS EXPERIMENTALES Para comprender mejor las fortalezas y debilidades de nuestra técnica, la evaluamos en una amplia gama de conjuntos de datos. La Tabla 2 proporciona un resumen de los conjuntos de datos de TREC considerados. Las colecciones WSJ, AP y ROBUST son más pequeñas y consisten enteramente de artículos de agencias de noticias, mientras que WT10g y GOV2 son colecciones web grandes. Para cada conjunto de datos, dividimos los temas disponibles en un conjunto de entrenamiento y otro de prueba, donde el conjunto de entrenamiento se utiliza únicamente para la estimación de parámetros y el conjunto de prueba se utiliza con fines de evaluación. Todos los experimentos se llevaron a cabo utilizando una versión modificada de Indri, que forma parte del Lemur Toolkit [18, 23]. Todas las colecciones fueron detenidas utilizando una lista estándar de 418 términos comunes y truncadas utilizando un truncador de Porter. En todos los casos, solo se utiliza la parte del título de los temas de TREC para construir las consultas. Construimos G utilizando la suposición de dependencia secuencial para todos los conjuntos de datos [14]. 4.1 Resultados de recuperación ad-hoc Ahora investigamos qué tan bien se desempeña nuestro modelo en la práctica en un entorno de retroalimentación de relevancia pseudo. Comparamos el modelado de lenguaje unigrama (con suavizado de Dirichlet), el modelo MRF (sin expansión), los modelos de relevancia y LCE para comprender mejor cómo se desempeña cada modelo en los diferentes conjuntos de datos. Para el modelo de lenguaje unigrama, se entrenó el parámetro de suavizado. Para el modelo MRF, entrenamos los parámetros del modelo (es decir, y hiperparámetros del modelo (es decir, α, β). Para RM3 y LCE, también entrenamos el número de pseudoNombre Descripción # Docs Temas de Entrenamiento Temas de Prueba WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc. Presione 88-90 242,918 51-150 151-200 ROBUST Robust 2004 datos 528,155 301-450 601-700 WT10g Colección Web de TREC 1,692,096 451-500 501-550 GOV2 Rastreo 2004 del dominio .gov 25,205,179 701-750 751-800 Tabla 2: Resumen de las colecciones y temas de TREC. documentos de retroalimentación relevantes utilizados y el número de términos de expansión. 4.1.1 Expansión con Conceptos de Términos Únicos Comenzamos evaluando qué tan bien funciona nuestro modelo al expandir utilizando solo términos individuales. Antes de describir y analizar los resultados, declaramos explícitamente cómo se calculan las probabilidades de términos de expansión bajo esta configuración (es decir, utilizando la suposición de dependencia secuencial, expandiendo con conceptos de un solo término y utilizando nuestro conjunto de características). Las probabilidades de términos de expansión se calculan de la siguiente manera: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) donde b ∈ Q denota el conjunto de bigramas en Q. Esta ecuación muestra claramente cómo LCE difiere de los modelos de relevancia. Cuando establecemos λTD = λT,D = 1 y todos los demás parámetros en 0, obtenemos la fórmula exacta que se utiliza para calcular las probabilidades de términos en el marco de modelado de relevancia. Por lo tanto, LCE añade dos factores muy importantes a la ecuación. Primero, agrega las características de ventana ordenadas y no ordenadas que se aplican a la consulta original. En segundo lugar, aplica una forma intuitiva similar a tf.idf al término de expansión candidato w. El factor idf, que no está presente en los modelos de relevancia, juega un papel importante en la selección del término de expansión. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figura 2: Histogramas que demuestran y comparan la robustez de los modelos de relevancia (RM3) y la expansión de conceptos latentes (LCE) con respecto al modelo de probabilidad de consulta (QL) para los conjuntos de datos AP, ROBUST y WT10G. Los resultados, evaluados utilizando la precisión promedio media, se muestran en la Tabla 3. Como vemos, el modelo MRF, los modelos de relevancia y LCE siempre superan significativamente al modelo de lenguaje unigrama. Además, LCE muestra mejoras significativas sobre los modelos de relevancia en todos los conjuntos de datos. Las mejoras relativas sobre los modelos de relevancia son del 6.9% para AP, 12.9% para WSJ, 6.5% para ROBUST, 16.7% para WT10G y 7.3% para GOV2. Además, LCE muestra pequeñas mejoras, pero no significativas, respecto al modelado de relevancia para métricas como precisión en 5, 10 y 20. Sin embargo, tanto el modelado de relevancia como el LCE muestran mejoras estadísticamente significativas en dichas métricas sobre el modelo de lenguaje unigrama. Otro resultado interesante es que el modelo MRF es estadísticamente equivalente a los modelos de relevancia en los dos conjuntos de datos web. De hecho, el modelo MRF supera a los modelos de relevancia en el conjunto de datos WT10g. Esto reitera la importancia de las características no unigrama, basadas en la proximidad para la búsqueda web basada en contenido observada previamente [14, 16]. Aunque nuestro modelo tiene más parámetros libres que los modelos de relevancia, sorprendentemente hay poco sobreajuste. En cambio, el modelo muestra buenas propiedades de generalización. 4.1.2 Expansión con Conceptos de Múltiples Términos También investigamos la expansión utilizando conceptos de una y dos palabras. Para cada consulta, expandimos utilizando un conjunto de conceptos de un solo término y un conjunto de conceptos de dos términos. Los conjuntos fueron elegidos de forma independiente. Desafortunadamente, solo se observaron aumentos insignificantes en la precisión promedio. Este resultado puede deberse al hecho de que existen fuertes correlaciones entre los conceptos de expansión de términos individuales. Descubrimos que los dos conceptos de palabras elegidos a menudo consistían en dos términos altamente correlacionados que también son elegidos como conceptos de términos individuales. Por ejemplo, se eligió el concepto de dos términos mercado de valores, mientras que también se eligieron los conceptos de un solo término acciones y mercado. Por lo tanto, muchos conceptos de dos palabras es poco probable que aumenten el poder discriminativo de la consulta ampliada. Este resultado sugiere que los conceptos deben ser elegidos de acuerdo con ciertos criterios que también tengan en cuenta la novedad, la diversidad o las correlaciones de términos. Otro problema potencial es el conjunto de características utilizado. Otros conjuntos de características pueden dar resultados diferentes en última instancia, especialmente si reducen la correlación entre los conceptos de expansión. Por lo tanto, nuestros experimentos no arrojan resultados concluyentes en cuanto a la expansión utilizando conceptos de varios términos. En cambio, los resultados plantean preguntas abiertas interesantes y direcciones para futuras exploraciones. Tabla 3: Promedio de precisión media en el conjunto de pruebas para modelado de lenguaje (LM), campo aleatorio de Markov (MRF), modelos de relevancia (RM3) y expansión de conceptos latentes (LCE). Los superíndices α, β y γ indican mejoras estadísticamente significativas (p < 0.05) sobre LM, MRF y RM3, respectivamente. 4.2 Robustez Como hemos demostrado, los modelos de relevancia y la expansión de conceptos latentes pueden mejorar significativamente la efectividad de recuperación sobre el modelo de probabilidad de consulta base. En esta sección analizamos la robustez de estos dos métodos. Aquí definimos la robustez como el número de consultas cuya efectividad se ve mejorada/afectada (y en qué medida) como resultado de aplicar estos métodos. Una técnica de expansión altamente robusta mejorará significativamente muchas consultas y solo perjudicará mínimamente a unas pocas. La Figura 2 proporciona un análisis de la robustez del modelado de relevancia y la expansión de conceptos latentes para los conjuntos de datos AP, ROBUST y WT10G. El análisis de los dos conjuntos de datos no mostrados es similar. Los histogramas proporcionan, para varios rangos de disminuciones/aumentos relativos en la precisión media promedio, el número de consultas que se vieron perjudicadas/mejoradas con respecto a la línea base de probabilidad de consulta. Como muestran los resultados, LCE muestra una fuerte robustez para cada conjunto de datos. Para AP, los modelos de relevancia mejoran 38 consultas y perjudican 11, mientras que LCE mejora 35 y perjudica 14. Aunque los modelos de relevancia mejoran la efectividad de 3 consultas más que LCE, la mejora relativa exhibida por LCE es significativamente mayor. Para el conjunto de datos ROBUST, los modelos de relevancia mejoran 67 consultas y perjudican 32, y LCE mejora 77 y perjudica 22. Finalmente, para la colección WT10G, los modelos de relevancia mejoran 32 consultas y perjudican 16, y LCE mejora 35 y perjudica 14. Al igual que con AP, la cantidad de mejora exhibida por el LCE frente a los modelos de relevancia es significativamente mayor tanto para los conjuntos de datos ROBUST como WT10G. Además, cuando LCE afecta al rendimiento, es menos probable que afecte tanto como el modelado de relevancia, lo cual es una propiedad deseable. En general, LCE mejora la efectividad para el 65%-80% de las consultas, dependiendo del conjunto de datos. Cuando se utiliza en combinación con un sistema de predicción de rendimiento de consulta altamente preciso, puede ser posible expandir selectivamente las consultas y minimizar la pérdida asociada con el rendimiento sub-baseline. 4.3 Generación de Conceptos de Múltiples Términos Aunque encontramos que la expansión utilizando conceptos de múltiples términos no logró producir mejoras concluyentes en la efectividad, hay otras tareas potenciales para las cuales estos conceptos pueden ser útiles, como sugerencia/reformulación de consultas, resumen y extracción de conceptos. Por ejemplo, para una tarea de sugerencia de consultas, la consulta original podría usarse para generar un conjunto de conceptos latentes que corresponden a formulaciones alternativas de la consulta. Aunque evaluar nuestro modelo en estas tareas está fuera del alcance de este trabajo, deseamos mostrar un ejemplo ilustrativo de los tipos de conceptos generados utilizando nuestro modelo. En la Tabla 4, presentamos los conceptos de una, dos y tres palabras más probables generados utilizando LCE para la consulta logros del telescopio Hubble utilizando los 25 documentos mejor clasificados de la colección ROBUST. Es bien sabido que generar conceptos de múltiples términos utilizando un modelo basado en unigramas produce resultados insatisfactorios, ya que no considera las dependencias entre los términos. Esto no es el caso al generar conceptos de múltiples términos usando nuestro modelo. En cambio, la mayoría de los conceptos generados son bien formados y significativos. Hay varios casos donde los conceptos son menos coherentes, como espejo espejo espejo. En este caso, la probabilidad de que aparezca el término \"espejo\" en un documento pseudo-relevante supera a las características de modelado de lenguaje (por ejemplo, fOQ), lo que provoca que este concepto no coherente tenga una alta probabilidad. Tales ejemplos son minoría, sin embargo. No solo los conceptos generados son bien formados y significativos, sino que también son relevantes al tema de la consulta original. Como podemos ver, todos los conceptos generados están relacionados con el tema y de alguna manera están relacionados con el telescopio Hubble. Es interesante ver que el concepto de fallo del telescopio Hubble es uno de los tres conceptos de términos más probables, dado que es algo contradictorio con la consulta original. A pesar de esta contradicción, es probable que los documentos que discuten las fallas del telescopio también describan los éxitos, por lo tanto, es probable que este sea un concepto significativo. Una cosa importante a tener en cuenta es que los conceptos generados por LCE son de una naturaleza diferente a los que se generarían utilizando un modelo de relevancia de bigrama. Por ejemplo, un modelo de bigrama sería poco probable que genere el concepto telescopio espacio NASA, ya que ninguno de los bigramas que componen el concepto tiene una alta probabilidad. Sin embargo, dado que nuestro modelo se basa en una serie de características diferentes sobre varios tipos de cliques, es más general y robusto que un modelo de bigrama. Aunque solo proporcionamos los conceptos generados para una sola consulta, señalamos que el mismo análisis y conclusiones se generalizan a través de otros conjuntos de datos, con conceptos coherentes y relacionados temáticamente generados de manera consistente utilizando LCE. 4.4 Discusión Nuestra técnica de expansión de conceptos latentes captura dos tipos de dependencia semiortogonales. En la recuperación de información, ha existido un interés a largo plazo en comprender el papel de la dependencia de términos. De esta investigación, se han identificado dos tipos generales de dependencias. El primer tipo de dependencia es la dependencia sintáctica. Este tipo de dependencia abarca frases, proximidad de términos y co-ocurrencia de términos [2, 4, 5, 7, 26]. Estos métodos capturan el hecho de que las consultas imponen implícita o explícitamente un cierto conjunto de dependencias posicionales. El segundo tipo es la dependencia semántica. Ejemplos de dependencia semántica son la retroalimentación de relevancia, la retroalimentación de pseudo-relevancia, sinónimos y en cierta medida el truncamiento [3]. Estas técnicas han sido exploradas tanto en el lado de la consulta como en el lado del documento. En el lado de la consulta, esto se suele hacer utilizando alguna forma de expansión de consulta, como modelos de relevancia o LCE. En el lado del documento, esto se hace como expansión de documentos o suavizado de documentos [11, 13, 24]. Aunque puede haber cierta superposición entre las dependencias sintácticas y semánticas, en su mayoría son ortogonales. Nuestro modelo utiliza ambos tipos de dependencias. El uso de características de frase y proximidad dentro del modelo captura dependencias sintácticas, mientras que LCE captura dependencias semánticas del lado de la consulta. Esto explica por qué la mejora inicial en la efectividad lograda al usar el modelo MRF no se pierde después de la expansión de consultas. Si los mismos tipos de dependencias fueran capturados tanto por dependencias sintácticas como semánticas, se esperaría que LCE funcionara aproximadamente igual de bien que los modelos de relevancia. Por lo tanto, al modelar ambos tipos de dependencias, observamos un efecto aditivo en lugar de un efecto absorbente. Una área interesante de trabajo futuro es determinar si modelar las dependencias semánticas del lado del documento puede aportar algo al modelo. Resultados previos que han combinado dependencias semánticas del lado de la consulta y del documento han mostrado resultados mixtos [13, 27]. 5. CONCLUSIONES En este artículo propusimos una técnica robusta de expansión de consultas llamada expansión de conceptos latentes. La técnica se demostró ser una extensión natural del modelo de campo aleatorio de Markov para la recuperación de información y una generalización de los modelos de relevancia. LCE es novedoso en el sentido de que realiza una expansión de un solo término o de varios términos dentro de un marco que permite el modelado de dependencias entre términos y el uso de características arbitrarias, mientras que trabajos anteriores se basaban en la suposición de la bolsa de palabras y características de ocurrencia de términos. Mostramos que la técnica puede ser utilizada para producir conceptos de expansión de varios términos de alta calidad, bien formados y relevantes desde el punto de vista temático. Los conceptos generados pueden ser utilizados en un módulo de sugerencia de consultas alternativas. También demostramos que el modelo es altamente efectivo. De hecho, logra mejoras significativas en la precisión promedio media en comparación con los modelos de relevancia en una selección de conjuntos de datos de TREC. También se demostró que el modelo MRF por sí solo, sin ninguna expansión de consulta, supera a los modelos de relevancia en grandes conjuntos de datos web. Esto reafirma observaciones previas de que modelar dependencias a través del uso de características de proximidad dentro del MRF tiene un mayor impacto en colecciones más grandes y ruidosas que en colecciones más pequeñas y bien comportadas. Finalmente, reiteramos la importancia de elegir términos de expansión que modelen la relevancia, en lugar de los documentos relevantes, y mostramos cómo LCE captura tanto las dependencias sintácticas como semánticas del lado de la consulta. El trabajo futuro se centrará en incorporar dependencias del lado del documento también. Agradecimientos Este trabajo fue apoyado en parte por el Centro de Recuperación de Información Inteligente, en parte por la subvención NSF #CNS-0454018, en parte por ARDA y la subvención NSF #CCF-0205575, y en parte por Microsoft Live Labs. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son responsabilidad del autor o los autores y no necesariamente reflejan las del patrocinador.  REFERENCIAS [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker y C. Wade. UMass en TREC 2004: Novedad y DIFICULTAD. En Actas en línea de la Conferencia de Recuperación de Información de 2004, 2004. [2] C. L. A. Clarke y G. V. Cormack. Recuperación y clasificación de la subcadena más corta. ACM Trans. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate to Spanish? Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson y J. Callan. Expansión de consultas utilizando modelos de caminata aleatoria. En Proc. 14th Intl. Conf. sobre Gestión de Información y Conocimiento, páginas 704-711, 2005. [4] W. B. Croft. Consultas booleanas y dependencias de términos en modelos de recuperación probabilística. Revista de la Sociedad Americana de Ciencia de la Información, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle y D. Lewis. El uso de frases y consultas estructuradas en la recuperación de información. En Proc. 14º Anu. Internacional. Conferencia ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 32-45, 1991. [6] K. Eguchi. Experimentos de expansión de consultas NTCIR-5 utilizando modelos de dependencia de términos. En Actas del Quinto Taller de Reunión NTCIR sobre Evaluación de Tecnologías de Acceso a la Información, páginas 494-501, 2005. [7] J. Fagan. Indexación automática de frases para la recuperación de documentos: Un examen de métodos sintácticos y no sintácticos. En el Proc. décimo anual. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 91-101, 1987. [8] J. Gao, J. Nie, G. Wu y G. Cao. Modelo de lenguaje de dependencia para recuperación de información. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 170-177, 2004. [9] D. Harper y C. J. van Rijsbergen. Una evaluación de la retroalimentación en la recuperación de documentos utilizando datos de co-ocurrencia. Revista de Documentación, 34(3):189-216, 1978. [10] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Proc. de la Conf. Internacional de Aprendizaje Automático, páginas 377-384, 2005. [11] O. Kurland y L. Lee. Estructura del corpus, modelos de lenguaje y recuperación de información ad-hoc. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 194-201, 2004. [12] V. Lavrenko y W. B. Croft. Modelos de lenguaje basados en relevancia. En Proc. 24º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 120-127, 2001. [13] X. Liu y W. B. Croft. Recuperación basada en clústeres utilizando modelos de lenguaje. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 186-193, 2004. [14] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias entre términos. En Proc. 28vo Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [15] D. Metzler y W. B. Croft. Modelos basados en características lineales para la recuperación de información. Recuperación de información, por aparecer, 2006. [16] D. Metzler, T. Strohman, Y. Zhou y W. B. Croft. Indri en la pista de terabyte en 2005. En Actas en línea de la Conferencia de Recuperación de Texto de 2005, 2005. [17] W. Morgan, W. Greiff y J. Henderson. Maximización directa de la precisión promedio mediante escalada de colina con una comparación con un enfoque de entropía máxima. Informe técnico, MITRE, 2004. [18] P. Ogilvie y J. P. Callan. Experimentos utilizando el kit de herramientas de lémures. En Proc. de la Conferencia de Recuperación de Texto, 2001. [19] R. Papka y J. Allan. Por qué las ventanas más grandes son mejores que las más pequeñas. Informe técnico, Universidad de Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu y M. Gatford. Okapi en trec-3. En Actas en línea de la Tercera Conferencia de Recuperación de Texto, páginas 109-126, 1995. [21] J. J. Rocchio. Retroalimentación de relevancia en la recuperación de información, páginas 313-323. Prentice-Hall, 1971. [22] F. Song y W. B. Croft. Un modelo de lenguaje general para la recuperación de información. En Proc. octava conferencia internacional sobre Gestión de la Información y el Conocimiento (CIKM 99), páginas 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle y W. B. Croft. Indri: Un motor de búsqueda basado en modelos de lenguaje para consultas complejas. En Actas de la Conferencia Internacional sobre Análisis de Inteligencia, 2004. [24] T. Tao, X. Wang, Q. Mei y C. Zhai. Recuperación de información del modelo de lenguaje con expansión de documentos. En Proc. de HLT/NAACL, páginas 407-414, 2006. [25] B. Taskar, C. Guestrin y D. Koller. Redes de Markov de margen máximo. En Proc. de Avances en Sistemas de Información Neural (NIPS 2003), 2003. [26] C. J. van Rijsbergen. Una base teórica para el uso de datos de coocurrencia en la recuperación de información. Revista de Documentación, 33(2):106-119, 1977. [27] X. Wei y W. B. Croft. Modelos de documentos basados en LDA para recuperación ad-hoc. En Proc. 29º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 178-185, 2006. [28] J. Xu y W. B. Croft. Mejorando la efectividad de la recuperación de información con análisis de contexto local. ACM Trans. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate into Spanish? Syst., 18(1):79-112, 2000. [29] C. Zhai y J. Lafferty. Retroalimentación basada en modelos en el enfoque de modelado del lenguaje para la recuperación de información. En Proc. 10th Intl. Conferencia sobre Gestión de la Información y el Conocimiento, páginas 403-410, 2001.",
    "original_sentences": [
        "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
        "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
        "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
        "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
        "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
        "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
        "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
        "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
        "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
        "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
        "A great deal of information is lost during the process of translating from the information need to the actual query.",
        "For this reason, there has been a strong interest in query expansion techniques.",
        "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
        "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
        "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
        "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
        "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
        "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
        "Until now, the model has been solely used for ranking documents in response to a given query.",
        "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
        "There are three primary contributions of our work.",
        "First, LCE provides a mechanism for combining term dependence with query expansion.",
        "Previous query expansion techniques are based on bag of words models.",
        "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
        "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
        "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
        "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
        "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
        "Most previous techniques, by default, generate terms independently.",
        "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
        "Our approach is both formally motivated and a natural extension of the underlying model.",
        "The remainder of this paper is laid out as follows.",
        "In Section 2 we describe related query expansion approaches.",
        "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
        "In Section 4 we evaluate our proposed model and analyze the results.",
        "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
        "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
        "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
        "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
        "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
        "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
        "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
        "This separates the content model from the background model.",
        "The content model is then interpolated with the original query model to form the expanded query.",
        "The other technique, relevance models, is more closely related to our work.",
        "Therefore, we go into the details of the model.",
        "Much like model-based feedback, relevance models estimate an improved query model.",
        "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
        "Instead, they model a more generalized notion of relevance, as we now show.",
        "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
        "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
        "In the pseudo-relevant case, these are the top ranked documents for query Q.",
        "Furthermore, it is assumed that P(D) is uniform over this set.",
        "These mild assumptions make computing the Bayesian posterior more practical.",
        "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
        "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
        "This can be thought of as expanding the original query by k weighted terms.",
        "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
        "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
        "However, there have been several attempts to expand using multi-term concepts.",
        "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
        "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
        "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
        "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
        "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
        "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
        "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
        "MODEL This section details our proposed latent concept expansion technique.",
        "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
        "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
        "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
        "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
        "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
        "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
        "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
        "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
        "However, following previous work, we consider three simple variants [14].",
        "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
        "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
        "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
        "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
        "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
        "We propose seven clique sets for use with information retrieval.",
        "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
        "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
        "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
        "Note that UD is a superset of OD.",
        "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
        "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
        "Instead, we now must only estimate a single parameter per set.",
        "Next, we consider cliques that only contain query term nodes.",
        "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
        "Feature functions over these cliques should capture how compatible query terms are to one another.",
        "These clique features may take on the form of language models that impose well-formedness of the terms.",
        "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
        "Finally, there is the clique that only contains the document node.",
        "Features over this node can be used as a type of document prior, encoding document-centric properties.",
        "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
        "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
        "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
        "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
        "Therefore, there is likely not to be a single, universally applicable set of features.",
        "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
        "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
        "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
        "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
        "See Table 1 for a list of features used.",
        "These features attempt to capture term occurrence and term proximity.",
        "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
        "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
        "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
        "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
        "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
        "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
        "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
        "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
        "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
        "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
        "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
        "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
        "It is, therefore, our goal to recover these latent concepts given some original query.",
        "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
        "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
        "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
        "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
        "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
        "Since it is not practical to compute this summation, we must approximate it.",
        "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
        "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
        "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
        "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
        "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
        "We then select the k latent concepts with the highest likelihood given by Equation 3.",
        "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
        "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
        "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
        "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
        "There are important differences between MRFs/LCE and unigram language models/relevance models.",
        "See Figure 1 for graphical model representations of both models.",
        "Unigram language models and relevance models are based on the multinomial distribution.",
        "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
        "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
        "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
        "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
        "Table 2 provides a summary of the TREC data sets considered.",
        "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
        "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
        "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
        "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
        "In all cases, only the title portion of the TREC topics are used to construct queries.",
        "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
        "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
        "For the unigram language model, the smoothing parameter was trained.",
        "For the MRF model, we train the model parameters (i.e.",
        "Λ) and model hyperparameters (i.e. α, β).",
        "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
        "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
        "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
        "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
        "This equation clearly shows how LCE differs from relevance models.",
        "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
        "Therefore, LCE adds two very important factors to the equation.",
        "First, it adds the ordered and unordered window features that are applied to the original query.",
        "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
        "The results, evaluated using mean average precision, are given in Table 3.",
        "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
        "In addition, LCE shows significant improvements over relevance models across all data sets.",
        "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
        "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
        "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
        "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
        "In fact, the MRF model outperforms relevance models on the WT10g data set.",
        "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
        "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
        "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
        "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
        "The sets were chosen independently.",
        "Unfortunately, only negligible increases in mean average precision were observed.",
        "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
        "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
        "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
        "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
        "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
        "Another potential issue is the feature set used.",
        "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
        "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
        "Instead, the results introduce interesting open questions and directions for future exploration.",
        "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
        "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
        "In this section we analyze the robustness of these two methods.",
        "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
        "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
        "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
        "The analysis for the two data sets not shown is similar.",
        "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
        "As the results show, LCE exhibits strong robustness for each data set.",
        "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
        "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
        "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
        "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
        "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
        "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
        "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
        "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
        "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
        "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
        "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
        "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
        "This is not the case when generating multi-term concepts using our model.",
        "Instead, a majority of the concepts generated are well-formed and meaningful.",
        "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
        "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
        "Such examples are in the minority, however.",
        "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
        "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
        "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
        "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
        "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
        "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
        "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
        "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
        "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
        "Out of this research, two broad types of dependencies have been identified.",
        "The first type of dependence is syntactic dependence.",
        "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
        "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
        "The second type is semantic dependence.",
        "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
        "These techniques have been explored on both the query and document side.",
        "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
        "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
        "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
        "Our model uses both types of dependencies.",
        "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
        "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
        "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
        "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
        "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
        "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
        "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
        "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
        "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
        "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
        "The concepts generated can be used in an alternative query suggestion module.",
        "We also showed that the model is highly effective.",
        "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
        "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
        "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
        "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
        "Future work will look at incorporating document-side dependencies, as well.",
        "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
        "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
        "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
        "UMass at TREC 2004: Novelty and HARD.",
        "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
        "Shortest-substring retrieval and ranking.",
        "ACM Trans.",
        "Inf.",
        "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
        "Query expansion using random walk models.",
        "In Proc. 14th Intl.",
        "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
        "Boolean queries and term dependencies in probabilistic retrieval models.",
        "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
        "The use of phrases and structured queries in information retrieval.",
        "In Proc. 14th Ann.",
        "Intl.",
        "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
        "NTCIR-5 query expansion experiments using term dependence models.",
        "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
        "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
        "In Proc. tenth Ann.",
        "Intl.",
        "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
        "Dependence language model for information retrieval.",
        "In Proc. 27th Ann.",
        "Intl.",
        "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
        "An evaluation of feedback in document retrieval using co-occurrence data.",
        "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
        "A support vector method for multivariate performance measures.",
        "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
        "Corpus structure, language models, and ad-hoc information retrieval.",
        "In Proc. 27th Ann.",
        "Intl.",
        "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
        "Relevance-based language models.",
        "In Proc. 24th Ann.",
        "Intl.",
        "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
        "Cluster-based retrieval using language models.",
        "In Proc. 27th Ann.",
        "Intl.",
        "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
        "A Markov random field model for term dependencies.",
        "In Proc. 28th Ann.",
        "Intl.",
        "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
        "Linear feature based models for information retrieval.",
        "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
        "Indri at terabyte track 2005.",
        "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
        "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
        "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
        "Experiments using the lemur toolkit.",
        "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
        "Why bigger windows are better than smaller ones.",
        "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
        "Okapi at trec-3.",
        "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
        "Relevance Feedback in Information Retrieval, pages 313-323.",
        "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
        "A general language model for information retrieval.",
        "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
        "Indri: A language model-based serach engine for complex queries.",
        "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
        "Language model information retrieval with document expansion.",
        "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
        "Max-margin markov networks.",
        "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
        "A theoretical basis for the use of cooccurrence data in information retrieval.",
        "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
        "LDA-based document models for ad-hoc retrieval.",
        "In Proc. 29th Ann.",
        "Intl.",
        "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
        "Improving the effectiveness of information retrieval with local context analysis.",
        "ACM Trans.",
        "Inf.",
        "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
        "Model-based feedback in the language modeling approach to information retrieval.",
        "In Proc. 10th Intl.",
        "Conf. on Information and Knowledge Management, pages 403-410, 2001."
    ],
    "translated_text_sentences": [
        "Expansión de conceptos latentes utilizando campos aleatorios de Markov. Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Centro de Recuperación de Información Inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 RESUMEN La expansión de consultas, en forma de retroalimentación de pseudo relevancia o retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación.",
        "La mayoría de enfoques anteriores han ignorado problemas importantes, como el papel de las características y la importancia de modelar las dependencias entre términos.",
        "En este artículo, proponemos una técnica robusta de expansión de consultas basada en el modelo de campo aleatorio de Markov para la recuperación de información.",
        "La técnica, llamada expansión de conceptos latentes, proporciona un mecanismo para modelar las dependencias de términos durante la expansión.",
        "Además, el uso de características arbitrarias dentro del modelo proporciona un marco poderoso para ir más allá de las simples características de ocurrencia de términos que son utilizadas implícitamente por la mayoría de las otras técnicas de expansión.",
        "Evaluamos nuestra técnica frente a modelos de relevancia, una técnica de expansión de consultas de modelado de lenguaje de última generación.",
        "Nuestro modelo demuestra mejoras consistentes y significativas en la efectividad de recuperación en varios conjuntos de datos de TREC.",
        "También describimos cómo nuestra técnica puede ser utilizada para generar conceptos significativos de varios términos para tareas como sugerencia/reformulación de consultas.",
        "Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales Algoritmos, Experimentación, Teoría 1.",
        "Los usuarios de los sistemas de recuperación de información deben expresar necesidades de información complejas en términos de expresiones booleanas, una lista corta de palabras clave, una oración, una pregunta o posiblemente un relato más extenso.",
        "Se pierde mucha información durante el proceso de traducción desde la necesidad de información hasta la consulta real.",
        "Por esta razón, ha habido un fuerte interés en las técnicas de expansión de consultas.",
        "Tales técnicas se utilizan para ampliar la consulta original y producir una representación que refleje mejor la necesidad de información subyacente.",
        "Las técnicas de expansión de consultas han sido ampliamente estudiadas para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la retroalimentación de pseudo-relevancia [12, 21, 28, 29].",
        "Recientemente, se propuso un modelo de campo aleatorio de Markov (MRF) para la recuperación de información que va más allá de la simplista suposición de bolsa de palabras que subyace en BM25 y en el enfoque de modelado de lenguaje (unigrama) para la recuperación de información [20, 22].",
        "El modelo MRF generaliza los modelos de unigrama, bigrama y otras diversas dependencias [14].",
        "La mayoría de los modelos de dependencia de términos pasados no han logrado mostrar mejoras consistentes y significativas sobre las líneas de base de unigramas, con pocas excepciones [8].",
        "El modelo MRF, sin embargo, ha demostrado ser altamente efectivo en una serie de tareas, incluyendo la recuperación ad hoc [14, 16], la búsqueda de páginas con nombres [16] y la búsqueda web en japonés [6].",
        "Hasta ahora, el modelo ha sido utilizado únicamente para clasificar documentos en respuesta a una consulta dada.",
        "En este trabajo, mostramos cómo el modelo puede ser ampliado y utilizado para la expansión de consultas utilizando una técnica que llamamos expansión de conceptos latentes (LCE).",
        "Hay tres contribuciones principales de nuestro trabajo.",
        "Primero, LCE proporciona un mecanismo para combinar la dependencia de términos con la expansión de consultas.",
        "Las técnicas de expansión de consultas anteriores se basan en modelos de bolsa de palabras.",
        "Por lo tanto, al realizar la expansión de consultas utilizando el modelo MRF, podemos estudiar la dinámica entre la dependencia de términos y la expansión de consultas.",
        "A continuación, como mostraremos, el modelo MRF permite que se utilicen características arbitrarias dentro del modelo.",
        "Las técnicas de expansión de consultas en el pasado solo han hecho uso implícito de características de ocurrencia de términos.",
        "Al utilizar conjuntos de características más robustos, es posible producir términos de expansión mejores que discriminan de manera más efectiva entre documentos relevantes y no relevantes.",
        "Finalmente, nuestro enfoque propuesto proporciona de manera fluida un mecanismo para generar conceptos de una sola y múltiples términos.",
        "La mayoría de las técnicas anteriores, por defecto, generan términos de forma independiente.",
        "Ha habido varios enfoques que hacen uso de conceptos generalizados, sin embargo, dichos enfoques fueron algo heurísticos y realizados fuera del modelo [19, 28].",
        "Nuestro enfoque está motivado tanto formalmente como es una extensión natural del modelo subyacente.",
        "El resto de este documento está estructurado de la siguiente manera.",
        "En la Sección 2 describimos enfoques relacionados de expansión de consultas.",
        "La sección 3 proporciona una visión general del modelo MRF y detalla nuestra técnica propuesta de expansión de conceptos latentes.",
        "En la Sección 4 evaluamos nuestro modelo propuesto y analizamos los resultados.",
        "Finalmente, la Sección 5 concluye el artículo y resume los principales resultados. 2.",
        "TRABAJO RELACIONADO Uno de los enfoques clásicos y más ampliamente utilizados para la expansión de consultas es el algoritmo de Rocchio [21].",
        "El enfoque de Rocchio, que fue desarrollado dentro del modelo de espacio vectorial, reajusta el vector de consulta original moviendo los pesos hacia el conjunto de documentos relevantes o pseudo-relevantes y alejándolos de los documentos no relevantes.",
        "Desafortunadamente, no es posible aplicar formalmente el enfoque de Rocchio a un modelo de recuperación estadística, como el modelado del lenguaje para la recuperación de información.",
        "Se han desarrollado varias técnicas de expansión de consultas formalizadas para el marco de modelado de lenguaje, incluyendo el feedback basado en el modelo de Zhai y Lafferty y los modelos de relevancia de Lavrenko y Crofts [12, 29].",
        "Ambos enfoques intentan utilizar documentos pseudo-relevantes o relevantes para estimar un modelo de consulta mejor.",
        "El feedback basado en modelos encuentra el modelo que mejor describe los documentos relevantes teniendo en cuenta un modelo de fondo (ruido).",
        "Esto separa el modelo de contenido del modelo de fondo.",
        "El modelo de contenido se interpola con el modelo de consulta original para formar la consulta ampliada.",
        "La otra técnica, modelos de relevancia, está más relacionada con nuestro trabajo.",
        "Por lo tanto, entramos en los detalles del modelo.",
        "Al igual que el feedback basado en modelos, los modelos de relevancia estiman un modelo de consulta mejorado.",
        "La única diferencia entre los dos enfoques es que los modelos de relevancia no modelan explícitamente los documentos relevantes o pseudo-relevantes.",
        "En cambio, ellos modelan una noción más generalizada de relevancia, como mostraremos ahora.",
        "Dada una consulta Q, un modelo de relevancia es una distribución multinomial, P(·|Q), que codifica la probabilidad de cada término dado la consulta como evidencia.",
        "Se calcula como: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) donde RQ es el conjunto de documentos que son relevantes o pseudo relevantes para la consulta Q.",
        "En el caso pseudo-relevante, estos son los documentos mejor clasificados para la consulta Q.",
        "Además, se asume que P(D) es uniforme en este conjunto.",
        "Estas suposiciones suaves hacen que el cálculo del posterior bayesiano sea más práctico.",
        "Después de que el modelo es estimado, los documentos son clasificados por recortar el modelo de relevancia al elegir los k términos más probables de P(·|Q).",
        "Esta distribución recortada se interpola luego con el modelo de consulta de máxima verosimilitud original.",
        "Esto se puede considerar como la expansión de la consulta original por k términos ponderados.",
        "A lo largo del resto de este trabajo, nos referimos a esta instancia de modelos de relevancia como RM3.",
        "Ha habido relativamente poco trabajo realizado en el área de expansión de consultas en el contexto de modelos de dependencia [9].",
        "Sin embargo, ha habido varios intentos de expandir utilizando conceptos de varios términos.",
        "El método de análisis de contexto local (LCA) de Xu y Crofts combinaba la recuperación a nivel de pasaje con la expansión de conceptos, donde los conceptos eran términos y frases simples [28].",
        "Los conceptos de expansión fueron elegidos y ponderados utilizando una métrica basada en estadísticas de co-ocurrencia.",
        "Sin embargo, no está claro, basándose en el análisis realizado, cuánto ayudaron las frases en comparación con los términos individuales solos.",
        "Papka y Allan investigan el uso de retroalimentación de relevancia para realizar la expansión de conceptos de varios términos en el enrutamiento de documentos [19].",
        "Los conceptos utilizados en su trabajo son más generales que los utilizados en el LCA e incluyen estructuras de lenguaje de consulta InQuery, como #UW50(casa blanca), que corresponde al concepto en el que los términos casa y blanca ocurren, en cualquier orden, dentro de 50 términos uno del otro.",
        "Los resultados mostraron que combinar conceptos de un solo término y conceptos de varios términos con una ventana grande mejoró significativamente la efectividad.",
        "Sin embargo, no está claro si el mismo enfoque también es efectivo para la recuperación ad hoc, debido a las diferencias en las tareas. 3.",
        "Este apartado detalla nuestra técnica propuesta de expansión de conceptos latentes.",
        "Como se mencionó anteriormente, la técnica es una extensión del modelo MRF para la recuperación de información [14].",
        "Por lo tanto, comenzamos proporcionando una visión general del modelo MRF y nuestras extensiones propuestas. 3.1 MRFs para IR 3.1.1 Conceptos básicos Los campos aleatorios de Markov, que son modelos gráficos no dirigidos, proporcionan una forma compacta y robusta de modelar una distribución conjunta.",
        "Aquí estamos interesados en modelar la distribución conjunta sobre una consulta Q = q1, . . . , qn y un documento D. Se asume que la distribución subyacente sobre pares de documentos y consultas es una distribución de relevancia.",
        "Es decir, muestrear de la distribución proporciona pares de documentos y consultas, de modo que el documento sea relevante para la consulta.",
        "Un MRF se define por un grafo G y un conjunto de funciones de potencial no negativas sobre los cliques en G. Los nodos en el grafo representan las variables aleatorias y las aristas definen la semántica de independencia de la distribución.",
        "Un MRF cumple con la propiedad de Markov, la cual establece que un nodo es independiente de todos sus nodos no vecinos dado los valores observados de sus vecinos.",
        "Dado un grafo G, un conjunto de potenciales ψi y un vector de parámetros Λ, la distribución conjunta sobre Q y D está dada por: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) donde Z es una constante de normalización.",
        "Seguimos la convención común y parametrizamos los potenciales como ψi(c; Λ) = exp[λifi(c)], donde fi(c) es una función de características de valores reales. 3.1.2 Construcción de G Dada una consulta Q, el grafo G puede ser construido de varias maneras.",
        "Sin embargo, siguiendo el trabajo previo, consideramos tres variantes simples [14].",
        "Estas variantes son independencia total, donde cada término de consulta es independiente de los demás dado un documento, dependencia secuencial, que asume que existe una dependencia entre los términos de consulta adyacentes, y dependencia total, que no hace suposiciones de independencia. 3.1.3 Parametrización Los MRFs suelen ser parametrizados comúnmente en función de los cliques máximos de G. Sin embargo, dicha parametrización es demasiado gruesa para nuestras necesidades.",
        "Necesitamos una parametrización que nos permita asociar funciones de características con cliques a un nivel más detallado, manteniendo al mismo tiempo el número de características, y por lo tanto el número de parámetros, razonable.",
        "Por lo tanto, permitimos que los grupos compartan funciones de características y parámetros basados en conjuntos de grupos.",
        "Es decir, todos los subgrupos dentro de un conjunto de subgrupos están asociados con la misma función de característica y comparten un solo parámetro.",
        "Esto une de manera efectiva los parámetros de las características asociadas con cada conjunto, lo que reduce significativamente el número de parámetros mientras aún proporciona un mecanismo para el ajuste fino en el nivel de conjuntos de cliques.",
        "Proponemos siete conjuntos de cliques para utilizar en la recuperación de información.",
        "Los primeros tres conjuntos de cliques consisten en cliques que contienen uno o más términos de consulta y el nodo del documento.",
        "Las características sobre estos grupos deberían codificar qué tan bien los términos en la configuración del grupo describen el documento.",
        "Estos conjuntos son: • TD - conjunto de cliques que contienen el nodo del documento y exactamente un término de consulta. • OD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en orden secuencial dentro de la consulta. • UD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en cualquier orden dentro de la consulta.",
        "Ten en cuenta que UD es un superconjunto de OD.",
        "Al atar los parámetros entre los grupos dentro de cada conjunto podemos controlar cuánta influencia recibe cada tipo.",
        "Esto también evita el problema de tratar de determinar cómo estimar los pesos para cada clique dentro de los conjuntos.",
        "En cambio, ahora solo debemos estimar un parámetro por conjunto.",
        "A continuación, consideramos cliques que solo contienen nodos de términos de consulta.",
        "Estas cliques, que no fueron consideradas en [14], se definen de manera análoga a las recién definidas, excepto que las cliques solo están formadas por nodos de términos de consulta y no contienen el nodo de documento.",
        "Las funciones de características sobre estos conjuntos deben capturar qué tan compatibles son entre sí los términos de consulta.",
        "Estas características de grupo pueden adoptar la forma de modelos de lenguaje que imponen la corrección de los términos.",
        "Por lo tanto, definimos los siguientes conjuntos de cliques dependientes de la consulta: • TQ - conjunto de cliques que contienen exactamente un término de la consulta. • OQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en orden secuencial dentro de la consulta. • UQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en cualquier orden dentro de la consulta.",
        "Finalmente, está la clique que solo contiene el nodo del documento.",
        "Las características sobre este nodo pueden ser utilizadas como un tipo de documento previo, codificando propiedades centradas en el documento.",
        "Este conjunto de cliques trivial es entonces: • D - conjunto de cliques que contiene solo el nodo único D. Observamos que nuestros conjuntos de cliques forman una cobertura de conjuntos sobre los cliques de G, pero no son una partición, ya que algunos cliques aparecen en múltiples conjuntos de cliques.",
        "Después de atar los parámetros en nuestros conjuntos de cliques y usar la forma de la función potencial exponencial, terminamos con la siguiente forma simplificada de la distribución conjunta: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - dependiente del documento y la consulta + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - dependiente de la consulta + λDfD(D) FD(D) - dependiente del documento − log ZΛ documento + independiente de la consulta donde FDQ, FQ y FD son funciones de conveniencia definidas por los componentes dependientes del documento y la consulta, dependientes de la consulta y dependientes del documento de la distribución conjunta, respectivamente.",
        "Estos se utilizarán para simplificar y clarificar las expresiones derivadas a lo largo del resto del documento. 3.1.4 Características Cualquier función de característica arbitraria sobre configuraciones de cliques puede ser utilizada en el modelo.",
        "La elección correcta de las características depende en gran medida de la tarea de recuperación y la métrica de evaluación.",
        "Por lo tanto, es probable que no exista un conjunto único y universalmente aplicable de características.",
        "Para dar una idea de la variedad de características que se pueden utilizar, ahora describimos brevemente posibles tipos de características que podrían ser utilizadas.",
        "Posibles características dependientes del término de consulta incluyen tf, idf, entidades nombradas, proximidad de términos y estilo de texto, por nombrar algunas.",
        "Se pueden utilizar muchos tipos de características dependientes del documento, como la longitud del documento, el PageRank, la legibilidad y el género, entre otros.",
        "Dado que nuestro objetivo aquí no es encontrar características óptimas, utilizamos un conjunto simple y fijo de características que han demostrado ser efectivas en trabajos anteriores [14].",
        "Consulte la Tabla 1 para ver la lista de características utilizadas.",
        "Estas características intentan capturar la ocurrencia de términos y la proximidad entre términos.",
        "Una mejor selección de características en el futuro probablemente conducirá a una mayor efectividad. 3.1.5 Clasificación Dada una consulta Q, deseamos clasificar los documentos en orden descendente según PG,Λ(D|Q).",
        "Después de eliminar las expresiones independientes del documento del registro PG,Λ(Q, D), derivamos la siguiente función de clasificación: PG,Λ(D|Q) rango = FDQ(D, Q) + FD(D) (2), que es una simple combinación lineal ponderada de funciones de características que pueden calcularse eficientemente para grafos razonables. 3.1.6 Estimación de Parámetros Ahora que el modelo ha sido completamente especificado, el paso final es estimar los parámetros del modelo.",
        "Aunque los MRF son modelos generativos, no es apropiado entrenarlos utilizando la función de valor de características fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Tabla 1: Funciones de características utilizadas en el modelo de campo aleatorio de Markov.",
        "Aquí, tfw,D es el número de veces que el término w ocurre en el documento D, tf#1(qi...qi+k),D denota el número de veces que la frase exacta qi . . . qi+k ocurre en el documento D, tf#uw(qi...qj ),D es el número de veces que los términos qi, . . . qj aparecen ordenados o desordenados dentro de una ventana de N términos, y |D| es la longitud del documento D. Los valores de cf y |C| se definen de manera análoga a nivel de colección.",
        "Finalmente, α y β son hiperparámetros del modelo que controlan el suavizado para las características de términos únicos y frases, respectivamente. Enfoques convencionales basados en la verosimilitud debido a la divergencia métrica [17].",
        "Es decir, es poco probable que la estimación de máxima verosimilitud sea la estimación que maximiza nuestra métrica de evaluación.",
        "Por esta razón, entrenamos de manera discriminativa nuestro modelo para maximizar directamente la métrica de evaluación considerada [14, 15, 25].",
        "Dado que nuestro espacio de parámetros es pequeño, hacemos uso de una estrategia simple de escalada de colina, aunque son posibles otros enfoques más sofisticados [10]. 3.2 Expansión de Conceptos Latentes En esta sección describimos cómo este modelo MRF extendido puede ser utilizado de una manera novedosa para generar conceptos de un solo término y de varios términos que están relacionados temáticamente con alguna consulta original.",
        "Como mostraremos, los conceptos generados utilizando nuestra técnica pueden ser utilizados para la expansión de consultas u otras tareas, como sugerir formulaciones alternativas de consultas.",
        "Suponemos que cuando un usuario formula su consulta original, tiene en mente un conjunto de conceptos, pero solo puede expresar un pequeño número de ellos en forma de consulta.",
        "Tratamos los conceptos que el usuario tiene en mente, pero no expresó explícitamente en la consulta, como conceptos latentes.",
        "Estos conceptos latentes pueden consistir en un solo término, varios términos o alguna combinación de ambos.",
        "Por lo tanto, nuestro objetivo es recuperar estos conceptos latentes dada alguna consulta original.",
        "Esto se puede lograr dentro de nuestro marco de trabajo al expandir primero el grafo original G para incluir el tipo de concepto que nos interesa generar.",
        "Llamamos a este gráfico expandido H. En la Figura 1, el gráfico del medio proporciona un ejemplo de cómo construir un gráfico expandido que puede generar conceptos de un solo término.",
        "De manera similar, el gráfico de la derecha ilustra un gráfico ampliado que genera dos conceptos de términos.",
        "Aunque estos dos ejemplos hacen uso de la suposición de dependencia secuencial (es decir, dependencias entre términos de consulta adyacentes), es importante tener en cuenta que tanto la consulta original como los conceptos de expansión pueden utilizar cualquier estructura de independencia.",
        "Después de que H se construye, calculamos PH,Λ(E|Q), una distribución de probabilidad sobre conceptos latentes, de acuerdo a: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) donde R es el universo de todos los documentos posibles y E es un concepto latente que puede consistir en uno o más términos.",
        "Dado que no es práctico calcular esta suma, debemos aproximarla.",
        "Observamos que PH,Λ(Q, E, D) probablemente se concentra alrededor de aquellos documentos D que están altamente clasificados según la consulta Q.",
        "Por lo tanto, aproximamos PH,Λ(E|Q) sumando solo un pequeño subconjunto de documentos relevantes o pseudo-relevantes para la consulta Q.",
        "Esto se calcula de la siguiente manera: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) donde RQ es un conjunto de documentos relevantes o pseudo-relevantes para la consulta Q y todos los conjuntos de cliques se construyen utilizando H. Como vemos, la contribución de probabilidad para cada documento en RQ es una combinación de la puntuación original de la consulta para el documento (ver Ecuación 2), la puntuación del concepto E para el documento y la puntuación independiente del documento de E.",
        "Por lo tanto, esta ecuación puede interpretarse como la medida de qué tan bien Q y E explican los documentos mejor clasificados y la bondad de E, independientemente de los documentos.",
        "Para lograr la máxima robustez, utilizamos un conjunto diferente de parámetros para FQD(Q, D) y FQD(E, D), lo que nos permite ponderar de manera diferente las características de ventana ordenadas y no ordenadas para la consulta original y el concepto de expansión candidato. 3.2.1 Expansión de consulta Para utilizar este marco para la expansión de consultas, primero elegimos un grafo de expansión H que codifique la estructura de concepto latente en la que estamos interesados en expandir la consulta.",
        "Luego seleccionamos los k conceptos latentes con la mayor probabilidad dada por la Ecuación 3.",
        "Se construye un nuevo grafo G al aumentar el grafo original G con los k conceptos de expansión E1, . . . , Ek.",
        "Finalmente, los documentos se clasifican según PG ,Λ(D|Q, E1, . . . , Ek) utilizando la Ecuación 2. 3.2.2 Comparación con los Modelos de Relevancia. Al inspeccionar las Ecuaciones 1 y 3 se revela la estrecha conexión que existe entre LCE y los modelos de relevancia.",
        "Ambos modelos esencialmente calculan la probabilidad de un término (o concepto) de la misma manera.",
        "Es fácil ver que al igual que el modelo MRF puede ser visto como una generalización del modelado del lenguaje, también LCE puede ser visto como una generalización de los modelos de relevancia.",
        "Existen diferencias importantes entre los modelos de lenguaje MRFs/LCE y los modelos de lenguaje unigram/relevancia.",
        "Consulte la Figura 1 para ver las representaciones gráficas de ambos modelos.",
        "Los modelos de lenguaje unigrama y los modelos de relevancia se basan en la distribución multinomial.",
        "Esta suposición de distribución encasilla el modelo en la representación de bolsa de palabras y el uso implícito de características de ocurrencia de términos.",
        "Sin embargo, la distribución subyacente al modelo MRF nos permite ir más allá de ambas suposiciones, al modelar tanto las dependencias entre los términos de consulta como permitir el uso explícito de características arbitrarias.",
        "Ir más allá de la simplista suposición de la bolsa de palabras de esta manera resulta en un modelo general y robusto y, como mostramos en la siguiente sección, se traduce en mejoras significativas en la efectividad de recuperación. 4.",
        "RESULTADOS EXPERIMENTALES Para comprender mejor las fortalezas y debilidades de nuestra técnica, la evaluamos en una amplia gama de conjuntos de datos.",
        "La Tabla 2 proporciona un resumen de los conjuntos de datos de TREC considerados.",
        "Las colecciones WSJ, AP y ROBUST son más pequeñas y consisten enteramente de artículos de agencias de noticias, mientras que WT10g y GOV2 son colecciones web grandes.",
        "Para cada conjunto de datos, dividimos los temas disponibles en un conjunto de entrenamiento y otro de prueba, donde el conjunto de entrenamiento se utiliza únicamente para la estimación de parámetros y el conjunto de prueba se utiliza con fines de evaluación.",
        "Todos los experimentos se llevaron a cabo utilizando una versión modificada de Indri, que forma parte del Lemur Toolkit [18, 23].",
        "Todas las colecciones fueron detenidas utilizando una lista estándar de 418 términos comunes y truncadas utilizando un truncador de Porter.",
        "En todos los casos, solo se utiliza la parte del título de los temas de TREC para construir las consultas.",
        "Construimos G utilizando la suposición de dependencia secuencial para todos los conjuntos de datos [14]. 4.1 Resultados de recuperación ad-hoc Ahora investigamos qué tan bien se desempeña nuestro modelo en la práctica en un entorno de retroalimentación de relevancia pseudo.",
        "Comparamos el modelado de lenguaje unigrama (con suavizado de Dirichlet), el modelo MRF (sin expansión), los modelos de relevancia y LCE para comprender mejor cómo se desempeña cada modelo en los diferentes conjuntos de datos.",
        "Para el modelo de lenguaje unigrama, se entrenó el parámetro de suavizado.",
        "Para el modelo MRF, entrenamos los parámetros del modelo (es decir,",
        "y hiperparámetros del modelo (es decir, α, β).",
        "Para RM3 y LCE, también entrenamos el número de pseudoNombre Descripción # Docs Temas de Entrenamiento Temas de Prueba WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
        "Presione 88-90 242,918 51-150 151-200 ROBUST Robust 2004 datos 528,155 301-450 601-700 WT10g Colección Web de TREC 1,692,096 451-500 501-550 GOV2 Rastreo 2004 del dominio .gov 25,205,179 701-750 751-800 Tabla 2: Resumen de las colecciones y temas de TREC. documentos de retroalimentación relevantes utilizados y el número de términos de expansión. 4.1.1 Expansión con Conceptos de Términos Únicos Comenzamos evaluando qué tan bien funciona nuestro modelo al expandir utilizando solo términos individuales.",
        "Antes de describir y analizar los resultados, declaramos explícitamente cómo se calculan las probabilidades de términos de expansión bajo esta configuración (es decir, utilizando la suposición de dependencia secuencial, expandiendo con conceptos de un solo término y utilizando nuestro conjunto de características).",
        "Las probabilidades de términos de expansión se calculan de la siguiente manera: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) donde b ∈ Q denota el conjunto de bigramas en Q.",
        "Esta ecuación muestra claramente cómo LCE difiere de los modelos de relevancia.",
        "Cuando establecemos λTD = λT,D = 1 y todos los demás parámetros en 0, obtenemos la fórmula exacta que se utiliza para calcular las probabilidades de términos en el marco de modelado de relevancia.",
        "Por lo tanto, LCE añade dos factores muy importantes a la ecuación.",
        "Primero, agrega las características de ventana ordenadas y no ordenadas que se aplican a la consulta original.",
        "En segundo lugar, aplica una forma intuitiva similar a tf.idf al término de expansión candidato w. El factor idf, que no está presente en los modelos de relevancia, juega un papel importante en la selección del término de expansión. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figura 2: Histogramas que demuestran y comparan la robustez de los modelos de relevancia (RM3) y la expansión de conceptos latentes (LCE) con respecto al modelo de probabilidad de consulta (QL) para los conjuntos de datos AP, ROBUST y WT10G.",
        "Los resultados, evaluados utilizando la precisión promedio media, se muestran en la Tabla 3.",
        "Como vemos, el modelo MRF, los modelos de relevancia y LCE siempre superan significativamente al modelo de lenguaje unigrama.",
        "Además, LCE muestra mejoras significativas sobre los modelos de relevancia en todos los conjuntos de datos.",
        "Las mejoras relativas sobre los modelos de relevancia son del 6.9% para AP, 12.9% para WSJ, 6.5% para ROBUST, 16.7% para WT10G y 7.3% para GOV2.",
        "Además, LCE muestra pequeñas mejoras, pero no significativas, respecto al modelado de relevancia para métricas como precisión en 5, 10 y 20.",
        "Sin embargo, tanto el modelado de relevancia como el LCE muestran mejoras estadísticamente significativas en dichas métricas sobre el modelo de lenguaje unigrama.",
        "Otro resultado interesante es que el modelo MRF es estadísticamente equivalente a los modelos de relevancia en los dos conjuntos de datos web.",
        "De hecho, el modelo MRF supera a los modelos de relevancia en el conjunto de datos WT10g.",
        "Esto reitera la importancia de las características no unigrama, basadas en la proximidad para la búsqueda web basada en contenido observada previamente [14, 16].",
        "Aunque nuestro modelo tiene más parámetros libres que los modelos de relevancia, sorprendentemente hay poco sobreajuste.",
        "En cambio, el modelo muestra buenas propiedades de generalización. 4.1.2 Expansión con Conceptos de Múltiples Términos También investigamos la expansión utilizando conceptos de una y dos palabras.",
        "Para cada consulta, expandimos utilizando un conjunto de conceptos de un solo término y un conjunto de conceptos de dos términos.",
        "Los conjuntos fueron elegidos de forma independiente.",
        "Desafortunadamente, solo se observaron aumentos insignificantes en la precisión promedio.",
        "Este resultado puede deberse al hecho de que existen fuertes correlaciones entre los conceptos de expansión de términos individuales.",
        "Descubrimos que los dos conceptos de palabras elegidos a menudo consistían en dos términos altamente correlacionados que también son elegidos como conceptos de términos individuales.",
        "Por ejemplo, se eligió el concepto de dos términos mercado de valores, mientras que también se eligieron los conceptos de un solo término acciones y mercado.",
        "Por lo tanto, muchos conceptos de dos palabras es poco probable que aumenten el poder discriminativo de la consulta ampliada.",
        "Este resultado sugiere que los conceptos deben ser elegidos de acuerdo con ciertos criterios que también tengan en cuenta la novedad, la diversidad o las correlaciones de términos.",
        "Otro problema potencial es el conjunto de características utilizado.",
        "Otros conjuntos de características pueden dar resultados diferentes en última instancia, especialmente si reducen la correlación entre los conceptos de expansión.",
        "Por lo tanto, nuestros experimentos no arrojan resultados concluyentes en cuanto a la expansión utilizando conceptos de varios términos.",
        "En cambio, los resultados plantean preguntas abiertas interesantes y direcciones para futuras exploraciones.",
        "Tabla 3: Promedio de precisión media en el conjunto de pruebas para modelado de lenguaje (LM), campo aleatorio de Markov (MRF), modelos de relevancia (RM3) y expansión de conceptos latentes (LCE).",
        "Los superíndices α, β y γ indican mejoras estadísticamente significativas (p < 0.05) sobre LM, MRF y RM3, respectivamente. 4.2 Robustez Como hemos demostrado, los modelos de relevancia y la expansión de conceptos latentes pueden mejorar significativamente la efectividad de recuperación sobre el modelo de probabilidad de consulta base.",
        "En esta sección analizamos la robustez de estos dos métodos.",
        "Aquí definimos la robustez como el número de consultas cuya efectividad se ve mejorada/afectada (y en qué medida) como resultado de aplicar estos métodos.",
        "Una técnica de expansión altamente robusta mejorará significativamente muchas consultas y solo perjudicará mínimamente a unas pocas.",
        "La Figura 2 proporciona un análisis de la robustez del modelado de relevancia y la expansión de conceptos latentes para los conjuntos de datos AP, ROBUST y WT10G.",
        "El análisis de los dos conjuntos de datos no mostrados es similar.",
        "Los histogramas proporcionan, para varios rangos de disminuciones/aumentos relativos en la precisión media promedio, el número de consultas que se vieron perjudicadas/mejoradas con respecto a la línea base de probabilidad de consulta.",
        "Como muestran los resultados, LCE muestra una fuerte robustez para cada conjunto de datos.",
        "Para AP, los modelos de relevancia mejoran 38 consultas y perjudican 11, mientras que LCE mejora 35 y perjudica 14.",
        "Aunque los modelos de relevancia mejoran la efectividad de 3 consultas más que LCE, la mejora relativa exhibida por LCE es significativamente mayor.",
        "Para el conjunto de datos ROBUST, los modelos de relevancia mejoran 67 consultas y perjudican 32, y LCE mejora 77 y perjudica 22.",
        "Finalmente, para la colección WT10G, los modelos de relevancia mejoran 32 consultas y perjudican 16, y LCE mejora 35 y perjudica 14.",
        "Al igual que con AP, la cantidad de mejora exhibida por el LCE frente a los modelos de relevancia es significativamente mayor tanto para los conjuntos de datos ROBUST como WT10G.",
        "Además, cuando LCE afecta al rendimiento, es menos probable que afecte tanto como el modelado de relevancia, lo cual es una propiedad deseable.",
        "En general, LCE mejora la efectividad para el 65%-80% de las consultas, dependiendo del conjunto de datos.",
        "Cuando se utiliza en combinación con un sistema de predicción de rendimiento de consulta altamente preciso, puede ser posible expandir selectivamente las consultas y minimizar la pérdida asociada con el rendimiento sub-baseline. 4.3 Generación de Conceptos de Múltiples Términos Aunque encontramos que la expansión utilizando conceptos de múltiples términos no logró producir mejoras concluyentes en la efectividad, hay otras tareas potenciales para las cuales estos conceptos pueden ser útiles, como sugerencia/reformulación de consultas, resumen y extracción de conceptos.",
        "Por ejemplo, para una tarea de sugerencia de consultas, la consulta original podría usarse para generar un conjunto de conceptos latentes que corresponden a formulaciones alternativas de la consulta.",
        "Aunque evaluar nuestro modelo en estas tareas está fuera del alcance de este trabajo, deseamos mostrar un ejemplo ilustrativo de los tipos de conceptos generados utilizando nuestro modelo.",
        "En la Tabla 4, presentamos los conceptos de una, dos y tres palabras más probables generados utilizando LCE para la consulta logros del telescopio Hubble utilizando los 25 documentos mejor clasificados de la colección ROBUST.",
        "Es bien sabido que generar conceptos de múltiples términos utilizando un modelo basado en unigramas produce resultados insatisfactorios, ya que no considera las dependencias entre los términos.",
        "Esto no es el caso al generar conceptos de múltiples términos usando nuestro modelo.",
        "En cambio, la mayoría de los conceptos generados son bien formados y significativos.",
        "Hay varios casos donde los conceptos son menos coherentes, como espejo espejo espejo.",
        "En este caso, la probabilidad de que aparezca el término \"espejo\" en un documento pseudo-relevante supera a las características de modelado de lenguaje (por ejemplo, fOQ), lo que provoca que este concepto no coherente tenga una alta probabilidad.",
        "Tales ejemplos son minoría, sin embargo.",
        "No solo los conceptos generados son bien formados y significativos, sino que también son relevantes al tema de la consulta original.",
        "Como podemos ver, todos los conceptos generados están relacionados con el tema y de alguna manera están relacionados con el telescopio Hubble.",
        "Es interesante ver que el concepto de fallo del telescopio Hubble es uno de los tres conceptos de términos más probables, dado que es algo contradictorio con la consulta original.",
        "A pesar de esta contradicción, es probable que los documentos que discuten las fallas del telescopio también describan los éxitos, por lo tanto, es probable que este sea un concepto significativo.",
        "Una cosa importante a tener en cuenta es que los conceptos generados por LCE son de una naturaleza diferente a los que se generarían utilizando un modelo de relevancia de bigrama.",
        "Por ejemplo, un modelo de bigrama sería poco probable que genere el concepto telescopio espacio NASA, ya que ninguno de los bigramas que componen el concepto tiene una alta probabilidad.",
        "Sin embargo, dado que nuestro modelo se basa en una serie de características diferentes sobre varios tipos de cliques, es más general y robusto que un modelo de bigrama.",
        "Aunque solo proporcionamos los conceptos generados para una sola consulta, señalamos que el mismo análisis y conclusiones se generalizan a través de otros conjuntos de datos, con conceptos coherentes y relacionados temáticamente generados de manera consistente utilizando LCE. 4.4 Discusión Nuestra técnica de expansión de conceptos latentes captura dos tipos de dependencia semiortogonales.",
        "En la recuperación de información, ha existido un interés a largo plazo en comprender el papel de la dependencia de términos.",
        "De esta investigación, se han identificado dos tipos generales de dependencias.",
        "El primer tipo de dependencia es la dependencia sintáctica.",
        "Este tipo de dependencia abarca frases, proximidad de términos y co-ocurrencia de términos [2, 4, 5, 7, 26].",
        "Estos métodos capturan el hecho de que las consultas imponen implícita o explícitamente un cierto conjunto de dependencias posicionales.",
        "El segundo tipo es la dependencia semántica.",
        "Ejemplos de dependencia semántica son la retroalimentación de relevancia, la retroalimentación de pseudo-relevancia, sinónimos y en cierta medida el truncamiento [3].",
        "Estas técnicas han sido exploradas tanto en el lado de la consulta como en el lado del documento.",
        "En el lado de la consulta, esto se suele hacer utilizando alguna forma de expansión de consulta, como modelos de relevancia o LCE.",
        "En el lado del documento, esto se hace como expansión de documentos o suavizado de documentos [11, 13, 24].",
        "Aunque puede haber cierta superposición entre las dependencias sintácticas y semánticas, en su mayoría son ortogonales.",
        "Nuestro modelo utiliza ambos tipos de dependencias.",
        "El uso de características de frase y proximidad dentro del modelo captura dependencias sintácticas, mientras que LCE captura dependencias semánticas del lado de la consulta.",
        "Esto explica por qué la mejora inicial en la efectividad lograda al usar el modelo MRF no se pierde después de la expansión de consultas.",
        "Si los mismos tipos de dependencias fueran capturados tanto por dependencias sintácticas como semánticas, se esperaría que LCE funcionara aproximadamente igual de bien que los modelos de relevancia.",
        "Por lo tanto, al modelar ambos tipos de dependencias, observamos un efecto aditivo en lugar de un efecto absorbente.",
        "Una área interesante de trabajo futuro es determinar si modelar las dependencias semánticas del lado del documento puede aportar algo al modelo.",
        "Resultados previos que han combinado dependencias semánticas del lado de la consulta y del documento han mostrado resultados mixtos [13, 27]. 5.",
        "CONCLUSIONES En este artículo propusimos una técnica robusta de expansión de consultas llamada expansión de conceptos latentes.",
        "La técnica se demostró ser una extensión natural del modelo de campo aleatorio de Markov para la recuperación de información y una generalización de los modelos de relevancia.",
        "LCE es novedoso en el sentido de que realiza una expansión de un solo término o de varios términos dentro de un marco que permite el modelado de dependencias entre términos y el uso de características arbitrarias, mientras que trabajos anteriores se basaban en la suposición de la bolsa de palabras y características de ocurrencia de términos.",
        "Mostramos que la técnica puede ser utilizada para producir conceptos de expansión de varios términos de alta calidad, bien formados y relevantes desde el punto de vista temático.",
        "Los conceptos generados pueden ser utilizados en un módulo de sugerencia de consultas alternativas.",
        "También demostramos que el modelo es altamente efectivo.",
        "De hecho, logra mejoras significativas en la precisión promedio media en comparación con los modelos de relevancia en una selección de conjuntos de datos de TREC.",
        "También se demostró que el modelo MRF por sí solo, sin ninguna expansión de consulta, supera a los modelos de relevancia en grandes conjuntos de datos web.",
        "Esto reafirma observaciones previas de que modelar dependencias a través del uso de características de proximidad dentro del MRF tiene un mayor impacto en colecciones más grandes y ruidosas que en colecciones más pequeñas y bien comportadas.",
        "Finalmente, reiteramos la importancia de elegir términos de expansión que modelen la relevancia, en lugar de los documentos relevantes, y mostramos cómo LCE captura tanto las dependencias sintácticas como semánticas del lado de la consulta.",
        "El trabajo futuro se centrará en incorporar dependencias del lado del documento también.",
        "Agradecimientos Este trabajo fue apoyado en parte por el Centro de Recuperación de Información Inteligente, en parte por la subvención NSF #CNS-0454018, en parte por ARDA y la subvención NSF #CCF-0205575, y en parte por Microsoft Live Labs.",
        "Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son responsabilidad del autor o los autores y no necesariamente reflejan las del patrocinador. ",
        "REFERENCIAS [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker y C. Wade.",
        "UMass en TREC 2004: Novedad y DIFICULTAD.",
        "En Actas en línea de la Conferencia de Recuperación de Información de 2004, 2004. [2] C. L. A. Clarke y G. V. Cormack.",
        "Recuperación y clasificación de la subcadena más corta.",
        "ACM Trans.",
        "I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate to Spanish?",
        "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson y J. Callan.",
        "Expansión de consultas utilizando modelos de caminata aleatoria.",
        "En Proc. 14th Intl.",
        "Conf. sobre Gestión de Información y Conocimiento, páginas 704-711, 2005. [4] W. B. Croft.",
        "Consultas booleanas y dependencias de términos en modelos de recuperación probabilística.",
        "Revista de la Sociedad Americana de Ciencia de la Información, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle y D. Lewis.",
        "El uso de frases y consultas estructuradas en la recuperación de información.",
        "En Proc. 14º Anu.",
        "Internacional.",
        "Conferencia ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 32-45, 1991. [6] K. Eguchi.",
        "Experimentos de expansión de consultas NTCIR-5 utilizando modelos de dependencia de términos.",
        "En Actas del Quinto Taller de Reunión NTCIR sobre Evaluación de Tecnologías de Acceso a la Información, páginas 494-501, 2005. [7] J. Fagan.",
        "Indexación automática de frases para la recuperación de documentos: Un examen de métodos sintácticos y no sintácticos.",
        "En el Proc. décimo anual.",
        "Internacional.",
        "ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 91-101, 1987. [8] J. Gao, J. Nie, G. Wu y G. Cao.",
        "Modelo de lenguaje de dependencia para recuperación de información.",
        "En Proc. 27º Anu.",
        "Internacional.",
        "ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 170-177, 2004. [9] D. Harper y C. J. van Rijsbergen.",
        "Una evaluación de la retroalimentación en la recuperación de documentos utilizando datos de co-ocurrencia.",
        "Revista de Documentación, 34(3):189-216, 1978. [10] T. Joachims.",
        "Un método de vector de soporte para medidas de rendimiento multivariadas.",
        "En Proc. de la Conf. Internacional de Aprendizaje Automático, páginas 377-384, 2005. [11] O. Kurland y L. Lee.",
        "Estructura del corpus, modelos de lenguaje y recuperación de información ad-hoc.",
        "En Proc. 27º Anu.",
        "Internacional.",
        "ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 194-201, 2004. [12] V. Lavrenko y W. B. Croft.",
        "Modelos de lenguaje basados en relevancia.",
        "En Proc. 24º Anu.",
        "Internacional.",
        "ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 120-127, 2001. [13] X. Liu y W. B. Croft.",
        "Recuperación basada en clústeres utilizando modelos de lenguaje.",
        "En Proc. 27º Anu.",
        "Internacional.",
        "ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 186-193, 2004. [14] D. Metzler y W. B. Croft.",
        "Un modelo de campo aleatorio de Markov para dependencias entre términos.",
        "En Proc. 28vo Anu.",
        "Internacional.",
        "ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [15] D. Metzler y W. B. Croft.",
        "Modelos basados en características lineales para la recuperación de información.",
        "Recuperación de información, por aparecer, 2006. [16] D. Metzler, T. Strohman, Y. Zhou y W. B. Croft.",
        "Indri en la pista de terabyte en 2005.",
        "En Actas en línea de la Conferencia de Recuperación de Texto de 2005, 2005. [17] W. Morgan, W. Greiff y J. Henderson.",
        "Maximización directa de la precisión promedio mediante escalada de colina con una comparación con un enfoque de entropía máxima.",
        "Informe técnico, MITRE, 2004. [18] P. Ogilvie y J. P. Callan.",
        "Experimentos utilizando el kit de herramientas de lémures.",
        "En Proc. de la Conferencia de Recuperación de Texto, 2001. [19] R. Papka y J. Allan.",
        "Por qué las ventanas más grandes son mejores que las más pequeñas.",
        "Informe técnico, Universidad de Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu y M. Gatford.",
        "Okapi en trec-3.",
        "En Actas en línea de la Tercera Conferencia de Recuperación de Texto, páginas 109-126, 1995. [21] J. J. Rocchio.",
        "Retroalimentación de relevancia en la recuperación de información, páginas 313-323.",
        "Prentice-Hall, 1971. [22] F. Song y W. B. Croft.",
        "Un modelo de lenguaje general para la recuperación de información.",
        "En Proc. octava conferencia internacional sobre Gestión de la Información y el Conocimiento (CIKM 99), páginas 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle y W. B. Croft.",
        "Indri: Un motor de búsqueda basado en modelos de lenguaje para consultas complejas.",
        "En Actas de la Conferencia Internacional sobre Análisis de Inteligencia, 2004. [24] T. Tao, X. Wang, Q. Mei y C. Zhai.",
        "Recuperación de información del modelo de lenguaje con expansión de documentos.",
        "En Proc. de HLT/NAACL, páginas 407-414, 2006. [25] B. Taskar, C. Guestrin y D. Koller.",
        "Redes de Markov de margen máximo.",
        "En Proc. de Avances en Sistemas de Información Neural (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
        "Una base teórica para el uso de datos de coocurrencia en la recuperación de información.",
        "Revista de Documentación, 33(2):106-119, 1977. [27] X. Wei y W. B. Croft.",
        "Modelos de documentos basados en LDA para recuperación ad-hoc.",
        "En Proc. 29º Anu.",
        "Internacional.",
        "ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 178-185, 2006. [28] J. Xu y W. B. Croft.",
        "Mejorando la efectividad de la recuperación de información con análisis de contexto local.",
        "ACM Trans.",
        "I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate into Spanish?",
        "Syst., 18(1):79-112, 2000. [29] C. Zhai y J. Lafferty.",
        "Retroalimentación basada en modelos en el enfoque de modelado del lenguaje para la recuperación de información.",
        "En Proc. 10th Intl.",
        "Conferencia sobre Gestión de la Información y el Conocimiento, páginas 403-410, 2001."
    ],
    "error_count": 5,
    "keys": {
        "robust query expansion technique": {
            "translated_key": "técnica robusta de expansión de consultas",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a <br>robust query expansion technique</br> based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a <br>robust query expansion technique</br> called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [
                "In this paper, we propose a <br>robust query expansion technique</br> based on the Markov random field model for information retrieval.",
                "CONCLUSIONS In this paper we proposed a <br>robust query expansion technique</br> called latent concept expansion."
            ],
            "translated_annotated_samples": [
                "En este artículo, proponemos una <br>técnica robusta de expansión de consultas</br> basada en el modelo de campo aleatorio de Markov para la recuperación de información.",
                "CONCLUSIONES En este artículo propusimos una <br>técnica robusta de expansión de consultas</br> llamada expansión de conceptos latentes."
            ],
            "translated_text": "Expansión de conceptos latentes utilizando campos aleatorios de Markov. Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Centro de Recuperación de Información Inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 RESUMEN La expansión de consultas, en forma de retroalimentación de pseudo relevancia o retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación. La mayoría de enfoques anteriores han ignorado problemas importantes, como el papel de las características y la importancia de modelar las dependencias entre términos. En este artículo, proponemos una <br>técnica robusta de expansión de consultas</br> basada en el modelo de campo aleatorio de Markov para la recuperación de información. La técnica, llamada expansión de conceptos latentes, proporciona un mecanismo para modelar las dependencias de términos durante la expansión. Además, el uso de características arbitrarias dentro del modelo proporciona un marco poderoso para ir más allá de las simples características de ocurrencia de términos que son utilizadas implícitamente por la mayoría de las otras técnicas de expansión. Evaluamos nuestra técnica frente a modelos de relevancia, una técnica de expansión de consultas de modelado de lenguaje de última generación. Nuestro modelo demuestra mejoras consistentes y significativas en la efectividad de recuperación en varios conjuntos de datos de TREC. También describimos cómo nuestra técnica puede ser utilizada para generar conceptos significativos de varios términos para tareas como sugerencia/reformulación de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales Algoritmos, Experimentación, Teoría 1. Los usuarios de los sistemas de recuperación de información deben expresar necesidades de información complejas en términos de expresiones booleanas, una lista corta de palabras clave, una oración, una pregunta o posiblemente un relato más extenso. Se pierde mucha información durante el proceso de traducción desde la necesidad de información hasta la consulta real. Por esta razón, ha habido un fuerte interés en las técnicas de expansión de consultas. Tales técnicas se utilizan para ampliar la consulta original y producir una representación que refleje mejor la necesidad de información subyacente. Las técnicas de expansión de consultas han sido ampliamente estudiadas para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la retroalimentación de pseudo-relevancia [12, 21, 28, 29]. Recientemente, se propuso un modelo de campo aleatorio de Markov (MRF) para la recuperación de información que va más allá de la simplista suposición de bolsa de palabras que subyace en BM25 y en el enfoque de modelado de lenguaje (unigrama) para la recuperación de información [20, 22]. El modelo MRF generaliza los modelos de unigrama, bigrama y otras diversas dependencias [14]. La mayoría de los modelos de dependencia de términos pasados no han logrado mostrar mejoras consistentes y significativas sobre las líneas de base de unigramas, con pocas excepciones [8]. El modelo MRF, sin embargo, ha demostrado ser altamente efectivo en una serie de tareas, incluyendo la recuperación ad hoc [14, 16], la búsqueda de páginas con nombres [16] y la búsqueda web en japonés [6]. Hasta ahora, el modelo ha sido utilizado únicamente para clasificar documentos en respuesta a una consulta dada. En este trabajo, mostramos cómo el modelo puede ser ampliado y utilizado para la expansión de consultas utilizando una técnica que llamamos expansión de conceptos latentes (LCE). Hay tres contribuciones principales de nuestro trabajo. Primero, LCE proporciona un mecanismo para combinar la dependencia de términos con la expansión de consultas. Las técnicas de expansión de consultas anteriores se basan en modelos de bolsa de palabras. Por lo tanto, al realizar la expansión de consultas utilizando el modelo MRF, podemos estudiar la dinámica entre la dependencia de términos y la expansión de consultas. A continuación, como mostraremos, el modelo MRF permite que se utilicen características arbitrarias dentro del modelo. Las técnicas de expansión de consultas en el pasado solo han hecho uso implícito de características de ocurrencia de términos. Al utilizar conjuntos de características más robustos, es posible producir términos de expansión mejores que discriminan de manera más efectiva entre documentos relevantes y no relevantes. Finalmente, nuestro enfoque propuesto proporciona de manera fluida un mecanismo para generar conceptos de una sola y múltiples términos. La mayoría de las técnicas anteriores, por defecto, generan términos de forma independiente. Ha habido varios enfoques que hacen uso de conceptos generalizados, sin embargo, dichos enfoques fueron algo heurísticos y realizados fuera del modelo [19, 28]. Nuestro enfoque está motivado tanto formalmente como es una extensión natural del modelo subyacente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2 describimos enfoques relacionados de expansión de consultas. La sección 3 proporciona una visión general del modelo MRF y detalla nuestra técnica propuesta de expansión de conceptos latentes. En la Sección 4 evaluamos nuestro modelo propuesto y analizamos los resultados. Finalmente, la Sección 5 concluye el artículo y resume los principales resultados. 2. TRABAJO RELACIONADO Uno de los enfoques clásicos y más ampliamente utilizados para la expansión de consultas es el algoritmo de Rocchio [21]. El enfoque de Rocchio, que fue desarrollado dentro del modelo de espacio vectorial, reajusta el vector de consulta original moviendo los pesos hacia el conjunto de documentos relevantes o pseudo-relevantes y alejándolos de los documentos no relevantes. Desafortunadamente, no es posible aplicar formalmente el enfoque de Rocchio a un modelo de recuperación estadística, como el modelado del lenguaje para la recuperación de información. Se han desarrollado varias técnicas de expansión de consultas formalizadas para el marco de modelado de lenguaje, incluyendo el feedback basado en el modelo de Zhai y Lafferty y los modelos de relevancia de Lavrenko y Crofts [12, 29]. Ambos enfoques intentan utilizar documentos pseudo-relevantes o relevantes para estimar un modelo de consulta mejor. El feedback basado en modelos encuentra el modelo que mejor describe los documentos relevantes teniendo en cuenta un modelo de fondo (ruido). Esto separa el modelo de contenido del modelo de fondo. El modelo de contenido se interpola con el modelo de consulta original para formar la consulta ampliada. La otra técnica, modelos de relevancia, está más relacionada con nuestro trabajo. Por lo tanto, entramos en los detalles del modelo. Al igual que el feedback basado en modelos, los modelos de relevancia estiman un modelo de consulta mejorado. La única diferencia entre los dos enfoques es que los modelos de relevancia no modelan explícitamente los documentos relevantes o pseudo-relevantes. En cambio, ellos modelan una noción más generalizada de relevancia, como mostraremos ahora. Dada una consulta Q, un modelo de relevancia es una distribución multinomial, P(·|Q), que codifica la probabilidad de cada término dado la consulta como evidencia. Se calcula como: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) donde RQ es el conjunto de documentos que son relevantes o pseudo relevantes para la consulta Q. En el caso pseudo-relevante, estos son los documentos mejor clasificados para la consulta Q. Además, se asume que P(D) es uniforme en este conjunto. Estas suposiciones suaves hacen que el cálculo del posterior bayesiano sea más práctico. Después de que el modelo es estimado, los documentos son clasificados por recortar el modelo de relevancia al elegir los k términos más probables de P(·|Q). Esta distribución recortada se interpola luego con el modelo de consulta de máxima verosimilitud original. Esto se puede considerar como la expansión de la consulta original por k términos ponderados. A lo largo del resto de este trabajo, nos referimos a esta instancia de modelos de relevancia como RM3. Ha habido relativamente poco trabajo realizado en el área de expansión de consultas en el contexto de modelos de dependencia [9]. Sin embargo, ha habido varios intentos de expandir utilizando conceptos de varios términos. El método de análisis de contexto local (LCA) de Xu y Crofts combinaba la recuperación a nivel de pasaje con la expansión de conceptos, donde los conceptos eran términos y frases simples [28]. Los conceptos de expansión fueron elegidos y ponderados utilizando una métrica basada en estadísticas de co-ocurrencia. Sin embargo, no está claro, basándose en el análisis realizado, cuánto ayudaron las frases en comparación con los términos individuales solos. Papka y Allan investigan el uso de retroalimentación de relevancia para realizar la expansión de conceptos de varios términos en el enrutamiento de documentos [19]. Los conceptos utilizados en su trabajo son más generales que los utilizados en el LCA e incluyen estructuras de lenguaje de consulta InQuery, como #UW50(casa blanca), que corresponde al concepto en el que los términos casa y blanca ocurren, en cualquier orden, dentro de 50 términos uno del otro. Los resultados mostraron que combinar conceptos de un solo término y conceptos de varios términos con una ventana grande mejoró significativamente la efectividad. Sin embargo, no está claro si el mismo enfoque también es efectivo para la recuperación ad hoc, debido a las diferencias en las tareas. 3. Este apartado detalla nuestra técnica propuesta de expansión de conceptos latentes. Como se mencionó anteriormente, la técnica es una extensión del modelo MRF para la recuperación de información [14]. Por lo tanto, comenzamos proporcionando una visión general del modelo MRF y nuestras extensiones propuestas. 3.1 MRFs para IR 3.1.1 Conceptos básicos Los campos aleatorios de Markov, que son modelos gráficos no dirigidos, proporcionan una forma compacta y robusta de modelar una distribución conjunta. Aquí estamos interesados en modelar la distribución conjunta sobre una consulta Q = q1, . . . , qn y un documento D. Se asume que la distribución subyacente sobre pares de documentos y consultas es una distribución de relevancia. Es decir, muestrear de la distribución proporciona pares de documentos y consultas, de modo que el documento sea relevante para la consulta. Un MRF se define por un grafo G y un conjunto de funciones de potencial no negativas sobre los cliques en G. Los nodos en el grafo representan las variables aleatorias y las aristas definen la semántica de independencia de la distribución. Un MRF cumple con la propiedad de Markov, la cual establece que un nodo es independiente de todos sus nodos no vecinos dado los valores observados de sus vecinos. Dado un grafo G, un conjunto de potenciales ψi y un vector de parámetros Λ, la distribución conjunta sobre Q y D está dada por: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) donde Z es una constante de normalización. Seguimos la convención común y parametrizamos los potenciales como ψi(c; Λ) = exp[λifi(c)], donde fi(c) es una función de características de valores reales. 3.1.2 Construcción de G Dada una consulta Q, el grafo G puede ser construido de varias maneras. Sin embargo, siguiendo el trabajo previo, consideramos tres variantes simples [14]. Estas variantes son independencia total, donde cada término de consulta es independiente de los demás dado un documento, dependencia secuencial, que asume que existe una dependencia entre los términos de consulta adyacentes, y dependencia total, que no hace suposiciones de independencia. 3.1.3 Parametrización Los MRFs suelen ser parametrizados comúnmente en función de los cliques máximos de G. Sin embargo, dicha parametrización es demasiado gruesa para nuestras necesidades. Necesitamos una parametrización que nos permita asociar funciones de características con cliques a un nivel más detallado, manteniendo al mismo tiempo el número de características, y por lo tanto el número de parámetros, razonable. Por lo tanto, permitimos que los grupos compartan funciones de características y parámetros basados en conjuntos de grupos. Es decir, todos los subgrupos dentro de un conjunto de subgrupos están asociados con la misma función de característica y comparten un solo parámetro. Esto une de manera efectiva los parámetros de las características asociadas con cada conjunto, lo que reduce significativamente el número de parámetros mientras aún proporciona un mecanismo para el ajuste fino en el nivel de conjuntos de cliques. Proponemos siete conjuntos de cliques para utilizar en la recuperación de información. Los primeros tres conjuntos de cliques consisten en cliques que contienen uno o más términos de consulta y el nodo del documento. Las características sobre estos grupos deberían codificar qué tan bien los términos en la configuración del grupo describen el documento. Estos conjuntos son: • TD - conjunto de cliques que contienen el nodo del documento y exactamente un término de consulta. • OD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en orden secuencial dentro de la consulta. • UD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en cualquier orden dentro de la consulta. Ten en cuenta que UD es un superconjunto de OD. Al atar los parámetros entre los grupos dentro de cada conjunto podemos controlar cuánta influencia recibe cada tipo. Esto también evita el problema de tratar de determinar cómo estimar los pesos para cada clique dentro de los conjuntos. En cambio, ahora solo debemos estimar un parámetro por conjunto. A continuación, consideramos cliques que solo contienen nodos de términos de consulta. Estas cliques, que no fueron consideradas en [14], se definen de manera análoga a las recién definidas, excepto que las cliques solo están formadas por nodos de términos de consulta y no contienen el nodo de documento. Las funciones de características sobre estos conjuntos deben capturar qué tan compatibles son entre sí los términos de consulta. Estas características de grupo pueden adoptar la forma de modelos de lenguaje que imponen la corrección de los términos. Por lo tanto, definimos los siguientes conjuntos de cliques dependientes de la consulta: • TQ - conjunto de cliques que contienen exactamente un término de la consulta. • OQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en orden secuencial dentro de la consulta. • UQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en cualquier orden dentro de la consulta. Finalmente, está la clique que solo contiene el nodo del documento. Las características sobre este nodo pueden ser utilizadas como un tipo de documento previo, codificando propiedades centradas en el documento. Este conjunto de cliques trivial es entonces: • D - conjunto de cliques que contiene solo el nodo único D. Observamos que nuestros conjuntos de cliques forman una cobertura de conjuntos sobre los cliques de G, pero no son una partición, ya que algunos cliques aparecen en múltiples conjuntos de cliques. Después de atar los parámetros en nuestros conjuntos de cliques y usar la forma de la función potencial exponencial, terminamos con la siguiente forma simplificada de la distribución conjunta: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - dependiente del documento y la consulta + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - dependiente de la consulta + λDfD(D) FD(D) - dependiente del documento − log ZΛ documento + independiente de la consulta donde FDQ, FQ y FD son funciones de conveniencia definidas por los componentes dependientes del documento y la consulta, dependientes de la consulta y dependientes del documento de la distribución conjunta, respectivamente. Estos se utilizarán para simplificar y clarificar las expresiones derivadas a lo largo del resto del documento. 3.1.4 Características Cualquier función de característica arbitraria sobre configuraciones de cliques puede ser utilizada en el modelo. La elección correcta de las características depende en gran medida de la tarea de recuperación y la métrica de evaluación. Por lo tanto, es probable que no exista un conjunto único y universalmente aplicable de características. Para dar una idea de la variedad de características que se pueden utilizar, ahora describimos brevemente posibles tipos de características que podrían ser utilizadas. Posibles características dependientes del término de consulta incluyen tf, idf, entidades nombradas, proximidad de términos y estilo de texto, por nombrar algunas. Se pueden utilizar muchos tipos de características dependientes del documento, como la longitud del documento, el PageRank, la legibilidad y el género, entre otros. Dado que nuestro objetivo aquí no es encontrar características óptimas, utilizamos un conjunto simple y fijo de características que han demostrado ser efectivas en trabajos anteriores [14]. Consulte la Tabla 1 para ver la lista de características utilizadas. Estas características intentan capturar la ocurrencia de términos y la proximidad entre términos. Una mejor selección de características en el futuro probablemente conducirá a una mayor efectividad. 3.1.5 Clasificación Dada una consulta Q, deseamos clasificar los documentos en orden descendente según PG,Λ(D|Q). Después de eliminar las expresiones independientes del documento del registro PG,Λ(Q, D), derivamos la siguiente función de clasificación: PG,Λ(D|Q) rango = FDQ(D, Q) + FD(D) (2), que es una simple combinación lineal ponderada de funciones de características que pueden calcularse eficientemente para grafos razonables. 3.1.6 Estimación de Parámetros Ahora que el modelo ha sido completamente especificado, el paso final es estimar los parámetros del modelo. Aunque los MRF son modelos generativos, no es apropiado entrenarlos utilizando la función de valor de características fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Tabla 1: Funciones de características utilizadas en el modelo de campo aleatorio de Markov. Aquí, tfw,D es el número de veces que el término w ocurre en el documento D, tf#1(qi...qi+k),D denota el número de veces que la frase exacta qi . . . qi+k ocurre en el documento D, tf#uw(qi...qj ),D es el número de veces que los términos qi, . . . qj aparecen ordenados o desordenados dentro de una ventana de N términos, y |D| es la longitud del documento D. Los valores de cf y |C| se definen de manera análoga a nivel de colección. Finalmente, α y β son hiperparámetros del modelo que controlan el suavizado para las características de términos únicos y frases, respectivamente. Enfoques convencionales basados en la verosimilitud debido a la divergencia métrica [17]. Es decir, es poco probable que la estimación de máxima verosimilitud sea la estimación que maximiza nuestra métrica de evaluación. Por esta razón, entrenamos de manera discriminativa nuestro modelo para maximizar directamente la métrica de evaluación considerada [14, 15, 25]. Dado que nuestro espacio de parámetros es pequeño, hacemos uso de una estrategia simple de escalada de colina, aunque son posibles otros enfoques más sofisticados [10]. 3.2 Expansión de Conceptos Latentes En esta sección describimos cómo este modelo MRF extendido puede ser utilizado de una manera novedosa para generar conceptos de un solo término y de varios términos que están relacionados temáticamente con alguna consulta original. Como mostraremos, los conceptos generados utilizando nuestra técnica pueden ser utilizados para la expansión de consultas u otras tareas, como sugerir formulaciones alternativas de consultas. Suponemos que cuando un usuario formula su consulta original, tiene en mente un conjunto de conceptos, pero solo puede expresar un pequeño número de ellos en forma de consulta. Tratamos los conceptos que el usuario tiene en mente, pero no expresó explícitamente en la consulta, como conceptos latentes. Estos conceptos latentes pueden consistir en un solo término, varios términos o alguna combinación de ambos. Por lo tanto, nuestro objetivo es recuperar estos conceptos latentes dada alguna consulta original. Esto se puede lograr dentro de nuestro marco de trabajo al expandir primero el grafo original G para incluir el tipo de concepto que nos interesa generar. Llamamos a este gráfico expandido H. En la Figura 1, el gráfico del medio proporciona un ejemplo de cómo construir un gráfico expandido que puede generar conceptos de un solo término. De manera similar, el gráfico de la derecha ilustra un gráfico ampliado que genera dos conceptos de términos. Aunque estos dos ejemplos hacen uso de la suposición de dependencia secuencial (es decir, dependencias entre términos de consulta adyacentes), es importante tener en cuenta que tanto la consulta original como los conceptos de expansión pueden utilizar cualquier estructura de independencia. Después de que H se construye, calculamos PH,Λ(E|Q), una distribución de probabilidad sobre conceptos latentes, de acuerdo a: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) donde R es el universo de todos los documentos posibles y E es un concepto latente que puede consistir en uno o más términos. Dado que no es práctico calcular esta suma, debemos aproximarla. Observamos que PH,Λ(Q, E, D) probablemente se concentra alrededor de aquellos documentos D que están altamente clasificados según la consulta Q. Por lo tanto, aproximamos PH,Λ(E|Q) sumando solo un pequeño subconjunto de documentos relevantes o pseudo-relevantes para la consulta Q. Esto se calcula de la siguiente manera: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) donde RQ es un conjunto de documentos relevantes o pseudo-relevantes para la consulta Q y todos los conjuntos de cliques se construyen utilizando H. Como vemos, la contribución de probabilidad para cada documento en RQ es una combinación de la puntuación original de la consulta para el documento (ver Ecuación 2), la puntuación del concepto E para el documento y la puntuación independiente del documento de E. Por lo tanto, esta ecuación puede interpretarse como la medida de qué tan bien Q y E explican los documentos mejor clasificados y la bondad de E, independientemente de los documentos. Para lograr la máxima robustez, utilizamos un conjunto diferente de parámetros para FQD(Q, D) y FQD(E, D), lo que nos permite ponderar de manera diferente las características de ventana ordenadas y no ordenadas para la consulta original y el concepto de expansión candidato. 3.2.1 Expansión de consulta Para utilizar este marco para la expansión de consultas, primero elegimos un grafo de expansión H que codifique la estructura de concepto latente en la que estamos interesados en expandir la consulta. Luego seleccionamos los k conceptos latentes con la mayor probabilidad dada por la Ecuación 3. Se construye un nuevo grafo G al aumentar el grafo original G con los k conceptos de expansión E1, . . . , Ek. Finalmente, los documentos se clasifican según PG ,Λ(D|Q, E1, . . . , Ek) utilizando la Ecuación 2. 3.2.2 Comparación con los Modelos de Relevancia. Al inspeccionar las Ecuaciones 1 y 3 se revela la estrecha conexión que existe entre LCE y los modelos de relevancia. Ambos modelos esencialmente calculan la probabilidad de un término (o concepto) de la misma manera. Es fácil ver que al igual que el modelo MRF puede ser visto como una generalización del modelado del lenguaje, también LCE puede ser visto como una generalización de los modelos de relevancia. Existen diferencias importantes entre los modelos de lenguaje MRFs/LCE y los modelos de lenguaje unigram/relevancia. Consulte la Figura 1 para ver las representaciones gráficas de ambos modelos. Los modelos de lenguaje unigrama y los modelos de relevancia se basan en la distribución multinomial. Esta suposición de distribución encasilla el modelo en la representación de bolsa de palabras y el uso implícito de características de ocurrencia de términos. Sin embargo, la distribución subyacente al modelo MRF nos permite ir más allá de ambas suposiciones, al modelar tanto las dependencias entre los términos de consulta como permitir el uso explícito de características arbitrarias. Ir más allá de la simplista suposición de la bolsa de palabras de esta manera resulta en un modelo general y robusto y, como mostramos en la siguiente sección, se traduce en mejoras significativas en la efectividad de recuperación. 4. RESULTADOS EXPERIMENTALES Para comprender mejor las fortalezas y debilidades de nuestra técnica, la evaluamos en una amplia gama de conjuntos de datos. La Tabla 2 proporciona un resumen de los conjuntos de datos de TREC considerados. Las colecciones WSJ, AP y ROBUST son más pequeñas y consisten enteramente de artículos de agencias de noticias, mientras que WT10g y GOV2 son colecciones web grandes. Para cada conjunto de datos, dividimos los temas disponibles en un conjunto de entrenamiento y otro de prueba, donde el conjunto de entrenamiento se utiliza únicamente para la estimación de parámetros y el conjunto de prueba se utiliza con fines de evaluación. Todos los experimentos se llevaron a cabo utilizando una versión modificada de Indri, que forma parte del Lemur Toolkit [18, 23]. Todas las colecciones fueron detenidas utilizando una lista estándar de 418 términos comunes y truncadas utilizando un truncador de Porter. En todos los casos, solo se utiliza la parte del título de los temas de TREC para construir las consultas. Construimos G utilizando la suposición de dependencia secuencial para todos los conjuntos de datos [14]. 4.1 Resultados de recuperación ad-hoc Ahora investigamos qué tan bien se desempeña nuestro modelo en la práctica en un entorno de retroalimentación de relevancia pseudo. Comparamos el modelado de lenguaje unigrama (con suavizado de Dirichlet), el modelo MRF (sin expansión), los modelos de relevancia y LCE para comprender mejor cómo se desempeña cada modelo en los diferentes conjuntos de datos. Para el modelo de lenguaje unigrama, se entrenó el parámetro de suavizado. Para el modelo MRF, entrenamos los parámetros del modelo (es decir, y hiperparámetros del modelo (es decir, α, β). Para RM3 y LCE, también entrenamos el número de pseudoNombre Descripción # Docs Temas de Entrenamiento Temas de Prueba WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc. Presione 88-90 242,918 51-150 151-200 ROBUST Robust 2004 datos 528,155 301-450 601-700 WT10g Colección Web de TREC 1,692,096 451-500 501-550 GOV2 Rastreo 2004 del dominio .gov 25,205,179 701-750 751-800 Tabla 2: Resumen de las colecciones y temas de TREC. documentos de retroalimentación relevantes utilizados y el número de términos de expansión. 4.1.1 Expansión con Conceptos de Términos Únicos Comenzamos evaluando qué tan bien funciona nuestro modelo al expandir utilizando solo términos individuales. Antes de describir y analizar los resultados, declaramos explícitamente cómo se calculan las probabilidades de términos de expansión bajo esta configuración (es decir, utilizando la suposición de dependencia secuencial, expandiendo con conceptos de un solo término y utilizando nuestro conjunto de características). Las probabilidades de términos de expansión se calculan de la siguiente manera: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) donde b ∈ Q denota el conjunto de bigramas en Q. Esta ecuación muestra claramente cómo LCE difiere de los modelos de relevancia. Cuando establecemos λTD = λT,D = 1 y todos los demás parámetros en 0, obtenemos la fórmula exacta que se utiliza para calcular las probabilidades de términos en el marco de modelado de relevancia. Por lo tanto, LCE añade dos factores muy importantes a la ecuación. Primero, agrega las características de ventana ordenadas y no ordenadas que se aplican a la consulta original. En segundo lugar, aplica una forma intuitiva similar a tf.idf al término de expansión candidato w. El factor idf, que no está presente en los modelos de relevancia, juega un papel importante en la selección del término de expansión. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figura 2: Histogramas que demuestran y comparan la robustez de los modelos de relevancia (RM3) y la expansión de conceptos latentes (LCE) con respecto al modelo de probabilidad de consulta (QL) para los conjuntos de datos AP, ROBUST y WT10G. Los resultados, evaluados utilizando la precisión promedio media, se muestran en la Tabla 3. Como vemos, el modelo MRF, los modelos de relevancia y LCE siempre superan significativamente al modelo de lenguaje unigrama. Además, LCE muestra mejoras significativas sobre los modelos de relevancia en todos los conjuntos de datos. Las mejoras relativas sobre los modelos de relevancia son del 6.9% para AP, 12.9% para WSJ, 6.5% para ROBUST, 16.7% para WT10G y 7.3% para GOV2. Además, LCE muestra pequeñas mejoras, pero no significativas, respecto al modelado de relevancia para métricas como precisión en 5, 10 y 20. Sin embargo, tanto el modelado de relevancia como el LCE muestran mejoras estadísticamente significativas en dichas métricas sobre el modelo de lenguaje unigrama. Otro resultado interesante es que el modelo MRF es estadísticamente equivalente a los modelos de relevancia en los dos conjuntos de datos web. De hecho, el modelo MRF supera a los modelos de relevancia en el conjunto de datos WT10g. Esto reitera la importancia de las características no unigrama, basadas en la proximidad para la búsqueda web basada en contenido observada previamente [14, 16]. Aunque nuestro modelo tiene más parámetros libres que los modelos de relevancia, sorprendentemente hay poco sobreajuste. En cambio, el modelo muestra buenas propiedades de generalización. 4.1.2 Expansión con Conceptos de Múltiples Términos También investigamos la expansión utilizando conceptos de una y dos palabras. Para cada consulta, expandimos utilizando un conjunto de conceptos de un solo término y un conjunto de conceptos de dos términos. Los conjuntos fueron elegidos de forma independiente. Desafortunadamente, solo se observaron aumentos insignificantes en la precisión promedio. Este resultado puede deberse al hecho de que existen fuertes correlaciones entre los conceptos de expansión de términos individuales. Descubrimos que los dos conceptos de palabras elegidos a menudo consistían en dos términos altamente correlacionados que también son elegidos como conceptos de términos individuales. Por ejemplo, se eligió el concepto de dos términos mercado de valores, mientras que también se eligieron los conceptos de un solo término acciones y mercado. Por lo tanto, muchos conceptos de dos palabras es poco probable que aumenten el poder discriminativo de la consulta ampliada. Este resultado sugiere que los conceptos deben ser elegidos de acuerdo con ciertos criterios que también tengan en cuenta la novedad, la diversidad o las correlaciones de términos. Otro problema potencial es el conjunto de características utilizado. Otros conjuntos de características pueden dar resultados diferentes en última instancia, especialmente si reducen la correlación entre los conceptos de expansión. Por lo tanto, nuestros experimentos no arrojan resultados concluyentes en cuanto a la expansión utilizando conceptos de varios términos. En cambio, los resultados plantean preguntas abiertas interesantes y direcciones para futuras exploraciones. Tabla 3: Promedio de precisión media en el conjunto de pruebas para modelado de lenguaje (LM), campo aleatorio de Markov (MRF), modelos de relevancia (RM3) y expansión de conceptos latentes (LCE). Los superíndices α, β y γ indican mejoras estadísticamente significativas (p < 0.05) sobre LM, MRF y RM3, respectivamente. 4.2 Robustez Como hemos demostrado, los modelos de relevancia y la expansión de conceptos latentes pueden mejorar significativamente la efectividad de recuperación sobre el modelo de probabilidad de consulta base. En esta sección analizamos la robustez de estos dos métodos. Aquí definimos la robustez como el número de consultas cuya efectividad se ve mejorada/afectada (y en qué medida) como resultado de aplicar estos métodos. Una técnica de expansión altamente robusta mejorará significativamente muchas consultas y solo perjudicará mínimamente a unas pocas. La Figura 2 proporciona un análisis de la robustez del modelado de relevancia y la expansión de conceptos latentes para los conjuntos de datos AP, ROBUST y WT10G. El análisis de los dos conjuntos de datos no mostrados es similar. Los histogramas proporcionan, para varios rangos de disminuciones/aumentos relativos en la precisión media promedio, el número de consultas que se vieron perjudicadas/mejoradas con respecto a la línea base de probabilidad de consulta. Como muestran los resultados, LCE muestra una fuerte robustez para cada conjunto de datos. Para AP, los modelos de relevancia mejoran 38 consultas y perjudican 11, mientras que LCE mejora 35 y perjudica 14. Aunque los modelos de relevancia mejoran la efectividad de 3 consultas más que LCE, la mejora relativa exhibida por LCE es significativamente mayor. Para el conjunto de datos ROBUST, los modelos de relevancia mejoran 67 consultas y perjudican 32, y LCE mejora 77 y perjudica 22. Finalmente, para la colección WT10G, los modelos de relevancia mejoran 32 consultas y perjudican 16, y LCE mejora 35 y perjudica 14. Al igual que con AP, la cantidad de mejora exhibida por el LCE frente a los modelos de relevancia es significativamente mayor tanto para los conjuntos de datos ROBUST como WT10G. Además, cuando LCE afecta al rendimiento, es menos probable que afecte tanto como el modelado de relevancia, lo cual es una propiedad deseable. En general, LCE mejora la efectividad para el 65%-80% de las consultas, dependiendo del conjunto de datos. Cuando se utiliza en combinación con un sistema de predicción de rendimiento de consulta altamente preciso, puede ser posible expandir selectivamente las consultas y minimizar la pérdida asociada con el rendimiento sub-baseline. 4.3 Generación de Conceptos de Múltiples Términos Aunque encontramos que la expansión utilizando conceptos de múltiples términos no logró producir mejoras concluyentes en la efectividad, hay otras tareas potenciales para las cuales estos conceptos pueden ser útiles, como sugerencia/reformulación de consultas, resumen y extracción de conceptos. Por ejemplo, para una tarea de sugerencia de consultas, la consulta original podría usarse para generar un conjunto de conceptos latentes que corresponden a formulaciones alternativas de la consulta. Aunque evaluar nuestro modelo en estas tareas está fuera del alcance de este trabajo, deseamos mostrar un ejemplo ilustrativo de los tipos de conceptos generados utilizando nuestro modelo. En la Tabla 4, presentamos los conceptos de una, dos y tres palabras más probables generados utilizando LCE para la consulta logros del telescopio Hubble utilizando los 25 documentos mejor clasificados de la colección ROBUST. Es bien sabido que generar conceptos de múltiples términos utilizando un modelo basado en unigramas produce resultados insatisfactorios, ya que no considera las dependencias entre los términos. Esto no es el caso al generar conceptos de múltiples términos usando nuestro modelo. En cambio, la mayoría de los conceptos generados son bien formados y significativos. Hay varios casos donde los conceptos son menos coherentes, como espejo espejo espejo. En este caso, la probabilidad de que aparezca el término \"espejo\" en un documento pseudo-relevante supera a las características de modelado de lenguaje (por ejemplo, fOQ), lo que provoca que este concepto no coherente tenga una alta probabilidad. Tales ejemplos son minoría, sin embargo. No solo los conceptos generados son bien formados y significativos, sino que también son relevantes al tema de la consulta original. Como podemos ver, todos los conceptos generados están relacionados con el tema y de alguna manera están relacionados con el telescopio Hubble. Es interesante ver que el concepto de fallo del telescopio Hubble es uno de los tres conceptos de términos más probables, dado que es algo contradictorio con la consulta original. A pesar de esta contradicción, es probable que los documentos que discuten las fallas del telescopio también describan los éxitos, por lo tanto, es probable que este sea un concepto significativo. Una cosa importante a tener en cuenta es que los conceptos generados por LCE son de una naturaleza diferente a los que se generarían utilizando un modelo de relevancia de bigrama. Por ejemplo, un modelo de bigrama sería poco probable que genere el concepto telescopio espacio NASA, ya que ninguno de los bigramas que componen el concepto tiene una alta probabilidad. Sin embargo, dado que nuestro modelo se basa en una serie de características diferentes sobre varios tipos de cliques, es más general y robusto que un modelo de bigrama. Aunque solo proporcionamos los conceptos generados para una sola consulta, señalamos que el mismo análisis y conclusiones se generalizan a través de otros conjuntos de datos, con conceptos coherentes y relacionados temáticamente generados de manera consistente utilizando LCE. 4.4 Discusión Nuestra técnica de expansión de conceptos latentes captura dos tipos de dependencia semiortogonales. En la recuperación de información, ha existido un interés a largo plazo en comprender el papel de la dependencia de términos. De esta investigación, se han identificado dos tipos generales de dependencias. El primer tipo de dependencia es la dependencia sintáctica. Este tipo de dependencia abarca frases, proximidad de términos y co-ocurrencia de términos [2, 4, 5, 7, 26]. Estos métodos capturan el hecho de que las consultas imponen implícita o explícitamente un cierto conjunto de dependencias posicionales. El segundo tipo es la dependencia semántica. Ejemplos de dependencia semántica son la retroalimentación de relevancia, la retroalimentación de pseudo-relevancia, sinónimos y en cierta medida el truncamiento [3]. Estas técnicas han sido exploradas tanto en el lado de la consulta como en el lado del documento. En el lado de la consulta, esto se suele hacer utilizando alguna forma de expansión de consulta, como modelos de relevancia o LCE. En el lado del documento, esto se hace como expansión de documentos o suavizado de documentos [11, 13, 24]. Aunque puede haber cierta superposición entre las dependencias sintácticas y semánticas, en su mayoría son ortogonales. Nuestro modelo utiliza ambos tipos de dependencias. El uso de características de frase y proximidad dentro del modelo captura dependencias sintácticas, mientras que LCE captura dependencias semánticas del lado de la consulta. Esto explica por qué la mejora inicial en la efectividad lograda al usar el modelo MRF no se pierde después de la expansión de consultas. Si los mismos tipos de dependencias fueran capturados tanto por dependencias sintácticas como semánticas, se esperaría que LCE funcionara aproximadamente igual de bien que los modelos de relevancia. Por lo tanto, al modelar ambos tipos de dependencias, observamos un efecto aditivo en lugar de un efecto absorbente. Una área interesante de trabajo futuro es determinar si modelar las dependencias semánticas del lado del documento puede aportar algo al modelo. Resultados previos que han combinado dependencias semánticas del lado de la consulta y del documento han mostrado resultados mixtos [13, 27]. 5. CONCLUSIONES En este artículo propusimos una <br>técnica robusta de expansión de consultas</br> llamada expansión de conceptos latentes. La técnica se demostró ser una extensión natural del modelo de campo aleatorio de Markov para la recuperación de información y una generalización de los modelos de relevancia. LCE es novedoso en el sentido de que realiza una expansión de un solo término o de varios términos dentro de un marco que permite el modelado de dependencias entre términos y el uso de características arbitrarias, mientras que trabajos anteriores se basaban en la suposición de la bolsa de palabras y características de ocurrencia de términos. Mostramos que la técnica puede ser utilizada para producir conceptos de expansión de varios términos de alta calidad, bien formados y relevantes desde el punto de vista temático. Los conceptos generados pueden ser utilizados en un módulo de sugerencia de consultas alternativas. También demostramos que el modelo es altamente efectivo. De hecho, logra mejoras significativas en la precisión promedio media en comparación con los modelos de relevancia en una selección de conjuntos de datos de TREC. También se demostró que el modelo MRF por sí solo, sin ninguna expansión de consulta, supera a los modelos de relevancia en grandes conjuntos de datos web. Esto reafirma observaciones previas de que modelar dependencias a través del uso de características de proximidad dentro del MRF tiene un mayor impacto en colecciones más grandes y ruidosas que en colecciones más pequeñas y bien comportadas. Finalmente, reiteramos la importancia de elegir términos de expansión que modelen la relevancia, en lugar de los documentos relevantes, y mostramos cómo LCE captura tanto las dependencias sintácticas como semánticas del lado de la consulta. El trabajo futuro se centrará en incorporar dependencias del lado del documento también. Agradecimientos Este trabajo fue apoyado en parte por el Centro de Recuperación de Información Inteligente, en parte por la subvención NSF #CNS-0454018, en parte por ARDA y la subvención NSF #CCF-0205575, y en parte por Microsoft Live Labs. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son responsabilidad del autor o los autores y no necesariamente reflejan las del patrocinador.  REFERENCIAS [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker y C. Wade. UMass en TREC 2004: Novedad y DIFICULTAD. En Actas en línea de la Conferencia de Recuperación de Información de 2004, 2004. [2] C. L. A. Clarke y G. V. Cormack. Recuperación y clasificación de la subcadena más corta. ACM Trans. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate to Spanish? Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson y J. Callan. Expansión de consultas utilizando modelos de caminata aleatoria. En Proc. 14th Intl. Conf. sobre Gestión de Información y Conocimiento, páginas 704-711, 2005. [4] W. B. Croft. Consultas booleanas y dependencias de términos en modelos de recuperación probabilística. Revista de la Sociedad Americana de Ciencia de la Información, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle y D. Lewis. El uso de frases y consultas estructuradas en la recuperación de información. En Proc. 14º Anu. Internacional. Conferencia ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 32-45, 1991. [6] K. Eguchi. Experimentos de expansión de consultas NTCIR-5 utilizando modelos de dependencia de términos. En Actas del Quinto Taller de Reunión NTCIR sobre Evaluación de Tecnologías de Acceso a la Información, páginas 494-501, 2005. [7] J. Fagan. Indexación automática de frases para la recuperación de documentos: Un examen de métodos sintácticos y no sintácticos. En el Proc. décimo anual. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 91-101, 1987. [8] J. Gao, J. Nie, G. Wu y G. Cao. Modelo de lenguaje de dependencia para recuperación de información. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 170-177, 2004. [9] D. Harper y C. J. van Rijsbergen. Una evaluación de la retroalimentación en la recuperación de documentos utilizando datos de co-ocurrencia. Revista de Documentación, 34(3):189-216, 1978. [10] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Proc. de la Conf. Internacional de Aprendizaje Automático, páginas 377-384, 2005. [11] O. Kurland y L. Lee. Estructura del corpus, modelos de lenguaje y recuperación de información ad-hoc. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 194-201, 2004. [12] V. Lavrenko y W. B. Croft. Modelos de lenguaje basados en relevancia. En Proc. 24º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 120-127, 2001. [13] X. Liu y W. B. Croft. Recuperación basada en clústeres utilizando modelos de lenguaje. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 186-193, 2004. [14] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias entre términos. En Proc. 28vo Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [15] D. Metzler y W. B. Croft. Modelos basados en características lineales para la recuperación de información. Recuperación de información, por aparecer, 2006. [16] D. Metzler, T. Strohman, Y. Zhou y W. B. Croft. Indri en la pista de terabyte en 2005. En Actas en línea de la Conferencia de Recuperación de Texto de 2005, 2005. [17] W. Morgan, W. Greiff y J. Henderson. Maximización directa de la precisión promedio mediante escalada de colina con una comparación con un enfoque de entropía máxima. Informe técnico, MITRE, 2004. [18] P. Ogilvie y J. P. Callan. Experimentos utilizando el kit de herramientas de lémures. En Proc. de la Conferencia de Recuperación de Texto, 2001. [19] R. Papka y J. Allan. Por qué las ventanas más grandes son mejores que las más pequeñas. Informe técnico, Universidad de Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu y M. Gatford. Okapi en trec-3. En Actas en línea de la Tercera Conferencia de Recuperación de Texto, páginas 109-126, 1995. [21] J. J. Rocchio. Retroalimentación de relevancia en la recuperación de información, páginas 313-323. Prentice-Hall, 1971. [22] F. Song y W. B. Croft. Un modelo de lenguaje general para la recuperación de información. En Proc. octava conferencia internacional sobre Gestión de la Información y el Conocimiento (CIKM 99), páginas 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle y W. B. Croft. Indri: Un motor de búsqueda basado en modelos de lenguaje para consultas complejas. En Actas de la Conferencia Internacional sobre Análisis de Inteligencia, 2004. [24] T. Tao, X. Wang, Q. Mei y C. Zhai. Recuperación de información del modelo de lenguaje con expansión de documentos. En Proc. de HLT/NAACL, páginas 407-414, 2006. [25] B. Taskar, C. Guestrin y D. Koller. Redes de Markov de margen máximo. En Proc. de Avances en Sistemas de Información Neural (NIPS 2003), 2003. [26] C. J. van Rijsbergen. Una base teórica para el uso de datos de coocurrencia en la recuperación de información. Revista de Documentación, 33(2):106-119, 1977. [27] X. Wei y W. B. Croft. Modelos de documentos basados en LDA para recuperación ad-hoc. En Proc. 29º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 178-185, 2006. [28] J. Xu y W. B. Croft. Mejorando la efectividad de la recuperación de información con análisis de contexto local. ACM Trans. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate into Spanish? Syst., 18(1):79-112, 2000. [29] C. Zhai y J. Lafferty. Retroalimentación basada en modelos en el enfoque de modelado del lenguaje para la recuperación de información. En Proc. 10th Intl. Conferencia sobre Gestión de la Información y el Conocimiento, páginas 403-410, 2001. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "language modeling query expansion technique": {
            "translated_key": "modelado de lenguaje",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art <br>language modeling query expansion technique</br>.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [
                "We evaluate our technique against relevance models, a state-of-the-art <br>language modeling query expansion technique</br>."
            ],
            "translated_annotated_samples": [
                "Evaluamos nuestra técnica frente a modelos de relevancia, una técnica de expansión de consultas de <br>modelado de lenguaje</br> de última generación."
            ],
            "translated_text": "Expansión de conceptos latentes utilizando campos aleatorios de Markov. Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Centro de Recuperación de Información Inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 RESUMEN La expansión de consultas, en forma de retroalimentación de pseudo relevancia o retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación. La mayoría de enfoques anteriores han ignorado problemas importantes, como el papel de las características y la importancia de modelar las dependencias entre términos. En este artículo, proponemos una técnica robusta de expansión de consultas basada en el modelo de campo aleatorio de Markov para la recuperación de información. La técnica, llamada expansión de conceptos latentes, proporciona un mecanismo para modelar las dependencias de términos durante la expansión. Además, el uso de características arbitrarias dentro del modelo proporciona un marco poderoso para ir más allá de las simples características de ocurrencia de términos que son utilizadas implícitamente por la mayoría de las otras técnicas de expansión. Evaluamos nuestra técnica frente a modelos de relevancia, una técnica de expansión de consultas de <br>modelado de lenguaje</br> de última generación. Nuestro modelo demuestra mejoras consistentes y significativas en la efectividad de recuperación en varios conjuntos de datos de TREC. También describimos cómo nuestra técnica puede ser utilizada para generar conceptos significativos de varios términos para tareas como sugerencia/reformulación de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales Algoritmos, Experimentación, Teoría 1. Los usuarios de los sistemas de recuperación de información deben expresar necesidades de información complejas en términos de expresiones booleanas, una lista corta de palabras clave, una oración, una pregunta o posiblemente un relato más extenso. Se pierde mucha información durante el proceso de traducción desde la necesidad de información hasta la consulta real. Por esta razón, ha habido un fuerte interés en las técnicas de expansión de consultas. Tales técnicas se utilizan para ampliar la consulta original y producir una representación que refleje mejor la necesidad de información subyacente. Las técnicas de expansión de consultas han sido ampliamente estudiadas para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la retroalimentación de pseudo-relevancia [12, 21, 28, 29]. Recientemente, se propuso un modelo de campo aleatorio de Markov (MRF) para la recuperación de información que va más allá de la simplista suposición de bolsa de palabras que subyace en BM25 y en el enfoque de modelado de lenguaje (unigrama) para la recuperación de información [20, 22]. El modelo MRF generaliza los modelos de unigrama, bigrama y otras diversas dependencias [14]. La mayoría de los modelos de dependencia de términos pasados no han logrado mostrar mejoras consistentes y significativas sobre las líneas de base de unigramas, con pocas excepciones [8]. El modelo MRF, sin embargo, ha demostrado ser altamente efectivo en una serie de tareas, incluyendo la recuperación ad hoc [14, 16], la búsqueda de páginas con nombres [16] y la búsqueda web en japonés [6]. Hasta ahora, el modelo ha sido utilizado únicamente para clasificar documentos en respuesta a una consulta dada. En este trabajo, mostramos cómo el modelo puede ser ampliado y utilizado para la expansión de consultas utilizando una técnica que llamamos expansión de conceptos latentes (LCE). Hay tres contribuciones principales de nuestro trabajo. Primero, LCE proporciona un mecanismo para combinar la dependencia de términos con la expansión de consultas. Las técnicas de expansión de consultas anteriores se basan en modelos de bolsa de palabras. Por lo tanto, al realizar la expansión de consultas utilizando el modelo MRF, podemos estudiar la dinámica entre la dependencia de términos y la expansión de consultas. A continuación, como mostraremos, el modelo MRF permite que se utilicen características arbitrarias dentro del modelo. Las técnicas de expansión de consultas en el pasado solo han hecho uso implícito de características de ocurrencia de términos. Al utilizar conjuntos de características más robustos, es posible producir términos de expansión mejores que discriminan de manera más efectiva entre documentos relevantes y no relevantes. Finalmente, nuestro enfoque propuesto proporciona de manera fluida un mecanismo para generar conceptos de una sola y múltiples términos. La mayoría de las técnicas anteriores, por defecto, generan términos de forma independiente. Ha habido varios enfoques que hacen uso de conceptos generalizados, sin embargo, dichos enfoques fueron algo heurísticos y realizados fuera del modelo [19, 28]. Nuestro enfoque está motivado tanto formalmente como es una extensión natural del modelo subyacente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2 describimos enfoques relacionados de expansión de consultas. La sección 3 proporciona una visión general del modelo MRF y detalla nuestra técnica propuesta de expansión de conceptos latentes. En la Sección 4 evaluamos nuestro modelo propuesto y analizamos los resultados. Finalmente, la Sección 5 concluye el artículo y resume los principales resultados. 2. TRABAJO RELACIONADO Uno de los enfoques clásicos y más ampliamente utilizados para la expansión de consultas es el algoritmo de Rocchio [21]. El enfoque de Rocchio, que fue desarrollado dentro del modelo de espacio vectorial, reajusta el vector de consulta original moviendo los pesos hacia el conjunto de documentos relevantes o pseudo-relevantes y alejándolos de los documentos no relevantes. Desafortunadamente, no es posible aplicar formalmente el enfoque de Rocchio a un modelo de recuperación estadística, como el modelado del lenguaje para la recuperación de información. Se han desarrollado varias técnicas de expansión de consultas formalizadas para el marco de modelado de lenguaje, incluyendo el feedback basado en el modelo de Zhai y Lafferty y los modelos de relevancia de Lavrenko y Crofts [12, 29]. Ambos enfoques intentan utilizar documentos pseudo-relevantes o relevantes para estimar un modelo de consulta mejor. El feedback basado en modelos encuentra el modelo que mejor describe los documentos relevantes teniendo en cuenta un modelo de fondo (ruido). Esto separa el modelo de contenido del modelo de fondo. El modelo de contenido se interpola con el modelo de consulta original para formar la consulta ampliada. La otra técnica, modelos de relevancia, está más relacionada con nuestro trabajo. Por lo tanto, entramos en los detalles del modelo. Al igual que el feedback basado en modelos, los modelos de relevancia estiman un modelo de consulta mejorado. La única diferencia entre los dos enfoques es que los modelos de relevancia no modelan explícitamente los documentos relevantes o pseudo-relevantes. En cambio, ellos modelan una noción más generalizada de relevancia, como mostraremos ahora. Dada una consulta Q, un modelo de relevancia es una distribución multinomial, P(·|Q), que codifica la probabilidad de cada término dado la consulta como evidencia. Se calcula como: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) donde RQ es el conjunto de documentos que son relevantes o pseudo relevantes para la consulta Q. En el caso pseudo-relevante, estos son los documentos mejor clasificados para la consulta Q. Además, se asume que P(D) es uniforme en este conjunto. Estas suposiciones suaves hacen que el cálculo del posterior bayesiano sea más práctico. Después de que el modelo es estimado, los documentos son clasificados por recortar el modelo de relevancia al elegir los k términos más probables de P(·|Q). Esta distribución recortada se interpola luego con el modelo de consulta de máxima verosimilitud original. Esto se puede considerar como la expansión de la consulta original por k términos ponderados. A lo largo del resto de este trabajo, nos referimos a esta instancia de modelos de relevancia como RM3. Ha habido relativamente poco trabajo realizado en el área de expansión de consultas en el contexto de modelos de dependencia [9]. Sin embargo, ha habido varios intentos de expandir utilizando conceptos de varios términos. El método de análisis de contexto local (LCA) de Xu y Crofts combinaba la recuperación a nivel de pasaje con la expansión de conceptos, donde los conceptos eran términos y frases simples [28]. Los conceptos de expansión fueron elegidos y ponderados utilizando una métrica basada en estadísticas de co-ocurrencia. Sin embargo, no está claro, basándose en el análisis realizado, cuánto ayudaron las frases en comparación con los términos individuales solos. Papka y Allan investigan el uso de retroalimentación de relevancia para realizar la expansión de conceptos de varios términos en el enrutamiento de documentos [19]. Los conceptos utilizados en su trabajo son más generales que los utilizados en el LCA e incluyen estructuras de lenguaje de consulta InQuery, como #UW50(casa blanca), que corresponde al concepto en el que los términos casa y blanca ocurren, en cualquier orden, dentro de 50 términos uno del otro. Los resultados mostraron que combinar conceptos de un solo término y conceptos de varios términos con una ventana grande mejoró significativamente la efectividad. Sin embargo, no está claro si el mismo enfoque también es efectivo para la recuperación ad hoc, debido a las diferencias en las tareas. 3. Este apartado detalla nuestra técnica propuesta de expansión de conceptos latentes. Como se mencionó anteriormente, la técnica es una extensión del modelo MRF para la recuperación de información [14]. Por lo tanto, comenzamos proporcionando una visión general del modelo MRF y nuestras extensiones propuestas. 3.1 MRFs para IR 3.1.1 Conceptos básicos Los campos aleatorios de Markov, que son modelos gráficos no dirigidos, proporcionan una forma compacta y robusta de modelar una distribución conjunta. Aquí estamos interesados en modelar la distribución conjunta sobre una consulta Q = q1, . . . , qn y un documento D. Se asume que la distribución subyacente sobre pares de documentos y consultas es una distribución de relevancia. Es decir, muestrear de la distribución proporciona pares de documentos y consultas, de modo que el documento sea relevante para la consulta. Un MRF se define por un grafo G y un conjunto de funciones de potencial no negativas sobre los cliques en G. Los nodos en el grafo representan las variables aleatorias y las aristas definen la semántica de independencia de la distribución. Un MRF cumple con la propiedad de Markov, la cual establece que un nodo es independiente de todos sus nodos no vecinos dado los valores observados de sus vecinos. Dado un grafo G, un conjunto de potenciales ψi y un vector de parámetros Λ, la distribución conjunta sobre Q y D está dada por: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) donde Z es una constante de normalización. Seguimos la convención común y parametrizamos los potenciales como ψi(c; Λ) = exp[λifi(c)], donde fi(c) es una función de características de valores reales. 3.1.2 Construcción de G Dada una consulta Q, el grafo G puede ser construido de varias maneras. Sin embargo, siguiendo el trabajo previo, consideramos tres variantes simples [14]. Estas variantes son independencia total, donde cada término de consulta es independiente de los demás dado un documento, dependencia secuencial, que asume que existe una dependencia entre los términos de consulta adyacentes, y dependencia total, que no hace suposiciones de independencia. 3.1.3 Parametrización Los MRFs suelen ser parametrizados comúnmente en función de los cliques máximos de G. Sin embargo, dicha parametrización es demasiado gruesa para nuestras necesidades. Necesitamos una parametrización que nos permita asociar funciones de características con cliques a un nivel más detallado, manteniendo al mismo tiempo el número de características, y por lo tanto el número de parámetros, razonable. Por lo tanto, permitimos que los grupos compartan funciones de características y parámetros basados en conjuntos de grupos. Es decir, todos los subgrupos dentro de un conjunto de subgrupos están asociados con la misma función de característica y comparten un solo parámetro. Esto une de manera efectiva los parámetros de las características asociadas con cada conjunto, lo que reduce significativamente el número de parámetros mientras aún proporciona un mecanismo para el ajuste fino en el nivel de conjuntos de cliques. Proponemos siete conjuntos de cliques para utilizar en la recuperación de información. Los primeros tres conjuntos de cliques consisten en cliques que contienen uno o más términos de consulta y el nodo del documento. Las características sobre estos grupos deberían codificar qué tan bien los términos en la configuración del grupo describen el documento. Estos conjuntos son: • TD - conjunto de cliques que contienen el nodo del documento y exactamente un término de consulta. • OD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en orden secuencial dentro de la consulta. • UD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en cualquier orden dentro de la consulta. Ten en cuenta que UD es un superconjunto de OD. Al atar los parámetros entre los grupos dentro de cada conjunto podemos controlar cuánta influencia recibe cada tipo. Esto también evita el problema de tratar de determinar cómo estimar los pesos para cada clique dentro de los conjuntos. En cambio, ahora solo debemos estimar un parámetro por conjunto. A continuación, consideramos cliques que solo contienen nodos de términos de consulta. Estas cliques, que no fueron consideradas en [14], se definen de manera análoga a las recién definidas, excepto que las cliques solo están formadas por nodos de términos de consulta y no contienen el nodo de documento. Las funciones de características sobre estos conjuntos deben capturar qué tan compatibles son entre sí los términos de consulta. Estas características de grupo pueden adoptar la forma de modelos de lenguaje que imponen la corrección de los términos. Por lo tanto, definimos los siguientes conjuntos de cliques dependientes de la consulta: • TQ - conjunto de cliques que contienen exactamente un término de la consulta. • OQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en orden secuencial dentro de la consulta. • UQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en cualquier orden dentro de la consulta. Finalmente, está la clique que solo contiene el nodo del documento. Las características sobre este nodo pueden ser utilizadas como un tipo de documento previo, codificando propiedades centradas en el documento. Este conjunto de cliques trivial es entonces: • D - conjunto de cliques que contiene solo el nodo único D. Observamos que nuestros conjuntos de cliques forman una cobertura de conjuntos sobre los cliques de G, pero no son una partición, ya que algunos cliques aparecen en múltiples conjuntos de cliques. Después de atar los parámetros en nuestros conjuntos de cliques y usar la forma de la función potencial exponencial, terminamos con la siguiente forma simplificada de la distribución conjunta: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - dependiente del documento y la consulta + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - dependiente de la consulta + λDfD(D) FD(D) - dependiente del documento − log ZΛ documento + independiente de la consulta donde FDQ, FQ y FD son funciones de conveniencia definidas por los componentes dependientes del documento y la consulta, dependientes de la consulta y dependientes del documento de la distribución conjunta, respectivamente. Estos se utilizarán para simplificar y clarificar las expresiones derivadas a lo largo del resto del documento. 3.1.4 Características Cualquier función de característica arbitraria sobre configuraciones de cliques puede ser utilizada en el modelo. La elección correcta de las características depende en gran medida de la tarea de recuperación y la métrica de evaluación. Por lo tanto, es probable que no exista un conjunto único y universalmente aplicable de características. Para dar una idea de la variedad de características que se pueden utilizar, ahora describimos brevemente posibles tipos de características que podrían ser utilizadas. Posibles características dependientes del término de consulta incluyen tf, idf, entidades nombradas, proximidad de términos y estilo de texto, por nombrar algunas. Se pueden utilizar muchos tipos de características dependientes del documento, como la longitud del documento, el PageRank, la legibilidad y el género, entre otros. Dado que nuestro objetivo aquí no es encontrar características óptimas, utilizamos un conjunto simple y fijo de características que han demostrado ser efectivas en trabajos anteriores [14]. Consulte la Tabla 1 para ver la lista de características utilizadas. Estas características intentan capturar la ocurrencia de términos y la proximidad entre términos. Una mejor selección de características en el futuro probablemente conducirá a una mayor efectividad. 3.1.5 Clasificación Dada una consulta Q, deseamos clasificar los documentos en orden descendente según PG,Λ(D|Q). Después de eliminar las expresiones independientes del documento del registro PG,Λ(Q, D), derivamos la siguiente función de clasificación: PG,Λ(D|Q) rango = FDQ(D, Q) + FD(D) (2), que es una simple combinación lineal ponderada de funciones de características que pueden calcularse eficientemente para grafos razonables. 3.1.6 Estimación de Parámetros Ahora que el modelo ha sido completamente especificado, el paso final es estimar los parámetros del modelo. Aunque los MRF son modelos generativos, no es apropiado entrenarlos utilizando la función de valor de características fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Tabla 1: Funciones de características utilizadas en el modelo de campo aleatorio de Markov. Aquí, tfw,D es el número de veces que el término w ocurre en el documento D, tf#1(qi...qi+k),D denota el número de veces que la frase exacta qi . . . qi+k ocurre en el documento D, tf#uw(qi...qj ),D es el número de veces que los términos qi, . . . qj aparecen ordenados o desordenados dentro de una ventana de N términos, y |D| es la longitud del documento D. Los valores de cf y |C| se definen de manera análoga a nivel de colección. Finalmente, α y β son hiperparámetros del modelo que controlan el suavizado para las características de términos únicos y frases, respectivamente. Enfoques convencionales basados en la verosimilitud debido a la divergencia métrica [17]. Es decir, es poco probable que la estimación de máxima verosimilitud sea la estimación que maximiza nuestra métrica de evaluación. Por esta razón, entrenamos de manera discriminativa nuestro modelo para maximizar directamente la métrica de evaluación considerada [14, 15, 25]. Dado que nuestro espacio de parámetros es pequeño, hacemos uso de una estrategia simple de escalada de colina, aunque son posibles otros enfoques más sofisticados [10]. 3.2 Expansión de Conceptos Latentes En esta sección describimos cómo este modelo MRF extendido puede ser utilizado de una manera novedosa para generar conceptos de un solo término y de varios términos que están relacionados temáticamente con alguna consulta original. Como mostraremos, los conceptos generados utilizando nuestra técnica pueden ser utilizados para la expansión de consultas u otras tareas, como sugerir formulaciones alternativas de consultas. Suponemos que cuando un usuario formula su consulta original, tiene en mente un conjunto de conceptos, pero solo puede expresar un pequeño número de ellos en forma de consulta. Tratamos los conceptos que el usuario tiene en mente, pero no expresó explícitamente en la consulta, como conceptos latentes. Estos conceptos latentes pueden consistir en un solo término, varios términos o alguna combinación de ambos. Por lo tanto, nuestro objetivo es recuperar estos conceptos latentes dada alguna consulta original. Esto se puede lograr dentro de nuestro marco de trabajo al expandir primero el grafo original G para incluir el tipo de concepto que nos interesa generar. Llamamos a este gráfico expandido H. En la Figura 1, el gráfico del medio proporciona un ejemplo de cómo construir un gráfico expandido que puede generar conceptos de un solo término. De manera similar, el gráfico de la derecha ilustra un gráfico ampliado que genera dos conceptos de términos. Aunque estos dos ejemplos hacen uso de la suposición de dependencia secuencial (es decir, dependencias entre términos de consulta adyacentes), es importante tener en cuenta que tanto la consulta original como los conceptos de expansión pueden utilizar cualquier estructura de independencia. Después de que H se construye, calculamos PH,Λ(E|Q), una distribución de probabilidad sobre conceptos latentes, de acuerdo a: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) donde R es el universo de todos los documentos posibles y E es un concepto latente que puede consistir en uno o más términos. Dado que no es práctico calcular esta suma, debemos aproximarla. Observamos que PH,Λ(Q, E, D) probablemente se concentra alrededor de aquellos documentos D que están altamente clasificados según la consulta Q. Por lo tanto, aproximamos PH,Λ(E|Q) sumando solo un pequeño subconjunto de documentos relevantes o pseudo-relevantes para la consulta Q. Esto se calcula de la siguiente manera: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) donde RQ es un conjunto de documentos relevantes o pseudo-relevantes para la consulta Q y todos los conjuntos de cliques se construyen utilizando H. Como vemos, la contribución de probabilidad para cada documento en RQ es una combinación de la puntuación original de la consulta para el documento (ver Ecuación 2), la puntuación del concepto E para el documento y la puntuación independiente del documento de E. Por lo tanto, esta ecuación puede interpretarse como la medida de qué tan bien Q y E explican los documentos mejor clasificados y la bondad de E, independientemente de los documentos. Para lograr la máxima robustez, utilizamos un conjunto diferente de parámetros para FQD(Q, D) y FQD(E, D), lo que nos permite ponderar de manera diferente las características de ventana ordenadas y no ordenadas para la consulta original y el concepto de expansión candidato. 3.2.1 Expansión de consulta Para utilizar este marco para la expansión de consultas, primero elegimos un grafo de expansión H que codifique la estructura de concepto latente en la que estamos interesados en expandir la consulta. Luego seleccionamos los k conceptos latentes con la mayor probabilidad dada por la Ecuación 3. Se construye un nuevo grafo G al aumentar el grafo original G con los k conceptos de expansión E1, . . . , Ek. Finalmente, los documentos se clasifican según PG ,Λ(D|Q, E1, . . . , Ek) utilizando la Ecuación 2. 3.2.2 Comparación con los Modelos de Relevancia. Al inspeccionar las Ecuaciones 1 y 3 se revela la estrecha conexión que existe entre LCE y los modelos de relevancia. Ambos modelos esencialmente calculan la probabilidad de un término (o concepto) de la misma manera. Es fácil ver que al igual que el modelo MRF puede ser visto como una generalización del modelado del lenguaje, también LCE puede ser visto como una generalización de los modelos de relevancia. Existen diferencias importantes entre los modelos de lenguaje MRFs/LCE y los modelos de lenguaje unigram/relevancia. Consulte la Figura 1 para ver las representaciones gráficas de ambos modelos. Los modelos de lenguaje unigrama y los modelos de relevancia se basan en la distribución multinomial. Esta suposición de distribución encasilla el modelo en la representación de bolsa de palabras y el uso implícito de características de ocurrencia de términos. Sin embargo, la distribución subyacente al modelo MRF nos permite ir más allá de ambas suposiciones, al modelar tanto las dependencias entre los términos de consulta como permitir el uso explícito de características arbitrarias. Ir más allá de la simplista suposición de la bolsa de palabras de esta manera resulta en un modelo general y robusto y, como mostramos en la siguiente sección, se traduce en mejoras significativas en la efectividad de recuperación. 4. RESULTADOS EXPERIMENTALES Para comprender mejor las fortalezas y debilidades de nuestra técnica, la evaluamos en una amplia gama de conjuntos de datos. La Tabla 2 proporciona un resumen de los conjuntos de datos de TREC considerados. Las colecciones WSJ, AP y ROBUST son más pequeñas y consisten enteramente de artículos de agencias de noticias, mientras que WT10g y GOV2 son colecciones web grandes. Para cada conjunto de datos, dividimos los temas disponibles en un conjunto de entrenamiento y otro de prueba, donde el conjunto de entrenamiento se utiliza únicamente para la estimación de parámetros y el conjunto de prueba se utiliza con fines de evaluación. Todos los experimentos se llevaron a cabo utilizando una versión modificada de Indri, que forma parte del Lemur Toolkit [18, 23]. Todas las colecciones fueron detenidas utilizando una lista estándar de 418 términos comunes y truncadas utilizando un truncador de Porter. En todos los casos, solo se utiliza la parte del título de los temas de TREC para construir las consultas. Construimos G utilizando la suposición de dependencia secuencial para todos los conjuntos de datos [14]. 4.1 Resultados de recuperación ad-hoc Ahora investigamos qué tan bien se desempeña nuestro modelo en la práctica en un entorno de retroalimentación de relevancia pseudo. Comparamos el modelado de lenguaje unigrama (con suavizado de Dirichlet), el modelo MRF (sin expansión), los modelos de relevancia y LCE para comprender mejor cómo se desempeña cada modelo en los diferentes conjuntos de datos. Para el modelo de lenguaje unigrama, se entrenó el parámetro de suavizado. Para el modelo MRF, entrenamos los parámetros del modelo (es decir, y hiperparámetros del modelo (es decir, α, β). Para RM3 y LCE, también entrenamos el número de pseudoNombre Descripción # Docs Temas de Entrenamiento Temas de Prueba WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc. Presione 88-90 242,918 51-150 151-200 ROBUST Robust 2004 datos 528,155 301-450 601-700 WT10g Colección Web de TREC 1,692,096 451-500 501-550 GOV2 Rastreo 2004 del dominio .gov 25,205,179 701-750 751-800 Tabla 2: Resumen de las colecciones y temas de TREC. documentos de retroalimentación relevantes utilizados y el número de términos de expansión. 4.1.1 Expansión con Conceptos de Términos Únicos Comenzamos evaluando qué tan bien funciona nuestro modelo al expandir utilizando solo términos individuales. Antes de describir y analizar los resultados, declaramos explícitamente cómo se calculan las probabilidades de términos de expansión bajo esta configuración (es decir, utilizando la suposición de dependencia secuencial, expandiendo con conceptos de un solo término y utilizando nuestro conjunto de características). Las probabilidades de términos de expansión se calculan de la siguiente manera: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) donde b ∈ Q denota el conjunto de bigramas en Q. Esta ecuación muestra claramente cómo LCE difiere de los modelos de relevancia. Cuando establecemos λTD = λT,D = 1 y todos los demás parámetros en 0, obtenemos la fórmula exacta que se utiliza para calcular las probabilidades de términos en el marco de modelado de relevancia. Por lo tanto, LCE añade dos factores muy importantes a la ecuación. Primero, agrega las características de ventana ordenadas y no ordenadas que se aplican a la consulta original. En segundo lugar, aplica una forma intuitiva similar a tf.idf al término de expansión candidato w. El factor idf, que no está presente en los modelos de relevancia, juega un papel importante en la selección del término de expansión. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figura 2: Histogramas que demuestran y comparan la robustez de los modelos de relevancia (RM3) y la expansión de conceptos latentes (LCE) con respecto al modelo de probabilidad de consulta (QL) para los conjuntos de datos AP, ROBUST y WT10G. Los resultados, evaluados utilizando la precisión promedio media, se muestran en la Tabla 3. Como vemos, el modelo MRF, los modelos de relevancia y LCE siempre superan significativamente al modelo de lenguaje unigrama. Además, LCE muestra mejoras significativas sobre los modelos de relevancia en todos los conjuntos de datos. Las mejoras relativas sobre los modelos de relevancia son del 6.9% para AP, 12.9% para WSJ, 6.5% para ROBUST, 16.7% para WT10G y 7.3% para GOV2. Además, LCE muestra pequeñas mejoras, pero no significativas, respecto al modelado de relevancia para métricas como precisión en 5, 10 y 20. Sin embargo, tanto el modelado de relevancia como el LCE muestran mejoras estadísticamente significativas en dichas métricas sobre el modelo de lenguaje unigrama. Otro resultado interesante es que el modelo MRF es estadísticamente equivalente a los modelos de relevancia en los dos conjuntos de datos web. De hecho, el modelo MRF supera a los modelos de relevancia en el conjunto de datos WT10g. Esto reitera la importancia de las características no unigrama, basadas en la proximidad para la búsqueda web basada en contenido observada previamente [14, 16]. Aunque nuestro modelo tiene más parámetros libres que los modelos de relevancia, sorprendentemente hay poco sobreajuste. En cambio, el modelo muestra buenas propiedades de generalización. 4.1.2 Expansión con Conceptos de Múltiples Términos También investigamos la expansión utilizando conceptos de una y dos palabras. Para cada consulta, expandimos utilizando un conjunto de conceptos de un solo término y un conjunto de conceptos de dos términos. Los conjuntos fueron elegidos de forma independiente. Desafortunadamente, solo se observaron aumentos insignificantes en la precisión promedio. Este resultado puede deberse al hecho de que existen fuertes correlaciones entre los conceptos de expansión de términos individuales. Descubrimos que los dos conceptos de palabras elegidos a menudo consistían en dos términos altamente correlacionados que también son elegidos como conceptos de términos individuales. Por ejemplo, se eligió el concepto de dos términos mercado de valores, mientras que también se eligieron los conceptos de un solo término acciones y mercado. Por lo tanto, muchos conceptos de dos palabras es poco probable que aumenten el poder discriminativo de la consulta ampliada. Este resultado sugiere que los conceptos deben ser elegidos de acuerdo con ciertos criterios que también tengan en cuenta la novedad, la diversidad o las correlaciones de términos. Otro problema potencial es el conjunto de características utilizado. Otros conjuntos de características pueden dar resultados diferentes en última instancia, especialmente si reducen la correlación entre los conceptos de expansión. Por lo tanto, nuestros experimentos no arrojan resultados concluyentes en cuanto a la expansión utilizando conceptos de varios términos. En cambio, los resultados plantean preguntas abiertas interesantes y direcciones para futuras exploraciones. Tabla 3: Promedio de precisión media en el conjunto de pruebas para modelado de lenguaje (LM), campo aleatorio de Markov (MRF), modelos de relevancia (RM3) y expansión de conceptos latentes (LCE). Los superíndices α, β y γ indican mejoras estadísticamente significativas (p < 0.05) sobre LM, MRF y RM3, respectivamente. 4.2 Robustez Como hemos demostrado, los modelos de relevancia y la expansión de conceptos latentes pueden mejorar significativamente la efectividad de recuperación sobre el modelo de probabilidad de consulta base. En esta sección analizamos la robustez de estos dos métodos. Aquí definimos la robustez como el número de consultas cuya efectividad se ve mejorada/afectada (y en qué medida) como resultado de aplicar estos métodos. Una técnica de expansión altamente robusta mejorará significativamente muchas consultas y solo perjudicará mínimamente a unas pocas. La Figura 2 proporciona un análisis de la robustez del modelado de relevancia y la expansión de conceptos latentes para los conjuntos de datos AP, ROBUST y WT10G. El análisis de los dos conjuntos de datos no mostrados es similar. Los histogramas proporcionan, para varios rangos de disminuciones/aumentos relativos en la precisión media promedio, el número de consultas que se vieron perjudicadas/mejoradas con respecto a la línea base de probabilidad de consulta. Como muestran los resultados, LCE muestra una fuerte robustez para cada conjunto de datos. Para AP, los modelos de relevancia mejoran 38 consultas y perjudican 11, mientras que LCE mejora 35 y perjudica 14. Aunque los modelos de relevancia mejoran la efectividad de 3 consultas más que LCE, la mejora relativa exhibida por LCE es significativamente mayor. Para el conjunto de datos ROBUST, los modelos de relevancia mejoran 67 consultas y perjudican 32, y LCE mejora 77 y perjudica 22. Finalmente, para la colección WT10G, los modelos de relevancia mejoran 32 consultas y perjudican 16, y LCE mejora 35 y perjudica 14. Al igual que con AP, la cantidad de mejora exhibida por el LCE frente a los modelos de relevancia es significativamente mayor tanto para los conjuntos de datos ROBUST como WT10G. Además, cuando LCE afecta al rendimiento, es menos probable que afecte tanto como el modelado de relevancia, lo cual es una propiedad deseable. En general, LCE mejora la efectividad para el 65%-80% de las consultas, dependiendo del conjunto de datos. Cuando se utiliza en combinación con un sistema de predicción de rendimiento de consulta altamente preciso, puede ser posible expandir selectivamente las consultas y minimizar la pérdida asociada con el rendimiento sub-baseline. 4.3 Generación de Conceptos de Múltiples Términos Aunque encontramos que la expansión utilizando conceptos de múltiples términos no logró producir mejoras concluyentes en la efectividad, hay otras tareas potenciales para las cuales estos conceptos pueden ser útiles, como sugerencia/reformulación de consultas, resumen y extracción de conceptos. Por ejemplo, para una tarea de sugerencia de consultas, la consulta original podría usarse para generar un conjunto de conceptos latentes que corresponden a formulaciones alternativas de la consulta. Aunque evaluar nuestro modelo en estas tareas está fuera del alcance de este trabajo, deseamos mostrar un ejemplo ilustrativo de los tipos de conceptos generados utilizando nuestro modelo. En la Tabla 4, presentamos los conceptos de una, dos y tres palabras más probables generados utilizando LCE para la consulta logros del telescopio Hubble utilizando los 25 documentos mejor clasificados de la colección ROBUST. Es bien sabido que generar conceptos de múltiples términos utilizando un modelo basado en unigramas produce resultados insatisfactorios, ya que no considera las dependencias entre los términos. Esto no es el caso al generar conceptos de múltiples términos usando nuestro modelo. En cambio, la mayoría de los conceptos generados son bien formados y significativos. Hay varios casos donde los conceptos son menos coherentes, como espejo espejo espejo. En este caso, la probabilidad de que aparezca el término \"espejo\" en un documento pseudo-relevante supera a las características de modelado de lenguaje (por ejemplo, fOQ), lo que provoca que este concepto no coherente tenga una alta probabilidad. Tales ejemplos son minoría, sin embargo. No solo los conceptos generados son bien formados y significativos, sino que también son relevantes al tema de la consulta original. Como podemos ver, todos los conceptos generados están relacionados con el tema y de alguna manera están relacionados con el telescopio Hubble. Es interesante ver que el concepto de fallo del telescopio Hubble es uno de los tres conceptos de términos más probables, dado que es algo contradictorio con la consulta original. A pesar de esta contradicción, es probable que los documentos que discuten las fallas del telescopio también describan los éxitos, por lo tanto, es probable que este sea un concepto significativo. Una cosa importante a tener en cuenta es que los conceptos generados por LCE son de una naturaleza diferente a los que se generarían utilizando un modelo de relevancia de bigrama. Por ejemplo, un modelo de bigrama sería poco probable que genere el concepto telescopio espacio NASA, ya que ninguno de los bigramas que componen el concepto tiene una alta probabilidad. Sin embargo, dado que nuestro modelo se basa en una serie de características diferentes sobre varios tipos de cliques, es más general y robusto que un modelo de bigrama. Aunque solo proporcionamos los conceptos generados para una sola consulta, señalamos que el mismo análisis y conclusiones se generalizan a través de otros conjuntos de datos, con conceptos coherentes y relacionados temáticamente generados de manera consistente utilizando LCE. 4.4 Discusión Nuestra técnica de expansión de conceptos latentes captura dos tipos de dependencia semiortogonales. En la recuperación de información, ha existido un interés a largo plazo en comprender el papel de la dependencia de términos. De esta investigación, se han identificado dos tipos generales de dependencias. El primer tipo de dependencia es la dependencia sintáctica. Este tipo de dependencia abarca frases, proximidad de términos y co-ocurrencia de términos [2, 4, 5, 7, 26]. Estos métodos capturan el hecho de que las consultas imponen implícita o explícitamente un cierto conjunto de dependencias posicionales. El segundo tipo es la dependencia semántica. Ejemplos de dependencia semántica son la retroalimentación de relevancia, la retroalimentación de pseudo-relevancia, sinónimos y en cierta medida el truncamiento [3]. Estas técnicas han sido exploradas tanto en el lado de la consulta como en el lado del documento. En el lado de la consulta, esto se suele hacer utilizando alguna forma de expansión de consulta, como modelos de relevancia o LCE. En el lado del documento, esto se hace como expansión de documentos o suavizado de documentos [11, 13, 24]. Aunque puede haber cierta superposición entre las dependencias sintácticas y semánticas, en su mayoría son ortogonales. Nuestro modelo utiliza ambos tipos de dependencias. El uso de características de frase y proximidad dentro del modelo captura dependencias sintácticas, mientras que LCE captura dependencias semánticas del lado de la consulta. Esto explica por qué la mejora inicial en la efectividad lograda al usar el modelo MRF no se pierde después de la expansión de consultas. Si los mismos tipos de dependencias fueran capturados tanto por dependencias sintácticas como semánticas, se esperaría que LCE funcionara aproximadamente igual de bien que los modelos de relevancia. Por lo tanto, al modelar ambos tipos de dependencias, observamos un efecto aditivo en lugar de un efecto absorbente. Una área interesante de trabajo futuro es determinar si modelar las dependencias semánticas del lado del documento puede aportar algo al modelo. Resultados previos que han combinado dependencias semánticas del lado de la consulta y del documento han mostrado resultados mixtos [13, 27]. 5. CONCLUSIONES En este artículo propusimos una técnica robusta de expansión de consultas llamada expansión de conceptos latentes. La técnica se demostró ser una extensión natural del modelo de campo aleatorio de Markov para la recuperación de información y una generalización de los modelos de relevancia. LCE es novedoso en el sentido de que realiza una expansión de un solo término o de varios términos dentro de un marco que permite el modelado de dependencias entre términos y el uso de características arbitrarias, mientras que trabajos anteriores se basaban en la suposición de la bolsa de palabras y características de ocurrencia de términos. Mostramos que la técnica puede ser utilizada para producir conceptos de expansión de varios términos de alta calidad, bien formados y relevantes desde el punto de vista temático. Los conceptos generados pueden ser utilizados en un módulo de sugerencia de consultas alternativas. También demostramos que el modelo es altamente efectivo. De hecho, logra mejoras significativas en la precisión promedio media en comparación con los modelos de relevancia en una selección de conjuntos de datos de TREC. También se demostró que el modelo MRF por sí solo, sin ninguna expansión de consulta, supera a los modelos de relevancia en grandes conjuntos de datos web. Esto reafirma observaciones previas de que modelar dependencias a través del uso de características de proximidad dentro del MRF tiene un mayor impacto en colecciones más grandes y ruidosas que en colecciones más pequeñas y bien comportadas. Finalmente, reiteramos la importancia de elegir términos de expansión que modelen la relevancia, en lugar de los documentos relevantes, y mostramos cómo LCE captura tanto las dependencias sintácticas como semánticas del lado de la consulta. El trabajo futuro se centrará en incorporar dependencias del lado del documento también. Agradecimientos Este trabajo fue apoyado en parte por el Centro de Recuperación de Información Inteligente, en parte por la subvención NSF #CNS-0454018, en parte por ARDA y la subvención NSF #CCF-0205575, y en parte por Microsoft Live Labs. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son responsabilidad del autor o los autores y no necesariamente reflejan las del patrocinador.  REFERENCIAS [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker y C. Wade. UMass en TREC 2004: Novedad y DIFICULTAD. En Actas en línea de la Conferencia de Recuperación de Información de 2004, 2004. [2] C. L. A. Clarke y G. V. Cormack. Recuperación y clasificación de la subcadena más corta. ACM Trans. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate to Spanish? Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson y J. Callan. Expansión de consultas utilizando modelos de caminata aleatoria. En Proc. 14th Intl. Conf. sobre Gestión de Información y Conocimiento, páginas 704-711, 2005. [4] W. B. Croft. Consultas booleanas y dependencias de términos en modelos de recuperación probabilística. Revista de la Sociedad Americana de Ciencia de la Información, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle y D. Lewis. El uso de frases y consultas estructuradas en la recuperación de información. En Proc. 14º Anu. Internacional. Conferencia ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 32-45, 1991. [6] K. Eguchi. Experimentos de expansión de consultas NTCIR-5 utilizando modelos de dependencia de términos. En Actas del Quinto Taller de Reunión NTCIR sobre Evaluación de Tecnologías de Acceso a la Información, páginas 494-501, 2005. [7] J. Fagan. Indexación automática de frases para la recuperación de documentos: Un examen de métodos sintácticos y no sintácticos. En el Proc. décimo anual. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 91-101, 1987. [8] J. Gao, J. Nie, G. Wu y G. Cao. Modelo de lenguaje de dependencia para recuperación de información. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 170-177, 2004. [9] D. Harper y C. J. van Rijsbergen. Una evaluación de la retroalimentación en la recuperación de documentos utilizando datos de co-ocurrencia. Revista de Documentación, 34(3):189-216, 1978. [10] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Proc. de la Conf. Internacional de Aprendizaje Automático, páginas 377-384, 2005. [11] O. Kurland y L. Lee. Estructura del corpus, modelos de lenguaje y recuperación de información ad-hoc. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 194-201, 2004. [12] V. Lavrenko y W. B. Croft. Modelos de lenguaje basados en relevancia. En Proc. 24º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 120-127, 2001. [13] X. Liu y W. B. Croft. Recuperación basada en clústeres utilizando modelos de lenguaje. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 186-193, 2004. [14] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias entre términos. En Proc. 28vo Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [15] D. Metzler y W. B. Croft. Modelos basados en características lineales para la recuperación de información. Recuperación de información, por aparecer, 2006. [16] D. Metzler, T. Strohman, Y. Zhou y W. B. Croft. Indri en la pista de terabyte en 2005. En Actas en línea de la Conferencia de Recuperación de Texto de 2005, 2005. [17] W. Morgan, W. Greiff y J. Henderson. Maximización directa de la precisión promedio mediante escalada de colina con una comparación con un enfoque de entropía máxima. Informe técnico, MITRE, 2004. [18] P. Ogilvie y J. P. Callan. Experimentos utilizando el kit de herramientas de lémures. En Proc. de la Conferencia de Recuperación de Texto, 2001. [19] R. Papka y J. Allan. Por qué las ventanas más grandes son mejores que las más pequeñas. Informe técnico, Universidad de Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu y M. Gatford. Okapi en trec-3. En Actas en línea de la Tercera Conferencia de Recuperación de Texto, páginas 109-126, 1995. [21] J. J. Rocchio. Retroalimentación de relevancia en la recuperación de información, páginas 313-323. Prentice-Hall, 1971. [22] F. Song y W. B. Croft. Un modelo de lenguaje general para la recuperación de información. En Proc. octava conferencia internacional sobre Gestión de la Información y el Conocimiento (CIKM 99), páginas 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle y W. B. Croft. Indri: Un motor de búsqueda basado en modelos de lenguaje para consultas complejas. En Actas de la Conferencia Internacional sobre Análisis de Inteligencia, 2004. [24] T. Tao, X. Wang, Q. Mei y C. Zhai. Recuperación de información del modelo de lenguaje con expansión de documentos. En Proc. de HLT/NAACL, páginas 407-414, 2006. [25] B. Taskar, C. Guestrin y D. Koller. Redes de Markov de margen máximo. En Proc. de Avances en Sistemas de Información Neural (NIPS 2003), 2003. [26] C. J. van Rijsbergen. Una base teórica para el uso de datos de coocurrencia en la recuperación de información. Revista de Documentación, 33(2):106-119, 1977. [27] X. Wei y W. B. Croft. Modelos de documentos basados en LDA para recuperación ad-hoc. En Proc. 29º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 178-185, 2006. [28] J. Xu y W. B. Croft. Mejorando la efectividad de la recuperación de información con análisis de contexto local. ACM Trans. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate into Spanish? Syst., 18(1):79-112, 2000. [29] C. Zhai y J. Lafferty. Retroalimentación basada en modelos en el enfoque de modelado del lenguaje para la recuperación de información. En Proc. 10th Intl. Conferencia sobre Gestión de la Información y el Conocimiento, páginas 403-410, 2001. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "relevance feedback": {
            "translated_key": "retroalimentación de relevancia",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-<br>relevance feedback</br> or <br>relevance feedback</br>, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the <br>relevance feedback</br> and pseudo-<br>relevance feedback</br> setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using <br>relevance feedback</br> to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-<br>relevance feedback</br> setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are <br>relevance feedback</br>, pseudo-<br>relevance feedback</br>, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "<br>relevance feedback</br> in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-<br>relevance feedback</br> or <br>relevance feedback</br>, is a common technique used to improve retrieval effectiveness.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the <br>relevance feedback</br> and pseudo-<br>relevance feedback</br> setting [12, 21, 28, 29].",
                "Papka and Allan investigate using <br>relevance feedback</br> to perform multi-term concept expansion for document routing [19].",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-<br>relevance feedback</br> setting.",
                "Examples of semantic dependence are <br>relevance feedback</br>, pseudo-<br>relevance feedback</br>, synonyms, and to some extent stemming [3]."
            ],
            "translated_annotated_samples": [
                "Expansión de conceptos latentes utilizando campos aleatorios de Markov. Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Centro de Recuperación de Información Inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 RESUMEN La expansión de consultas, en forma de retroalimentación de pseudo relevancia o retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación.",
                "Las técnicas de expansión de consultas han sido ampliamente estudiadas para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la retroalimentación de pseudo-relevancia [12, 21, 28, 29].",
                "Papka y Allan investigan el uso de <br>retroalimentación de relevancia</br> para realizar la expansión de conceptos de varios términos en el enrutamiento de documentos [19].",
                "Construimos G utilizando la suposición de dependencia secuencial para todos los conjuntos de datos [14]. 4.1 Resultados de recuperación ad-hoc Ahora investigamos qué tan bien se desempeña nuestro modelo en la práctica en un entorno de <br>retroalimentación de relevancia</br> pseudo.",
                "Ejemplos de dependencia semántica son la retroalimentación de relevancia, la retroalimentación de pseudo-relevancia, sinónimos y en cierta medida el truncamiento [3]."
            ],
            "translated_text": "Expansión de conceptos latentes utilizando campos aleatorios de Markov. Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Centro de Recuperación de Información Inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 RESUMEN La expansión de consultas, en forma de retroalimentación de pseudo relevancia o retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación. La mayoría de enfoques anteriores han ignorado problemas importantes, como el papel de las características y la importancia de modelar las dependencias entre términos. En este artículo, proponemos una técnica robusta de expansión de consultas basada en el modelo de campo aleatorio de Markov para la recuperación de información. La técnica, llamada expansión de conceptos latentes, proporciona un mecanismo para modelar las dependencias de términos durante la expansión. Además, el uso de características arbitrarias dentro del modelo proporciona un marco poderoso para ir más allá de las simples características de ocurrencia de términos que son utilizadas implícitamente por la mayoría de las otras técnicas de expansión. Evaluamos nuestra técnica frente a modelos de relevancia, una técnica de expansión de consultas de modelado de lenguaje de última generación. Nuestro modelo demuestra mejoras consistentes y significativas en la efectividad de recuperación en varios conjuntos de datos de TREC. También describimos cómo nuestra técnica puede ser utilizada para generar conceptos significativos de varios términos para tareas como sugerencia/reformulación de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales Algoritmos, Experimentación, Teoría 1. Los usuarios de los sistemas de recuperación de información deben expresar necesidades de información complejas en términos de expresiones booleanas, una lista corta de palabras clave, una oración, una pregunta o posiblemente un relato más extenso. Se pierde mucha información durante el proceso de traducción desde la necesidad de información hasta la consulta real. Por esta razón, ha habido un fuerte interés en las técnicas de expansión de consultas. Tales técnicas se utilizan para ampliar la consulta original y producir una representación que refleje mejor la necesidad de información subyacente. Las técnicas de expansión de consultas han sido ampliamente estudiadas para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la retroalimentación de pseudo-relevancia [12, 21, 28, 29]. Recientemente, se propuso un modelo de campo aleatorio de Markov (MRF) para la recuperación de información que va más allá de la simplista suposición de bolsa de palabras que subyace en BM25 y en el enfoque de modelado de lenguaje (unigrama) para la recuperación de información [20, 22]. El modelo MRF generaliza los modelos de unigrama, bigrama y otras diversas dependencias [14]. La mayoría de los modelos de dependencia de términos pasados no han logrado mostrar mejoras consistentes y significativas sobre las líneas de base de unigramas, con pocas excepciones [8]. El modelo MRF, sin embargo, ha demostrado ser altamente efectivo en una serie de tareas, incluyendo la recuperación ad hoc [14, 16], la búsqueda de páginas con nombres [16] y la búsqueda web en japonés [6]. Hasta ahora, el modelo ha sido utilizado únicamente para clasificar documentos en respuesta a una consulta dada. En este trabajo, mostramos cómo el modelo puede ser ampliado y utilizado para la expansión de consultas utilizando una técnica que llamamos expansión de conceptos latentes (LCE). Hay tres contribuciones principales de nuestro trabajo. Primero, LCE proporciona un mecanismo para combinar la dependencia de términos con la expansión de consultas. Las técnicas de expansión de consultas anteriores se basan en modelos de bolsa de palabras. Por lo tanto, al realizar la expansión de consultas utilizando el modelo MRF, podemos estudiar la dinámica entre la dependencia de términos y la expansión de consultas. A continuación, como mostraremos, el modelo MRF permite que se utilicen características arbitrarias dentro del modelo. Las técnicas de expansión de consultas en el pasado solo han hecho uso implícito de características de ocurrencia de términos. Al utilizar conjuntos de características más robustos, es posible producir términos de expansión mejores que discriminan de manera más efectiva entre documentos relevantes y no relevantes. Finalmente, nuestro enfoque propuesto proporciona de manera fluida un mecanismo para generar conceptos de una sola y múltiples términos. La mayoría de las técnicas anteriores, por defecto, generan términos de forma independiente. Ha habido varios enfoques que hacen uso de conceptos generalizados, sin embargo, dichos enfoques fueron algo heurísticos y realizados fuera del modelo [19, 28]. Nuestro enfoque está motivado tanto formalmente como es una extensión natural del modelo subyacente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2 describimos enfoques relacionados de expansión de consultas. La sección 3 proporciona una visión general del modelo MRF y detalla nuestra técnica propuesta de expansión de conceptos latentes. En la Sección 4 evaluamos nuestro modelo propuesto y analizamos los resultados. Finalmente, la Sección 5 concluye el artículo y resume los principales resultados. 2. TRABAJO RELACIONADO Uno de los enfoques clásicos y más ampliamente utilizados para la expansión de consultas es el algoritmo de Rocchio [21]. El enfoque de Rocchio, que fue desarrollado dentro del modelo de espacio vectorial, reajusta el vector de consulta original moviendo los pesos hacia el conjunto de documentos relevantes o pseudo-relevantes y alejándolos de los documentos no relevantes. Desafortunadamente, no es posible aplicar formalmente el enfoque de Rocchio a un modelo de recuperación estadística, como el modelado del lenguaje para la recuperación de información. Se han desarrollado varias técnicas de expansión de consultas formalizadas para el marco de modelado de lenguaje, incluyendo el feedback basado en el modelo de Zhai y Lafferty y los modelos de relevancia de Lavrenko y Crofts [12, 29]. Ambos enfoques intentan utilizar documentos pseudo-relevantes o relevantes para estimar un modelo de consulta mejor. El feedback basado en modelos encuentra el modelo que mejor describe los documentos relevantes teniendo en cuenta un modelo de fondo (ruido). Esto separa el modelo de contenido del modelo de fondo. El modelo de contenido se interpola con el modelo de consulta original para formar la consulta ampliada. La otra técnica, modelos de relevancia, está más relacionada con nuestro trabajo. Por lo tanto, entramos en los detalles del modelo. Al igual que el feedback basado en modelos, los modelos de relevancia estiman un modelo de consulta mejorado. La única diferencia entre los dos enfoques es que los modelos de relevancia no modelan explícitamente los documentos relevantes o pseudo-relevantes. En cambio, ellos modelan una noción más generalizada de relevancia, como mostraremos ahora. Dada una consulta Q, un modelo de relevancia es una distribución multinomial, P(·|Q), que codifica la probabilidad de cada término dado la consulta como evidencia. Se calcula como: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) donde RQ es el conjunto de documentos que son relevantes o pseudo relevantes para la consulta Q. En el caso pseudo-relevante, estos son los documentos mejor clasificados para la consulta Q. Además, se asume que P(D) es uniforme en este conjunto. Estas suposiciones suaves hacen que el cálculo del posterior bayesiano sea más práctico. Después de que el modelo es estimado, los documentos son clasificados por recortar el modelo de relevancia al elegir los k términos más probables de P(·|Q). Esta distribución recortada se interpola luego con el modelo de consulta de máxima verosimilitud original. Esto se puede considerar como la expansión de la consulta original por k términos ponderados. A lo largo del resto de este trabajo, nos referimos a esta instancia de modelos de relevancia como RM3. Ha habido relativamente poco trabajo realizado en el área de expansión de consultas en el contexto de modelos de dependencia [9]. Sin embargo, ha habido varios intentos de expandir utilizando conceptos de varios términos. El método de análisis de contexto local (LCA) de Xu y Crofts combinaba la recuperación a nivel de pasaje con la expansión de conceptos, donde los conceptos eran términos y frases simples [28]. Los conceptos de expansión fueron elegidos y ponderados utilizando una métrica basada en estadísticas de co-ocurrencia. Sin embargo, no está claro, basándose en el análisis realizado, cuánto ayudaron las frases en comparación con los términos individuales solos. Papka y Allan investigan el uso de <br>retroalimentación de relevancia</br> para realizar la expansión de conceptos de varios términos en el enrutamiento de documentos [19]. Los conceptos utilizados en su trabajo son más generales que los utilizados en el LCA e incluyen estructuras de lenguaje de consulta InQuery, como #UW50(casa blanca), que corresponde al concepto en el que los términos casa y blanca ocurren, en cualquier orden, dentro de 50 términos uno del otro. Los resultados mostraron que combinar conceptos de un solo término y conceptos de varios términos con una ventana grande mejoró significativamente la efectividad. Sin embargo, no está claro si el mismo enfoque también es efectivo para la recuperación ad hoc, debido a las diferencias en las tareas. 3. Este apartado detalla nuestra técnica propuesta de expansión de conceptos latentes. Como se mencionó anteriormente, la técnica es una extensión del modelo MRF para la recuperación de información [14]. Por lo tanto, comenzamos proporcionando una visión general del modelo MRF y nuestras extensiones propuestas. 3.1 MRFs para IR 3.1.1 Conceptos básicos Los campos aleatorios de Markov, que son modelos gráficos no dirigidos, proporcionan una forma compacta y robusta de modelar una distribución conjunta. Aquí estamos interesados en modelar la distribución conjunta sobre una consulta Q = q1, . . . , qn y un documento D. Se asume que la distribución subyacente sobre pares de documentos y consultas es una distribución de relevancia. Es decir, muestrear de la distribución proporciona pares de documentos y consultas, de modo que el documento sea relevante para la consulta. Un MRF se define por un grafo G y un conjunto de funciones de potencial no negativas sobre los cliques en G. Los nodos en el grafo representan las variables aleatorias y las aristas definen la semántica de independencia de la distribución. Un MRF cumple con la propiedad de Markov, la cual establece que un nodo es independiente de todos sus nodos no vecinos dado los valores observados de sus vecinos. Dado un grafo G, un conjunto de potenciales ψi y un vector de parámetros Λ, la distribución conjunta sobre Q y D está dada por: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) donde Z es una constante de normalización. Seguimos la convención común y parametrizamos los potenciales como ψi(c; Λ) = exp[λifi(c)], donde fi(c) es una función de características de valores reales. 3.1.2 Construcción de G Dada una consulta Q, el grafo G puede ser construido de varias maneras. Sin embargo, siguiendo el trabajo previo, consideramos tres variantes simples [14]. Estas variantes son independencia total, donde cada término de consulta es independiente de los demás dado un documento, dependencia secuencial, que asume que existe una dependencia entre los términos de consulta adyacentes, y dependencia total, que no hace suposiciones de independencia. 3.1.3 Parametrización Los MRFs suelen ser parametrizados comúnmente en función de los cliques máximos de G. Sin embargo, dicha parametrización es demasiado gruesa para nuestras necesidades. Necesitamos una parametrización que nos permita asociar funciones de características con cliques a un nivel más detallado, manteniendo al mismo tiempo el número de características, y por lo tanto el número de parámetros, razonable. Por lo tanto, permitimos que los grupos compartan funciones de características y parámetros basados en conjuntos de grupos. Es decir, todos los subgrupos dentro de un conjunto de subgrupos están asociados con la misma función de característica y comparten un solo parámetro. Esto une de manera efectiva los parámetros de las características asociadas con cada conjunto, lo que reduce significativamente el número de parámetros mientras aún proporciona un mecanismo para el ajuste fino en el nivel de conjuntos de cliques. Proponemos siete conjuntos de cliques para utilizar en la recuperación de información. Los primeros tres conjuntos de cliques consisten en cliques que contienen uno o más términos de consulta y el nodo del documento. Las características sobre estos grupos deberían codificar qué tan bien los términos en la configuración del grupo describen el documento. Estos conjuntos son: • TD - conjunto de cliques que contienen el nodo del documento y exactamente un término de consulta. • OD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en orden secuencial dentro de la consulta. • UD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en cualquier orden dentro de la consulta. Ten en cuenta que UD es un superconjunto de OD. Al atar los parámetros entre los grupos dentro de cada conjunto podemos controlar cuánta influencia recibe cada tipo. Esto también evita el problema de tratar de determinar cómo estimar los pesos para cada clique dentro de los conjuntos. En cambio, ahora solo debemos estimar un parámetro por conjunto. A continuación, consideramos cliques que solo contienen nodos de términos de consulta. Estas cliques, que no fueron consideradas en [14], se definen de manera análoga a las recién definidas, excepto que las cliques solo están formadas por nodos de términos de consulta y no contienen el nodo de documento. Las funciones de características sobre estos conjuntos deben capturar qué tan compatibles son entre sí los términos de consulta. Estas características de grupo pueden adoptar la forma de modelos de lenguaje que imponen la corrección de los términos. Por lo tanto, definimos los siguientes conjuntos de cliques dependientes de la consulta: • TQ - conjunto de cliques que contienen exactamente un término de la consulta. • OQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en orden secuencial dentro de la consulta. • UQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en cualquier orden dentro de la consulta. Finalmente, está la clique que solo contiene el nodo del documento. Las características sobre este nodo pueden ser utilizadas como un tipo de documento previo, codificando propiedades centradas en el documento. Este conjunto de cliques trivial es entonces: • D - conjunto de cliques que contiene solo el nodo único D. Observamos que nuestros conjuntos de cliques forman una cobertura de conjuntos sobre los cliques de G, pero no son una partición, ya que algunos cliques aparecen en múltiples conjuntos de cliques. Después de atar los parámetros en nuestros conjuntos de cliques y usar la forma de la función potencial exponencial, terminamos con la siguiente forma simplificada de la distribución conjunta: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - dependiente del documento y la consulta + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - dependiente de la consulta + λDfD(D) FD(D) - dependiente del documento − log ZΛ documento + independiente de la consulta donde FDQ, FQ y FD son funciones de conveniencia definidas por los componentes dependientes del documento y la consulta, dependientes de la consulta y dependientes del documento de la distribución conjunta, respectivamente. Estos se utilizarán para simplificar y clarificar las expresiones derivadas a lo largo del resto del documento. 3.1.4 Características Cualquier función de característica arbitraria sobre configuraciones de cliques puede ser utilizada en el modelo. La elección correcta de las características depende en gran medida de la tarea de recuperación y la métrica de evaluación. Por lo tanto, es probable que no exista un conjunto único y universalmente aplicable de características. Para dar una idea de la variedad de características que se pueden utilizar, ahora describimos brevemente posibles tipos de características que podrían ser utilizadas. Posibles características dependientes del término de consulta incluyen tf, idf, entidades nombradas, proximidad de términos y estilo de texto, por nombrar algunas. Se pueden utilizar muchos tipos de características dependientes del documento, como la longitud del documento, el PageRank, la legibilidad y el género, entre otros. Dado que nuestro objetivo aquí no es encontrar características óptimas, utilizamos un conjunto simple y fijo de características que han demostrado ser efectivas en trabajos anteriores [14]. Consulte la Tabla 1 para ver la lista de características utilizadas. Estas características intentan capturar la ocurrencia de términos y la proximidad entre términos. Una mejor selección de características en el futuro probablemente conducirá a una mayor efectividad. 3.1.5 Clasificación Dada una consulta Q, deseamos clasificar los documentos en orden descendente según PG,Λ(D|Q). Después de eliminar las expresiones independientes del documento del registro PG,Λ(Q, D), derivamos la siguiente función de clasificación: PG,Λ(D|Q) rango = FDQ(D, Q) + FD(D) (2), que es una simple combinación lineal ponderada de funciones de características que pueden calcularse eficientemente para grafos razonables. 3.1.6 Estimación de Parámetros Ahora que el modelo ha sido completamente especificado, el paso final es estimar los parámetros del modelo. Aunque los MRF son modelos generativos, no es apropiado entrenarlos utilizando la función de valor de características fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Tabla 1: Funciones de características utilizadas en el modelo de campo aleatorio de Markov. Aquí, tfw,D es el número de veces que el término w ocurre en el documento D, tf#1(qi...qi+k),D denota el número de veces que la frase exacta qi . . . qi+k ocurre en el documento D, tf#uw(qi...qj ),D es el número de veces que los términos qi, . . . qj aparecen ordenados o desordenados dentro de una ventana de N términos, y |D| es la longitud del documento D. Los valores de cf y |C| se definen de manera análoga a nivel de colección. Finalmente, α y β son hiperparámetros del modelo que controlan el suavizado para las características de términos únicos y frases, respectivamente. Enfoques convencionales basados en la verosimilitud debido a la divergencia métrica [17]. Es decir, es poco probable que la estimación de máxima verosimilitud sea la estimación que maximiza nuestra métrica de evaluación. Por esta razón, entrenamos de manera discriminativa nuestro modelo para maximizar directamente la métrica de evaluación considerada [14, 15, 25]. Dado que nuestro espacio de parámetros es pequeño, hacemos uso de una estrategia simple de escalada de colina, aunque son posibles otros enfoques más sofisticados [10]. 3.2 Expansión de Conceptos Latentes En esta sección describimos cómo este modelo MRF extendido puede ser utilizado de una manera novedosa para generar conceptos de un solo término y de varios términos que están relacionados temáticamente con alguna consulta original. Como mostraremos, los conceptos generados utilizando nuestra técnica pueden ser utilizados para la expansión de consultas u otras tareas, como sugerir formulaciones alternativas de consultas. Suponemos que cuando un usuario formula su consulta original, tiene en mente un conjunto de conceptos, pero solo puede expresar un pequeño número de ellos en forma de consulta. Tratamos los conceptos que el usuario tiene en mente, pero no expresó explícitamente en la consulta, como conceptos latentes. Estos conceptos latentes pueden consistir en un solo término, varios términos o alguna combinación de ambos. Por lo tanto, nuestro objetivo es recuperar estos conceptos latentes dada alguna consulta original. Esto se puede lograr dentro de nuestro marco de trabajo al expandir primero el grafo original G para incluir el tipo de concepto que nos interesa generar. Llamamos a este gráfico expandido H. En la Figura 1, el gráfico del medio proporciona un ejemplo de cómo construir un gráfico expandido que puede generar conceptos de un solo término. De manera similar, el gráfico de la derecha ilustra un gráfico ampliado que genera dos conceptos de términos. Aunque estos dos ejemplos hacen uso de la suposición de dependencia secuencial (es decir, dependencias entre términos de consulta adyacentes), es importante tener en cuenta que tanto la consulta original como los conceptos de expansión pueden utilizar cualquier estructura de independencia. Después de que H se construye, calculamos PH,Λ(E|Q), una distribución de probabilidad sobre conceptos latentes, de acuerdo a: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) donde R es el universo de todos los documentos posibles y E es un concepto latente que puede consistir en uno o más términos. Dado que no es práctico calcular esta suma, debemos aproximarla. Observamos que PH,Λ(Q, E, D) probablemente se concentra alrededor de aquellos documentos D que están altamente clasificados según la consulta Q. Por lo tanto, aproximamos PH,Λ(E|Q) sumando solo un pequeño subconjunto de documentos relevantes o pseudo-relevantes para la consulta Q. Esto se calcula de la siguiente manera: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) donde RQ es un conjunto de documentos relevantes o pseudo-relevantes para la consulta Q y todos los conjuntos de cliques se construyen utilizando H. Como vemos, la contribución de probabilidad para cada documento en RQ es una combinación de la puntuación original de la consulta para el documento (ver Ecuación 2), la puntuación del concepto E para el documento y la puntuación independiente del documento de E. Por lo tanto, esta ecuación puede interpretarse como la medida de qué tan bien Q y E explican los documentos mejor clasificados y la bondad de E, independientemente de los documentos. Para lograr la máxima robustez, utilizamos un conjunto diferente de parámetros para FQD(Q, D) y FQD(E, D), lo que nos permite ponderar de manera diferente las características de ventana ordenadas y no ordenadas para la consulta original y el concepto de expansión candidato. 3.2.1 Expansión de consulta Para utilizar este marco para la expansión de consultas, primero elegimos un grafo de expansión H que codifique la estructura de concepto latente en la que estamos interesados en expandir la consulta. Luego seleccionamos los k conceptos latentes con la mayor probabilidad dada por la Ecuación 3. Se construye un nuevo grafo G al aumentar el grafo original G con los k conceptos de expansión E1, . . . , Ek. Finalmente, los documentos se clasifican según PG ,Λ(D|Q, E1, . . . , Ek) utilizando la Ecuación 2. 3.2.2 Comparación con los Modelos de Relevancia. Al inspeccionar las Ecuaciones 1 y 3 se revela la estrecha conexión que existe entre LCE y los modelos de relevancia. Ambos modelos esencialmente calculan la probabilidad de un término (o concepto) de la misma manera. Es fácil ver que al igual que el modelo MRF puede ser visto como una generalización del modelado del lenguaje, también LCE puede ser visto como una generalización de los modelos de relevancia. Existen diferencias importantes entre los modelos de lenguaje MRFs/LCE y los modelos de lenguaje unigram/relevancia. Consulte la Figura 1 para ver las representaciones gráficas de ambos modelos. Los modelos de lenguaje unigrama y los modelos de relevancia se basan en la distribución multinomial. Esta suposición de distribución encasilla el modelo en la representación de bolsa de palabras y el uso implícito de características de ocurrencia de términos. Sin embargo, la distribución subyacente al modelo MRF nos permite ir más allá de ambas suposiciones, al modelar tanto las dependencias entre los términos de consulta como permitir el uso explícito de características arbitrarias. Ir más allá de la simplista suposición de la bolsa de palabras de esta manera resulta en un modelo general y robusto y, como mostramos en la siguiente sección, se traduce en mejoras significativas en la efectividad de recuperación. 4. RESULTADOS EXPERIMENTALES Para comprender mejor las fortalezas y debilidades de nuestra técnica, la evaluamos en una amplia gama de conjuntos de datos. La Tabla 2 proporciona un resumen de los conjuntos de datos de TREC considerados. Las colecciones WSJ, AP y ROBUST son más pequeñas y consisten enteramente de artículos de agencias de noticias, mientras que WT10g y GOV2 son colecciones web grandes. Para cada conjunto de datos, dividimos los temas disponibles en un conjunto de entrenamiento y otro de prueba, donde el conjunto de entrenamiento se utiliza únicamente para la estimación de parámetros y el conjunto de prueba se utiliza con fines de evaluación. Todos los experimentos se llevaron a cabo utilizando una versión modificada de Indri, que forma parte del Lemur Toolkit [18, 23]. Todas las colecciones fueron detenidas utilizando una lista estándar de 418 términos comunes y truncadas utilizando un truncador de Porter. En todos los casos, solo se utiliza la parte del título de los temas de TREC para construir las consultas. Construimos G utilizando la suposición de dependencia secuencial para todos los conjuntos de datos [14]. 4.1 Resultados de recuperación ad-hoc Ahora investigamos qué tan bien se desempeña nuestro modelo en la práctica en un entorno de <br>retroalimentación de relevancia</br> pseudo. Comparamos el modelado de lenguaje unigrama (con suavizado de Dirichlet), el modelo MRF (sin expansión), los modelos de relevancia y LCE para comprender mejor cómo se desempeña cada modelo en los diferentes conjuntos de datos. Para el modelo de lenguaje unigrama, se entrenó el parámetro de suavizado. Para el modelo MRF, entrenamos los parámetros del modelo (es decir, y hiperparámetros del modelo (es decir, α, β). Para RM3 y LCE, también entrenamos el número de pseudoNombre Descripción # Docs Temas de Entrenamiento Temas de Prueba WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc. Presione 88-90 242,918 51-150 151-200 ROBUST Robust 2004 datos 528,155 301-450 601-700 WT10g Colección Web de TREC 1,692,096 451-500 501-550 GOV2 Rastreo 2004 del dominio .gov 25,205,179 701-750 751-800 Tabla 2: Resumen de las colecciones y temas de TREC. documentos de retroalimentación relevantes utilizados y el número de términos de expansión. 4.1.1 Expansión con Conceptos de Términos Únicos Comenzamos evaluando qué tan bien funciona nuestro modelo al expandir utilizando solo términos individuales. Antes de describir y analizar los resultados, declaramos explícitamente cómo se calculan las probabilidades de términos de expansión bajo esta configuración (es decir, utilizando la suposición de dependencia secuencial, expandiendo con conceptos de un solo término y utilizando nuestro conjunto de características). Las probabilidades de términos de expansión se calculan de la siguiente manera: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) donde b ∈ Q denota el conjunto de bigramas en Q. Esta ecuación muestra claramente cómo LCE difiere de los modelos de relevancia. Cuando establecemos λTD = λT,D = 1 y todos los demás parámetros en 0, obtenemos la fórmula exacta que se utiliza para calcular las probabilidades de términos en el marco de modelado de relevancia. Por lo tanto, LCE añade dos factores muy importantes a la ecuación. Primero, agrega las características de ventana ordenadas y no ordenadas que se aplican a la consulta original. En segundo lugar, aplica una forma intuitiva similar a tf.idf al término de expansión candidato w. El factor idf, que no está presente en los modelos de relevancia, juega un papel importante en la selección del término de expansión. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figura 2: Histogramas que demuestran y comparan la robustez de los modelos de relevancia (RM3) y la expansión de conceptos latentes (LCE) con respecto al modelo de probabilidad de consulta (QL) para los conjuntos de datos AP, ROBUST y WT10G. Los resultados, evaluados utilizando la precisión promedio media, se muestran en la Tabla 3. Como vemos, el modelo MRF, los modelos de relevancia y LCE siempre superan significativamente al modelo de lenguaje unigrama. Además, LCE muestra mejoras significativas sobre los modelos de relevancia en todos los conjuntos de datos. Las mejoras relativas sobre los modelos de relevancia son del 6.9% para AP, 12.9% para WSJ, 6.5% para ROBUST, 16.7% para WT10G y 7.3% para GOV2. Además, LCE muestra pequeñas mejoras, pero no significativas, respecto al modelado de relevancia para métricas como precisión en 5, 10 y 20. Sin embargo, tanto el modelado de relevancia como el LCE muestran mejoras estadísticamente significativas en dichas métricas sobre el modelo de lenguaje unigrama. Otro resultado interesante es que el modelo MRF es estadísticamente equivalente a los modelos de relevancia en los dos conjuntos de datos web. De hecho, el modelo MRF supera a los modelos de relevancia en el conjunto de datos WT10g. Esto reitera la importancia de las características no unigrama, basadas en la proximidad para la búsqueda web basada en contenido observada previamente [14, 16]. Aunque nuestro modelo tiene más parámetros libres que los modelos de relevancia, sorprendentemente hay poco sobreajuste. En cambio, el modelo muestra buenas propiedades de generalización. 4.1.2 Expansión con Conceptos de Múltiples Términos También investigamos la expansión utilizando conceptos de una y dos palabras. Para cada consulta, expandimos utilizando un conjunto de conceptos de un solo término y un conjunto de conceptos de dos términos. Los conjuntos fueron elegidos de forma independiente. Desafortunadamente, solo se observaron aumentos insignificantes en la precisión promedio. Este resultado puede deberse al hecho de que existen fuertes correlaciones entre los conceptos de expansión de términos individuales. Descubrimos que los dos conceptos de palabras elegidos a menudo consistían en dos términos altamente correlacionados que también son elegidos como conceptos de términos individuales. Por ejemplo, se eligió el concepto de dos términos mercado de valores, mientras que también se eligieron los conceptos de un solo término acciones y mercado. Por lo tanto, muchos conceptos de dos palabras es poco probable que aumenten el poder discriminativo de la consulta ampliada. Este resultado sugiere que los conceptos deben ser elegidos de acuerdo con ciertos criterios que también tengan en cuenta la novedad, la diversidad o las correlaciones de términos. Otro problema potencial es el conjunto de características utilizado. Otros conjuntos de características pueden dar resultados diferentes en última instancia, especialmente si reducen la correlación entre los conceptos de expansión. Por lo tanto, nuestros experimentos no arrojan resultados concluyentes en cuanto a la expansión utilizando conceptos de varios términos. En cambio, los resultados plantean preguntas abiertas interesantes y direcciones para futuras exploraciones. Tabla 3: Promedio de precisión media en el conjunto de pruebas para modelado de lenguaje (LM), campo aleatorio de Markov (MRF), modelos de relevancia (RM3) y expansión de conceptos latentes (LCE). Los superíndices α, β y γ indican mejoras estadísticamente significativas (p < 0.05) sobre LM, MRF y RM3, respectivamente. 4.2 Robustez Como hemos demostrado, los modelos de relevancia y la expansión de conceptos latentes pueden mejorar significativamente la efectividad de recuperación sobre el modelo de probabilidad de consulta base. En esta sección analizamos la robustez de estos dos métodos. Aquí definimos la robustez como el número de consultas cuya efectividad se ve mejorada/afectada (y en qué medida) como resultado de aplicar estos métodos. Una técnica de expansión altamente robusta mejorará significativamente muchas consultas y solo perjudicará mínimamente a unas pocas. La Figura 2 proporciona un análisis de la robustez del modelado de relevancia y la expansión de conceptos latentes para los conjuntos de datos AP, ROBUST y WT10G. El análisis de los dos conjuntos de datos no mostrados es similar. Los histogramas proporcionan, para varios rangos de disminuciones/aumentos relativos en la precisión media promedio, el número de consultas que se vieron perjudicadas/mejoradas con respecto a la línea base de probabilidad de consulta. Como muestran los resultados, LCE muestra una fuerte robustez para cada conjunto de datos. Para AP, los modelos de relevancia mejoran 38 consultas y perjudican 11, mientras que LCE mejora 35 y perjudica 14. Aunque los modelos de relevancia mejoran la efectividad de 3 consultas más que LCE, la mejora relativa exhibida por LCE es significativamente mayor. Para el conjunto de datos ROBUST, los modelos de relevancia mejoran 67 consultas y perjudican 32, y LCE mejora 77 y perjudica 22. Finalmente, para la colección WT10G, los modelos de relevancia mejoran 32 consultas y perjudican 16, y LCE mejora 35 y perjudica 14. Al igual que con AP, la cantidad de mejora exhibida por el LCE frente a los modelos de relevancia es significativamente mayor tanto para los conjuntos de datos ROBUST como WT10G. Además, cuando LCE afecta al rendimiento, es menos probable que afecte tanto como el modelado de relevancia, lo cual es una propiedad deseable. En general, LCE mejora la efectividad para el 65%-80% de las consultas, dependiendo del conjunto de datos. Cuando se utiliza en combinación con un sistema de predicción de rendimiento de consulta altamente preciso, puede ser posible expandir selectivamente las consultas y minimizar la pérdida asociada con el rendimiento sub-baseline. 4.3 Generación de Conceptos de Múltiples Términos Aunque encontramos que la expansión utilizando conceptos de múltiples términos no logró producir mejoras concluyentes en la efectividad, hay otras tareas potenciales para las cuales estos conceptos pueden ser útiles, como sugerencia/reformulación de consultas, resumen y extracción de conceptos. Por ejemplo, para una tarea de sugerencia de consultas, la consulta original podría usarse para generar un conjunto de conceptos latentes que corresponden a formulaciones alternativas de la consulta. Aunque evaluar nuestro modelo en estas tareas está fuera del alcance de este trabajo, deseamos mostrar un ejemplo ilustrativo de los tipos de conceptos generados utilizando nuestro modelo. En la Tabla 4, presentamos los conceptos de una, dos y tres palabras más probables generados utilizando LCE para la consulta logros del telescopio Hubble utilizando los 25 documentos mejor clasificados de la colección ROBUST. Es bien sabido que generar conceptos de múltiples términos utilizando un modelo basado en unigramas produce resultados insatisfactorios, ya que no considera las dependencias entre los términos. Esto no es el caso al generar conceptos de múltiples términos usando nuestro modelo. En cambio, la mayoría de los conceptos generados son bien formados y significativos. Hay varios casos donde los conceptos son menos coherentes, como espejo espejo espejo. En este caso, la probabilidad de que aparezca el término \"espejo\" en un documento pseudo-relevante supera a las características de modelado de lenguaje (por ejemplo, fOQ), lo que provoca que este concepto no coherente tenga una alta probabilidad. Tales ejemplos son minoría, sin embargo. No solo los conceptos generados son bien formados y significativos, sino que también son relevantes al tema de la consulta original. Como podemos ver, todos los conceptos generados están relacionados con el tema y de alguna manera están relacionados con el telescopio Hubble. Es interesante ver que el concepto de fallo del telescopio Hubble es uno de los tres conceptos de términos más probables, dado que es algo contradictorio con la consulta original. A pesar de esta contradicción, es probable que los documentos que discuten las fallas del telescopio también describan los éxitos, por lo tanto, es probable que este sea un concepto significativo. Una cosa importante a tener en cuenta es que los conceptos generados por LCE son de una naturaleza diferente a los que se generarían utilizando un modelo de relevancia de bigrama. Por ejemplo, un modelo de bigrama sería poco probable que genere el concepto telescopio espacio NASA, ya que ninguno de los bigramas que componen el concepto tiene una alta probabilidad. Sin embargo, dado que nuestro modelo se basa en una serie de características diferentes sobre varios tipos de cliques, es más general y robusto que un modelo de bigrama. Aunque solo proporcionamos los conceptos generados para una sola consulta, señalamos que el mismo análisis y conclusiones se generalizan a través de otros conjuntos de datos, con conceptos coherentes y relacionados temáticamente generados de manera consistente utilizando LCE. 4.4 Discusión Nuestra técnica de expansión de conceptos latentes captura dos tipos de dependencia semiortogonales. En la recuperación de información, ha existido un interés a largo plazo en comprender el papel de la dependencia de términos. De esta investigación, se han identificado dos tipos generales de dependencias. El primer tipo de dependencia es la dependencia sintáctica. Este tipo de dependencia abarca frases, proximidad de términos y co-ocurrencia de términos [2, 4, 5, 7, 26]. Estos métodos capturan el hecho de que las consultas imponen implícita o explícitamente un cierto conjunto de dependencias posicionales. El segundo tipo es la dependencia semántica. Ejemplos de dependencia semántica son la retroalimentación de relevancia, la retroalimentación de pseudo-relevancia, sinónimos y en cierta medida el truncamiento [3]. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "pseudo-relevance feedback": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of <br>pseudo-relevance feedback</br> or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and <br>pseudo-relevance feedback</br> setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a <br>pseudo-relevance feedback</br> setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, <br>pseudo-relevance feedback</br>, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of <br>pseudo-relevance feedback</br> or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and <br>pseudo-relevance feedback</br> setting [12, 21, 28, 29].",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a <br>pseudo-relevance feedback</br> setting.",
                "Examples of semantic dependence are relevance feedback, <br>pseudo-relevance feedback</br>, synonyms, and to some extent stemming [3]."
            ],
            "translated_annotated_samples": [
                "Expansión de conceptos latentes utilizando campos aleatorios de Markov. Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Centro de Recuperación de Información Inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 RESUMEN La expansión de consultas, en forma de <br>retroalimentación de pseudo relevancia</br> o retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación.",
                "Las técnicas de expansión de consultas han sido ampliamente estudiadas para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la retroalimentación de <br>pseudo-relevancia</br> [12, 21, 28, 29].",
                "Construimos G utilizando la suposición de dependencia secuencial para todos los conjuntos de datos [14]. 4.1 Resultados de recuperación ad-hoc Ahora investigamos qué tan bien se desempeña nuestro modelo en la práctica en un entorno de <br>retroalimentación de relevancia pseudo</br>.",
                "Ejemplos de dependencia semántica son la retroalimentación de relevancia, la <br>retroalimentación de pseudo-relevancia</br>, sinónimos y en cierta medida el truncamiento [3]."
            ],
            "translated_text": "Expansión de conceptos latentes utilizando campos aleatorios de Markov. Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Centro de Recuperación de Información Inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 RESUMEN La expansión de consultas, en forma de <br>retroalimentación de pseudo relevancia</br> o retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación. La mayoría de enfoques anteriores han ignorado problemas importantes, como el papel de las características y la importancia de modelar las dependencias entre términos. En este artículo, proponemos una técnica robusta de expansión de consultas basada en el modelo de campo aleatorio de Markov para la recuperación de información. La técnica, llamada expansión de conceptos latentes, proporciona un mecanismo para modelar las dependencias de términos durante la expansión. Además, el uso de características arbitrarias dentro del modelo proporciona un marco poderoso para ir más allá de las simples características de ocurrencia de términos que son utilizadas implícitamente por la mayoría de las otras técnicas de expansión. Evaluamos nuestra técnica frente a modelos de relevancia, una técnica de expansión de consultas de modelado de lenguaje de última generación. Nuestro modelo demuestra mejoras consistentes y significativas en la efectividad de recuperación en varios conjuntos de datos de TREC. También describimos cómo nuestra técnica puede ser utilizada para generar conceptos significativos de varios términos para tareas como sugerencia/reformulación de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales Algoritmos, Experimentación, Teoría 1. Los usuarios de los sistemas de recuperación de información deben expresar necesidades de información complejas en términos de expresiones booleanas, una lista corta de palabras clave, una oración, una pregunta o posiblemente un relato más extenso. Se pierde mucha información durante el proceso de traducción desde la necesidad de información hasta la consulta real. Por esta razón, ha habido un fuerte interés en las técnicas de expansión de consultas. Tales técnicas se utilizan para ampliar la consulta original y producir una representación que refleje mejor la necesidad de información subyacente. Las técnicas de expansión de consultas han sido ampliamente estudiadas para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la retroalimentación de <br>pseudo-relevancia</br> [12, 21, 28, 29]. Recientemente, se propuso un modelo de campo aleatorio de Markov (MRF) para la recuperación de información que va más allá de la simplista suposición de bolsa de palabras que subyace en BM25 y en el enfoque de modelado de lenguaje (unigrama) para la recuperación de información [20, 22]. El modelo MRF generaliza los modelos de unigrama, bigrama y otras diversas dependencias [14]. La mayoría de los modelos de dependencia de términos pasados no han logrado mostrar mejoras consistentes y significativas sobre las líneas de base de unigramas, con pocas excepciones [8]. El modelo MRF, sin embargo, ha demostrado ser altamente efectivo en una serie de tareas, incluyendo la recuperación ad hoc [14, 16], la búsqueda de páginas con nombres [16] y la búsqueda web en japonés [6]. Hasta ahora, el modelo ha sido utilizado únicamente para clasificar documentos en respuesta a una consulta dada. En este trabajo, mostramos cómo el modelo puede ser ampliado y utilizado para la expansión de consultas utilizando una técnica que llamamos expansión de conceptos latentes (LCE). Hay tres contribuciones principales de nuestro trabajo. Primero, LCE proporciona un mecanismo para combinar la dependencia de términos con la expansión de consultas. Las técnicas de expansión de consultas anteriores se basan en modelos de bolsa de palabras. Por lo tanto, al realizar la expansión de consultas utilizando el modelo MRF, podemos estudiar la dinámica entre la dependencia de términos y la expansión de consultas. A continuación, como mostraremos, el modelo MRF permite que se utilicen características arbitrarias dentro del modelo. Las técnicas de expansión de consultas en el pasado solo han hecho uso implícito de características de ocurrencia de términos. Al utilizar conjuntos de características más robustos, es posible producir términos de expansión mejores que discriminan de manera más efectiva entre documentos relevantes y no relevantes. Finalmente, nuestro enfoque propuesto proporciona de manera fluida un mecanismo para generar conceptos de una sola y múltiples términos. La mayoría de las técnicas anteriores, por defecto, generan términos de forma independiente. Ha habido varios enfoques que hacen uso de conceptos generalizados, sin embargo, dichos enfoques fueron algo heurísticos y realizados fuera del modelo [19, 28]. Nuestro enfoque está motivado tanto formalmente como es una extensión natural del modelo subyacente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2 describimos enfoques relacionados de expansión de consultas. La sección 3 proporciona una visión general del modelo MRF y detalla nuestra técnica propuesta de expansión de conceptos latentes. En la Sección 4 evaluamos nuestro modelo propuesto y analizamos los resultados. Finalmente, la Sección 5 concluye el artículo y resume los principales resultados. 2. TRABAJO RELACIONADO Uno de los enfoques clásicos y más ampliamente utilizados para la expansión de consultas es el algoritmo de Rocchio [21]. El enfoque de Rocchio, que fue desarrollado dentro del modelo de espacio vectorial, reajusta el vector de consulta original moviendo los pesos hacia el conjunto de documentos relevantes o pseudo-relevantes y alejándolos de los documentos no relevantes. Desafortunadamente, no es posible aplicar formalmente el enfoque de Rocchio a un modelo de recuperación estadística, como el modelado del lenguaje para la recuperación de información. Se han desarrollado varias técnicas de expansión de consultas formalizadas para el marco de modelado de lenguaje, incluyendo el feedback basado en el modelo de Zhai y Lafferty y los modelos de relevancia de Lavrenko y Crofts [12, 29]. Ambos enfoques intentan utilizar documentos pseudo-relevantes o relevantes para estimar un modelo de consulta mejor. El feedback basado en modelos encuentra el modelo que mejor describe los documentos relevantes teniendo en cuenta un modelo de fondo (ruido). Esto separa el modelo de contenido del modelo de fondo. El modelo de contenido se interpola con el modelo de consulta original para formar la consulta ampliada. La otra técnica, modelos de relevancia, está más relacionada con nuestro trabajo. Por lo tanto, entramos en los detalles del modelo. Al igual que el feedback basado en modelos, los modelos de relevancia estiman un modelo de consulta mejorado. La única diferencia entre los dos enfoques es que los modelos de relevancia no modelan explícitamente los documentos relevantes o pseudo-relevantes. En cambio, ellos modelan una noción más generalizada de relevancia, como mostraremos ahora. Dada una consulta Q, un modelo de relevancia es una distribución multinomial, P(·|Q), que codifica la probabilidad de cada término dado la consulta como evidencia. Se calcula como: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) donde RQ es el conjunto de documentos que son relevantes o pseudo relevantes para la consulta Q. En el caso pseudo-relevante, estos son los documentos mejor clasificados para la consulta Q. Además, se asume que P(D) es uniforme en este conjunto. Estas suposiciones suaves hacen que el cálculo del posterior bayesiano sea más práctico. Después de que el modelo es estimado, los documentos son clasificados por recortar el modelo de relevancia al elegir los k términos más probables de P(·|Q). Esta distribución recortada se interpola luego con el modelo de consulta de máxima verosimilitud original. Esto se puede considerar como la expansión de la consulta original por k términos ponderados. A lo largo del resto de este trabajo, nos referimos a esta instancia de modelos de relevancia como RM3. Ha habido relativamente poco trabajo realizado en el área de expansión de consultas en el contexto de modelos de dependencia [9]. Sin embargo, ha habido varios intentos de expandir utilizando conceptos de varios términos. El método de análisis de contexto local (LCA) de Xu y Crofts combinaba la recuperación a nivel de pasaje con la expansión de conceptos, donde los conceptos eran términos y frases simples [28]. Los conceptos de expansión fueron elegidos y ponderados utilizando una métrica basada en estadísticas de co-ocurrencia. Sin embargo, no está claro, basándose en el análisis realizado, cuánto ayudaron las frases en comparación con los términos individuales solos. Papka y Allan investigan el uso de retroalimentación de relevancia para realizar la expansión de conceptos de varios términos en el enrutamiento de documentos [19]. Los conceptos utilizados en su trabajo son más generales que los utilizados en el LCA e incluyen estructuras de lenguaje de consulta InQuery, como #UW50(casa blanca), que corresponde al concepto en el que los términos casa y blanca ocurren, en cualquier orden, dentro de 50 términos uno del otro. Los resultados mostraron que combinar conceptos de un solo término y conceptos de varios términos con una ventana grande mejoró significativamente la efectividad. Sin embargo, no está claro si el mismo enfoque también es efectivo para la recuperación ad hoc, debido a las diferencias en las tareas. 3. Este apartado detalla nuestra técnica propuesta de expansión de conceptos latentes. Como se mencionó anteriormente, la técnica es una extensión del modelo MRF para la recuperación de información [14]. Por lo tanto, comenzamos proporcionando una visión general del modelo MRF y nuestras extensiones propuestas. 3.1 MRFs para IR 3.1.1 Conceptos básicos Los campos aleatorios de Markov, que son modelos gráficos no dirigidos, proporcionan una forma compacta y robusta de modelar una distribución conjunta. Aquí estamos interesados en modelar la distribución conjunta sobre una consulta Q = q1, . . . , qn y un documento D. Se asume que la distribución subyacente sobre pares de documentos y consultas es una distribución de relevancia. Es decir, muestrear de la distribución proporciona pares de documentos y consultas, de modo que el documento sea relevante para la consulta. Un MRF se define por un grafo G y un conjunto de funciones de potencial no negativas sobre los cliques en G. Los nodos en el grafo representan las variables aleatorias y las aristas definen la semántica de independencia de la distribución. Un MRF cumple con la propiedad de Markov, la cual establece que un nodo es independiente de todos sus nodos no vecinos dado los valores observados de sus vecinos. Dado un grafo G, un conjunto de potenciales ψi y un vector de parámetros Λ, la distribución conjunta sobre Q y D está dada por: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) donde Z es una constante de normalización. Seguimos la convención común y parametrizamos los potenciales como ψi(c; Λ) = exp[λifi(c)], donde fi(c) es una función de características de valores reales. 3.1.2 Construcción de G Dada una consulta Q, el grafo G puede ser construido de varias maneras. Sin embargo, siguiendo el trabajo previo, consideramos tres variantes simples [14]. Estas variantes son independencia total, donde cada término de consulta es independiente de los demás dado un documento, dependencia secuencial, que asume que existe una dependencia entre los términos de consulta adyacentes, y dependencia total, que no hace suposiciones de independencia. 3.1.3 Parametrización Los MRFs suelen ser parametrizados comúnmente en función de los cliques máximos de G. Sin embargo, dicha parametrización es demasiado gruesa para nuestras necesidades. Necesitamos una parametrización que nos permita asociar funciones de características con cliques a un nivel más detallado, manteniendo al mismo tiempo el número de características, y por lo tanto el número de parámetros, razonable. Por lo tanto, permitimos que los grupos compartan funciones de características y parámetros basados en conjuntos de grupos. Es decir, todos los subgrupos dentro de un conjunto de subgrupos están asociados con la misma función de característica y comparten un solo parámetro. Esto une de manera efectiva los parámetros de las características asociadas con cada conjunto, lo que reduce significativamente el número de parámetros mientras aún proporciona un mecanismo para el ajuste fino en el nivel de conjuntos de cliques. Proponemos siete conjuntos de cliques para utilizar en la recuperación de información. Los primeros tres conjuntos de cliques consisten en cliques que contienen uno o más términos de consulta y el nodo del documento. Las características sobre estos grupos deberían codificar qué tan bien los términos en la configuración del grupo describen el documento. Estos conjuntos son: • TD - conjunto de cliques que contienen el nodo del documento y exactamente un término de consulta. • OD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en orden secuencial dentro de la consulta. • UD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en cualquier orden dentro de la consulta. Ten en cuenta que UD es un superconjunto de OD. Al atar los parámetros entre los grupos dentro de cada conjunto podemos controlar cuánta influencia recibe cada tipo. Esto también evita el problema de tratar de determinar cómo estimar los pesos para cada clique dentro de los conjuntos. En cambio, ahora solo debemos estimar un parámetro por conjunto. A continuación, consideramos cliques que solo contienen nodos de términos de consulta. Estas cliques, que no fueron consideradas en [14], se definen de manera análoga a las recién definidas, excepto que las cliques solo están formadas por nodos de términos de consulta y no contienen el nodo de documento. Las funciones de características sobre estos conjuntos deben capturar qué tan compatibles son entre sí los términos de consulta. Estas características de grupo pueden adoptar la forma de modelos de lenguaje que imponen la corrección de los términos. Por lo tanto, definimos los siguientes conjuntos de cliques dependientes de la consulta: • TQ - conjunto de cliques que contienen exactamente un término de la consulta. • OQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en orden secuencial dentro de la consulta. • UQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en cualquier orden dentro de la consulta. Finalmente, está la clique que solo contiene el nodo del documento. Las características sobre este nodo pueden ser utilizadas como un tipo de documento previo, codificando propiedades centradas en el documento. Este conjunto de cliques trivial es entonces: • D - conjunto de cliques que contiene solo el nodo único D. Observamos que nuestros conjuntos de cliques forman una cobertura de conjuntos sobre los cliques de G, pero no son una partición, ya que algunos cliques aparecen en múltiples conjuntos de cliques. Después de atar los parámetros en nuestros conjuntos de cliques y usar la forma de la función potencial exponencial, terminamos con la siguiente forma simplificada de la distribución conjunta: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - dependiente del documento y la consulta + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - dependiente de la consulta + λDfD(D) FD(D) - dependiente del documento − log ZΛ documento + independiente de la consulta donde FDQ, FQ y FD son funciones de conveniencia definidas por los componentes dependientes del documento y la consulta, dependientes de la consulta y dependientes del documento de la distribución conjunta, respectivamente. Estos se utilizarán para simplificar y clarificar las expresiones derivadas a lo largo del resto del documento. 3.1.4 Características Cualquier función de característica arbitraria sobre configuraciones de cliques puede ser utilizada en el modelo. La elección correcta de las características depende en gran medida de la tarea de recuperación y la métrica de evaluación. Por lo tanto, es probable que no exista un conjunto único y universalmente aplicable de características. Para dar una idea de la variedad de características que se pueden utilizar, ahora describimos brevemente posibles tipos de características que podrían ser utilizadas. Posibles características dependientes del término de consulta incluyen tf, idf, entidades nombradas, proximidad de términos y estilo de texto, por nombrar algunas. Se pueden utilizar muchos tipos de características dependientes del documento, como la longitud del documento, el PageRank, la legibilidad y el género, entre otros. Dado que nuestro objetivo aquí no es encontrar características óptimas, utilizamos un conjunto simple y fijo de características que han demostrado ser efectivas en trabajos anteriores [14]. Consulte la Tabla 1 para ver la lista de características utilizadas. Estas características intentan capturar la ocurrencia de términos y la proximidad entre términos. Una mejor selección de características en el futuro probablemente conducirá a una mayor efectividad. 3.1.5 Clasificación Dada una consulta Q, deseamos clasificar los documentos en orden descendente según PG,Λ(D|Q). Después de eliminar las expresiones independientes del documento del registro PG,Λ(Q, D), derivamos la siguiente función de clasificación: PG,Λ(D|Q) rango = FDQ(D, Q) + FD(D) (2), que es una simple combinación lineal ponderada de funciones de características que pueden calcularse eficientemente para grafos razonables. 3.1.6 Estimación de Parámetros Ahora que el modelo ha sido completamente especificado, el paso final es estimar los parámetros del modelo. Aunque los MRF son modelos generativos, no es apropiado entrenarlos utilizando la función de valor de características fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Tabla 1: Funciones de características utilizadas en el modelo de campo aleatorio de Markov. Aquí, tfw,D es el número de veces que el término w ocurre en el documento D, tf#1(qi...qi+k),D denota el número de veces que la frase exacta qi . . . qi+k ocurre en el documento D, tf#uw(qi...qj ),D es el número de veces que los términos qi, . . . qj aparecen ordenados o desordenados dentro de una ventana de N términos, y |D| es la longitud del documento D. Los valores de cf y |C| se definen de manera análoga a nivel de colección. Finalmente, α y β son hiperparámetros del modelo que controlan el suavizado para las características de términos únicos y frases, respectivamente. Enfoques convencionales basados en la verosimilitud debido a la divergencia métrica [17]. Es decir, es poco probable que la estimación de máxima verosimilitud sea la estimación que maximiza nuestra métrica de evaluación. Por esta razón, entrenamos de manera discriminativa nuestro modelo para maximizar directamente la métrica de evaluación considerada [14, 15, 25]. Dado que nuestro espacio de parámetros es pequeño, hacemos uso de una estrategia simple de escalada de colina, aunque son posibles otros enfoques más sofisticados [10]. 3.2 Expansión de Conceptos Latentes En esta sección describimos cómo este modelo MRF extendido puede ser utilizado de una manera novedosa para generar conceptos de un solo término y de varios términos que están relacionados temáticamente con alguna consulta original. Como mostraremos, los conceptos generados utilizando nuestra técnica pueden ser utilizados para la expansión de consultas u otras tareas, como sugerir formulaciones alternativas de consultas. Suponemos que cuando un usuario formula su consulta original, tiene en mente un conjunto de conceptos, pero solo puede expresar un pequeño número de ellos en forma de consulta. Tratamos los conceptos que el usuario tiene en mente, pero no expresó explícitamente en la consulta, como conceptos latentes. Estos conceptos latentes pueden consistir en un solo término, varios términos o alguna combinación de ambos. Por lo tanto, nuestro objetivo es recuperar estos conceptos latentes dada alguna consulta original. Esto se puede lograr dentro de nuestro marco de trabajo al expandir primero el grafo original G para incluir el tipo de concepto que nos interesa generar. Llamamos a este gráfico expandido H. En la Figura 1, el gráfico del medio proporciona un ejemplo de cómo construir un gráfico expandido que puede generar conceptos de un solo término. De manera similar, el gráfico de la derecha ilustra un gráfico ampliado que genera dos conceptos de términos. Aunque estos dos ejemplos hacen uso de la suposición de dependencia secuencial (es decir, dependencias entre términos de consulta adyacentes), es importante tener en cuenta que tanto la consulta original como los conceptos de expansión pueden utilizar cualquier estructura de independencia. Después de que H se construye, calculamos PH,Λ(E|Q), una distribución de probabilidad sobre conceptos latentes, de acuerdo a: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) donde R es el universo de todos los documentos posibles y E es un concepto latente que puede consistir en uno o más términos. Dado que no es práctico calcular esta suma, debemos aproximarla. Observamos que PH,Λ(Q, E, D) probablemente se concentra alrededor de aquellos documentos D que están altamente clasificados según la consulta Q. Por lo tanto, aproximamos PH,Λ(E|Q) sumando solo un pequeño subconjunto de documentos relevantes o pseudo-relevantes para la consulta Q. Esto se calcula de la siguiente manera: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) donde RQ es un conjunto de documentos relevantes o pseudo-relevantes para la consulta Q y todos los conjuntos de cliques se construyen utilizando H. Como vemos, la contribución de probabilidad para cada documento en RQ es una combinación de la puntuación original de la consulta para el documento (ver Ecuación 2), la puntuación del concepto E para el documento y la puntuación independiente del documento de E. Por lo tanto, esta ecuación puede interpretarse como la medida de qué tan bien Q y E explican los documentos mejor clasificados y la bondad de E, independientemente de los documentos. Para lograr la máxima robustez, utilizamos un conjunto diferente de parámetros para FQD(Q, D) y FQD(E, D), lo que nos permite ponderar de manera diferente las características de ventana ordenadas y no ordenadas para la consulta original y el concepto de expansión candidato. 3.2.1 Expansión de consulta Para utilizar este marco para la expansión de consultas, primero elegimos un grafo de expansión H que codifique la estructura de concepto latente en la que estamos interesados en expandir la consulta. Luego seleccionamos los k conceptos latentes con la mayor probabilidad dada por la Ecuación 3. Se construye un nuevo grafo G al aumentar el grafo original G con los k conceptos de expansión E1, . . . , Ek. Finalmente, los documentos se clasifican según PG ,Λ(D|Q, E1, . . . , Ek) utilizando la Ecuación 2. 3.2.2 Comparación con los Modelos de Relevancia. Al inspeccionar las Ecuaciones 1 y 3 se revela la estrecha conexión que existe entre LCE y los modelos de relevancia. Ambos modelos esencialmente calculan la probabilidad de un término (o concepto) de la misma manera. Es fácil ver que al igual que el modelo MRF puede ser visto como una generalización del modelado del lenguaje, también LCE puede ser visto como una generalización de los modelos de relevancia. Existen diferencias importantes entre los modelos de lenguaje MRFs/LCE y los modelos de lenguaje unigram/relevancia. Consulte la Figura 1 para ver las representaciones gráficas de ambos modelos. Los modelos de lenguaje unigrama y los modelos de relevancia se basan en la distribución multinomial. Esta suposición de distribución encasilla el modelo en la representación de bolsa de palabras y el uso implícito de características de ocurrencia de términos. Sin embargo, la distribución subyacente al modelo MRF nos permite ir más allá de ambas suposiciones, al modelar tanto las dependencias entre los términos de consulta como permitir el uso explícito de características arbitrarias. Ir más allá de la simplista suposición de la bolsa de palabras de esta manera resulta en un modelo general y robusto y, como mostramos en la siguiente sección, se traduce en mejoras significativas en la efectividad de recuperación. 4. RESULTADOS EXPERIMENTALES Para comprender mejor las fortalezas y debilidades de nuestra técnica, la evaluamos en una amplia gama de conjuntos de datos. La Tabla 2 proporciona un resumen de los conjuntos de datos de TREC considerados. Las colecciones WSJ, AP y ROBUST son más pequeñas y consisten enteramente de artículos de agencias de noticias, mientras que WT10g y GOV2 son colecciones web grandes. Para cada conjunto de datos, dividimos los temas disponibles en un conjunto de entrenamiento y otro de prueba, donde el conjunto de entrenamiento se utiliza únicamente para la estimación de parámetros y el conjunto de prueba se utiliza con fines de evaluación. Todos los experimentos se llevaron a cabo utilizando una versión modificada de Indri, que forma parte del Lemur Toolkit [18, 23]. Todas las colecciones fueron detenidas utilizando una lista estándar de 418 términos comunes y truncadas utilizando un truncador de Porter. En todos los casos, solo se utiliza la parte del título de los temas de TREC para construir las consultas. Construimos G utilizando la suposición de dependencia secuencial para todos los conjuntos de datos [14]. 4.1 Resultados de recuperación ad-hoc Ahora investigamos qué tan bien se desempeña nuestro modelo en la práctica en un entorno de <br>retroalimentación de relevancia pseudo</br>. Comparamos el modelado de lenguaje unigrama (con suavizado de Dirichlet), el modelo MRF (sin expansión), los modelos de relevancia y LCE para comprender mejor cómo se desempeña cada modelo en los diferentes conjuntos de datos. Para el modelo de lenguaje unigrama, se entrenó el parámetro de suavizado. Para el modelo MRF, entrenamos los parámetros del modelo (es decir, y hiperparámetros del modelo (es decir, α, β). Para RM3 y LCE, también entrenamos el número de pseudoNombre Descripción # Docs Temas de Entrenamiento Temas de Prueba WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc. Presione 88-90 242,918 51-150 151-200 ROBUST Robust 2004 datos 528,155 301-450 601-700 WT10g Colección Web de TREC 1,692,096 451-500 501-550 GOV2 Rastreo 2004 del dominio .gov 25,205,179 701-750 751-800 Tabla 2: Resumen de las colecciones y temas de TREC. documentos de retroalimentación relevantes utilizados y el número de términos de expansión. 4.1.1 Expansión con Conceptos de Términos Únicos Comenzamos evaluando qué tan bien funciona nuestro modelo al expandir utilizando solo términos individuales. Antes de describir y analizar los resultados, declaramos explícitamente cómo se calculan las probabilidades de términos de expansión bajo esta configuración (es decir, utilizando la suposición de dependencia secuencial, expandiendo con conceptos de un solo término y utilizando nuestro conjunto de características). Las probabilidades de términos de expansión se calculan de la siguiente manera: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) donde b ∈ Q denota el conjunto de bigramas en Q. Esta ecuación muestra claramente cómo LCE difiere de los modelos de relevancia. Cuando establecemos λTD = λT,D = 1 y todos los demás parámetros en 0, obtenemos la fórmula exacta que se utiliza para calcular las probabilidades de términos en el marco de modelado de relevancia. Por lo tanto, LCE añade dos factores muy importantes a la ecuación. Primero, agrega las características de ventana ordenadas y no ordenadas que se aplican a la consulta original. En segundo lugar, aplica una forma intuitiva similar a tf.idf al término de expansión candidato w. El factor idf, que no está presente en los modelos de relevancia, juega un papel importante en la selección del término de expansión. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figura 2: Histogramas que demuestran y comparan la robustez de los modelos de relevancia (RM3) y la expansión de conceptos latentes (LCE) con respecto al modelo de probabilidad de consulta (QL) para los conjuntos de datos AP, ROBUST y WT10G. Los resultados, evaluados utilizando la precisión promedio media, se muestran en la Tabla 3. Como vemos, el modelo MRF, los modelos de relevancia y LCE siempre superan significativamente al modelo de lenguaje unigrama. Además, LCE muestra mejoras significativas sobre los modelos de relevancia en todos los conjuntos de datos. Las mejoras relativas sobre los modelos de relevancia son del 6.9% para AP, 12.9% para WSJ, 6.5% para ROBUST, 16.7% para WT10G y 7.3% para GOV2. Además, LCE muestra pequeñas mejoras, pero no significativas, respecto al modelado de relevancia para métricas como precisión en 5, 10 y 20. Sin embargo, tanto el modelado de relevancia como el LCE muestran mejoras estadísticamente significativas en dichas métricas sobre el modelo de lenguaje unigrama. Otro resultado interesante es que el modelo MRF es estadísticamente equivalente a los modelos de relevancia en los dos conjuntos de datos web. De hecho, el modelo MRF supera a los modelos de relevancia en el conjunto de datos WT10g. Esto reitera la importancia de las características no unigrama, basadas en la proximidad para la búsqueda web basada en contenido observada previamente [14, 16]. Aunque nuestro modelo tiene más parámetros libres que los modelos de relevancia, sorprendentemente hay poco sobreajuste. En cambio, el modelo muestra buenas propiedades de generalización. 4.1.2 Expansión con Conceptos de Múltiples Términos También investigamos la expansión utilizando conceptos de una y dos palabras. Para cada consulta, expandimos utilizando un conjunto de conceptos de un solo término y un conjunto de conceptos de dos términos. Los conjuntos fueron elegidos de forma independiente. Desafortunadamente, solo se observaron aumentos insignificantes en la precisión promedio. Este resultado puede deberse al hecho de que existen fuertes correlaciones entre los conceptos de expansión de términos individuales. Descubrimos que los dos conceptos de palabras elegidos a menudo consistían en dos términos altamente correlacionados que también son elegidos como conceptos de términos individuales. Por ejemplo, se eligió el concepto de dos términos mercado de valores, mientras que también se eligieron los conceptos de un solo término acciones y mercado. Por lo tanto, muchos conceptos de dos palabras es poco probable que aumenten el poder discriminativo de la consulta ampliada. Este resultado sugiere que los conceptos deben ser elegidos de acuerdo con ciertos criterios que también tengan en cuenta la novedad, la diversidad o las correlaciones de términos. Otro problema potencial es el conjunto de características utilizado. Otros conjuntos de características pueden dar resultados diferentes en última instancia, especialmente si reducen la correlación entre los conceptos de expansión. Por lo tanto, nuestros experimentos no arrojan resultados concluyentes en cuanto a la expansión utilizando conceptos de varios términos. En cambio, los resultados plantean preguntas abiertas interesantes y direcciones para futuras exploraciones. Tabla 3: Promedio de precisión media en el conjunto de pruebas para modelado de lenguaje (LM), campo aleatorio de Markov (MRF), modelos de relevancia (RM3) y expansión de conceptos latentes (LCE). Los superíndices α, β y γ indican mejoras estadísticamente significativas (p < 0.05) sobre LM, MRF y RM3, respectivamente. 4.2 Robustez Como hemos demostrado, los modelos de relevancia y la expansión de conceptos latentes pueden mejorar significativamente la efectividad de recuperación sobre el modelo de probabilidad de consulta base. En esta sección analizamos la robustez de estos dos métodos. Aquí definimos la robustez como el número de consultas cuya efectividad se ve mejorada/afectada (y en qué medida) como resultado de aplicar estos métodos. Una técnica de expansión altamente robusta mejorará significativamente muchas consultas y solo perjudicará mínimamente a unas pocas. La Figura 2 proporciona un análisis de la robustez del modelado de relevancia y la expansión de conceptos latentes para los conjuntos de datos AP, ROBUST y WT10G. El análisis de los dos conjuntos de datos no mostrados es similar. Los histogramas proporcionan, para varios rangos de disminuciones/aumentos relativos en la precisión media promedio, el número de consultas que se vieron perjudicadas/mejoradas con respecto a la línea base de probabilidad de consulta. Como muestran los resultados, LCE muestra una fuerte robustez para cada conjunto de datos. Para AP, los modelos de relevancia mejoran 38 consultas y perjudican 11, mientras que LCE mejora 35 y perjudica 14. Aunque los modelos de relevancia mejoran la efectividad de 3 consultas más que LCE, la mejora relativa exhibida por LCE es significativamente mayor. Para el conjunto de datos ROBUST, los modelos de relevancia mejoran 67 consultas y perjudican 32, y LCE mejora 77 y perjudica 22. Finalmente, para la colección WT10G, los modelos de relevancia mejoran 32 consultas y perjudican 16, y LCE mejora 35 y perjudica 14. Al igual que con AP, la cantidad de mejora exhibida por el LCE frente a los modelos de relevancia es significativamente mayor tanto para los conjuntos de datos ROBUST como WT10G. Además, cuando LCE afecta al rendimiento, es menos probable que afecte tanto como el modelado de relevancia, lo cual es una propiedad deseable. En general, LCE mejora la efectividad para el 65%-80% de las consultas, dependiendo del conjunto de datos. Cuando se utiliza en combinación con un sistema de predicción de rendimiento de consulta altamente preciso, puede ser posible expandir selectivamente las consultas y minimizar la pérdida asociada con el rendimiento sub-baseline. 4.3 Generación de Conceptos de Múltiples Términos Aunque encontramos que la expansión utilizando conceptos de múltiples términos no logró producir mejoras concluyentes en la efectividad, hay otras tareas potenciales para las cuales estos conceptos pueden ser útiles, como sugerencia/reformulación de consultas, resumen y extracción de conceptos. Por ejemplo, para una tarea de sugerencia de consultas, la consulta original podría usarse para generar un conjunto de conceptos latentes que corresponden a formulaciones alternativas de la consulta. Aunque evaluar nuestro modelo en estas tareas está fuera del alcance de este trabajo, deseamos mostrar un ejemplo ilustrativo de los tipos de conceptos generados utilizando nuestro modelo. En la Tabla 4, presentamos los conceptos de una, dos y tres palabras más probables generados utilizando LCE para la consulta logros del telescopio Hubble utilizando los 25 documentos mejor clasificados de la colección ROBUST. Es bien sabido que generar conceptos de múltiples términos utilizando un modelo basado en unigramas produce resultados insatisfactorios, ya que no considera las dependencias entre los términos. Esto no es el caso al generar conceptos de múltiples términos usando nuestro modelo. En cambio, la mayoría de los conceptos generados son bien formados y significativos. Hay varios casos donde los conceptos son menos coherentes, como espejo espejo espejo. En este caso, la probabilidad de que aparezca el término \"espejo\" en un documento pseudo-relevante supera a las características de modelado de lenguaje (por ejemplo, fOQ), lo que provoca que este concepto no coherente tenga una alta probabilidad. Tales ejemplos son minoría, sin embargo. No solo los conceptos generados son bien formados y significativos, sino que también son relevantes al tema de la consulta original. Como podemos ver, todos los conceptos generados están relacionados con el tema y de alguna manera están relacionados con el telescopio Hubble. Es interesante ver que el concepto de fallo del telescopio Hubble es uno de los tres conceptos de términos más probables, dado que es algo contradictorio con la consulta original. A pesar de esta contradicción, es probable que los documentos que discuten las fallas del telescopio también describan los éxitos, por lo tanto, es probable que este sea un concepto significativo. Una cosa importante a tener en cuenta es que los conceptos generados por LCE son de una naturaleza diferente a los que se generarían utilizando un modelo de relevancia de bigrama. Por ejemplo, un modelo de bigrama sería poco probable que genere el concepto telescopio espacio NASA, ya que ninguno de los bigramas que componen el concepto tiene una alta probabilidad. Sin embargo, dado que nuestro modelo se basa en una serie de características diferentes sobre varios tipos de cliques, es más general y robusto que un modelo de bigrama. Aunque solo proporcionamos los conceptos generados para una sola consulta, señalamos que el mismo análisis y conclusiones se generalizan a través de otros conjuntos de datos, con conceptos coherentes y relacionados temáticamente generados de manera consistente utilizando LCE. 4.4 Discusión Nuestra técnica de expansión de conceptos latentes captura dos tipos de dependencia semiortogonales. En la recuperación de información, ha existido un interés a largo plazo en comprender el papel de la dependencia de términos. De esta investigación, se han identificado dos tipos generales de dependencias. El primer tipo de dependencia es la dependencia sintáctica. Este tipo de dependencia abarca frases, proximidad de términos y co-ocurrencia de términos [2, 4, 5, 7, 26]. Estos métodos capturan el hecho de que las consultas imponen implícita o explícitamente un cierto conjunto de dependencias posicionales. El segundo tipo es la dependencia semántica. Ejemplos de dependencia semántica son la retroalimentación de relevancia, la <br>retroalimentación de pseudo-relevancia</br>, sinónimos y en cierta medida el truncamiento [3]. Estas técnicas han sido exploradas tanto en el lado de la consulta como en el lado del documento. En el lado de la consulta, esto se suele hacer utilizando alguna forma de expansión de consulta, como modelos de relevancia o LCE. En el lado del documento, esto se hace como expansión de documentos o suavizado de documentos [11, 13, 24]. Aunque puede haber cierta superposición entre las dependencias sintácticas y semánticas, en su mayoría son ortogonales. Nuestro modelo utiliza ambos tipos de dependencias. El uso de características de frase y proximidad dentro del modelo captura dependencias sintácticas, mientras que LCE captura dependencias semánticas del lado de la consulta. Esto explica por qué la mejora inicial en la efectividad lograda al usar el modelo MRF no se pierde después de la expansión de consultas. Si los mismos tipos de dependencias fueran capturados tanto por dependencias sintácticas como semánticas, se esperaría que LCE funcionara aproximadamente igual de bien que los modelos de relevancia. Por lo tanto, al modelar ambos tipos de dependencias, observamos un efecto aditivo en lugar de un efecto absorbente. Una área interesante de trabajo futuro es determinar si modelar las dependencias semánticas del lado del documento puede aportar algo al modelo. Resultados previos que han combinado dependencias semánticas del lado de la consulta y del documento han mostrado resultados mixtos [13, 27]. 5. CONCLUSIONES En este artículo propusimos una técnica robusta de expansión de consultas llamada expansión de conceptos latentes. La técnica se demostró ser una extensión natural del modelo de campo aleatorio de Markov para la recuperación de información y una generalización de los modelos de relevancia. LCE es novedoso en el sentido de que realiza una expansión de un solo término o de varios términos dentro de un marco que permite el modelado de dependencias entre términos y el uso de características arbitrarias, mientras que trabajos anteriores se basaban en la suposición de la bolsa de palabras y características de ocurrencia de términos. Mostramos que la técnica puede ser utilizada para producir conceptos de expansión de varios términos de alta calidad, bien formados y relevantes desde el punto de vista temático. Los conceptos generados pueden ser utilizados en un módulo de sugerencia de consultas alternativas. También demostramos que el modelo es altamente efectivo. De hecho, logra mejoras significativas en la precisión promedio media en comparación con los modelos de relevancia en una selección de conjuntos de datos de TREC. También se demostró que el modelo MRF por sí solo, sin ninguna expansión de consulta, supera a los modelos de relevancia en grandes conjuntos de datos web. Esto reafirma observaciones previas de que modelar dependencias a través del uso de características de proximidad dentro del MRF tiene un mayor impacto en colecciones más grandes y ruidosas que en colecciones más pequeñas y bien comportadas. Finalmente, reiteramos la importancia de elegir términos de expansión que modelen la relevancia, en lugar de los documentos relevantes, y mostramos cómo LCE captura tanto las dependencias sintácticas como semánticas del lado de la consulta. El trabajo futuro se centrará en incorporar dependencias del lado del documento también. Agradecimientos Este trabajo fue apoyado en parte por el Centro de Recuperación de Información Inteligente, en parte por la subvención NSF #CNS-0454018, en parte por ARDA y la subvención NSF #CCF-0205575, y en parte por Microsoft Live Labs. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son responsabilidad del autor o los autores y no necesariamente reflejan las del patrocinador.  REFERENCIAS [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker y C. Wade. UMass en TREC 2004: Novedad y DIFICULTAD. En Actas en línea de la Conferencia de Recuperación de Información de 2004, 2004. [2] C. L. A. Clarke y G. V. Cormack. Recuperación y clasificación de la subcadena más corta. ACM Trans. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate to Spanish? Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson y J. Callan. Expansión de consultas utilizando modelos de caminata aleatoria. En Proc. 14th Intl. Conf. sobre Gestión de Información y Conocimiento, páginas 704-711, 2005. [4] W. B. Croft. Consultas booleanas y dependencias de términos en modelos de recuperación probabilística. Revista de la Sociedad Americana de Ciencia de la Información, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle y D. Lewis. El uso de frases y consultas estructuradas en la recuperación de información. En Proc. 14º Anu. Internacional. Conferencia ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 32-45, 1991. [6] K. Eguchi. Experimentos de expansión de consultas NTCIR-5 utilizando modelos de dependencia de términos. En Actas del Quinto Taller de Reunión NTCIR sobre Evaluación de Tecnologías de Acceso a la Información, páginas 494-501, 2005. [7] J. Fagan. Indexación automática de frases para la recuperación de documentos: Un examen de métodos sintácticos y no sintácticos. En el Proc. décimo anual. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 91-101, 1987. [8] J. Gao, J. Nie, G. Wu y G. Cao. Modelo de lenguaje de dependencia para recuperación de información. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 170-177, 2004. [9] D. Harper y C. J. van Rijsbergen. Una evaluación de la retroalimentación en la recuperación de documentos utilizando datos de co-ocurrencia. Revista de Documentación, 34(3):189-216, 1978. [10] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Proc. de la Conf. Internacional de Aprendizaje Automático, páginas 377-384, 2005. [11] O. Kurland y L. Lee. Estructura del corpus, modelos de lenguaje y recuperación de información ad-hoc. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 194-201, 2004. [12] V. Lavrenko y W. B. Croft. Modelos de lenguaje basados en relevancia. En Proc. 24º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 120-127, 2001. [13] X. Liu y W. B. Croft. Recuperación basada en clústeres utilizando modelos de lenguaje. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 186-193, 2004. [14] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias entre términos. En Proc. 28vo Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [15] D. Metzler y W. B. Croft. Modelos basados en características lineales para la recuperación de información. Recuperación de información, por aparecer, 2006. [16] D. Metzler, T. Strohman, Y. Zhou y W. B. Croft. Indri en la pista de terabyte en 2005. En Actas en línea de la Conferencia de Recuperación de Texto de 2005, 2005. [17] W. Morgan, W. Greiff y J. Henderson. Maximización directa de la precisión promedio mediante escalada de colina con una comparación con un enfoque de entropía máxima. Informe técnico, MITRE, 2004. [18] P. Ogilvie y J. P. Callan. Experimentos utilizando el kit de herramientas de lémures. En Proc. de la Conferencia de Recuperación de Texto, 2001. [19] R. Papka y J. Allan. Por qué las ventanas más grandes son mejores que las más pequeñas. Informe técnico, Universidad de Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu y M. Gatford. Okapi en trec-3. En Actas en línea de la Tercera Conferencia de Recuperación de Texto, páginas 109-126, 1995. [21] J. J. Rocchio. Retroalimentación de relevancia en la recuperación de información, páginas 313-323. Prentice-Hall, 1971. [22] F. Song y W. B. Croft. Un modelo de lenguaje general para la recuperación de información. En Proc. octava conferencia internacional sobre Gestión de la Información y el Conocimiento (CIKM 99), páginas 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle y W. B. Croft. Indri: Un motor de búsqueda basado en modelos de lenguaje para consultas complejas. En Actas de la Conferencia Internacional sobre Análisis de Inteligencia, 2004. [24] T. Tao, X. Wang, Q. Mei y C. Zhai. Recuperación de información del modelo de lenguaje con expansión de documentos. En Proc. de HLT/NAACL, páginas 407-414, 2006. [25] B. Taskar, C. Guestrin y D. Koller. Redes de Markov de margen máximo. En Proc. de Avances en Sistemas de Información Neural (NIPS 2003), 2003. [26] C. J. van Rijsbergen. Una base teórica para el uso de datos de coocurrencia en la recuperación de información. Revista de Documentación, 33(2):106-119, 1977. [27] X. Wei y W. B. Croft. Modelos de documentos basados en LDA para recuperación ad-hoc. En Proc. 29º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 178-185, 2006. [28] J. Xu y W. B. Croft. Mejorando la efectividad de la recuperación de información con análisis de contexto local. ACM Trans. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate into Spanish? Syst., 18(1):79-112, 2000. [29] C. Zhai y J. Lafferty. Retroalimentación basada en modelos en el enfoque de modelado del lenguaje para la recuperación de información. En Proc. 10th Intl. Conferencia sobre Gestión de la Información y el Conocimiento, páginas 403-410, 2001. ",
            "candidates": [],
            "error": [
                [
                    "retroalimentación de pseudo relevancia",
                    "pseudo-relevancia",
                    "retroalimentación de relevancia pseudo",
                    "retroalimentación de pseudo-relevancia"
                ]
            ]
        },
        "information retrieval": {
            "translated_key": "recuperación de información",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent <br>information retrieval</br> Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for <br>information retrieval</br>.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of <br>information retrieval</br> systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for <br>information retrieval</br> was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to <br>information retrieval</br> [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for <br>information retrieval</br>.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for <br>information retrieval</br> [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with <br>information retrieval</br>.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In <br>information retrieval</br>, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for <br>information retrieval</br> and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent <br>information retrieval</br>, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in <br>information retrieval</br>.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in <br>information retrieval</br>, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in <br>information retrieval</br>, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for <br>information retrieval</br>.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in <br>information retrieval</br>, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc <br>information retrieval</br>.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in <br>information retrieval</br>, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in <br>information retrieval</br>, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in <br>information retrieval</br>, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in <br>information retrieval</br>, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for <br>information retrieval</br>.",
                "<br>information retrieval</br>, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in <br>information retrieval</br>, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for <br>information retrieval</br>.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model <br>information retrieval</br> with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in <br>information retrieval</br>.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in <br>information retrieval</br>, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of <br>information retrieval</br> with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to <br>information retrieval</br>.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent <br>information retrieval</br> Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for <br>information retrieval</br>.",
                "INTRODUCTION Users of <br>information retrieval</br> systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "Recently, a Markov random field (MRF) model for <br>information retrieval</br> was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to <br>information retrieval</br> [20, 22].",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for <br>information retrieval</br>."
            ],
            "translated_annotated_samples": [
                "Expansión de conceptos latentes utilizando campos aleatorios de Markov. Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Centro de Recuperación de Información Inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 RESUMEN La expansión de consultas, en forma de retroalimentación de pseudo relevancia o retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación.",
                "En este artículo, proponemos una técnica robusta de expansión de consultas basada en el modelo de campo aleatorio de Markov para la <br>recuperación de información</br>.",
                "Los usuarios de los sistemas de <br>recuperación de información</br> deben expresar necesidades de información complejas en términos de expresiones booleanas, una lista corta de palabras clave, una oración, una pregunta o posiblemente un relato más extenso.",
                "Recientemente, se propuso un modelo de campo aleatorio de Markov (MRF) para la <br>recuperación de información</br> que va más allá de la simplista suposición de bolsa de palabras que subyace en BM25 y en el enfoque de modelado de lenguaje (unigrama) para la <br>recuperación de información</br> [20, 22].",
                "Desafortunadamente, no es posible aplicar formalmente el enfoque de Rocchio a un modelo de recuperación estadística, como el modelado del lenguaje para la <br>recuperación de información</br>."
            ],
            "translated_text": "Expansión de conceptos latentes utilizando campos aleatorios de Markov. Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Centro de Recuperación de Información Inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 RESUMEN La expansión de consultas, en forma de retroalimentación de pseudo relevancia o retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación. La mayoría de enfoques anteriores han ignorado problemas importantes, como el papel de las características y la importancia de modelar las dependencias entre términos. En este artículo, proponemos una técnica robusta de expansión de consultas basada en el modelo de campo aleatorio de Markov para la <br>recuperación de información</br>. La técnica, llamada expansión de conceptos latentes, proporciona un mecanismo para modelar las dependencias de términos durante la expansión. Además, el uso de características arbitrarias dentro del modelo proporciona un marco poderoso para ir más allá de las simples características de ocurrencia de términos que son utilizadas implícitamente por la mayoría de las otras técnicas de expansión. Evaluamos nuestra técnica frente a modelos de relevancia, una técnica de expansión de consultas de modelado de lenguaje de última generación. Nuestro modelo demuestra mejoras consistentes y significativas en la efectividad de recuperación en varios conjuntos de datos de TREC. También describimos cómo nuestra técnica puede ser utilizada para generar conceptos significativos de varios términos para tareas como sugerencia/reformulación de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales Algoritmos, Experimentación, Teoría 1. Los usuarios de los sistemas de <br>recuperación de información</br> deben expresar necesidades de información complejas en términos de expresiones booleanas, una lista corta de palabras clave, una oración, una pregunta o posiblemente un relato más extenso. Se pierde mucha información durante el proceso de traducción desde la necesidad de información hasta la consulta real. Por esta razón, ha habido un fuerte interés en las técnicas de expansión de consultas. Tales técnicas se utilizan para ampliar la consulta original y producir una representación que refleje mejor la necesidad de información subyacente. Las técnicas de expansión de consultas han sido ampliamente estudiadas para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la retroalimentación de pseudo-relevancia [12, 21, 28, 29]. Recientemente, se propuso un modelo de campo aleatorio de Markov (MRF) para la <br>recuperación de información</br> que va más allá de la simplista suposición de bolsa de palabras que subyace en BM25 y en el enfoque de modelado de lenguaje (unigrama) para la <br>recuperación de información</br> [20, 22]. El modelo MRF generaliza los modelos de unigrama, bigrama y otras diversas dependencias [14]. La mayoría de los modelos de dependencia de términos pasados no han logrado mostrar mejoras consistentes y significativas sobre las líneas de base de unigramas, con pocas excepciones [8]. El modelo MRF, sin embargo, ha demostrado ser altamente efectivo en una serie de tareas, incluyendo la recuperación ad hoc [14, 16], la búsqueda de páginas con nombres [16] y la búsqueda web en japonés [6]. Hasta ahora, el modelo ha sido utilizado únicamente para clasificar documentos en respuesta a una consulta dada. En este trabajo, mostramos cómo el modelo puede ser ampliado y utilizado para la expansión de consultas utilizando una técnica que llamamos expansión de conceptos latentes (LCE). Hay tres contribuciones principales de nuestro trabajo. Primero, LCE proporciona un mecanismo para combinar la dependencia de términos con la expansión de consultas. Las técnicas de expansión de consultas anteriores se basan en modelos de bolsa de palabras. Por lo tanto, al realizar la expansión de consultas utilizando el modelo MRF, podemos estudiar la dinámica entre la dependencia de términos y la expansión de consultas. A continuación, como mostraremos, el modelo MRF permite que se utilicen características arbitrarias dentro del modelo. Las técnicas de expansión de consultas en el pasado solo han hecho uso implícito de características de ocurrencia de términos. Al utilizar conjuntos de características más robustos, es posible producir términos de expansión mejores que discriminan de manera más efectiva entre documentos relevantes y no relevantes. Finalmente, nuestro enfoque propuesto proporciona de manera fluida un mecanismo para generar conceptos de una sola y múltiples términos. La mayoría de las técnicas anteriores, por defecto, generan términos de forma independiente. Ha habido varios enfoques que hacen uso de conceptos generalizados, sin embargo, dichos enfoques fueron algo heurísticos y realizados fuera del modelo [19, 28]. Nuestro enfoque está motivado tanto formalmente como es una extensión natural del modelo subyacente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2 describimos enfoques relacionados de expansión de consultas. La sección 3 proporciona una visión general del modelo MRF y detalla nuestra técnica propuesta de expansión de conceptos latentes. En la Sección 4 evaluamos nuestro modelo propuesto y analizamos los resultados. Finalmente, la Sección 5 concluye el artículo y resume los principales resultados. 2. TRABAJO RELACIONADO Uno de los enfoques clásicos y más ampliamente utilizados para la expansión de consultas es el algoritmo de Rocchio [21]. El enfoque de Rocchio, que fue desarrollado dentro del modelo de espacio vectorial, reajusta el vector de consulta original moviendo los pesos hacia el conjunto de documentos relevantes o pseudo-relevantes y alejándolos de los documentos no relevantes. Desafortunadamente, no es posible aplicar formalmente el enfoque de Rocchio a un modelo de recuperación estadística, como el modelado del lenguaje para la <br>recuperación de información</br>. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "language modeling approach": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) <br>language modeling approach</br> to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the <br>language modeling approach</br> to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) <br>language modeling approach</br> to information retrieval [20, 22].",
                "Model-based feedback in the <br>language modeling approach</br> to information retrieval."
            ],
            "translated_annotated_samples": [
                "Recientemente, se propuso un modelo de campo aleatorio de Markov (MRF) para la recuperación de información que va más allá de la simplista suposición de bolsa de palabras que subyace en BM25 y en el enfoque de <br>modelado de lenguaje</br> (unigrama) para la recuperación de información [20, 22].",
                "Retroalimentación basada en modelos en el <br>enfoque de modelado del lenguaje</br> para la recuperación de información."
            ],
            "translated_text": "Expansión de conceptos latentes utilizando campos aleatorios de Markov. Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Centro de Recuperación de Información Inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 RESUMEN La expansión de consultas, en forma de retroalimentación de pseudo relevancia o retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación. La mayoría de enfoques anteriores han ignorado problemas importantes, como el papel de las características y la importancia de modelar las dependencias entre términos. En este artículo, proponemos una técnica robusta de expansión de consultas basada en el modelo de campo aleatorio de Markov para la recuperación de información. La técnica, llamada expansión de conceptos latentes, proporciona un mecanismo para modelar las dependencias de términos durante la expansión. Además, el uso de características arbitrarias dentro del modelo proporciona un marco poderoso para ir más allá de las simples características de ocurrencia de términos que son utilizadas implícitamente por la mayoría de las otras técnicas de expansión. Evaluamos nuestra técnica frente a modelos de relevancia, una técnica de expansión de consultas de modelado de lenguaje de última generación. Nuestro modelo demuestra mejoras consistentes y significativas en la efectividad de recuperación en varios conjuntos de datos de TREC. También describimos cómo nuestra técnica puede ser utilizada para generar conceptos significativos de varios términos para tareas como sugerencia/reformulación de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales Algoritmos, Experimentación, Teoría 1. Los usuarios de los sistemas de recuperación de información deben expresar necesidades de información complejas en términos de expresiones booleanas, una lista corta de palabras clave, una oración, una pregunta o posiblemente un relato más extenso. Se pierde mucha información durante el proceso de traducción desde la necesidad de información hasta la consulta real. Por esta razón, ha habido un fuerte interés en las técnicas de expansión de consultas. Tales técnicas se utilizan para ampliar la consulta original y producir una representación que refleje mejor la necesidad de información subyacente. Las técnicas de expansión de consultas han sido ampliamente estudiadas para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la retroalimentación de pseudo-relevancia [12, 21, 28, 29]. Recientemente, se propuso un modelo de campo aleatorio de Markov (MRF) para la recuperación de información que va más allá de la simplista suposición de bolsa de palabras que subyace en BM25 y en el enfoque de <br>modelado de lenguaje</br> (unigrama) para la recuperación de información [20, 22]. El modelo MRF generaliza los modelos de unigrama, bigrama y otras diversas dependencias [14]. La mayoría de los modelos de dependencia de términos pasados no han logrado mostrar mejoras consistentes y significativas sobre las líneas de base de unigramas, con pocas excepciones [8]. El modelo MRF, sin embargo, ha demostrado ser altamente efectivo en una serie de tareas, incluyendo la recuperación ad hoc [14, 16], la búsqueda de páginas con nombres [16] y la búsqueda web en japonés [6]. Hasta ahora, el modelo ha sido utilizado únicamente para clasificar documentos en respuesta a una consulta dada. En este trabajo, mostramos cómo el modelo puede ser ampliado y utilizado para la expansión de consultas utilizando una técnica que llamamos expansión de conceptos latentes (LCE). Hay tres contribuciones principales de nuestro trabajo. Primero, LCE proporciona un mecanismo para combinar la dependencia de términos con la expansión de consultas. Las técnicas de expansión de consultas anteriores se basan en modelos de bolsa de palabras. Por lo tanto, al realizar la expansión de consultas utilizando el modelo MRF, podemos estudiar la dinámica entre la dependencia de términos y la expansión de consultas. A continuación, como mostraremos, el modelo MRF permite que se utilicen características arbitrarias dentro del modelo. Las técnicas de expansión de consultas en el pasado solo han hecho uso implícito de características de ocurrencia de términos. Al utilizar conjuntos de características más robustos, es posible producir términos de expansión mejores que discriminan de manera más efectiva entre documentos relevantes y no relevantes. Finalmente, nuestro enfoque propuesto proporciona de manera fluida un mecanismo para generar conceptos de una sola y múltiples términos. La mayoría de las técnicas anteriores, por defecto, generan términos de forma independiente. Ha habido varios enfoques que hacen uso de conceptos generalizados, sin embargo, dichos enfoques fueron algo heurísticos y realizados fuera del modelo [19, 28]. Nuestro enfoque está motivado tanto formalmente como es una extensión natural del modelo subyacente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2 describimos enfoques relacionados de expansión de consultas. La sección 3 proporciona una visión general del modelo MRF y detalla nuestra técnica propuesta de expansión de conceptos latentes. En la Sección 4 evaluamos nuestro modelo propuesto y analizamos los resultados. Finalmente, la Sección 5 concluye el artículo y resume los principales resultados. 2. TRABAJO RELACIONADO Uno de los enfoques clásicos y más ampliamente utilizados para la expansión de consultas es el algoritmo de Rocchio [21]. El enfoque de Rocchio, que fue desarrollado dentro del modelo de espacio vectorial, reajusta el vector de consulta original moviendo los pesos hacia el conjunto de documentos relevantes o pseudo-relevantes y alejándolos de los documentos no relevantes. Desafortunadamente, no es posible aplicar formalmente el enfoque de Rocchio a un modelo de recuperación estadística, como el modelado del lenguaje para la recuperación de información. Se han desarrollado varias técnicas de expansión de consultas formalizadas para el marco de modelado de lenguaje, incluyendo el feedback basado en el modelo de Zhai y Lafferty y los modelos de relevancia de Lavrenko y Crofts [12, 29]. Ambos enfoques intentan utilizar documentos pseudo-relevantes o relevantes para estimar un modelo de consulta mejor. El feedback basado en modelos encuentra el modelo que mejor describe los documentos relevantes teniendo en cuenta un modelo de fondo (ruido). Esto separa el modelo de contenido del modelo de fondo. El modelo de contenido se interpola con el modelo de consulta original para formar la consulta ampliada. La otra técnica, modelos de relevancia, está más relacionada con nuestro trabajo. Por lo tanto, entramos en los detalles del modelo. Al igual que el feedback basado en modelos, los modelos de relevancia estiman un modelo de consulta mejorado. La única diferencia entre los dos enfoques es que los modelos de relevancia no modelan explícitamente los documentos relevantes o pseudo-relevantes. En cambio, ellos modelan una noción más generalizada de relevancia, como mostraremos ahora. Dada una consulta Q, un modelo de relevancia es una distribución multinomial, P(·|Q), que codifica la probabilidad de cada término dado la consulta como evidencia. Se calcula como: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) donde RQ es el conjunto de documentos que son relevantes o pseudo relevantes para la consulta Q. En el caso pseudo-relevante, estos son los documentos mejor clasificados para la consulta Q. Además, se asume que P(D) es uniforme en este conjunto. Estas suposiciones suaves hacen que el cálculo del posterior bayesiano sea más práctico. Después de que el modelo es estimado, los documentos son clasificados por recortar el modelo de relevancia al elegir los k términos más probables de P(·|Q). Esta distribución recortada se interpola luego con el modelo de consulta de máxima verosimilitud original. Esto se puede considerar como la expansión de la consulta original por k términos ponderados. A lo largo del resto de este trabajo, nos referimos a esta instancia de modelos de relevancia como RM3. Ha habido relativamente poco trabajo realizado en el área de expansión de consultas en el contexto de modelos de dependencia [9]. Sin embargo, ha habido varios intentos de expandir utilizando conceptos de varios términos. El método de análisis de contexto local (LCA) de Xu y Crofts combinaba la recuperación a nivel de pasaje con la expansión de conceptos, donde los conceptos eran términos y frases simples [28]. Los conceptos de expansión fueron elegidos y ponderados utilizando una métrica basada en estadísticas de co-ocurrencia. Sin embargo, no está claro, basándose en el análisis realizado, cuánto ayudaron las frases en comparación con los términos individuales solos. Papka y Allan investigan el uso de retroalimentación de relevancia para realizar la expansión de conceptos de varios términos en el enrutamiento de documentos [19]. Los conceptos utilizados en su trabajo son más generales que los utilizados en el LCA e incluyen estructuras de lenguaje de consulta InQuery, como #UW50(casa blanca), que corresponde al concepto en el que los términos casa y blanca ocurren, en cualquier orden, dentro de 50 términos uno del otro. Los resultados mostraron que combinar conceptos de un solo término y conceptos de varios términos con una ventana grande mejoró significativamente la efectividad. Sin embargo, no está claro si el mismo enfoque también es efectivo para la recuperación ad hoc, debido a las diferencias en las tareas. 3. Este apartado detalla nuestra técnica propuesta de expansión de conceptos latentes. Como se mencionó anteriormente, la técnica es una extensión del modelo MRF para la recuperación de información [14]. Por lo tanto, comenzamos proporcionando una visión general del modelo MRF y nuestras extensiones propuestas. 3.1 MRFs para IR 3.1.1 Conceptos básicos Los campos aleatorios de Markov, que son modelos gráficos no dirigidos, proporcionan una forma compacta y robusta de modelar una distribución conjunta. Aquí estamos interesados en modelar la distribución conjunta sobre una consulta Q = q1, . . . , qn y un documento D. Se asume que la distribución subyacente sobre pares de documentos y consultas es una distribución de relevancia. Es decir, muestrear de la distribución proporciona pares de documentos y consultas, de modo que el documento sea relevante para la consulta. Un MRF se define por un grafo G y un conjunto de funciones de potencial no negativas sobre los cliques en G. Los nodos en el grafo representan las variables aleatorias y las aristas definen la semántica de independencia de la distribución. Un MRF cumple con la propiedad de Markov, la cual establece que un nodo es independiente de todos sus nodos no vecinos dado los valores observados de sus vecinos. Dado un grafo G, un conjunto de potenciales ψi y un vector de parámetros Λ, la distribución conjunta sobre Q y D está dada por: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) donde Z es una constante de normalización. Seguimos la convención común y parametrizamos los potenciales como ψi(c; Λ) = exp[λifi(c)], donde fi(c) es una función de características de valores reales. 3.1.2 Construcción de G Dada una consulta Q, el grafo G puede ser construido de varias maneras. Sin embargo, siguiendo el trabajo previo, consideramos tres variantes simples [14]. Estas variantes son independencia total, donde cada término de consulta es independiente de los demás dado un documento, dependencia secuencial, que asume que existe una dependencia entre los términos de consulta adyacentes, y dependencia total, que no hace suposiciones de independencia. 3.1.3 Parametrización Los MRFs suelen ser parametrizados comúnmente en función de los cliques máximos de G. Sin embargo, dicha parametrización es demasiado gruesa para nuestras necesidades. Necesitamos una parametrización que nos permita asociar funciones de características con cliques a un nivel más detallado, manteniendo al mismo tiempo el número de características, y por lo tanto el número de parámetros, razonable. Por lo tanto, permitimos que los grupos compartan funciones de características y parámetros basados en conjuntos de grupos. Es decir, todos los subgrupos dentro de un conjunto de subgrupos están asociados con la misma función de característica y comparten un solo parámetro. Esto une de manera efectiva los parámetros de las características asociadas con cada conjunto, lo que reduce significativamente el número de parámetros mientras aún proporciona un mecanismo para el ajuste fino en el nivel de conjuntos de cliques. Proponemos siete conjuntos de cliques para utilizar en la recuperación de información. Los primeros tres conjuntos de cliques consisten en cliques que contienen uno o más términos de consulta y el nodo del documento. Las características sobre estos grupos deberían codificar qué tan bien los términos en la configuración del grupo describen el documento. Estos conjuntos son: • TD - conjunto de cliques que contienen el nodo del documento y exactamente un término de consulta. • OD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en orden secuencial dentro de la consulta. • UD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en cualquier orden dentro de la consulta. Ten en cuenta que UD es un superconjunto de OD. Al atar los parámetros entre los grupos dentro de cada conjunto podemos controlar cuánta influencia recibe cada tipo. Esto también evita el problema de tratar de determinar cómo estimar los pesos para cada clique dentro de los conjuntos. En cambio, ahora solo debemos estimar un parámetro por conjunto. A continuación, consideramos cliques que solo contienen nodos de términos de consulta. Estas cliques, que no fueron consideradas en [14], se definen de manera análoga a las recién definidas, excepto que las cliques solo están formadas por nodos de términos de consulta y no contienen el nodo de documento. Las funciones de características sobre estos conjuntos deben capturar qué tan compatibles son entre sí los términos de consulta. Estas características de grupo pueden adoptar la forma de modelos de lenguaje que imponen la corrección de los términos. Por lo tanto, definimos los siguientes conjuntos de cliques dependientes de la consulta: • TQ - conjunto de cliques que contienen exactamente un término de la consulta. • OQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en orden secuencial dentro de la consulta. • UQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en cualquier orden dentro de la consulta. Finalmente, está la clique que solo contiene el nodo del documento. Las características sobre este nodo pueden ser utilizadas como un tipo de documento previo, codificando propiedades centradas en el documento. Este conjunto de cliques trivial es entonces: • D - conjunto de cliques que contiene solo el nodo único D. Observamos que nuestros conjuntos de cliques forman una cobertura de conjuntos sobre los cliques de G, pero no son una partición, ya que algunos cliques aparecen en múltiples conjuntos de cliques. Después de atar los parámetros en nuestros conjuntos de cliques y usar la forma de la función potencial exponencial, terminamos con la siguiente forma simplificada de la distribución conjunta: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - dependiente del documento y la consulta + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - dependiente de la consulta + λDfD(D) FD(D) - dependiente del documento − log ZΛ documento + independiente de la consulta donde FDQ, FQ y FD son funciones de conveniencia definidas por los componentes dependientes del documento y la consulta, dependientes de la consulta y dependientes del documento de la distribución conjunta, respectivamente. Estos se utilizarán para simplificar y clarificar las expresiones derivadas a lo largo del resto del documento. 3.1.4 Características Cualquier función de característica arbitraria sobre configuraciones de cliques puede ser utilizada en el modelo. La elección correcta de las características depende en gran medida de la tarea de recuperación y la métrica de evaluación. Por lo tanto, es probable que no exista un conjunto único y universalmente aplicable de características. Para dar una idea de la variedad de características que se pueden utilizar, ahora describimos brevemente posibles tipos de características que podrían ser utilizadas. Posibles características dependientes del término de consulta incluyen tf, idf, entidades nombradas, proximidad de términos y estilo de texto, por nombrar algunas. Se pueden utilizar muchos tipos de características dependientes del documento, como la longitud del documento, el PageRank, la legibilidad y el género, entre otros. Dado que nuestro objetivo aquí no es encontrar características óptimas, utilizamos un conjunto simple y fijo de características que han demostrado ser efectivas en trabajos anteriores [14]. Consulte la Tabla 1 para ver la lista de características utilizadas. Estas características intentan capturar la ocurrencia de términos y la proximidad entre términos. Una mejor selección de características en el futuro probablemente conducirá a una mayor efectividad. 3.1.5 Clasificación Dada una consulta Q, deseamos clasificar los documentos en orden descendente según PG,Λ(D|Q). Después de eliminar las expresiones independientes del documento del registro PG,Λ(Q, D), derivamos la siguiente función de clasificación: PG,Λ(D|Q) rango = FDQ(D, Q) + FD(D) (2), que es una simple combinación lineal ponderada de funciones de características que pueden calcularse eficientemente para grafos razonables. 3.1.6 Estimación de Parámetros Ahora que el modelo ha sido completamente especificado, el paso final es estimar los parámetros del modelo. Aunque los MRF son modelos generativos, no es apropiado entrenarlos utilizando la función de valor de características fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Tabla 1: Funciones de características utilizadas en el modelo de campo aleatorio de Markov. Aquí, tfw,D es el número de veces que el término w ocurre en el documento D, tf#1(qi...qi+k),D denota el número de veces que la frase exacta qi . . . qi+k ocurre en el documento D, tf#uw(qi...qj ),D es el número de veces que los términos qi, . . . qj aparecen ordenados o desordenados dentro de una ventana de N términos, y |D| es la longitud del documento D. Los valores de cf y |C| se definen de manera análoga a nivel de colección. Finalmente, α y β son hiperparámetros del modelo que controlan el suavizado para las características de términos únicos y frases, respectivamente. Enfoques convencionales basados en la verosimilitud debido a la divergencia métrica [17]. Es decir, es poco probable que la estimación de máxima verosimilitud sea la estimación que maximiza nuestra métrica de evaluación. Por esta razón, entrenamos de manera discriminativa nuestro modelo para maximizar directamente la métrica de evaluación considerada [14, 15, 25]. Dado que nuestro espacio de parámetros es pequeño, hacemos uso de una estrategia simple de escalada de colina, aunque son posibles otros enfoques más sofisticados [10]. 3.2 Expansión de Conceptos Latentes En esta sección describimos cómo este modelo MRF extendido puede ser utilizado de una manera novedosa para generar conceptos de un solo término y de varios términos que están relacionados temáticamente con alguna consulta original. Como mostraremos, los conceptos generados utilizando nuestra técnica pueden ser utilizados para la expansión de consultas u otras tareas, como sugerir formulaciones alternativas de consultas. Suponemos que cuando un usuario formula su consulta original, tiene en mente un conjunto de conceptos, pero solo puede expresar un pequeño número de ellos en forma de consulta. Tratamos los conceptos que el usuario tiene en mente, pero no expresó explícitamente en la consulta, como conceptos latentes. Estos conceptos latentes pueden consistir en un solo término, varios términos o alguna combinación de ambos. Por lo tanto, nuestro objetivo es recuperar estos conceptos latentes dada alguna consulta original. Esto se puede lograr dentro de nuestro marco de trabajo al expandir primero el grafo original G para incluir el tipo de concepto que nos interesa generar. Llamamos a este gráfico expandido H. En la Figura 1, el gráfico del medio proporciona un ejemplo de cómo construir un gráfico expandido que puede generar conceptos de un solo término. De manera similar, el gráfico de la derecha ilustra un gráfico ampliado que genera dos conceptos de términos. Aunque estos dos ejemplos hacen uso de la suposición de dependencia secuencial (es decir, dependencias entre términos de consulta adyacentes), es importante tener en cuenta que tanto la consulta original como los conceptos de expansión pueden utilizar cualquier estructura de independencia. Después de que H se construye, calculamos PH,Λ(E|Q), una distribución de probabilidad sobre conceptos latentes, de acuerdo a: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) donde R es el universo de todos los documentos posibles y E es un concepto latente que puede consistir en uno o más términos. Dado que no es práctico calcular esta suma, debemos aproximarla. Observamos que PH,Λ(Q, E, D) probablemente se concentra alrededor de aquellos documentos D que están altamente clasificados según la consulta Q. Por lo tanto, aproximamos PH,Λ(E|Q) sumando solo un pequeño subconjunto de documentos relevantes o pseudo-relevantes para la consulta Q. Esto se calcula de la siguiente manera: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) donde RQ es un conjunto de documentos relevantes o pseudo-relevantes para la consulta Q y todos los conjuntos de cliques se construyen utilizando H. Como vemos, la contribución de probabilidad para cada documento en RQ es una combinación de la puntuación original de la consulta para el documento (ver Ecuación 2), la puntuación del concepto E para el documento y la puntuación independiente del documento de E. Por lo tanto, esta ecuación puede interpretarse como la medida de qué tan bien Q y E explican los documentos mejor clasificados y la bondad de E, independientemente de los documentos. Para lograr la máxima robustez, utilizamos un conjunto diferente de parámetros para FQD(Q, D) y FQD(E, D), lo que nos permite ponderar de manera diferente las características de ventana ordenadas y no ordenadas para la consulta original y el concepto de expansión candidato. 3.2.1 Expansión de consulta Para utilizar este marco para la expansión de consultas, primero elegimos un grafo de expansión H que codifique la estructura de concepto latente en la que estamos interesados en expandir la consulta. Luego seleccionamos los k conceptos latentes con la mayor probabilidad dada por la Ecuación 3. Se construye un nuevo grafo G al aumentar el grafo original G con los k conceptos de expansión E1, . . . , Ek. Finalmente, los documentos se clasifican según PG ,Λ(D|Q, E1, . . . , Ek) utilizando la Ecuación 2. 3.2.2 Comparación con los Modelos de Relevancia. Al inspeccionar las Ecuaciones 1 y 3 se revela la estrecha conexión que existe entre LCE y los modelos de relevancia. Ambos modelos esencialmente calculan la probabilidad de un término (o concepto) de la misma manera. Es fácil ver que al igual que el modelo MRF puede ser visto como una generalización del modelado del lenguaje, también LCE puede ser visto como una generalización de los modelos de relevancia. Existen diferencias importantes entre los modelos de lenguaje MRFs/LCE y los modelos de lenguaje unigram/relevancia. Consulte la Figura 1 para ver las representaciones gráficas de ambos modelos. Los modelos de lenguaje unigrama y los modelos de relevancia se basan en la distribución multinomial. Esta suposición de distribución encasilla el modelo en la representación de bolsa de palabras y el uso implícito de características de ocurrencia de términos. Sin embargo, la distribución subyacente al modelo MRF nos permite ir más allá de ambas suposiciones, al modelar tanto las dependencias entre los términos de consulta como permitir el uso explícito de características arbitrarias. Ir más allá de la simplista suposición de la bolsa de palabras de esta manera resulta en un modelo general y robusto y, como mostramos en la siguiente sección, se traduce en mejoras significativas en la efectividad de recuperación. 4. RESULTADOS EXPERIMENTALES Para comprender mejor las fortalezas y debilidades de nuestra técnica, la evaluamos en una amplia gama de conjuntos de datos. La Tabla 2 proporciona un resumen de los conjuntos de datos de TREC considerados. Las colecciones WSJ, AP y ROBUST son más pequeñas y consisten enteramente de artículos de agencias de noticias, mientras que WT10g y GOV2 son colecciones web grandes. Para cada conjunto de datos, dividimos los temas disponibles en un conjunto de entrenamiento y otro de prueba, donde el conjunto de entrenamiento se utiliza únicamente para la estimación de parámetros y el conjunto de prueba se utiliza con fines de evaluación. Todos los experimentos se llevaron a cabo utilizando una versión modificada de Indri, que forma parte del Lemur Toolkit [18, 23]. Todas las colecciones fueron detenidas utilizando una lista estándar de 418 términos comunes y truncadas utilizando un truncador de Porter. En todos los casos, solo se utiliza la parte del título de los temas de TREC para construir las consultas. Construimos G utilizando la suposición de dependencia secuencial para todos los conjuntos de datos [14]. 4.1 Resultados de recuperación ad-hoc Ahora investigamos qué tan bien se desempeña nuestro modelo en la práctica en un entorno de retroalimentación de relevancia pseudo. Comparamos el modelado de lenguaje unigrama (con suavizado de Dirichlet), el modelo MRF (sin expansión), los modelos de relevancia y LCE para comprender mejor cómo se desempeña cada modelo en los diferentes conjuntos de datos. Para el modelo de lenguaje unigrama, se entrenó el parámetro de suavizado. Para el modelo MRF, entrenamos los parámetros del modelo (es decir, y hiperparámetros del modelo (es decir, α, β). Para RM3 y LCE, también entrenamos el número de pseudoNombre Descripción # Docs Temas de Entrenamiento Temas de Prueba WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc. Presione 88-90 242,918 51-150 151-200 ROBUST Robust 2004 datos 528,155 301-450 601-700 WT10g Colección Web de TREC 1,692,096 451-500 501-550 GOV2 Rastreo 2004 del dominio .gov 25,205,179 701-750 751-800 Tabla 2: Resumen de las colecciones y temas de TREC. documentos de retroalimentación relevantes utilizados y el número de términos de expansión. 4.1.1 Expansión con Conceptos de Términos Únicos Comenzamos evaluando qué tan bien funciona nuestro modelo al expandir utilizando solo términos individuales. Antes de describir y analizar los resultados, declaramos explícitamente cómo se calculan las probabilidades de términos de expansión bajo esta configuración (es decir, utilizando la suposición de dependencia secuencial, expandiendo con conceptos de un solo término y utilizando nuestro conjunto de características). Las probabilidades de términos de expansión se calculan de la siguiente manera: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) donde b ∈ Q denota el conjunto de bigramas en Q. Esta ecuación muestra claramente cómo LCE difiere de los modelos de relevancia. Cuando establecemos λTD = λT,D = 1 y todos los demás parámetros en 0, obtenemos la fórmula exacta que se utiliza para calcular las probabilidades de términos en el marco de modelado de relevancia. Por lo tanto, LCE añade dos factores muy importantes a la ecuación. Primero, agrega las características de ventana ordenadas y no ordenadas que se aplican a la consulta original. En segundo lugar, aplica una forma intuitiva similar a tf.idf al término de expansión candidato w. El factor idf, que no está presente en los modelos de relevancia, juega un papel importante en la selección del término de expansión. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figura 2: Histogramas que demuestran y comparan la robustez de los modelos de relevancia (RM3) y la expansión de conceptos latentes (LCE) con respecto al modelo de probabilidad de consulta (QL) para los conjuntos de datos AP, ROBUST y WT10G. Los resultados, evaluados utilizando la precisión promedio media, se muestran en la Tabla 3. Como vemos, el modelo MRF, los modelos de relevancia y LCE siempre superan significativamente al modelo de lenguaje unigrama. Además, LCE muestra mejoras significativas sobre los modelos de relevancia en todos los conjuntos de datos. Las mejoras relativas sobre los modelos de relevancia son del 6.9% para AP, 12.9% para WSJ, 6.5% para ROBUST, 16.7% para WT10G y 7.3% para GOV2. Además, LCE muestra pequeñas mejoras, pero no significativas, respecto al modelado de relevancia para métricas como precisión en 5, 10 y 20. Sin embargo, tanto el modelado de relevancia como el LCE muestran mejoras estadísticamente significativas en dichas métricas sobre el modelo de lenguaje unigrama. Otro resultado interesante es que el modelo MRF es estadísticamente equivalente a los modelos de relevancia en los dos conjuntos de datos web. De hecho, el modelo MRF supera a los modelos de relevancia en el conjunto de datos WT10g. Esto reitera la importancia de las características no unigrama, basadas en la proximidad para la búsqueda web basada en contenido observada previamente [14, 16]. Aunque nuestro modelo tiene más parámetros libres que los modelos de relevancia, sorprendentemente hay poco sobreajuste. En cambio, el modelo muestra buenas propiedades de generalización. 4.1.2 Expansión con Conceptos de Múltiples Términos También investigamos la expansión utilizando conceptos de una y dos palabras. Para cada consulta, expandimos utilizando un conjunto de conceptos de un solo término y un conjunto de conceptos de dos términos. Los conjuntos fueron elegidos de forma independiente. Desafortunadamente, solo se observaron aumentos insignificantes en la precisión promedio. Este resultado puede deberse al hecho de que existen fuertes correlaciones entre los conceptos de expansión de términos individuales. Descubrimos que los dos conceptos de palabras elegidos a menudo consistían en dos términos altamente correlacionados que también son elegidos como conceptos de términos individuales. Por ejemplo, se eligió el concepto de dos términos mercado de valores, mientras que también se eligieron los conceptos de un solo término acciones y mercado. Por lo tanto, muchos conceptos de dos palabras es poco probable que aumenten el poder discriminativo de la consulta ampliada. Este resultado sugiere que los conceptos deben ser elegidos de acuerdo con ciertos criterios que también tengan en cuenta la novedad, la diversidad o las correlaciones de términos. Otro problema potencial es el conjunto de características utilizado. Otros conjuntos de características pueden dar resultados diferentes en última instancia, especialmente si reducen la correlación entre los conceptos de expansión. Por lo tanto, nuestros experimentos no arrojan resultados concluyentes en cuanto a la expansión utilizando conceptos de varios términos. En cambio, los resultados plantean preguntas abiertas interesantes y direcciones para futuras exploraciones. Tabla 3: Promedio de precisión media en el conjunto de pruebas para modelado de lenguaje (LM), campo aleatorio de Markov (MRF), modelos de relevancia (RM3) y expansión de conceptos latentes (LCE). Los superíndices α, β y γ indican mejoras estadísticamente significativas (p < 0.05) sobre LM, MRF y RM3, respectivamente. 4.2 Robustez Como hemos demostrado, los modelos de relevancia y la expansión de conceptos latentes pueden mejorar significativamente la efectividad de recuperación sobre el modelo de probabilidad de consulta base. En esta sección analizamos la robustez de estos dos métodos. Aquí definimos la robustez como el número de consultas cuya efectividad se ve mejorada/afectada (y en qué medida) como resultado de aplicar estos métodos. Una técnica de expansión altamente robusta mejorará significativamente muchas consultas y solo perjudicará mínimamente a unas pocas. La Figura 2 proporciona un análisis de la robustez del modelado de relevancia y la expansión de conceptos latentes para los conjuntos de datos AP, ROBUST y WT10G. El análisis de los dos conjuntos de datos no mostrados es similar. Los histogramas proporcionan, para varios rangos de disminuciones/aumentos relativos en la precisión media promedio, el número de consultas que se vieron perjudicadas/mejoradas con respecto a la línea base de probabilidad de consulta. Como muestran los resultados, LCE muestra una fuerte robustez para cada conjunto de datos. Para AP, los modelos de relevancia mejoran 38 consultas y perjudican 11, mientras que LCE mejora 35 y perjudica 14. Aunque los modelos de relevancia mejoran la efectividad de 3 consultas más que LCE, la mejora relativa exhibida por LCE es significativamente mayor. Para el conjunto de datos ROBUST, los modelos de relevancia mejoran 67 consultas y perjudican 32, y LCE mejora 77 y perjudica 22. Finalmente, para la colección WT10G, los modelos de relevancia mejoran 32 consultas y perjudican 16, y LCE mejora 35 y perjudica 14. Al igual que con AP, la cantidad de mejora exhibida por el LCE frente a los modelos de relevancia es significativamente mayor tanto para los conjuntos de datos ROBUST como WT10G. Además, cuando LCE afecta al rendimiento, es menos probable que afecte tanto como el modelado de relevancia, lo cual es una propiedad deseable. En general, LCE mejora la efectividad para el 65%-80% de las consultas, dependiendo del conjunto de datos. Cuando se utiliza en combinación con un sistema de predicción de rendimiento de consulta altamente preciso, puede ser posible expandir selectivamente las consultas y minimizar la pérdida asociada con el rendimiento sub-baseline. 4.3 Generación de Conceptos de Múltiples Términos Aunque encontramos que la expansión utilizando conceptos de múltiples términos no logró producir mejoras concluyentes en la efectividad, hay otras tareas potenciales para las cuales estos conceptos pueden ser útiles, como sugerencia/reformulación de consultas, resumen y extracción de conceptos. Por ejemplo, para una tarea de sugerencia de consultas, la consulta original podría usarse para generar un conjunto de conceptos latentes que corresponden a formulaciones alternativas de la consulta. Aunque evaluar nuestro modelo en estas tareas está fuera del alcance de este trabajo, deseamos mostrar un ejemplo ilustrativo de los tipos de conceptos generados utilizando nuestro modelo. En la Tabla 4, presentamos los conceptos de una, dos y tres palabras más probables generados utilizando LCE para la consulta logros del telescopio Hubble utilizando los 25 documentos mejor clasificados de la colección ROBUST. Es bien sabido que generar conceptos de múltiples términos utilizando un modelo basado en unigramas produce resultados insatisfactorios, ya que no considera las dependencias entre los términos. Esto no es el caso al generar conceptos de múltiples términos usando nuestro modelo. En cambio, la mayoría de los conceptos generados son bien formados y significativos. Hay varios casos donde los conceptos son menos coherentes, como espejo espejo espejo. En este caso, la probabilidad de que aparezca el término \"espejo\" en un documento pseudo-relevante supera a las características de modelado de lenguaje (por ejemplo, fOQ), lo que provoca que este concepto no coherente tenga una alta probabilidad. Tales ejemplos son minoría, sin embargo. No solo los conceptos generados son bien formados y significativos, sino que también son relevantes al tema de la consulta original. Como podemos ver, todos los conceptos generados están relacionados con el tema y de alguna manera están relacionados con el telescopio Hubble. Es interesante ver que el concepto de fallo del telescopio Hubble es uno de los tres conceptos de términos más probables, dado que es algo contradictorio con la consulta original. A pesar de esta contradicción, es probable que los documentos que discuten las fallas del telescopio también describan los éxitos, por lo tanto, es probable que este sea un concepto significativo. Una cosa importante a tener en cuenta es que los conceptos generados por LCE son de una naturaleza diferente a los que se generarían utilizando un modelo de relevancia de bigrama. Por ejemplo, un modelo de bigrama sería poco probable que genere el concepto telescopio espacio NASA, ya que ninguno de los bigramas que componen el concepto tiene una alta probabilidad. Sin embargo, dado que nuestro modelo se basa en una serie de características diferentes sobre varios tipos de cliques, es más general y robusto que un modelo de bigrama. Aunque solo proporcionamos los conceptos generados para una sola consulta, señalamos que el mismo análisis y conclusiones se generalizan a través de otros conjuntos de datos, con conceptos coherentes y relacionados temáticamente generados de manera consistente utilizando LCE. 4.4 Discusión Nuestra técnica de expansión de conceptos latentes captura dos tipos de dependencia semiortogonales. En la recuperación de información, ha existido un interés a largo plazo en comprender el papel de la dependencia de términos. De esta investigación, se han identificado dos tipos generales de dependencias. El primer tipo de dependencia es la dependencia sintáctica. Este tipo de dependencia abarca frases, proximidad de términos y co-ocurrencia de términos [2, 4, 5, 7, 26]. Estos métodos capturan el hecho de que las consultas imponen implícita o explícitamente un cierto conjunto de dependencias posicionales. El segundo tipo es la dependencia semántica. Ejemplos de dependencia semántica son la retroalimentación de relevancia, la retroalimentación de pseudo-relevancia, sinónimos y en cierta medida el truncamiento [3]. Estas técnicas han sido exploradas tanto en el lado de la consulta como en el lado del documento. En el lado de la consulta, esto se suele hacer utilizando alguna forma de expansión de consulta, como modelos de relevancia o LCE. En el lado del documento, esto se hace como expansión de documentos o suavizado de documentos [11, 13, 24]. Aunque puede haber cierta superposición entre las dependencias sintácticas y semánticas, en su mayoría son ortogonales. Nuestro modelo utiliza ambos tipos de dependencias. El uso de características de frase y proximidad dentro del modelo captura dependencias sintácticas, mientras que LCE captura dependencias semánticas del lado de la consulta. Esto explica por qué la mejora inicial en la efectividad lograda al usar el modelo MRF no se pierde después de la expansión de consultas. Si los mismos tipos de dependencias fueran capturados tanto por dependencias sintácticas como semánticas, se esperaría que LCE funcionara aproximadamente igual de bien que los modelos de relevancia. Por lo tanto, al modelar ambos tipos de dependencias, observamos un efecto aditivo en lugar de un efecto absorbente. Una área interesante de trabajo futuro es determinar si modelar las dependencias semánticas del lado del documento puede aportar algo al modelo. Resultados previos que han combinado dependencias semánticas del lado de la consulta y del documento han mostrado resultados mixtos [13, 27]. 5. CONCLUSIONES En este artículo propusimos una técnica robusta de expansión de consultas llamada expansión de conceptos latentes. La técnica se demostró ser una extensión natural del modelo de campo aleatorio de Markov para la recuperación de información y una generalización de los modelos de relevancia. LCE es novedoso en el sentido de que realiza una expansión de un solo término o de varios términos dentro de un marco que permite el modelado de dependencias entre términos y el uso de características arbitrarias, mientras que trabajos anteriores se basaban en la suposición de la bolsa de palabras y características de ocurrencia de términos. Mostramos que la técnica puede ser utilizada para producir conceptos de expansión de varios términos de alta calidad, bien formados y relevantes desde el punto de vista temático. Los conceptos generados pueden ser utilizados en un módulo de sugerencia de consultas alternativas. También demostramos que el modelo es altamente efectivo. De hecho, logra mejoras significativas en la precisión promedio media en comparación con los modelos de relevancia en una selección de conjuntos de datos de TREC. También se demostró que el modelo MRF por sí solo, sin ninguna expansión de consulta, supera a los modelos de relevancia en grandes conjuntos de datos web. Esto reafirma observaciones previas de que modelar dependencias a través del uso de características de proximidad dentro del MRF tiene un mayor impacto en colecciones más grandes y ruidosas que en colecciones más pequeñas y bien comportadas. Finalmente, reiteramos la importancia de elegir términos de expansión que modelen la relevancia, en lugar de los documentos relevantes, y mostramos cómo LCE captura tanto las dependencias sintácticas como semánticas del lado de la consulta. El trabajo futuro se centrará en incorporar dependencias del lado del documento también. Agradecimientos Este trabajo fue apoyado en parte por el Centro de Recuperación de Información Inteligente, en parte por la subvención NSF #CNS-0454018, en parte por ARDA y la subvención NSF #CCF-0205575, y en parte por Microsoft Live Labs. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son responsabilidad del autor o los autores y no necesariamente reflejan las del patrocinador.  REFERENCIAS [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker y C. Wade. UMass en TREC 2004: Novedad y DIFICULTAD. En Actas en línea de la Conferencia de Recuperación de Información de 2004, 2004. [2] C. L. A. Clarke y G. V. Cormack. Recuperación y clasificación de la subcadena más corta. ACM Trans. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate to Spanish? Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson y J. Callan. Expansión de consultas utilizando modelos de caminata aleatoria. En Proc. 14th Intl. Conf. sobre Gestión de Información y Conocimiento, páginas 704-711, 2005. [4] W. B. Croft. Consultas booleanas y dependencias de términos en modelos de recuperación probabilística. Revista de la Sociedad Americana de Ciencia de la Información, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle y D. Lewis. El uso de frases y consultas estructuradas en la recuperación de información. En Proc. 14º Anu. Internacional. Conferencia ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 32-45, 1991. [6] K. Eguchi. Experimentos de expansión de consultas NTCIR-5 utilizando modelos de dependencia de términos. En Actas del Quinto Taller de Reunión NTCIR sobre Evaluación de Tecnologías de Acceso a la Información, páginas 494-501, 2005. [7] J. Fagan. Indexación automática de frases para la recuperación de documentos: Un examen de métodos sintácticos y no sintácticos. En el Proc. décimo anual. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 91-101, 1987. [8] J. Gao, J. Nie, G. Wu y G. Cao. Modelo de lenguaje de dependencia para recuperación de información. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 170-177, 2004. [9] D. Harper y C. J. van Rijsbergen. Una evaluación de la retroalimentación en la recuperación de documentos utilizando datos de co-ocurrencia. Revista de Documentación, 34(3):189-216, 1978. [10] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Proc. de la Conf. Internacional de Aprendizaje Automático, páginas 377-384, 2005. [11] O. Kurland y L. Lee. Estructura del corpus, modelos de lenguaje y recuperación de información ad-hoc. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 194-201, 2004. [12] V. Lavrenko y W. B. Croft. Modelos de lenguaje basados en relevancia. En Proc. 24º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 120-127, 2001. [13] X. Liu y W. B. Croft. Recuperación basada en clústeres utilizando modelos de lenguaje. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 186-193, 2004. [14] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias entre términos. En Proc. 28vo Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [15] D. Metzler y W. B. Croft. Modelos basados en características lineales para la recuperación de información. Recuperación de información, por aparecer, 2006. [16] D. Metzler, T. Strohman, Y. Zhou y W. B. Croft. Indri en la pista de terabyte en 2005. En Actas en línea de la Conferencia de Recuperación de Texto de 2005, 2005. [17] W. Morgan, W. Greiff y J. Henderson. Maximización directa de la precisión promedio mediante escalada de colina con una comparación con un enfoque de entropía máxima. Informe técnico, MITRE, 2004. [18] P. Ogilvie y J. P. Callan. Experimentos utilizando el kit de herramientas de lémures. En Proc. de la Conferencia de Recuperación de Texto, 2001. [19] R. Papka y J. Allan. Por qué las ventanas más grandes son mejores que las más pequeñas. Informe técnico, Universidad de Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu y M. Gatford. Okapi en trec-3. En Actas en línea de la Tercera Conferencia de Recuperación de Texto, páginas 109-126, 1995. [21] J. J. Rocchio. Retroalimentación de relevancia en la recuperación de información, páginas 313-323. Prentice-Hall, 1971. [22] F. Song y W. B. Croft. Un modelo de lenguaje general para la recuperación de información. En Proc. octava conferencia internacional sobre Gestión de la Información y el Conocimiento (CIKM 99), páginas 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle y W. B. Croft. Indri: Un motor de búsqueda basado en modelos de lenguaje para consultas complejas. En Actas de la Conferencia Internacional sobre Análisis de Inteligencia, 2004. [24] T. Tao, X. Wang, Q. Mei y C. Zhai. Recuperación de información del modelo de lenguaje con expansión de documentos. En Proc. de HLT/NAACL, páginas 407-414, 2006. [25] B. Taskar, C. Guestrin y D. Koller. Redes de Markov de margen máximo. En Proc. de Avances en Sistemas de Información Neural (NIPS 2003), 2003. [26] C. J. van Rijsbergen. Una base teórica para el uso de datos de coocurrencia en la recuperación de información. Revista de Documentación, 33(2):106-119, 1977. [27] X. Wei y W. B. Croft. Modelos de documentos basados en LDA para recuperación ad-hoc. En Proc. 29º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 178-185, 2006. [28] J. Xu y W. B. Croft. Mejorando la efectividad de la recuperación de información con análisis de contexto local. ACM Trans. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate into Spanish? Syst., 18(1):79-112, 2000. [29] C. Zhai y J. Lafferty. Retroalimentación basada en modelos en el <br>enfoque de modelado del lenguaje</br> para la recuperación de información. En Proc. 10th Intl. Conferencia sobre Gestión de la Información y el Conocimiento, páginas 403-410, 2001. ",
            "candidates": [],
            "error": [
                [
                    "modelado de lenguaje",
                    "enfoque de modelado del lenguaje"
                ]
            ]
        },
        "web search": {
            "translated_key": "búsqueda web",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language <br>web search</br> [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based <br>web search</br> observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language <br>web search</br> [6].",
                "This reiterates the importance of non-unigram, proximity-based features for content-based <br>web search</br> observed previously [14, 16]."
            ],
            "translated_annotated_samples": [
                "El modelo MRF, sin embargo, ha demostrado ser altamente efectivo en una serie de tareas, incluyendo la recuperación ad hoc [14, 16], la búsqueda de páginas con nombres [16] y la <br>búsqueda web</br> en japonés [6].",
                "Esto reitera la importancia de las características no unigrama, basadas en la proximidad para la <br>búsqueda web</br> basada en contenido observada previamente [14, 16]."
            ],
            "translated_text": "Expansión de conceptos latentes utilizando campos aleatorios de Markov. Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Centro de Recuperación de Información Inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 RESUMEN La expansión de consultas, en forma de retroalimentación de pseudo relevancia o retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación. La mayoría de enfoques anteriores han ignorado problemas importantes, como el papel de las características y la importancia de modelar las dependencias entre términos. En este artículo, proponemos una técnica robusta de expansión de consultas basada en el modelo de campo aleatorio de Markov para la recuperación de información. La técnica, llamada expansión de conceptos latentes, proporciona un mecanismo para modelar las dependencias de términos durante la expansión. Además, el uso de características arbitrarias dentro del modelo proporciona un marco poderoso para ir más allá de las simples características de ocurrencia de términos que son utilizadas implícitamente por la mayoría de las otras técnicas de expansión. Evaluamos nuestra técnica frente a modelos de relevancia, una técnica de expansión de consultas de modelado de lenguaje de última generación. Nuestro modelo demuestra mejoras consistentes y significativas en la efectividad de recuperación en varios conjuntos de datos de TREC. También describimos cómo nuestra técnica puede ser utilizada para generar conceptos significativos de varios términos para tareas como sugerencia/reformulación de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales Algoritmos, Experimentación, Teoría 1. Los usuarios de los sistemas de recuperación de información deben expresar necesidades de información complejas en términos de expresiones booleanas, una lista corta de palabras clave, una oración, una pregunta o posiblemente un relato más extenso. Se pierde mucha información durante el proceso de traducción desde la necesidad de información hasta la consulta real. Por esta razón, ha habido un fuerte interés en las técnicas de expansión de consultas. Tales técnicas se utilizan para ampliar la consulta original y producir una representación que refleje mejor la necesidad de información subyacente. Las técnicas de expansión de consultas han sido ampliamente estudiadas para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la retroalimentación de pseudo-relevancia [12, 21, 28, 29]. Recientemente, se propuso un modelo de campo aleatorio de Markov (MRF) para la recuperación de información que va más allá de la simplista suposición de bolsa de palabras que subyace en BM25 y en el enfoque de modelado de lenguaje (unigrama) para la recuperación de información [20, 22]. El modelo MRF generaliza los modelos de unigrama, bigrama y otras diversas dependencias [14]. La mayoría de los modelos de dependencia de términos pasados no han logrado mostrar mejoras consistentes y significativas sobre las líneas de base de unigramas, con pocas excepciones [8]. El modelo MRF, sin embargo, ha demostrado ser altamente efectivo en una serie de tareas, incluyendo la recuperación ad hoc [14, 16], la búsqueda de páginas con nombres [16] y la <br>búsqueda web</br> en japonés [6]. Hasta ahora, el modelo ha sido utilizado únicamente para clasificar documentos en respuesta a una consulta dada. En este trabajo, mostramos cómo el modelo puede ser ampliado y utilizado para la expansión de consultas utilizando una técnica que llamamos expansión de conceptos latentes (LCE). Hay tres contribuciones principales de nuestro trabajo. Primero, LCE proporciona un mecanismo para combinar la dependencia de términos con la expansión de consultas. Las técnicas de expansión de consultas anteriores se basan en modelos de bolsa de palabras. Por lo tanto, al realizar la expansión de consultas utilizando el modelo MRF, podemos estudiar la dinámica entre la dependencia de términos y la expansión de consultas. A continuación, como mostraremos, el modelo MRF permite que se utilicen características arbitrarias dentro del modelo. Las técnicas de expansión de consultas en el pasado solo han hecho uso implícito de características de ocurrencia de términos. Al utilizar conjuntos de características más robustos, es posible producir términos de expansión mejores que discriminan de manera más efectiva entre documentos relevantes y no relevantes. Finalmente, nuestro enfoque propuesto proporciona de manera fluida un mecanismo para generar conceptos de una sola y múltiples términos. La mayoría de las técnicas anteriores, por defecto, generan términos de forma independiente. Ha habido varios enfoques que hacen uso de conceptos generalizados, sin embargo, dichos enfoques fueron algo heurísticos y realizados fuera del modelo [19, 28]. Nuestro enfoque está motivado tanto formalmente como es una extensión natural del modelo subyacente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2 describimos enfoques relacionados de expansión de consultas. La sección 3 proporciona una visión general del modelo MRF y detalla nuestra técnica propuesta de expansión de conceptos latentes. En la Sección 4 evaluamos nuestro modelo propuesto y analizamos los resultados. Finalmente, la Sección 5 concluye el artículo y resume los principales resultados. 2. TRABAJO RELACIONADO Uno de los enfoques clásicos y más ampliamente utilizados para la expansión de consultas es el algoritmo de Rocchio [21]. El enfoque de Rocchio, que fue desarrollado dentro del modelo de espacio vectorial, reajusta el vector de consulta original moviendo los pesos hacia el conjunto de documentos relevantes o pseudo-relevantes y alejándolos de los documentos no relevantes. Desafortunadamente, no es posible aplicar formalmente el enfoque de Rocchio a un modelo de recuperación estadística, como el modelado del lenguaje para la recuperación de información. Se han desarrollado varias técnicas de expansión de consultas formalizadas para el marco de modelado de lenguaje, incluyendo el feedback basado en el modelo de Zhai y Lafferty y los modelos de relevancia de Lavrenko y Crofts [12, 29]. Ambos enfoques intentan utilizar documentos pseudo-relevantes o relevantes para estimar un modelo de consulta mejor. El feedback basado en modelos encuentra el modelo que mejor describe los documentos relevantes teniendo en cuenta un modelo de fondo (ruido). Esto separa el modelo de contenido del modelo de fondo. El modelo de contenido se interpola con el modelo de consulta original para formar la consulta ampliada. La otra técnica, modelos de relevancia, está más relacionada con nuestro trabajo. Por lo tanto, entramos en los detalles del modelo. Al igual que el feedback basado en modelos, los modelos de relevancia estiman un modelo de consulta mejorado. La única diferencia entre los dos enfoques es que los modelos de relevancia no modelan explícitamente los documentos relevantes o pseudo-relevantes. En cambio, ellos modelan una noción más generalizada de relevancia, como mostraremos ahora. Dada una consulta Q, un modelo de relevancia es una distribución multinomial, P(·|Q), que codifica la probabilidad de cada término dado la consulta como evidencia. Se calcula como: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) donde RQ es el conjunto de documentos que son relevantes o pseudo relevantes para la consulta Q. En el caso pseudo-relevante, estos son los documentos mejor clasificados para la consulta Q. Además, se asume que P(D) es uniforme en este conjunto. Estas suposiciones suaves hacen que el cálculo del posterior bayesiano sea más práctico. Después de que el modelo es estimado, los documentos son clasificados por recortar el modelo de relevancia al elegir los k términos más probables de P(·|Q). Esta distribución recortada se interpola luego con el modelo de consulta de máxima verosimilitud original. Esto se puede considerar como la expansión de la consulta original por k términos ponderados. A lo largo del resto de este trabajo, nos referimos a esta instancia de modelos de relevancia como RM3. Ha habido relativamente poco trabajo realizado en el área de expansión de consultas en el contexto de modelos de dependencia [9]. Sin embargo, ha habido varios intentos de expandir utilizando conceptos de varios términos. El método de análisis de contexto local (LCA) de Xu y Crofts combinaba la recuperación a nivel de pasaje con la expansión de conceptos, donde los conceptos eran términos y frases simples [28]. Los conceptos de expansión fueron elegidos y ponderados utilizando una métrica basada en estadísticas de co-ocurrencia. Sin embargo, no está claro, basándose en el análisis realizado, cuánto ayudaron las frases en comparación con los términos individuales solos. Papka y Allan investigan el uso de retroalimentación de relevancia para realizar la expansión de conceptos de varios términos en el enrutamiento de documentos [19]. Los conceptos utilizados en su trabajo son más generales que los utilizados en el LCA e incluyen estructuras de lenguaje de consulta InQuery, como #UW50(casa blanca), que corresponde al concepto en el que los términos casa y blanca ocurren, en cualquier orden, dentro de 50 términos uno del otro. Los resultados mostraron que combinar conceptos de un solo término y conceptos de varios términos con una ventana grande mejoró significativamente la efectividad. Sin embargo, no está claro si el mismo enfoque también es efectivo para la recuperación ad hoc, debido a las diferencias en las tareas. 3. Este apartado detalla nuestra técnica propuesta de expansión de conceptos latentes. Como se mencionó anteriormente, la técnica es una extensión del modelo MRF para la recuperación de información [14]. Por lo tanto, comenzamos proporcionando una visión general del modelo MRF y nuestras extensiones propuestas. 3.1 MRFs para IR 3.1.1 Conceptos básicos Los campos aleatorios de Markov, que son modelos gráficos no dirigidos, proporcionan una forma compacta y robusta de modelar una distribución conjunta. Aquí estamos interesados en modelar la distribución conjunta sobre una consulta Q = q1, . . . , qn y un documento D. Se asume que la distribución subyacente sobre pares de documentos y consultas es una distribución de relevancia. Es decir, muestrear de la distribución proporciona pares de documentos y consultas, de modo que el documento sea relevante para la consulta. Un MRF se define por un grafo G y un conjunto de funciones de potencial no negativas sobre los cliques en G. Los nodos en el grafo representan las variables aleatorias y las aristas definen la semántica de independencia de la distribución. Un MRF cumple con la propiedad de Markov, la cual establece que un nodo es independiente de todos sus nodos no vecinos dado los valores observados de sus vecinos. Dado un grafo G, un conjunto de potenciales ψi y un vector de parámetros Λ, la distribución conjunta sobre Q y D está dada por: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) donde Z es una constante de normalización. Seguimos la convención común y parametrizamos los potenciales como ψi(c; Λ) = exp[λifi(c)], donde fi(c) es una función de características de valores reales. 3.1.2 Construcción de G Dada una consulta Q, el grafo G puede ser construido de varias maneras. Sin embargo, siguiendo el trabajo previo, consideramos tres variantes simples [14]. Estas variantes son independencia total, donde cada término de consulta es independiente de los demás dado un documento, dependencia secuencial, que asume que existe una dependencia entre los términos de consulta adyacentes, y dependencia total, que no hace suposiciones de independencia. 3.1.3 Parametrización Los MRFs suelen ser parametrizados comúnmente en función de los cliques máximos de G. Sin embargo, dicha parametrización es demasiado gruesa para nuestras necesidades. Necesitamos una parametrización que nos permita asociar funciones de características con cliques a un nivel más detallado, manteniendo al mismo tiempo el número de características, y por lo tanto el número de parámetros, razonable. Por lo tanto, permitimos que los grupos compartan funciones de características y parámetros basados en conjuntos de grupos. Es decir, todos los subgrupos dentro de un conjunto de subgrupos están asociados con la misma función de característica y comparten un solo parámetro. Esto une de manera efectiva los parámetros de las características asociadas con cada conjunto, lo que reduce significativamente el número de parámetros mientras aún proporciona un mecanismo para el ajuste fino en el nivel de conjuntos de cliques. Proponemos siete conjuntos de cliques para utilizar en la recuperación de información. Los primeros tres conjuntos de cliques consisten en cliques que contienen uno o más términos de consulta y el nodo del documento. Las características sobre estos grupos deberían codificar qué tan bien los términos en la configuración del grupo describen el documento. Estos conjuntos son: • TD - conjunto de cliques que contienen el nodo del documento y exactamente un término de consulta. • OD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en orden secuencial dentro de la consulta. • UD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en cualquier orden dentro de la consulta. Ten en cuenta que UD es un superconjunto de OD. Al atar los parámetros entre los grupos dentro de cada conjunto podemos controlar cuánta influencia recibe cada tipo. Esto también evita el problema de tratar de determinar cómo estimar los pesos para cada clique dentro de los conjuntos. En cambio, ahora solo debemos estimar un parámetro por conjunto. A continuación, consideramos cliques que solo contienen nodos de términos de consulta. Estas cliques, que no fueron consideradas en [14], se definen de manera análoga a las recién definidas, excepto que las cliques solo están formadas por nodos de términos de consulta y no contienen el nodo de documento. Las funciones de características sobre estos conjuntos deben capturar qué tan compatibles son entre sí los términos de consulta. Estas características de grupo pueden adoptar la forma de modelos de lenguaje que imponen la corrección de los términos. Por lo tanto, definimos los siguientes conjuntos de cliques dependientes de la consulta: • TQ - conjunto de cliques que contienen exactamente un término de la consulta. • OQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en orden secuencial dentro de la consulta. • UQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en cualquier orden dentro de la consulta. Finalmente, está la clique que solo contiene el nodo del documento. Las características sobre este nodo pueden ser utilizadas como un tipo de documento previo, codificando propiedades centradas en el documento. Este conjunto de cliques trivial es entonces: • D - conjunto de cliques que contiene solo el nodo único D. Observamos que nuestros conjuntos de cliques forman una cobertura de conjuntos sobre los cliques de G, pero no son una partición, ya que algunos cliques aparecen en múltiples conjuntos de cliques. Después de atar los parámetros en nuestros conjuntos de cliques y usar la forma de la función potencial exponencial, terminamos con la siguiente forma simplificada de la distribución conjunta: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - dependiente del documento y la consulta + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - dependiente de la consulta + λDfD(D) FD(D) - dependiente del documento − log ZΛ documento + independiente de la consulta donde FDQ, FQ y FD son funciones de conveniencia definidas por los componentes dependientes del documento y la consulta, dependientes de la consulta y dependientes del documento de la distribución conjunta, respectivamente. Estos se utilizarán para simplificar y clarificar las expresiones derivadas a lo largo del resto del documento. 3.1.4 Características Cualquier función de característica arbitraria sobre configuraciones de cliques puede ser utilizada en el modelo. La elección correcta de las características depende en gran medida de la tarea de recuperación y la métrica de evaluación. Por lo tanto, es probable que no exista un conjunto único y universalmente aplicable de características. Para dar una idea de la variedad de características que se pueden utilizar, ahora describimos brevemente posibles tipos de características que podrían ser utilizadas. Posibles características dependientes del término de consulta incluyen tf, idf, entidades nombradas, proximidad de términos y estilo de texto, por nombrar algunas. Se pueden utilizar muchos tipos de características dependientes del documento, como la longitud del documento, el PageRank, la legibilidad y el género, entre otros. Dado que nuestro objetivo aquí no es encontrar características óptimas, utilizamos un conjunto simple y fijo de características que han demostrado ser efectivas en trabajos anteriores [14]. Consulte la Tabla 1 para ver la lista de características utilizadas. Estas características intentan capturar la ocurrencia de términos y la proximidad entre términos. Una mejor selección de características en el futuro probablemente conducirá a una mayor efectividad. 3.1.5 Clasificación Dada una consulta Q, deseamos clasificar los documentos en orden descendente según PG,Λ(D|Q). Después de eliminar las expresiones independientes del documento del registro PG,Λ(Q, D), derivamos la siguiente función de clasificación: PG,Λ(D|Q) rango = FDQ(D, Q) + FD(D) (2), que es una simple combinación lineal ponderada de funciones de características que pueden calcularse eficientemente para grafos razonables. 3.1.6 Estimación de Parámetros Ahora que el modelo ha sido completamente especificado, el paso final es estimar los parámetros del modelo. Aunque los MRF son modelos generativos, no es apropiado entrenarlos utilizando la función de valor de características fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Tabla 1: Funciones de características utilizadas en el modelo de campo aleatorio de Markov. Aquí, tfw,D es el número de veces que el término w ocurre en el documento D, tf#1(qi...qi+k),D denota el número de veces que la frase exacta qi . . . qi+k ocurre en el documento D, tf#uw(qi...qj ),D es el número de veces que los términos qi, . . . qj aparecen ordenados o desordenados dentro de una ventana de N términos, y |D| es la longitud del documento D. Los valores de cf y |C| se definen de manera análoga a nivel de colección. Finalmente, α y β son hiperparámetros del modelo que controlan el suavizado para las características de términos únicos y frases, respectivamente. Enfoques convencionales basados en la verosimilitud debido a la divergencia métrica [17]. Es decir, es poco probable que la estimación de máxima verosimilitud sea la estimación que maximiza nuestra métrica de evaluación. Por esta razón, entrenamos de manera discriminativa nuestro modelo para maximizar directamente la métrica de evaluación considerada [14, 15, 25]. Dado que nuestro espacio de parámetros es pequeño, hacemos uso de una estrategia simple de escalada de colina, aunque son posibles otros enfoques más sofisticados [10]. 3.2 Expansión de Conceptos Latentes En esta sección describimos cómo este modelo MRF extendido puede ser utilizado de una manera novedosa para generar conceptos de un solo término y de varios términos que están relacionados temáticamente con alguna consulta original. Como mostraremos, los conceptos generados utilizando nuestra técnica pueden ser utilizados para la expansión de consultas u otras tareas, como sugerir formulaciones alternativas de consultas. Suponemos que cuando un usuario formula su consulta original, tiene en mente un conjunto de conceptos, pero solo puede expresar un pequeño número de ellos en forma de consulta. Tratamos los conceptos que el usuario tiene en mente, pero no expresó explícitamente en la consulta, como conceptos latentes. Estos conceptos latentes pueden consistir en un solo término, varios términos o alguna combinación de ambos. Por lo tanto, nuestro objetivo es recuperar estos conceptos latentes dada alguna consulta original. Esto se puede lograr dentro de nuestro marco de trabajo al expandir primero el grafo original G para incluir el tipo de concepto que nos interesa generar. Llamamos a este gráfico expandido H. En la Figura 1, el gráfico del medio proporciona un ejemplo de cómo construir un gráfico expandido que puede generar conceptos de un solo término. De manera similar, el gráfico de la derecha ilustra un gráfico ampliado que genera dos conceptos de términos. Aunque estos dos ejemplos hacen uso de la suposición de dependencia secuencial (es decir, dependencias entre términos de consulta adyacentes), es importante tener en cuenta que tanto la consulta original como los conceptos de expansión pueden utilizar cualquier estructura de independencia. Después de que H se construye, calculamos PH,Λ(E|Q), una distribución de probabilidad sobre conceptos latentes, de acuerdo a: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) donde R es el universo de todos los documentos posibles y E es un concepto latente que puede consistir en uno o más términos. Dado que no es práctico calcular esta suma, debemos aproximarla. Observamos que PH,Λ(Q, E, D) probablemente se concentra alrededor de aquellos documentos D que están altamente clasificados según la consulta Q. Por lo tanto, aproximamos PH,Λ(E|Q) sumando solo un pequeño subconjunto de documentos relevantes o pseudo-relevantes para la consulta Q. Esto se calcula de la siguiente manera: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) donde RQ es un conjunto de documentos relevantes o pseudo-relevantes para la consulta Q y todos los conjuntos de cliques se construyen utilizando H. Como vemos, la contribución de probabilidad para cada documento en RQ es una combinación de la puntuación original de la consulta para el documento (ver Ecuación 2), la puntuación del concepto E para el documento y la puntuación independiente del documento de E. Por lo tanto, esta ecuación puede interpretarse como la medida de qué tan bien Q y E explican los documentos mejor clasificados y la bondad de E, independientemente de los documentos. Para lograr la máxima robustez, utilizamos un conjunto diferente de parámetros para FQD(Q, D) y FQD(E, D), lo que nos permite ponderar de manera diferente las características de ventana ordenadas y no ordenadas para la consulta original y el concepto de expansión candidato. 3.2.1 Expansión de consulta Para utilizar este marco para la expansión de consultas, primero elegimos un grafo de expansión H que codifique la estructura de concepto latente en la que estamos interesados en expandir la consulta. Luego seleccionamos los k conceptos latentes con la mayor probabilidad dada por la Ecuación 3. Se construye un nuevo grafo G al aumentar el grafo original G con los k conceptos de expansión E1, . . . , Ek. Finalmente, los documentos se clasifican según PG ,Λ(D|Q, E1, . . . , Ek) utilizando la Ecuación 2. 3.2.2 Comparación con los Modelos de Relevancia. Al inspeccionar las Ecuaciones 1 y 3 se revela la estrecha conexión que existe entre LCE y los modelos de relevancia. Ambos modelos esencialmente calculan la probabilidad de un término (o concepto) de la misma manera. Es fácil ver que al igual que el modelo MRF puede ser visto como una generalización del modelado del lenguaje, también LCE puede ser visto como una generalización de los modelos de relevancia. Existen diferencias importantes entre los modelos de lenguaje MRFs/LCE y los modelos de lenguaje unigram/relevancia. Consulte la Figura 1 para ver las representaciones gráficas de ambos modelos. Los modelos de lenguaje unigrama y los modelos de relevancia se basan en la distribución multinomial. Esta suposición de distribución encasilla el modelo en la representación de bolsa de palabras y el uso implícito de características de ocurrencia de términos. Sin embargo, la distribución subyacente al modelo MRF nos permite ir más allá de ambas suposiciones, al modelar tanto las dependencias entre los términos de consulta como permitir el uso explícito de características arbitrarias. Ir más allá de la simplista suposición de la bolsa de palabras de esta manera resulta en un modelo general y robusto y, como mostramos en la siguiente sección, se traduce en mejoras significativas en la efectividad de recuperación. 4. RESULTADOS EXPERIMENTALES Para comprender mejor las fortalezas y debilidades de nuestra técnica, la evaluamos en una amplia gama de conjuntos de datos. La Tabla 2 proporciona un resumen de los conjuntos de datos de TREC considerados. Las colecciones WSJ, AP y ROBUST son más pequeñas y consisten enteramente de artículos de agencias de noticias, mientras que WT10g y GOV2 son colecciones web grandes. Para cada conjunto de datos, dividimos los temas disponibles en un conjunto de entrenamiento y otro de prueba, donde el conjunto de entrenamiento se utiliza únicamente para la estimación de parámetros y el conjunto de prueba se utiliza con fines de evaluación. Todos los experimentos se llevaron a cabo utilizando una versión modificada de Indri, que forma parte del Lemur Toolkit [18, 23]. Todas las colecciones fueron detenidas utilizando una lista estándar de 418 términos comunes y truncadas utilizando un truncador de Porter. En todos los casos, solo se utiliza la parte del título de los temas de TREC para construir las consultas. Construimos G utilizando la suposición de dependencia secuencial para todos los conjuntos de datos [14]. 4.1 Resultados de recuperación ad-hoc Ahora investigamos qué tan bien se desempeña nuestro modelo en la práctica en un entorno de retroalimentación de relevancia pseudo. Comparamos el modelado de lenguaje unigrama (con suavizado de Dirichlet), el modelo MRF (sin expansión), los modelos de relevancia y LCE para comprender mejor cómo se desempeña cada modelo en los diferentes conjuntos de datos. Para el modelo de lenguaje unigrama, se entrenó el parámetro de suavizado. Para el modelo MRF, entrenamos los parámetros del modelo (es decir, y hiperparámetros del modelo (es decir, α, β). Para RM3 y LCE, también entrenamos el número de pseudoNombre Descripción # Docs Temas de Entrenamiento Temas de Prueba WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc. Presione 88-90 242,918 51-150 151-200 ROBUST Robust 2004 datos 528,155 301-450 601-700 WT10g Colección Web de TREC 1,692,096 451-500 501-550 GOV2 Rastreo 2004 del dominio .gov 25,205,179 701-750 751-800 Tabla 2: Resumen de las colecciones y temas de TREC. documentos de retroalimentación relevantes utilizados y el número de términos de expansión. 4.1.1 Expansión con Conceptos de Términos Únicos Comenzamos evaluando qué tan bien funciona nuestro modelo al expandir utilizando solo términos individuales. Antes de describir y analizar los resultados, declaramos explícitamente cómo se calculan las probabilidades de términos de expansión bajo esta configuración (es decir, utilizando la suposición de dependencia secuencial, expandiendo con conceptos de un solo término y utilizando nuestro conjunto de características). Las probabilidades de términos de expansión se calculan de la siguiente manera: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) donde b ∈ Q denota el conjunto de bigramas en Q. Esta ecuación muestra claramente cómo LCE difiere de los modelos de relevancia. Cuando establecemos λTD = λT,D = 1 y todos los demás parámetros en 0, obtenemos la fórmula exacta que se utiliza para calcular las probabilidades de términos en el marco de modelado de relevancia. Por lo tanto, LCE añade dos factores muy importantes a la ecuación. Primero, agrega las características de ventana ordenadas y no ordenadas que se aplican a la consulta original. En segundo lugar, aplica una forma intuitiva similar a tf.idf al término de expansión candidato w. El factor idf, que no está presente en los modelos de relevancia, juega un papel importante en la selección del término de expansión. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figura 2: Histogramas que demuestran y comparan la robustez de los modelos de relevancia (RM3) y la expansión de conceptos latentes (LCE) con respecto al modelo de probabilidad de consulta (QL) para los conjuntos de datos AP, ROBUST y WT10G. Los resultados, evaluados utilizando la precisión promedio media, se muestran en la Tabla 3. Como vemos, el modelo MRF, los modelos de relevancia y LCE siempre superan significativamente al modelo de lenguaje unigrama. Además, LCE muestra mejoras significativas sobre los modelos de relevancia en todos los conjuntos de datos. Las mejoras relativas sobre los modelos de relevancia son del 6.9% para AP, 12.9% para WSJ, 6.5% para ROBUST, 16.7% para WT10G y 7.3% para GOV2. Además, LCE muestra pequeñas mejoras, pero no significativas, respecto al modelado de relevancia para métricas como precisión en 5, 10 y 20. Sin embargo, tanto el modelado de relevancia como el LCE muestran mejoras estadísticamente significativas en dichas métricas sobre el modelo de lenguaje unigrama. Otro resultado interesante es que el modelo MRF es estadísticamente equivalente a los modelos de relevancia en los dos conjuntos de datos web. De hecho, el modelo MRF supera a los modelos de relevancia en el conjunto de datos WT10g. Esto reitera la importancia de las características no unigrama, basadas en la proximidad para la <br>búsqueda web</br> basada en contenido observada previamente [14, 16]. Aunque nuestro modelo tiene más parámetros libres que los modelos de relevancia, sorprendentemente hay poco sobreajuste. En cambio, el modelo muestra buenas propiedades de generalización. 4.1.2 Expansión con Conceptos de Múltiples Términos También investigamos la expansión utilizando conceptos de una y dos palabras. Para cada consulta, expandimos utilizando un conjunto de conceptos de un solo término y un conjunto de conceptos de dos términos. Los conjuntos fueron elegidos de forma independiente. Desafortunadamente, solo se observaron aumentos insignificantes en la precisión promedio. Este resultado puede deberse al hecho de que existen fuertes correlaciones entre los conceptos de expansión de términos individuales. Descubrimos que los dos conceptos de palabras elegidos a menudo consistían en dos términos altamente correlacionados que también son elegidos como conceptos de términos individuales. Por ejemplo, se eligió el concepto de dos términos mercado de valores, mientras que también se eligieron los conceptos de un solo término acciones y mercado. Por lo tanto, muchos conceptos de dos palabras es poco probable que aumenten el poder discriminativo de la consulta ampliada. Este resultado sugiere que los conceptos deben ser elegidos de acuerdo con ciertos criterios que también tengan en cuenta la novedad, la diversidad o las correlaciones de términos. Otro problema potencial es el conjunto de características utilizado. Otros conjuntos de características pueden dar resultados diferentes en última instancia, especialmente si reducen la correlación entre los conceptos de expansión. Por lo tanto, nuestros experimentos no arrojan resultados concluyentes en cuanto a la expansión utilizando conceptos de varios términos. En cambio, los resultados plantean preguntas abiertas interesantes y direcciones para futuras exploraciones. Tabla 3: Promedio de precisión media en el conjunto de pruebas para modelado de lenguaje (LM), campo aleatorio de Markov (MRF), modelos de relevancia (RM3) y expansión de conceptos latentes (LCE). Los superíndices α, β y γ indican mejoras estadísticamente significativas (p < 0.05) sobre LM, MRF y RM3, respectivamente. 4.2 Robustez Como hemos demostrado, los modelos de relevancia y la expansión de conceptos latentes pueden mejorar significativamente la efectividad de recuperación sobre el modelo de probabilidad de consulta base. En esta sección analizamos la robustez de estos dos métodos. Aquí definimos la robustez como el número de consultas cuya efectividad se ve mejorada/afectada (y en qué medida) como resultado de aplicar estos métodos. Una técnica de expansión altamente robusta mejorará significativamente muchas consultas y solo perjudicará mínimamente a unas pocas. La Figura 2 proporciona un análisis de la robustez del modelado de relevancia y la expansión de conceptos latentes para los conjuntos de datos AP, ROBUST y WT10G. El análisis de los dos conjuntos de datos no mostrados es similar. Los histogramas proporcionan, para varios rangos de disminuciones/aumentos relativos en la precisión media promedio, el número de consultas que se vieron perjudicadas/mejoradas con respecto a la línea base de probabilidad de consulta. Como muestran los resultados, LCE muestra una fuerte robustez para cada conjunto de datos. Para AP, los modelos de relevancia mejoran 38 consultas y perjudican 11, mientras que LCE mejora 35 y perjudica 14. Aunque los modelos de relevancia mejoran la efectividad de 3 consultas más que LCE, la mejora relativa exhibida por LCE es significativamente mayor. Para el conjunto de datos ROBUST, los modelos de relevancia mejoran 67 consultas y perjudican 32, y LCE mejora 77 y perjudica 22. Finalmente, para la colección WT10G, los modelos de relevancia mejoran 32 consultas y perjudican 16, y LCE mejora 35 y perjudica 14. Al igual que con AP, la cantidad de mejora exhibida por el LCE frente a los modelos de relevancia es significativamente mayor tanto para los conjuntos de datos ROBUST como WT10G. Además, cuando LCE afecta al rendimiento, es menos probable que afecte tanto como el modelado de relevancia, lo cual es una propiedad deseable. En general, LCE mejora la efectividad para el 65%-80% de las consultas, dependiendo del conjunto de datos. Cuando se utiliza en combinación con un sistema de predicción de rendimiento de consulta altamente preciso, puede ser posible expandir selectivamente las consultas y minimizar la pérdida asociada con el rendimiento sub-baseline. 4.3 Generación de Conceptos de Múltiples Términos Aunque encontramos que la expansión utilizando conceptos de múltiples términos no logró producir mejoras concluyentes en la efectividad, hay otras tareas potenciales para las cuales estos conceptos pueden ser útiles, como sugerencia/reformulación de consultas, resumen y extracción de conceptos. Por ejemplo, para una tarea de sugerencia de consultas, la consulta original podría usarse para generar un conjunto de conceptos latentes que corresponden a formulaciones alternativas de la consulta. Aunque evaluar nuestro modelo en estas tareas está fuera del alcance de este trabajo, deseamos mostrar un ejemplo ilustrativo de los tipos de conceptos generados utilizando nuestro modelo. En la Tabla 4, presentamos los conceptos de una, dos y tres palabras más probables generados utilizando LCE para la consulta logros del telescopio Hubble utilizando los 25 documentos mejor clasificados de la colección ROBUST. Es bien sabido que generar conceptos de múltiples términos utilizando un modelo basado en unigramas produce resultados insatisfactorios, ya que no considera las dependencias entre los términos. Esto no es el caso al generar conceptos de múltiples términos usando nuestro modelo. En cambio, la mayoría de los conceptos generados son bien formados y significativos. Hay varios casos donde los conceptos son menos coherentes, como espejo espejo espejo. En este caso, la probabilidad de que aparezca el término \"espejo\" en un documento pseudo-relevante supera a las características de modelado de lenguaje (por ejemplo, fOQ), lo que provoca que este concepto no coherente tenga una alta probabilidad. Tales ejemplos son minoría, sin embargo. No solo los conceptos generados son bien formados y significativos, sino que también son relevantes al tema de la consulta original. Como podemos ver, todos los conceptos generados están relacionados con el tema y de alguna manera están relacionados con el telescopio Hubble. Es interesante ver que el concepto de fallo del telescopio Hubble es uno de los tres conceptos de términos más probables, dado que es algo contradictorio con la consulta original. A pesar de esta contradicción, es probable que los documentos que discuten las fallas del telescopio también describan los éxitos, por lo tanto, es probable que este sea un concepto significativo. Una cosa importante a tener en cuenta es que los conceptos generados por LCE son de una naturaleza diferente a los que se generarían utilizando un modelo de relevancia de bigrama. Por ejemplo, un modelo de bigrama sería poco probable que genere el concepto telescopio espacio NASA, ya que ninguno de los bigramas que componen el concepto tiene una alta probabilidad. Sin embargo, dado que nuestro modelo se basa en una serie de características diferentes sobre varios tipos de cliques, es más general y robusto que un modelo de bigrama. Aunque solo proporcionamos los conceptos generados para una sola consulta, señalamos que el mismo análisis y conclusiones se generalizan a través de otros conjuntos de datos, con conceptos coherentes y relacionados temáticamente generados de manera consistente utilizando LCE. 4.4 Discusión Nuestra técnica de expansión de conceptos latentes captura dos tipos de dependencia semiortogonales. En la recuperación de información, ha existido un interés a largo plazo en comprender el papel de la dependencia de términos. De esta investigación, se han identificado dos tipos generales de dependencias. El primer tipo de dependencia es la dependencia sintáctica. Este tipo de dependencia abarca frases, proximidad de términos y co-ocurrencia de términos [2, 4, 5, 7, 26]. Estos métodos capturan el hecho de que las consultas imponen implícita o explícitamente un cierto conjunto de dependencias posicionales. El segundo tipo es la dependencia semántica. Ejemplos de dependencia semántica son la retroalimentación de relevancia, la retroalimentación de pseudo-relevancia, sinónimos y en cierta medida el truncamiento [3]. Estas técnicas han sido exploradas tanto en el lado de la consulta como en el lado del documento. En el lado de la consulta, esto se suele hacer utilizando alguna forma de expansión de consulta, como modelos de relevancia o LCE. En el lado del documento, esto se hace como expansión de documentos o suavizado de documentos [11, 13, 24]. Aunque puede haber cierta superposición entre las dependencias sintácticas y semánticas, en su mayoría son ortogonales. Nuestro modelo utiliza ambos tipos de dependencias. El uso de características de frase y proximidad dentro del modelo captura dependencias sintácticas, mientras que LCE captura dependencias semánticas del lado de la consulta. Esto explica por qué la mejora inicial en la efectividad lograda al usar el modelo MRF no se pierde después de la expansión de consultas. Si los mismos tipos de dependencias fueran capturados tanto por dependencias sintácticas como semánticas, se esperaría que LCE funcionara aproximadamente igual de bien que los modelos de relevancia. Por lo tanto, al modelar ambos tipos de dependencias, observamos un efecto aditivo en lugar de un efecto absorbente. Una área interesante de trabajo futuro es determinar si modelar las dependencias semánticas del lado del documento puede aportar algo al modelo. Resultados previos que han combinado dependencias semánticas del lado de la consulta y del documento han mostrado resultados mixtos [13, 27]. 5. CONCLUSIONES En este artículo propusimos una técnica robusta de expansión de consultas llamada expansión de conceptos latentes. La técnica se demostró ser una extensión natural del modelo de campo aleatorio de Markov para la recuperación de información y una generalización de los modelos de relevancia. LCE es novedoso en el sentido de que realiza una expansión de un solo término o de varios términos dentro de un marco que permite el modelado de dependencias entre términos y el uso de características arbitrarias, mientras que trabajos anteriores se basaban en la suposición de la bolsa de palabras y características de ocurrencia de términos. Mostramos que la técnica puede ser utilizada para producir conceptos de expansión de varios términos de alta calidad, bien formados y relevantes desde el punto de vista temático. Los conceptos generados pueden ser utilizados en un módulo de sugerencia de consultas alternativas. También demostramos que el modelo es altamente efectivo. De hecho, logra mejoras significativas en la precisión promedio media en comparación con los modelos de relevancia en una selección de conjuntos de datos de TREC. También se demostró que el modelo MRF por sí solo, sin ninguna expansión de consulta, supera a los modelos de relevancia en grandes conjuntos de datos web. Esto reafirma observaciones previas de que modelar dependencias a través del uso de características de proximidad dentro del MRF tiene un mayor impacto en colecciones más grandes y ruidosas que en colecciones más pequeñas y bien comportadas. Finalmente, reiteramos la importancia de elegir términos de expansión que modelen la relevancia, en lugar de los documentos relevantes, y mostramos cómo LCE captura tanto las dependencias sintácticas como semánticas del lado de la consulta. El trabajo futuro se centrará en incorporar dependencias del lado del documento también. Agradecimientos Este trabajo fue apoyado en parte por el Centro de Recuperación de Información Inteligente, en parte por la subvención NSF #CNS-0454018, en parte por ARDA y la subvención NSF #CCF-0205575, y en parte por Microsoft Live Labs. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son responsabilidad del autor o los autores y no necesariamente reflejan las del patrocinador.  REFERENCIAS [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker y C. Wade. UMass en TREC 2004: Novedad y DIFICULTAD. En Actas en línea de la Conferencia de Recuperación de Información de 2004, 2004. [2] C. L. A. Clarke y G. V. Cormack. Recuperación y clasificación de la subcadena más corta. ACM Trans. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate to Spanish? Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson y J. Callan. Expansión de consultas utilizando modelos de caminata aleatoria. En Proc. 14th Intl. Conf. sobre Gestión de Información y Conocimiento, páginas 704-711, 2005. [4] W. B. Croft. Consultas booleanas y dependencias de términos en modelos de recuperación probabilística. Revista de la Sociedad Americana de Ciencia de la Información, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle y D. Lewis. El uso de frases y consultas estructuradas en la recuperación de información. En Proc. 14º Anu. Internacional. Conferencia ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 32-45, 1991. [6] K. Eguchi. Experimentos de expansión de consultas NTCIR-5 utilizando modelos de dependencia de términos. En Actas del Quinto Taller de Reunión NTCIR sobre Evaluación de Tecnologías de Acceso a la Información, páginas 494-501, 2005. [7] J. Fagan. Indexación automática de frases para la recuperación de documentos: Un examen de métodos sintácticos y no sintácticos. En el Proc. décimo anual. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 91-101, 1987. [8] J. Gao, J. Nie, G. Wu y G. Cao. Modelo de lenguaje de dependencia para recuperación de información. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 170-177, 2004. [9] D. Harper y C. J. van Rijsbergen. Una evaluación de la retroalimentación en la recuperación de documentos utilizando datos de co-ocurrencia. Revista de Documentación, 34(3):189-216, 1978. [10] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Proc. de la Conf. Internacional de Aprendizaje Automático, páginas 377-384, 2005. [11] O. Kurland y L. Lee. Estructura del corpus, modelos de lenguaje y recuperación de información ad-hoc. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 194-201, 2004. [12] V. Lavrenko y W. B. Croft. Modelos de lenguaje basados en relevancia. En Proc. 24º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 120-127, 2001. [13] X. Liu y W. B. Croft. Recuperación basada en clústeres utilizando modelos de lenguaje. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 186-193, 2004. [14] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias entre términos. En Proc. 28vo Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [15] D. Metzler y W. B. Croft. Modelos basados en características lineales para la recuperación de información. Recuperación de información, por aparecer, 2006. [16] D. Metzler, T. Strohman, Y. Zhou y W. B. Croft. Indri en la pista de terabyte en 2005. En Actas en línea de la Conferencia de Recuperación de Texto de 2005, 2005. [17] W. Morgan, W. Greiff y J. Henderson. Maximización directa de la precisión promedio mediante escalada de colina con una comparación con un enfoque de entropía máxima. Informe técnico, MITRE, 2004. [18] P. Ogilvie y J. P. Callan. Experimentos utilizando el kit de herramientas de lémures. En Proc. de la Conferencia de Recuperación de Texto, 2001. [19] R. Papka y J. Allan. Por qué las ventanas más grandes son mejores que las más pequeñas. Informe técnico, Universidad de Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu y M. Gatford. Okapi en trec-3. En Actas en línea de la Tercera Conferencia de Recuperación de Texto, páginas 109-126, 1995. [21] J. J. Rocchio. Retroalimentación de relevancia en la recuperación de información, páginas 313-323. Prentice-Hall, 1971. [22] F. Song y W. B. Croft. Un modelo de lenguaje general para la recuperación de información. En Proc. octava conferencia internacional sobre Gestión de la Información y el Conocimiento (CIKM 99), páginas 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle y W. B. Croft. Indri: Un motor de búsqueda basado en modelos de lenguaje para consultas complejas. En Actas de la Conferencia Internacional sobre Análisis de Inteligencia, 2004. [24] T. Tao, X. Wang, Q. Mei y C. Zhai. Recuperación de información del modelo de lenguaje con expansión de documentos. En Proc. de HLT/NAACL, páginas 407-414, 2006. [25] B. Taskar, C. Guestrin y D. Koller. Redes de Markov de margen máximo. En Proc. de Avances en Sistemas de Información Neural (NIPS 2003), 2003. [26] C. J. van Rijsbergen. Una base teórica para el uso de datos de coocurrencia en la recuperación de información. Revista de Documentación, 33(2):106-119, 1977. [27] X. Wei y W. B. Croft. Modelos de documentos basados en LDA para recuperación ad-hoc. En Proc. 29º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 178-185, 2006. [28] J. Xu y W. B. Croft. Mejorando la efectividad de la recuperación de información con análisis de contexto local. ACM Trans. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate into Spanish? Syst., 18(1):79-112, 2000. [29] C. Zhai y J. Lafferty. Retroalimentación basada en modelos en el enfoque de modelado del lenguaje para la recuperación de información. En Proc. 10th Intl. Conferencia sobre Gestión de la Información y el Conocimiento, páginas 403-410, 2001. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "query expansion": {
            "translated_key": "expansión de consultas",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT <br>query expansion</br>, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust <br>query expansion</br> technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling <br>query expansion</br> technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in <br>query expansion</br> techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "<br>query expansion</br> techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for <br>query expansion</br> using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with <br>query expansion</br>.",
                "Previous <br>query expansion</br> techniques are based on bag of words models.",
                "Therefore, by performing <br>query expansion</br> using the MRF model, we are able to study the dynamics between term dependence and <br>query expansion</br>.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "<br>query expansion</br> techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related <br>query expansion</br> approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to <br>query expansion</br> is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized <br>query expansion</br> techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of <br>query expansion</br> in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for <br>query expansion</br> or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 <br>query expansion</br> To use this framework for <br>query expansion</br>, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of <br>query expansion</br>, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after <br>query expansion</br>.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust <br>query expansion</br> technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any <br>query expansion</br>, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "<br>query expansion</br> using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 <br>query expansion</br> experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT <br>query expansion</br>, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "In this paper, we propose a robust <br>query expansion</br> technique based on the Markov random field model for information retrieval.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling <br>query expansion</br> technique.",
                "For this reason, there has been a strong interest in <br>query expansion</br> techniques.",
                "<br>query expansion</br> techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29]."
            ],
            "translated_annotated_samples": [
                "Expansión de conceptos latentes utilizando campos aleatorios de Markov. Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Centro de Recuperación de Información Inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 RESUMEN La <br>expansión de consultas</br>, en forma de retroalimentación de pseudo relevancia o retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación.",
                "En este artículo, proponemos una técnica robusta de <br>expansión de consultas</br> basada en el modelo de campo aleatorio de Markov para la recuperación de información.",
                "Evaluamos nuestra técnica frente a modelos de relevancia, una técnica de <br>expansión de consultas</br> de modelado de lenguaje de última generación.",
                "Por esta razón, ha habido un fuerte interés en las técnicas de <br>expansión de consultas</br>.",
                "Las técnicas de <br>expansión de consultas</br> han sido ampliamente estudiadas para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la retroalimentación de pseudo-relevancia [12, 21, 28, 29]."
            ],
            "translated_text": "Expansión de conceptos latentes utilizando campos aleatorios de Markov. Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Centro de Recuperación de Información Inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 RESUMEN La <br>expansión de consultas</br>, en forma de retroalimentación de pseudo relevancia o retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación. La mayoría de enfoques anteriores han ignorado problemas importantes, como el papel de las características y la importancia de modelar las dependencias entre términos. En este artículo, proponemos una técnica robusta de <br>expansión de consultas</br> basada en el modelo de campo aleatorio de Markov para la recuperación de información. La técnica, llamada expansión de conceptos latentes, proporciona un mecanismo para modelar las dependencias de términos durante la expansión. Además, el uso de características arbitrarias dentro del modelo proporciona un marco poderoso para ir más allá de las simples características de ocurrencia de términos que son utilizadas implícitamente por la mayoría de las otras técnicas de expansión. Evaluamos nuestra técnica frente a modelos de relevancia, una técnica de <br>expansión de consultas</br> de modelado de lenguaje de última generación. Nuestro modelo demuestra mejoras consistentes y significativas en la efectividad de recuperación en varios conjuntos de datos de TREC. También describimos cómo nuestra técnica puede ser utilizada para generar conceptos significativos de varios términos para tareas como sugerencia/reformulación de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales Algoritmos, Experimentación, Teoría 1. Los usuarios de los sistemas de recuperación de información deben expresar necesidades de información complejas en términos de expresiones booleanas, una lista corta de palabras clave, una oración, una pregunta o posiblemente un relato más extenso. Se pierde mucha información durante el proceso de traducción desde la necesidad de información hasta la consulta real. Por esta razón, ha habido un fuerte interés en las técnicas de <br>expansión de consultas</br>. Tales técnicas se utilizan para ampliar la consulta original y producir una representación que refleje mejor la necesidad de información subyacente. Las técnicas de <br>expansión de consultas</br> han sido ampliamente estudiadas para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la retroalimentación de pseudo-relevancia [12, 21, 28, 29]. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "mrf": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (<br>mrf</br>) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The <br>mrf</br> model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The <br>mrf</br> model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the <br>mrf</br> model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the <br>mrf</br> model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the <br>mrf</br> model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the <br>mrf</br> model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the <br>mrf</br> model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A <br>mrf</br> is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A <br>mrf</br> satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended <br>mrf</br> model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the <br>mrf</br> model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the <br>mrf</br> model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the <br>mrf</br> model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the <br>mrf</br> model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the <br>mrf</br> model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the <br>mrf</br> model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the <br>mrf</br> model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM <br>mrf</br> RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (<br>mrf</br>), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, <br>mrf</br>, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the <br>mrf</br> model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the <br>mrf</br> model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the <br>mrf</br> has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [
                "Recently, a Markov random field (<br>mrf</br>) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The <br>mrf</br> model generalizes the unigram, bigram, and other various dependence models [14].",
                "The <br>mrf</br> model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Therefore, by performing query expansion using the <br>mrf</br> model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the <br>mrf</br> model allows arbitrary features to be used within the model."
            ],
            "translated_annotated_samples": [
                "Recientemente, se propuso un modelo de <br>campo aleatorio de Markov</br> (MRF) para la recuperación de información que va más allá de la simplista suposición de bolsa de palabras que subyace en BM25 y en el enfoque de modelado de lenguaje (unigrama) para la recuperación de información [20, 22].",
                "El <br>modelo MRF</br> generaliza los modelos de unigrama, bigrama y otras diversas dependencias [14].",
                "El <br>modelo MRF</br>, sin embargo, ha demostrado ser altamente efectivo en una serie de tareas, incluyendo la recuperación ad hoc [14, 16], la búsqueda de páginas con nombres [16] y la búsqueda web en japonés [6].",
                "Por lo tanto, al realizar la expansión de consultas utilizando el <br>modelo MRF</br>, podemos estudiar la dinámica entre la dependencia de términos y la expansión de consultas.",
                "A continuación, como mostraremos, el <br>modelo MRF</br> permite que se utilicen características arbitrarias dentro del modelo."
            ],
            "translated_text": "Expansión de conceptos latentes utilizando campos aleatorios de Markov. Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Centro de Recuperación de Información Inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 RESUMEN La expansión de consultas, en forma de retroalimentación de pseudo relevancia o retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación. La mayoría de enfoques anteriores han ignorado problemas importantes, como el papel de las características y la importancia de modelar las dependencias entre términos. En este artículo, proponemos una técnica robusta de expansión de consultas basada en el modelo de campo aleatorio de Markov para la recuperación de información. La técnica, llamada expansión de conceptos latentes, proporciona un mecanismo para modelar las dependencias de términos durante la expansión. Además, el uso de características arbitrarias dentro del modelo proporciona un marco poderoso para ir más allá de las simples características de ocurrencia de términos que son utilizadas implícitamente por la mayoría de las otras técnicas de expansión. Evaluamos nuestra técnica frente a modelos de relevancia, una técnica de expansión de consultas de modelado de lenguaje de última generación. Nuestro modelo demuestra mejoras consistentes y significativas en la efectividad de recuperación en varios conjuntos de datos de TREC. También describimos cómo nuestra técnica puede ser utilizada para generar conceptos significativos de varios términos para tareas como sugerencia/reformulación de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales Algoritmos, Experimentación, Teoría 1. Los usuarios de los sistemas de recuperación de información deben expresar necesidades de información complejas en términos de expresiones booleanas, una lista corta de palabras clave, una oración, una pregunta o posiblemente un relato más extenso. Se pierde mucha información durante el proceso de traducción desde la necesidad de información hasta la consulta real. Por esta razón, ha habido un fuerte interés en las técnicas de expansión de consultas. Tales técnicas se utilizan para ampliar la consulta original y producir una representación que refleje mejor la necesidad de información subyacente. Las técnicas de expansión de consultas han sido ampliamente estudiadas para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la retroalimentación de pseudo-relevancia [12, 21, 28, 29]. Recientemente, se propuso un modelo de <br>campo aleatorio de Markov</br> (MRF) para la recuperación de información que va más allá de la simplista suposición de bolsa de palabras que subyace en BM25 y en el enfoque de modelado de lenguaje (unigrama) para la recuperación de información [20, 22]. El <br>modelo MRF</br> generaliza los modelos de unigrama, bigrama y otras diversas dependencias [14]. La mayoría de los modelos de dependencia de términos pasados no han logrado mostrar mejoras consistentes y significativas sobre las líneas de base de unigramas, con pocas excepciones [8]. El <br>modelo MRF</br>, sin embargo, ha demostrado ser altamente efectivo en una serie de tareas, incluyendo la recuperación ad hoc [14, 16], la búsqueda de páginas con nombres [16] y la búsqueda web en japonés [6]. Hasta ahora, el modelo ha sido utilizado únicamente para clasificar documentos en respuesta a una consulta dada. En este trabajo, mostramos cómo el modelo puede ser ampliado y utilizado para la expansión de consultas utilizando una técnica que llamamos expansión de conceptos latentes (LCE). Hay tres contribuciones principales de nuestro trabajo. Primero, LCE proporciona un mecanismo para combinar la dependencia de términos con la expansión de consultas. Las técnicas de expansión de consultas anteriores se basan en modelos de bolsa de palabras. Por lo tanto, al realizar la expansión de consultas utilizando el <br>modelo MRF</br>, podemos estudiar la dinámica entre la dependencia de términos y la expansión de consultas. A continuación, como mostraremos, el <br>modelo MRF</br> permite que se utilicen características arbitrarias dentro del modelo. ",
            "candidates": [],
            "error": [
                [
                    "campo aleatorio de Markov",
                    "modelo MRF",
                    "modelo MRF",
                    "modelo MRF",
                    "modelo MRF"
                ]
            ]
        },
        "rocchio algorithm": {
            "translated_key": "algoritmo de Rocchio",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the <br>rocchio algorithm</br> [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the <br>rocchio algorithm</br> [21]."
            ],
            "translated_annotated_samples": [
                "TRABAJO RELACIONADO Uno de los enfoques clásicos y más ampliamente utilizados para la expansión de consultas es el <br>algoritmo de Rocchio</br> [21]."
            ],
            "translated_text": "Expansión de conceptos latentes utilizando campos aleatorios de Markov. Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Centro de Recuperación de Información Inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 RESUMEN La expansión de consultas, en forma de retroalimentación de pseudo relevancia o retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación. La mayoría de enfoques anteriores han ignorado problemas importantes, como el papel de las características y la importancia de modelar las dependencias entre términos. En este artículo, proponemos una técnica robusta de expansión de consultas basada en el modelo de campo aleatorio de Markov para la recuperación de información. La técnica, llamada expansión de conceptos latentes, proporciona un mecanismo para modelar las dependencias de términos durante la expansión. Además, el uso de características arbitrarias dentro del modelo proporciona un marco poderoso para ir más allá de las simples características de ocurrencia de términos que son utilizadas implícitamente por la mayoría de las otras técnicas de expansión. Evaluamos nuestra técnica frente a modelos de relevancia, una técnica de expansión de consultas de modelado de lenguaje de última generación. Nuestro modelo demuestra mejoras consistentes y significativas en la efectividad de recuperación en varios conjuntos de datos de TREC. También describimos cómo nuestra técnica puede ser utilizada para generar conceptos significativos de varios términos para tareas como sugerencia/reformulación de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales Algoritmos, Experimentación, Teoría 1. Los usuarios de los sistemas de recuperación de información deben expresar necesidades de información complejas en términos de expresiones booleanas, una lista corta de palabras clave, una oración, una pregunta o posiblemente un relato más extenso. Se pierde mucha información durante el proceso de traducción desde la necesidad de información hasta la consulta real. Por esta razón, ha habido un fuerte interés en las técnicas de expansión de consultas. Tales técnicas se utilizan para ampliar la consulta original y producir una representación que refleje mejor la necesidad de información subyacente. Las técnicas de expansión de consultas han sido ampliamente estudiadas para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la retroalimentación de pseudo-relevancia [12, 21, 28, 29]. Recientemente, se propuso un modelo de campo aleatorio de Markov (MRF) para la recuperación de información que va más allá de la simplista suposición de bolsa de palabras que subyace en BM25 y en el enfoque de modelado de lenguaje (unigrama) para la recuperación de información [20, 22]. El modelo MRF generaliza los modelos de unigrama, bigrama y otras diversas dependencias [14]. La mayoría de los modelos de dependencia de términos pasados no han logrado mostrar mejoras consistentes y significativas sobre las líneas de base de unigramas, con pocas excepciones [8]. El modelo MRF, sin embargo, ha demostrado ser altamente efectivo en una serie de tareas, incluyendo la recuperación ad hoc [14, 16], la búsqueda de páginas con nombres [16] y la búsqueda web en japonés [6]. Hasta ahora, el modelo ha sido utilizado únicamente para clasificar documentos en respuesta a una consulta dada. En este trabajo, mostramos cómo el modelo puede ser ampliado y utilizado para la expansión de consultas utilizando una técnica que llamamos expansión de conceptos latentes (LCE). Hay tres contribuciones principales de nuestro trabajo. Primero, LCE proporciona un mecanismo para combinar la dependencia de términos con la expansión de consultas. Las técnicas de expansión de consultas anteriores se basan en modelos de bolsa de palabras. Por lo tanto, al realizar la expansión de consultas utilizando el modelo MRF, podemos estudiar la dinámica entre la dependencia de términos y la expansión de consultas. A continuación, como mostraremos, el modelo MRF permite que se utilicen características arbitrarias dentro del modelo. Las técnicas de expansión de consultas en el pasado solo han hecho uso implícito de características de ocurrencia de términos. Al utilizar conjuntos de características más robustos, es posible producir términos de expansión mejores que discriminan de manera más efectiva entre documentos relevantes y no relevantes. Finalmente, nuestro enfoque propuesto proporciona de manera fluida un mecanismo para generar conceptos de una sola y múltiples términos. La mayoría de las técnicas anteriores, por defecto, generan términos de forma independiente. Ha habido varios enfoques que hacen uso de conceptos generalizados, sin embargo, dichos enfoques fueron algo heurísticos y realizados fuera del modelo [19, 28]. Nuestro enfoque está motivado tanto formalmente como es una extensión natural del modelo subyacente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2 describimos enfoques relacionados de expansión de consultas. La sección 3 proporciona una visión general del modelo MRF y detalla nuestra técnica propuesta de expansión de conceptos latentes. En la Sección 4 evaluamos nuestro modelo propuesto y analizamos los resultados. Finalmente, la Sección 5 concluye el artículo y resume los principales resultados. 2. TRABAJO RELACIONADO Uno de los enfoques clásicos y más ampliamente utilizados para la expansión de consultas es el <br>algoritmo de Rocchio</br> [21]. El enfoque de Rocchio, que fue desarrollado dentro del modelo de espacio vectorial, reajusta el vector de consulta original moviendo los pesos hacia el conjunto de documentos relevantes o pseudo-relevantes y alejándolos de los documentos no relevantes. Desafortunadamente, no es posible aplicar formalmente el enfoque de Rocchio a un modelo de recuperación estadística, como el modelado del lenguaje para la recuperación de información. Se han desarrollado varias técnicas de expansión de consultas formalizadas para el marco de modelado de lenguaje, incluyendo el feedback basado en el modelo de Zhai y Lafferty y los modelos de relevancia de Lavrenko y Crofts [12, 29]. Ambos enfoques intentan utilizar documentos pseudo-relevantes o relevantes para estimar un modelo de consulta mejor. El feedback basado en modelos encuentra el modelo que mejor describe los documentos relevantes teniendo en cuenta un modelo de fondo (ruido). Esto separa el modelo de contenido del modelo de fondo. El modelo de contenido se interpola con el modelo de consulta original para formar la consulta ampliada. La otra técnica, modelos de relevancia, está más relacionada con nuestro trabajo. Por lo tanto, entramos en los detalles del modelo. Al igual que el feedback basado en modelos, los modelos de relevancia estiman un modelo de consulta mejorado. La única diferencia entre los dos enfoques es que los modelos de relevancia no modelan explícitamente los documentos relevantes o pseudo-relevantes. En cambio, ellos modelan una noción más generalizada de relevancia, como mostraremos ahora. Dada una consulta Q, un modelo de relevancia es una distribución multinomial, P(·|Q), que codifica la probabilidad de cada término dado la consulta como evidencia. Se calcula como: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) donde RQ es el conjunto de documentos que son relevantes o pseudo relevantes para la consulta Q. En el caso pseudo-relevante, estos son los documentos mejor clasificados para la consulta Q. Además, se asume que P(D) es uniforme en este conjunto. Estas suposiciones suaves hacen que el cálculo del posterior bayesiano sea más práctico. Después de que el modelo es estimado, los documentos son clasificados por recortar el modelo de relevancia al elegir los k términos más probables de P(·|Q). Esta distribución recortada se interpola luego con el modelo de consulta de máxima verosimilitud original. Esto se puede considerar como la expansión de la consulta original por k términos ponderados. A lo largo del resto de este trabajo, nos referimos a esta instancia de modelos de relevancia como RM3. Ha habido relativamente poco trabajo realizado en el área de expansión de consultas en el contexto de modelos de dependencia [9]. Sin embargo, ha habido varios intentos de expandir utilizando conceptos de varios términos. El método de análisis de contexto local (LCA) de Xu y Crofts combinaba la recuperación a nivel de pasaje con la expansión de conceptos, donde los conceptos eran términos y frases simples [28]. Los conceptos de expansión fueron elegidos y ponderados utilizando una métrica basada en estadísticas de co-ocurrencia. Sin embargo, no está claro, basándose en el análisis realizado, cuánto ayudaron las frases en comparación con los términos individuales solos. Papka y Allan investigan el uso de retroalimentación de relevancia para realizar la expansión de conceptos de varios términos en el enrutamiento de documentos [19]. Los conceptos utilizados en su trabajo son más generales que los utilizados en el LCA e incluyen estructuras de lenguaje de consulta InQuery, como #UW50(casa blanca), que corresponde al concepto en el que los términos casa y blanca ocurren, en cualquier orden, dentro de 50 términos uno del otro. Los resultados mostraron que combinar conceptos de un solo término y conceptos de varios términos con una ventana grande mejoró significativamente la efectividad. Sin embargo, no está claro si el mismo enfoque también es efectivo para la recuperación ad hoc, debido a las diferencias en las tareas. 3. Este apartado detalla nuestra técnica propuesta de expansión de conceptos latentes. Como se mencionó anteriormente, la técnica es una extensión del modelo MRF para la recuperación de información [14]. Por lo tanto, comenzamos proporcionando una visión general del modelo MRF y nuestras extensiones propuestas. 3.1 MRFs para IR 3.1.1 Conceptos básicos Los campos aleatorios de Markov, que son modelos gráficos no dirigidos, proporcionan una forma compacta y robusta de modelar una distribución conjunta. Aquí estamos interesados en modelar la distribución conjunta sobre una consulta Q = q1, . . . , qn y un documento D. Se asume que la distribución subyacente sobre pares de documentos y consultas es una distribución de relevancia. Es decir, muestrear de la distribución proporciona pares de documentos y consultas, de modo que el documento sea relevante para la consulta. Un MRF se define por un grafo G y un conjunto de funciones de potencial no negativas sobre los cliques en G. Los nodos en el grafo representan las variables aleatorias y las aristas definen la semántica de independencia de la distribución. Un MRF cumple con la propiedad de Markov, la cual establece que un nodo es independiente de todos sus nodos no vecinos dado los valores observados de sus vecinos. Dado un grafo G, un conjunto de potenciales ψi y un vector de parámetros Λ, la distribución conjunta sobre Q y D está dada por: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) donde Z es una constante de normalización. Seguimos la convención común y parametrizamos los potenciales como ψi(c; Λ) = exp[λifi(c)], donde fi(c) es una función de características de valores reales. 3.1.2 Construcción de G Dada una consulta Q, el grafo G puede ser construido de varias maneras. Sin embargo, siguiendo el trabajo previo, consideramos tres variantes simples [14]. Estas variantes son independencia total, donde cada término de consulta es independiente de los demás dado un documento, dependencia secuencial, que asume que existe una dependencia entre los términos de consulta adyacentes, y dependencia total, que no hace suposiciones de independencia. 3.1.3 Parametrización Los MRFs suelen ser parametrizados comúnmente en función de los cliques máximos de G. Sin embargo, dicha parametrización es demasiado gruesa para nuestras necesidades. Necesitamos una parametrización que nos permita asociar funciones de características con cliques a un nivel más detallado, manteniendo al mismo tiempo el número de características, y por lo tanto el número de parámetros, razonable. Por lo tanto, permitimos que los grupos compartan funciones de características y parámetros basados en conjuntos de grupos. Es decir, todos los subgrupos dentro de un conjunto de subgrupos están asociados con la misma función de característica y comparten un solo parámetro. Esto une de manera efectiva los parámetros de las características asociadas con cada conjunto, lo que reduce significativamente el número de parámetros mientras aún proporciona un mecanismo para el ajuste fino en el nivel de conjuntos de cliques. Proponemos siete conjuntos de cliques para utilizar en la recuperación de información. Los primeros tres conjuntos de cliques consisten en cliques que contienen uno o más términos de consulta y el nodo del documento. Las características sobre estos grupos deberían codificar qué tan bien los términos en la configuración del grupo describen el documento. Estos conjuntos son: • TD - conjunto de cliques que contienen el nodo del documento y exactamente un término de consulta. • OD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en orden secuencial dentro de la consulta. • UD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en cualquier orden dentro de la consulta. Ten en cuenta que UD es un superconjunto de OD. Al atar los parámetros entre los grupos dentro de cada conjunto podemos controlar cuánta influencia recibe cada tipo. Esto también evita el problema de tratar de determinar cómo estimar los pesos para cada clique dentro de los conjuntos. En cambio, ahora solo debemos estimar un parámetro por conjunto. A continuación, consideramos cliques que solo contienen nodos de términos de consulta. Estas cliques, que no fueron consideradas en [14], se definen de manera análoga a las recién definidas, excepto que las cliques solo están formadas por nodos de términos de consulta y no contienen el nodo de documento. Las funciones de características sobre estos conjuntos deben capturar qué tan compatibles son entre sí los términos de consulta. Estas características de grupo pueden adoptar la forma de modelos de lenguaje que imponen la corrección de los términos. Por lo tanto, definimos los siguientes conjuntos de cliques dependientes de la consulta: • TQ - conjunto de cliques que contienen exactamente un término de la consulta. • OQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en orden secuencial dentro de la consulta. • UQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en cualquier orden dentro de la consulta. Finalmente, está la clique que solo contiene el nodo del documento. Las características sobre este nodo pueden ser utilizadas como un tipo de documento previo, codificando propiedades centradas en el documento. Este conjunto de cliques trivial es entonces: • D - conjunto de cliques que contiene solo el nodo único D. Observamos que nuestros conjuntos de cliques forman una cobertura de conjuntos sobre los cliques de G, pero no son una partición, ya que algunos cliques aparecen en múltiples conjuntos de cliques. Después de atar los parámetros en nuestros conjuntos de cliques y usar la forma de la función potencial exponencial, terminamos con la siguiente forma simplificada de la distribución conjunta: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - dependiente del documento y la consulta + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - dependiente de la consulta + λDfD(D) FD(D) - dependiente del documento − log ZΛ documento + independiente de la consulta donde FDQ, FQ y FD son funciones de conveniencia definidas por los componentes dependientes del documento y la consulta, dependientes de la consulta y dependientes del documento de la distribución conjunta, respectivamente. Estos se utilizarán para simplificar y clarificar las expresiones derivadas a lo largo del resto del documento. 3.1.4 Características Cualquier función de característica arbitraria sobre configuraciones de cliques puede ser utilizada en el modelo. La elección correcta de las características depende en gran medida de la tarea de recuperación y la métrica de evaluación. Por lo tanto, es probable que no exista un conjunto único y universalmente aplicable de características. Para dar una idea de la variedad de características que se pueden utilizar, ahora describimos brevemente posibles tipos de características que podrían ser utilizadas. Posibles características dependientes del término de consulta incluyen tf, idf, entidades nombradas, proximidad de términos y estilo de texto, por nombrar algunas. Se pueden utilizar muchos tipos de características dependientes del documento, como la longitud del documento, el PageRank, la legibilidad y el género, entre otros. Dado que nuestro objetivo aquí no es encontrar características óptimas, utilizamos un conjunto simple y fijo de características que han demostrado ser efectivas en trabajos anteriores [14]. Consulte la Tabla 1 para ver la lista de características utilizadas. Estas características intentan capturar la ocurrencia de términos y la proximidad entre términos. Una mejor selección de características en el futuro probablemente conducirá a una mayor efectividad. 3.1.5 Clasificación Dada una consulta Q, deseamos clasificar los documentos en orden descendente según PG,Λ(D|Q). Después de eliminar las expresiones independientes del documento del registro PG,Λ(Q, D), derivamos la siguiente función de clasificación: PG,Λ(D|Q) rango = FDQ(D, Q) + FD(D) (2), que es una simple combinación lineal ponderada de funciones de características que pueden calcularse eficientemente para grafos razonables. 3.1.6 Estimación de Parámetros Ahora que el modelo ha sido completamente especificado, el paso final es estimar los parámetros del modelo. Aunque los MRF son modelos generativos, no es apropiado entrenarlos utilizando la función de valor de características fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Tabla 1: Funciones de características utilizadas en el modelo de campo aleatorio de Markov. Aquí, tfw,D es el número de veces que el término w ocurre en el documento D, tf#1(qi...qi+k),D denota el número de veces que la frase exacta qi . . . qi+k ocurre en el documento D, tf#uw(qi...qj ),D es el número de veces que los términos qi, . . . qj aparecen ordenados o desordenados dentro de una ventana de N términos, y |D| es la longitud del documento D. Los valores de cf y |C| se definen de manera análoga a nivel de colección. Finalmente, α y β son hiperparámetros del modelo que controlan el suavizado para las características de términos únicos y frases, respectivamente. Enfoques convencionales basados en la verosimilitud debido a la divergencia métrica [17]. Es decir, es poco probable que la estimación de máxima verosimilitud sea la estimación que maximiza nuestra métrica de evaluación. Por esta razón, entrenamos de manera discriminativa nuestro modelo para maximizar directamente la métrica de evaluación considerada [14, 15, 25]. Dado que nuestro espacio de parámetros es pequeño, hacemos uso de una estrategia simple de escalada de colina, aunque son posibles otros enfoques más sofisticados [10]. 3.2 Expansión de Conceptos Latentes En esta sección describimos cómo este modelo MRF extendido puede ser utilizado de una manera novedosa para generar conceptos de un solo término y de varios términos que están relacionados temáticamente con alguna consulta original. Como mostraremos, los conceptos generados utilizando nuestra técnica pueden ser utilizados para la expansión de consultas u otras tareas, como sugerir formulaciones alternativas de consultas. Suponemos que cuando un usuario formula su consulta original, tiene en mente un conjunto de conceptos, pero solo puede expresar un pequeño número de ellos en forma de consulta. Tratamos los conceptos que el usuario tiene en mente, pero no expresó explícitamente en la consulta, como conceptos latentes. Estos conceptos latentes pueden consistir en un solo término, varios términos o alguna combinación de ambos. Por lo tanto, nuestro objetivo es recuperar estos conceptos latentes dada alguna consulta original. Esto se puede lograr dentro de nuestro marco de trabajo al expandir primero el grafo original G para incluir el tipo de concepto que nos interesa generar. Llamamos a este gráfico expandido H. En la Figura 1, el gráfico del medio proporciona un ejemplo de cómo construir un gráfico expandido que puede generar conceptos de un solo término. De manera similar, el gráfico de la derecha ilustra un gráfico ampliado que genera dos conceptos de términos. Aunque estos dos ejemplos hacen uso de la suposición de dependencia secuencial (es decir, dependencias entre términos de consulta adyacentes), es importante tener en cuenta que tanto la consulta original como los conceptos de expansión pueden utilizar cualquier estructura de independencia. Después de que H se construye, calculamos PH,Λ(E|Q), una distribución de probabilidad sobre conceptos latentes, de acuerdo a: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) donde R es el universo de todos los documentos posibles y E es un concepto latente que puede consistir en uno o más términos. Dado que no es práctico calcular esta suma, debemos aproximarla. Observamos que PH,Λ(Q, E, D) probablemente se concentra alrededor de aquellos documentos D que están altamente clasificados según la consulta Q. Por lo tanto, aproximamos PH,Λ(E|Q) sumando solo un pequeño subconjunto de documentos relevantes o pseudo-relevantes para la consulta Q. Esto se calcula de la siguiente manera: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) donde RQ es un conjunto de documentos relevantes o pseudo-relevantes para la consulta Q y todos los conjuntos de cliques se construyen utilizando H. Como vemos, la contribución de probabilidad para cada documento en RQ es una combinación de la puntuación original de la consulta para el documento (ver Ecuación 2), la puntuación del concepto E para el documento y la puntuación independiente del documento de E. Por lo tanto, esta ecuación puede interpretarse como la medida de qué tan bien Q y E explican los documentos mejor clasificados y la bondad de E, independientemente de los documentos. Para lograr la máxima robustez, utilizamos un conjunto diferente de parámetros para FQD(Q, D) y FQD(E, D), lo que nos permite ponderar de manera diferente las características de ventana ordenadas y no ordenadas para la consulta original y el concepto de expansión candidato. 3.2.1 Expansión de consulta Para utilizar este marco para la expansión de consultas, primero elegimos un grafo de expansión H que codifique la estructura de concepto latente en la que estamos interesados en expandir la consulta. Luego seleccionamos los k conceptos latentes con la mayor probabilidad dada por la Ecuación 3. Se construye un nuevo grafo G al aumentar el grafo original G con los k conceptos de expansión E1, . . . , Ek. Finalmente, los documentos se clasifican según PG ,Λ(D|Q, E1, . . . , Ek) utilizando la Ecuación 2. 3.2.2 Comparación con los Modelos de Relevancia. Al inspeccionar las Ecuaciones 1 y 3 se revela la estrecha conexión que existe entre LCE y los modelos de relevancia. Ambos modelos esencialmente calculan la probabilidad de un término (o concepto) de la misma manera. Es fácil ver que al igual que el modelo MRF puede ser visto como una generalización del modelado del lenguaje, también LCE puede ser visto como una generalización de los modelos de relevancia. Existen diferencias importantes entre los modelos de lenguaje MRFs/LCE y los modelos de lenguaje unigram/relevancia. Consulte la Figura 1 para ver las representaciones gráficas de ambos modelos. Los modelos de lenguaje unigrama y los modelos de relevancia se basan en la distribución multinomial. Esta suposición de distribución encasilla el modelo en la representación de bolsa de palabras y el uso implícito de características de ocurrencia de términos. Sin embargo, la distribución subyacente al modelo MRF nos permite ir más allá de ambas suposiciones, al modelar tanto las dependencias entre los términos de consulta como permitir el uso explícito de características arbitrarias. Ir más allá de la simplista suposición de la bolsa de palabras de esta manera resulta en un modelo general y robusto y, como mostramos en la siguiente sección, se traduce en mejoras significativas en la efectividad de recuperación. 4. RESULTADOS EXPERIMENTALES Para comprender mejor las fortalezas y debilidades de nuestra técnica, la evaluamos en una amplia gama de conjuntos de datos. La Tabla 2 proporciona un resumen de los conjuntos de datos de TREC considerados. Las colecciones WSJ, AP y ROBUST son más pequeñas y consisten enteramente de artículos de agencias de noticias, mientras que WT10g y GOV2 son colecciones web grandes. Para cada conjunto de datos, dividimos los temas disponibles en un conjunto de entrenamiento y otro de prueba, donde el conjunto de entrenamiento se utiliza únicamente para la estimación de parámetros y el conjunto de prueba se utiliza con fines de evaluación. Todos los experimentos se llevaron a cabo utilizando una versión modificada de Indri, que forma parte del Lemur Toolkit [18, 23]. Todas las colecciones fueron detenidas utilizando una lista estándar de 418 términos comunes y truncadas utilizando un truncador de Porter. En todos los casos, solo se utiliza la parte del título de los temas de TREC para construir las consultas. Construimos G utilizando la suposición de dependencia secuencial para todos los conjuntos de datos [14]. 4.1 Resultados de recuperación ad-hoc Ahora investigamos qué tan bien se desempeña nuestro modelo en la práctica en un entorno de retroalimentación de relevancia pseudo. Comparamos el modelado de lenguaje unigrama (con suavizado de Dirichlet), el modelo MRF (sin expansión), los modelos de relevancia y LCE para comprender mejor cómo se desempeña cada modelo en los diferentes conjuntos de datos. Para el modelo de lenguaje unigrama, se entrenó el parámetro de suavizado. Para el modelo MRF, entrenamos los parámetros del modelo (es decir, y hiperparámetros del modelo (es decir, α, β). Para RM3 y LCE, también entrenamos el número de pseudoNombre Descripción # Docs Temas de Entrenamiento Temas de Prueba WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc. Presione 88-90 242,918 51-150 151-200 ROBUST Robust 2004 datos 528,155 301-450 601-700 WT10g Colección Web de TREC 1,692,096 451-500 501-550 GOV2 Rastreo 2004 del dominio .gov 25,205,179 701-750 751-800 Tabla 2: Resumen de las colecciones y temas de TREC. documentos de retroalimentación relevantes utilizados y el número de términos de expansión. 4.1.1 Expansión con Conceptos de Términos Únicos Comenzamos evaluando qué tan bien funciona nuestro modelo al expandir utilizando solo términos individuales. Antes de describir y analizar los resultados, declaramos explícitamente cómo se calculan las probabilidades de términos de expansión bajo esta configuración (es decir, utilizando la suposición de dependencia secuencial, expandiendo con conceptos de un solo término y utilizando nuestro conjunto de características). Las probabilidades de términos de expansión se calculan de la siguiente manera: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) donde b ∈ Q denota el conjunto de bigramas en Q. Esta ecuación muestra claramente cómo LCE difiere de los modelos de relevancia. Cuando establecemos λTD = λT,D = 1 y todos los demás parámetros en 0, obtenemos la fórmula exacta que se utiliza para calcular las probabilidades de términos en el marco de modelado de relevancia. Por lo tanto, LCE añade dos factores muy importantes a la ecuación. Primero, agrega las características de ventana ordenadas y no ordenadas que se aplican a la consulta original. En segundo lugar, aplica una forma intuitiva similar a tf.idf al término de expansión candidato w. El factor idf, que no está presente en los modelos de relevancia, juega un papel importante en la selección del término de expansión. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figura 2: Histogramas que demuestran y comparan la robustez de los modelos de relevancia (RM3) y la expansión de conceptos latentes (LCE) con respecto al modelo de probabilidad de consulta (QL) para los conjuntos de datos AP, ROBUST y WT10G. Los resultados, evaluados utilizando la precisión promedio media, se muestran en la Tabla 3. Como vemos, el modelo MRF, los modelos de relevancia y LCE siempre superan significativamente al modelo de lenguaje unigrama. Además, LCE muestra mejoras significativas sobre los modelos de relevancia en todos los conjuntos de datos. Las mejoras relativas sobre los modelos de relevancia son del 6.9% para AP, 12.9% para WSJ, 6.5% para ROBUST, 16.7% para WT10G y 7.3% para GOV2. Además, LCE muestra pequeñas mejoras, pero no significativas, respecto al modelado de relevancia para métricas como precisión en 5, 10 y 20. Sin embargo, tanto el modelado de relevancia como el LCE muestran mejoras estadísticamente significativas en dichas métricas sobre el modelo de lenguaje unigrama. Otro resultado interesante es que el modelo MRF es estadísticamente equivalente a los modelos de relevancia en los dos conjuntos de datos web. De hecho, el modelo MRF supera a los modelos de relevancia en el conjunto de datos WT10g. Esto reitera la importancia de las características no unigrama, basadas en la proximidad para la búsqueda web basada en contenido observada previamente [14, 16]. Aunque nuestro modelo tiene más parámetros libres que los modelos de relevancia, sorprendentemente hay poco sobreajuste. En cambio, el modelo muestra buenas propiedades de generalización. 4.1.2 Expansión con Conceptos de Múltiples Términos También investigamos la expansión utilizando conceptos de una y dos palabras. Para cada consulta, expandimos utilizando un conjunto de conceptos de un solo término y un conjunto de conceptos de dos términos. Los conjuntos fueron elegidos de forma independiente. Desafortunadamente, solo se observaron aumentos insignificantes en la precisión promedio. Este resultado puede deberse al hecho de que existen fuertes correlaciones entre los conceptos de expansión de términos individuales. Descubrimos que los dos conceptos de palabras elegidos a menudo consistían en dos términos altamente correlacionados que también son elegidos como conceptos de términos individuales. Por ejemplo, se eligió el concepto de dos términos mercado de valores, mientras que también se eligieron los conceptos de un solo término acciones y mercado. Por lo tanto, muchos conceptos de dos palabras es poco probable que aumenten el poder discriminativo de la consulta ampliada. Este resultado sugiere que los conceptos deben ser elegidos de acuerdo con ciertos criterios que también tengan en cuenta la novedad, la diversidad o las correlaciones de términos. Otro problema potencial es el conjunto de características utilizado. Otros conjuntos de características pueden dar resultados diferentes en última instancia, especialmente si reducen la correlación entre los conceptos de expansión. Por lo tanto, nuestros experimentos no arrojan resultados concluyentes en cuanto a la expansión utilizando conceptos de varios términos. En cambio, los resultados plantean preguntas abiertas interesantes y direcciones para futuras exploraciones. Tabla 3: Promedio de precisión media en el conjunto de pruebas para modelado de lenguaje (LM), campo aleatorio de Markov (MRF), modelos de relevancia (RM3) y expansión de conceptos latentes (LCE). Los superíndices α, β y γ indican mejoras estadísticamente significativas (p < 0.05) sobre LM, MRF y RM3, respectivamente. 4.2 Robustez Como hemos demostrado, los modelos de relevancia y la expansión de conceptos latentes pueden mejorar significativamente la efectividad de recuperación sobre el modelo de probabilidad de consulta base. En esta sección analizamos la robustez de estos dos métodos. Aquí definimos la robustez como el número de consultas cuya efectividad se ve mejorada/afectada (y en qué medida) como resultado de aplicar estos métodos. Una técnica de expansión altamente robusta mejorará significativamente muchas consultas y solo perjudicará mínimamente a unas pocas. La Figura 2 proporciona un análisis de la robustez del modelado de relevancia y la expansión de conceptos latentes para los conjuntos de datos AP, ROBUST y WT10G. El análisis de los dos conjuntos de datos no mostrados es similar. Los histogramas proporcionan, para varios rangos de disminuciones/aumentos relativos en la precisión media promedio, el número de consultas que se vieron perjudicadas/mejoradas con respecto a la línea base de probabilidad de consulta. Como muestran los resultados, LCE muestra una fuerte robustez para cada conjunto de datos. Para AP, los modelos de relevancia mejoran 38 consultas y perjudican 11, mientras que LCE mejora 35 y perjudica 14. Aunque los modelos de relevancia mejoran la efectividad de 3 consultas más que LCE, la mejora relativa exhibida por LCE es significativamente mayor. Para el conjunto de datos ROBUST, los modelos de relevancia mejoran 67 consultas y perjudican 32, y LCE mejora 77 y perjudica 22. Finalmente, para la colección WT10G, los modelos de relevancia mejoran 32 consultas y perjudican 16, y LCE mejora 35 y perjudica 14. Al igual que con AP, la cantidad de mejora exhibida por el LCE frente a los modelos de relevancia es significativamente mayor tanto para los conjuntos de datos ROBUST como WT10G. Además, cuando LCE afecta al rendimiento, es menos probable que afecte tanto como el modelado de relevancia, lo cual es una propiedad deseable. En general, LCE mejora la efectividad para el 65%-80% de las consultas, dependiendo del conjunto de datos. Cuando se utiliza en combinación con un sistema de predicción de rendimiento de consulta altamente preciso, puede ser posible expandir selectivamente las consultas y minimizar la pérdida asociada con el rendimiento sub-baseline. 4.3 Generación de Conceptos de Múltiples Términos Aunque encontramos que la expansión utilizando conceptos de múltiples términos no logró producir mejoras concluyentes en la efectividad, hay otras tareas potenciales para las cuales estos conceptos pueden ser útiles, como sugerencia/reformulación de consultas, resumen y extracción de conceptos. Por ejemplo, para una tarea de sugerencia de consultas, la consulta original podría usarse para generar un conjunto de conceptos latentes que corresponden a formulaciones alternativas de la consulta. Aunque evaluar nuestro modelo en estas tareas está fuera del alcance de este trabajo, deseamos mostrar un ejemplo ilustrativo de los tipos de conceptos generados utilizando nuestro modelo. En la Tabla 4, presentamos los conceptos de una, dos y tres palabras más probables generados utilizando LCE para la consulta logros del telescopio Hubble utilizando los 25 documentos mejor clasificados de la colección ROBUST. Es bien sabido que generar conceptos de múltiples términos utilizando un modelo basado en unigramas produce resultados insatisfactorios, ya que no considera las dependencias entre los términos. Esto no es el caso al generar conceptos de múltiples términos usando nuestro modelo. En cambio, la mayoría de los conceptos generados son bien formados y significativos. Hay varios casos donde los conceptos son menos coherentes, como espejo espejo espejo. En este caso, la probabilidad de que aparezca el término \"espejo\" en un documento pseudo-relevante supera a las características de modelado de lenguaje (por ejemplo, fOQ), lo que provoca que este concepto no coherente tenga una alta probabilidad. Tales ejemplos son minoría, sin embargo. No solo los conceptos generados son bien formados y significativos, sino que también son relevantes al tema de la consulta original. Como podemos ver, todos los conceptos generados están relacionados con el tema y de alguna manera están relacionados con el telescopio Hubble. Es interesante ver que el concepto de fallo del telescopio Hubble es uno de los tres conceptos de términos más probables, dado que es algo contradictorio con la consulta original. A pesar de esta contradicción, es probable que los documentos que discuten las fallas del telescopio también describan los éxitos, por lo tanto, es probable que este sea un concepto significativo. Una cosa importante a tener en cuenta es que los conceptos generados por LCE son de una naturaleza diferente a los que se generarían utilizando un modelo de relevancia de bigrama. Por ejemplo, un modelo de bigrama sería poco probable que genere el concepto telescopio espacio NASA, ya que ninguno de los bigramas que componen el concepto tiene una alta probabilidad. Sin embargo, dado que nuestro modelo se basa en una serie de características diferentes sobre varios tipos de cliques, es más general y robusto que un modelo de bigrama. Aunque solo proporcionamos los conceptos generados para una sola consulta, señalamos que el mismo análisis y conclusiones se generalizan a través de otros conjuntos de datos, con conceptos coherentes y relacionados temáticamente generados de manera consistente utilizando LCE. 4.4 Discusión Nuestra técnica de expansión de conceptos latentes captura dos tipos de dependencia semiortogonales. En la recuperación de información, ha existido un interés a largo plazo en comprender el papel de la dependencia de términos. De esta investigación, se han identificado dos tipos generales de dependencias. El primer tipo de dependencia es la dependencia sintáctica. Este tipo de dependencia abarca frases, proximidad de términos y co-ocurrencia de términos [2, 4, 5, 7, 26]. Estos métodos capturan el hecho de que las consultas imponen implícita o explícitamente un cierto conjunto de dependencias posicionales. El segundo tipo es la dependencia semántica. Ejemplos de dependencia semántica son la retroalimentación de relevancia, la retroalimentación de pseudo-relevancia, sinónimos y en cierta medida el truncamiento [3]. Estas técnicas han sido exploradas tanto en el lado de la consulta como en el lado del documento. En el lado de la consulta, esto se suele hacer utilizando alguna forma de expansión de consulta, como modelos de relevancia o LCE. En el lado del documento, esto se hace como expansión de documentos o suavizado de documentos [11, 13, 24]. Aunque puede haber cierta superposición entre las dependencias sintácticas y semánticas, en su mayoría son ortogonales. Nuestro modelo utiliza ambos tipos de dependencias. El uso de características de frase y proximidad dentro del modelo captura dependencias sintácticas, mientras que LCE captura dependencias semánticas del lado de la consulta. Esto explica por qué la mejora inicial en la efectividad lograda al usar el modelo MRF no se pierde después de la expansión de consultas. Si los mismos tipos de dependencias fueran capturados tanto por dependencias sintácticas como semánticas, se esperaría que LCE funcionara aproximadamente igual de bien que los modelos de relevancia. Por lo tanto, al modelar ambos tipos de dependencias, observamos un efecto aditivo en lugar de un efecto absorbente. Una área interesante de trabajo futuro es determinar si modelar las dependencias semánticas del lado del documento puede aportar algo al modelo. Resultados previos que han combinado dependencias semánticas del lado de la consulta y del documento han mostrado resultados mixtos [13, 27]. 5. CONCLUSIONES En este artículo propusimos una técnica robusta de expansión de consultas llamada expansión de conceptos latentes. La técnica se demostró ser una extensión natural del modelo de campo aleatorio de Markov para la recuperación de información y una generalización de los modelos de relevancia. LCE es novedoso en el sentido de que realiza una expansión de un solo término o de varios términos dentro de un marco que permite el modelado de dependencias entre términos y el uso de características arbitrarias, mientras que trabajos anteriores se basaban en la suposición de la bolsa de palabras y características de ocurrencia de términos. Mostramos que la técnica puede ser utilizada para producir conceptos de expansión de varios términos de alta calidad, bien formados y relevantes desde el punto de vista temático. Los conceptos generados pueden ser utilizados en un módulo de sugerencia de consultas alternativas. También demostramos que el modelo es altamente efectivo. De hecho, logra mejoras significativas en la precisión promedio media en comparación con los modelos de relevancia en una selección de conjuntos de datos de TREC. También se demostró que el modelo MRF por sí solo, sin ninguna expansión de consulta, supera a los modelos de relevancia en grandes conjuntos de datos web. Esto reafirma observaciones previas de que modelar dependencias a través del uso de características de proximidad dentro del MRF tiene un mayor impacto en colecciones más grandes y ruidosas que en colecciones más pequeñas y bien comportadas. Finalmente, reiteramos la importancia de elegir términos de expansión que modelen la relevancia, en lugar de los documentos relevantes, y mostramos cómo LCE captura tanto las dependencias sintácticas como semánticas del lado de la consulta. El trabajo futuro se centrará en incorporar dependencias del lado del documento también. Agradecimientos Este trabajo fue apoyado en parte por el Centro de Recuperación de Información Inteligente, en parte por la subvención NSF #CNS-0454018, en parte por ARDA y la subvención NSF #CCF-0205575, y en parte por Microsoft Live Labs. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son responsabilidad del autor o los autores y no necesariamente reflejan las del patrocinador.  REFERENCIAS [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker y C. Wade. UMass en TREC 2004: Novedad y DIFICULTAD. En Actas en línea de la Conferencia de Recuperación de Información de 2004, 2004. [2] C. L. A. Clarke y G. V. Cormack. Recuperación y clasificación de la subcadena más corta. ACM Trans. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate to Spanish? Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson y J. Callan. Expansión de consultas utilizando modelos de caminata aleatoria. En Proc. 14th Intl. Conf. sobre Gestión de Información y Conocimiento, páginas 704-711, 2005. [4] W. B. Croft. Consultas booleanas y dependencias de términos en modelos de recuperación probabilística. Revista de la Sociedad Americana de Ciencia de la Información, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle y D. Lewis. El uso de frases y consultas estructuradas en la recuperación de información. En Proc. 14º Anu. Internacional. Conferencia ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 32-45, 1991. [6] K. Eguchi. Experimentos de expansión de consultas NTCIR-5 utilizando modelos de dependencia de términos. En Actas del Quinto Taller de Reunión NTCIR sobre Evaluación de Tecnologías de Acceso a la Información, páginas 494-501, 2005. [7] J. Fagan. Indexación automática de frases para la recuperación de documentos: Un examen de métodos sintácticos y no sintácticos. En el Proc. décimo anual. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 91-101, 1987. [8] J. Gao, J. Nie, G. Wu y G. Cao. Modelo de lenguaje de dependencia para recuperación de información. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 170-177, 2004. [9] D. Harper y C. J. van Rijsbergen. Una evaluación de la retroalimentación en la recuperación de documentos utilizando datos de co-ocurrencia. Revista de Documentación, 34(3):189-216, 1978. [10] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Proc. de la Conf. Internacional de Aprendizaje Automático, páginas 377-384, 2005. [11] O. Kurland y L. Lee. Estructura del corpus, modelos de lenguaje y recuperación de información ad-hoc. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 194-201, 2004. [12] V. Lavrenko y W. B. Croft. Modelos de lenguaje basados en relevancia. En Proc. 24º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 120-127, 2001. [13] X. Liu y W. B. Croft. Recuperación basada en clústeres utilizando modelos de lenguaje. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 186-193, 2004. [14] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias entre términos. En Proc. 28vo Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [15] D. Metzler y W. B. Croft. Modelos basados en características lineales para la recuperación de información. Recuperación de información, por aparecer, 2006. [16] D. Metzler, T. Strohman, Y. Zhou y W. B. Croft. Indri en la pista de terabyte en 2005. En Actas en línea de la Conferencia de Recuperación de Texto de 2005, 2005. [17] W. Morgan, W. Greiff y J. Henderson. Maximización directa de la precisión promedio mediante escalada de colina con una comparación con un enfoque de entropía máxima. Informe técnico, MITRE, 2004. [18] P. Ogilvie y J. P. Callan. Experimentos utilizando el kit de herramientas de lémures. En Proc. de la Conferencia de Recuperación de Texto, 2001. [19] R. Papka y J. Allan. Por qué las ventanas más grandes son mejores que las más pequeñas. Informe técnico, Universidad de Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu y M. Gatford. Okapi en trec-3. En Actas en línea de la Tercera Conferencia de Recuperación de Texto, páginas 109-126, 1995. [21] J. J. Rocchio. Retroalimentación de relevancia en la recuperación de información, páginas 313-323. Prentice-Hall, 1971. [22] F. Song y W. B. Croft. Un modelo de lenguaje general para la recuperación de información. En Proc. octava conferencia internacional sobre Gestión de la Información y el Conocimiento (CIKM 99), páginas 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle y W. B. Croft. Indri: Un motor de búsqueda basado en modelos de lenguaje para consultas complejas. En Actas de la Conferencia Internacional sobre Análisis de Inteligencia, 2004. [24] T. Tao, X. Wang, Q. Mei y C. Zhai. Recuperación de información del modelo de lenguaje con expansión de documentos. En Proc. de HLT/NAACL, páginas 407-414, 2006. [25] B. Taskar, C. Guestrin y D. Koller. Redes de Markov de margen máximo. En Proc. de Avances en Sistemas de Información Neural (NIPS 2003), 2003. [26] C. J. van Rijsbergen. Una base teórica para el uso de datos de coocurrencia en la recuperación de información. Revista de Documentación, 33(2):106-119, 1977. [27] X. Wei y W. B. Croft. Modelos de documentos basados en LDA para recuperación ad-hoc. En Proc. 29º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 178-185, 2006. [28] J. Xu y W. B. Croft. Mejorando la efectividad de la recuperación de información con análisis de contexto local. ACM Trans. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate into Spanish? Syst., 18(1):79-112, 2000. [29] C. Zhai y J. Lafferty. Retroalimentación basada en modelos en el enfoque de modelado del lenguaje para la recuperación de información. En Proc. 10th Intl. Conferencia sobre Gestión de la Información y el Conocimiento, páginas 403-410, 2001. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "language modeling framework": {
            "translated_key": "marco de modelado de lenguaje",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the <br>language modeling framework</br>, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [
                "A number of formalized query expansion techniques have been developed for the <br>language modeling framework</br>, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29]."
            ],
            "translated_annotated_samples": [
                "Se han desarrollado varias técnicas de expansión de consultas formalizadas para el <br>marco de modelado de lenguaje</br>, incluyendo el feedback basado en el modelo de Zhai y Lafferty y los modelos de relevancia de Lavrenko y Crofts [12, 29]."
            ],
            "translated_text": "Expansión de conceptos latentes utilizando campos aleatorios de Markov. Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Centro de Recuperación de Información Inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 RESUMEN La expansión de consultas, en forma de retroalimentación de pseudo relevancia o retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación. La mayoría de enfoques anteriores han ignorado problemas importantes, como el papel de las características y la importancia de modelar las dependencias entre términos. En este artículo, proponemos una técnica robusta de expansión de consultas basada en el modelo de campo aleatorio de Markov para la recuperación de información. La técnica, llamada expansión de conceptos latentes, proporciona un mecanismo para modelar las dependencias de términos durante la expansión. Además, el uso de características arbitrarias dentro del modelo proporciona un marco poderoso para ir más allá de las simples características de ocurrencia de términos que son utilizadas implícitamente por la mayoría de las otras técnicas de expansión. Evaluamos nuestra técnica frente a modelos de relevancia, una técnica de expansión de consultas de modelado de lenguaje de última generación. Nuestro modelo demuestra mejoras consistentes y significativas en la efectividad de recuperación en varios conjuntos de datos de TREC. También describimos cómo nuestra técnica puede ser utilizada para generar conceptos significativos de varios términos para tareas como sugerencia/reformulación de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales Algoritmos, Experimentación, Teoría 1. Los usuarios de los sistemas de recuperación de información deben expresar necesidades de información complejas en términos de expresiones booleanas, una lista corta de palabras clave, una oración, una pregunta o posiblemente un relato más extenso. Se pierde mucha información durante el proceso de traducción desde la necesidad de información hasta la consulta real. Por esta razón, ha habido un fuerte interés en las técnicas de expansión de consultas. Tales técnicas se utilizan para ampliar la consulta original y producir una representación que refleje mejor la necesidad de información subyacente. Las técnicas de expansión de consultas han sido ampliamente estudiadas para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la retroalimentación de pseudo-relevancia [12, 21, 28, 29]. Recientemente, se propuso un modelo de campo aleatorio de Markov (MRF) para la recuperación de información que va más allá de la simplista suposición de bolsa de palabras que subyace en BM25 y en el enfoque de modelado de lenguaje (unigrama) para la recuperación de información [20, 22]. El modelo MRF generaliza los modelos de unigrama, bigrama y otras diversas dependencias [14]. La mayoría de los modelos de dependencia de términos pasados no han logrado mostrar mejoras consistentes y significativas sobre las líneas de base de unigramas, con pocas excepciones [8]. El modelo MRF, sin embargo, ha demostrado ser altamente efectivo en una serie de tareas, incluyendo la recuperación ad hoc [14, 16], la búsqueda de páginas con nombres [16] y la búsqueda web en japonés [6]. Hasta ahora, el modelo ha sido utilizado únicamente para clasificar documentos en respuesta a una consulta dada. En este trabajo, mostramos cómo el modelo puede ser ampliado y utilizado para la expansión de consultas utilizando una técnica que llamamos expansión de conceptos latentes (LCE). Hay tres contribuciones principales de nuestro trabajo. Primero, LCE proporciona un mecanismo para combinar la dependencia de términos con la expansión de consultas. Las técnicas de expansión de consultas anteriores se basan en modelos de bolsa de palabras. Por lo tanto, al realizar la expansión de consultas utilizando el modelo MRF, podemos estudiar la dinámica entre la dependencia de términos y la expansión de consultas. A continuación, como mostraremos, el modelo MRF permite que se utilicen características arbitrarias dentro del modelo. Las técnicas de expansión de consultas en el pasado solo han hecho uso implícito de características de ocurrencia de términos. Al utilizar conjuntos de características más robustos, es posible producir términos de expansión mejores que discriminan de manera más efectiva entre documentos relevantes y no relevantes. Finalmente, nuestro enfoque propuesto proporciona de manera fluida un mecanismo para generar conceptos de una sola y múltiples términos. La mayoría de las técnicas anteriores, por defecto, generan términos de forma independiente. Ha habido varios enfoques que hacen uso de conceptos generalizados, sin embargo, dichos enfoques fueron algo heurísticos y realizados fuera del modelo [19, 28]. Nuestro enfoque está motivado tanto formalmente como es una extensión natural del modelo subyacente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2 describimos enfoques relacionados de expansión de consultas. La sección 3 proporciona una visión general del modelo MRF y detalla nuestra técnica propuesta de expansión de conceptos latentes. En la Sección 4 evaluamos nuestro modelo propuesto y analizamos los resultados. Finalmente, la Sección 5 concluye el artículo y resume los principales resultados. 2. TRABAJO RELACIONADO Uno de los enfoques clásicos y más ampliamente utilizados para la expansión de consultas es el algoritmo de Rocchio [21]. El enfoque de Rocchio, que fue desarrollado dentro del modelo de espacio vectorial, reajusta el vector de consulta original moviendo los pesos hacia el conjunto de documentos relevantes o pseudo-relevantes y alejándolos de los documentos no relevantes. Desafortunadamente, no es posible aplicar formalmente el enfoque de Rocchio a un modelo de recuperación estadística, como el modelado del lenguaje para la recuperación de información. Se han desarrollado varias técnicas de expansión de consultas formalizadas para el <br>marco de modelado de lenguaje</br>, incluyendo el feedback basado en el modelo de Zhai y Lafferty y los modelos de relevancia de Lavrenko y Crofts [12, 29]. Ambos enfoques intentan utilizar documentos pseudo-relevantes o relevantes para estimar un modelo de consulta mejor. El feedback basado en modelos encuentra el modelo que mejor describe los documentos relevantes teniendo en cuenta un modelo de fondo (ruido). Esto separa el modelo de contenido del modelo de fondo. El modelo de contenido se interpola con el modelo de consulta original para formar la consulta ampliada. La otra técnica, modelos de relevancia, está más relacionada con nuestro trabajo. Por lo tanto, entramos en los detalles del modelo. Al igual que el feedback basado en modelos, los modelos de relevancia estiman un modelo de consulta mejorado. La única diferencia entre los dos enfoques es que los modelos de relevancia no modelan explícitamente los documentos relevantes o pseudo-relevantes. En cambio, ellos modelan una noción más generalizada de relevancia, como mostraremos ahora. Dada una consulta Q, un modelo de relevancia es una distribución multinomial, P(·|Q), que codifica la probabilidad de cada término dado la consulta como evidencia. Se calcula como: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) donde RQ es el conjunto de documentos que son relevantes o pseudo relevantes para la consulta Q. En el caso pseudo-relevante, estos son los documentos mejor clasificados para la consulta Q. Además, se asume que P(D) es uniforme en este conjunto. Estas suposiciones suaves hacen que el cálculo del posterior bayesiano sea más práctico. Después de que el modelo es estimado, los documentos son clasificados por recortar el modelo de relevancia al elegir los k términos más probables de P(·|Q). Esta distribución recortada se interpola luego con el modelo de consulta de máxima verosimilitud original. Esto se puede considerar como la expansión de la consulta original por k términos ponderados. A lo largo del resto de este trabajo, nos referimos a esta instancia de modelos de relevancia como RM3. Ha habido relativamente poco trabajo realizado en el área de expansión de consultas en el contexto de modelos de dependencia [9]. Sin embargo, ha habido varios intentos de expandir utilizando conceptos de varios términos. El método de análisis de contexto local (LCA) de Xu y Crofts combinaba la recuperación a nivel de pasaje con la expansión de conceptos, donde los conceptos eran términos y frases simples [28]. Los conceptos de expansión fueron elegidos y ponderados utilizando una métrica basada en estadísticas de co-ocurrencia. Sin embargo, no está claro, basándose en el análisis realizado, cuánto ayudaron las frases en comparación con los términos individuales solos. Papka y Allan investigan el uso de retroalimentación de relevancia para realizar la expansión de conceptos de varios términos en el enrutamiento de documentos [19]. Los conceptos utilizados en su trabajo son más generales que los utilizados en el LCA e incluyen estructuras de lenguaje de consulta InQuery, como #UW50(casa blanca), que corresponde al concepto en el que los términos casa y blanca ocurren, en cualquier orden, dentro de 50 términos uno del otro. Los resultados mostraron que combinar conceptos de un solo término y conceptos de varios términos con una ventana grande mejoró significativamente la efectividad. Sin embargo, no está claro si el mismo enfoque también es efectivo para la recuperación ad hoc, debido a las diferencias en las tareas. 3. Este apartado detalla nuestra técnica propuesta de expansión de conceptos latentes. Como se mencionó anteriormente, la técnica es una extensión del modelo MRF para la recuperación de información [14]. Por lo tanto, comenzamos proporcionando una visión general del modelo MRF y nuestras extensiones propuestas. 3.1 MRFs para IR 3.1.1 Conceptos básicos Los campos aleatorios de Markov, que son modelos gráficos no dirigidos, proporcionan una forma compacta y robusta de modelar una distribución conjunta. Aquí estamos interesados en modelar la distribución conjunta sobre una consulta Q = q1, . . . , qn y un documento D. Se asume que la distribución subyacente sobre pares de documentos y consultas es una distribución de relevancia. Es decir, muestrear de la distribución proporciona pares de documentos y consultas, de modo que el documento sea relevante para la consulta. Un MRF se define por un grafo G y un conjunto de funciones de potencial no negativas sobre los cliques en G. Los nodos en el grafo representan las variables aleatorias y las aristas definen la semántica de independencia de la distribución. Un MRF cumple con la propiedad de Markov, la cual establece que un nodo es independiente de todos sus nodos no vecinos dado los valores observados de sus vecinos. Dado un grafo G, un conjunto de potenciales ψi y un vector de parámetros Λ, la distribución conjunta sobre Q y D está dada por: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) donde Z es una constante de normalización. Seguimos la convención común y parametrizamos los potenciales como ψi(c; Λ) = exp[λifi(c)], donde fi(c) es una función de características de valores reales. 3.1.2 Construcción de G Dada una consulta Q, el grafo G puede ser construido de varias maneras. Sin embargo, siguiendo el trabajo previo, consideramos tres variantes simples [14]. Estas variantes son independencia total, donde cada término de consulta es independiente de los demás dado un documento, dependencia secuencial, que asume que existe una dependencia entre los términos de consulta adyacentes, y dependencia total, que no hace suposiciones de independencia. 3.1.3 Parametrización Los MRFs suelen ser parametrizados comúnmente en función de los cliques máximos de G. Sin embargo, dicha parametrización es demasiado gruesa para nuestras necesidades. Necesitamos una parametrización que nos permita asociar funciones de características con cliques a un nivel más detallado, manteniendo al mismo tiempo el número de características, y por lo tanto el número de parámetros, razonable. Por lo tanto, permitimos que los grupos compartan funciones de características y parámetros basados en conjuntos de grupos. Es decir, todos los subgrupos dentro de un conjunto de subgrupos están asociados con la misma función de característica y comparten un solo parámetro. Esto une de manera efectiva los parámetros de las características asociadas con cada conjunto, lo que reduce significativamente el número de parámetros mientras aún proporciona un mecanismo para el ajuste fino en el nivel de conjuntos de cliques. Proponemos siete conjuntos de cliques para utilizar en la recuperación de información. Los primeros tres conjuntos de cliques consisten en cliques que contienen uno o más términos de consulta y el nodo del documento. Las características sobre estos grupos deberían codificar qué tan bien los términos en la configuración del grupo describen el documento. Estos conjuntos son: • TD - conjunto de cliques que contienen el nodo del documento y exactamente un término de consulta. • OD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en orden secuencial dentro de la consulta. • UD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en cualquier orden dentro de la consulta. Ten en cuenta que UD es un superconjunto de OD. Al atar los parámetros entre los grupos dentro de cada conjunto podemos controlar cuánta influencia recibe cada tipo. Esto también evita el problema de tratar de determinar cómo estimar los pesos para cada clique dentro de los conjuntos. En cambio, ahora solo debemos estimar un parámetro por conjunto. A continuación, consideramos cliques que solo contienen nodos de términos de consulta. Estas cliques, que no fueron consideradas en [14], se definen de manera análoga a las recién definidas, excepto que las cliques solo están formadas por nodos de términos de consulta y no contienen el nodo de documento. Las funciones de características sobre estos conjuntos deben capturar qué tan compatibles son entre sí los términos de consulta. Estas características de grupo pueden adoptar la forma de modelos de lenguaje que imponen la corrección de los términos. Por lo tanto, definimos los siguientes conjuntos de cliques dependientes de la consulta: • TQ - conjunto de cliques que contienen exactamente un término de la consulta. • OQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en orden secuencial dentro de la consulta. • UQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en cualquier orden dentro de la consulta. Finalmente, está la clique que solo contiene el nodo del documento. Las características sobre este nodo pueden ser utilizadas como un tipo de documento previo, codificando propiedades centradas en el documento. Este conjunto de cliques trivial es entonces: • D - conjunto de cliques que contiene solo el nodo único D. Observamos que nuestros conjuntos de cliques forman una cobertura de conjuntos sobre los cliques de G, pero no son una partición, ya que algunos cliques aparecen en múltiples conjuntos de cliques. Después de atar los parámetros en nuestros conjuntos de cliques y usar la forma de la función potencial exponencial, terminamos con la siguiente forma simplificada de la distribución conjunta: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - dependiente del documento y la consulta + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - dependiente de la consulta + λDfD(D) FD(D) - dependiente del documento − log ZΛ documento + independiente de la consulta donde FDQ, FQ y FD son funciones de conveniencia definidas por los componentes dependientes del documento y la consulta, dependientes de la consulta y dependientes del documento de la distribución conjunta, respectivamente. Estos se utilizarán para simplificar y clarificar las expresiones derivadas a lo largo del resto del documento. 3.1.4 Características Cualquier función de característica arbitraria sobre configuraciones de cliques puede ser utilizada en el modelo. La elección correcta de las características depende en gran medida de la tarea de recuperación y la métrica de evaluación. Por lo tanto, es probable que no exista un conjunto único y universalmente aplicable de características. Para dar una idea de la variedad de características que se pueden utilizar, ahora describimos brevemente posibles tipos de características que podrían ser utilizadas. Posibles características dependientes del término de consulta incluyen tf, idf, entidades nombradas, proximidad de términos y estilo de texto, por nombrar algunas. Se pueden utilizar muchos tipos de características dependientes del documento, como la longitud del documento, el PageRank, la legibilidad y el género, entre otros. Dado que nuestro objetivo aquí no es encontrar características óptimas, utilizamos un conjunto simple y fijo de características que han demostrado ser efectivas en trabajos anteriores [14]. Consulte la Tabla 1 para ver la lista de características utilizadas. Estas características intentan capturar la ocurrencia de términos y la proximidad entre términos. Una mejor selección de características en el futuro probablemente conducirá a una mayor efectividad. 3.1.5 Clasificación Dada una consulta Q, deseamos clasificar los documentos en orden descendente según PG,Λ(D|Q). Después de eliminar las expresiones independientes del documento del registro PG,Λ(Q, D), derivamos la siguiente función de clasificación: PG,Λ(D|Q) rango = FDQ(D, Q) + FD(D) (2), que es una simple combinación lineal ponderada de funciones de características que pueden calcularse eficientemente para grafos razonables. 3.1.6 Estimación de Parámetros Ahora que el modelo ha sido completamente especificado, el paso final es estimar los parámetros del modelo. Aunque los MRF son modelos generativos, no es apropiado entrenarlos utilizando la función de valor de características fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Tabla 1: Funciones de características utilizadas en el modelo de campo aleatorio de Markov. Aquí, tfw,D es el número de veces que el término w ocurre en el documento D, tf#1(qi...qi+k),D denota el número de veces que la frase exacta qi . . . qi+k ocurre en el documento D, tf#uw(qi...qj ),D es el número de veces que los términos qi, . . . qj aparecen ordenados o desordenados dentro de una ventana de N términos, y |D| es la longitud del documento D. Los valores de cf y |C| se definen de manera análoga a nivel de colección. Finalmente, α y β son hiperparámetros del modelo que controlan el suavizado para las características de términos únicos y frases, respectivamente. Enfoques convencionales basados en la verosimilitud debido a la divergencia métrica [17]. Es decir, es poco probable que la estimación de máxima verosimilitud sea la estimación que maximiza nuestra métrica de evaluación. Por esta razón, entrenamos de manera discriminativa nuestro modelo para maximizar directamente la métrica de evaluación considerada [14, 15, 25]. Dado que nuestro espacio de parámetros es pequeño, hacemos uso de una estrategia simple de escalada de colina, aunque son posibles otros enfoques más sofisticados [10]. 3.2 Expansión de Conceptos Latentes En esta sección describimos cómo este modelo MRF extendido puede ser utilizado de una manera novedosa para generar conceptos de un solo término y de varios términos que están relacionados temáticamente con alguna consulta original. Como mostraremos, los conceptos generados utilizando nuestra técnica pueden ser utilizados para la expansión de consultas u otras tareas, como sugerir formulaciones alternativas de consultas. Suponemos que cuando un usuario formula su consulta original, tiene en mente un conjunto de conceptos, pero solo puede expresar un pequeño número de ellos en forma de consulta. Tratamos los conceptos que el usuario tiene en mente, pero no expresó explícitamente en la consulta, como conceptos latentes. Estos conceptos latentes pueden consistir en un solo término, varios términos o alguna combinación de ambos. Por lo tanto, nuestro objetivo es recuperar estos conceptos latentes dada alguna consulta original. Esto se puede lograr dentro de nuestro marco de trabajo al expandir primero el grafo original G para incluir el tipo de concepto que nos interesa generar. Llamamos a este gráfico expandido H. En la Figura 1, el gráfico del medio proporciona un ejemplo de cómo construir un gráfico expandido que puede generar conceptos de un solo término. De manera similar, el gráfico de la derecha ilustra un gráfico ampliado que genera dos conceptos de términos. Aunque estos dos ejemplos hacen uso de la suposición de dependencia secuencial (es decir, dependencias entre términos de consulta adyacentes), es importante tener en cuenta que tanto la consulta original como los conceptos de expansión pueden utilizar cualquier estructura de independencia. Después de que H se construye, calculamos PH,Λ(E|Q), una distribución de probabilidad sobre conceptos latentes, de acuerdo a: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) donde R es el universo de todos los documentos posibles y E es un concepto latente que puede consistir en uno o más términos. Dado que no es práctico calcular esta suma, debemos aproximarla. Observamos que PH,Λ(Q, E, D) probablemente se concentra alrededor de aquellos documentos D que están altamente clasificados según la consulta Q. Por lo tanto, aproximamos PH,Λ(E|Q) sumando solo un pequeño subconjunto de documentos relevantes o pseudo-relevantes para la consulta Q. Esto se calcula de la siguiente manera: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) donde RQ es un conjunto de documentos relevantes o pseudo-relevantes para la consulta Q y todos los conjuntos de cliques se construyen utilizando H. Como vemos, la contribución de probabilidad para cada documento en RQ es una combinación de la puntuación original de la consulta para el documento (ver Ecuación 2), la puntuación del concepto E para el documento y la puntuación independiente del documento de E. Por lo tanto, esta ecuación puede interpretarse como la medida de qué tan bien Q y E explican los documentos mejor clasificados y la bondad de E, independientemente de los documentos. Para lograr la máxima robustez, utilizamos un conjunto diferente de parámetros para FQD(Q, D) y FQD(E, D), lo que nos permite ponderar de manera diferente las características de ventana ordenadas y no ordenadas para la consulta original y el concepto de expansión candidato. 3.2.1 Expansión de consulta Para utilizar este marco para la expansión de consultas, primero elegimos un grafo de expansión H que codifique la estructura de concepto latente en la que estamos interesados en expandir la consulta. Luego seleccionamos los k conceptos latentes con la mayor probabilidad dada por la Ecuación 3. Se construye un nuevo grafo G al aumentar el grafo original G con los k conceptos de expansión E1, . . . , Ek. Finalmente, los documentos se clasifican según PG ,Λ(D|Q, E1, . . . , Ek) utilizando la Ecuación 2. 3.2.2 Comparación con los Modelos de Relevancia. Al inspeccionar las Ecuaciones 1 y 3 se revela la estrecha conexión que existe entre LCE y los modelos de relevancia. Ambos modelos esencialmente calculan la probabilidad de un término (o concepto) de la misma manera. Es fácil ver que al igual que el modelo MRF puede ser visto como una generalización del modelado del lenguaje, también LCE puede ser visto como una generalización de los modelos de relevancia. Existen diferencias importantes entre los modelos de lenguaje MRFs/LCE y los modelos de lenguaje unigram/relevancia. Consulte la Figura 1 para ver las representaciones gráficas de ambos modelos. Los modelos de lenguaje unigrama y los modelos de relevancia se basan en la distribución multinomial. Esta suposición de distribución encasilla el modelo en la representación de bolsa de palabras y el uso implícito de características de ocurrencia de términos. Sin embargo, la distribución subyacente al modelo MRF nos permite ir más allá de ambas suposiciones, al modelar tanto las dependencias entre los términos de consulta como permitir el uso explícito de características arbitrarias. Ir más allá de la simplista suposición de la bolsa de palabras de esta manera resulta en un modelo general y robusto y, como mostramos en la siguiente sección, se traduce en mejoras significativas en la efectividad de recuperación. 4. RESULTADOS EXPERIMENTALES Para comprender mejor las fortalezas y debilidades de nuestra técnica, la evaluamos en una amplia gama de conjuntos de datos. La Tabla 2 proporciona un resumen de los conjuntos de datos de TREC considerados. Las colecciones WSJ, AP y ROBUST son más pequeñas y consisten enteramente de artículos de agencias de noticias, mientras que WT10g y GOV2 son colecciones web grandes. Para cada conjunto de datos, dividimos los temas disponibles en un conjunto de entrenamiento y otro de prueba, donde el conjunto de entrenamiento se utiliza únicamente para la estimación de parámetros y el conjunto de prueba se utiliza con fines de evaluación. Todos los experimentos se llevaron a cabo utilizando una versión modificada de Indri, que forma parte del Lemur Toolkit [18, 23]. Todas las colecciones fueron detenidas utilizando una lista estándar de 418 términos comunes y truncadas utilizando un truncador de Porter. En todos los casos, solo se utiliza la parte del título de los temas de TREC para construir las consultas. Construimos G utilizando la suposición de dependencia secuencial para todos los conjuntos de datos [14]. 4.1 Resultados de recuperación ad-hoc Ahora investigamos qué tan bien se desempeña nuestro modelo en la práctica en un entorno de retroalimentación de relevancia pseudo. Comparamos el modelado de lenguaje unigrama (con suavizado de Dirichlet), el modelo MRF (sin expansión), los modelos de relevancia y LCE para comprender mejor cómo se desempeña cada modelo en los diferentes conjuntos de datos. Para el modelo de lenguaje unigrama, se entrenó el parámetro de suavizado. Para el modelo MRF, entrenamos los parámetros del modelo (es decir, y hiperparámetros del modelo (es decir, α, β). Para RM3 y LCE, también entrenamos el número de pseudoNombre Descripción # Docs Temas de Entrenamiento Temas de Prueba WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc. Presione 88-90 242,918 51-150 151-200 ROBUST Robust 2004 datos 528,155 301-450 601-700 WT10g Colección Web de TREC 1,692,096 451-500 501-550 GOV2 Rastreo 2004 del dominio .gov 25,205,179 701-750 751-800 Tabla 2: Resumen de las colecciones y temas de TREC. documentos de retroalimentación relevantes utilizados y el número de términos de expansión. 4.1.1 Expansión con Conceptos de Términos Únicos Comenzamos evaluando qué tan bien funciona nuestro modelo al expandir utilizando solo términos individuales. Antes de describir y analizar los resultados, declaramos explícitamente cómo se calculan las probabilidades de términos de expansión bajo esta configuración (es decir, utilizando la suposición de dependencia secuencial, expandiendo con conceptos de un solo término y utilizando nuestro conjunto de características). Las probabilidades de términos de expansión se calculan de la siguiente manera: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) donde b ∈ Q denota el conjunto de bigramas en Q. Esta ecuación muestra claramente cómo LCE difiere de los modelos de relevancia. Cuando establecemos λTD = λT,D = 1 y todos los demás parámetros en 0, obtenemos la fórmula exacta que se utiliza para calcular las probabilidades de términos en el marco de modelado de relevancia. Por lo tanto, LCE añade dos factores muy importantes a la ecuación. Primero, agrega las características de ventana ordenadas y no ordenadas que se aplican a la consulta original. En segundo lugar, aplica una forma intuitiva similar a tf.idf al término de expansión candidato w. El factor idf, que no está presente en los modelos de relevancia, juega un papel importante en la selección del término de expansión. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figura 2: Histogramas que demuestran y comparan la robustez de los modelos de relevancia (RM3) y la expansión de conceptos latentes (LCE) con respecto al modelo de probabilidad de consulta (QL) para los conjuntos de datos AP, ROBUST y WT10G. Los resultados, evaluados utilizando la precisión promedio media, se muestran en la Tabla 3. Como vemos, el modelo MRF, los modelos de relevancia y LCE siempre superan significativamente al modelo de lenguaje unigrama. Además, LCE muestra mejoras significativas sobre los modelos de relevancia en todos los conjuntos de datos. Las mejoras relativas sobre los modelos de relevancia son del 6.9% para AP, 12.9% para WSJ, 6.5% para ROBUST, 16.7% para WT10G y 7.3% para GOV2. Además, LCE muestra pequeñas mejoras, pero no significativas, respecto al modelado de relevancia para métricas como precisión en 5, 10 y 20. Sin embargo, tanto el modelado de relevancia como el LCE muestran mejoras estadísticamente significativas en dichas métricas sobre el modelo de lenguaje unigrama. Otro resultado interesante es que el modelo MRF es estadísticamente equivalente a los modelos de relevancia en los dos conjuntos de datos web. De hecho, el modelo MRF supera a los modelos de relevancia en el conjunto de datos WT10g. Esto reitera la importancia de las características no unigrama, basadas en la proximidad para la búsqueda web basada en contenido observada previamente [14, 16]. Aunque nuestro modelo tiene más parámetros libres que los modelos de relevancia, sorprendentemente hay poco sobreajuste. En cambio, el modelo muestra buenas propiedades de generalización. 4.1.2 Expansión con Conceptos de Múltiples Términos También investigamos la expansión utilizando conceptos de una y dos palabras. Para cada consulta, expandimos utilizando un conjunto de conceptos de un solo término y un conjunto de conceptos de dos términos. Los conjuntos fueron elegidos de forma independiente. Desafortunadamente, solo se observaron aumentos insignificantes en la precisión promedio. Este resultado puede deberse al hecho de que existen fuertes correlaciones entre los conceptos de expansión de términos individuales. Descubrimos que los dos conceptos de palabras elegidos a menudo consistían en dos términos altamente correlacionados que también son elegidos como conceptos de términos individuales. Por ejemplo, se eligió el concepto de dos términos mercado de valores, mientras que también se eligieron los conceptos de un solo término acciones y mercado. Por lo tanto, muchos conceptos de dos palabras es poco probable que aumenten el poder discriminativo de la consulta ampliada. Este resultado sugiere que los conceptos deben ser elegidos de acuerdo con ciertos criterios que también tengan en cuenta la novedad, la diversidad o las correlaciones de términos. Otro problema potencial es el conjunto de características utilizado. Otros conjuntos de características pueden dar resultados diferentes en última instancia, especialmente si reducen la correlación entre los conceptos de expansión. Por lo tanto, nuestros experimentos no arrojan resultados concluyentes en cuanto a la expansión utilizando conceptos de varios términos. En cambio, los resultados plantean preguntas abiertas interesantes y direcciones para futuras exploraciones. Tabla 3: Promedio de precisión media en el conjunto de pruebas para modelado de lenguaje (LM), campo aleatorio de Markov (MRF), modelos de relevancia (RM3) y expansión de conceptos latentes (LCE). Los superíndices α, β y γ indican mejoras estadísticamente significativas (p < 0.05) sobre LM, MRF y RM3, respectivamente. 4.2 Robustez Como hemos demostrado, los modelos de relevancia y la expansión de conceptos latentes pueden mejorar significativamente la efectividad de recuperación sobre el modelo de probabilidad de consulta base. En esta sección analizamos la robustez de estos dos métodos. Aquí definimos la robustez como el número de consultas cuya efectividad se ve mejorada/afectada (y en qué medida) como resultado de aplicar estos métodos. Una técnica de expansión altamente robusta mejorará significativamente muchas consultas y solo perjudicará mínimamente a unas pocas. La Figura 2 proporciona un análisis de la robustez del modelado de relevancia y la expansión de conceptos latentes para los conjuntos de datos AP, ROBUST y WT10G. El análisis de los dos conjuntos de datos no mostrados es similar. Los histogramas proporcionan, para varios rangos de disminuciones/aumentos relativos en la precisión media promedio, el número de consultas que se vieron perjudicadas/mejoradas con respecto a la línea base de probabilidad de consulta. Como muestran los resultados, LCE muestra una fuerte robustez para cada conjunto de datos. Para AP, los modelos de relevancia mejoran 38 consultas y perjudican 11, mientras que LCE mejora 35 y perjudica 14. Aunque los modelos de relevancia mejoran la efectividad de 3 consultas más que LCE, la mejora relativa exhibida por LCE es significativamente mayor. Para el conjunto de datos ROBUST, los modelos de relevancia mejoran 67 consultas y perjudican 32, y LCE mejora 77 y perjudica 22. Finalmente, para la colección WT10G, los modelos de relevancia mejoran 32 consultas y perjudican 16, y LCE mejora 35 y perjudica 14. Al igual que con AP, la cantidad de mejora exhibida por el LCE frente a los modelos de relevancia es significativamente mayor tanto para los conjuntos de datos ROBUST como WT10G. Además, cuando LCE afecta al rendimiento, es menos probable que afecte tanto como el modelado de relevancia, lo cual es una propiedad deseable. En general, LCE mejora la efectividad para el 65%-80% de las consultas, dependiendo del conjunto de datos. Cuando se utiliza en combinación con un sistema de predicción de rendimiento de consulta altamente preciso, puede ser posible expandir selectivamente las consultas y minimizar la pérdida asociada con el rendimiento sub-baseline. 4.3 Generación de Conceptos de Múltiples Términos Aunque encontramos que la expansión utilizando conceptos de múltiples términos no logró producir mejoras concluyentes en la efectividad, hay otras tareas potenciales para las cuales estos conceptos pueden ser útiles, como sugerencia/reformulación de consultas, resumen y extracción de conceptos. Por ejemplo, para una tarea de sugerencia de consultas, la consulta original podría usarse para generar un conjunto de conceptos latentes que corresponden a formulaciones alternativas de la consulta. Aunque evaluar nuestro modelo en estas tareas está fuera del alcance de este trabajo, deseamos mostrar un ejemplo ilustrativo de los tipos de conceptos generados utilizando nuestro modelo. En la Tabla 4, presentamos los conceptos de una, dos y tres palabras más probables generados utilizando LCE para la consulta logros del telescopio Hubble utilizando los 25 documentos mejor clasificados de la colección ROBUST. Es bien sabido que generar conceptos de múltiples términos utilizando un modelo basado en unigramas produce resultados insatisfactorios, ya que no considera las dependencias entre los términos. Esto no es el caso al generar conceptos de múltiples términos usando nuestro modelo. En cambio, la mayoría de los conceptos generados son bien formados y significativos. Hay varios casos donde los conceptos son menos coherentes, como espejo espejo espejo. En este caso, la probabilidad de que aparezca el término \"espejo\" en un documento pseudo-relevante supera a las características de modelado de lenguaje (por ejemplo, fOQ), lo que provoca que este concepto no coherente tenga una alta probabilidad. Tales ejemplos son minoría, sin embargo. No solo los conceptos generados son bien formados y significativos, sino que también son relevantes al tema de la consulta original. Como podemos ver, todos los conceptos generados están relacionados con el tema y de alguna manera están relacionados con el telescopio Hubble. Es interesante ver que el concepto de fallo del telescopio Hubble es uno de los tres conceptos de términos más probables, dado que es algo contradictorio con la consulta original. A pesar de esta contradicción, es probable que los documentos que discuten las fallas del telescopio también describan los éxitos, por lo tanto, es probable que este sea un concepto significativo. Una cosa importante a tener en cuenta es que los conceptos generados por LCE son de una naturaleza diferente a los que se generarían utilizando un modelo de relevancia de bigrama. Por ejemplo, un modelo de bigrama sería poco probable que genere el concepto telescopio espacio NASA, ya que ninguno de los bigramas que componen el concepto tiene una alta probabilidad. Sin embargo, dado que nuestro modelo se basa en una serie de características diferentes sobre varios tipos de cliques, es más general y robusto que un modelo de bigrama. Aunque solo proporcionamos los conceptos generados para una sola consulta, señalamos que el mismo análisis y conclusiones se generalizan a través de otros conjuntos de datos, con conceptos coherentes y relacionados temáticamente generados de manera consistente utilizando LCE. 4.4 Discusión Nuestra técnica de expansión de conceptos latentes captura dos tipos de dependencia semiortogonales. En la recuperación de información, ha existido un interés a largo plazo en comprender el papel de la dependencia de términos. De esta investigación, se han identificado dos tipos generales de dependencias. El primer tipo de dependencia es la dependencia sintáctica. Este tipo de dependencia abarca frases, proximidad de términos y co-ocurrencia de términos [2, 4, 5, 7, 26]. Estos métodos capturan el hecho de que las consultas imponen implícita o explícitamente un cierto conjunto de dependencias posicionales. El segundo tipo es la dependencia semántica. Ejemplos de dependencia semántica son la retroalimentación de relevancia, la retroalimentación de pseudo-relevancia, sinónimos y en cierta medida el truncamiento [3]. Estas técnicas han sido exploradas tanto en el lado de la consulta como en el lado del documento. En el lado de la consulta, esto se suele hacer utilizando alguna forma de expansión de consulta, como modelos de relevancia o LCE. En el lado del documento, esto se hace como expansión de documentos o suavizado de documentos [11, 13, 24]. Aunque puede haber cierta superposición entre las dependencias sintácticas y semánticas, en su mayoría son ortogonales. Nuestro modelo utiliza ambos tipos de dependencias. El uso de características de frase y proximidad dentro del modelo captura dependencias sintácticas, mientras que LCE captura dependencias semánticas del lado de la consulta. Esto explica por qué la mejora inicial en la efectividad lograda al usar el modelo MRF no se pierde después de la expansión de consultas. Si los mismos tipos de dependencias fueran capturados tanto por dependencias sintácticas como semánticas, se esperaría que LCE funcionara aproximadamente igual de bien que los modelos de relevancia. Por lo tanto, al modelar ambos tipos de dependencias, observamos un efecto aditivo en lugar de un efecto absorbente. Una área interesante de trabajo futuro es determinar si modelar las dependencias semánticas del lado del documento puede aportar algo al modelo. Resultados previos que han combinado dependencias semánticas del lado de la consulta y del documento han mostrado resultados mixtos [13, 27]. 5. CONCLUSIONES En este artículo propusimos una técnica robusta de expansión de consultas llamada expansión de conceptos latentes. La técnica se demostró ser una extensión natural del modelo de campo aleatorio de Markov para la recuperación de información y una generalización de los modelos de relevancia. LCE es novedoso en el sentido de que realiza una expansión de un solo término o de varios términos dentro de un marco que permite el modelado de dependencias entre términos y el uso de características arbitrarias, mientras que trabajos anteriores se basaban en la suposición de la bolsa de palabras y características de ocurrencia de términos. Mostramos que la técnica puede ser utilizada para producir conceptos de expansión de varios términos de alta calidad, bien formados y relevantes desde el punto de vista temático. Los conceptos generados pueden ser utilizados en un módulo de sugerencia de consultas alternativas. También demostramos que el modelo es altamente efectivo. De hecho, logra mejoras significativas en la precisión promedio media en comparación con los modelos de relevancia en una selección de conjuntos de datos de TREC. También se demostró que el modelo MRF por sí solo, sin ninguna expansión de consulta, supera a los modelos de relevancia en grandes conjuntos de datos web. Esto reafirma observaciones previas de que modelar dependencias a través del uso de características de proximidad dentro del MRF tiene un mayor impacto en colecciones más grandes y ruidosas que en colecciones más pequeñas y bien comportadas. Finalmente, reiteramos la importancia de elegir términos de expansión que modelen la relevancia, en lugar de los documentos relevantes, y mostramos cómo LCE captura tanto las dependencias sintácticas como semánticas del lado de la consulta. El trabajo futuro se centrará en incorporar dependencias del lado del documento también. Agradecimientos Este trabajo fue apoyado en parte por el Centro de Recuperación de Información Inteligente, en parte por la subvención NSF #CNS-0454018, en parte por ARDA y la subvención NSF #CCF-0205575, y en parte por Microsoft Live Labs. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son responsabilidad del autor o los autores y no necesariamente reflejan las del patrocinador.  REFERENCIAS [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker y C. Wade. UMass en TREC 2004: Novedad y DIFICULTAD. En Actas en línea de la Conferencia de Recuperación de Información de 2004, 2004. [2] C. L. A. Clarke y G. V. Cormack. Recuperación y clasificación de la subcadena más corta. ACM Trans. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate to Spanish? Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson y J. Callan. Expansión de consultas utilizando modelos de caminata aleatoria. En Proc. 14th Intl. Conf. sobre Gestión de Información y Conocimiento, páginas 704-711, 2005. [4] W. B. Croft. Consultas booleanas y dependencias de términos en modelos de recuperación probabilística. Revista de la Sociedad Americana de Ciencia de la Información, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle y D. Lewis. El uso de frases y consultas estructuradas en la recuperación de información. En Proc. 14º Anu. Internacional. Conferencia ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 32-45, 1991. [6] K. Eguchi. Experimentos de expansión de consultas NTCIR-5 utilizando modelos de dependencia de términos. En Actas del Quinto Taller de Reunión NTCIR sobre Evaluación de Tecnologías de Acceso a la Información, páginas 494-501, 2005. [7] J. Fagan. Indexación automática de frases para la recuperación de documentos: Un examen de métodos sintácticos y no sintácticos. En el Proc. décimo anual. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 91-101, 1987. [8] J. Gao, J. Nie, G. Wu y G. Cao. Modelo de lenguaje de dependencia para recuperación de información. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 170-177, 2004. [9] D. Harper y C. J. van Rijsbergen. Una evaluación de la retroalimentación en la recuperación de documentos utilizando datos de co-ocurrencia. Revista de Documentación, 34(3):189-216, 1978. [10] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Proc. de la Conf. Internacional de Aprendizaje Automático, páginas 377-384, 2005. [11] O. Kurland y L. Lee. Estructura del corpus, modelos de lenguaje y recuperación de información ad-hoc. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 194-201, 2004. [12] V. Lavrenko y W. B. Croft. Modelos de lenguaje basados en relevancia. En Proc. 24º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 120-127, 2001. [13] X. Liu y W. B. Croft. Recuperación basada en clústeres utilizando modelos de lenguaje. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 186-193, 2004. [14] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias entre términos. En Proc. 28vo Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [15] D. Metzler y W. B. Croft. Modelos basados en características lineales para la recuperación de información. Recuperación de información, por aparecer, 2006. [16] D. Metzler, T. Strohman, Y. Zhou y W. B. Croft. Indri en la pista de terabyte en 2005. En Actas en línea de la Conferencia de Recuperación de Texto de 2005, 2005. [17] W. Morgan, W. Greiff y J. Henderson. Maximización directa de la precisión promedio mediante escalada de colina con una comparación con un enfoque de entropía máxima. Informe técnico, MITRE, 2004. [18] P. Ogilvie y J. P. Callan. Experimentos utilizando el kit de herramientas de lémures. En Proc. de la Conferencia de Recuperación de Texto, 2001. [19] R. Papka y J. Allan. Por qué las ventanas más grandes son mejores que las más pequeñas. Informe técnico, Universidad de Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu y M. Gatford. Okapi en trec-3. En Actas en línea de la Tercera Conferencia de Recuperación de Texto, páginas 109-126, 1995. [21] J. J. Rocchio. Retroalimentación de relevancia en la recuperación de información, páginas 313-323. Prentice-Hall, 1971. [22] F. Song y W. B. Croft. Un modelo de lenguaje general para la recuperación de información. En Proc. octava conferencia internacional sobre Gestión de la Información y el Conocimiento (CIKM 99), páginas 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle y W. B. Croft. Indri: Un motor de búsqueda basado en modelos de lenguaje para consultas complejas. En Actas de la Conferencia Internacional sobre Análisis de Inteligencia, 2004. [24] T. Tao, X. Wang, Q. Mei y C. Zhai. Recuperación de información del modelo de lenguaje con expansión de documentos. En Proc. de HLT/NAACL, páginas 407-414, 2006. [25] B. Taskar, C. Guestrin y D. Koller. Redes de Markov de margen máximo. En Proc. de Avances en Sistemas de Información Neural (NIPS 2003), 2003. [26] C. J. van Rijsbergen. Una base teórica para el uso de datos de coocurrencia en la recuperación de información. Revista de Documentación, 33(2):106-119, 1977. [27] X. Wei y W. B. Croft. Modelos de documentos basados en LDA para recuperación ad-hoc. En Proc. 29º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 178-185, 2006. [28] J. Xu y W. B. Croft. Mejorando la efectividad de la recuperación de información con análisis de contexto local. ACM Trans. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate into Spanish? Syst., 18(1):79-112, 2000. [29] C. Zhai y J. Lafferty. Retroalimentación basada en modelos en el enfoque de modelado del lenguaje para la recuperación de información. En Proc. 10th Intl. Conferencia sobre Gestión de la Información y el Conocimiento, páginas 403-410, 2001. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "rm3": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as <br>rm3</br>.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For <br>rm3</br> and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% <br>rm3</br> LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% <br>rm3</br> LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF <br>rm3</br> LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (<br>rm3</br>), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and <br>rm3</br>, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as <br>rm3</br>.",
                "For <br>rm3</br> and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% <br>rm3</br> LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% <br>rm3</br> LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "LM MRF <br>rm3</br> LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (<br>rm3</br>), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and <br>rm3</br>, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model."
            ],
            "translated_annotated_samples": [
                "A lo largo del resto de este trabajo, nos referimos a esta instancia de <br>modelos de relevancia</br> como RM3.",
                "Para <br>RM3</br> y LCE, también entrenamos el número de pseudoNombre Descripción # Docs Temas de Entrenamiento Temas de Prueba WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "En segundo lugar, aplica una forma intuitiva similar a tf.idf al término de expansión candidato w. El factor idf, que no está presente en los modelos de relevancia, juega un papel importante en la selección del término de expansión. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% <br>RM3 LCE</br> 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% <br>RM3 LCE</br> 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figura 2: Histogramas que demuestran y comparan la robustez de los modelos de relevancia (RM3) y la expansión de conceptos latentes (LCE) con respecto al modelo de probabilidad de consulta (QL) para los conjuntos de datos AP, ROBUST y WT10G.",
                "Tabla 3: Promedio de precisión media en el conjunto de pruebas para modelado de lenguaje (LM), campo aleatorio de Markov (MRF), modelos de relevancia (<br>RM3</br>) y expansión de conceptos latentes (LCE).",
                "Los superíndices α, β y γ indican mejoras estadísticamente significativas (p < 0.05) sobre LM, MRF y <br>RM3</br>, respectivamente. 4.2 Robustez Como hemos demostrado, los modelos de relevancia y la expansión de conceptos latentes pueden mejorar significativamente la efectividad de recuperación sobre el modelo de probabilidad de consulta base."
            ],
            "translated_text": "Expansión de conceptos latentes utilizando campos aleatorios de Markov. Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Centro de Recuperación de Información Inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 RESUMEN La expansión de consultas, en forma de retroalimentación de pseudo relevancia o retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación. La mayoría de enfoques anteriores han ignorado problemas importantes, como el papel de las características y la importancia de modelar las dependencias entre términos. En este artículo, proponemos una técnica robusta de expansión de consultas basada en el modelo de campo aleatorio de Markov para la recuperación de información. La técnica, llamada expansión de conceptos latentes, proporciona un mecanismo para modelar las dependencias de términos durante la expansión. Además, el uso de características arbitrarias dentro del modelo proporciona un marco poderoso para ir más allá de las simples características de ocurrencia de términos que son utilizadas implícitamente por la mayoría de las otras técnicas de expansión. Evaluamos nuestra técnica frente a modelos de relevancia, una técnica de expansión de consultas de modelado de lenguaje de última generación. Nuestro modelo demuestra mejoras consistentes y significativas en la efectividad de recuperación en varios conjuntos de datos de TREC. También describimos cómo nuestra técnica puede ser utilizada para generar conceptos significativos de varios términos para tareas como sugerencia/reformulación de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales Algoritmos, Experimentación, Teoría 1. Los usuarios de los sistemas de recuperación de información deben expresar necesidades de información complejas en términos de expresiones booleanas, una lista corta de palabras clave, una oración, una pregunta o posiblemente un relato más extenso. Se pierde mucha información durante el proceso de traducción desde la necesidad de información hasta la consulta real. Por esta razón, ha habido un fuerte interés en las técnicas de expansión de consultas. Tales técnicas se utilizan para ampliar la consulta original y producir una representación que refleje mejor la necesidad de información subyacente. Las técnicas de expansión de consultas han sido ampliamente estudiadas para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la retroalimentación de pseudo-relevancia [12, 21, 28, 29]. Recientemente, se propuso un modelo de campo aleatorio de Markov (MRF) para la recuperación de información que va más allá de la simplista suposición de bolsa de palabras que subyace en BM25 y en el enfoque de modelado de lenguaje (unigrama) para la recuperación de información [20, 22]. El modelo MRF generaliza los modelos de unigrama, bigrama y otras diversas dependencias [14]. La mayoría de los modelos de dependencia de términos pasados no han logrado mostrar mejoras consistentes y significativas sobre las líneas de base de unigramas, con pocas excepciones [8]. El modelo MRF, sin embargo, ha demostrado ser altamente efectivo en una serie de tareas, incluyendo la recuperación ad hoc [14, 16], la búsqueda de páginas con nombres [16] y la búsqueda web en japonés [6]. Hasta ahora, el modelo ha sido utilizado únicamente para clasificar documentos en respuesta a una consulta dada. En este trabajo, mostramos cómo el modelo puede ser ampliado y utilizado para la expansión de consultas utilizando una técnica que llamamos expansión de conceptos latentes (LCE). Hay tres contribuciones principales de nuestro trabajo. Primero, LCE proporciona un mecanismo para combinar la dependencia de términos con la expansión de consultas. Las técnicas de expansión de consultas anteriores se basan en modelos de bolsa de palabras. Por lo tanto, al realizar la expansión de consultas utilizando el modelo MRF, podemos estudiar la dinámica entre la dependencia de términos y la expansión de consultas. A continuación, como mostraremos, el modelo MRF permite que se utilicen características arbitrarias dentro del modelo. Las técnicas de expansión de consultas en el pasado solo han hecho uso implícito de características de ocurrencia de términos. Al utilizar conjuntos de características más robustos, es posible producir términos de expansión mejores que discriminan de manera más efectiva entre documentos relevantes y no relevantes. Finalmente, nuestro enfoque propuesto proporciona de manera fluida un mecanismo para generar conceptos de una sola y múltiples términos. La mayoría de las técnicas anteriores, por defecto, generan términos de forma independiente. Ha habido varios enfoques que hacen uso de conceptos generalizados, sin embargo, dichos enfoques fueron algo heurísticos y realizados fuera del modelo [19, 28]. Nuestro enfoque está motivado tanto formalmente como es una extensión natural del modelo subyacente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2 describimos enfoques relacionados de expansión de consultas. La sección 3 proporciona una visión general del modelo MRF y detalla nuestra técnica propuesta de expansión de conceptos latentes. En la Sección 4 evaluamos nuestro modelo propuesto y analizamos los resultados. Finalmente, la Sección 5 concluye el artículo y resume los principales resultados. 2. TRABAJO RELACIONADO Uno de los enfoques clásicos y más ampliamente utilizados para la expansión de consultas es el algoritmo de Rocchio [21]. El enfoque de Rocchio, que fue desarrollado dentro del modelo de espacio vectorial, reajusta el vector de consulta original moviendo los pesos hacia el conjunto de documentos relevantes o pseudo-relevantes y alejándolos de los documentos no relevantes. Desafortunadamente, no es posible aplicar formalmente el enfoque de Rocchio a un modelo de recuperación estadística, como el modelado del lenguaje para la recuperación de información. Se han desarrollado varias técnicas de expansión de consultas formalizadas para el marco de modelado de lenguaje, incluyendo el feedback basado en el modelo de Zhai y Lafferty y los modelos de relevancia de Lavrenko y Crofts [12, 29]. Ambos enfoques intentan utilizar documentos pseudo-relevantes o relevantes para estimar un modelo de consulta mejor. El feedback basado en modelos encuentra el modelo que mejor describe los documentos relevantes teniendo en cuenta un modelo de fondo (ruido). Esto separa el modelo de contenido del modelo de fondo. El modelo de contenido se interpola con el modelo de consulta original para formar la consulta ampliada. La otra técnica, modelos de relevancia, está más relacionada con nuestro trabajo. Por lo tanto, entramos en los detalles del modelo. Al igual que el feedback basado en modelos, los modelos de relevancia estiman un modelo de consulta mejorado. La única diferencia entre los dos enfoques es que los modelos de relevancia no modelan explícitamente los documentos relevantes o pseudo-relevantes. En cambio, ellos modelan una noción más generalizada de relevancia, como mostraremos ahora. Dada una consulta Q, un modelo de relevancia es una distribución multinomial, P(·|Q), que codifica la probabilidad de cada término dado la consulta como evidencia. Se calcula como: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) donde RQ es el conjunto de documentos que son relevantes o pseudo relevantes para la consulta Q. En el caso pseudo-relevante, estos son los documentos mejor clasificados para la consulta Q. Además, se asume que P(D) es uniforme en este conjunto. Estas suposiciones suaves hacen que el cálculo del posterior bayesiano sea más práctico. Después de que el modelo es estimado, los documentos son clasificados por recortar el modelo de relevancia al elegir los k términos más probables de P(·|Q). Esta distribución recortada se interpola luego con el modelo de consulta de máxima verosimilitud original. Esto se puede considerar como la expansión de la consulta original por k términos ponderados. A lo largo del resto de este trabajo, nos referimos a esta instancia de <br>modelos de relevancia</br> como RM3. Ha habido relativamente poco trabajo realizado en el área de expansión de consultas en el contexto de modelos de dependencia [9]. Sin embargo, ha habido varios intentos de expandir utilizando conceptos de varios términos. El método de análisis de contexto local (LCA) de Xu y Crofts combinaba la recuperación a nivel de pasaje con la expansión de conceptos, donde los conceptos eran términos y frases simples [28]. Los conceptos de expansión fueron elegidos y ponderados utilizando una métrica basada en estadísticas de co-ocurrencia. Sin embargo, no está claro, basándose en el análisis realizado, cuánto ayudaron las frases en comparación con los términos individuales solos. Papka y Allan investigan el uso de retroalimentación de relevancia para realizar la expansión de conceptos de varios términos en el enrutamiento de documentos [19]. Los conceptos utilizados en su trabajo son más generales que los utilizados en el LCA e incluyen estructuras de lenguaje de consulta InQuery, como #UW50(casa blanca), que corresponde al concepto en el que los términos casa y blanca ocurren, en cualquier orden, dentro de 50 términos uno del otro. Los resultados mostraron que combinar conceptos de un solo término y conceptos de varios términos con una ventana grande mejoró significativamente la efectividad. Sin embargo, no está claro si el mismo enfoque también es efectivo para la recuperación ad hoc, debido a las diferencias en las tareas. 3. Este apartado detalla nuestra técnica propuesta de expansión de conceptos latentes. Como se mencionó anteriormente, la técnica es una extensión del modelo MRF para la recuperación de información [14]. Por lo tanto, comenzamos proporcionando una visión general del modelo MRF y nuestras extensiones propuestas. 3.1 MRFs para IR 3.1.1 Conceptos básicos Los campos aleatorios de Markov, que son modelos gráficos no dirigidos, proporcionan una forma compacta y robusta de modelar una distribución conjunta. Aquí estamos interesados en modelar la distribución conjunta sobre una consulta Q = q1, . . . , qn y un documento D. Se asume que la distribución subyacente sobre pares de documentos y consultas es una distribución de relevancia. Es decir, muestrear de la distribución proporciona pares de documentos y consultas, de modo que el documento sea relevante para la consulta. Un MRF se define por un grafo G y un conjunto de funciones de potencial no negativas sobre los cliques en G. Los nodos en el grafo representan las variables aleatorias y las aristas definen la semántica de independencia de la distribución. Un MRF cumple con la propiedad de Markov, la cual establece que un nodo es independiente de todos sus nodos no vecinos dado los valores observados de sus vecinos. Dado un grafo G, un conjunto de potenciales ψi y un vector de parámetros Λ, la distribución conjunta sobre Q y D está dada por: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) donde Z es una constante de normalización. Seguimos la convención común y parametrizamos los potenciales como ψi(c; Λ) = exp[λifi(c)], donde fi(c) es una función de características de valores reales. 3.1.2 Construcción de G Dada una consulta Q, el grafo G puede ser construido de varias maneras. Sin embargo, siguiendo el trabajo previo, consideramos tres variantes simples [14]. Estas variantes son independencia total, donde cada término de consulta es independiente de los demás dado un documento, dependencia secuencial, que asume que existe una dependencia entre los términos de consulta adyacentes, y dependencia total, que no hace suposiciones de independencia. 3.1.3 Parametrización Los MRFs suelen ser parametrizados comúnmente en función de los cliques máximos de G. Sin embargo, dicha parametrización es demasiado gruesa para nuestras necesidades. Necesitamos una parametrización que nos permita asociar funciones de características con cliques a un nivel más detallado, manteniendo al mismo tiempo el número de características, y por lo tanto el número de parámetros, razonable. Por lo tanto, permitimos que los grupos compartan funciones de características y parámetros basados en conjuntos de grupos. Es decir, todos los subgrupos dentro de un conjunto de subgrupos están asociados con la misma función de característica y comparten un solo parámetro. Esto une de manera efectiva los parámetros de las características asociadas con cada conjunto, lo que reduce significativamente el número de parámetros mientras aún proporciona un mecanismo para el ajuste fino en el nivel de conjuntos de cliques. Proponemos siete conjuntos de cliques para utilizar en la recuperación de información. Los primeros tres conjuntos de cliques consisten en cliques que contienen uno o más términos de consulta y el nodo del documento. Las características sobre estos grupos deberían codificar qué tan bien los términos en la configuración del grupo describen el documento. Estos conjuntos son: • TD - conjunto de cliques que contienen el nodo del documento y exactamente un término de consulta. • OD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en orden secuencial dentro de la consulta. • UD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en cualquier orden dentro de la consulta. Ten en cuenta que UD es un superconjunto de OD. Al atar los parámetros entre los grupos dentro de cada conjunto podemos controlar cuánta influencia recibe cada tipo. Esto también evita el problema de tratar de determinar cómo estimar los pesos para cada clique dentro de los conjuntos. En cambio, ahora solo debemos estimar un parámetro por conjunto. A continuación, consideramos cliques que solo contienen nodos de términos de consulta. Estas cliques, que no fueron consideradas en [14], se definen de manera análoga a las recién definidas, excepto que las cliques solo están formadas por nodos de términos de consulta y no contienen el nodo de documento. Las funciones de características sobre estos conjuntos deben capturar qué tan compatibles son entre sí los términos de consulta. Estas características de grupo pueden adoptar la forma de modelos de lenguaje que imponen la corrección de los términos. Por lo tanto, definimos los siguientes conjuntos de cliques dependientes de la consulta: • TQ - conjunto de cliques que contienen exactamente un término de la consulta. • OQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en orden secuencial dentro de la consulta. • UQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en cualquier orden dentro de la consulta. Finalmente, está la clique que solo contiene el nodo del documento. Las características sobre este nodo pueden ser utilizadas como un tipo de documento previo, codificando propiedades centradas en el documento. Este conjunto de cliques trivial es entonces: • D - conjunto de cliques que contiene solo el nodo único D. Observamos que nuestros conjuntos de cliques forman una cobertura de conjuntos sobre los cliques de G, pero no son una partición, ya que algunos cliques aparecen en múltiples conjuntos de cliques. Después de atar los parámetros en nuestros conjuntos de cliques y usar la forma de la función potencial exponencial, terminamos con la siguiente forma simplificada de la distribución conjunta: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - dependiente del documento y la consulta + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - dependiente de la consulta + λDfD(D) FD(D) - dependiente del documento − log ZΛ documento + independiente de la consulta donde FDQ, FQ y FD son funciones de conveniencia definidas por los componentes dependientes del documento y la consulta, dependientes de la consulta y dependientes del documento de la distribución conjunta, respectivamente. Estos se utilizarán para simplificar y clarificar las expresiones derivadas a lo largo del resto del documento. 3.1.4 Características Cualquier función de característica arbitraria sobre configuraciones de cliques puede ser utilizada en el modelo. La elección correcta de las características depende en gran medida de la tarea de recuperación y la métrica de evaluación. Por lo tanto, es probable que no exista un conjunto único y universalmente aplicable de características. Para dar una idea de la variedad de características que se pueden utilizar, ahora describimos brevemente posibles tipos de características que podrían ser utilizadas. Posibles características dependientes del término de consulta incluyen tf, idf, entidades nombradas, proximidad de términos y estilo de texto, por nombrar algunas. Se pueden utilizar muchos tipos de características dependientes del documento, como la longitud del documento, el PageRank, la legibilidad y el género, entre otros. Dado que nuestro objetivo aquí no es encontrar características óptimas, utilizamos un conjunto simple y fijo de características que han demostrado ser efectivas en trabajos anteriores [14]. Consulte la Tabla 1 para ver la lista de características utilizadas. Estas características intentan capturar la ocurrencia de términos y la proximidad entre términos. Una mejor selección de características en el futuro probablemente conducirá a una mayor efectividad. 3.1.5 Clasificación Dada una consulta Q, deseamos clasificar los documentos en orden descendente según PG,Λ(D|Q). Después de eliminar las expresiones independientes del documento del registro PG,Λ(Q, D), derivamos la siguiente función de clasificación: PG,Λ(D|Q) rango = FDQ(D, Q) + FD(D) (2), que es una simple combinación lineal ponderada de funciones de características que pueden calcularse eficientemente para grafos razonables. 3.1.6 Estimación de Parámetros Ahora que el modelo ha sido completamente especificado, el paso final es estimar los parámetros del modelo. Aunque los MRF son modelos generativos, no es apropiado entrenarlos utilizando la función de valor de características fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Tabla 1: Funciones de características utilizadas en el modelo de campo aleatorio de Markov. Aquí, tfw,D es el número de veces que el término w ocurre en el documento D, tf#1(qi...qi+k),D denota el número de veces que la frase exacta qi . . . qi+k ocurre en el documento D, tf#uw(qi...qj ),D es el número de veces que los términos qi, . . . qj aparecen ordenados o desordenados dentro de una ventana de N términos, y |D| es la longitud del documento D. Los valores de cf y |C| se definen de manera análoga a nivel de colección. Finalmente, α y β son hiperparámetros del modelo que controlan el suavizado para las características de términos únicos y frases, respectivamente. Enfoques convencionales basados en la verosimilitud debido a la divergencia métrica [17]. Es decir, es poco probable que la estimación de máxima verosimilitud sea la estimación que maximiza nuestra métrica de evaluación. Por esta razón, entrenamos de manera discriminativa nuestro modelo para maximizar directamente la métrica de evaluación considerada [14, 15, 25]. Dado que nuestro espacio de parámetros es pequeño, hacemos uso de una estrategia simple de escalada de colina, aunque son posibles otros enfoques más sofisticados [10]. 3.2 Expansión de Conceptos Latentes En esta sección describimos cómo este modelo MRF extendido puede ser utilizado de una manera novedosa para generar conceptos de un solo término y de varios términos que están relacionados temáticamente con alguna consulta original. Como mostraremos, los conceptos generados utilizando nuestra técnica pueden ser utilizados para la expansión de consultas u otras tareas, como sugerir formulaciones alternativas de consultas. Suponemos que cuando un usuario formula su consulta original, tiene en mente un conjunto de conceptos, pero solo puede expresar un pequeño número de ellos en forma de consulta. Tratamos los conceptos que el usuario tiene en mente, pero no expresó explícitamente en la consulta, como conceptos latentes. Estos conceptos latentes pueden consistir en un solo término, varios términos o alguna combinación de ambos. Por lo tanto, nuestro objetivo es recuperar estos conceptos latentes dada alguna consulta original. Esto se puede lograr dentro de nuestro marco de trabajo al expandir primero el grafo original G para incluir el tipo de concepto que nos interesa generar. Llamamos a este gráfico expandido H. En la Figura 1, el gráfico del medio proporciona un ejemplo de cómo construir un gráfico expandido que puede generar conceptos de un solo término. De manera similar, el gráfico de la derecha ilustra un gráfico ampliado que genera dos conceptos de términos. Aunque estos dos ejemplos hacen uso de la suposición de dependencia secuencial (es decir, dependencias entre términos de consulta adyacentes), es importante tener en cuenta que tanto la consulta original como los conceptos de expansión pueden utilizar cualquier estructura de independencia. Después de que H se construye, calculamos PH,Λ(E|Q), una distribución de probabilidad sobre conceptos latentes, de acuerdo a: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) donde R es el universo de todos los documentos posibles y E es un concepto latente que puede consistir en uno o más términos. Dado que no es práctico calcular esta suma, debemos aproximarla. Observamos que PH,Λ(Q, E, D) probablemente se concentra alrededor de aquellos documentos D que están altamente clasificados según la consulta Q. Por lo tanto, aproximamos PH,Λ(E|Q) sumando solo un pequeño subconjunto de documentos relevantes o pseudo-relevantes para la consulta Q. Esto se calcula de la siguiente manera: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) donde RQ es un conjunto de documentos relevantes o pseudo-relevantes para la consulta Q y todos los conjuntos de cliques se construyen utilizando H. Como vemos, la contribución de probabilidad para cada documento en RQ es una combinación de la puntuación original de la consulta para el documento (ver Ecuación 2), la puntuación del concepto E para el documento y la puntuación independiente del documento de E. Por lo tanto, esta ecuación puede interpretarse como la medida de qué tan bien Q y E explican los documentos mejor clasificados y la bondad de E, independientemente de los documentos. Para lograr la máxima robustez, utilizamos un conjunto diferente de parámetros para FQD(Q, D) y FQD(E, D), lo que nos permite ponderar de manera diferente las características de ventana ordenadas y no ordenadas para la consulta original y el concepto de expansión candidato. 3.2.1 Expansión de consulta Para utilizar este marco para la expansión de consultas, primero elegimos un grafo de expansión H que codifique la estructura de concepto latente en la que estamos interesados en expandir la consulta. Luego seleccionamos los k conceptos latentes con la mayor probabilidad dada por la Ecuación 3. Se construye un nuevo grafo G al aumentar el grafo original G con los k conceptos de expansión E1, . . . , Ek. Finalmente, los documentos se clasifican según PG ,Λ(D|Q, E1, . . . , Ek) utilizando la Ecuación 2. 3.2.2 Comparación con los Modelos de Relevancia. Al inspeccionar las Ecuaciones 1 y 3 se revela la estrecha conexión que existe entre LCE y los modelos de relevancia. Ambos modelos esencialmente calculan la probabilidad de un término (o concepto) de la misma manera. Es fácil ver que al igual que el modelo MRF puede ser visto como una generalización del modelado del lenguaje, también LCE puede ser visto como una generalización de los modelos de relevancia. Existen diferencias importantes entre los modelos de lenguaje MRFs/LCE y los modelos de lenguaje unigram/relevancia. Consulte la Figura 1 para ver las representaciones gráficas de ambos modelos. Los modelos de lenguaje unigrama y los modelos de relevancia se basan en la distribución multinomial. Esta suposición de distribución encasilla el modelo en la representación de bolsa de palabras y el uso implícito de características de ocurrencia de términos. Sin embargo, la distribución subyacente al modelo MRF nos permite ir más allá de ambas suposiciones, al modelar tanto las dependencias entre los términos de consulta como permitir el uso explícito de características arbitrarias. Ir más allá de la simplista suposición de la bolsa de palabras de esta manera resulta en un modelo general y robusto y, como mostramos en la siguiente sección, se traduce en mejoras significativas en la efectividad de recuperación. 4. RESULTADOS EXPERIMENTALES Para comprender mejor las fortalezas y debilidades de nuestra técnica, la evaluamos en una amplia gama de conjuntos de datos. La Tabla 2 proporciona un resumen de los conjuntos de datos de TREC considerados. Las colecciones WSJ, AP y ROBUST son más pequeñas y consisten enteramente de artículos de agencias de noticias, mientras que WT10g y GOV2 son colecciones web grandes. Para cada conjunto de datos, dividimos los temas disponibles en un conjunto de entrenamiento y otro de prueba, donde el conjunto de entrenamiento se utiliza únicamente para la estimación de parámetros y el conjunto de prueba se utiliza con fines de evaluación. Todos los experimentos se llevaron a cabo utilizando una versión modificada de Indri, que forma parte del Lemur Toolkit [18, 23]. Todas las colecciones fueron detenidas utilizando una lista estándar de 418 términos comunes y truncadas utilizando un truncador de Porter. En todos los casos, solo se utiliza la parte del título de los temas de TREC para construir las consultas. Construimos G utilizando la suposición de dependencia secuencial para todos los conjuntos de datos [14]. 4.1 Resultados de recuperación ad-hoc Ahora investigamos qué tan bien se desempeña nuestro modelo en la práctica en un entorno de retroalimentación de relevancia pseudo. Comparamos el modelado de lenguaje unigrama (con suavizado de Dirichlet), el modelo MRF (sin expansión), los modelos de relevancia y LCE para comprender mejor cómo se desempeña cada modelo en los diferentes conjuntos de datos. Para el modelo de lenguaje unigrama, se entrenó el parámetro de suavizado. Para el modelo MRF, entrenamos los parámetros del modelo (es decir, y hiperparámetros del modelo (es decir, α, β). Para <br>RM3</br> y LCE, también entrenamos el número de pseudoNombre Descripción # Docs Temas de Entrenamiento Temas de Prueba WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc. Presione 88-90 242,918 51-150 151-200 ROBUST Robust 2004 datos 528,155 301-450 601-700 WT10g Colección Web de TREC 1,692,096 451-500 501-550 GOV2 Rastreo 2004 del dominio .gov 25,205,179 701-750 751-800 Tabla 2: Resumen de las colecciones y temas de TREC. documentos de retroalimentación relevantes utilizados y el número de términos de expansión. 4.1.1 Expansión con Conceptos de Términos Únicos Comenzamos evaluando qué tan bien funciona nuestro modelo al expandir utilizando solo términos individuales. Antes de describir y analizar los resultados, declaramos explícitamente cómo se calculan las probabilidades de términos de expansión bajo esta configuración (es decir, utilizando la suposición de dependencia secuencial, expandiendo con conceptos de un solo término y utilizando nuestro conjunto de características). Las probabilidades de términos de expansión se calculan de la siguiente manera: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) donde b ∈ Q denota el conjunto de bigramas en Q. Esta ecuación muestra claramente cómo LCE difiere de los modelos de relevancia. Cuando establecemos λTD = λT,D = 1 y todos los demás parámetros en 0, obtenemos la fórmula exacta que se utiliza para calcular las probabilidades de términos en el marco de modelado de relevancia. Por lo tanto, LCE añade dos factores muy importantes a la ecuación. Primero, agrega las características de ventana ordenadas y no ordenadas que se aplican a la consulta original. En segundo lugar, aplica una forma intuitiva similar a tf.idf al término de expansión candidato w. El factor idf, que no está presente en los modelos de relevancia, juega un papel importante en la selección del término de expansión. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% <br>RM3 LCE</br> 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% <br>RM3 LCE</br> 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figura 2: Histogramas que demuestran y comparan la robustez de los modelos de relevancia (RM3) y la expansión de conceptos latentes (LCE) con respecto al modelo de probabilidad de consulta (QL) para los conjuntos de datos AP, ROBUST y WT10G. Los resultados, evaluados utilizando la precisión promedio media, se muestran en la Tabla 3. Como vemos, el modelo MRF, los modelos de relevancia y LCE siempre superan significativamente al modelo de lenguaje unigrama. Además, LCE muestra mejoras significativas sobre los modelos de relevancia en todos los conjuntos de datos. Las mejoras relativas sobre los modelos de relevancia son del 6.9% para AP, 12.9% para WSJ, 6.5% para ROBUST, 16.7% para WT10G y 7.3% para GOV2. Además, LCE muestra pequeñas mejoras, pero no significativas, respecto al modelado de relevancia para métricas como precisión en 5, 10 y 20. Sin embargo, tanto el modelado de relevancia como el LCE muestran mejoras estadísticamente significativas en dichas métricas sobre el modelo de lenguaje unigrama. Otro resultado interesante es que el modelo MRF es estadísticamente equivalente a los modelos de relevancia en los dos conjuntos de datos web. De hecho, el modelo MRF supera a los modelos de relevancia en el conjunto de datos WT10g. Esto reitera la importancia de las características no unigrama, basadas en la proximidad para la búsqueda web basada en contenido observada previamente [14, 16]. Aunque nuestro modelo tiene más parámetros libres que los modelos de relevancia, sorprendentemente hay poco sobreajuste. En cambio, el modelo muestra buenas propiedades de generalización. 4.1.2 Expansión con Conceptos de Múltiples Términos También investigamos la expansión utilizando conceptos de una y dos palabras. Para cada consulta, expandimos utilizando un conjunto de conceptos de un solo término y un conjunto de conceptos de dos términos. Los conjuntos fueron elegidos de forma independiente. Desafortunadamente, solo se observaron aumentos insignificantes en la precisión promedio. Este resultado puede deberse al hecho de que existen fuertes correlaciones entre los conceptos de expansión de términos individuales. Descubrimos que los dos conceptos de palabras elegidos a menudo consistían en dos términos altamente correlacionados que también son elegidos como conceptos de términos individuales. Por ejemplo, se eligió el concepto de dos términos mercado de valores, mientras que también se eligieron los conceptos de un solo término acciones y mercado. Por lo tanto, muchos conceptos de dos palabras es poco probable que aumenten el poder discriminativo de la consulta ampliada. Este resultado sugiere que los conceptos deben ser elegidos de acuerdo con ciertos criterios que también tengan en cuenta la novedad, la diversidad o las correlaciones de términos. Otro problema potencial es el conjunto de características utilizado. Otros conjuntos de características pueden dar resultados diferentes en última instancia, especialmente si reducen la correlación entre los conceptos de expansión. Por lo tanto, nuestros experimentos no arrojan resultados concluyentes en cuanto a la expansión utilizando conceptos de varios términos. En cambio, los resultados plantean preguntas abiertas interesantes y direcciones para futuras exploraciones. Tabla 3: Promedio de precisión media en el conjunto de pruebas para modelado de lenguaje (LM), campo aleatorio de Markov (MRF), modelos de relevancia (<br>RM3</br>) y expansión de conceptos latentes (LCE). Los superíndices α, β y γ indican mejoras estadísticamente significativas (p < 0.05) sobre LM, MRF y <br>RM3</br>, respectivamente. 4.2 Robustez Como hemos demostrado, los modelos de relevancia y la expansión de conceptos latentes pueden mejorar significativamente la efectividad de recuperación sobre el modelo de probabilidad de consulta base. ",
            "candidates": [],
            "error": [
                [
                    "modelos de relevancia",
                    "RM3",
                    "RM3 LCE",
                    "RM3 LCE",
                    "RM3",
                    "RM3"
                ]
            ]
        },
        "document routing": {
            "translated_key": "en el enrutamiento de documentos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for <br>document routing</br> [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for <br>document routing</br> [19]."
            ],
            "translated_annotated_samples": [
                "Papka y Allan investigan el uso de retroalimentación de relevancia para realizar la expansión de conceptos de varios términos <br>en el enrutamiento de documentos</br> [19]."
            ],
            "translated_text": "Expansión de conceptos latentes utilizando campos aleatorios de Markov. Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Centro de Recuperación de Información Inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 RESUMEN La expansión de consultas, en forma de retroalimentación de pseudo relevancia o retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación. La mayoría de enfoques anteriores han ignorado problemas importantes, como el papel de las características y la importancia de modelar las dependencias entre términos. En este artículo, proponemos una técnica robusta de expansión de consultas basada en el modelo de campo aleatorio de Markov para la recuperación de información. La técnica, llamada expansión de conceptos latentes, proporciona un mecanismo para modelar las dependencias de términos durante la expansión. Además, el uso de características arbitrarias dentro del modelo proporciona un marco poderoso para ir más allá de las simples características de ocurrencia de términos que son utilizadas implícitamente por la mayoría de las otras técnicas de expansión. Evaluamos nuestra técnica frente a modelos de relevancia, una técnica de expansión de consultas de modelado de lenguaje de última generación. Nuestro modelo demuestra mejoras consistentes y significativas en la efectividad de recuperación en varios conjuntos de datos de TREC. También describimos cómo nuestra técnica puede ser utilizada para generar conceptos significativos de varios términos para tareas como sugerencia/reformulación de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales Algoritmos, Experimentación, Teoría 1. Los usuarios de los sistemas de recuperación de información deben expresar necesidades de información complejas en términos de expresiones booleanas, una lista corta de palabras clave, una oración, una pregunta o posiblemente un relato más extenso. Se pierde mucha información durante el proceso de traducción desde la necesidad de información hasta la consulta real. Por esta razón, ha habido un fuerte interés en las técnicas de expansión de consultas. Tales técnicas se utilizan para ampliar la consulta original y producir una representación que refleje mejor la necesidad de información subyacente. Las técnicas de expansión de consultas han sido ampliamente estudiadas para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la retroalimentación de pseudo-relevancia [12, 21, 28, 29]. Recientemente, se propuso un modelo de campo aleatorio de Markov (MRF) para la recuperación de información que va más allá de la simplista suposición de bolsa de palabras que subyace en BM25 y en el enfoque de modelado de lenguaje (unigrama) para la recuperación de información [20, 22]. El modelo MRF generaliza los modelos de unigrama, bigrama y otras diversas dependencias [14]. La mayoría de los modelos de dependencia de términos pasados no han logrado mostrar mejoras consistentes y significativas sobre las líneas de base de unigramas, con pocas excepciones [8]. El modelo MRF, sin embargo, ha demostrado ser altamente efectivo en una serie de tareas, incluyendo la recuperación ad hoc [14, 16], la búsqueda de páginas con nombres [16] y la búsqueda web en japonés [6]. Hasta ahora, el modelo ha sido utilizado únicamente para clasificar documentos en respuesta a una consulta dada. En este trabajo, mostramos cómo el modelo puede ser ampliado y utilizado para la expansión de consultas utilizando una técnica que llamamos expansión de conceptos latentes (LCE). Hay tres contribuciones principales de nuestro trabajo. Primero, LCE proporciona un mecanismo para combinar la dependencia de términos con la expansión de consultas. Las técnicas de expansión de consultas anteriores se basan en modelos de bolsa de palabras. Por lo tanto, al realizar la expansión de consultas utilizando el modelo MRF, podemos estudiar la dinámica entre la dependencia de términos y la expansión de consultas. A continuación, como mostraremos, el modelo MRF permite que se utilicen características arbitrarias dentro del modelo. Las técnicas de expansión de consultas en el pasado solo han hecho uso implícito de características de ocurrencia de términos. Al utilizar conjuntos de características más robustos, es posible producir términos de expansión mejores que discriminan de manera más efectiva entre documentos relevantes y no relevantes. Finalmente, nuestro enfoque propuesto proporciona de manera fluida un mecanismo para generar conceptos de una sola y múltiples términos. La mayoría de las técnicas anteriores, por defecto, generan términos de forma independiente. Ha habido varios enfoques que hacen uso de conceptos generalizados, sin embargo, dichos enfoques fueron algo heurísticos y realizados fuera del modelo [19, 28]. Nuestro enfoque está motivado tanto formalmente como es una extensión natural del modelo subyacente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2 describimos enfoques relacionados de expansión de consultas. La sección 3 proporciona una visión general del modelo MRF y detalla nuestra técnica propuesta de expansión de conceptos latentes. En la Sección 4 evaluamos nuestro modelo propuesto y analizamos los resultados. Finalmente, la Sección 5 concluye el artículo y resume los principales resultados. 2. TRABAJO RELACIONADO Uno de los enfoques clásicos y más ampliamente utilizados para la expansión de consultas es el algoritmo de Rocchio [21]. El enfoque de Rocchio, que fue desarrollado dentro del modelo de espacio vectorial, reajusta el vector de consulta original moviendo los pesos hacia el conjunto de documentos relevantes o pseudo-relevantes y alejándolos de los documentos no relevantes. Desafortunadamente, no es posible aplicar formalmente el enfoque de Rocchio a un modelo de recuperación estadística, como el modelado del lenguaje para la recuperación de información. Se han desarrollado varias técnicas de expansión de consultas formalizadas para el marco de modelado de lenguaje, incluyendo el feedback basado en el modelo de Zhai y Lafferty y los modelos de relevancia de Lavrenko y Crofts [12, 29]. Ambos enfoques intentan utilizar documentos pseudo-relevantes o relevantes para estimar un modelo de consulta mejor. El feedback basado en modelos encuentra el modelo que mejor describe los documentos relevantes teniendo en cuenta un modelo de fondo (ruido). Esto separa el modelo de contenido del modelo de fondo. El modelo de contenido se interpola con el modelo de consulta original para formar la consulta ampliada. La otra técnica, modelos de relevancia, está más relacionada con nuestro trabajo. Por lo tanto, entramos en los detalles del modelo. Al igual que el feedback basado en modelos, los modelos de relevancia estiman un modelo de consulta mejorado. La única diferencia entre los dos enfoques es que los modelos de relevancia no modelan explícitamente los documentos relevantes o pseudo-relevantes. En cambio, ellos modelan una noción más generalizada de relevancia, como mostraremos ahora. Dada una consulta Q, un modelo de relevancia es una distribución multinomial, P(·|Q), que codifica la probabilidad de cada término dado la consulta como evidencia. Se calcula como: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) donde RQ es el conjunto de documentos que son relevantes o pseudo relevantes para la consulta Q. En el caso pseudo-relevante, estos son los documentos mejor clasificados para la consulta Q. Además, se asume que P(D) es uniforme en este conjunto. Estas suposiciones suaves hacen que el cálculo del posterior bayesiano sea más práctico. Después de que el modelo es estimado, los documentos son clasificados por recortar el modelo de relevancia al elegir los k términos más probables de P(·|Q). Esta distribución recortada se interpola luego con el modelo de consulta de máxima verosimilitud original. Esto se puede considerar como la expansión de la consulta original por k términos ponderados. A lo largo del resto de este trabajo, nos referimos a esta instancia de modelos de relevancia como RM3. Ha habido relativamente poco trabajo realizado en el área de expansión de consultas en el contexto de modelos de dependencia [9]. Sin embargo, ha habido varios intentos de expandir utilizando conceptos de varios términos. El método de análisis de contexto local (LCA) de Xu y Crofts combinaba la recuperación a nivel de pasaje con la expansión de conceptos, donde los conceptos eran términos y frases simples [28]. Los conceptos de expansión fueron elegidos y ponderados utilizando una métrica basada en estadísticas de co-ocurrencia. Sin embargo, no está claro, basándose en el análisis realizado, cuánto ayudaron las frases en comparación con los términos individuales solos. Papka y Allan investigan el uso de retroalimentación de relevancia para realizar la expansión de conceptos de varios términos <br>en el enrutamiento de documentos</br> [19]. Los conceptos utilizados en su trabajo son más generales que los utilizados en el LCA e incluyen estructuras de lenguaje de consulta InQuery, como #UW50(casa blanca), que corresponde al concepto en el que los términos casa y blanca ocurren, en cualquier orden, dentro de 50 términos uno del otro. Los resultados mostraron que combinar conceptos de un solo término y conceptos de varios términos con una ventana grande mejoró significativamente la efectividad. Sin embargo, no está claro si el mismo enfoque también es efectivo para la recuperación ad hoc, debido a las diferencias en las tareas. 3. Este apartado detalla nuestra técnica propuesta de expansión de conceptos latentes. Como se mencionó anteriormente, la técnica es una extensión del modelo MRF para la recuperación de información [14]. Por lo tanto, comenzamos proporcionando una visión general del modelo MRF y nuestras extensiones propuestas. 3.1 MRFs para IR 3.1.1 Conceptos básicos Los campos aleatorios de Markov, que son modelos gráficos no dirigidos, proporcionan una forma compacta y robusta de modelar una distribución conjunta. Aquí estamos interesados en modelar la distribución conjunta sobre una consulta Q = q1, . . . , qn y un documento D. Se asume que la distribución subyacente sobre pares de documentos y consultas es una distribución de relevancia. Es decir, muestrear de la distribución proporciona pares de documentos y consultas, de modo que el documento sea relevante para la consulta. Un MRF se define por un grafo G y un conjunto de funciones de potencial no negativas sobre los cliques en G. Los nodos en el grafo representan las variables aleatorias y las aristas definen la semántica de independencia de la distribución. Un MRF cumple con la propiedad de Markov, la cual establece que un nodo es independiente de todos sus nodos no vecinos dado los valores observados de sus vecinos. Dado un grafo G, un conjunto de potenciales ψi y un vector de parámetros Λ, la distribución conjunta sobre Q y D está dada por: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) donde Z es una constante de normalización. Seguimos la convención común y parametrizamos los potenciales como ψi(c; Λ) = exp[λifi(c)], donde fi(c) es una función de características de valores reales. 3.1.2 Construcción de G Dada una consulta Q, el grafo G puede ser construido de varias maneras. Sin embargo, siguiendo el trabajo previo, consideramos tres variantes simples [14]. Estas variantes son independencia total, donde cada término de consulta es independiente de los demás dado un documento, dependencia secuencial, que asume que existe una dependencia entre los términos de consulta adyacentes, y dependencia total, que no hace suposiciones de independencia. 3.1.3 Parametrización Los MRFs suelen ser parametrizados comúnmente en función de los cliques máximos de G. Sin embargo, dicha parametrización es demasiado gruesa para nuestras necesidades. Necesitamos una parametrización que nos permita asociar funciones de características con cliques a un nivel más detallado, manteniendo al mismo tiempo el número de características, y por lo tanto el número de parámetros, razonable. Por lo tanto, permitimos que los grupos compartan funciones de características y parámetros basados en conjuntos de grupos. Es decir, todos los subgrupos dentro de un conjunto de subgrupos están asociados con la misma función de característica y comparten un solo parámetro. Esto une de manera efectiva los parámetros de las características asociadas con cada conjunto, lo que reduce significativamente el número de parámetros mientras aún proporciona un mecanismo para el ajuste fino en el nivel de conjuntos de cliques. Proponemos siete conjuntos de cliques para utilizar en la recuperación de información. Los primeros tres conjuntos de cliques consisten en cliques que contienen uno o más términos de consulta y el nodo del documento. Las características sobre estos grupos deberían codificar qué tan bien los términos en la configuración del grupo describen el documento. Estos conjuntos son: • TD - conjunto de cliques que contienen el nodo del documento y exactamente un término de consulta. • OD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en orden secuencial dentro de la consulta. • UD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en cualquier orden dentro de la consulta. Ten en cuenta que UD es un superconjunto de OD. Al atar los parámetros entre los grupos dentro de cada conjunto podemos controlar cuánta influencia recibe cada tipo. Esto también evita el problema de tratar de determinar cómo estimar los pesos para cada clique dentro de los conjuntos. En cambio, ahora solo debemos estimar un parámetro por conjunto. A continuación, consideramos cliques que solo contienen nodos de términos de consulta. Estas cliques, que no fueron consideradas en [14], se definen de manera análoga a las recién definidas, excepto que las cliques solo están formadas por nodos de términos de consulta y no contienen el nodo de documento. Las funciones de características sobre estos conjuntos deben capturar qué tan compatibles son entre sí los términos de consulta. Estas características de grupo pueden adoptar la forma de modelos de lenguaje que imponen la corrección de los términos. Por lo tanto, definimos los siguientes conjuntos de cliques dependientes de la consulta: • TQ - conjunto de cliques que contienen exactamente un término de la consulta. • OQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en orden secuencial dentro de la consulta. • UQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en cualquier orden dentro de la consulta. Finalmente, está la clique que solo contiene el nodo del documento. Las características sobre este nodo pueden ser utilizadas como un tipo de documento previo, codificando propiedades centradas en el documento. Este conjunto de cliques trivial es entonces: • D - conjunto de cliques que contiene solo el nodo único D. Observamos que nuestros conjuntos de cliques forman una cobertura de conjuntos sobre los cliques de G, pero no son una partición, ya que algunos cliques aparecen en múltiples conjuntos de cliques. Después de atar los parámetros en nuestros conjuntos de cliques y usar la forma de la función potencial exponencial, terminamos con la siguiente forma simplificada de la distribución conjunta: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - dependiente del documento y la consulta + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - dependiente de la consulta + λDfD(D) FD(D) - dependiente del documento − log ZΛ documento + independiente de la consulta donde FDQ, FQ y FD son funciones de conveniencia definidas por los componentes dependientes del documento y la consulta, dependientes de la consulta y dependientes del documento de la distribución conjunta, respectivamente. Estos se utilizarán para simplificar y clarificar las expresiones derivadas a lo largo del resto del documento. 3.1.4 Características Cualquier función de característica arbitraria sobre configuraciones de cliques puede ser utilizada en el modelo. La elección correcta de las características depende en gran medida de la tarea de recuperación y la métrica de evaluación. Por lo tanto, es probable que no exista un conjunto único y universalmente aplicable de características. Para dar una idea de la variedad de características que se pueden utilizar, ahora describimos brevemente posibles tipos de características que podrían ser utilizadas. Posibles características dependientes del término de consulta incluyen tf, idf, entidades nombradas, proximidad de términos y estilo de texto, por nombrar algunas. Se pueden utilizar muchos tipos de características dependientes del documento, como la longitud del documento, el PageRank, la legibilidad y el género, entre otros. Dado que nuestro objetivo aquí no es encontrar características óptimas, utilizamos un conjunto simple y fijo de características que han demostrado ser efectivas en trabajos anteriores [14]. Consulte la Tabla 1 para ver la lista de características utilizadas. Estas características intentan capturar la ocurrencia de términos y la proximidad entre términos. Una mejor selección de características en el futuro probablemente conducirá a una mayor efectividad. 3.1.5 Clasificación Dada una consulta Q, deseamos clasificar los documentos en orden descendente según PG,Λ(D|Q). Después de eliminar las expresiones independientes del documento del registro PG,Λ(Q, D), derivamos la siguiente función de clasificación: PG,Λ(D|Q) rango = FDQ(D, Q) + FD(D) (2), que es una simple combinación lineal ponderada de funciones de características que pueden calcularse eficientemente para grafos razonables. 3.1.6 Estimación de Parámetros Ahora que el modelo ha sido completamente especificado, el paso final es estimar los parámetros del modelo. Aunque los MRF son modelos generativos, no es apropiado entrenarlos utilizando la función de valor de características fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Tabla 1: Funciones de características utilizadas en el modelo de campo aleatorio de Markov. Aquí, tfw,D es el número de veces que el término w ocurre en el documento D, tf#1(qi...qi+k),D denota el número de veces que la frase exacta qi . . . qi+k ocurre en el documento D, tf#uw(qi...qj ),D es el número de veces que los términos qi, . . . qj aparecen ordenados o desordenados dentro de una ventana de N términos, y |D| es la longitud del documento D. Los valores de cf y |C| se definen de manera análoga a nivel de colección. Finalmente, α y β son hiperparámetros del modelo que controlan el suavizado para las características de términos únicos y frases, respectivamente. Enfoques convencionales basados en la verosimilitud debido a la divergencia métrica [17]. Es decir, es poco probable que la estimación de máxima verosimilitud sea la estimación que maximiza nuestra métrica de evaluación. Por esta razón, entrenamos de manera discriminativa nuestro modelo para maximizar directamente la métrica de evaluación considerada [14, 15, 25]. Dado que nuestro espacio de parámetros es pequeño, hacemos uso de una estrategia simple de escalada de colina, aunque son posibles otros enfoques más sofisticados [10]. 3.2 Expansión de Conceptos Latentes En esta sección describimos cómo este modelo MRF extendido puede ser utilizado de una manera novedosa para generar conceptos de un solo término y de varios términos que están relacionados temáticamente con alguna consulta original. Como mostraremos, los conceptos generados utilizando nuestra técnica pueden ser utilizados para la expansión de consultas u otras tareas, como sugerir formulaciones alternativas de consultas. Suponemos que cuando un usuario formula su consulta original, tiene en mente un conjunto de conceptos, pero solo puede expresar un pequeño número de ellos en forma de consulta. Tratamos los conceptos que el usuario tiene en mente, pero no expresó explícitamente en la consulta, como conceptos latentes. Estos conceptos latentes pueden consistir en un solo término, varios términos o alguna combinación de ambos. Por lo tanto, nuestro objetivo es recuperar estos conceptos latentes dada alguna consulta original. Esto se puede lograr dentro de nuestro marco de trabajo al expandir primero el grafo original G para incluir el tipo de concepto que nos interesa generar. Llamamos a este gráfico expandido H. En la Figura 1, el gráfico del medio proporciona un ejemplo de cómo construir un gráfico expandido que puede generar conceptos de un solo término. De manera similar, el gráfico de la derecha ilustra un gráfico ampliado que genera dos conceptos de términos. Aunque estos dos ejemplos hacen uso de la suposición de dependencia secuencial (es decir, dependencias entre términos de consulta adyacentes), es importante tener en cuenta que tanto la consulta original como los conceptos de expansión pueden utilizar cualquier estructura de independencia. Después de que H se construye, calculamos PH,Λ(E|Q), una distribución de probabilidad sobre conceptos latentes, de acuerdo a: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) donde R es el universo de todos los documentos posibles y E es un concepto latente que puede consistir en uno o más términos. Dado que no es práctico calcular esta suma, debemos aproximarla. Observamos que PH,Λ(Q, E, D) probablemente se concentra alrededor de aquellos documentos D que están altamente clasificados según la consulta Q. Por lo tanto, aproximamos PH,Λ(E|Q) sumando solo un pequeño subconjunto de documentos relevantes o pseudo-relevantes para la consulta Q. Esto se calcula de la siguiente manera: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) donde RQ es un conjunto de documentos relevantes o pseudo-relevantes para la consulta Q y todos los conjuntos de cliques se construyen utilizando H. Como vemos, la contribución de probabilidad para cada documento en RQ es una combinación de la puntuación original de la consulta para el documento (ver Ecuación 2), la puntuación del concepto E para el documento y la puntuación independiente del documento de E. Por lo tanto, esta ecuación puede interpretarse como la medida de qué tan bien Q y E explican los documentos mejor clasificados y la bondad de E, independientemente de los documentos. Para lograr la máxima robustez, utilizamos un conjunto diferente de parámetros para FQD(Q, D) y FQD(E, D), lo que nos permite ponderar de manera diferente las características de ventana ordenadas y no ordenadas para la consulta original y el concepto de expansión candidato. 3.2.1 Expansión de consulta Para utilizar este marco para la expansión de consultas, primero elegimos un grafo de expansión H que codifique la estructura de concepto latente en la que estamos interesados en expandir la consulta. Luego seleccionamos los k conceptos latentes con la mayor probabilidad dada por la Ecuación 3. Se construye un nuevo grafo G al aumentar el grafo original G con los k conceptos de expansión E1, . . . , Ek. Finalmente, los documentos se clasifican según PG ,Λ(D|Q, E1, . . . , Ek) utilizando la Ecuación 2. 3.2.2 Comparación con los Modelos de Relevancia. Al inspeccionar las Ecuaciones 1 y 3 se revela la estrecha conexión que existe entre LCE y los modelos de relevancia. Ambos modelos esencialmente calculan la probabilidad de un término (o concepto) de la misma manera. Es fácil ver que al igual que el modelo MRF puede ser visto como una generalización del modelado del lenguaje, también LCE puede ser visto como una generalización de los modelos de relevancia. Existen diferencias importantes entre los modelos de lenguaje MRFs/LCE y los modelos de lenguaje unigram/relevancia. Consulte la Figura 1 para ver las representaciones gráficas de ambos modelos. Los modelos de lenguaje unigrama y los modelos de relevancia se basan en la distribución multinomial. Esta suposición de distribución encasilla el modelo en la representación de bolsa de palabras y el uso implícito de características de ocurrencia de términos. Sin embargo, la distribución subyacente al modelo MRF nos permite ir más allá de ambas suposiciones, al modelar tanto las dependencias entre los términos de consulta como permitir el uso explícito de características arbitrarias. Ir más allá de la simplista suposición de la bolsa de palabras de esta manera resulta en un modelo general y robusto y, como mostramos en la siguiente sección, se traduce en mejoras significativas en la efectividad de recuperación. 4. RESULTADOS EXPERIMENTALES Para comprender mejor las fortalezas y debilidades de nuestra técnica, la evaluamos en una amplia gama de conjuntos de datos. La Tabla 2 proporciona un resumen de los conjuntos de datos de TREC considerados. Las colecciones WSJ, AP y ROBUST son más pequeñas y consisten enteramente de artículos de agencias de noticias, mientras que WT10g y GOV2 son colecciones web grandes. Para cada conjunto de datos, dividimos los temas disponibles en un conjunto de entrenamiento y otro de prueba, donde el conjunto de entrenamiento se utiliza únicamente para la estimación de parámetros y el conjunto de prueba se utiliza con fines de evaluación. Todos los experimentos se llevaron a cabo utilizando una versión modificada de Indri, que forma parte del Lemur Toolkit [18, 23]. Todas las colecciones fueron detenidas utilizando una lista estándar de 418 términos comunes y truncadas utilizando un truncador de Porter. En todos los casos, solo se utiliza la parte del título de los temas de TREC para construir las consultas. Construimos G utilizando la suposición de dependencia secuencial para todos los conjuntos de datos [14]. 4.1 Resultados de recuperación ad-hoc Ahora investigamos qué tan bien se desempeña nuestro modelo en la práctica en un entorno de retroalimentación de relevancia pseudo. Comparamos el modelado de lenguaje unigrama (con suavizado de Dirichlet), el modelo MRF (sin expansión), los modelos de relevancia y LCE para comprender mejor cómo se desempeña cada modelo en los diferentes conjuntos de datos. Para el modelo de lenguaje unigrama, se entrenó el parámetro de suavizado. Para el modelo MRF, entrenamos los parámetros del modelo (es decir, y hiperparámetros del modelo (es decir, α, β). Para RM3 y LCE, también entrenamos el número de pseudoNombre Descripción # Docs Temas de Entrenamiento Temas de Prueba WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc. Presione 88-90 242,918 51-150 151-200 ROBUST Robust 2004 datos 528,155 301-450 601-700 WT10g Colección Web de TREC 1,692,096 451-500 501-550 GOV2 Rastreo 2004 del dominio .gov 25,205,179 701-750 751-800 Tabla 2: Resumen de las colecciones y temas de TREC. documentos de retroalimentación relevantes utilizados y el número de términos de expansión. 4.1.1 Expansión con Conceptos de Términos Únicos Comenzamos evaluando qué tan bien funciona nuestro modelo al expandir utilizando solo términos individuales. Antes de describir y analizar los resultados, declaramos explícitamente cómo se calculan las probabilidades de términos de expansión bajo esta configuración (es decir, utilizando la suposición de dependencia secuencial, expandiendo con conceptos de un solo término y utilizando nuestro conjunto de características). Las probabilidades de términos de expansión se calculan de la siguiente manera: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) donde b ∈ Q denota el conjunto de bigramas en Q. Esta ecuación muestra claramente cómo LCE difiere de los modelos de relevancia. Cuando establecemos λTD = λT,D = 1 y todos los demás parámetros en 0, obtenemos la fórmula exacta que se utiliza para calcular las probabilidades de términos en el marco de modelado de relevancia. Por lo tanto, LCE añade dos factores muy importantes a la ecuación. Primero, agrega las características de ventana ordenadas y no ordenadas que se aplican a la consulta original. En segundo lugar, aplica una forma intuitiva similar a tf.idf al término de expansión candidato w. El factor idf, que no está presente en los modelos de relevancia, juega un papel importante en la selección del término de expansión. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figura 2: Histogramas que demuestran y comparan la robustez de los modelos de relevancia (RM3) y la expansión de conceptos latentes (LCE) con respecto al modelo de probabilidad de consulta (QL) para los conjuntos de datos AP, ROBUST y WT10G. Los resultados, evaluados utilizando la precisión promedio media, se muestran en la Tabla 3. Como vemos, el modelo MRF, los modelos de relevancia y LCE siempre superan significativamente al modelo de lenguaje unigrama. Además, LCE muestra mejoras significativas sobre los modelos de relevancia en todos los conjuntos de datos. Las mejoras relativas sobre los modelos de relevancia son del 6.9% para AP, 12.9% para WSJ, 6.5% para ROBUST, 16.7% para WT10G y 7.3% para GOV2. Además, LCE muestra pequeñas mejoras, pero no significativas, respecto al modelado de relevancia para métricas como precisión en 5, 10 y 20. Sin embargo, tanto el modelado de relevancia como el LCE muestran mejoras estadísticamente significativas en dichas métricas sobre el modelo de lenguaje unigrama. Otro resultado interesante es que el modelo MRF es estadísticamente equivalente a los modelos de relevancia en los dos conjuntos de datos web. De hecho, el modelo MRF supera a los modelos de relevancia en el conjunto de datos WT10g. Esto reitera la importancia de las características no unigrama, basadas en la proximidad para la búsqueda web basada en contenido observada previamente [14, 16]. Aunque nuestro modelo tiene más parámetros libres que los modelos de relevancia, sorprendentemente hay poco sobreajuste. En cambio, el modelo muestra buenas propiedades de generalización. 4.1.2 Expansión con Conceptos de Múltiples Términos También investigamos la expansión utilizando conceptos de una y dos palabras. Para cada consulta, expandimos utilizando un conjunto de conceptos de un solo término y un conjunto de conceptos de dos términos. Los conjuntos fueron elegidos de forma independiente. Desafortunadamente, solo se observaron aumentos insignificantes en la precisión promedio. Este resultado puede deberse al hecho de que existen fuertes correlaciones entre los conceptos de expansión de términos individuales. Descubrimos que los dos conceptos de palabras elegidos a menudo consistían en dos términos altamente correlacionados que también son elegidos como conceptos de términos individuales. Por ejemplo, se eligió el concepto de dos términos mercado de valores, mientras que también se eligieron los conceptos de un solo término acciones y mercado. Por lo tanto, muchos conceptos de dos palabras es poco probable que aumenten el poder discriminativo de la consulta ampliada. Este resultado sugiere que los conceptos deben ser elegidos de acuerdo con ciertos criterios que también tengan en cuenta la novedad, la diversidad o las correlaciones de términos. Otro problema potencial es el conjunto de características utilizado. Otros conjuntos de características pueden dar resultados diferentes en última instancia, especialmente si reducen la correlación entre los conceptos de expansión. Por lo tanto, nuestros experimentos no arrojan resultados concluyentes en cuanto a la expansión utilizando conceptos de varios términos. En cambio, los resultados plantean preguntas abiertas interesantes y direcciones para futuras exploraciones. Tabla 3: Promedio de precisión media en el conjunto de pruebas para modelado de lenguaje (LM), campo aleatorio de Markov (MRF), modelos de relevancia (RM3) y expansión de conceptos latentes (LCE). Los superíndices α, β y γ indican mejoras estadísticamente significativas (p < 0.05) sobre LM, MRF y RM3, respectivamente. 4.2 Robustez Como hemos demostrado, los modelos de relevancia y la expansión de conceptos latentes pueden mejorar significativamente la efectividad de recuperación sobre el modelo de probabilidad de consulta base. En esta sección analizamos la robustez de estos dos métodos. Aquí definimos la robustez como el número de consultas cuya efectividad se ve mejorada/afectada (y en qué medida) como resultado de aplicar estos métodos. Una técnica de expansión altamente robusta mejorará significativamente muchas consultas y solo perjudicará mínimamente a unas pocas. La Figura 2 proporciona un análisis de la robustez del modelado de relevancia y la expansión de conceptos latentes para los conjuntos de datos AP, ROBUST y WT10G. El análisis de los dos conjuntos de datos no mostrados es similar. Los histogramas proporcionan, para varios rangos de disminuciones/aumentos relativos en la precisión media promedio, el número de consultas que se vieron perjudicadas/mejoradas con respecto a la línea base de probabilidad de consulta. Como muestran los resultados, LCE muestra una fuerte robustez para cada conjunto de datos. Para AP, los modelos de relevancia mejoran 38 consultas y perjudican 11, mientras que LCE mejora 35 y perjudica 14. Aunque los modelos de relevancia mejoran la efectividad de 3 consultas más que LCE, la mejora relativa exhibida por LCE es significativamente mayor. Para el conjunto de datos ROBUST, los modelos de relevancia mejoran 67 consultas y perjudican 32, y LCE mejora 77 y perjudica 22. Finalmente, para la colección WT10G, los modelos de relevancia mejoran 32 consultas y perjudican 16, y LCE mejora 35 y perjudica 14. Al igual que con AP, la cantidad de mejora exhibida por el LCE frente a los modelos de relevancia es significativamente mayor tanto para los conjuntos de datos ROBUST como WT10G. Además, cuando LCE afecta al rendimiento, es menos probable que afecte tanto como el modelado de relevancia, lo cual es una propiedad deseable. En general, LCE mejora la efectividad para el 65%-80% de las consultas, dependiendo del conjunto de datos. Cuando se utiliza en combinación con un sistema de predicción de rendimiento de consulta altamente preciso, puede ser posible expandir selectivamente las consultas y minimizar la pérdida asociada con el rendimiento sub-baseline. 4.3 Generación de Conceptos de Múltiples Términos Aunque encontramos que la expansión utilizando conceptos de múltiples términos no logró producir mejoras concluyentes en la efectividad, hay otras tareas potenciales para las cuales estos conceptos pueden ser útiles, como sugerencia/reformulación de consultas, resumen y extracción de conceptos. Por ejemplo, para una tarea de sugerencia de consultas, la consulta original podría usarse para generar un conjunto de conceptos latentes que corresponden a formulaciones alternativas de la consulta. Aunque evaluar nuestro modelo en estas tareas está fuera del alcance de este trabajo, deseamos mostrar un ejemplo ilustrativo de los tipos de conceptos generados utilizando nuestro modelo. En la Tabla 4, presentamos los conceptos de una, dos y tres palabras más probables generados utilizando LCE para la consulta logros del telescopio Hubble utilizando los 25 documentos mejor clasificados de la colección ROBUST. Es bien sabido que generar conceptos de múltiples términos utilizando un modelo basado en unigramas produce resultados insatisfactorios, ya que no considera las dependencias entre los términos. Esto no es el caso al generar conceptos de múltiples términos usando nuestro modelo. En cambio, la mayoría de los conceptos generados son bien formados y significativos. Hay varios casos donde los conceptos son menos coherentes, como espejo espejo espejo. En este caso, la probabilidad de que aparezca el término \"espejo\" en un documento pseudo-relevante supera a las características de modelado de lenguaje (por ejemplo, fOQ), lo que provoca que este concepto no coherente tenga una alta probabilidad. Tales ejemplos son minoría, sin embargo. No solo los conceptos generados son bien formados y significativos, sino que también son relevantes al tema de la consulta original. Como podemos ver, todos los conceptos generados están relacionados con el tema y de alguna manera están relacionados con el telescopio Hubble. Es interesante ver que el concepto de fallo del telescopio Hubble es uno de los tres conceptos de términos más probables, dado que es algo contradictorio con la consulta original. A pesar de esta contradicción, es probable que los documentos que discuten las fallas del telescopio también describan los éxitos, por lo tanto, es probable que este sea un concepto significativo. Una cosa importante a tener en cuenta es que los conceptos generados por LCE son de una naturaleza diferente a los que se generarían utilizando un modelo de relevancia de bigrama. Por ejemplo, un modelo de bigrama sería poco probable que genere el concepto telescopio espacio NASA, ya que ninguno de los bigramas que componen el concepto tiene una alta probabilidad. Sin embargo, dado que nuestro modelo se basa en una serie de características diferentes sobre varios tipos de cliques, es más general y robusto que un modelo de bigrama. Aunque solo proporcionamos los conceptos generados para una sola consulta, señalamos que el mismo análisis y conclusiones se generalizan a través de otros conjuntos de datos, con conceptos coherentes y relacionados temáticamente generados de manera consistente utilizando LCE. 4.4 Discusión Nuestra técnica de expansión de conceptos latentes captura dos tipos de dependencia semiortogonales. En la recuperación de información, ha existido un interés a largo plazo en comprender el papel de la dependencia de términos. De esta investigación, se han identificado dos tipos generales de dependencias. El primer tipo de dependencia es la dependencia sintáctica. Este tipo de dependencia abarca frases, proximidad de términos y co-ocurrencia de términos [2, 4, 5, 7, 26]. Estos métodos capturan el hecho de que las consultas imponen implícita o explícitamente un cierto conjunto de dependencias posicionales. El segundo tipo es la dependencia semántica. Ejemplos de dependencia semántica son la retroalimentación de relevancia, la retroalimentación de pseudo-relevancia, sinónimos y en cierta medida el truncamiento [3]. Estas técnicas han sido exploradas tanto en el lado de la consulta como en el lado del documento. En el lado de la consulta, esto se suele hacer utilizando alguna forma de expansión de consulta, como modelos de relevancia o LCE. En el lado del documento, esto se hace como expansión de documentos o suavizado de documentos [11, 13, 24]. Aunque puede haber cierta superposición entre las dependencias sintácticas y semánticas, en su mayoría son ortogonales. Nuestro modelo utiliza ambos tipos de dependencias. El uso de características de frase y proximidad dentro del modelo captura dependencias sintácticas, mientras que LCE captura dependencias semánticas del lado de la consulta. Esto explica por qué la mejora inicial en la efectividad lograda al usar el modelo MRF no se pierde después de la expansión de consultas. Si los mismos tipos de dependencias fueran capturados tanto por dependencias sintácticas como semánticas, se esperaría que LCE funcionara aproximadamente igual de bien que los modelos de relevancia. Por lo tanto, al modelar ambos tipos de dependencias, observamos un efecto aditivo en lugar de un efecto absorbente. Una área interesante de trabajo futuro es determinar si modelar las dependencias semánticas del lado del documento puede aportar algo al modelo. Resultados previos que han combinado dependencias semánticas del lado de la consulta y del documento han mostrado resultados mixtos [13, 27]. 5. CONCLUSIONES En este artículo propusimos una técnica robusta de expansión de consultas llamada expansión de conceptos latentes. La técnica se demostró ser una extensión natural del modelo de campo aleatorio de Markov para la recuperación de información y una generalización de los modelos de relevancia. LCE es novedoso en el sentido de que realiza una expansión de un solo término o de varios términos dentro de un marco que permite el modelado de dependencias entre términos y el uso de características arbitrarias, mientras que trabajos anteriores se basaban en la suposición de la bolsa de palabras y características de ocurrencia de términos. Mostramos que la técnica puede ser utilizada para producir conceptos de expansión de varios términos de alta calidad, bien formados y relevantes desde el punto de vista temático. Los conceptos generados pueden ser utilizados en un módulo de sugerencia de consultas alternativas. También demostramos que el modelo es altamente efectivo. De hecho, logra mejoras significativas en la precisión promedio media en comparación con los modelos de relevancia en una selección de conjuntos de datos de TREC. También se demostró que el modelo MRF por sí solo, sin ninguna expansión de consulta, supera a los modelos de relevancia en grandes conjuntos de datos web. Esto reafirma observaciones previas de que modelar dependencias a través del uso de características de proximidad dentro del MRF tiene un mayor impacto en colecciones más grandes y ruidosas que en colecciones más pequeñas y bien comportadas. Finalmente, reiteramos la importancia de elegir términos de expansión que modelen la relevancia, en lugar de los documentos relevantes, y mostramos cómo LCE captura tanto las dependencias sintácticas como semánticas del lado de la consulta. El trabajo futuro se centrará en incorporar dependencias del lado del documento también. Agradecimientos Este trabajo fue apoyado en parte por el Centro de Recuperación de Información Inteligente, en parte por la subvención NSF #CNS-0454018, en parte por ARDA y la subvención NSF #CCF-0205575, y en parte por Microsoft Live Labs. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son responsabilidad del autor o los autores y no necesariamente reflejan las del patrocinador.  REFERENCIAS [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker y C. Wade. UMass en TREC 2004: Novedad y DIFICULTAD. En Actas en línea de la Conferencia de Recuperación de Información de 2004, 2004. [2] C. L. A. Clarke y G. V. Cormack. Recuperación y clasificación de la subcadena más corta. ACM Trans. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate to Spanish? Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson y J. Callan. Expansión de consultas utilizando modelos de caminata aleatoria. En Proc. 14th Intl. Conf. sobre Gestión de Información y Conocimiento, páginas 704-711, 2005. [4] W. B. Croft. Consultas booleanas y dependencias de términos en modelos de recuperación probabilística. Revista de la Sociedad Americana de Ciencia de la Información, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle y D. Lewis. El uso de frases y consultas estructuradas en la recuperación de información. En Proc. 14º Anu. Internacional. Conferencia ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 32-45, 1991. [6] K. Eguchi. Experimentos de expansión de consultas NTCIR-5 utilizando modelos de dependencia de términos. En Actas del Quinto Taller de Reunión NTCIR sobre Evaluación de Tecnologías de Acceso a la Información, páginas 494-501, 2005. [7] J. Fagan. Indexación automática de frases para la recuperación de documentos: Un examen de métodos sintácticos y no sintácticos. En el Proc. décimo anual. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 91-101, 1987. [8] J. Gao, J. Nie, G. Wu y G. Cao. Modelo de lenguaje de dependencia para recuperación de información. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 170-177, 2004. [9] D. Harper y C. J. van Rijsbergen. Una evaluación de la retroalimentación en la recuperación de documentos utilizando datos de co-ocurrencia. Revista de Documentación, 34(3):189-216, 1978. [10] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Proc. de la Conf. Internacional de Aprendizaje Automático, páginas 377-384, 2005. [11] O. Kurland y L. Lee. Estructura del corpus, modelos de lenguaje y recuperación de información ad-hoc. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 194-201, 2004. [12] V. Lavrenko y W. B. Croft. Modelos de lenguaje basados en relevancia. En Proc. 24º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 120-127, 2001. [13] X. Liu y W. B. Croft. Recuperación basada en clústeres utilizando modelos de lenguaje. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 186-193, 2004. [14] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias entre términos. En Proc. 28vo Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [15] D. Metzler y W. B. Croft. Modelos basados en características lineales para la recuperación de información. Recuperación de información, por aparecer, 2006. [16] D. Metzler, T. Strohman, Y. Zhou y W. B. Croft. Indri en la pista de terabyte en 2005. En Actas en línea de la Conferencia de Recuperación de Texto de 2005, 2005. [17] W. Morgan, W. Greiff y J. Henderson. Maximización directa de la precisión promedio mediante escalada de colina con una comparación con un enfoque de entropía máxima. Informe técnico, MITRE, 2004. [18] P. Ogilvie y J. P. Callan. Experimentos utilizando el kit de herramientas de lémures. En Proc. de la Conferencia de Recuperación de Texto, 2001. [19] R. Papka y J. Allan. Por qué las ventanas más grandes son mejores que las más pequeñas. Informe técnico, Universidad de Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu y M. Gatford. Okapi en trec-3. En Actas en línea de la Tercera Conferencia de Recuperación de Texto, páginas 109-126, 1995. [21] J. J. Rocchio. Retroalimentación de relevancia en la recuperación de información, páginas 313-323. Prentice-Hall, 1971. [22] F. Song y W. B. Croft. Un modelo de lenguaje general para la recuperación de información. En Proc. octava conferencia internacional sobre Gestión de la Información y el Conocimiento (CIKM 99), páginas 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle y W. B. Croft. Indri: Un motor de búsqueda basado en modelos de lenguaje para consultas complejas. En Actas de la Conferencia Internacional sobre Análisis de Inteligencia, 2004. [24] T. Tao, X. Wang, Q. Mei y C. Zhai. Recuperación de información del modelo de lenguaje con expansión de documentos. En Proc. de HLT/NAACL, páginas 407-414, 2006. [25] B. Taskar, C. Guestrin y D. Koller. Redes de Markov de margen máximo. En Proc. de Avances en Sistemas de Información Neural (NIPS 2003), 2003. [26] C. J. van Rijsbergen. Una base teórica para el uso de datos de coocurrencia en la recuperación de información. Revista de Documentación, 33(2):106-119, 1977. [27] X. Wei y W. B. Croft. Modelos de documentos basados en LDA para recuperación ad-hoc. En Proc. 29º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 178-185, 2006. [28] J. Xu y W. B. Croft. Mejorando la efectividad de la recuperación de información con análisis de contexto local. ACM Trans. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate into Spanish? Syst., 18(1):79-112, 2000. [29] C. Zhai y J. Lafferty. Retroalimentación basada en modelos en el enfoque de modelado del lenguaje para la recuperación de información. En Proc. 10th Intl. Conferencia sobre Gestión de la Información y el Conocimiento, páginas 403-410, 2001. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "ad-hoc retrieval": {
            "translated_key": "recuperación ad-hoc",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 <br>ad-hoc retrieval</br> Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for <br>ad-hoc retrieval</br>.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 <br>ad-hoc retrieval</br> Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "LDA-based document models for <br>ad-hoc retrieval</br>."
            ],
            "translated_annotated_samples": [
                "Construimos G utilizando la suposición de dependencia secuencial para todos los conjuntos de datos [14]. 4.1 Resultados de <br>recuperación ad-hoc</br> Ahora investigamos qué tan bien se desempeña nuestro modelo en la práctica en un entorno de retroalimentación de relevancia pseudo.",
                "Modelos de documentos basados en LDA para <br>recuperación ad-hoc</br>."
            ],
            "translated_text": "Expansión de conceptos latentes utilizando campos aleatorios de Markov. Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Centro de Recuperación de Información Inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 RESUMEN La expansión de consultas, en forma de retroalimentación de pseudo relevancia o retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación. La mayoría de enfoques anteriores han ignorado problemas importantes, como el papel de las características y la importancia de modelar las dependencias entre términos. En este artículo, proponemos una técnica robusta de expansión de consultas basada en el modelo de campo aleatorio de Markov para la recuperación de información. La técnica, llamada expansión de conceptos latentes, proporciona un mecanismo para modelar las dependencias de términos durante la expansión. Además, el uso de características arbitrarias dentro del modelo proporciona un marco poderoso para ir más allá de las simples características de ocurrencia de términos que son utilizadas implícitamente por la mayoría de las otras técnicas de expansión. Evaluamos nuestra técnica frente a modelos de relevancia, una técnica de expansión de consultas de modelado de lenguaje de última generación. Nuestro modelo demuestra mejoras consistentes y significativas en la efectividad de recuperación en varios conjuntos de datos de TREC. También describimos cómo nuestra técnica puede ser utilizada para generar conceptos significativos de varios términos para tareas como sugerencia/reformulación de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales Algoritmos, Experimentación, Teoría 1. Los usuarios de los sistemas de recuperación de información deben expresar necesidades de información complejas en términos de expresiones booleanas, una lista corta de palabras clave, una oración, una pregunta o posiblemente un relato más extenso. Se pierde mucha información durante el proceso de traducción desde la necesidad de información hasta la consulta real. Por esta razón, ha habido un fuerte interés en las técnicas de expansión de consultas. Tales técnicas se utilizan para ampliar la consulta original y producir una representación que refleje mejor la necesidad de información subyacente. Las técnicas de expansión de consultas han sido ampliamente estudiadas para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la retroalimentación de pseudo-relevancia [12, 21, 28, 29]. Recientemente, se propuso un modelo de campo aleatorio de Markov (MRF) para la recuperación de información que va más allá de la simplista suposición de bolsa de palabras que subyace en BM25 y en el enfoque de modelado de lenguaje (unigrama) para la recuperación de información [20, 22]. El modelo MRF generaliza los modelos de unigrama, bigrama y otras diversas dependencias [14]. La mayoría de los modelos de dependencia de términos pasados no han logrado mostrar mejoras consistentes y significativas sobre las líneas de base de unigramas, con pocas excepciones [8]. El modelo MRF, sin embargo, ha demostrado ser altamente efectivo en una serie de tareas, incluyendo la recuperación ad hoc [14, 16], la búsqueda de páginas con nombres [16] y la búsqueda web en japonés [6]. Hasta ahora, el modelo ha sido utilizado únicamente para clasificar documentos en respuesta a una consulta dada. En este trabajo, mostramos cómo el modelo puede ser ampliado y utilizado para la expansión de consultas utilizando una técnica que llamamos expansión de conceptos latentes (LCE). Hay tres contribuciones principales de nuestro trabajo. Primero, LCE proporciona un mecanismo para combinar la dependencia de términos con la expansión de consultas. Las técnicas de expansión de consultas anteriores se basan en modelos de bolsa de palabras. Por lo tanto, al realizar la expansión de consultas utilizando el modelo MRF, podemos estudiar la dinámica entre la dependencia de términos y la expansión de consultas. A continuación, como mostraremos, el modelo MRF permite que se utilicen características arbitrarias dentro del modelo. Las técnicas de expansión de consultas en el pasado solo han hecho uso implícito de características de ocurrencia de términos. Al utilizar conjuntos de características más robustos, es posible producir términos de expansión mejores que discriminan de manera más efectiva entre documentos relevantes y no relevantes. Finalmente, nuestro enfoque propuesto proporciona de manera fluida un mecanismo para generar conceptos de una sola y múltiples términos. La mayoría de las técnicas anteriores, por defecto, generan términos de forma independiente. Ha habido varios enfoques que hacen uso de conceptos generalizados, sin embargo, dichos enfoques fueron algo heurísticos y realizados fuera del modelo [19, 28]. Nuestro enfoque está motivado tanto formalmente como es una extensión natural del modelo subyacente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2 describimos enfoques relacionados de expansión de consultas. La sección 3 proporciona una visión general del modelo MRF y detalla nuestra técnica propuesta de expansión de conceptos latentes. En la Sección 4 evaluamos nuestro modelo propuesto y analizamos los resultados. Finalmente, la Sección 5 concluye el artículo y resume los principales resultados. 2. TRABAJO RELACIONADO Uno de los enfoques clásicos y más ampliamente utilizados para la expansión de consultas es el algoritmo de Rocchio [21]. El enfoque de Rocchio, que fue desarrollado dentro del modelo de espacio vectorial, reajusta el vector de consulta original moviendo los pesos hacia el conjunto de documentos relevantes o pseudo-relevantes y alejándolos de los documentos no relevantes. Desafortunadamente, no es posible aplicar formalmente el enfoque de Rocchio a un modelo de recuperación estadística, como el modelado del lenguaje para la recuperación de información. Se han desarrollado varias técnicas de expansión de consultas formalizadas para el marco de modelado de lenguaje, incluyendo el feedback basado en el modelo de Zhai y Lafferty y los modelos de relevancia de Lavrenko y Crofts [12, 29]. Ambos enfoques intentan utilizar documentos pseudo-relevantes o relevantes para estimar un modelo de consulta mejor. El feedback basado en modelos encuentra el modelo que mejor describe los documentos relevantes teniendo en cuenta un modelo de fondo (ruido). Esto separa el modelo de contenido del modelo de fondo. El modelo de contenido se interpola con el modelo de consulta original para formar la consulta ampliada. La otra técnica, modelos de relevancia, está más relacionada con nuestro trabajo. Por lo tanto, entramos en los detalles del modelo. Al igual que el feedback basado en modelos, los modelos de relevancia estiman un modelo de consulta mejorado. La única diferencia entre los dos enfoques es que los modelos de relevancia no modelan explícitamente los documentos relevantes o pseudo-relevantes. En cambio, ellos modelan una noción más generalizada de relevancia, como mostraremos ahora. Dada una consulta Q, un modelo de relevancia es una distribución multinomial, P(·|Q), que codifica la probabilidad de cada término dado la consulta como evidencia. Se calcula como: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) donde RQ es el conjunto de documentos que son relevantes o pseudo relevantes para la consulta Q. En el caso pseudo-relevante, estos son los documentos mejor clasificados para la consulta Q. Además, se asume que P(D) es uniforme en este conjunto. Estas suposiciones suaves hacen que el cálculo del posterior bayesiano sea más práctico. Después de que el modelo es estimado, los documentos son clasificados por recortar el modelo de relevancia al elegir los k términos más probables de P(·|Q). Esta distribución recortada se interpola luego con el modelo de consulta de máxima verosimilitud original. Esto se puede considerar como la expansión de la consulta original por k términos ponderados. A lo largo del resto de este trabajo, nos referimos a esta instancia de modelos de relevancia como RM3. Ha habido relativamente poco trabajo realizado en el área de expansión de consultas en el contexto de modelos de dependencia [9]. Sin embargo, ha habido varios intentos de expandir utilizando conceptos de varios términos. El método de análisis de contexto local (LCA) de Xu y Crofts combinaba la recuperación a nivel de pasaje con la expansión de conceptos, donde los conceptos eran términos y frases simples [28]. Los conceptos de expansión fueron elegidos y ponderados utilizando una métrica basada en estadísticas de co-ocurrencia. Sin embargo, no está claro, basándose en el análisis realizado, cuánto ayudaron las frases en comparación con los términos individuales solos. Papka y Allan investigan el uso de retroalimentación de relevancia para realizar la expansión de conceptos de varios términos en el enrutamiento de documentos [19]. Los conceptos utilizados en su trabajo son más generales que los utilizados en el LCA e incluyen estructuras de lenguaje de consulta InQuery, como #UW50(casa blanca), que corresponde al concepto en el que los términos casa y blanca ocurren, en cualquier orden, dentro de 50 términos uno del otro. Los resultados mostraron que combinar conceptos de un solo término y conceptos de varios términos con una ventana grande mejoró significativamente la efectividad. Sin embargo, no está claro si el mismo enfoque también es efectivo para la recuperación ad hoc, debido a las diferencias en las tareas. 3. Este apartado detalla nuestra técnica propuesta de expansión de conceptos latentes. Como se mencionó anteriormente, la técnica es una extensión del modelo MRF para la recuperación de información [14]. Por lo tanto, comenzamos proporcionando una visión general del modelo MRF y nuestras extensiones propuestas. 3.1 MRFs para IR 3.1.1 Conceptos básicos Los campos aleatorios de Markov, que son modelos gráficos no dirigidos, proporcionan una forma compacta y robusta de modelar una distribución conjunta. Aquí estamos interesados en modelar la distribución conjunta sobre una consulta Q = q1, . . . , qn y un documento D. Se asume que la distribución subyacente sobre pares de documentos y consultas es una distribución de relevancia. Es decir, muestrear de la distribución proporciona pares de documentos y consultas, de modo que el documento sea relevante para la consulta. Un MRF se define por un grafo G y un conjunto de funciones de potencial no negativas sobre los cliques en G. Los nodos en el grafo representan las variables aleatorias y las aristas definen la semántica de independencia de la distribución. Un MRF cumple con la propiedad de Markov, la cual establece que un nodo es independiente de todos sus nodos no vecinos dado los valores observados de sus vecinos. Dado un grafo G, un conjunto de potenciales ψi y un vector de parámetros Λ, la distribución conjunta sobre Q y D está dada por: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) donde Z es una constante de normalización. Seguimos la convención común y parametrizamos los potenciales como ψi(c; Λ) = exp[λifi(c)], donde fi(c) es una función de características de valores reales. 3.1.2 Construcción de G Dada una consulta Q, el grafo G puede ser construido de varias maneras. Sin embargo, siguiendo el trabajo previo, consideramos tres variantes simples [14]. Estas variantes son independencia total, donde cada término de consulta es independiente de los demás dado un documento, dependencia secuencial, que asume que existe una dependencia entre los términos de consulta adyacentes, y dependencia total, que no hace suposiciones de independencia. 3.1.3 Parametrización Los MRFs suelen ser parametrizados comúnmente en función de los cliques máximos de G. Sin embargo, dicha parametrización es demasiado gruesa para nuestras necesidades. Necesitamos una parametrización que nos permita asociar funciones de características con cliques a un nivel más detallado, manteniendo al mismo tiempo el número de características, y por lo tanto el número de parámetros, razonable. Por lo tanto, permitimos que los grupos compartan funciones de características y parámetros basados en conjuntos de grupos. Es decir, todos los subgrupos dentro de un conjunto de subgrupos están asociados con la misma función de característica y comparten un solo parámetro. Esto une de manera efectiva los parámetros de las características asociadas con cada conjunto, lo que reduce significativamente el número de parámetros mientras aún proporciona un mecanismo para el ajuste fino en el nivel de conjuntos de cliques. Proponemos siete conjuntos de cliques para utilizar en la recuperación de información. Los primeros tres conjuntos de cliques consisten en cliques que contienen uno o más términos de consulta y el nodo del documento. Las características sobre estos grupos deberían codificar qué tan bien los términos en la configuración del grupo describen el documento. Estos conjuntos son: • TD - conjunto de cliques que contienen el nodo del documento y exactamente un término de consulta. • OD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en orden secuencial dentro de la consulta. • UD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en cualquier orden dentro de la consulta. Ten en cuenta que UD es un superconjunto de OD. Al atar los parámetros entre los grupos dentro de cada conjunto podemos controlar cuánta influencia recibe cada tipo. Esto también evita el problema de tratar de determinar cómo estimar los pesos para cada clique dentro de los conjuntos. En cambio, ahora solo debemos estimar un parámetro por conjunto. A continuación, consideramos cliques que solo contienen nodos de términos de consulta. Estas cliques, que no fueron consideradas en [14], se definen de manera análoga a las recién definidas, excepto que las cliques solo están formadas por nodos de términos de consulta y no contienen el nodo de documento. Las funciones de características sobre estos conjuntos deben capturar qué tan compatibles son entre sí los términos de consulta. Estas características de grupo pueden adoptar la forma de modelos de lenguaje que imponen la corrección de los términos. Por lo tanto, definimos los siguientes conjuntos de cliques dependientes de la consulta: • TQ - conjunto de cliques que contienen exactamente un término de la consulta. • OQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en orden secuencial dentro de la consulta. • UQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en cualquier orden dentro de la consulta. Finalmente, está la clique que solo contiene el nodo del documento. Las características sobre este nodo pueden ser utilizadas como un tipo de documento previo, codificando propiedades centradas en el documento. Este conjunto de cliques trivial es entonces: • D - conjunto de cliques que contiene solo el nodo único D. Observamos que nuestros conjuntos de cliques forman una cobertura de conjuntos sobre los cliques de G, pero no son una partición, ya que algunos cliques aparecen en múltiples conjuntos de cliques. Después de atar los parámetros en nuestros conjuntos de cliques y usar la forma de la función potencial exponencial, terminamos con la siguiente forma simplificada de la distribución conjunta: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - dependiente del documento y la consulta + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - dependiente de la consulta + λDfD(D) FD(D) - dependiente del documento − log ZΛ documento + independiente de la consulta donde FDQ, FQ y FD son funciones de conveniencia definidas por los componentes dependientes del documento y la consulta, dependientes de la consulta y dependientes del documento de la distribución conjunta, respectivamente. Estos se utilizarán para simplificar y clarificar las expresiones derivadas a lo largo del resto del documento. 3.1.4 Características Cualquier función de característica arbitraria sobre configuraciones de cliques puede ser utilizada en el modelo. La elección correcta de las características depende en gran medida de la tarea de recuperación y la métrica de evaluación. Por lo tanto, es probable que no exista un conjunto único y universalmente aplicable de características. Para dar una idea de la variedad de características que se pueden utilizar, ahora describimos brevemente posibles tipos de características que podrían ser utilizadas. Posibles características dependientes del término de consulta incluyen tf, idf, entidades nombradas, proximidad de términos y estilo de texto, por nombrar algunas. Se pueden utilizar muchos tipos de características dependientes del documento, como la longitud del documento, el PageRank, la legibilidad y el género, entre otros. Dado que nuestro objetivo aquí no es encontrar características óptimas, utilizamos un conjunto simple y fijo de características que han demostrado ser efectivas en trabajos anteriores [14]. Consulte la Tabla 1 para ver la lista de características utilizadas. Estas características intentan capturar la ocurrencia de términos y la proximidad entre términos. Una mejor selección de características en el futuro probablemente conducirá a una mayor efectividad. 3.1.5 Clasificación Dada una consulta Q, deseamos clasificar los documentos en orden descendente según PG,Λ(D|Q). Después de eliminar las expresiones independientes del documento del registro PG,Λ(Q, D), derivamos la siguiente función de clasificación: PG,Λ(D|Q) rango = FDQ(D, Q) + FD(D) (2), que es una simple combinación lineal ponderada de funciones de características que pueden calcularse eficientemente para grafos razonables. 3.1.6 Estimación de Parámetros Ahora que el modelo ha sido completamente especificado, el paso final es estimar los parámetros del modelo. Aunque los MRF son modelos generativos, no es apropiado entrenarlos utilizando la función de valor de características fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Tabla 1: Funciones de características utilizadas en el modelo de campo aleatorio de Markov. Aquí, tfw,D es el número de veces que el término w ocurre en el documento D, tf#1(qi...qi+k),D denota el número de veces que la frase exacta qi . . . qi+k ocurre en el documento D, tf#uw(qi...qj ),D es el número de veces que los términos qi, . . . qj aparecen ordenados o desordenados dentro de una ventana de N términos, y |D| es la longitud del documento D. Los valores de cf y |C| se definen de manera análoga a nivel de colección. Finalmente, α y β son hiperparámetros del modelo que controlan el suavizado para las características de términos únicos y frases, respectivamente. Enfoques convencionales basados en la verosimilitud debido a la divergencia métrica [17]. Es decir, es poco probable que la estimación de máxima verosimilitud sea la estimación que maximiza nuestra métrica de evaluación. Por esta razón, entrenamos de manera discriminativa nuestro modelo para maximizar directamente la métrica de evaluación considerada [14, 15, 25]. Dado que nuestro espacio de parámetros es pequeño, hacemos uso de una estrategia simple de escalada de colina, aunque son posibles otros enfoques más sofisticados [10]. 3.2 Expansión de Conceptos Latentes En esta sección describimos cómo este modelo MRF extendido puede ser utilizado de una manera novedosa para generar conceptos de un solo término y de varios términos que están relacionados temáticamente con alguna consulta original. Como mostraremos, los conceptos generados utilizando nuestra técnica pueden ser utilizados para la expansión de consultas u otras tareas, como sugerir formulaciones alternativas de consultas. Suponemos que cuando un usuario formula su consulta original, tiene en mente un conjunto de conceptos, pero solo puede expresar un pequeño número de ellos en forma de consulta. Tratamos los conceptos que el usuario tiene en mente, pero no expresó explícitamente en la consulta, como conceptos latentes. Estos conceptos latentes pueden consistir en un solo término, varios términos o alguna combinación de ambos. Por lo tanto, nuestro objetivo es recuperar estos conceptos latentes dada alguna consulta original. Esto se puede lograr dentro de nuestro marco de trabajo al expandir primero el grafo original G para incluir el tipo de concepto que nos interesa generar. Llamamos a este gráfico expandido H. En la Figura 1, el gráfico del medio proporciona un ejemplo de cómo construir un gráfico expandido que puede generar conceptos de un solo término. De manera similar, el gráfico de la derecha ilustra un gráfico ampliado que genera dos conceptos de términos. Aunque estos dos ejemplos hacen uso de la suposición de dependencia secuencial (es decir, dependencias entre términos de consulta adyacentes), es importante tener en cuenta que tanto la consulta original como los conceptos de expansión pueden utilizar cualquier estructura de independencia. Después de que H se construye, calculamos PH,Λ(E|Q), una distribución de probabilidad sobre conceptos latentes, de acuerdo a: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) donde R es el universo de todos los documentos posibles y E es un concepto latente que puede consistir en uno o más términos. Dado que no es práctico calcular esta suma, debemos aproximarla. Observamos que PH,Λ(Q, E, D) probablemente se concentra alrededor de aquellos documentos D que están altamente clasificados según la consulta Q. Por lo tanto, aproximamos PH,Λ(E|Q) sumando solo un pequeño subconjunto de documentos relevantes o pseudo-relevantes para la consulta Q. Esto se calcula de la siguiente manera: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) donde RQ es un conjunto de documentos relevantes o pseudo-relevantes para la consulta Q y todos los conjuntos de cliques se construyen utilizando H. Como vemos, la contribución de probabilidad para cada documento en RQ es una combinación de la puntuación original de la consulta para el documento (ver Ecuación 2), la puntuación del concepto E para el documento y la puntuación independiente del documento de E. Por lo tanto, esta ecuación puede interpretarse como la medida de qué tan bien Q y E explican los documentos mejor clasificados y la bondad de E, independientemente de los documentos. Para lograr la máxima robustez, utilizamos un conjunto diferente de parámetros para FQD(Q, D) y FQD(E, D), lo que nos permite ponderar de manera diferente las características de ventana ordenadas y no ordenadas para la consulta original y el concepto de expansión candidato. 3.2.1 Expansión de consulta Para utilizar este marco para la expansión de consultas, primero elegimos un grafo de expansión H que codifique la estructura de concepto latente en la que estamos interesados en expandir la consulta. Luego seleccionamos los k conceptos latentes con la mayor probabilidad dada por la Ecuación 3. Se construye un nuevo grafo G al aumentar el grafo original G con los k conceptos de expansión E1, . . . , Ek. Finalmente, los documentos se clasifican según PG ,Λ(D|Q, E1, . . . , Ek) utilizando la Ecuación 2. 3.2.2 Comparación con los Modelos de Relevancia. Al inspeccionar las Ecuaciones 1 y 3 se revela la estrecha conexión que existe entre LCE y los modelos de relevancia. Ambos modelos esencialmente calculan la probabilidad de un término (o concepto) de la misma manera. Es fácil ver que al igual que el modelo MRF puede ser visto como una generalización del modelado del lenguaje, también LCE puede ser visto como una generalización de los modelos de relevancia. Existen diferencias importantes entre los modelos de lenguaje MRFs/LCE y los modelos de lenguaje unigram/relevancia. Consulte la Figura 1 para ver las representaciones gráficas de ambos modelos. Los modelos de lenguaje unigrama y los modelos de relevancia se basan en la distribución multinomial. Esta suposición de distribución encasilla el modelo en la representación de bolsa de palabras y el uso implícito de características de ocurrencia de términos. Sin embargo, la distribución subyacente al modelo MRF nos permite ir más allá de ambas suposiciones, al modelar tanto las dependencias entre los términos de consulta como permitir el uso explícito de características arbitrarias. Ir más allá de la simplista suposición de la bolsa de palabras de esta manera resulta en un modelo general y robusto y, como mostramos en la siguiente sección, se traduce en mejoras significativas en la efectividad de recuperación. 4. RESULTADOS EXPERIMENTALES Para comprender mejor las fortalezas y debilidades de nuestra técnica, la evaluamos en una amplia gama de conjuntos de datos. La Tabla 2 proporciona un resumen de los conjuntos de datos de TREC considerados. Las colecciones WSJ, AP y ROBUST son más pequeñas y consisten enteramente de artículos de agencias de noticias, mientras que WT10g y GOV2 son colecciones web grandes. Para cada conjunto de datos, dividimos los temas disponibles en un conjunto de entrenamiento y otro de prueba, donde el conjunto de entrenamiento se utiliza únicamente para la estimación de parámetros y el conjunto de prueba se utiliza con fines de evaluación. Todos los experimentos se llevaron a cabo utilizando una versión modificada de Indri, que forma parte del Lemur Toolkit [18, 23]. Todas las colecciones fueron detenidas utilizando una lista estándar de 418 términos comunes y truncadas utilizando un truncador de Porter. En todos los casos, solo se utiliza la parte del título de los temas de TREC para construir las consultas. Construimos G utilizando la suposición de dependencia secuencial para todos los conjuntos de datos [14]. 4.1 Resultados de <br>recuperación ad-hoc</br> Ahora investigamos qué tan bien se desempeña nuestro modelo en la práctica en un entorno de retroalimentación de relevancia pseudo. Comparamos el modelado de lenguaje unigrama (con suavizado de Dirichlet), el modelo MRF (sin expansión), los modelos de relevancia y LCE para comprender mejor cómo se desempeña cada modelo en los diferentes conjuntos de datos. Para el modelo de lenguaje unigrama, se entrenó el parámetro de suavizado. Para el modelo MRF, entrenamos los parámetros del modelo (es decir, y hiperparámetros del modelo (es decir, α, β). Para RM3 y LCE, también entrenamos el número de pseudoNombre Descripción # Docs Temas de Entrenamiento Temas de Prueba WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc. Presione 88-90 242,918 51-150 151-200 ROBUST Robust 2004 datos 528,155 301-450 601-700 WT10g Colección Web de TREC 1,692,096 451-500 501-550 GOV2 Rastreo 2004 del dominio .gov 25,205,179 701-750 751-800 Tabla 2: Resumen de las colecciones y temas de TREC. documentos de retroalimentación relevantes utilizados y el número de términos de expansión. 4.1.1 Expansión con Conceptos de Términos Únicos Comenzamos evaluando qué tan bien funciona nuestro modelo al expandir utilizando solo términos individuales. Antes de describir y analizar los resultados, declaramos explícitamente cómo se calculan las probabilidades de términos de expansión bajo esta configuración (es decir, utilizando la suposición de dependencia secuencial, expandiendo con conceptos de un solo término y utilizando nuestro conjunto de características). Las probabilidades de términos de expansión se calculan de la siguiente manera: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) donde b ∈ Q denota el conjunto de bigramas en Q. Esta ecuación muestra claramente cómo LCE difiere de los modelos de relevancia. Cuando establecemos λTD = λT,D = 1 y todos los demás parámetros en 0, obtenemos la fórmula exacta que se utiliza para calcular las probabilidades de términos en el marco de modelado de relevancia. Por lo tanto, LCE añade dos factores muy importantes a la ecuación. Primero, agrega las características de ventana ordenadas y no ordenadas que se aplican a la consulta original. En segundo lugar, aplica una forma intuitiva similar a tf.idf al término de expansión candidato w. El factor idf, que no está presente en los modelos de relevancia, juega un papel importante en la selección del término de expansión. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figura 2: Histogramas que demuestran y comparan la robustez de los modelos de relevancia (RM3) y la expansión de conceptos latentes (LCE) con respecto al modelo de probabilidad de consulta (QL) para los conjuntos de datos AP, ROBUST y WT10G. Los resultados, evaluados utilizando la precisión promedio media, se muestran en la Tabla 3. Como vemos, el modelo MRF, los modelos de relevancia y LCE siempre superan significativamente al modelo de lenguaje unigrama. Además, LCE muestra mejoras significativas sobre los modelos de relevancia en todos los conjuntos de datos. Las mejoras relativas sobre los modelos de relevancia son del 6.9% para AP, 12.9% para WSJ, 6.5% para ROBUST, 16.7% para WT10G y 7.3% para GOV2. Además, LCE muestra pequeñas mejoras, pero no significativas, respecto al modelado de relevancia para métricas como precisión en 5, 10 y 20. Sin embargo, tanto el modelado de relevancia como el LCE muestran mejoras estadísticamente significativas en dichas métricas sobre el modelo de lenguaje unigrama. Otro resultado interesante es que el modelo MRF es estadísticamente equivalente a los modelos de relevancia en los dos conjuntos de datos web. De hecho, el modelo MRF supera a los modelos de relevancia en el conjunto de datos WT10g. Esto reitera la importancia de las características no unigrama, basadas en la proximidad para la búsqueda web basada en contenido observada previamente [14, 16]. Aunque nuestro modelo tiene más parámetros libres que los modelos de relevancia, sorprendentemente hay poco sobreajuste. En cambio, el modelo muestra buenas propiedades de generalización. 4.1.2 Expansión con Conceptos de Múltiples Términos También investigamos la expansión utilizando conceptos de una y dos palabras. Para cada consulta, expandimos utilizando un conjunto de conceptos de un solo término y un conjunto de conceptos de dos términos. Los conjuntos fueron elegidos de forma independiente. Desafortunadamente, solo se observaron aumentos insignificantes en la precisión promedio. Este resultado puede deberse al hecho de que existen fuertes correlaciones entre los conceptos de expansión de términos individuales. Descubrimos que los dos conceptos de palabras elegidos a menudo consistían en dos términos altamente correlacionados que también son elegidos como conceptos de términos individuales. Por ejemplo, se eligió el concepto de dos términos mercado de valores, mientras que también se eligieron los conceptos de un solo término acciones y mercado. Por lo tanto, muchos conceptos de dos palabras es poco probable que aumenten el poder discriminativo de la consulta ampliada. Este resultado sugiere que los conceptos deben ser elegidos de acuerdo con ciertos criterios que también tengan en cuenta la novedad, la diversidad o las correlaciones de términos. Otro problema potencial es el conjunto de características utilizado. Otros conjuntos de características pueden dar resultados diferentes en última instancia, especialmente si reducen la correlación entre los conceptos de expansión. Por lo tanto, nuestros experimentos no arrojan resultados concluyentes en cuanto a la expansión utilizando conceptos de varios términos. En cambio, los resultados plantean preguntas abiertas interesantes y direcciones para futuras exploraciones. Tabla 3: Promedio de precisión media en el conjunto de pruebas para modelado de lenguaje (LM), campo aleatorio de Markov (MRF), modelos de relevancia (RM3) y expansión de conceptos latentes (LCE). Los superíndices α, β y γ indican mejoras estadísticamente significativas (p < 0.05) sobre LM, MRF y RM3, respectivamente. 4.2 Robustez Como hemos demostrado, los modelos de relevancia y la expansión de conceptos latentes pueden mejorar significativamente la efectividad de recuperación sobre el modelo de probabilidad de consulta base. En esta sección analizamos la robustez de estos dos métodos. Aquí definimos la robustez como el número de consultas cuya efectividad se ve mejorada/afectada (y en qué medida) como resultado de aplicar estos métodos. Una técnica de expansión altamente robusta mejorará significativamente muchas consultas y solo perjudicará mínimamente a unas pocas. La Figura 2 proporciona un análisis de la robustez del modelado de relevancia y la expansión de conceptos latentes para los conjuntos de datos AP, ROBUST y WT10G. El análisis de los dos conjuntos de datos no mostrados es similar. Los histogramas proporcionan, para varios rangos de disminuciones/aumentos relativos en la precisión media promedio, el número de consultas que se vieron perjudicadas/mejoradas con respecto a la línea base de probabilidad de consulta. Como muestran los resultados, LCE muestra una fuerte robustez para cada conjunto de datos. Para AP, los modelos de relevancia mejoran 38 consultas y perjudican 11, mientras que LCE mejora 35 y perjudica 14. Aunque los modelos de relevancia mejoran la efectividad de 3 consultas más que LCE, la mejora relativa exhibida por LCE es significativamente mayor. Para el conjunto de datos ROBUST, los modelos de relevancia mejoran 67 consultas y perjudican 32, y LCE mejora 77 y perjudica 22. Finalmente, para la colección WT10G, los modelos de relevancia mejoran 32 consultas y perjudican 16, y LCE mejora 35 y perjudica 14. Al igual que con AP, la cantidad de mejora exhibida por el LCE frente a los modelos de relevancia es significativamente mayor tanto para los conjuntos de datos ROBUST como WT10G. Además, cuando LCE afecta al rendimiento, es menos probable que afecte tanto como el modelado de relevancia, lo cual es una propiedad deseable. En general, LCE mejora la efectividad para el 65%-80% de las consultas, dependiendo del conjunto de datos. Cuando se utiliza en combinación con un sistema de predicción de rendimiento de consulta altamente preciso, puede ser posible expandir selectivamente las consultas y minimizar la pérdida asociada con el rendimiento sub-baseline. 4.3 Generación de Conceptos de Múltiples Términos Aunque encontramos que la expansión utilizando conceptos de múltiples términos no logró producir mejoras concluyentes en la efectividad, hay otras tareas potenciales para las cuales estos conceptos pueden ser útiles, como sugerencia/reformulación de consultas, resumen y extracción de conceptos. Por ejemplo, para una tarea de sugerencia de consultas, la consulta original podría usarse para generar un conjunto de conceptos latentes que corresponden a formulaciones alternativas de la consulta. Aunque evaluar nuestro modelo en estas tareas está fuera del alcance de este trabajo, deseamos mostrar un ejemplo ilustrativo de los tipos de conceptos generados utilizando nuestro modelo. En la Tabla 4, presentamos los conceptos de una, dos y tres palabras más probables generados utilizando LCE para la consulta logros del telescopio Hubble utilizando los 25 documentos mejor clasificados de la colección ROBUST. Es bien sabido que generar conceptos de múltiples términos utilizando un modelo basado en unigramas produce resultados insatisfactorios, ya que no considera las dependencias entre los términos. Esto no es el caso al generar conceptos de múltiples términos usando nuestro modelo. En cambio, la mayoría de los conceptos generados son bien formados y significativos. Hay varios casos donde los conceptos son menos coherentes, como espejo espejo espejo. En este caso, la probabilidad de que aparezca el término \"espejo\" en un documento pseudo-relevante supera a las características de modelado de lenguaje (por ejemplo, fOQ), lo que provoca que este concepto no coherente tenga una alta probabilidad. Tales ejemplos son minoría, sin embargo. No solo los conceptos generados son bien formados y significativos, sino que también son relevantes al tema de la consulta original. Como podemos ver, todos los conceptos generados están relacionados con el tema y de alguna manera están relacionados con el telescopio Hubble. Es interesante ver que el concepto de fallo del telescopio Hubble es uno de los tres conceptos de términos más probables, dado que es algo contradictorio con la consulta original. A pesar de esta contradicción, es probable que los documentos que discuten las fallas del telescopio también describan los éxitos, por lo tanto, es probable que este sea un concepto significativo. Una cosa importante a tener en cuenta es que los conceptos generados por LCE son de una naturaleza diferente a los que se generarían utilizando un modelo de relevancia de bigrama. Por ejemplo, un modelo de bigrama sería poco probable que genere el concepto telescopio espacio NASA, ya que ninguno de los bigramas que componen el concepto tiene una alta probabilidad. Sin embargo, dado que nuestro modelo se basa en una serie de características diferentes sobre varios tipos de cliques, es más general y robusto que un modelo de bigrama. Aunque solo proporcionamos los conceptos generados para una sola consulta, señalamos que el mismo análisis y conclusiones se generalizan a través de otros conjuntos de datos, con conceptos coherentes y relacionados temáticamente generados de manera consistente utilizando LCE. 4.4 Discusión Nuestra técnica de expansión de conceptos latentes captura dos tipos de dependencia semiortogonales. En la recuperación de información, ha existido un interés a largo plazo en comprender el papel de la dependencia de términos. De esta investigación, se han identificado dos tipos generales de dependencias. El primer tipo de dependencia es la dependencia sintáctica. Este tipo de dependencia abarca frases, proximidad de términos y co-ocurrencia de términos [2, 4, 5, 7, 26]. Estos métodos capturan el hecho de que las consultas imponen implícita o explícitamente un cierto conjunto de dependencias posicionales. El segundo tipo es la dependencia semántica. Ejemplos de dependencia semántica son la retroalimentación de relevancia, la retroalimentación de pseudo-relevancia, sinónimos y en cierta medida el truncamiento [3]. Estas técnicas han sido exploradas tanto en el lado de la consulta como en el lado del documento. En el lado de la consulta, esto se suele hacer utilizando alguna forma de expansión de consulta, como modelos de relevancia o LCE. En el lado del documento, esto se hace como expansión de documentos o suavizado de documentos [11, 13, 24]. Aunque puede haber cierta superposición entre las dependencias sintácticas y semánticas, en su mayoría son ortogonales. Nuestro modelo utiliza ambos tipos de dependencias. El uso de características de frase y proximidad dentro del modelo captura dependencias sintácticas, mientras que LCE captura dependencias semánticas del lado de la consulta. Esto explica por qué la mejora inicial en la efectividad lograda al usar el modelo MRF no se pierde después de la expansión de consultas. Si los mismos tipos de dependencias fueran capturados tanto por dependencias sintácticas como semánticas, se esperaría que LCE funcionara aproximadamente igual de bien que los modelos de relevancia. Por lo tanto, al modelar ambos tipos de dependencias, observamos un efecto aditivo en lugar de un efecto absorbente. Una área interesante de trabajo futuro es determinar si modelar las dependencias semánticas del lado del documento puede aportar algo al modelo. Resultados previos que han combinado dependencias semánticas del lado de la consulta y del documento han mostrado resultados mixtos [13, 27]. 5. CONCLUSIONES En este artículo propusimos una técnica robusta de expansión de consultas llamada expansión de conceptos latentes. La técnica se demostró ser una extensión natural del modelo de campo aleatorio de Markov para la recuperación de información y una generalización de los modelos de relevancia. LCE es novedoso en el sentido de que realiza una expansión de un solo término o de varios términos dentro de un marco que permite el modelado de dependencias entre términos y el uso de características arbitrarias, mientras que trabajos anteriores se basaban en la suposición de la bolsa de palabras y características de ocurrencia de términos. Mostramos que la técnica puede ser utilizada para producir conceptos de expansión de varios términos de alta calidad, bien formados y relevantes desde el punto de vista temático. Los conceptos generados pueden ser utilizados en un módulo de sugerencia de consultas alternativas. También demostramos que el modelo es altamente efectivo. De hecho, logra mejoras significativas en la precisión promedio media en comparación con los modelos de relevancia en una selección de conjuntos de datos de TREC. También se demostró que el modelo MRF por sí solo, sin ninguna expansión de consulta, supera a los modelos de relevancia en grandes conjuntos de datos web. Esto reafirma observaciones previas de que modelar dependencias a través del uso de características de proximidad dentro del MRF tiene un mayor impacto en colecciones más grandes y ruidosas que en colecciones más pequeñas y bien comportadas. Finalmente, reiteramos la importancia de elegir términos de expansión que modelen la relevancia, en lugar de los documentos relevantes, y mostramos cómo LCE captura tanto las dependencias sintácticas como semánticas del lado de la consulta. El trabajo futuro se centrará en incorporar dependencias del lado del documento también. Agradecimientos Este trabajo fue apoyado en parte por el Centro de Recuperación de Información Inteligente, en parte por la subvención NSF #CNS-0454018, en parte por ARDA y la subvención NSF #CCF-0205575, y en parte por Microsoft Live Labs. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son responsabilidad del autor o los autores y no necesariamente reflejan las del patrocinador.  REFERENCIAS [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker y C. Wade. UMass en TREC 2004: Novedad y DIFICULTAD. En Actas en línea de la Conferencia de Recuperación de Información de 2004, 2004. [2] C. L. A. Clarke y G. V. Cormack. Recuperación y clasificación de la subcadena más corta. ACM Trans. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate to Spanish? Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson y J. Callan. Expansión de consultas utilizando modelos de caminata aleatoria. En Proc. 14th Intl. Conf. sobre Gestión de Información y Conocimiento, páginas 704-711, 2005. [4] W. B. Croft. Consultas booleanas y dependencias de términos en modelos de recuperación probabilística. Revista de la Sociedad Americana de Ciencia de la Información, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle y D. Lewis. El uso de frases y consultas estructuradas en la recuperación de información. En Proc. 14º Anu. Internacional. Conferencia ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 32-45, 1991. [6] K. Eguchi. Experimentos de expansión de consultas NTCIR-5 utilizando modelos de dependencia de términos. En Actas del Quinto Taller de Reunión NTCIR sobre Evaluación de Tecnologías de Acceso a la Información, páginas 494-501, 2005. [7] J. Fagan. Indexación automática de frases para la recuperación de documentos: Un examen de métodos sintácticos y no sintácticos. En el Proc. décimo anual. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 91-101, 1987. [8] J. Gao, J. Nie, G. Wu y G. Cao. Modelo de lenguaje de dependencia para recuperación de información. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 170-177, 2004. [9] D. Harper y C. J. van Rijsbergen. Una evaluación de la retroalimentación en la recuperación de documentos utilizando datos de co-ocurrencia. Revista de Documentación, 34(3):189-216, 1978. [10] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Proc. de la Conf. Internacional de Aprendizaje Automático, páginas 377-384, 2005. [11] O. Kurland y L. Lee. Estructura del corpus, modelos de lenguaje y recuperación de información ad-hoc. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 194-201, 2004. [12] V. Lavrenko y W. B. Croft. Modelos de lenguaje basados en relevancia. En Proc. 24º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 120-127, 2001. [13] X. Liu y W. B. Croft. Recuperación basada en clústeres utilizando modelos de lenguaje. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 186-193, 2004. [14] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias entre términos. En Proc. 28vo Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [15] D. Metzler y W. B. Croft. Modelos basados en características lineales para la recuperación de información. Recuperación de información, por aparecer, 2006. [16] D. Metzler, T. Strohman, Y. Zhou y W. B. Croft. Indri en la pista de terabyte en 2005. En Actas en línea de la Conferencia de Recuperación de Texto de 2005, 2005. [17] W. Morgan, W. Greiff y J. Henderson. Maximización directa de la precisión promedio mediante escalada de colina con una comparación con un enfoque de entropía máxima. Informe técnico, MITRE, 2004. [18] P. Ogilvie y J. P. Callan. Experimentos utilizando el kit de herramientas de lémures. En Proc. de la Conferencia de Recuperación de Texto, 2001. [19] R. Papka y J. Allan. Por qué las ventanas más grandes son mejores que las más pequeñas. Informe técnico, Universidad de Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu y M. Gatford. Okapi en trec-3. En Actas en línea de la Tercera Conferencia de Recuperación de Texto, páginas 109-126, 1995. [21] J. J. Rocchio. Retroalimentación de relevancia en la recuperación de información, páginas 313-323. Prentice-Hall, 1971. [22] F. Song y W. B. Croft. Un modelo de lenguaje general para la recuperación de información. En Proc. octava conferencia internacional sobre Gestión de la Información y el Conocimiento (CIKM 99), páginas 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle y W. B. Croft. Indri: Un motor de búsqueda basado en modelos de lenguaje para consultas complejas. En Actas de la Conferencia Internacional sobre Análisis de Inteligencia, 2004. [24] T. Tao, X. Wang, Q. Mei y C. Zhai. Recuperación de información del modelo de lenguaje con expansión de documentos. En Proc. de HLT/NAACL, páginas 407-414, 2006. [25] B. Taskar, C. Guestrin y D. Koller. Redes de Markov de margen máximo. En Proc. de Avances en Sistemas de Información Neural (NIPS 2003), 2003. [26] C. J. van Rijsbergen. Una base teórica para el uso de datos de coocurrencia en la recuperación de información. Revista de Documentación, 33(2):106-119, 1977. [27] X. Wei y W. B. Croft. Modelos de documentos basados en LDA para <br>recuperación ad-hoc</br>. En Proc. 29º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 178-185, 2006. [28] J. Xu y W. B. Croft. Mejorando la efectividad de la recuperación de información con análisis de contexto local. ACM Trans. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate into Spanish? Syst., 18(1):79-112, 2000. [29] C. Zhai y J. Lafferty. Retroalimentación basada en modelos en el enfoque de modelado del lenguaje para la recuperación de información. En Proc. 10th Intl. Conferencia sobre Gestión de la Información y el Conocimiento, páginas 403-410, 2001. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "mrf model": {
            "translated_key": "modelo MRF",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The <br>mrf model</br> generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The <br>mrf model</br>, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the <br>mrf model</br>, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the <br>mrf model</br> allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the <br>mrf model</br> and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the <br>mrf model</br> for information retrieval [14].",
                "Therefore, we begin by providing an overview of the <br>mrf model</br> and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended <br>mrf model</br> can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the <br>mrf model</br> can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the <br>mrf model</br> allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the <br>mrf model</br> (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the <br>mrf model</br>, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the <br>mrf model</br>, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the <br>mrf model</br> is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the <br>mrf model</br> outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the <br>mrf model</br> is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the <br>mrf model</br> itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [
                "The <br>mrf model</br> generalizes the unigram, bigram, and other various dependence models [14].",
                "The <br>mrf model</br>, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Therefore, by performing query expansion using the <br>mrf model</br>, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the <br>mrf model</br> allows arbitrary features to be used within the model.",
                "Section 3 provides an overview of the <br>mrf model</br> and details our proposed latent concept expansion technique."
            ],
            "translated_annotated_samples": [
                "El <br>modelo MRF</br> generaliza los modelos de unigrama, bigrama y otras diversas dependencias [14].",
                "El <br>modelo MRF</br>, sin embargo, ha demostrado ser altamente efectivo en una serie de tareas, incluyendo la recuperación ad hoc [14, 16], la búsqueda de páginas con nombres [16] y la búsqueda web en japonés [6].",
                "Por lo tanto, al realizar la expansión de consultas utilizando el <br>modelo MRF</br>, podemos estudiar la dinámica entre la dependencia de términos y la expansión de consultas.",
                "A continuación, como mostraremos, el <br>modelo MRF</br> permite que se utilicen características arbitrarias dentro del modelo.",
                "La sección 3 proporciona una visión general del <br>modelo MRF</br> y detalla nuestra técnica propuesta de expansión de conceptos latentes."
            ],
            "translated_text": "Expansión de conceptos latentes utilizando campos aleatorios de Markov. Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Centro de Recuperación de Información Inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 RESUMEN La expansión de consultas, en forma de retroalimentación de pseudo relevancia o retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación. La mayoría de enfoques anteriores han ignorado problemas importantes, como el papel de las características y la importancia de modelar las dependencias entre términos. En este artículo, proponemos una técnica robusta de expansión de consultas basada en el modelo de campo aleatorio de Markov para la recuperación de información. La técnica, llamada expansión de conceptos latentes, proporciona un mecanismo para modelar las dependencias de términos durante la expansión. Además, el uso de características arbitrarias dentro del modelo proporciona un marco poderoso para ir más allá de las simples características de ocurrencia de términos que son utilizadas implícitamente por la mayoría de las otras técnicas de expansión. Evaluamos nuestra técnica frente a modelos de relevancia, una técnica de expansión de consultas de modelado de lenguaje de última generación. Nuestro modelo demuestra mejoras consistentes y significativas en la efectividad de recuperación en varios conjuntos de datos de TREC. También describimos cómo nuestra técnica puede ser utilizada para generar conceptos significativos de varios términos para tareas como sugerencia/reformulación de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales Algoritmos, Experimentación, Teoría 1. Los usuarios de los sistemas de recuperación de información deben expresar necesidades de información complejas en términos de expresiones booleanas, una lista corta de palabras clave, una oración, una pregunta o posiblemente un relato más extenso. Se pierde mucha información durante el proceso de traducción desde la necesidad de información hasta la consulta real. Por esta razón, ha habido un fuerte interés en las técnicas de expansión de consultas. Tales técnicas se utilizan para ampliar la consulta original y producir una representación que refleje mejor la necesidad de información subyacente. Las técnicas de expansión de consultas han sido ampliamente estudiadas para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la retroalimentación de pseudo-relevancia [12, 21, 28, 29]. Recientemente, se propuso un modelo de campo aleatorio de Markov (MRF) para la recuperación de información que va más allá de la simplista suposición de bolsa de palabras que subyace en BM25 y en el enfoque de modelado de lenguaje (unigrama) para la recuperación de información [20, 22]. El <br>modelo MRF</br> generaliza los modelos de unigrama, bigrama y otras diversas dependencias [14]. La mayoría de los modelos de dependencia de términos pasados no han logrado mostrar mejoras consistentes y significativas sobre las líneas de base de unigramas, con pocas excepciones [8]. El <br>modelo MRF</br>, sin embargo, ha demostrado ser altamente efectivo en una serie de tareas, incluyendo la recuperación ad hoc [14, 16], la búsqueda de páginas con nombres [16] y la búsqueda web en japonés [6]. Hasta ahora, el modelo ha sido utilizado únicamente para clasificar documentos en respuesta a una consulta dada. En este trabajo, mostramos cómo el modelo puede ser ampliado y utilizado para la expansión de consultas utilizando una técnica que llamamos expansión de conceptos latentes (LCE). Hay tres contribuciones principales de nuestro trabajo. Primero, LCE proporciona un mecanismo para combinar la dependencia de términos con la expansión de consultas. Las técnicas de expansión de consultas anteriores se basan en modelos de bolsa de palabras. Por lo tanto, al realizar la expansión de consultas utilizando el <br>modelo MRF</br>, podemos estudiar la dinámica entre la dependencia de términos y la expansión de consultas. A continuación, como mostraremos, el <br>modelo MRF</br> permite que se utilicen características arbitrarias dentro del modelo. Las técnicas de expansión de consultas en el pasado solo han hecho uso implícito de características de ocurrencia de términos. Al utilizar conjuntos de características más robustos, es posible producir términos de expansión mejores que discriminan de manera más efectiva entre documentos relevantes y no relevantes. Finalmente, nuestro enfoque propuesto proporciona de manera fluida un mecanismo para generar conceptos de una sola y múltiples términos. La mayoría de las técnicas anteriores, por defecto, generan términos de forma independiente. Ha habido varios enfoques que hacen uso de conceptos generalizados, sin embargo, dichos enfoques fueron algo heurísticos y realizados fuera del modelo [19, 28]. Nuestro enfoque está motivado tanto formalmente como es una extensión natural del modelo subyacente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2 describimos enfoques relacionados de expansión de consultas. La sección 3 proporciona una visión general del <br>modelo MRF</br> y detalla nuestra técnica propuesta de expansión de conceptos latentes. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "relevance distribution": {
            "translated_key": "distribución de relevancia",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a <br>relevance distribution</br>.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a <br>relevance distribution</br>."
            ],
            "translated_annotated_samples": [
                "Aquí estamos interesados en modelar la distribución conjunta sobre una consulta Q = q1, . . . , qn y un documento D. Se asume que la distribución subyacente sobre pares de documentos y consultas es una <br>distribución de relevancia</br>."
            ],
            "translated_text": "Expansión de conceptos latentes utilizando campos aleatorios de Markov. Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Centro de Recuperación de Información Inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 RESUMEN La expansión de consultas, en forma de retroalimentación de pseudo relevancia o retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación. La mayoría de enfoques anteriores han ignorado problemas importantes, como el papel de las características y la importancia de modelar las dependencias entre términos. En este artículo, proponemos una técnica robusta de expansión de consultas basada en el modelo de campo aleatorio de Markov para la recuperación de información. La técnica, llamada expansión de conceptos latentes, proporciona un mecanismo para modelar las dependencias de términos durante la expansión. Además, el uso de características arbitrarias dentro del modelo proporciona un marco poderoso para ir más allá de las simples características de ocurrencia de términos que son utilizadas implícitamente por la mayoría de las otras técnicas de expansión. Evaluamos nuestra técnica frente a modelos de relevancia, una técnica de expansión de consultas de modelado de lenguaje de última generación. Nuestro modelo demuestra mejoras consistentes y significativas en la efectividad de recuperación en varios conjuntos de datos de TREC. También describimos cómo nuestra técnica puede ser utilizada para generar conceptos significativos de varios términos para tareas como sugerencia/reformulación de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales Algoritmos, Experimentación, Teoría 1. Los usuarios de los sistemas de recuperación de información deben expresar necesidades de información complejas en términos de expresiones booleanas, una lista corta de palabras clave, una oración, una pregunta o posiblemente un relato más extenso. Se pierde mucha información durante el proceso de traducción desde la necesidad de información hasta la consulta real. Por esta razón, ha habido un fuerte interés en las técnicas de expansión de consultas. Tales técnicas se utilizan para ampliar la consulta original y producir una representación que refleje mejor la necesidad de información subyacente. Las técnicas de expansión de consultas han sido ampliamente estudiadas para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la retroalimentación de pseudo-relevancia [12, 21, 28, 29]. Recientemente, se propuso un modelo de campo aleatorio de Markov (MRF) para la recuperación de información que va más allá de la simplista suposición de bolsa de palabras que subyace en BM25 y en el enfoque de modelado de lenguaje (unigrama) para la recuperación de información [20, 22]. El modelo MRF generaliza los modelos de unigrama, bigrama y otras diversas dependencias [14]. La mayoría de los modelos de dependencia de términos pasados no han logrado mostrar mejoras consistentes y significativas sobre las líneas de base de unigramas, con pocas excepciones [8]. El modelo MRF, sin embargo, ha demostrado ser altamente efectivo en una serie de tareas, incluyendo la recuperación ad hoc [14, 16], la búsqueda de páginas con nombres [16] y la búsqueda web en japonés [6]. Hasta ahora, el modelo ha sido utilizado únicamente para clasificar documentos en respuesta a una consulta dada. En este trabajo, mostramos cómo el modelo puede ser ampliado y utilizado para la expansión de consultas utilizando una técnica que llamamos expansión de conceptos latentes (LCE). Hay tres contribuciones principales de nuestro trabajo. Primero, LCE proporciona un mecanismo para combinar la dependencia de términos con la expansión de consultas. Las técnicas de expansión de consultas anteriores se basan en modelos de bolsa de palabras. Por lo tanto, al realizar la expansión de consultas utilizando el modelo MRF, podemos estudiar la dinámica entre la dependencia de términos y la expansión de consultas. A continuación, como mostraremos, el modelo MRF permite que se utilicen características arbitrarias dentro del modelo. Las técnicas de expansión de consultas en el pasado solo han hecho uso implícito de características de ocurrencia de términos. Al utilizar conjuntos de características más robustos, es posible producir términos de expansión mejores que discriminan de manera más efectiva entre documentos relevantes y no relevantes. Finalmente, nuestro enfoque propuesto proporciona de manera fluida un mecanismo para generar conceptos de una sola y múltiples términos. La mayoría de las técnicas anteriores, por defecto, generan términos de forma independiente. Ha habido varios enfoques que hacen uso de conceptos generalizados, sin embargo, dichos enfoques fueron algo heurísticos y realizados fuera del modelo [19, 28]. Nuestro enfoque está motivado tanto formalmente como es una extensión natural del modelo subyacente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2 describimos enfoques relacionados de expansión de consultas. La sección 3 proporciona una visión general del modelo MRF y detalla nuestra técnica propuesta de expansión de conceptos latentes. En la Sección 4 evaluamos nuestro modelo propuesto y analizamos los resultados. Finalmente, la Sección 5 concluye el artículo y resume los principales resultados. 2. TRABAJO RELACIONADO Uno de los enfoques clásicos y más ampliamente utilizados para la expansión de consultas es el algoritmo de Rocchio [21]. El enfoque de Rocchio, que fue desarrollado dentro del modelo de espacio vectorial, reajusta el vector de consulta original moviendo los pesos hacia el conjunto de documentos relevantes o pseudo-relevantes y alejándolos de los documentos no relevantes. Desafortunadamente, no es posible aplicar formalmente el enfoque de Rocchio a un modelo de recuperación estadística, como el modelado del lenguaje para la recuperación de información. Se han desarrollado varias técnicas de expansión de consultas formalizadas para el marco de modelado de lenguaje, incluyendo el feedback basado en el modelo de Zhai y Lafferty y los modelos de relevancia de Lavrenko y Crofts [12, 29]. Ambos enfoques intentan utilizar documentos pseudo-relevantes o relevantes para estimar un modelo de consulta mejor. El feedback basado en modelos encuentra el modelo que mejor describe los documentos relevantes teniendo en cuenta un modelo de fondo (ruido). Esto separa el modelo de contenido del modelo de fondo. El modelo de contenido se interpola con el modelo de consulta original para formar la consulta ampliada. La otra técnica, modelos de relevancia, está más relacionada con nuestro trabajo. Por lo tanto, entramos en los detalles del modelo. Al igual que el feedback basado en modelos, los modelos de relevancia estiman un modelo de consulta mejorado. La única diferencia entre los dos enfoques es que los modelos de relevancia no modelan explícitamente los documentos relevantes o pseudo-relevantes. En cambio, ellos modelan una noción más generalizada de relevancia, como mostraremos ahora. Dada una consulta Q, un modelo de relevancia es una distribución multinomial, P(·|Q), que codifica la probabilidad de cada término dado la consulta como evidencia. Se calcula como: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) donde RQ es el conjunto de documentos que son relevantes o pseudo relevantes para la consulta Q. En el caso pseudo-relevante, estos son los documentos mejor clasificados para la consulta Q. Además, se asume que P(D) es uniforme en este conjunto. Estas suposiciones suaves hacen que el cálculo del posterior bayesiano sea más práctico. Después de que el modelo es estimado, los documentos son clasificados por recortar el modelo de relevancia al elegir los k términos más probables de P(·|Q). Esta distribución recortada se interpola luego con el modelo de consulta de máxima verosimilitud original. Esto se puede considerar como la expansión de la consulta original por k términos ponderados. A lo largo del resto de este trabajo, nos referimos a esta instancia de modelos de relevancia como RM3. Ha habido relativamente poco trabajo realizado en el área de expansión de consultas en el contexto de modelos de dependencia [9]. Sin embargo, ha habido varios intentos de expandir utilizando conceptos de varios términos. El método de análisis de contexto local (LCA) de Xu y Crofts combinaba la recuperación a nivel de pasaje con la expansión de conceptos, donde los conceptos eran términos y frases simples [28]. Los conceptos de expansión fueron elegidos y ponderados utilizando una métrica basada en estadísticas de co-ocurrencia. Sin embargo, no está claro, basándose en el análisis realizado, cuánto ayudaron las frases en comparación con los términos individuales solos. Papka y Allan investigan el uso de retroalimentación de relevancia para realizar la expansión de conceptos de varios términos en el enrutamiento de documentos [19]. Los conceptos utilizados en su trabajo son más generales que los utilizados en el LCA e incluyen estructuras de lenguaje de consulta InQuery, como #UW50(casa blanca), que corresponde al concepto en el que los términos casa y blanca ocurren, en cualquier orden, dentro de 50 términos uno del otro. Los resultados mostraron que combinar conceptos de un solo término y conceptos de varios términos con una ventana grande mejoró significativamente la efectividad. Sin embargo, no está claro si el mismo enfoque también es efectivo para la recuperación ad hoc, debido a las diferencias en las tareas. 3. Este apartado detalla nuestra técnica propuesta de expansión de conceptos latentes. Como se mencionó anteriormente, la técnica es una extensión del modelo MRF para la recuperación de información [14]. Por lo tanto, comenzamos proporcionando una visión general del modelo MRF y nuestras extensiones propuestas. 3.1 MRFs para IR 3.1.1 Conceptos básicos Los campos aleatorios de Markov, que son modelos gráficos no dirigidos, proporcionan una forma compacta y robusta de modelar una distribución conjunta. Aquí estamos interesados en modelar la distribución conjunta sobre una consulta Q = q1, . . . , qn y un documento D. Se asume que la distribución subyacente sobre pares de documentos y consultas es una <br>distribución de relevancia</br>. Es decir, muestrear de la distribución proporciona pares de documentos y consultas, de modo que el documento sea relevante para la consulta. Un MRF se define por un grafo G y un conjunto de funciones de potencial no negativas sobre los cliques en G. Los nodos en el grafo representan las variables aleatorias y las aristas definen la semántica de independencia de la distribución. Un MRF cumple con la propiedad de Markov, la cual establece que un nodo es independiente de todos sus nodos no vecinos dado los valores observados de sus vecinos. Dado un grafo G, un conjunto de potenciales ψi y un vector de parámetros Λ, la distribución conjunta sobre Q y D está dada por: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) donde Z es una constante de normalización. Seguimos la convención común y parametrizamos los potenciales como ψi(c; Λ) = exp[λifi(c)], donde fi(c) es una función de características de valores reales. 3.1.2 Construcción de G Dada una consulta Q, el grafo G puede ser construido de varias maneras. Sin embargo, siguiendo el trabajo previo, consideramos tres variantes simples [14]. Estas variantes son independencia total, donde cada término de consulta es independiente de los demás dado un documento, dependencia secuencial, que asume que existe una dependencia entre los términos de consulta adyacentes, y dependencia total, que no hace suposiciones de independencia. 3.1.3 Parametrización Los MRFs suelen ser parametrizados comúnmente en función de los cliques máximos de G. Sin embargo, dicha parametrización es demasiado gruesa para nuestras necesidades. Necesitamos una parametrización que nos permita asociar funciones de características con cliques a un nivel más detallado, manteniendo al mismo tiempo el número de características, y por lo tanto el número de parámetros, razonable. Por lo tanto, permitimos que los grupos compartan funciones de características y parámetros basados en conjuntos de grupos. Es decir, todos los subgrupos dentro de un conjunto de subgrupos están asociados con la misma función de característica y comparten un solo parámetro. Esto une de manera efectiva los parámetros de las características asociadas con cada conjunto, lo que reduce significativamente el número de parámetros mientras aún proporciona un mecanismo para el ajuste fino en el nivel de conjuntos de cliques. Proponemos siete conjuntos de cliques para utilizar en la recuperación de información. Los primeros tres conjuntos de cliques consisten en cliques que contienen uno o más términos de consulta y el nodo del documento. Las características sobre estos grupos deberían codificar qué tan bien los términos en la configuración del grupo describen el documento. Estos conjuntos son: • TD - conjunto de cliques que contienen el nodo del documento y exactamente un término de consulta. • OD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en orden secuencial dentro de la consulta. • UD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en cualquier orden dentro de la consulta. Ten en cuenta que UD es un superconjunto de OD. Al atar los parámetros entre los grupos dentro de cada conjunto podemos controlar cuánta influencia recibe cada tipo. Esto también evita el problema de tratar de determinar cómo estimar los pesos para cada clique dentro de los conjuntos. En cambio, ahora solo debemos estimar un parámetro por conjunto. A continuación, consideramos cliques que solo contienen nodos de términos de consulta. Estas cliques, que no fueron consideradas en [14], se definen de manera análoga a las recién definidas, excepto que las cliques solo están formadas por nodos de términos de consulta y no contienen el nodo de documento. Las funciones de características sobre estos conjuntos deben capturar qué tan compatibles son entre sí los términos de consulta. Estas características de grupo pueden adoptar la forma de modelos de lenguaje que imponen la corrección de los términos. Por lo tanto, definimos los siguientes conjuntos de cliques dependientes de la consulta: • TQ - conjunto de cliques que contienen exactamente un término de la consulta. • OQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en orden secuencial dentro de la consulta. • UQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en cualquier orden dentro de la consulta. Finalmente, está la clique que solo contiene el nodo del documento. Las características sobre este nodo pueden ser utilizadas como un tipo de documento previo, codificando propiedades centradas en el documento. Este conjunto de cliques trivial es entonces: • D - conjunto de cliques que contiene solo el nodo único D. Observamos que nuestros conjuntos de cliques forman una cobertura de conjuntos sobre los cliques de G, pero no son una partición, ya que algunos cliques aparecen en múltiples conjuntos de cliques. Después de atar los parámetros en nuestros conjuntos de cliques y usar la forma de la función potencial exponencial, terminamos con la siguiente forma simplificada de la distribución conjunta: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - dependiente del documento y la consulta + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - dependiente de la consulta + λDfD(D) FD(D) - dependiente del documento − log ZΛ documento + independiente de la consulta donde FDQ, FQ y FD son funciones de conveniencia definidas por los componentes dependientes del documento y la consulta, dependientes de la consulta y dependientes del documento de la distribución conjunta, respectivamente. Estos se utilizarán para simplificar y clarificar las expresiones derivadas a lo largo del resto del documento. 3.1.4 Características Cualquier función de característica arbitraria sobre configuraciones de cliques puede ser utilizada en el modelo. La elección correcta de las características depende en gran medida de la tarea de recuperación y la métrica de evaluación. Por lo tanto, es probable que no exista un conjunto único y universalmente aplicable de características. Para dar una idea de la variedad de características que se pueden utilizar, ahora describimos brevemente posibles tipos de características que podrían ser utilizadas. Posibles características dependientes del término de consulta incluyen tf, idf, entidades nombradas, proximidad de términos y estilo de texto, por nombrar algunas. Se pueden utilizar muchos tipos de características dependientes del documento, como la longitud del documento, el PageRank, la legibilidad y el género, entre otros. Dado que nuestro objetivo aquí no es encontrar características óptimas, utilizamos un conjunto simple y fijo de características que han demostrado ser efectivas en trabajos anteriores [14]. Consulte la Tabla 1 para ver la lista de características utilizadas. Estas características intentan capturar la ocurrencia de términos y la proximidad entre términos. Una mejor selección de características en el futuro probablemente conducirá a una mayor efectividad. 3.1.5 Clasificación Dada una consulta Q, deseamos clasificar los documentos en orden descendente según PG,Λ(D|Q). Después de eliminar las expresiones independientes del documento del registro PG,Λ(Q, D), derivamos la siguiente función de clasificación: PG,Λ(D|Q) rango = FDQ(D, Q) + FD(D) (2), que es una simple combinación lineal ponderada de funciones de características que pueden calcularse eficientemente para grafos razonables. 3.1.6 Estimación de Parámetros Ahora que el modelo ha sido completamente especificado, el paso final es estimar los parámetros del modelo. Aunque los MRF son modelos generativos, no es apropiado entrenarlos utilizando la función de valor de características fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Tabla 1: Funciones de características utilizadas en el modelo de campo aleatorio de Markov. Aquí, tfw,D es el número de veces que el término w ocurre en el documento D, tf#1(qi...qi+k),D denota el número de veces que la frase exacta qi . . . qi+k ocurre en el documento D, tf#uw(qi...qj ),D es el número de veces que los términos qi, . . . qj aparecen ordenados o desordenados dentro de una ventana de N términos, y |D| es la longitud del documento D. Los valores de cf y |C| se definen de manera análoga a nivel de colección. Finalmente, α y β son hiperparámetros del modelo que controlan el suavizado para las características de términos únicos y frases, respectivamente. Enfoques convencionales basados en la verosimilitud debido a la divergencia métrica [17]. Es decir, es poco probable que la estimación de máxima verosimilitud sea la estimación que maximiza nuestra métrica de evaluación. Por esta razón, entrenamos de manera discriminativa nuestro modelo para maximizar directamente la métrica de evaluación considerada [14, 15, 25]. Dado que nuestro espacio de parámetros es pequeño, hacemos uso de una estrategia simple de escalada de colina, aunque son posibles otros enfoques más sofisticados [10]. 3.2 Expansión de Conceptos Latentes En esta sección describimos cómo este modelo MRF extendido puede ser utilizado de una manera novedosa para generar conceptos de un solo término y de varios términos que están relacionados temáticamente con alguna consulta original. Como mostraremos, los conceptos generados utilizando nuestra técnica pueden ser utilizados para la expansión de consultas u otras tareas, como sugerir formulaciones alternativas de consultas. Suponemos que cuando un usuario formula su consulta original, tiene en mente un conjunto de conceptos, pero solo puede expresar un pequeño número de ellos en forma de consulta. Tratamos los conceptos que el usuario tiene en mente, pero no expresó explícitamente en la consulta, como conceptos latentes. Estos conceptos latentes pueden consistir en un solo término, varios términos o alguna combinación de ambos. Por lo tanto, nuestro objetivo es recuperar estos conceptos latentes dada alguna consulta original. Esto se puede lograr dentro de nuestro marco de trabajo al expandir primero el grafo original G para incluir el tipo de concepto que nos interesa generar. Llamamos a este gráfico expandido H. En la Figura 1, el gráfico del medio proporciona un ejemplo de cómo construir un gráfico expandido que puede generar conceptos de un solo término. De manera similar, el gráfico de la derecha ilustra un gráfico ampliado que genera dos conceptos de términos. Aunque estos dos ejemplos hacen uso de la suposición de dependencia secuencial (es decir, dependencias entre términos de consulta adyacentes), es importante tener en cuenta que tanto la consulta original como los conceptos de expansión pueden utilizar cualquier estructura de independencia. Después de que H se construye, calculamos PH,Λ(E|Q), una distribución de probabilidad sobre conceptos latentes, de acuerdo a: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) donde R es el universo de todos los documentos posibles y E es un concepto latente que puede consistir en uno o más términos. Dado que no es práctico calcular esta suma, debemos aproximarla. Observamos que PH,Λ(Q, E, D) probablemente se concentra alrededor de aquellos documentos D que están altamente clasificados según la consulta Q. Por lo tanto, aproximamos PH,Λ(E|Q) sumando solo un pequeño subconjunto de documentos relevantes o pseudo-relevantes para la consulta Q. Esto se calcula de la siguiente manera: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) donde RQ es un conjunto de documentos relevantes o pseudo-relevantes para la consulta Q y todos los conjuntos de cliques se construyen utilizando H. Como vemos, la contribución de probabilidad para cada documento en RQ es una combinación de la puntuación original de la consulta para el documento (ver Ecuación 2), la puntuación del concepto E para el documento y la puntuación independiente del documento de E. Por lo tanto, esta ecuación puede interpretarse como la medida de qué tan bien Q y E explican los documentos mejor clasificados y la bondad de E, independientemente de los documentos. Para lograr la máxima robustez, utilizamos un conjunto diferente de parámetros para FQD(Q, D) y FQD(E, D), lo que nos permite ponderar de manera diferente las características de ventana ordenadas y no ordenadas para la consulta original y el concepto de expansión candidato. 3.2.1 Expansión de consulta Para utilizar este marco para la expansión de consultas, primero elegimos un grafo de expansión H que codifique la estructura de concepto latente en la que estamos interesados en expandir la consulta. Luego seleccionamos los k conceptos latentes con la mayor probabilidad dada por la Ecuación 3. Se construye un nuevo grafo G al aumentar el grafo original G con los k conceptos de expansión E1, . . . , Ek. Finalmente, los documentos se clasifican según PG ,Λ(D|Q, E1, . . . , Ek) utilizando la Ecuación 2. 3.2.2 Comparación con los Modelos de Relevancia. Al inspeccionar las Ecuaciones 1 y 3 se revela la estrecha conexión que existe entre LCE y los modelos de relevancia. Ambos modelos esencialmente calculan la probabilidad de un término (o concepto) de la misma manera. Es fácil ver que al igual que el modelo MRF puede ser visto como una generalización del modelado del lenguaje, también LCE puede ser visto como una generalización de los modelos de relevancia. Existen diferencias importantes entre los modelos de lenguaje MRFs/LCE y los modelos de lenguaje unigram/relevancia. Consulte la Figura 1 para ver las representaciones gráficas de ambos modelos. Los modelos de lenguaje unigrama y los modelos de relevancia se basan en la distribución multinomial. Esta suposición de distribución encasilla el modelo en la representación de bolsa de palabras y el uso implícito de características de ocurrencia de términos. Sin embargo, la distribución subyacente al modelo MRF nos permite ir más allá de ambas suposiciones, al modelar tanto las dependencias entre los términos de consulta como permitir el uso explícito de características arbitrarias. Ir más allá de la simplista suposición de la bolsa de palabras de esta manera resulta en un modelo general y robusto y, como mostramos en la siguiente sección, se traduce en mejoras significativas en la efectividad de recuperación. 4. RESULTADOS EXPERIMENTALES Para comprender mejor las fortalezas y debilidades de nuestra técnica, la evaluamos en una amplia gama de conjuntos de datos. La Tabla 2 proporciona un resumen de los conjuntos de datos de TREC considerados. Las colecciones WSJ, AP y ROBUST son más pequeñas y consisten enteramente de artículos de agencias de noticias, mientras que WT10g y GOV2 son colecciones web grandes. Para cada conjunto de datos, dividimos los temas disponibles en un conjunto de entrenamiento y otro de prueba, donde el conjunto de entrenamiento se utiliza únicamente para la estimación de parámetros y el conjunto de prueba se utiliza con fines de evaluación. Todos los experimentos se llevaron a cabo utilizando una versión modificada de Indri, que forma parte del Lemur Toolkit [18, 23]. Todas las colecciones fueron detenidas utilizando una lista estándar de 418 términos comunes y truncadas utilizando un truncador de Porter. En todos los casos, solo se utiliza la parte del título de los temas de TREC para construir las consultas. Construimos G utilizando la suposición de dependencia secuencial para todos los conjuntos de datos [14]. 4.1 Resultados de recuperación ad-hoc Ahora investigamos qué tan bien se desempeña nuestro modelo en la práctica en un entorno de retroalimentación de relevancia pseudo. Comparamos el modelado de lenguaje unigrama (con suavizado de Dirichlet), el modelo MRF (sin expansión), los modelos de relevancia y LCE para comprender mejor cómo se desempeña cada modelo en los diferentes conjuntos de datos. Para el modelo de lenguaje unigrama, se entrenó el parámetro de suavizado. Para el modelo MRF, entrenamos los parámetros del modelo (es decir, y hiperparámetros del modelo (es decir, α, β). Para RM3 y LCE, también entrenamos el número de pseudoNombre Descripción # Docs Temas de Entrenamiento Temas de Prueba WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc. Presione 88-90 242,918 51-150 151-200 ROBUST Robust 2004 datos 528,155 301-450 601-700 WT10g Colección Web de TREC 1,692,096 451-500 501-550 GOV2 Rastreo 2004 del dominio .gov 25,205,179 701-750 751-800 Tabla 2: Resumen de las colecciones y temas de TREC. documentos de retroalimentación relevantes utilizados y el número de términos de expansión. 4.1.1 Expansión con Conceptos de Términos Únicos Comenzamos evaluando qué tan bien funciona nuestro modelo al expandir utilizando solo términos individuales. Antes de describir y analizar los resultados, declaramos explícitamente cómo se calculan las probabilidades de términos de expansión bajo esta configuración (es decir, utilizando la suposición de dependencia secuencial, expandiendo con conceptos de un solo término y utilizando nuestro conjunto de características). Las probabilidades de términos de expansión se calculan de la siguiente manera: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) donde b ∈ Q denota el conjunto de bigramas en Q. Esta ecuación muestra claramente cómo LCE difiere de los modelos de relevancia. Cuando establecemos λTD = λT,D = 1 y todos los demás parámetros en 0, obtenemos la fórmula exacta que se utiliza para calcular las probabilidades de términos en el marco de modelado de relevancia. Por lo tanto, LCE añade dos factores muy importantes a la ecuación. Primero, agrega las características de ventana ordenadas y no ordenadas que se aplican a la consulta original. En segundo lugar, aplica una forma intuitiva similar a tf.idf al término de expansión candidato w. El factor idf, que no está presente en los modelos de relevancia, juega un papel importante en la selección del término de expansión. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figura 2: Histogramas que demuestran y comparan la robustez de los modelos de relevancia (RM3) y la expansión de conceptos latentes (LCE) con respecto al modelo de probabilidad de consulta (QL) para los conjuntos de datos AP, ROBUST y WT10G. Los resultados, evaluados utilizando la precisión promedio media, se muestran en la Tabla 3. Como vemos, el modelo MRF, los modelos de relevancia y LCE siempre superan significativamente al modelo de lenguaje unigrama. Además, LCE muestra mejoras significativas sobre los modelos de relevancia en todos los conjuntos de datos. Las mejoras relativas sobre los modelos de relevancia son del 6.9% para AP, 12.9% para WSJ, 6.5% para ROBUST, 16.7% para WT10G y 7.3% para GOV2. Además, LCE muestra pequeñas mejoras, pero no significativas, respecto al modelado de relevancia para métricas como precisión en 5, 10 y 20. Sin embargo, tanto el modelado de relevancia como el LCE muestran mejoras estadísticamente significativas en dichas métricas sobre el modelo de lenguaje unigrama. Otro resultado interesante es que el modelo MRF es estadísticamente equivalente a los modelos de relevancia en los dos conjuntos de datos web. De hecho, el modelo MRF supera a los modelos de relevancia en el conjunto de datos WT10g. Esto reitera la importancia de las características no unigrama, basadas en la proximidad para la búsqueda web basada en contenido observada previamente [14, 16]. Aunque nuestro modelo tiene más parámetros libres que los modelos de relevancia, sorprendentemente hay poco sobreajuste. En cambio, el modelo muestra buenas propiedades de generalización. 4.1.2 Expansión con Conceptos de Múltiples Términos También investigamos la expansión utilizando conceptos de una y dos palabras. Para cada consulta, expandimos utilizando un conjunto de conceptos de un solo término y un conjunto de conceptos de dos términos. Los conjuntos fueron elegidos de forma independiente. Desafortunadamente, solo se observaron aumentos insignificantes en la precisión promedio. Este resultado puede deberse al hecho de que existen fuertes correlaciones entre los conceptos de expansión de términos individuales. Descubrimos que los dos conceptos de palabras elegidos a menudo consistían en dos términos altamente correlacionados que también son elegidos como conceptos de términos individuales. Por ejemplo, se eligió el concepto de dos términos mercado de valores, mientras que también se eligieron los conceptos de un solo término acciones y mercado. Por lo tanto, muchos conceptos de dos palabras es poco probable que aumenten el poder discriminativo de la consulta ampliada. Este resultado sugiere que los conceptos deben ser elegidos de acuerdo con ciertos criterios que también tengan en cuenta la novedad, la diversidad o las correlaciones de términos. Otro problema potencial es el conjunto de características utilizado. Otros conjuntos de características pueden dar resultados diferentes en última instancia, especialmente si reducen la correlación entre los conceptos de expansión. Por lo tanto, nuestros experimentos no arrojan resultados concluyentes en cuanto a la expansión utilizando conceptos de varios términos. En cambio, los resultados plantean preguntas abiertas interesantes y direcciones para futuras exploraciones. Tabla 3: Promedio de precisión media en el conjunto de pruebas para modelado de lenguaje (LM), campo aleatorio de Markov (MRF), modelos de relevancia (RM3) y expansión de conceptos latentes (LCE). Los superíndices α, β y γ indican mejoras estadísticamente significativas (p < 0.05) sobre LM, MRF y RM3, respectivamente. 4.2 Robustez Como hemos demostrado, los modelos de relevancia y la expansión de conceptos latentes pueden mejorar significativamente la efectividad de recuperación sobre el modelo de probabilidad de consulta base. En esta sección analizamos la robustez de estos dos métodos. Aquí definimos la robustez como el número de consultas cuya efectividad se ve mejorada/afectada (y en qué medida) como resultado de aplicar estos métodos. Una técnica de expansión altamente robusta mejorará significativamente muchas consultas y solo perjudicará mínimamente a unas pocas. La Figura 2 proporciona un análisis de la robustez del modelado de relevancia y la expansión de conceptos latentes para los conjuntos de datos AP, ROBUST y WT10G. El análisis de los dos conjuntos de datos no mostrados es similar. Los histogramas proporcionan, para varios rangos de disminuciones/aumentos relativos en la precisión media promedio, el número de consultas que se vieron perjudicadas/mejoradas con respecto a la línea base de probabilidad de consulta. Como muestran los resultados, LCE muestra una fuerte robustez para cada conjunto de datos. Para AP, los modelos de relevancia mejoran 38 consultas y perjudican 11, mientras que LCE mejora 35 y perjudica 14. Aunque los modelos de relevancia mejoran la efectividad de 3 consultas más que LCE, la mejora relativa exhibida por LCE es significativamente mayor. Para el conjunto de datos ROBUST, los modelos de relevancia mejoran 67 consultas y perjudican 32, y LCE mejora 77 y perjudica 22. Finalmente, para la colección WT10G, los modelos de relevancia mejoran 32 consultas y perjudican 16, y LCE mejora 35 y perjudica 14. Al igual que con AP, la cantidad de mejora exhibida por el LCE frente a los modelos de relevancia es significativamente mayor tanto para los conjuntos de datos ROBUST como WT10G. Además, cuando LCE afecta al rendimiento, es menos probable que afecte tanto como el modelado de relevancia, lo cual es una propiedad deseable. En general, LCE mejora la efectividad para el 65%-80% de las consultas, dependiendo del conjunto de datos. Cuando se utiliza en combinación con un sistema de predicción de rendimiento de consulta altamente preciso, puede ser posible expandir selectivamente las consultas y minimizar la pérdida asociada con el rendimiento sub-baseline. 4.3 Generación de Conceptos de Múltiples Términos Aunque encontramos que la expansión utilizando conceptos de múltiples términos no logró producir mejoras concluyentes en la efectividad, hay otras tareas potenciales para las cuales estos conceptos pueden ser útiles, como sugerencia/reformulación de consultas, resumen y extracción de conceptos. Por ejemplo, para una tarea de sugerencia de consultas, la consulta original podría usarse para generar un conjunto de conceptos latentes que corresponden a formulaciones alternativas de la consulta. Aunque evaluar nuestro modelo en estas tareas está fuera del alcance de este trabajo, deseamos mostrar un ejemplo ilustrativo de los tipos de conceptos generados utilizando nuestro modelo. En la Tabla 4, presentamos los conceptos de una, dos y tres palabras más probables generados utilizando LCE para la consulta logros del telescopio Hubble utilizando los 25 documentos mejor clasificados de la colección ROBUST. Es bien sabido que generar conceptos de múltiples términos utilizando un modelo basado en unigramas produce resultados insatisfactorios, ya que no considera las dependencias entre los términos. Esto no es el caso al generar conceptos de múltiples términos usando nuestro modelo. En cambio, la mayoría de los conceptos generados son bien formados y significativos. Hay varios casos donde los conceptos son menos coherentes, como espejo espejo espejo. En este caso, la probabilidad de que aparezca el término \"espejo\" en un documento pseudo-relevante supera a las características de modelado de lenguaje (por ejemplo, fOQ), lo que provoca que este concepto no coherente tenga una alta probabilidad. Tales ejemplos son minoría, sin embargo. No solo los conceptos generados son bien formados y significativos, sino que también son relevantes al tema de la consulta original. Como podemos ver, todos los conceptos generados están relacionados con el tema y de alguna manera están relacionados con el telescopio Hubble. Es interesante ver que el concepto de fallo del telescopio Hubble es uno de los tres conceptos de términos más probables, dado que es algo contradictorio con la consulta original. A pesar de esta contradicción, es probable que los documentos que discuten las fallas del telescopio también describan los éxitos, por lo tanto, es probable que este sea un concepto significativo. Una cosa importante a tener en cuenta es que los conceptos generados por LCE son de una naturaleza diferente a los que se generarían utilizando un modelo de relevancia de bigrama. Por ejemplo, un modelo de bigrama sería poco probable que genere el concepto telescopio espacio NASA, ya que ninguno de los bigramas que componen el concepto tiene una alta probabilidad. Sin embargo, dado que nuestro modelo se basa en una serie de características diferentes sobre varios tipos de cliques, es más general y robusto que un modelo de bigrama. Aunque solo proporcionamos los conceptos generados para una sola consulta, señalamos que el mismo análisis y conclusiones se generalizan a través de otros conjuntos de datos, con conceptos coherentes y relacionados temáticamente generados de manera consistente utilizando LCE. 4.4 Discusión Nuestra técnica de expansión de conceptos latentes captura dos tipos de dependencia semiortogonales. En la recuperación de información, ha existido un interés a largo plazo en comprender el papel de la dependencia de términos. De esta investigación, se han identificado dos tipos generales de dependencias. El primer tipo de dependencia es la dependencia sintáctica. Este tipo de dependencia abarca frases, proximidad de términos y co-ocurrencia de términos [2, 4, 5, 7, 26]. Estos métodos capturan el hecho de que las consultas imponen implícita o explícitamente un cierto conjunto de dependencias posicionales. El segundo tipo es la dependencia semántica. Ejemplos de dependencia semántica son la retroalimentación de relevancia, la retroalimentación de pseudo-relevancia, sinónimos y en cierta medida el truncamiento [3]. Estas técnicas han sido exploradas tanto en el lado de la consulta como en el lado del documento. En el lado de la consulta, esto se suele hacer utilizando alguna forma de expansión de consulta, como modelos de relevancia o LCE. En el lado del documento, esto se hace como expansión de documentos o suavizado de documentos [11, 13, 24]. Aunque puede haber cierta superposición entre las dependencias sintácticas y semánticas, en su mayoría son ortogonales. Nuestro modelo utiliza ambos tipos de dependencias. El uso de características de frase y proximidad dentro del modelo captura dependencias sintácticas, mientras que LCE captura dependencias semánticas del lado de la consulta. Esto explica por qué la mejora inicial en la efectividad lograda al usar el modelo MRF no se pierde después de la expansión de consultas. Si los mismos tipos de dependencias fueran capturados tanto por dependencias sintácticas como semánticas, se esperaría que LCE funcionara aproximadamente igual de bien que los modelos de relevancia. Por lo tanto, al modelar ambos tipos de dependencias, observamos un efecto aditivo en lugar de un efecto absorbente. Una área interesante de trabajo futuro es determinar si modelar las dependencias semánticas del lado del documento puede aportar algo al modelo. Resultados previos que han combinado dependencias semánticas del lado de la consulta y del documento han mostrado resultados mixtos [13, 27]. 5. CONCLUSIONES En este artículo propusimos una técnica robusta de expansión de consultas llamada expansión de conceptos latentes. La técnica se demostró ser una extensión natural del modelo de campo aleatorio de Markov para la recuperación de información y una generalización de los modelos de relevancia. LCE es novedoso en el sentido de que realiza una expansión de un solo término o de varios términos dentro de un marco que permite el modelado de dependencias entre términos y el uso de características arbitrarias, mientras que trabajos anteriores se basaban en la suposición de la bolsa de palabras y características de ocurrencia de términos. Mostramos que la técnica puede ser utilizada para producir conceptos de expansión de varios términos de alta calidad, bien formados y relevantes desde el punto de vista temático. Los conceptos generados pueden ser utilizados en un módulo de sugerencia de consultas alternativas. También demostramos que el modelo es altamente efectivo. De hecho, logra mejoras significativas en la precisión promedio media en comparación con los modelos de relevancia en una selección de conjuntos de datos de TREC. También se demostró que el modelo MRF por sí solo, sin ninguna expansión de consulta, supera a los modelos de relevancia en grandes conjuntos de datos web. Esto reafirma observaciones previas de que modelar dependencias a través del uso de características de proximidad dentro del MRF tiene un mayor impacto en colecciones más grandes y ruidosas que en colecciones más pequeñas y bien comportadas. Finalmente, reiteramos la importancia de elegir términos de expansión que modelen la relevancia, en lugar de los documentos relevantes, y mostramos cómo LCE captura tanto las dependencias sintácticas como semánticas del lado de la consulta. El trabajo futuro se centrará en incorporar dependencias del lado del documento también. Agradecimientos Este trabajo fue apoyado en parte por el Centro de Recuperación de Información Inteligente, en parte por la subvención NSF #CNS-0454018, en parte por ARDA y la subvención NSF #CCF-0205575, y en parte por Microsoft Live Labs. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son responsabilidad del autor o los autores y no necesariamente reflejan las del patrocinador.  REFERENCIAS [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker y C. Wade. UMass en TREC 2004: Novedad y DIFICULTAD. En Actas en línea de la Conferencia de Recuperación de Información de 2004, 2004. [2] C. L. A. Clarke y G. V. Cormack. Recuperación y clasificación de la subcadena más corta. ACM Trans. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate to Spanish? Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson y J. Callan. Expansión de consultas utilizando modelos de caminata aleatoria. En Proc. 14th Intl. Conf. sobre Gestión de Información y Conocimiento, páginas 704-711, 2005. [4] W. B. Croft. Consultas booleanas y dependencias de términos en modelos de recuperación probabilística. Revista de la Sociedad Americana de Ciencia de la Información, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle y D. Lewis. El uso de frases y consultas estructuradas en la recuperación de información. En Proc. 14º Anu. Internacional. Conferencia ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 32-45, 1991. [6] K. Eguchi. Experimentos de expansión de consultas NTCIR-5 utilizando modelos de dependencia de términos. En Actas del Quinto Taller de Reunión NTCIR sobre Evaluación de Tecnologías de Acceso a la Información, páginas 494-501, 2005. [7] J. Fagan. Indexación automática de frases para la recuperación de documentos: Un examen de métodos sintácticos y no sintácticos. En el Proc. décimo anual. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 91-101, 1987. [8] J. Gao, J. Nie, G. Wu y G. Cao. Modelo de lenguaje de dependencia para recuperación de información. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 170-177, 2004. [9] D. Harper y C. J. van Rijsbergen. Una evaluación de la retroalimentación en la recuperación de documentos utilizando datos de co-ocurrencia. Revista de Documentación, 34(3):189-216, 1978. [10] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Proc. de la Conf. Internacional de Aprendizaje Automático, páginas 377-384, 2005. [11] O. Kurland y L. Lee. Estructura del corpus, modelos de lenguaje y recuperación de información ad-hoc. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 194-201, 2004. [12] V. Lavrenko y W. B. Croft. Modelos de lenguaje basados en relevancia. En Proc. 24º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 120-127, 2001. [13] X. Liu y W. B. Croft. Recuperación basada en clústeres utilizando modelos de lenguaje. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 186-193, 2004. [14] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias entre términos. En Proc. 28vo Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [15] D. Metzler y W. B. Croft. Modelos basados en características lineales para la recuperación de información. Recuperación de información, por aparecer, 2006. [16] D. Metzler, T. Strohman, Y. Zhou y W. B. Croft. Indri en la pista de terabyte en 2005. En Actas en línea de la Conferencia de Recuperación de Texto de 2005, 2005. [17] W. Morgan, W. Greiff y J. Henderson. Maximización directa de la precisión promedio mediante escalada de colina con una comparación con un enfoque de entropía máxima. Informe técnico, MITRE, 2004. [18] P. Ogilvie y J. P. Callan. Experimentos utilizando el kit de herramientas de lémures. En Proc. de la Conferencia de Recuperación de Texto, 2001. [19] R. Papka y J. Allan. Por qué las ventanas más grandes son mejores que las más pequeñas. Informe técnico, Universidad de Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu y M. Gatford. Okapi en trec-3. En Actas en línea de la Tercera Conferencia de Recuperación de Texto, páginas 109-126, 1995. [21] J. J. Rocchio. Retroalimentación de relevancia en la recuperación de información, páginas 313-323. Prentice-Hall, 1971. [22] F. Song y W. B. Croft. Un modelo de lenguaje general para la recuperación de información. En Proc. octava conferencia internacional sobre Gestión de la Información y el Conocimiento (CIKM 99), páginas 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle y W. B. Croft. Indri: Un motor de búsqueda basado en modelos de lenguaje para consultas complejas. En Actas de la Conferencia Internacional sobre Análisis de Inteligencia, 2004. [24] T. Tao, X. Wang, Q. Mei y C. Zhai. Recuperación de información del modelo de lenguaje con expansión de documentos. En Proc. de HLT/NAACL, páginas 407-414, 2006. [25] B. Taskar, C. Guestrin y D. Koller. Redes de Markov de margen máximo. En Proc. de Avances en Sistemas de Información Neural (NIPS 2003), 2003. [26] C. J. van Rijsbergen. Una base teórica para el uso de datos de coocurrencia en la recuperación de información. Revista de Documentación, 33(2):106-119, 1977. [27] X. Wei y W. B. Croft. Modelos de documentos basados en LDA para recuperación ad-hoc. En Proc. 29º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 178-185, 2006. [28] J. Xu y W. B. Croft. Mejorando la efectividad de la recuperación de información con análisis de contexto local. ACM Trans. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate into Spanish? Syst., 18(1):79-112, 2000. [29] C. Zhai y J. Lafferty. Retroalimentación basada en modelos en el enfoque de modelado del lenguaje para la recuperación de información. En Proc. 10th Intl. Conferencia sobre Gestión de la Información y el Conocimiento, páginas 403-410, 2001. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "markov random field": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the <br>markov random field</br> model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a <br>markov random field</br> (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in <br>markov random field</br> model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), <br>markov random field</br> (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the <br>markov random field</br> model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A <br>markov random field</br> model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [
                "In this paper, we propose a robust query expansion technique based on the <br>markov random field</br> model for information retrieval.",
                "Recently, a <br>markov random field</br> (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in <br>markov random field</br> model.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), <br>markov random field</br> (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The technique was shown to be a natural extension of the <br>markov random field</br> model for information retrieval and a generalization of relevance models."
            ],
            "translated_annotated_samples": [
                "En este artículo, proponemos una técnica robusta de expansión de consultas basada en el modelo de <br>campo aleatorio de Markov</br> para la recuperación de información.",
                "Recientemente, se propuso un modelo de <br>campo aleatorio de Markov</br> (MRF) para la recuperación de información que va más allá de la simplista suposición de bolsa de palabras que subyace en BM25 y en el enfoque de modelado de lenguaje (unigrama) para la recuperación de información [20, 22].",
                "Aunque los MRF son modelos generativos, no es apropiado entrenarlos utilizando la función de valor de características fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Tabla 1: Funciones de características utilizadas en el modelo de <br>campo aleatorio de Markov</br>.",
                "Tabla 3: Promedio de precisión media en el conjunto de pruebas para modelado de lenguaje (LM), <br>campo aleatorio de Markov</br> (MRF), modelos de relevancia (RM3) y expansión de conceptos latentes (LCE).",
                "La técnica se demostró ser una extensión natural del <br>modelo de campo aleatorio de Markov</br> para la recuperación de información y una generalización de los modelos de relevancia."
            ],
            "translated_text": "Expansión de conceptos latentes utilizando campos aleatorios de Markov. Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Centro de Recuperación de Información Inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 RESUMEN La expansión de consultas, en forma de retroalimentación de pseudo relevancia o retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación. La mayoría de enfoques anteriores han ignorado problemas importantes, como el papel de las características y la importancia de modelar las dependencias entre términos. En este artículo, proponemos una técnica robusta de expansión de consultas basada en el modelo de <br>campo aleatorio de Markov</br> para la recuperación de información. La técnica, llamada expansión de conceptos latentes, proporciona un mecanismo para modelar las dependencias de términos durante la expansión. Además, el uso de características arbitrarias dentro del modelo proporciona un marco poderoso para ir más allá de las simples características de ocurrencia de términos que son utilizadas implícitamente por la mayoría de las otras técnicas de expansión. Evaluamos nuestra técnica frente a modelos de relevancia, una técnica de expansión de consultas de modelado de lenguaje de última generación. Nuestro modelo demuestra mejoras consistentes y significativas en la efectividad de recuperación en varios conjuntos de datos de TREC. También describimos cómo nuestra técnica puede ser utilizada para generar conceptos significativos de varios términos para tareas como sugerencia/reformulación de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales Algoritmos, Experimentación, Teoría 1. Los usuarios de los sistemas de recuperación de información deben expresar necesidades de información complejas en términos de expresiones booleanas, una lista corta de palabras clave, una oración, una pregunta o posiblemente un relato más extenso. Se pierde mucha información durante el proceso de traducción desde la necesidad de información hasta la consulta real. Por esta razón, ha habido un fuerte interés en las técnicas de expansión de consultas. Tales técnicas se utilizan para ampliar la consulta original y producir una representación que refleje mejor la necesidad de información subyacente. Las técnicas de expansión de consultas han sido ampliamente estudiadas para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la retroalimentación de pseudo-relevancia [12, 21, 28, 29]. Recientemente, se propuso un modelo de <br>campo aleatorio de Markov</br> (MRF) para la recuperación de información que va más allá de la simplista suposición de bolsa de palabras que subyace en BM25 y en el enfoque de modelado de lenguaje (unigrama) para la recuperación de información [20, 22]. El modelo MRF generaliza los modelos de unigrama, bigrama y otras diversas dependencias [14]. La mayoría de los modelos de dependencia de términos pasados no han logrado mostrar mejoras consistentes y significativas sobre las líneas de base de unigramas, con pocas excepciones [8]. El modelo MRF, sin embargo, ha demostrado ser altamente efectivo en una serie de tareas, incluyendo la recuperación ad hoc [14, 16], la búsqueda de páginas con nombres [16] y la búsqueda web en japonés [6]. Hasta ahora, el modelo ha sido utilizado únicamente para clasificar documentos en respuesta a una consulta dada. En este trabajo, mostramos cómo el modelo puede ser ampliado y utilizado para la expansión de consultas utilizando una técnica que llamamos expansión de conceptos latentes (LCE). Hay tres contribuciones principales de nuestro trabajo. Primero, LCE proporciona un mecanismo para combinar la dependencia de términos con la expansión de consultas. Las técnicas de expansión de consultas anteriores se basan en modelos de bolsa de palabras. Por lo tanto, al realizar la expansión de consultas utilizando el modelo MRF, podemos estudiar la dinámica entre la dependencia de términos y la expansión de consultas. A continuación, como mostraremos, el modelo MRF permite que se utilicen características arbitrarias dentro del modelo. Las técnicas de expansión de consultas en el pasado solo han hecho uso implícito de características de ocurrencia de términos. Al utilizar conjuntos de características más robustos, es posible producir términos de expansión mejores que discriminan de manera más efectiva entre documentos relevantes y no relevantes. Finalmente, nuestro enfoque propuesto proporciona de manera fluida un mecanismo para generar conceptos de una sola y múltiples términos. La mayoría de las técnicas anteriores, por defecto, generan términos de forma independiente. Ha habido varios enfoques que hacen uso de conceptos generalizados, sin embargo, dichos enfoques fueron algo heurísticos y realizados fuera del modelo [19, 28]. Nuestro enfoque está motivado tanto formalmente como es una extensión natural del modelo subyacente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2 describimos enfoques relacionados de expansión de consultas. La sección 3 proporciona una visión general del modelo MRF y detalla nuestra técnica propuesta de expansión de conceptos latentes. En la Sección 4 evaluamos nuestro modelo propuesto y analizamos los resultados. Finalmente, la Sección 5 concluye el artículo y resume los principales resultados. 2. TRABAJO RELACIONADO Uno de los enfoques clásicos y más ampliamente utilizados para la expansión de consultas es el algoritmo de Rocchio [21]. El enfoque de Rocchio, que fue desarrollado dentro del modelo de espacio vectorial, reajusta el vector de consulta original moviendo los pesos hacia el conjunto de documentos relevantes o pseudo-relevantes y alejándolos de los documentos no relevantes. Desafortunadamente, no es posible aplicar formalmente el enfoque de Rocchio a un modelo de recuperación estadística, como el modelado del lenguaje para la recuperación de información. Se han desarrollado varias técnicas de expansión de consultas formalizadas para el marco de modelado de lenguaje, incluyendo el feedback basado en el modelo de Zhai y Lafferty y los modelos de relevancia de Lavrenko y Crofts [12, 29]. Ambos enfoques intentan utilizar documentos pseudo-relevantes o relevantes para estimar un modelo de consulta mejor. El feedback basado en modelos encuentra el modelo que mejor describe los documentos relevantes teniendo en cuenta un modelo de fondo (ruido). Esto separa el modelo de contenido del modelo de fondo. El modelo de contenido se interpola con el modelo de consulta original para formar la consulta ampliada. La otra técnica, modelos de relevancia, está más relacionada con nuestro trabajo. Por lo tanto, entramos en los detalles del modelo. Al igual que el feedback basado en modelos, los modelos de relevancia estiman un modelo de consulta mejorado. La única diferencia entre los dos enfoques es que los modelos de relevancia no modelan explícitamente los documentos relevantes o pseudo-relevantes. En cambio, ellos modelan una noción más generalizada de relevancia, como mostraremos ahora. Dada una consulta Q, un modelo de relevancia es una distribución multinomial, P(·|Q), que codifica la probabilidad de cada término dado la consulta como evidencia. Se calcula como: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) donde RQ es el conjunto de documentos que son relevantes o pseudo relevantes para la consulta Q. En el caso pseudo-relevante, estos son los documentos mejor clasificados para la consulta Q. Además, se asume que P(D) es uniforme en este conjunto. Estas suposiciones suaves hacen que el cálculo del posterior bayesiano sea más práctico. Después de que el modelo es estimado, los documentos son clasificados por recortar el modelo de relevancia al elegir los k términos más probables de P(·|Q). Esta distribución recortada se interpola luego con el modelo de consulta de máxima verosimilitud original. Esto se puede considerar como la expansión de la consulta original por k términos ponderados. A lo largo del resto de este trabajo, nos referimos a esta instancia de modelos de relevancia como RM3. Ha habido relativamente poco trabajo realizado en el área de expansión de consultas en el contexto de modelos de dependencia [9]. Sin embargo, ha habido varios intentos de expandir utilizando conceptos de varios términos. El método de análisis de contexto local (LCA) de Xu y Crofts combinaba la recuperación a nivel de pasaje con la expansión de conceptos, donde los conceptos eran términos y frases simples [28]. Los conceptos de expansión fueron elegidos y ponderados utilizando una métrica basada en estadísticas de co-ocurrencia. Sin embargo, no está claro, basándose en el análisis realizado, cuánto ayudaron las frases en comparación con los términos individuales solos. Papka y Allan investigan el uso de retroalimentación de relevancia para realizar la expansión de conceptos de varios términos en el enrutamiento de documentos [19]. Los conceptos utilizados en su trabajo son más generales que los utilizados en el LCA e incluyen estructuras de lenguaje de consulta InQuery, como #UW50(casa blanca), que corresponde al concepto en el que los términos casa y blanca ocurren, en cualquier orden, dentro de 50 términos uno del otro. Los resultados mostraron que combinar conceptos de un solo término y conceptos de varios términos con una ventana grande mejoró significativamente la efectividad. Sin embargo, no está claro si el mismo enfoque también es efectivo para la recuperación ad hoc, debido a las diferencias en las tareas. 3. Este apartado detalla nuestra técnica propuesta de expansión de conceptos latentes. Como se mencionó anteriormente, la técnica es una extensión del modelo MRF para la recuperación de información [14]. Por lo tanto, comenzamos proporcionando una visión general del modelo MRF y nuestras extensiones propuestas. 3.1 MRFs para IR 3.1.1 Conceptos básicos Los campos aleatorios de Markov, que son modelos gráficos no dirigidos, proporcionan una forma compacta y robusta de modelar una distribución conjunta. Aquí estamos interesados en modelar la distribución conjunta sobre una consulta Q = q1, . . . , qn y un documento D. Se asume que la distribución subyacente sobre pares de documentos y consultas es una distribución de relevancia. Es decir, muestrear de la distribución proporciona pares de documentos y consultas, de modo que el documento sea relevante para la consulta. Un MRF se define por un grafo G y un conjunto de funciones de potencial no negativas sobre los cliques en G. Los nodos en el grafo representan las variables aleatorias y las aristas definen la semántica de independencia de la distribución. Un MRF cumple con la propiedad de Markov, la cual establece que un nodo es independiente de todos sus nodos no vecinos dado los valores observados de sus vecinos. Dado un grafo G, un conjunto de potenciales ψi y un vector de parámetros Λ, la distribución conjunta sobre Q y D está dada por: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) donde Z es una constante de normalización. Seguimos la convención común y parametrizamos los potenciales como ψi(c; Λ) = exp[λifi(c)], donde fi(c) es una función de características de valores reales. 3.1.2 Construcción de G Dada una consulta Q, el grafo G puede ser construido de varias maneras. Sin embargo, siguiendo el trabajo previo, consideramos tres variantes simples [14]. Estas variantes son independencia total, donde cada término de consulta es independiente de los demás dado un documento, dependencia secuencial, que asume que existe una dependencia entre los términos de consulta adyacentes, y dependencia total, que no hace suposiciones de independencia. 3.1.3 Parametrización Los MRFs suelen ser parametrizados comúnmente en función de los cliques máximos de G. Sin embargo, dicha parametrización es demasiado gruesa para nuestras necesidades. Necesitamos una parametrización que nos permita asociar funciones de características con cliques a un nivel más detallado, manteniendo al mismo tiempo el número de características, y por lo tanto el número de parámetros, razonable. Por lo tanto, permitimos que los grupos compartan funciones de características y parámetros basados en conjuntos de grupos. Es decir, todos los subgrupos dentro de un conjunto de subgrupos están asociados con la misma función de característica y comparten un solo parámetro. Esto une de manera efectiva los parámetros de las características asociadas con cada conjunto, lo que reduce significativamente el número de parámetros mientras aún proporciona un mecanismo para el ajuste fino en el nivel de conjuntos de cliques. Proponemos siete conjuntos de cliques para utilizar en la recuperación de información. Los primeros tres conjuntos de cliques consisten en cliques que contienen uno o más términos de consulta y el nodo del documento. Las características sobre estos grupos deberían codificar qué tan bien los términos en la configuración del grupo describen el documento. Estos conjuntos son: • TD - conjunto de cliques que contienen el nodo del documento y exactamente un término de consulta. • OD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en orden secuencial dentro de la consulta. • UD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en cualquier orden dentro de la consulta. Ten en cuenta que UD es un superconjunto de OD. Al atar los parámetros entre los grupos dentro de cada conjunto podemos controlar cuánta influencia recibe cada tipo. Esto también evita el problema de tratar de determinar cómo estimar los pesos para cada clique dentro de los conjuntos. En cambio, ahora solo debemos estimar un parámetro por conjunto. A continuación, consideramos cliques que solo contienen nodos de términos de consulta. Estas cliques, que no fueron consideradas en [14], se definen de manera análoga a las recién definidas, excepto que las cliques solo están formadas por nodos de términos de consulta y no contienen el nodo de documento. Las funciones de características sobre estos conjuntos deben capturar qué tan compatibles son entre sí los términos de consulta. Estas características de grupo pueden adoptar la forma de modelos de lenguaje que imponen la corrección de los términos. Por lo tanto, definimos los siguientes conjuntos de cliques dependientes de la consulta: • TQ - conjunto de cliques que contienen exactamente un término de la consulta. • OQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en orden secuencial dentro de la consulta. • UQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en cualquier orden dentro de la consulta. Finalmente, está la clique que solo contiene el nodo del documento. Las características sobre este nodo pueden ser utilizadas como un tipo de documento previo, codificando propiedades centradas en el documento. Este conjunto de cliques trivial es entonces: • D - conjunto de cliques que contiene solo el nodo único D. Observamos que nuestros conjuntos de cliques forman una cobertura de conjuntos sobre los cliques de G, pero no son una partición, ya que algunos cliques aparecen en múltiples conjuntos de cliques. Después de atar los parámetros en nuestros conjuntos de cliques y usar la forma de la función potencial exponencial, terminamos con la siguiente forma simplificada de la distribución conjunta: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - dependiente del documento y la consulta + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - dependiente de la consulta + λDfD(D) FD(D) - dependiente del documento − log ZΛ documento + independiente de la consulta donde FDQ, FQ y FD son funciones de conveniencia definidas por los componentes dependientes del documento y la consulta, dependientes de la consulta y dependientes del documento de la distribución conjunta, respectivamente. Estos se utilizarán para simplificar y clarificar las expresiones derivadas a lo largo del resto del documento. 3.1.4 Características Cualquier función de característica arbitraria sobre configuraciones de cliques puede ser utilizada en el modelo. La elección correcta de las características depende en gran medida de la tarea de recuperación y la métrica de evaluación. Por lo tanto, es probable que no exista un conjunto único y universalmente aplicable de características. Para dar una idea de la variedad de características que se pueden utilizar, ahora describimos brevemente posibles tipos de características que podrían ser utilizadas. Posibles características dependientes del término de consulta incluyen tf, idf, entidades nombradas, proximidad de términos y estilo de texto, por nombrar algunas. Se pueden utilizar muchos tipos de características dependientes del documento, como la longitud del documento, el PageRank, la legibilidad y el género, entre otros. Dado que nuestro objetivo aquí no es encontrar características óptimas, utilizamos un conjunto simple y fijo de características que han demostrado ser efectivas en trabajos anteriores [14]. Consulte la Tabla 1 para ver la lista de características utilizadas. Estas características intentan capturar la ocurrencia de términos y la proximidad entre términos. Una mejor selección de características en el futuro probablemente conducirá a una mayor efectividad. 3.1.5 Clasificación Dada una consulta Q, deseamos clasificar los documentos en orden descendente según PG,Λ(D|Q). Después de eliminar las expresiones independientes del documento del registro PG,Λ(Q, D), derivamos la siguiente función de clasificación: PG,Λ(D|Q) rango = FDQ(D, Q) + FD(D) (2), que es una simple combinación lineal ponderada de funciones de características que pueden calcularse eficientemente para grafos razonables. 3.1.6 Estimación de Parámetros Ahora que el modelo ha sido completamente especificado, el paso final es estimar los parámetros del modelo. Aunque los MRF son modelos generativos, no es apropiado entrenarlos utilizando la función de valor de características fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Tabla 1: Funciones de características utilizadas en el modelo de <br>campo aleatorio de Markov</br>. Aquí, tfw,D es el número de veces que el término w ocurre en el documento D, tf#1(qi...qi+k),D denota el número de veces que la frase exacta qi . . . qi+k ocurre en el documento D, tf#uw(qi...qj ),D es el número de veces que los términos qi, . . . qj aparecen ordenados o desordenados dentro de una ventana de N términos, y |D| es la longitud del documento D. Los valores de cf y |C| se definen de manera análoga a nivel de colección. Finalmente, α y β son hiperparámetros del modelo que controlan el suavizado para las características de términos únicos y frases, respectivamente. Enfoques convencionales basados en la verosimilitud debido a la divergencia métrica [17]. Es decir, es poco probable que la estimación de máxima verosimilitud sea la estimación que maximiza nuestra métrica de evaluación. Por esta razón, entrenamos de manera discriminativa nuestro modelo para maximizar directamente la métrica de evaluación considerada [14, 15, 25]. Dado que nuestro espacio de parámetros es pequeño, hacemos uso de una estrategia simple de escalada de colina, aunque son posibles otros enfoques más sofisticados [10]. 3.2 Expansión de Conceptos Latentes En esta sección describimos cómo este modelo MRF extendido puede ser utilizado de una manera novedosa para generar conceptos de un solo término y de varios términos que están relacionados temáticamente con alguna consulta original. Como mostraremos, los conceptos generados utilizando nuestra técnica pueden ser utilizados para la expansión de consultas u otras tareas, como sugerir formulaciones alternativas de consultas. Suponemos que cuando un usuario formula su consulta original, tiene en mente un conjunto de conceptos, pero solo puede expresar un pequeño número de ellos en forma de consulta. Tratamos los conceptos que el usuario tiene en mente, pero no expresó explícitamente en la consulta, como conceptos latentes. Estos conceptos latentes pueden consistir en un solo término, varios términos o alguna combinación de ambos. Por lo tanto, nuestro objetivo es recuperar estos conceptos latentes dada alguna consulta original. Esto se puede lograr dentro de nuestro marco de trabajo al expandir primero el grafo original G para incluir el tipo de concepto que nos interesa generar. Llamamos a este gráfico expandido H. En la Figura 1, el gráfico del medio proporciona un ejemplo de cómo construir un gráfico expandido que puede generar conceptos de un solo término. De manera similar, el gráfico de la derecha ilustra un gráfico ampliado que genera dos conceptos de términos. Aunque estos dos ejemplos hacen uso de la suposición de dependencia secuencial (es decir, dependencias entre términos de consulta adyacentes), es importante tener en cuenta que tanto la consulta original como los conceptos de expansión pueden utilizar cualquier estructura de independencia. Después de que H se construye, calculamos PH,Λ(E|Q), una distribución de probabilidad sobre conceptos latentes, de acuerdo a: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) donde R es el universo de todos los documentos posibles y E es un concepto latente que puede consistir en uno o más términos. Dado que no es práctico calcular esta suma, debemos aproximarla. Observamos que PH,Λ(Q, E, D) probablemente se concentra alrededor de aquellos documentos D que están altamente clasificados según la consulta Q. Por lo tanto, aproximamos PH,Λ(E|Q) sumando solo un pequeño subconjunto de documentos relevantes o pseudo-relevantes para la consulta Q. Esto se calcula de la siguiente manera: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) donde RQ es un conjunto de documentos relevantes o pseudo-relevantes para la consulta Q y todos los conjuntos de cliques se construyen utilizando H. Como vemos, la contribución de probabilidad para cada documento en RQ es una combinación de la puntuación original de la consulta para el documento (ver Ecuación 2), la puntuación del concepto E para el documento y la puntuación independiente del documento de E. Por lo tanto, esta ecuación puede interpretarse como la medida de qué tan bien Q y E explican los documentos mejor clasificados y la bondad de E, independientemente de los documentos. Para lograr la máxima robustez, utilizamos un conjunto diferente de parámetros para FQD(Q, D) y FQD(E, D), lo que nos permite ponderar de manera diferente las características de ventana ordenadas y no ordenadas para la consulta original y el concepto de expansión candidato. 3.2.1 Expansión de consulta Para utilizar este marco para la expansión de consultas, primero elegimos un grafo de expansión H que codifique la estructura de concepto latente en la que estamos interesados en expandir la consulta. Luego seleccionamos los k conceptos latentes con la mayor probabilidad dada por la Ecuación 3. Se construye un nuevo grafo G al aumentar el grafo original G con los k conceptos de expansión E1, . . . , Ek. Finalmente, los documentos se clasifican según PG ,Λ(D|Q, E1, . . . , Ek) utilizando la Ecuación 2. 3.2.2 Comparación con los Modelos de Relevancia. Al inspeccionar las Ecuaciones 1 y 3 se revela la estrecha conexión que existe entre LCE y los modelos de relevancia. Ambos modelos esencialmente calculan la probabilidad de un término (o concepto) de la misma manera. Es fácil ver que al igual que el modelo MRF puede ser visto como una generalización del modelado del lenguaje, también LCE puede ser visto como una generalización de los modelos de relevancia. Existen diferencias importantes entre los modelos de lenguaje MRFs/LCE y los modelos de lenguaje unigram/relevancia. Consulte la Figura 1 para ver las representaciones gráficas de ambos modelos. Los modelos de lenguaje unigrama y los modelos de relevancia se basan en la distribución multinomial. Esta suposición de distribución encasilla el modelo en la representación de bolsa de palabras y el uso implícito de características de ocurrencia de términos. Sin embargo, la distribución subyacente al modelo MRF nos permite ir más allá de ambas suposiciones, al modelar tanto las dependencias entre los términos de consulta como permitir el uso explícito de características arbitrarias. Ir más allá de la simplista suposición de la bolsa de palabras de esta manera resulta en un modelo general y robusto y, como mostramos en la siguiente sección, se traduce en mejoras significativas en la efectividad de recuperación. 4. RESULTADOS EXPERIMENTALES Para comprender mejor las fortalezas y debilidades de nuestra técnica, la evaluamos en una amplia gama de conjuntos de datos. La Tabla 2 proporciona un resumen de los conjuntos de datos de TREC considerados. Las colecciones WSJ, AP y ROBUST son más pequeñas y consisten enteramente de artículos de agencias de noticias, mientras que WT10g y GOV2 son colecciones web grandes. Para cada conjunto de datos, dividimos los temas disponibles en un conjunto de entrenamiento y otro de prueba, donde el conjunto de entrenamiento se utiliza únicamente para la estimación de parámetros y el conjunto de prueba se utiliza con fines de evaluación. Todos los experimentos se llevaron a cabo utilizando una versión modificada de Indri, que forma parte del Lemur Toolkit [18, 23]. Todas las colecciones fueron detenidas utilizando una lista estándar de 418 términos comunes y truncadas utilizando un truncador de Porter. En todos los casos, solo se utiliza la parte del título de los temas de TREC para construir las consultas. Construimos G utilizando la suposición de dependencia secuencial para todos los conjuntos de datos [14]. 4.1 Resultados de recuperación ad-hoc Ahora investigamos qué tan bien se desempeña nuestro modelo en la práctica en un entorno de retroalimentación de relevancia pseudo. Comparamos el modelado de lenguaje unigrama (con suavizado de Dirichlet), el modelo MRF (sin expansión), los modelos de relevancia y LCE para comprender mejor cómo se desempeña cada modelo en los diferentes conjuntos de datos. Para el modelo de lenguaje unigrama, se entrenó el parámetro de suavizado. Para el modelo MRF, entrenamos los parámetros del modelo (es decir, y hiperparámetros del modelo (es decir, α, β). Para RM3 y LCE, también entrenamos el número de pseudoNombre Descripción # Docs Temas de Entrenamiento Temas de Prueba WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc. Presione 88-90 242,918 51-150 151-200 ROBUST Robust 2004 datos 528,155 301-450 601-700 WT10g Colección Web de TREC 1,692,096 451-500 501-550 GOV2 Rastreo 2004 del dominio .gov 25,205,179 701-750 751-800 Tabla 2: Resumen de las colecciones y temas de TREC. documentos de retroalimentación relevantes utilizados y el número de términos de expansión. 4.1.1 Expansión con Conceptos de Términos Únicos Comenzamos evaluando qué tan bien funciona nuestro modelo al expandir utilizando solo términos individuales. Antes de describir y analizar los resultados, declaramos explícitamente cómo se calculan las probabilidades de términos de expansión bajo esta configuración (es decir, utilizando la suposición de dependencia secuencial, expandiendo con conceptos de un solo término y utilizando nuestro conjunto de características). Las probabilidades de términos de expansión se calculan de la siguiente manera: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) donde b ∈ Q denota el conjunto de bigramas en Q. Esta ecuación muestra claramente cómo LCE difiere de los modelos de relevancia. Cuando establecemos λTD = λT,D = 1 y todos los demás parámetros en 0, obtenemos la fórmula exacta que se utiliza para calcular las probabilidades de términos en el marco de modelado de relevancia. Por lo tanto, LCE añade dos factores muy importantes a la ecuación. Primero, agrega las características de ventana ordenadas y no ordenadas que se aplican a la consulta original. En segundo lugar, aplica una forma intuitiva similar a tf.idf al término de expansión candidato w. El factor idf, que no está presente en los modelos de relevancia, juega un papel importante en la selección del término de expansión. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figura 2: Histogramas que demuestran y comparan la robustez de los modelos de relevancia (RM3) y la expansión de conceptos latentes (LCE) con respecto al modelo de probabilidad de consulta (QL) para los conjuntos de datos AP, ROBUST y WT10G. Los resultados, evaluados utilizando la precisión promedio media, se muestran en la Tabla 3. Como vemos, el modelo MRF, los modelos de relevancia y LCE siempre superan significativamente al modelo de lenguaje unigrama. Además, LCE muestra mejoras significativas sobre los modelos de relevancia en todos los conjuntos de datos. Las mejoras relativas sobre los modelos de relevancia son del 6.9% para AP, 12.9% para WSJ, 6.5% para ROBUST, 16.7% para WT10G y 7.3% para GOV2. Además, LCE muestra pequeñas mejoras, pero no significativas, respecto al modelado de relevancia para métricas como precisión en 5, 10 y 20. Sin embargo, tanto el modelado de relevancia como el LCE muestran mejoras estadísticamente significativas en dichas métricas sobre el modelo de lenguaje unigrama. Otro resultado interesante es que el modelo MRF es estadísticamente equivalente a los modelos de relevancia en los dos conjuntos de datos web. De hecho, el modelo MRF supera a los modelos de relevancia en el conjunto de datos WT10g. Esto reitera la importancia de las características no unigrama, basadas en la proximidad para la búsqueda web basada en contenido observada previamente [14, 16]. Aunque nuestro modelo tiene más parámetros libres que los modelos de relevancia, sorprendentemente hay poco sobreajuste. En cambio, el modelo muestra buenas propiedades de generalización. 4.1.2 Expansión con Conceptos de Múltiples Términos También investigamos la expansión utilizando conceptos de una y dos palabras. Para cada consulta, expandimos utilizando un conjunto de conceptos de un solo término y un conjunto de conceptos de dos términos. Los conjuntos fueron elegidos de forma independiente. Desafortunadamente, solo se observaron aumentos insignificantes en la precisión promedio. Este resultado puede deberse al hecho de que existen fuertes correlaciones entre los conceptos de expansión de términos individuales. Descubrimos que los dos conceptos de palabras elegidos a menudo consistían en dos términos altamente correlacionados que también son elegidos como conceptos de términos individuales. Por ejemplo, se eligió el concepto de dos términos mercado de valores, mientras que también se eligieron los conceptos de un solo término acciones y mercado. Por lo tanto, muchos conceptos de dos palabras es poco probable que aumenten el poder discriminativo de la consulta ampliada. Este resultado sugiere que los conceptos deben ser elegidos de acuerdo con ciertos criterios que también tengan en cuenta la novedad, la diversidad o las correlaciones de términos. Otro problema potencial es el conjunto de características utilizado. Otros conjuntos de características pueden dar resultados diferentes en última instancia, especialmente si reducen la correlación entre los conceptos de expansión. Por lo tanto, nuestros experimentos no arrojan resultados concluyentes en cuanto a la expansión utilizando conceptos de varios términos. En cambio, los resultados plantean preguntas abiertas interesantes y direcciones para futuras exploraciones. Tabla 3: Promedio de precisión media en el conjunto de pruebas para modelado de lenguaje (LM), <br>campo aleatorio de Markov</br> (MRF), modelos de relevancia (RM3) y expansión de conceptos latentes (LCE). Los superíndices α, β y γ indican mejoras estadísticamente significativas (p < 0.05) sobre LM, MRF y RM3, respectivamente. 4.2 Robustez Como hemos demostrado, los modelos de relevancia y la expansión de conceptos latentes pueden mejorar significativamente la efectividad de recuperación sobre el modelo de probabilidad de consulta base. En esta sección analizamos la robustez de estos dos métodos. Aquí definimos la robustez como el número de consultas cuya efectividad se ve mejorada/afectada (y en qué medida) como resultado de aplicar estos métodos. Una técnica de expansión altamente robusta mejorará significativamente muchas consultas y solo perjudicará mínimamente a unas pocas. La Figura 2 proporciona un análisis de la robustez del modelado de relevancia y la expansión de conceptos latentes para los conjuntos de datos AP, ROBUST y WT10G. El análisis de los dos conjuntos de datos no mostrados es similar. Los histogramas proporcionan, para varios rangos de disminuciones/aumentos relativos en la precisión media promedio, el número de consultas que se vieron perjudicadas/mejoradas con respecto a la línea base de probabilidad de consulta. Como muestran los resultados, LCE muestra una fuerte robustez para cada conjunto de datos. Para AP, los modelos de relevancia mejoran 38 consultas y perjudican 11, mientras que LCE mejora 35 y perjudica 14. Aunque los modelos de relevancia mejoran la efectividad de 3 consultas más que LCE, la mejora relativa exhibida por LCE es significativamente mayor. Para el conjunto de datos ROBUST, los modelos de relevancia mejoran 67 consultas y perjudican 32, y LCE mejora 77 y perjudica 22. Finalmente, para la colección WT10G, los modelos de relevancia mejoran 32 consultas y perjudican 16, y LCE mejora 35 y perjudica 14. Al igual que con AP, la cantidad de mejora exhibida por el LCE frente a los modelos de relevancia es significativamente mayor tanto para los conjuntos de datos ROBUST como WT10G. Además, cuando LCE afecta al rendimiento, es menos probable que afecte tanto como el modelado de relevancia, lo cual es una propiedad deseable. En general, LCE mejora la efectividad para el 65%-80% de las consultas, dependiendo del conjunto de datos. Cuando se utiliza en combinación con un sistema de predicción de rendimiento de consulta altamente preciso, puede ser posible expandir selectivamente las consultas y minimizar la pérdida asociada con el rendimiento sub-baseline. 4.3 Generación de Conceptos de Múltiples Términos Aunque encontramos que la expansión utilizando conceptos de múltiples términos no logró producir mejoras concluyentes en la efectividad, hay otras tareas potenciales para las cuales estos conceptos pueden ser útiles, como sugerencia/reformulación de consultas, resumen y extracción de conceptos. Por ejemplo, para una tarea de sugerencia de consultas, la consulta original podría usarse para generar un conjunto de conceptos latentes que corresponden a formulaciones alternativas de la consulta. Aunque evaluar nuestro modelo en estas tareas está fuera del alcance de este trabajo, deseamos mostrar un ejemplo ilustrativo de los tipos de conceptos generados utilizando nuestro modelo. En la Tabla 4, presentamos los conceptos de una, dos y tres palabras más probables generados utilizando LCE para la consulta logros del telescopio Hubble utilizando los 25 documentos mejor clasificados de la colección ROBUST. Es bien sabido que generar conceptos de múltiples términos utilizando un modelo basado en unigramas produce resultados insatisfactorios, ya que no considera las dependencias entre los términos. Esto no es el caso al generar conceptos de múltiples términos usando nuestro modelo. En cambio, la mayoría de los conceptos generados son bien formados y significativos. Hay varios casos donde los conceptos son menos coherentes, como espejo espejo espejo. En este caso, la probabilidad de que aparezca el término \"espejo\" en un documento pseudo-relevante supera a las características de modelado de lenguaje (por ejemplo, fOQ), lo que provoca que este concepto no coherente tenga una alta probabilidad. Tales ejemplos son minoría, sin embargo. No solo los conceptos generados son bien formados y significativos, sino que también son relevantes al tema de la consulta original. Como podemos ver, todos los conceptos generados están relacionados con el tema y de alguna manera están relacionados con el telescopio Hubble. Es interesante ver que el concepto de fallo del telescopio Hubble es uno de los tres conceptos de términos más probables, dado que es algo contradictorio con la consulta original. A pesar de esta contradicción, es probable que los documentos que discuten las fallas del telescopio también describan los éxitos, por lo tanto, es probable que este sea un concepto significativo. Una cosa importante a tener en cuenta es que los conceptos generados por LCE son de una naturaleza diferente a los que se generarían utilizando un modelo de relevancia de bigrama. Por ejemplo, un modelo de bigrama sería poco probable que genere el concepto telescopio espacio NASA, ya que ninguno de los bigramas que componen el concepto tiene una alta probabilidad. Sin embargo, dado que nuestro modelo se basa en una serie de características diferentes sobre varios tipos de cliques, es más general y robusto que un modelo de bigrama. Aunque solo proporcionamos los conceptos generados para una sola consulta, señalamos que el mismo análisis y conclusiones se generalizan a través de otros conjuntos de datos, con conceptos coherentes y relacionados temáticamente generados de manera consistente utilizando LCE. 4.4 Discusión Nuestra técnica de expansión de conceptos latentes captura dos tipos de dependencia semiortogonales. En la recuperación de información, ha existido un interés a largo plazo en comprender el papel de la dependencia de términos. De esta investigación, se han identificado dos tipos generales de dependencias. El primer tipo de dependencia es la dependencia sintáctica. Este tipo de dependencia abarca frases, proximidad de términos y co-ocurrencia de términos [2, 4, 5, 7, 26]. Estos métodos capturan el hecho de que las consultas imponen implícita o explícitamente un cierto conjunto de dependencias posicionales. El segundo tipo es la dependencia semántica. Ejemplos de dependencia semántica son la retroalimentación de relevancia, la retroalimentación de pseudo-relevancia, sinónimos y en cierta medida el truncamiento [3]. Estas técnicas han sido exploradas tanto en el lado de la consulta como en el lado del documento. En el lado de la consulta, esto se suele hacer utilizando alguna forma de expansión de consulta, como modelos de relevancia o LCE. En el lado del documento, esto se hace como expansión de documentos o suavizado de documentos [11, 13, 24]. Aunque puede haber cierta superposición entre las dependencias sintácticas y semánticas, en su mayoría son ortogonales. Nuestro modelo utiliza ambos tipos de dependencias. El uso de características de frase y proximidad dentro del modelo captura dependencias sintácticas, mientras que LCE captura dependencias semánticas del lado de la consulta. Esto explica por qué la mejora inicial en la efectividad lograda al usar el modelo MRF no se pierde después de la expansión de consultas. Si los mismos tipos de dependencias fueran capturados tanto por dependencias sintácticas como semánticas, se esperaría que LCE funcionara aproximadamente igual de bien que los modelos de relevancia. Por lo tanto, al modelar ambos tipos de dependencias, observamos un efecto aditivo en lugar de un efecto absorbente. Una área interesante de trabajo futuro es determinar si modelar las dependencias semánticas del lado del documento puede aportar algo al modelo. Resultados previos que han combinado dependencias semánticas del lado de la consulta y del documento han mostrado resultados mixtos [13, 27]. 5. CONCLUSIONES En este artículo propusimos una técnica robusta de expansión de consultas llamada expansión de conceptos latentes. La técnica se demostró ser una extensión natural del <br>modelo de campo aleatorio de Markov</br> para la recuperación de información y una generalización de los modelos de relevancia. ",
            "candidates": [],
            "error": [
                [
                    "campo aleatorio de Markov",
                    "campo aleatorio de Markov",
                    "campo aleatorio de Markov",
                    "campo aleatorio de Markov",
                    "modelo de campo aleatorio de Markov"
                ]
            ]
        }
    }
}